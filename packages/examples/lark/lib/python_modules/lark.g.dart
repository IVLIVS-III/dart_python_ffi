// ignore_for_file: camel_case_types, non_constant_identifier_names

library lark;

import "package:python_ffi_dart/python_ffi_dart.dart";

/// ## GrammarError
///
/// ### python source
/// ```py
/// class GrammarError(LarkError):
///     pass
/// ```
final class GrammarError extends PythonClass {
  factory GrammarError() => PythonFfiDart.instance.importClass(
        "lark.exceptions",
        "GrammarError",
        GrammarError.from,
        <Object?>[],
      );

  GrammarError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## Lark
///
/// ### python docstring
///
/// Main interface for the library.
///
/// It's mostly a thin wrapper for the many different parsers, and for the tree constructor.
///
/// Parameters:
///     grammar: a string or file-object containing the grammar spec (using Lark's ebnf syntax)
///     options: a dictionary controlling various aspects of Lark.
///
/// Example:
///     >>> Lark(r'''start: "foo" ''')
///     Lark(...)
///
///
///
/// **===  General Options  ===**
///
/// start
///         The start symbol. Either a string, or a list of strings for multiple possible starts (Default: "start")
/// debug
///         Display debug information and extra warnings. Use only when debugging (Default: ``False``)
///         When used with Earley, it generates a forest graph as "sppf.png", if 'dot' is installed.
/// transformer
///         Applies the transformer to every parse tree (equivalent to applying it after the parse, but faster)
/// propagate_positions
///         Propagates (line, column, end_line, end_column) attributes into all tree branches.
///         Accepts ``False``, ``True``, or a callable, which will filter which nodes to ignore when propagating.
/// maybe_placeholders
///         When ``True``, the ``[]`` operator returns ``None`` when not matched.
///         When ``False``,  ``[]`` behaves like the ``?`` operator, and returns no value at all.
///         (default= ``True``)
/// cache
///         Cache the results of the Lark grammar analysis, for x2 to x3 faster loading. LALR only for now.
///
///         - When ``False``, does nothing (default)
///         - When ``True``, caches to a temporary file in the local directory
///         - When given a string, caches to the path pointed by the string
/// regex
///         When True, uses the ``regex`` module instead of the stdlib ``re``.
/// g_regex_flags
///         Flags that are applied to all terminals (both regex and strings)
/// keep_all_tokens
///         Prevent the tree builder from automagically removing "punctuation" tokens (Default: ``False``)
/// tree_class
///         Lark will produce trees comprised of instances of this class instead of the default ``lark.Tree``.
///
/// **=== Algorithm Options ===**
///
/// parser
///         Decides which parser engine to use. Accepts "earley" or "lalr". (Default: "earley").
///         (there is also a "cyk" option for legacy)
/// lexer
///         Decides whether or not to use a lexer stage
///
///         - "auto" (default): Choose for me based on the parser
///         - "basic": Use a basic lexer
///         - "contextual": Stronger lexer (only works with parser="lalr")
///         - "dynamic": Flexible and powerful (only with parser="earley")
///         - "dynamic_complete": Same as dynamic, but tries *every* variation of tokenizing possible.
/// ambiguity
///         Decides how to handle ambiguity in the parse. Only relevant if parser="earley"
///
///         - "resolve": The parser will automatically choose the simplest derivation
///           (it chooses consistently: greedy for tokens, non-greedy for rules)
///         - "explicit": The parser will return all derivations wrapped in "_ambig" tree nodes (i.e. a forest).
///         - "forest": The parser will return the root of the shared packed parse forest.
///
/// **=== Misc. / Domain Specific Options ===**
///
/// postlex
///         Lexer post-processing (Default: ``None``) Only works with the basic and contextual lexers.
/// priority
///         How priorities should be evaluated - "auto", ``None``, "normal", "invert" (Default: "auto")
/// lexer_callbacks
///         Dictionary of callbacks for the lexer. May alter tokens during lexing. Use with caution.
/// use_bytes
///         Accept an input of type ``bytes`` instead of ``str``.
/// edit_terminals
///         A callback for editing the terminals before parse.
/// import_paths
///         A List of either paths or loader functions to specify from where grammars are imported
/// source_path
///         Override the source of from where the grammar was loaded. Useful for relative imports and unconventional grammar loading
/// **=== End of Options ===**
///
/// ### python source
/// ```py
/// class Lark(Serialize):
///     """Main interface for the library.
///
///     It's mostly a thin wrapper for the many different parsers, and for the tree constructor.
///
///     Parameters:
///         grammar: a string or file-object containing the grammar spec (using Lark's ebnf syntax)
///         options: a dictionary controlling various aspects of Lark.
///
///     Example:
///         >>> Lark(r'''start: "foo" ''')
///         Lark(...)
///     """
///
///     source_path: str
///     source_grammar: str
///     grammar: 'Grammar'
///     options: LarkOptions
///     lexer: Lexer
///     terminals: Collection[TerminalDef]
///
///     def __init__(self, grammar: 'Union[Grammar, str, IO[str]]', **options) -> None:
///         self.options = LarkOptions(options)
///         re_module: types.ModuleType
///
///         # Set regex or re module
///         use_regex = self.options.regex
///         if use_regex:
///             if _has_regex:
///                 re_module = regex
///             else:
///                 raise ImportError('`regex` module must be installed if calling `Lark(regex=True)`.')
///         else:
///             re_module = re
///
///         # Some, but not all file-like objects have a 'name' attribute
///         if self.options.source_path is None:
///             try:
///                 self.source_path = grammar.name  # type: ignore[union-attr]
///             except AttributeError:
///                 self.source_path = '<string>'
///         else:
///             self.source_path = self.options.source_path
///
///         # Drain file-like objects to get their contents
///         try:
///             read = grammar.read  # type: ignore[union-attr]
///         except AttributeError:
///             pass
///         else:
///             grammar = read()
///
///         cache_fn = None
///         cache_md5 = None
///         if isinstance(grammar, str):
///             self.source_grammar = grammar
///             if self.options.use_bytes:
///                 if not isascii(grammar):
///                     raise ConfigurationError("Grammar must be ascii only, when use_bytes=True")
///
///             if self.options.cache:
///                 if self.options.parser != 'lalr':
///                     raise ConfigurationError("cache only works with parser='lalr' for now")
///
///                 unhashable = ('transformer', 'postlex', 'lexer_callbacks', 'edit_terminals', '_plugins')
///                 options_str = ''.join(k+str(v) for k, v in options.items() if k not in unhashable)
///                 from . import __version__
///                 s = grammar + options_str + __version__ + str(sys.version_info[:2])
///                 cache_md5 = md5_digest(s)
///
///                 if isinstance(self.options.cache, str):
///                     cache_fn = self.options.cache
///                 else:
///                     if self.options.cache is not True:
///                         raise ConfigurationError("cache argument must be bool or str")
///
///                     try:
///                         username = getpass.getuser()
///                     except Exception:
///                         # The exception raised may be ImportError or OSError in
///                         # the future.  For the cache, we don't care about the
///                         # specific reason - we just want a username.
///                         username = "unknown"
///
///                     cache_fn = tempfile.gettempdir() + "/.lark_cache_%s_%s_%s_%s.tmp" % (username, cache_md5, *sys.version_info[:2])
///
///                 old_options = self.options
///                 try:
///                     with FS.open(cache_fn, 'rb') as f:
///                         logger.debug('Loading grammar from cache: %s', cache_fn)
///                         # Remove options that aren't relevant for loading from cache
///                         for name in (set(options) - _LOAD_ALLOWED_OPTIONS):
///                             del options[name]
///                         file_md5 = f.readline().rstrip(b'\n')
///                         cached_used_files = pickle.load(f)
///                         if file_md5 == cache_md5.encode('utf8') and verify_used_files(cached_used_files):
///                             cached_parser_data = pickle.load(f)
///                             self._load(cached_parser_data, **options)
///                             return
///                 except FileNotFoundError:
///                     # The cache file doesn't exist; parse and compose the grammar as normal
///                     pass
///                 except Exception: # We should probably narrow done which errors we catch here.
///                     logger.exception("Failed to load Lark from cache: %r. We will try to carry on.", cache_fn)
///
///                     # In theory, the Lark instance might have been messed up by the call to `_load`.
///                     # In practice the only relevant thing that might have been overwritten should be `options`
///                     self.options = old_options
///
///
///             # Parse the grammar file and compose the grammars
///             self.grammar, used_files = load_grammar(grammar, self.source_path, self.options.import_paths, self.options.keep_all_tokens)
///         else:
///             assert isinstance(grammar, Grammar)
///             self.grammar = grammar
///
///
///         if self.options.lexer == 'auto':
///             if self.options.parser == 'lalr':
///                 self.options.lexer = 'contextual'
///             elif self.options.parser == 'earley':
///                 if self.options.postlex is not None:
///                     logger.info("postlex can't be used with the dynamic lexer, so we use 'basic' instead. "
///                                 "Consider using lalr with contextual instead of earley")
///                     self.options.lexer = 'basic'
///                 else:
///                     self.options.lexer = 'dynamic'
///             elif self.options.parser == 'cyk':
///                 self.options.lexer = 'basic'
///             else:
///                 assert False, self.options.parser
///         lexer = self.options.lexer
///         if isinstance(lexer, type):
///             assert issubclass(lexer, Lexer)     # XXX Is this really important? Maybe just ensure interface compliance
///         else:
///             assert_config(lexer, ('basic', 'contextual', 'dynamic', 'dynamic_complete'))
///             if self.options.postlex is not None and 'dynamic' in lexer:
///                 raise ConfigurationError("Can't use postlex with a dynamic lexer. Use basic or contextual instead")
///
///         if self.options.ambiguity == 'auto':
///             if self.options.parser == 'earley':
///                 self.options.ambiguity = 'resolve'
///         else:
///             assert_config(self.options.parser, ('earley', 'cyk'), "%r doesn't support disambiguation. Use one of these parsers instead: %s")
///
///         if self.options.priority == 'auto':
///             self.options.priority = 'normal'
///
///         if self.options.priority not in _VALID_PRIORITY_OPTIONS:
///             raise ConfigurationError("invalid priority option: %r. Must be one of %r" % (self.options.priority, _VALID_PRIORITY_OPTIONS))
///         if self.options.ambiguity not in _VALID_AMBIGUITY_OPTIONS:
///             raise ConfigurationError("invalid ambiguity option: %r. Must be one of %r" % (self.options.ambiguity, _VALID_AMBIGUITY_OPTIONS))
///
///         if self.options.parser is None:
///             terminals_to_keep = '*'
///         elif self.options.postlex is not None:
///             terminals_to_keep = set(self.options.postlex.always_accept)
///         else:
///             terminals_to_keep = set()
///
///         # Compile the EBNF grammar into BNF
///         self.terminals, self.rules, self.ignore_tokens = self.grammar.compile(self.options.start, terminals_to_keep)
///
///         if self.options.edit_terminals:
///             for t in self.terminals:
///                 self.options.edit_terminals(t)
///
///         self._terminals_dict = {t.name: t for t in self.terminals}
///
///         # If the user asked to invert the priorities, negate them all here.
///         if self.options.priority == 'invert':
///             for rule in self.rules:
///                 if rule.options.priority is not None:
///                     rule.options.priority = -rule.options.priority
///             for term in self.terminals:
///                 term.priority = -term.priority
///         # Else, if the user asked to disable priorities, strip them from the
///         # rules and terminals. This allows the Earley parsers to skip an extra forest walk
///         # for improved performance, if you don't need them (or didn't specify any).
///         elif self.options.priority is None:
///             for rule in self.rules:
///                 if rule.options.priority is not None:
///                     rule.options.priority = None
///             for term in self.terminals:
///                 term.priority = 0
///
///         # TODO Deprecate lexer_callbacks?
///         self.lexer_conf = LexerConf(
///                 self.terminals, re_module, self.ignore_tokens, self.options.postlex,
///                 self.options.lexer_callbacks, self.options.g_regex_flags, use_bytes=self.options.use_bytes
///             )
///
///         if self.options.parser:
///             self.parser = self._build_parser()
///         elif lexer:
///             self.lexer = self._build_lexer()
///
///         if cache_fn:
///             logger.debug('Saving grammar to cache: %s', cache_fn)
///             try:
///                 with FS.open(cache_fn, 'wb') as f:
///                     assert cache_md5 is not None
///                     f.write(cache_md5.encode('utf8') + b'\n')
///                     pickle.dump(used_files, f)
///                     self.save(f, _LOAD_ALLOWED_OPTIONS)
///             except IOError as e:
///                 logger.exception("Failed to save Lark to cache: %r.", cache_fn, e)
///
///     if __doc__:
///         __doc__ += "\n\n" + LarkOptions.OPTIONS_DOC
///
///     __serialize_fields__ = 'parser', 'rules', 'options'
///
///     def _build_lexer(self, dont_ignore: bool=False) -> BasicLexer:
///         lexer_conf = self.lexer_conf
///         if dont_ignore:
///             from copy import copy
///             lexer_conf = copy(lexer_conf)
///             lexer_conf.ignore = ()
///         return BasicLexer(lexer_conf)
///
///     def _prepare_callbacks(self) -> None:
///         self._callbacks = {}
///         # we don't need these callbacks if we aren't building a tree
///         if self.options.ambiguity != 'forest':
///             self._parse_tree_builder = ParseTreeBuilder(
///                     self.rules,
///                     self.options.tree_class or Tree,
///                     self.options.propagate_positions,
///                     self.options.parser != 'lalr' and self.options.ambiguity == 'explicit',
///                     self.options.maybe_placeholders
///                 )
///             self._callbacks = self._parse_tree_builder.create_callback(self.options.transformer)
///         self._callbacks.update(_get_lexer_callbacks(self.options.transformer, self.terminals))
///
///     def _build_parser(self) -> "ParsingFrontend":
///         self._prepare_callbacks()
///         _validate_frontend_args(self.options.parser, self.options.lexer)
///         parser_conf = ParserConf(self.rules, self._callbacks, self.options.start)
///         return _construct_parsing_frontend(
///             self.options.parser,
///             self.options.lexer,
///             self.lexer_conf,
///             parser_conf,
///             options=self.options
///         )
///
///     def save(self, f, exclude_options: Collection[str] = ()) -> None:
///         """Saves the instance into the given file object
///
///         Useful for caching and multiprocessing.
///         """
///         data, m = self.memo_serialize([TerminalDef, Rule])
///         if exclude_options:
///             data["options"] = {n: v for n, v in data["options"].items() if n not in exclude_options}
///         pickle.dump({'data': data, 'memo': m}, f, protocol=pickle.HIGHEST_PROTOCOL)
///
///     @classmethod
///     def load(cls: Type[_T], f) -> _T:
///         """Loads an instance from the given file object
///
///         Useful for caching and multiprocessing.
///         """
///         inst = cls.__new__(cls)
///         return inst._load(f)
///
///     def _deserialize_lexer_conf(self, data: Dict[str, Any], memo: Dict[int, Union[TerminalDef, Rule]], options: LarkOptions) -> LexerConf:
///         lexer_conf = LexerConf.deserialize(data['lexer_conf'], memo)
///         lexer_conf.callbacks = options.lexer_callbacks or {}
///         lexer_conf.re_module = regex if options.regex else re
///         lexer_conf.use_bytes = options.use_bytes
///         lexer_conf.g_regex_flags = options.g_regex_flags
///         lexer_conf.skip_validation = True
///         lexer_conf.postlex = options.postlex
///         return lexer_conf
///
///     def _load(self: _T, f: Any, **kwargs) -> _T:
///         if isinstance(f, dict):
///             d = f
///         else:
///             d = pickle.load(f)
///         memo_json = d['memo']
///         data = d['data']
///
///         assert memo_json
///         memo = SerializeMemoizer.deserialize(memo_json, {'Rule': Rule, 'TerminalDef': TerminalDef}, {})
///         options = dict(data['options'])
///         if (set(kwargs) - _LOAD_ALLOWED_OPTIONS) & set(LarkOptions._defaults):
///             raise ConfigurationError("Some options are not allowed when loading a Parser: {}"
///                              .format(set(kwargs) - _LOAD_ALLOWED_OPTIONS))
///         options.update(kwargs)
///         self.options = LarkOptions.deserialize(options, memo)
///         self.rules = [Rule.deserialize(r, memo) for r in data['rules']]
///         self.source_path = '<deserialized>'
///         _validate_frontend_args(self.options.parser, self.options.lexer)
///         self.lexer_conf = self._deserialize_lexer_conf(data['parser'], memo, self.options)
///         self.terminals = self.lexer_conf.terminals
///         self._prepare_callbacks()
///         self._terminals_dict = {t.name: t for t in self.terminals}
///         self.parser = _deserialize_parsing_frontend(
///             data['parser'],
///             memo,
///             self.lexer_conf,
///             self._callbacks,
///             self.options,  # Not all, but multiple attributes are used
///         )
///         return self
///
///     @classmethod
///     def _load_from_dict(cls, data, memo, **kwargs):
///         inst = cls.__new__(cls)
///         return inst._load({'data': data, 'memo': memo}, **kwargs)
///
///     @classmethod
///     def open(cls: Type[_T], grammar_filename: str, rel_to: Optional[str]=None, **options) -> _T:
///         """Create an instance of Lark with the grammar given by its filename
///
///         If ``rel_to`` is provided, the function will find the grammar filename in relation to it.
///
///         Example:
///
///             >>> Lark.open("grammar_file.lark", rel_to=__file__, parser="lalr")
///             Lark(...)
///
///         """
///         if rel_to:
///             basepath = os.path.dirname(rel_to)
///             grammar_filename = os.path.join(basepath, grammar_filename)
///         with open(grammar_filename, encoding='utf8') as f:
///             return cls(f, **options)
///
///     @classmethod
///     def open_from_package(cls: Type[_T], package: str, grammar_path: str, search_paths: 'Sequence[str]'=[""], **options) -> _T:
///         """Create an instance of Lark with the grammar loaded from within the package `package`.
///         This allows grammar loading from zipapps.
///
///         Imports in the grammar will use the `package` and `search_paths` provided, through `FromPackageLoader`
///
///         Example:
///
///             Lark.open_from_package(__name__, "example.lark", ("grammars",), parser=...)
///         """
///         package_loader = FromPackageLoader(package, search_paths)
///         full_path, text = package_loader(None, grammar_path)
///         options.setdefault('source_path', full_path)
///         options.setdefault('import_paths', [])
///         options['import_paths'].append(package_loader)
///         return cls(text, **options)
///
///     def __repr__(self):
///         return 'Lark(open(%r), parser=%r, lexer=%r, ...)' % (self.source_path, self.options.parser, self.options.lexer)
///
///
///     def lex(self, text: str, dont_ignore: bool=False) -> Iterator[Token]:
///         """Only lex (and postlex) the text, without parsing it. Only relevant when lexer='basic'
///
///         When dont_ignore=True, the lexer will return all tokens, even those marked for %ignore.
///
///         :raises UnexpectedCharacters: In case the lexer cannot find a suitable match.
///         """
///         lexer: Lexer
///         if not hasattr(self, 'lexer') or dont_ignore:
///             lexer = self._build_lexer(dont_ignore)
///         else:
///             lexer = self.lexer
///         lexer_thread = LexerThread.from_text(lexer, text)
///         stream = lexer_thread.lex(None)
///         if self.options.postlex:
///             return self.options.postlex.process(stream)
///         return stream
///
///     def get_terminal(self, name: str) -> TerminalDef:
///         """Get information about a terminal"""
///         return self._terminals_dict[name]
///
///     def parse_interactive(self, text: Optional[str]=None, start: Optional[str]=None) -> 'InteractiveParser':
///         """Start an interactive parsing session.
///
///         Parameters:
///             text (str, optional): Text to be parsed. Required for ``resume_parse()``.
///             start (str, optional): Start symbol
///
///         Returns:
///             A new InteractiveParser instance.
///
///         See Also: ``Lark.parse()``
///         """
///         return self.parser.parse_interactive(text, start=start)
///
///     def parse(self, text: str, start: Optional[str]=None, on_error: 'Optional[Callable[[UnexpectedInput], bool]]'=None) -> 'ParseTree':
///         """Parse the given text, according to the options provided.
///
///         Parameters:
///             text (str): Text to be parsed.
///             start (str, optional): Required if Lark was given multiple possible start symbols (using the start option).
///             on_error (function, optional): if provided, will be called on UnexpectedToken error. Return true to resume parsing.
///                 LALR only. See examples/advanced/error_handling.py for an example of how to use on_error.
///
///         Returns:
///             If a transformer is supplied to ``__init__``, returns whatever is the
///             result of the transformation. Otherwise, returns a Tree instance.
///
///         :raises UnexpectedInput: On a parse error, one of these sub-exceptions will rise:
///                 ``UnexpectedCharacters``, ``UnexpectedToken``, or ``UnexpectedEOF``.
///                 For convenience, these sub-exceptions also inherit from ``ParserError`` and ``LexerError``.
///
///         """
///         return self.parser.parse(text, start=start, on_error=on_error)
/// ```
final class Lark extends PythonClass {
  factory Lark({
    required Object? grammar,
    Map<String, Object?> options = const <String, Object?>{},
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.lark",
        "Lark",
        Lark.from,
        <Object?>[
          grammar,
        ],
        <String, Object?>{
          ...options,
        },
      );

  Lark.from(super.pythonClass) : super.from();

  /// ## get_terminal
  ///
  /// ### python docstring
  ///
  /// Get information about a terminal
  ///
  /// ### python source
  /// ```py
  /// def get_terminal(self, name: str) -> TerminalDef:
  ///         """Get information about a terminal"""
  ///         return self._terminals_dict[name]
  /// ```
  Object? get_terminal({
    required Object? name,
  }) =>
      getFunction("get_terminal").call(
        <Object?>[
          name,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## lex
  ///
  /// ### python docstring
  ///
  /// Only lex (and postlex) the text, without parsing it. Only relevant when lexer='basic'
  ///
  /// When dont_ignore=True, the lexer will return all tokens, even those marked for %ignore.
  ///
  /// :raises UnexpectedCharacters: In case the lexer cannot find a suitable match.
  ///
  /// ### python source
  /// ```py
  /// def lex(self, text: str, dont_ignore: bool=False) -> Iterator[Token]:
  ///         """Only lex (and postlex) the text, without parsing it. Only relevant when lexer='basic'
  ///
  ///         When dont_ignore=True, the lexer will return all tokens, even those marked for %ignore.
  ///
  ///         :raises UnexpectedCharacters: In case the lexer cannot find a suitable match.
  ///         """
  ///         lexer: Lexer
  ///         if not hasattr(self, 'lexer') or dont_ignore:
  ///             lexer = self._build_lexer(dont_ignore)
  ///         else:
  ///             lexer = self.lexer
  ///         lexer_thread = LexerThread.from_text(lexer, text)
  ///         stream = lexer_thread.lex(None)
  ///         if self.options.postlex:
  ///             return self.options.postlex.process(stream)
  ///         return stream
  /// ```
  Object? lex({
    required Object? text,
    Object? dont_ignore = false,
  }) =>
      getFunction("lex").call(
        <Object?>[
          text,
          dont_ignore,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## memo_serialize
  ///
  /// ### python source
  /// ```py
  /// def memo_serialize(self, types_to_memoize: List) -> Any:
  ///         memo = SerializeMemoizer(types_to_memoize)
  ///         return self.serialize(memo), memo.serialize()
  /// ```
  Object? memo_serialize({
    required Object? types_to_memoize,
  }) =>
      getFunction("memo_serialize").call(
        <Object?>[
          types_to_memoize,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## parse
  ///
  /// ### python docstring
  ///
  /// Parse the given text, according to the options provided.
  ///
  /// Parameters:
  ///     text (str): Text to be parsed.
  ///     start (str, optional): Required if Lark was given multiple possible start symbols (using the start option).
  ///     on_error (function, optional): if provided, will be called on UnexpectedToken error. Return true to resume parsing.
  ///         LALR only. See examples/advanced/error_handling.py for an example of how to use on_error.
  ///
  /// Returns:
  ///     If a transformer is supplied to ``__init__``, returns whatever is the
  ///     result of the transformation. Otherwise, returns a Tree instance.
  ///
  /// :raises UnexpectedInput: On a parse error, one of these sub-exceptions will rise:
  ///         ``UnexpectedCharacters``, ``UnexpectedToken``, or ``UnexpectedEOF``.
  ///         For convenience, these sub-exceptions also inherit from ``ParserError`` and ``LexerError``.
  ///
  /// ### python source
  /// ```py
  /// def parse(self, text: str, start: Optional[str]=None, on_error: 'Optional[Callable[[UnexpectedInput], bool]]'=None) -> 'ParseTree':
  ///         """Parse the given text, according to the options provided.
  ///
  ///         Parameters:
  ///             text (str): Text to be parsed.
  ///             start (str, optional): Required if Lark was given multiple possible start symbols (using the start option).
  ///             on_error (function, optional): if provided, will be called on UnexpectedToken error. Return true to resume parsing.
  ///                 LALR only. See examples/advanced/error_handling.py for an example of how to use on_error.
  ///
  ///         Returns:
  ///             If a transformer is supplied to ``__init__``, returns whatever is the
  ///             result of the transformation. Otherwise, returns a Tree instance.
  ///
  ///         :raises UnexpectedInput: On a parse error, one of these sub-exceptions will rise:
  ///                 ``UnexpectedCharacters``, ``UnexpectedToken``, or ``UnexpectedEOF``.
  ///                 For convenience, these sub-exceptions also inherit from ``ParserError`` and ``LexerError``.
  ///
  ///         """
  ///         return self.parser.parse(text, start=start, on_error=on_error)
  /// ```
  Object? parse({
    required Object? text,
    Object? start,
    Object? on_error,
  }) =>
      getFunction("parse").call(
        <Object?>[
          text,
          start,
          on_error,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## parse_interactive
  ///
  /// ### python docstring
  ///
  /// Start an interactive parsing session.
  ///
  /// Parameters:
  ///     text (str, optional): Text to be parsed. Required for ``resume_parse()``.
  ///     start (str, optional): Start symbol
  ///
  /// Returns:
  ///     A new InteractiveParser instance.
  ///
  /// See Also: ``Lark.parse()``
  ///
  /// ### python source
  /// ```py
  /// def parse_interactive(self, text: Optional[str]=None, start: Optional[str]=None) -> 'InteractiveParser':
  ///         """Start an interactive parsing session.
  ///
  ///         Parameters:
  ///             text (str, optional): Text to be parsed. Required for ``resume_parse()``.
  ///             start (str, optional): Start symbol
  ///
  ///         Returns:
  ///             A new InteractiveParser instance.
  ///
  ///         See Also: ``Lark.parse()``
  ///         """
  ///         return self.parser.parse_interactive(text, start=start)
  /// ```
  Object? parse_interactive({
    Object? text,
    Object? start,
  }) =>
      getFunction("parse_interactive").call(
        <Object?>[
          text,
          start,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## save
  ///
  /// ### python docstring
  ///
  /// Saves the instance into the given file object
  ///
  /// Useful for caching and multiprocessing.
  ///
  /// ### python source
  /// ```py
  /// def save(self, f, exclude_options: Collection[str] = ()) -> None:
  ///         """Saves the instance into the given file object
  ///
  ///         Useful for caching and multiprocessing.
  ///         """
  ///         data, m = self.memo_serialize([TerminalDef, Rule])
  ///         if exclude_options:
  ///             data["options"] = {n: v for n, v in data["options"].items() if n not in exclude_options}
  ///         pickle.dump({'data': data, 'memo': m}, f, protocol=pickle.HIGHEST_PROTOCOL)
  /// ```
  Object? save({
    required Object? f,
    Object? exclude_options = const [],
  }) =>
      getFunction("save").call(
        <Object?>[
          f,
          exclude_options,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## serialize
  ///
  /// ### python source
  /// ```py
  /// def serialize(self, memo = None) -> Dict[str, Any]:
  ///         if memo and memo.in_types(self):
  ///             return {'@': memo.memoized.get(self)}
  ///
  ///         fields = getattr(self, '__serialize_fields__')
  ///         res = {f: _serialize(getattr(self, f), memo) for f in fields}
  ///         res['__type__'] = type(self).__name__
  ///         if hasattr(self, '_serialize'):
  ///             self._serialize(res, memo)  # type: ignore[attr-defined]
  ///         return res
  /// ```
  Object? serialize({
    Object? memo,
  }) =>
      getFunction("serialize").call(
        <Object?>[
          memo,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## deserialize (getter)
  Object? get deserialize => getAttribute("deserialize");

  /// ## deserialize (setter)
  set deserialize(Object? deserialize) =>
      setAttribute("deserialize", deserialize);

  /// ## load (getter)
  ///
  /// ### python docstring
  ///
  /// Loads an instance from the given file object
  ///
  /// Useful for caching and multiprocessing.
  Object? get load => getAttribute("load");

  /// ## load (setter)
  ///
  /// ### python docstring
  ///
  /// Loads an instance from the given file object
  ///
  /// Useful for caching and multiprocessing.
  set load(Object? load) => setAttribute("load", load);

  /// ## open (getter)
  ///
  /// ### python docstring
  ///
  /// Create an instance of Lark with the grammar given by its filename
  ///
  /// If ``rel_to`` is provided, the function will find the grammar filename in relation to it.
  ///
  /// Example:
  ///
  ///     >>> Lark.open("grammar_file.lark", rel_to=__file__, parser="lalr")
  ///     Lark(...)
  Object? get open => getAttribute("open");

  /// ## open (setter)
  ///
  /// ### python docstring
  ///
  /// Create an instance of Lark with the grammar given by its filename
  ///
  /// If ``rel_to`` is provided, the function will find the grammar filename in relation to it.
  ///
  /// Example:
  ///
  ///     >>> Lark.open("grammar_file.lark", rel_to=__file__, parser="lalr")
  ///     Lark(...)
  set open(Object? open) => setAttribute("open", open);

  /// ## open_from_package (getter)
  ///
  /// ### python docstring
  ///
  /// Create an instance of Lark with the grammar loaded from within the package `package`.
  /// This allows grammar loading from zipapps.
  ///
  /// Imports in the grammar will use the `package` and `search_paths` provided, through `FromPackageLoader`
  ///
  /// Example:
  ///
  ///     Lark.open_from_package(__name__, "example.lark", ("grammars",), parser=...)
  Object? get open_from_package => getAttribute("open_from_package");

  /// ## open_from_package (setter)
  ///
  /// ### python docstring
  ///
  /// Create an instance of Lark with the grammar loaded from within the package `package`.
  /// This allows grammar loading from zipapps.
  ///
  /// Imports in the grammar will use the `package` and `search_paths` provided, through `FromPackageLoader`
  ///
  /// Example:
  ///
  ///     Lark.open_from_package(__name__, "example.lark", ("grammars",), parser=...)
  set open_from_package(Object? open_from_package) =>
      setAttribute("open_from_package", open_from_package);

  /// ## options (getter)
  Object? get options => getAttribute("options");

  /// ## options (setter)
  set options(Object? options) => setAttribute("options", options);

  /// ## source_path (getter)
  Object? get source_path => getAttribute("source_path");

  /// ## source_path (setter)
  set source_path(Object? source_path) =>
      setAttribute("source_path", source_path);

  /// ## source_grammar (getter)
  Object? get source_grammar => getAttribute("source_grammar");

  /// ## source_grammar (setter)
  set source_grammar(Object? source_grammar) =>
      setAttribute("source_grammar", source_grammar);

  /// ## parser (getter)
  Object? get parser => getAttribute("parser");

  /// ## parser (setter)
  set parser(Object? parser) => setAttribute("parser", parser);

  /// ## grammar (getter)
  Object? get grammar => getAttribute("grammar");

  /// ## grammar (setter)
  set grammar(Object? grammar) => setAttribute("grammar", grammar);

  /// ## lexer (getter)
  Object? get lexer => getAttribute("lexer");

  /// ## lexer (setter)
  set lexer(Object? lexer) => setAttribute("lexer", lexer);

  /// ## lexer_conf (getter)
  Object? get lexer_conf => getAttribute("lexer_conf");

  /// ## lexer_conf (setter)
  set lexer_conf(Object? lexer_conf) => setAttribute("lexer_conf", lexer_conf);
}

/// ## LarkError
///
/// ### python source
/// ```py
/// class LarkError(Exception):
///     pass
/// ```
final class LarkError extends PythonClass {
  factory LarkError() => PythonFfiDart.instance.importClass(
        "lark.exceptions",
        "LarkError",
        LarkError.from,
        <Object?>[],
      );

  LarkError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## LexError
///
/// ### python source
/// ```py
/// class LexError(LarkError):
///     pass
/// ```
final class LexError extends PythonClass {
  factory LexError() => PythonFfiDart.instance.importClass(
        "lark.exceptions",
        "LexError",
        LexError.from,
        <Object?>[],
      );

  LexError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## ParseError
///
/// ### python source
/// ```py
/// class ParseError(LarkError):
///     pass
/// ```
final class ParseError extends PythonClass {
  factory ParseError() => PythonFfiDart.instance.importClass(
        "lark.exceptions",
        "ParseError",
        ParseError.from,
        <Object?>[],
      );

  ParseError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## Token
///
/// ### python docstring
///
/// A string with meta-information, that is produced by the lexer.
///
/// When parsing text, the resulting chunks of the input that haven't been discarded,
/// will end up in the tree as Token instances. The Token class inherits from Python's ``str``,
/// so normal string comparisons and operations will work as expected.
///
/// Attributes:
///     type: Name of the token (as specified in grammar)
///     value: Value of the token (redundant, as ``token.value == token`` will always be true)
///     start_pos: The index of the token in the text
///     line: The line of the token in the text (starting with 1)
///     column: The column of the token in the text (starting with 1)
///     end_line: The line where the token ends
///     end_column: The next column after the end of the token. For example,
///         if the token is a single character with a column value of 4,
///         end_column will be 5.
///     end_pos: the index where the token ends (basically ``start_pos + len(token)``)
///
/// ### python source
/// ```py
/// class Token(str):
///     """A string with meta-information, that is produced by the lexer.
///
///     When parsing text, the resulting chunks of the input that haven't been discarded,
///     will end up in the tree as Token instances. The Token class inherits from Python's ``str``,
///     so normal string comparisons and operations will work as expected.
///
///     Attributes:
///         type: Name of the token (as specified in grammar)
///         value: Value of the token (redundant, as ``token.value == token`` will always be true)
///         start_pos: The index of the token in the text
///         line: The line of the token in the text (starting with 1)
///         column: The column of the token in the text (starting with 1)
///         end_line: The line where the token ends
///         end_column: The next column after the end of the token. For example,
///             if the token is a single character with a column value of 4,
///             end_column will be 5.
///         end_pos: the index where the token ends (basically ``start_pos + len(token)``)
///     """
///     __slots__ = ('type', 'start_pos', 'value', 'line', 'column', 'end_line', 'end_column', 'end_pos')
///
///     __match_args__ = ('type', 'value')
///
///     type: str
///     start_pos: Optional[int]
///     value: Any
///     line: Optional[int]
///     column: Optional[int]
///     end_line: Optional[int]
///     end_column: Optional[int]
///     end_pos: Optional[int]
///
///
///     @overload
///     def __new__(
///         cls,
///         type: str,
///         value: Any,
///         start_pos: Optional[int]=None,
///         line: Optional[int]=None,
///         column: Optional[int]=None,
///         end_line: Optional[int]=None,
///         end_column: Optional[int]=None,
///         end_pos: Optional[int]=None
///     ) -> 'Token':
///         ...
///
///     @overload
///     def __new__(
///         cls,
///         type_: str,
///         value: Any,
///         start_pos: Optional[int]=None,
///         line: Optional[int]=None,
///         column: Optional[int]=None,
///         end_line: Optional[int]=None,
///         end_column: Optional[int]=None,
///         end_pos: Optional[int]=None
///     ) -> 'Token':        ...
///
///     def __new__(cls, *args, **kwargs):
///         if "type_" in kwargs:
///             warnings.warn("`type_` is deprecated use `type` instead", DeprecationWarning)
///
///             if "type" in kwargs:
///                 raise TypeError("Error: using both 'type' and the deprecated 'type_' as arguments.")
///             kwargs["type"] = kwargs.pop("type_")
///
///         return cls._future_new(*args, **kwargs)
///
///
///     @classmethod
///     def _future_new(cls, type, value, start_pos=None, line=None, column=None, end_line=None, end_column=None, end_pos=None):
///         inst = super(Token, cls).__new__(cls, value)
///
///         inst.type = type
///         inst.start_pos = start_pos
///         inst.value = value
///         inst.line = line
///         inst.column = column
///         inst.end_line = end_line
///         inst.end_column = end_column
///         inst.end_pos = end_pos
///         return inst
///
///     @overload
///     def update(self, type: Optional[str]=None, value: Optional[Any]=None) -> 'Token':
///         ...
///
///     @overload
///     def update(self, type_: Optional[str]=None, value: Optional[Any]=None) -> 'Token':
///         ...
///
///     def update(self, *args, **kwargs):
///         if "type_" in kwargs:
///             warnings.warn("`type_` is deprecated use `type` instead", DeprecationWarning)
///
///             if "type" in kwargs:
///                 raise TypeError("Error: using both 'type' and the deprecated 'type_' as arguments.")
///             kwargs["type"] = kwargs.pop("type_")
///
///         return self._future_update(*args, **kwargs)
///
///     def _future_update(self, type: Optional[str]=None, value: Optional[Any]=None) -> 'Token':
///         return Token.new_borrow_pos(
///             type if type is not None else self.type,
///             value if value is not None else self.value,
///             self
///         )
///
///     @classmethod
///     def new_borrow_pos(cls: Type[_T], type_: str, value: Any, borrow_t: 'Token') -> _T:
///         return cls(type_, value, borrow_t.start_pos, borrow_t.line, borrow_t.column, borrow_t.end_line, borrow_t.end_column, borrow_t.end_pos)
///
///     def __reduce__(self):
///         return (self.__class__, (self.type, self.value, self.start_pos, self.line, self.column))
///
///     def __repr__(self):
///         return 'Token(%r, %r)' % (self.type, self.value)
///
///     def __deepcopy__(self, memo):
///         return Token(self.type, self.value, self.start_pos, self.line, self.column)
///
///     def __eq__(self, other):
///         if isinstance(other, Token) and self.type != other.type:
///             return False
///
///         return str.__eq__(self, other)
///
///     __hash__ = str.__hash__
/// ```
final class Token extends PythonClass {
  factory Token() => PythonFfiDart.instance.importClass(
        "lark.lexer",
        "Token",
        Token.from,
        <Object?>[],
      );

  Token.from(super.pythonClass) : super.from();

  /// ## update
  ///
  /// ### python source
  /// ```py
  /// def update(self, *args, **kwargs):
  ///         if "type_" in kwargs:
  ///             warnings.warn("`type_` is deprecated use `type` instead", DeprecationWarning)
  ///
  ///             if "type" in kwargs:
  ///                 raise TypeError("Error: using both 'type' and the deprecated 'type_' as arguments.")
  ///             kwargs["type"] = kwargs.pop("type_")
  ///
  ///         return self._future_update(*args, **kwargs)
  /// ```
  Object? update({
    List<Object?> args = const <Object?>[],
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("update").call(
        <Object?>[
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## column (getter)
  Object? get column => getAttribute("column");

  /// ## column (setter)
  set column(Object? column) => setAttribute("column", column);

  /// ## end_column (getter)
  Object? get end_column => getAttribute("end_column");

  /// ## end_column (setter)
  set end_column(Object? end_column) => setAttribute("end_column", end_column);

  /// ## end_line (getter)
  Object? get end_line => getAttribute("end_line");

  /// ## end_line (setter)
  set end_line(Object? end_line) => setAttribute("end_line", end_line);

  /// ## end_pos (getter)
  Object? get end_pos => getAttribute("end_pos");

  /// ## end_pos (setter)
  set end_pos(Object? end_pos) => setAttribute("end_pos", end_pos);

  /// ## line (getter)
  Object? get line => getAttribute("line");

  /// ## line (setter)
  set line(Object? line) => setAttribute("line", line);

  /// ## start_pos (getter)
  Object? get start_pos => getAttribute("start_pos");

  /// ## start_pos (setter)
  set start_pos(Object? start_pos) => setAttribute("start_pos", start_pos);

  /// ## type (getter)
  Object? get type => getAttribute("type");

  /// ## type (setter)
  set type(Object? type) => setAttribute("type", type);

  /// ## value (getter)
  Object? get value => getAttribute("value");

  /// ## value (setter)
  set value(Object? value) => setAttribute("value", value);

  /// ## capitalize (getter)
  Object? get capitalize => getAttribute("capitalize");

  /// ## capitalize (setter)
  set capitalize(Object? capitalize) => setAttribute("capitalize", capitalize);

  /// ## casefold (getter)
  Object? get casefold => getAttribute("casefold");

  /// ## casefold (setter)
  set casefold(Object? casefold) => setAttribute("casefold", casefold);

  /// ## center (getter)
  Object? get center => getAttribute("center");

  /// ## center (setter)
  set center(Object? center) => setAttribute("center", center);

  /// ## count (getter)
  Object? get count => getAttribute("count");

  /// ## count (setter)
  set count(Object? count) => setAttribute("count", count);

  /// ## encode (getter)
  Object? get encode => getAttribute("encode");

  /// ## encode (setter)
  set encode(Object? encode) => setAttribute("encode", encode);

  /// ## endswith (getter)
  Object? get endswith => getAttribute("endswith");

  /// ## endswith (setter)
  set endswith(Object? endswith) => setAttribute("endswith", endswith);

  /// ## expandtabs (getter)
  Object? get expandtabs => getAttribute("expandtabs");

  /// ## expandtabs (setter)
  set expandtabs(Object? expandtabs) => setAttribute("expandtabs", expandtabs);

  /// ## find (getter)
  Object? get find => getAttribute("find");

  /// ## find (setter)
  set find(Object? find) => setAttribute("find", find);

  /// ## format (getter)
  Object? get format => getAttribute("format");

  /// ## format (setter)
  set format(Object? format) => setAttribute("format", format);

  /// ## format_map (getter)
  Object? get format_map => getAttribute("format_map");

  /// ## format_map (setter)
  set format_map(Object? format_map) => setAttribute("format_map", format_map);

  /// ## index (getter)
  Object? get index => getAttribute("index");

  /// ## index (setter)
  set index(Object? index) => setAttribute("index", index);

  /// ## isalnum (getter)
  Object? get isalnum => getAttribute("isalnum");

  /// ## isalnum (setter)
  set isalnum(Object? isalnum) => setAttribute("isalnum", isalnum);

  /// ## isalpha (getter)
  Object? get isalpha => getAttribute("isalpha");

  /// ## isalpha (setter)
  set isalpha(Object? isalpha) => setAttribute("isalpha", isalpha);

  /// ## isascii (getter)
  Object? get isascii => getAttribute("isascii");

  /// ## isascii (setter)
  set isascii(Object? isascii) => setAttribute("isascii", isascii);

  /// ## isdecimal (getter)
  Object? get isdecimal => getAttribute("isdecimal");

  /// ## isdecimal (setter)
  set isdecimal(Object? isdecimal) => setAttribute("isdecimal", isdecimal);

  /// ## isdigit (getter)
  Object? get isdigit => getAttribute("isdigit");

  /// ## isdigit (setter)
  set isdigit(Object? isdigit) => setAttribute("isdigit", isdigit);

  /// ## isidentifier (getter)
  Object? get isidentifier => getAttribute("isidentifier");

  /// ## isidentifier (setter)
  set isidentifier(Object? isidentifier) =>
      setAttribute("isidentifier", isidentifier);

  /// ## islower (getter)
  Object? get islower => getAttribute("islower");

  /// ## islower (setter)
  set islower(Object? islower) => setAttribute("islower", islower);

  /// ## isnumeric (getter)
  Object? get isnumeric => getAttribute("isnumeric");

  /// ## isnumeric (setter)
  set isnumeric(Object? isnumeric) => setAttribute("isnumeric", isnumeric);

  /// ## isprintable (getter)
  Object? get isprintable => getAttribute("isprintable");

  /// ## isprintable (setter)
  set isprintable(Object? isprintable) =>
      setAttribute("isprintable", isprintable);

  /// ## isspace (getter)
  Object? get isspace => getAttribute("isspace");

  /// ## isspace (setter)
  set isspace(Object? isspace) => setAttribute("isspace", isspace);

  /// ## istitle (getter)
  Object? get istitle => getAttribute("istitle");

  /// ## istitle (setter)
  set istitle(Object? istitle) => setAttribute("istitle", istitle);

  /// ## isupper (getter)
  Object? get isupper => getAttribute("isupper");

  /// ## isupper (setter)
  set isupper(Object? isupper) => setAttribute("isupper", isupper);

  /// ## join (getter)
  Object? get join => getAttribute("join");

  /// ## join (setter)
  set join(Object? join) => setAttribute("join", join);

  /// ## ljust (getter)
  Object? get ljust => getAttribute("ljust");

  /// ## ljust (setter)
  set ljust(Object? ljust) => setAttribute("ljust", ljust);

  /// ## lower (getter)
  Object? get lower => getAttribute("lower");

  /// ## lower (setter)
  set lower(Object? lower) => setAttribute("lower", lower);

  /// ## lstrip (getter)
  Object? get lstrip => getAttribute("lstrip");

  /// ## lstrip (setter)
  set lstrip(Object? lstrip) => setAttribute("lstrip", lstrip);

  /// ## new_borrow_pos (getter)
  Object? get new_borrow_pos => getAttribute("new_borrow_pos");

  /// ## new_borrow_pos (setter)
  set new_borrow_pos(Object? new_borrow_pos) =>
      setAttribute("new_borrow_pos", new_borrow_pos);

  /// ## partition (getter)
  Object? get partition => getAttribute("partition");

  /// ## partition (setter)
  set partition(Object? partition) => setAttribute("partition", partition);

  /// ## removeprefix (getter)
  Object? get removeprefix => getAttribute("removeprefix");

  /// ## removeprefix (setter)
  set removeprefix(Object? removeprefix) =>
      setAttribute("removeprefix", removeprefix);

  /// ## removesuffix (getter)
  Object? get removesuffix => getAttribute("removesuffix");

  /// ## removesuffix (setter)
  set removesuffix(Object? removesuffix) =>
      setAttribute("removesuffix", removesuffix);

  /// ## replace (getter)
  Object? get replace => getAttribute("replace");

  /// ## replace (setter)
  set replace(Object? replace) => setAttribute("replace", replace);

  /// ## rfind (getter)
  Object? get rfind => getAttribute("rfind");

  /// ## rfind (setter)
  set rfind(Object? rfind) => setAttribute("rfind", rfind);

  /// ## rindex (getter)
  Object? get rindex => getAttribute("rindex");

  /// ## rindex (setter)
  set rindex(Object? rindex) => setAttribute("rindex", rindex);

  /// ## rjust (getter)
  Object? get rjust => getAttribute("rjust");

  /// ## rjust (setter)
  set rjust(Object? rjust) => setAttribute("rjust", rjust);

  /// ## rpartition (getter)
  Object? get rpartition => getAttribute("rpartition");

  /// ## rpartition (setter)
  set rpartition(Object? rpartition) => setAttribute("rpartition", rpartition);

  /// ## rsplit (getter)
  Object? get rsplit => getAttribute("rsplit");

  /// ## rsplit (setter)
  set rsplit(Object? rsplit) => setAttribute("rsplit", rsplit);

  /// ## rstrip (getter)
  Object? get rstrip => getAttribute("rstrip");

  /// ## rstrip (setter)
  set rstrip(Object? rstrip) => setAttribute("rstrip", rstrip);

  /// ## split (getter)
  Object? get split => getAttribute("split");

  /// ## split (setter)
  set split(Object? split) => setAttribute("split", split);

  /// ## splitlines (getter)
  Object? get splitlines => getAttribute("splitlines");

  /// ## splitlines (setter)
  set splitlines(Object? splitlines) => setAttribute("splitlines", splitlines);

  /// ## startswith (getter)
  Object? get startswith => getAttribute("startswith");

  /// ## startswith (setter)
  set startswith(Object? startswith) => setAttribute("startswith", startswith);

  /// ## strip (getter)
  Object? get strip => getAttribute("strip");

  /// ## strip (setter)
  set strip(Object? strip) => setAttribute("strip", strip);

  /// ## swapcase (getter)
  Object? get swapcase => getAttribute("swapcase");

  /// ## swapcase (setter)
  set swapcase(Object? swapcase) => setAttribute("swapcase", swapcase);

  /// ## title (getter)
  Object? get title => getAttribute("title");

  /// ## title (setter)
  set title(Object? title) => setAttribute("title", title);

  /// ## translate (getter)
  Object? get translate => getAttribute("translate");

  /// ## translate (setter)
  set translate(Object? translate) => setAttribute("translate", translate);

  /// ## upper (getter)
  Object? get upper => getAttribute("upper");

  /// ## upper (setter)
  set upper(Object? upper) => setAttribute("upper", upper);

  /// ## zfill (getter)
  Object? get zfill => getAttribute("zfill");

  /// ## zfill (setter)
  set zfill(Object? zfill) => setAttribute("zfill", zfill);
}

/// ## Transformer
///
/// ### python docstring
///
/// Transformers work bottom-up (or depth-first), starting with visiting the leaves and working
/// their way up until ending at the root of the tree.
///
/// For each node visited, the transformer will call the appropriate method (callbacks), according to the
/// node's ``data``, and use the returned value to replace the node, thereby creating a new tree structure.
///
/// Transformers can be used to implement map & reduce patterns. Because nodes are reduced from leaf to root,
/// at any point the callbacks may assume the children have already been transformed (if applicable).
///
/// If the transformer cannot find a method with the right name, it will instead call ``__default__``, which by
/// default creates a copy of the node.
///
/// To discard a node, return Discard (``lark.visitors.Discard``).
///
/// ``Transformer`` can do anything ``Visitor`` can do, but because it reconstructs the tree,
/// it is slightly less efficient.
///
/// A transformer without methods essentially performs a non-memoized partial deepcopy.
///
/// All these classes implement the transformer interface:
///
/// - ``Transformer`` - Recursively transforms the tree. This is the one you probably want.
/// - ``Transformer_InPlace`` - Non-recursive. Changes the tree in-place instead of returning new instances
/// - ``Transformer_InPlaceRecursive`` - Recursive. Changes the tree in-place instead of returning new instances
///
/// Parameters:
///     visit_tokens (bool, optional): Should the transformer visit tokens in addition to rules.
///                                    Setting this to ``False`` is slightly faster. Defaults to ``True``.
///                                    (For processing ignored tokens, use the ``lexer_callbacks`` options)
///
/// ### python source
/// ```py
/// class Transformer(_Decoratable, ABC, Generic[_Leaf_T, _Return_T]):
///     """Transformers work bottom-up (or depth-first), starting with visiting the leaves and working
///     their way up until ending at the root of the tree.
///
///     For each node visited, the transformer will call the appropriate method (callbacks), according to the
///     node's ``data``, and use the returned value to replace the node, thereby creating a new tree structure.
///
///     Transformers can be used to implement map & reduce patterns. Because nodes are reduced from leaf to root,
///     at any point the callbacks may assume the children have already been transformed (if applicable).
///
///     If the transformer cannot find a method with the right name, it will instead call ``__default__``, which by
///     default creates a copy of the node.
///
///     To discard a node, return Discard (``lark.visitors.Discard``).
///
///     ``Transformer`` can do anything ``Visitor`` can do, but because it reconstructs the tree,
///     it is slightly less efficient.
///
///     A transformer without methods essentially performs a non-memoized partial deepcopy.
///
///     All these classes implement the transformer interface:
///
///     - ``Transformer`` - Recursively transforms the tree. This is the one you probably want.
///     - ``Transformer_InPlace`` - Non-recursive. Changes the tree in-place instead of returning new instances
///     - ``Transformer_InPlaceRecursive`` - Recursive. Changes the tree in-place instead of returning new instances
///
///     Parameters:
///         visit_tokens (bool, optional): Should the transformer visit tokens in addition to rules.
///                                        Setting this to ``False`` is slightly faster. Defaults to ``True``.
///                                        (For processing ignored tokens, use the ``lexer_callbacks`` options)
///
///     """
///     __visit_tokens__ = True   # For backwards compatibility
///
///     def __init__(self,  visit_tokens: bool=True) -> None:
///         self.__visit_tokens__ = visit_tokens
///
///     def _call_userfunc(self, tree, new_children=None):
///         # Assumes tree is already transformed
///         children = new_children if new_children is not None else tree.children
///         try:
///             f = getattr(self, tree.data)
///         except AttributeError:
///             return self.__default__(tree.data, children, tree.meta)
///         else:
///             try:
///                 wrapper = getattr(f, 'visit_wrapper', None)
///                 if wrapper is not None:
///                     return f.visit_wrapper(f, tree.data, children, tree.meta)
///                 else:
///                     return f(children)
///             except GrammarError:
///                 raise
///             except Exception as e:
///                 raise VisitError(tree.data, tree, e)
///
///     def _call_userfunc_token(self, token):
///         try:
///             f = getattr(self, token.type)
///         except AttributeError:
///             return self.__default_token__(token)
///         else:
///             try:
///                 return f(token)
///             except GrammarError:
///                 raise
///             except Exception as e:
///                 raise VisitError(token.type, token, e)
///
///     def _transform_children(self, children):
///         for c in children:
///             if isinstance(c, Tree):
///                 res = self._transform_tree(c)
///             elif self.__visit_tokens__ and isinstance(c, Token):
///                 res = self._call_userfunc_token(c)
///             else:
///                 res = c
///
///             if res is not Discard:
///                 yield res
///
///     def _transform_tree(self, tree):
///         children = list(self._transform_children(tree.children))
///         return self._call_userfunc(tree, children)
///
///     def transform(self, tree: Tree[_Leaf_T]) -> _Return_T:
///         "Transform the given tree, and return the final result"
///         return self._transform_tree(tree)
///
///     def __mul__(
///             self: 'Transformer[_Leaf_T, Tree[_Leaf_U]]',
///             other: 'Union[Transformer[_Leaf_U, _Return_V], TransformerChain[_Leaf_U, _Return_V,]]'
///     ) -> 'TransformerChain[_Leaf_T, _Return_V]':
///         """Chain two transformers together, returning a new transformer.
///         """
///         return TransformerChain(self, other)
///
///     def __default__(self, data, children, meta):
///         """Default function that is called if there is no attribute matching ``data``
///
///         Can be overridden. Defaults to creating a new copy of the tree node (i.e. ``return Tree(data, children, meta)``)
///         """
///         return Tree(data, children, meta)
///
///     def __default_token__(self, token):
///         """Default function that is called if there is no attribute matching ``token.type``
///
///         Can be overridden. Defaults to returning the token as-is.
///         """
///         return token
/// ```
final class Transformer extends PythonClass {
  factory Transformer({
    Object? visit_tokens = true,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.visitors",
        "Transformer",
        Transformer.from,
        <Object?>[
          visit_tokens,
        ],
        <String, Object?>{},
      );

  Transformer.from(super.pythonClass) : super.from();

  /// ## transform
  ///
  /// ### python docstring
  ///
  /// Transform the given tree, and return the final result
  ///
  /// ### python source
  /// ```py
  /// def transform(self, tree: Tree[_Leaf_T]) -> _Return_T:
  ///         "Transform the given tree, and return the final result"
  ///         return self._transform_tree(tree)
  /// ```
  Object? transform({
    required Object? tree,
  }) =>
      getFunction("transform").call(
        <Object?>[
          tree,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## Transformer_NonRecursive
///
/// ### python docstring
///
/// Same as Transformer but non-recursive.
///
/// Like Transformer, it doesn't change the original tree.
///
/// Useful for huge trees.
///
/// ### python source
/// ```py
/// class Transformer_NonRecursive(Transformer):
///     """Same as Transformer but non-recursive.
///
///     Like Transformer, it doesn't change the original tree.
///
///     Useful for huge trees.
///     """
///
///     def transform(self, tree: Tree[_Leaf_T]) -> _Return_T:
///         # Tree to postfix
///         rev_postfix = []
///         q: List[Branch[_Leaf_T]] = [tree]
///         while q:
///             t = q.pop()
///             rev_postfix.append(t)
///             if isinstance(t, Tree):
///                 q += t.children
///
///         # Postfix to tree
///         stack: List = []
///         for x in reversed(rev_postfix):
///             if isinstance(x, Tree):
///                 size = len(x.children)
///                 if size:
///                     args = stack[-size:]
///                     del stack[-size:]
///                 else:
///                     args = []
///
///                 res = self._call_userfunc(x, args)
///                 if res is not Discard:
///                     stack.append(res)
///
///             elif self.__visit_tokens__ and isinstance(x, Token):
///                 res = self._call_userfunc_token(x)
///                 if res is not Discard:
///                     stack.append(res)
///             else:
///                 stack.append(x)
///
///         result, = stack  # We should have only one tree remaining
///         # There are no guarantees on the type of the value produced by calling a user func for a
///         # child will produce. This means type system can't statically know that the final result is
///         # _Return_T. As a result a cast is required.
///         return cast(_Return_T, result)
/// ```
final class Transformer_NonRecursive extends PythonClass {
  factory Transformer_NonRecursive({
    Object? visit_tokens = true,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.visitors",
        "Transformer_NonRecursive",
        Transformer_NonRecursive.from,
        <Object?>[
          visit_tokens,
        ],
        <String, Object?>{},
      );

  Transformer_NonRecursive.from(super.pythonClass) : super.from();

  /// ## transform
  ///
  /// ### python docstring
  ///
  /// Transform the given tree, and return the final result
  ///
  /// ### python source
  /// ```py
  /// def transform(self, tree: Tree[_Leaf_T]) -> _Return_T:
  ///         # Tree to postfix
  ///         rev_postfix = []
  ///         q: List[Branch[_Leaf_T]] = [tree]
  ///         while q:
  ///             t = q.pop()
  ///             rev_postfix.append(t)
  ///             if isinstance(t, Tree):
  ///                 q += t.children
  ///
  ///         # Postfix to tree
  ///         stack: List = []
  ///         for x in reversed(rev_postfix):
  ///             if isinstance(x, Tree):
  ///                 size = len(x.children)
  ///                 if size:
  ///                     args = stack[-size:]
  ///                     del stack[-size:]
  ///                 else:
  ///                     args = []
  ///
  ///                 res = self._call_userfunc(x, args)
  ///                 if res is not Discard:
  ///                     stack.append(res)
  ///
  ///             elif self.__visit_tokens__ and isinstance(x, Token):
  ///                 res = self._call_userfunc_token(x)
  ///                 if res is not Discard:
  ///                     stack.append(res)
  ///             else:
  ///                 stack.append(x)
  ///
  ///         result, = stack  # We should have only one tree remaining
  ///         # There are no guarantees on the type of the value produced by calling a user func for a
  ///         # child will produce. This means type system can't statically know that the final result is
  ///         # _Return_T. As a result a cast is required.
  ///         return cast(_Return_T, result)
  /// ```
  Object? transform({
    required Object? tree,
  }) =>
      getFunction("transform").call(
        <Object?>[
          tree,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## Tree
///
/// ### python docstring
///
/// The main tree class.
///
/// Creates a new tree, and stores "data" and "children" in attributes of the same name.
/// Trees can be hashed and compared.
///
/// Parameters:
///     data: The name of the rule or alias
///     children: List of matched sub-rules and terminals
///     meta: Line & Column numbers (if ``propagate_positions`` is enabled).
///         meta attributes: line, column, start_pos, end_line, end_column, end_pos
///
/// ### python source
/// ```py
/// class Tree(Generic[_Leaf_T]):
///     """The main tree class.
///
///     Creates a new tree, and stores "data" and "children" in attributes of the same name.
///     Trees can be hashed and compared.
///
///     Parameters:
///         data: The name of the rule or alias
///         children: List of matched sub-rules and terminals
///         meta: Line & Column numbers (if ``propagate_positions`` is enabled).
///             meta attributes: line, column, start_pos, end_line, end_column, end_pos
///     """
///
///     data: str
///     children: 'List[Branch[_Leaf_T]]'
///
///     def __init__(self, data: str, children: 'List[Branch[_Leaf_T]]', meta: Optional[Meta]=None) -> None:
///         self.data = data
///         self.children = children
///         self._meta = meta
///
///     @property
///     def meta(self) -> Meta:
///         if self._meta is None:
///             self._meta = Meta()
///         return self._meta
///
///     def __repr__(self):
///         return 'Tree(%r, %r)' % (self.data, self.children)
///
///     def _pretty_label(self):
///         return self.data
///
///     def _pretty(self, level, indent_str):
///         yield f'{indent_str*level}{self._pretty_label()}'
///         if len(self.children) == 1 and not isinstance(self.children[0], Tree):
///             yield f'\t{self.children[0]}\n'
///         else:
///             yield '\n'
///             for n in self.children:
///                 if isinstance(n, Tree):
///                     yield from n._pretty(level+1, indent_str)
///                 else:
///                     yield f'{indent_str*(level+1)}{n}\n'
///
///     def pretty(self, indent_str: str='  ') -> str:
///         """Returns an indented string representation of the tree.
///
///         Great for debugging.
///         """
///         return ''.join(self._pretty(0, indent_str))
///
///     def __rich__(self, parent:'rich.tree.Tree'=None) -> 'rich.tree.Tree':
///         """Returns a tree widget for the 'rich' library.
///
///         Example:
///             ::
///                 from rich import print
///                 from lark import Tree
///
///                 tree = Tree('root', ['node1', 'node2'])
///                 print(tree)
///         """
///         return self._rich(parent)
///
///     def _rich(self, parent):
///         if parent:
///             tree = parent.add(f'[bold]{self.data}[/bold]')
///         else:
///             import rich.tree
///             tree = rich.tree.Tree(self.data)
///
///         for c in self.children:
///             if isinstance(c, Tree):
///                 c._rich(tree)
///             else:
///                 tree.add(f'[green]{c}[/green]')
///
///         return tree
///
///     def __eq__(self, other):
///         try:
///             return self.data == other.data and self.children == other.children
///         except AttributeError:
///             return False
///
///     def __ne__(self, other):
///         return not (self == other)
///
///     def __hash__(self) -> int:
///         return hash((self.data, tuple(self.children)))
///
///     def iter_subtrees(self) -> 'Iterator[Tree[_Leaf_T]]':
///         """Depth-first iteration.
///
///         Iterates over all the subtrees, never returning to the same node twice (Lark's parse-tree is actually a DAG).
///         """
///         queue = [self]
///         subtrees = OrderedDict()
///         for subtree in queue:
///             subtrees[id(subtree)] = subtree
///             # Reason for type ignore https://github.com/python/mypy/issues/10999
///             queue += [c for c in reversed(subtree.children)  # type: ignore[misc]
///                       if isinstance(c, Tree) and id(c) not in subtrees]
///
///         del queue
///         return reversed(list(subtrees.values()))
///
///     def iter_subtrees_topdown(self):
///         """Breadth-first iteration.
///
///         Iterates over all the subtrees, return nodes in order like pretty() does.
///         """
///         stack = [self]
///         stack_append = stack.append
///         stack_pop = stack.pop
///         while stack:
///             node = stack_pop()
///             if not isinstance(node, Tree):
///                 continue
///             yield node
///             for child in reversed(node.children):
///                 stack_append(child)
///
///     def find_pred(self, pred: 'Callable[[Tree[_Leaf_T]], bool]') -> 'Iterator[Tree[_Leaf_T]]':
///         """Returns all nodes of the tree that evaluate pred(node) as true."""
///         return filter(pred, self.iter_subtrees())
///
///     def find_data(self, data: str) -> 'Iterator[Tree[_Leaf_T]]':
///         """Returns all nodes of the tree whose data equals the given data."""
///         return self.find_pred(lambda t: t.data == data)
///
/// ###}
///
///     def expand_kids_by_data(self, *data_values):
///         """Expand (inline) children with any of the given data values. Returns True if anything changed"""
///         changed = False
///         for i in range(len(self.children)-1, -1, -1):
///             child = self.children[i]
///             if isinstance(child, Tree) and child.data in data_values:
///                 self.children[i:i+1] = child.children
///                 changed = True
///         return changed
///
///
///     def scan_values(self, pred: 'Callable[[Branch[_Leaf_T]], bool]') -> Iterator[_Leaf_T]:
///         """Return all values in the tree that evaluate pred(value) as true.
///
///         This can be used to find all the tokens in the tree.
///
///         Example:
///             >>> all_tokens = tree.scan_values(lambda v: isinstance(v, Token))
///         """
///         for c in self.children:
///             if isinstance(c, Tree):
///                 for t in c.scan_values(pred):
///                     yield t
///             else:
///                 if pred(c):
///                     yield c
///
///     def __deepcopy__(self, memo):
///         return type(self)(self.data, deepcopy(self.children, memo), meta=self._meta)
///
///     def copy(self) -> 'Tree[_Leaf_T]':
///         return type(self)(self.data, self.children)
///
///     def set(self, data: str, children: 'List[Branch[_Leaf_T]]') -> None:
///         self.data = data
///         self.children = children
/// ```
final class Tree extends PythonClass {
  factory Tree({
    required Object? data,
    required Object? children,
    Object? meta,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.tree",
        "Tree",
        Tree.from,
        <Object?>[
          data,
          children,
          meta,
        ],
        <String, Object?>{},
      );

  Tree.from(super.pythonClass) : super.from();

  /// ## copy
  ///
  /// ### python source
  /// ```py
  /// def copy(self) -> 'Tree[_Leaf_T]':
  ///         return type(self)(self.data, self.children)
  /// ```
  Object? copy() => getFunction("copy").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## expand_kids_by_data
  ///
  /// ### python docstring
  ///
  /// Expand (inline) children with any of the given data values. Returns True if anything changed
  ///
  /// ### python source
  /// ```py
  /// def expand_kids_by_data(self, *data_values):
  ///         """Expand (inline) children with any of the given data values. Returns True if anything changed"""
  ///         changed = False
  ///         for i in range(len(self.children)-1, -1, -1):
  ///             child = self.children[i]
  ///             if isinstance(child, Tree) and child.data in data_values:
  ///                 self.children[i:i+1] = child.children
  ///                 changed = True
  ///         return changed
  /// ```
  Object? expand_kids_by_data({
    List<Object?> data_values = const <Object?>[],
  }) =>
      getFunction("expand_kids_by_data").call(
        <Object?>[
          ...data_values,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## find_data
  ///
  /// ### python docstring
  ///
  /// Returns all nodes of the tree whose data equals the given data.
  ///
  /// ### python source
  /// ```py
  /// def find_data(self, data: str) -> 'Iterator[Tree[_Leaf_T]]':
  ///         """Returns all nodes of the tree whose data equals the given data."""
  ///         return self.find_pred(lambda t: t.data == data)
  /// ```
  Object? find_data({
    required Object? data,
  }) =>
      getFunction("find_data").call(
        <Object?>[
          data,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## find_pred
  ///
  /// ### python docstring
  ///
  /// Returns all nodes of the tree that evaluate pred(node) as true.
  ///
  /// ### python source
  /// ```py
  /// def find_pred(self, pred: 'Callable[[Tree[_Leaf_T]], bool]') -> 'Iterator[Tree[_Leaf_T]]':
  ///         """Returns all nodes of the tree that evaluate pred(node) as true."""
  ///         return filter(pred, self.iter_subtrees())
  /// ```
  Object? find_pred({
    required Object? pred,
  }) =>
      getFunction("find_pred").call(
        <Object?>[
          pred,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## iter_subtrees
  ///
  /// ### python docstring
  ///
  /// Depth-first iteration.
  ///
  /// Iterates over all the subtrees, never returning to the same node twice (Lark's parse-tree is actually a DAG).
  ///
  /// ### python source
  /// ```py
  /// def iter_subtrees(self) -> 'Iterator[Tree[_Leaf_T]]':
  ///         """Depth-first iteration.
  ///
  ///         Iterates over all the subtrees, never returning to the same node twice (Lark's parse-tree is actually a DAG).
  ///         """
  ///         queue = [self]
  ///         subtrees = OrderedDict()
  ///         for subtree in queue:
  ///             subtrees[id(subtree)] = subtree
  ///             # Reason for type ignore https://github.com/python/mypy/issues/10999
  ///             queue += [c for c in reversed(subtree.children)  # type: ignore[misc]
  ///                       if isinstance(c, Tree) and id(c) not in subtrees]
  ///
  ///         del queue
  ///         return reversed(list(subtrees.values()))
  /// ```
  Object? iter_subtrees() => getFunction("iter_subtrees").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## iter_subtrees_topdown
  ///
  /// ### python docstring
  ///
  /// Breadth-first iteration.
  ///
  /// Iterates over all the subtrees, return nodes in order like pretty() does.
  ///
  /// ### python source
  /// ```py
  /// def iter_subtrees_topdown(self):
  ///         """Breadth-first iteration.
  ///
  ///         Iterates over all the subtrees, return nodes in order like pretty() does.
  ///         """
  ///         stack = [self]
  ///         stack_append = stack.append
  ///         stack_pop = stack.pop
  ///         while stack:
  ///             node = stack_pop()
  ///             if not isinstance(node, Tree):
  ///                 continue
  ///             yield node
  ///             for child in reversed(node.children):
  ///                 stack_append(child)
  /// ```
  Object? iter_subtrees_topdown() => getFunction("iter_subtrees_topdown").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## pretty
  ///
  /// ### python docstring
  ///
  /// Returns an indented string representation of the tree.
  ///
  /// Great for debugging.
  ///
  /// ### python source
  /// ```py
  /// def pretty(self, indent_str: str='  ') -> str:
  ///         """Returns an indented string representation of the tree.
  ///
  ///         Great for debugging.
  ///         """
  ///         return ''.join(self._pretty(0, indent_str))
  /// ```
  Object? pretty({
    Object? indent_str = "  ",
  }) =>
      getFunction("pretty").call(
        <Object?>[
          indent_str,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## scan_values
  ///
  /// ### python docstring
  ///
  /// Return all values in the tree that evaluate pred(value) as true.
  ///
  /// This can be used to find all the tokens in the tree.
  ///
  /// Example:
  ///     >>> all_tokens = tree.scan_values(lambda v: isinstance(v, Token))
  ///
  /// ### python source
  /// ```py
  /// def scan_values(self, pred: 'Callable[[Branch[_Leaf_T]], bool]') -> Iterator[_Leaf_T]:
  ///         """Return all values in the tree that evaluate pred(value) as true.
  ///
  ///         This can be used to find all the tokens in the tree.
  ///
  ///         Example:
  ///             >>> all_tokens = tree.scan_values(lambda v: isinstance(v, Token))
  ///         """
  ///         for c in self.children:
  ///             if isinstance(c, Tree):
  ///                 for t in c.scan_values(pred):
  ///                     yield t
  ///             else:
  ///                 if pred(c):
  ///                     yield c
  /// ```
  Object? scan_values({
    required Object? pred,
  }) =>
      getFunction("scan_values").call(
        <Object?>[
          pred,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## set
  ///
  /// ### python source
  /// ```py
  /// def set(self, data: str, children: 'List[Branch[_Leaf_T]]') -> None:
  ///         self.data = data
  ///         self.children = children
  /// ```
  Object? $set({
    required Object? data,
    required Object? children,
  }) =>
      getFunction("set").call(
        <Object?>[
          data,
          children,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## meta (getter)
  Object? get meta => getAttribute("meta");

  /// ## meta (setter)
  set meta(Object? meta) => setAttribute("meta", meta);

  /// ## data (getter)
  Object? get data => getAttribute("data");

  /// ## data (setter)
  set data(Object? data) => setAttribute("data", data);

  /// ## children (getter)
  Object? get children => getAttribute("children");

  /// ## children (setter)
  set children(Object? children) => setAttribute("children", children);
}

/// ## UnexpectedCharacters
///
/// ### python docstring
///
/// An exception that is raised by the lexer, when it cannot match the next
/// string of characters to any of its terminals.
///
/// ### python source
/// ```py
/// class UnexpectedCharacters(LexError, UnexpectedInput):
///     """An exception that is raised by the lexer, when it cannot match the next
///     string of characters to any of its terminals.
///     """
///
///     allowed: Set[str]
///     considered_tokens: Set[Any]
///
///     def __init__(self, seq, lex_pos, line, column, allowed=None, considered_tokens=None, state=None, token_history=None,
///                  terminals_by_name=None, considered_rules=None):
///         super(UnexpectedCharacters, self).__init__()
///
///         # TODO considered_tokens and allowed can be figured out using state
///         self.line = line
///         self.column = column
///         self.pos_in_stream = lex_pos
///         self.state = state
///         self._terminals_by_name = terminals_by_name
///
///         self.allowed = allowed
///         self.considered_tokens = considered_tokens
///         self.considered_rules = considered_rules
///         self.token_history = token_history
///
///         if isinstance(seq, bytes):
///             self.char = seq[lex_pos:lex_pos + 1].decode("ascii", "backslashreplace")
///         else:
///             self.char = seq[lex_pos]
///         self._context = self.get_context(seq)
///
///
///     def __str__(self):
///         message = "No terminal matches '%s' in the current parser context, at line %d col %d" % (self.char, self.line, self.column)
///         message += '\n\n' + self._context
///         if self.allowed:
///             message += self._format_expected(self.allowed)
///         if self.token_history:
///             message += '\nPrevious tokens: %s\n' % ', '.join(repr(t) for t in self.token_history)
///         return message
/// ```
final class UnexpectedCharacters extends PythonClass {
  factory UnexpectedCharacters({
    required Object? seq,
    required Object? lex_pos,
    required Object? line,
    required Object? column,
    Object? allowed,
    Object? considered_tokens,
    Object? state,
    Object? token_history,
    Object? terminals_by_name,
    Object? considered_rules,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.exceptions",
        "UnexpectedCharacters",
        UnexpectedCharacters.from,
        <Object?>[
          seq,
          lex_pos,
          line,
          column,
          allowed,
          considered_tokens,
          state,
          token_history,
          terminals_by_name,
          considered_rules,
        ],
        <String, Object?>{},
      );

  UnexpectedCharacters.from(super.pythonClass) : super.from();

  /// ## get_context
  ///
  /// ### python docstring
  ///
  /// Returns a pretty string pinpointing the error in the text,
  /// with span amount of context characters around it.
  ///
  /// Note:
  ///     The parser doesn't hold a copy of the text it has to parse,
  ///     so you have to provide it again
  ///
  /// ### python source
  /// ```py
  /// def get_context(self, text: str, span: int=40) -> str:
  ///         """Returns a pretty string pinpointing the error in the text,
  ///         with span amount of context characters around it.
  ///
  ///         Note:
  ///             The parser doesn't hold a copy of the text it has to parse,
  ///             so you have to provide it again
  ///         """
  ///         assert self.pos_in_stream is not None, self
  ///         pos = self.pos_in_stream
  ///         start = max(pos - span, 0)
  ///         end = pos + span
  ///         if not isinstance(text, bytes):
  ///             before = text[start:pos].rsplit('\n', 1)[-1]
  ///             after = text[pos:end].split('\n', 1)[0]
  ///             return before + after + '\n' + ' ' * len(before.expandtabs()) + '^\n'
  ///         else:
  ///             before = text[start:pos].rsplit(b'\n', 1)[-1]
  ///             after = text[pos:end].split(b'\n', 1)[0]
  ///             return (before + after + b'\n' + b' ' * len(before.expandtabs()) + b'^\n').decode("ascii", "backslashreplace")
  /// ```
  Object? get_context({
    required Object? text,
    Object? span = 40,
  }) =>
      getFunction("get_context").call(
        <Object?>[
          text,
          span,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## match_examples
  ///
  /// ### python docstring
  ///
  /// Allows you to detect what's wrong in the input text by matching
  /// against example errors.
  ///
  /// Given a parser instance and a dictionary mapping some label with
  /// some malformed syntax examples, it'll return the label for the
  /// example that bests matches the current error. The function will
  /// iterate the dictionary until it finds a matching error, and
  /// return the corresponding value.
  ///
  /// For an example usage, see `examples/error_reporting_lalr.py`
  ///
  /// Parameters:
  ///     parse_fn: parse function (usually ``lark_instance.parse``)
  ///     examples: dictionary of ``{'example_string': value}``.
  ///     use_accepts: Recommended to keep this as ``use_accepts=True``.
  ///
  /// ### python source
  /// ```py
  /// def match_examples(self, parse_fn: 'Callable[[str], Tree]',
  ///                              examples: Union[Mapping[T, Iterable[str]], Iterable[Tuple[T, Iterable[str]]]],
  ///                              token_type_match_fallback: bool=False,
  ///                              use_accepts: bool=True
  ///                          ) -> Optional[T]:
  ///         """Allows you to detect what's wrong in the input text by matching
  ///         against example errors.
  ///
  ///         Given a parser instance and a dictionary mapping some label with
  ///         some malformed syntax examples, it'll return the label for the
  ///         example that bests matches the current error. The function will
  ///         iterate the dictionary until it finds a matching error, and
  ///         return the corresponding value.
  ///
  ///         For an example usage, see `examples/error_reporting_lalr.py`
  ///
  ///         Parameters:
  ///             parse_fn: parse function (usually ``lark_instance.parse``)
  ///             examples: dictionary of ``{'example_string': value}``.
  ///             use_accepts: Recommended to keep this as ``use_accepts=True``.
  ///         """
  ///         assert self.state is not None, "Not supported for this exception"
  ///
  ///         if isinstance(examples, Mapping):
  ///             examples = examples.items()
  ///
  ///         candidate = (None, False)
  ///         for i, (label, example) in enumerate(examples):
  ///             assert not isinstance(example, str), "Expecting a list"
  ///
  ///             for j, malformed in enumerate(example):
  ///                 try:
  ///                     parse_fn(malformed)
  ///                 except UnexpectedInput as ut:
  ///                     if ut.state == self.state:
  ///                         if (
  ///                             use_accepts
  ///                             and isinstance(self, UnexpectedToken)
  ///                             and isinstance(ut, UnexpectedToken)
  ///                             and ut.accepts != self.accepts
  ///                         ):
  ///                             logger.debug("Different accepts with same state[%d]: %s != %s at example [%s][%s]" %
  ///                                          (self.state, self.accepts, ut.accepts, i, j))
  ///                             continue
  ///                         if (
  ///                             isinstance(self, (UnexpectedToken, UnexpectedEOF))
  ///                             and isinstance(ut, (UnexpectedToken, UnexpectedEOF))
  ///                         ):
  ///                             if ut.token == self.token:  # Try exact match first
  ///                                 logger.debug("Exact Match at example [%s][%s]" % (i, j))
  ///                                 return label
  ///
  ///                             if token_type_match_fallback:
  ///                                 # Fallback to token types match
  ///                                 if (ut.token.type == self.token.type) and not candidate[-1]:
  ///                                     logger.debug("Token Type Fallback at example [%s][%s]" % (i, j))
  ///                                     candidate = label, True
  ///
  ///                         if candidate[0] is None:
  ///                             logger.debug("Same State match at example [%s][%s]" % (i, j))
  ///                             candidate = label, False
  ///
  ///         return candidate[0]
  /// ```
  Object? match_examples({
    required Object? parse_fn,
    required Object? examples,
    Object? token_type_match_fallback = false,
    Object? use_accepts = true,
  }) =>
      getFunction("match_examples").call(
        <Object?>[
          parse_fn,
          examples,
          token_type_match_fallback,
          use_accepts,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);

  /// ## pos_in_stream (getter)
  Object? get pos_in_stream => getAttribute("pos_in_stream");

  /// ## pos_in_stream (setter)
  set pos_in_stream(Object? pos_in_stream) =>
      setAttribute("pos_in_stream", pos_in_stream);

  /// ## line (getter)
  Object? get line => getAttribute("line");

  /// ## line (setter)
  set line(Object? line) => setAttribute("line", line);

  /// ## column (getter)
  Object? get column => getAttribute("column");

  /// ## column (setter)
  set column(Object? column) => setAttribute("column", column);

  /// ## state (getter)
  Object? get state => getAttribute("state");

  /// ## state (setter)
  set state(Object? state) => setAttribute("state", state);

  /// ## allowed (getter)
  Object? get allowed => getAttribute("allowed");

  /// ## allowed (setter)
  set allowed(Object? allowed) => setAttribute("allowed", allowed);

  /// ## considered_tokens (getter)
  Object? get considered_tokens => getAttribute("considered_tokens");

  /// ## considered_tokens (setter)
  set considered_tokens(Object? considered_tokens) =>
      setAttribute("considered_tokens", considered_tokens);

  /// ## considered_rules (getter)
  Object? get considered_rules => getAttribute("considered_rules");

  /// ## considered_rules (setter)
  set considered_rules(Object? considered_rules) =>
      setAttribute("considered_rules", considered_rules);

  /// ## token_history (getter)
  Object? get token_history => getAttribute("token_history");

  /// ## token_history (setter)
  set token_history(Object? token_history) =>
      setAttribute("token_history", token_history);

  /// ## char (getter)
  Object? get char => getAttribute("char");

  /// ## char (setter)
  set char(Object? char) => setAttribute("char", char);
}

/// ## UnexpectedEOF
///
/// ### python docstring
///
/// An exception that is raised by the parser, when the input ends while it still expects a token.
///
/// ### python source
/// ```py
/// class UnexpectedEOF(ParseError, UnexpectedInput):
///     """An exception that is raised by the parser, when the input ends while it still expects a token.
///     """
///     expected: 'List[Token]'
///
///     def __init__(self, expected, state=None, terminals_by_name=None):
///         super(UnexpectedEOF, self).__init__()
///
///         self.expected = expected
///         self.state = state
///         from .lexer import Token
///         self.token = Token("<EOF>", "")  # , line=-1, column=-1, pos_in_stream=-1)
///         self.pos_in_stream = -1
///         self.line = -1
///         self.column = -1
///         self._terminals_by_name = terminals_by_name
///
///
///     def __str__(self):
///         message = "Unexpected end-of-input. "
///         message += self._format_expected(self.expected)
///         return message
/// ```
final class UnexpectedEOF extends PythonClass {
  factory UnexpectedEOF({
    required Object? expected,
    Object? state,
    Object? terminals_by_name,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.exceptions",
        "UnexpectedEOF",
        UnexpectedEOF.from,
        <Object?>[
          expected,
          state,
          terminals_by_name,
        ],
        <String, Object?>{},
      );

  UnexpectedEOF.from(super.pythonClass) : super.from();

  /// ## get_context
  ///
  /// ### python docstring
  ///
  /// Returns a pretty string pinpointing the error in the text,
  /// with span amount of context characters around it.
  ///
  /// Note:
  ///     The parser doesn't hold a copy of the text it has to parse,
  ///     so you have to provide it again
  ///
  /// ### python source
  /// ```py
  /// def get_context(self, text: str, span: int=40) -> str:
  ///         """Returns a pretty string pinpointing the error in the text,
  ///         with span amount of context characters around it.
  ///
  ///         Note:
  ///             The parser doesn't hold a copy of the text it has to parse,
  ///             so you have to provide it again
  ///         """
  ///         assert self.pos_in_stream is not None, self
  ///         pos = self.pos_in_stream
  ///         start = max(pos - span, 0)
  ///         end = pos + span
  ///         if not isinstance(text, bytes):
  ///             before = text[start:pos].rsplit('\n', 1)[-1]
  ///             after = text[pos:end].split('\n', 1)[0]
  ///             return before + after + '\n' + ' ' * len(before.expandtabs()) + '^\n'
  ///         else:
  ///             before = text[start:pos].rsplit(b'\n', 1)[-1]
  ///             after = text[pos:end].split(b'\n', 1)[0]
  ///             return (before + after + b'\n' + b' ' * len(before.expandtabs()) + b'^\n').decode("ascii", "backslashreplace")
  /// ```
  Object? get_context({
    required Object? text,
    Object? span = 40,
  }) =>
      getFunction("get_context").call(
        <Object?>[
          text,
          span,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## match_examples
  ///
  /// ### python docstring
  ///
  /// Allows you to detect what's wrong in the input text by matching
  /// against example errors.
  ///
  /// Given a parser instance and a dictionary mapping some label with
  /// some malformed syntax examples, it'll return the label for the
  /// example that bests matches the current error. The function will
  /// iterate the dictionary until it finds a matching error, and
  /// return the corresponding value.
  ///
  /// For an example usage, see `examples/error_reporting_lalr.py`
  ///
  /// Parameters:
  ///     parse_fn: parse function (usually ``lark_instance.parse``)
  ///     examples: dictionary of ``{'example_string': value}``.
  ///     use_accepts: Recommended to keep this as ``use_accepts=True``.
  ///
  /// ### python source
  /// ```py
  /// def match_examples(self, parse_fn: 'Callable[[str], Tree]',
  ///                              examples: Union[Mapping[T, Iterable[str]], Iterable[Tuple[T, Iterable[str]]]],
  ///                              token_type_match_fallback: bool=False,
  ///                              use_accepts: bool=True
  ///                          ) -> Optional[T]:
  ///         """Allows you to detect what's wrong in the input text by matching
  ///         against example errors.
  ///
  ///         Given a parser instance and a dictionary mapping some label with
  ///         some malformed syntax examples, it'll return the label for the
  ///         example that bests matches the current error. The function will
  ///         iterate the dictionary until it finds a matching error, and
  ///         return the corresponding value.
  ///
  ///         For an example usage, see `examples/error_reporting_lalr.py`
  ///
  ///         Parameters:
  ///             parse_fn: parse function (usually ``lark_instance.parse``)
  ///             examples: dictionary of ``{'example_string': value}``.
  ///             use_accepts: Recommended to keep this as ``use_accepts=True``.
  ///         """
  ///         assert self.state is not None, "Not supported for this exception"
  ///
  ///         if isinstance(examples, Mapping):
  ///             examples = examples.items()
  ///
  ///         candidate = (None, False)
  ///         for i, (label, example) in enumerate(examples):
  ///             assert not isinstance(example, str), "Expecting a list"
  ///
  ///             for j, malformed in enumerate(example):
  ///                 try:
  ///                     parse_fn(malformed)
  ///                 except UnexpectedInput as ut:
  ///                     if ut.state == self.state:
  ///                         if (
  ///                             use_accepts
  ///                             and isinstance(self, UnexpectedToken)
  ///                             and isinstance(ut, UnexpectedToken)
  ///                             and ut.accepts != self.accepts
  ///                         ):
  ///                             logger.debug("Different accepts with same state[%d]: %s != %s at example [%s][%s]" %
  ///                                          (self.state, self.accepts, ut.accepts, i, j))
  ///                             continue
  ///                         if (
  ///                             isinstance(self, (UnexpectedToken, UnexpectedEOF))
  ///                             and isinstance(ut, (UnexpectedToken, UnexpectedEOF))
  ///                         ):
  ///                             if ut.token == self.token:  # Try exact match first
  ///                                 logger.debug("Exact Match at example [%s][%s]" % (i, j))
  ///                                 return label
  ///
  ///                             if token_type_match_fallback:
  ///                                 # Fallback to token types match
  ///                                 if (ut.token.type == self.token.type) and not candidate[-1]:
  ///                                     logger.debug("Token Type Fallback at example [%s][%s]" % (i, j))
  ///                                     candidate = label, True
  ///
  ///                         if candidate[0] is None:
  ///                             logger.debug("Same State match at example [%s][%s]" % (i, j))
  ///                             candidate = label, False
  ///
  ///         return candidate[0]
  /// ```
  Object? match_examples({
    required Object? parse_fn,
    required Object? examples,
    Object? token_type_match_fallback = false,
    Object? use_accepts = true,
  }) =>
      getFunction("match_examples").call(
        <Object?>[
          parse_fn,
          examples,
          token_type_match_fallback,
          use_accepts,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);

  /// ## pos_in_stream (getter)
  Object? get pos_in_stream => getAttribute("pos_in_stream");

  /// ## pos_in_stream (setter)
  set pos_in_stream(Object? pos_in_stream) =>
      setAttribute("pos_in_stream", pos_in_stream);

  /// ## expected (getter)
  Object? get expected => getAttribute("expected");

  /// ## expected (setter)
  set expected(Object? expected) => setAttribute("expected", expected);

  /// ## state (getter)
  Object? get state => getAttribute("state");

  /// ## state (setter)
  set state(Object? state) => setAttribute("state", state);

  /// ## token (getter)
  Object? get token => getAttribute("token");

  /// ## token (setter)
  set token(Object? token) => setAttribute("token", token);

  /// ## line (getter)
  Object? get line => getAttribute("line");

  /// ## line (setter)
  set line(Object? line) => setAttribute("line", line);

  /// ## column (getter)
  Object? get column => getAttribute("column");

  /// ## column (setter)
  set column(Object? column) => setAttribute("column", column);
}

/// ## UnexpectedInput
///
/// ### python docstring
///
/// UnexpectedInput Error.
///
/// Used as a base class for the following exceptions:
///
/// - ``UnexpectedCharacters``: The lexer encountered an unexpected string
/// - ``UnexpectedToken``: The parser received an unexpected token
/// - ``UnexpectedEOF``: The parser expected a token, but the input ended
///
/// After catching one of these exceptions, you may call the following helper methods to create a nicer error message.
///
/// ### python source
/// ```py
/// class UnexpectedInput(LarkError):
///     """UnexpectedInput Error.
///
///     Used as a base class for the following exceptions:
///
///     - ``UnexpectedCharacters``: The lexer encountered an unexpected string
///     - ``UnexpectedToken``: The parser received an unexpected token
///     - ``UnexpectedEOF``: The parser expected a token, but the input ended
///
///     After catching one of these exceptions, you may call the following helper methods to create a nicer error message.
///     """
///     line: int
///     column: int
///     pos_in_stream = None
///     state: Any
///     _terminals_by_name = None
///
///     def get_context(self, text: str, span: int=40) -> str:
///         """Returns a pretty string pinpointing the error in the text,
///         with span amount of context characters around it.
///
///         Note:
///             The parser doesn't hold a copy of the text it has to parse,
///             so you have to provide it again
///         """
///         assert self.pos_in_stream is not None, self
///         pos = self.pos_in_stream
///         start = max(pos - span, 0)
///         end = pos + span
///         if not isinstance(text, bytes):
///             before = text[start:pos].rsplit('\n', 1)[-1]
///             after = text[pos:end].split('\n', 1)[0]
///             return before + after + '\n' + ' ' * len(before.expandtabs()) + '^\n'
///         else:
///             before = text[start:pos].rsplit(b'\n', 1)[-1]
///             after = text[pos:end].split(b'\n', 1)[0]
///             return (before + after + b'\n' + b' ' * len(before.expandtabs()) + b'^\n').decode("ascii", "backslashreplace")
///
///     def match_examples(self, parse_fn: 'Callable[[str], Tree]',
///                              examples: Union[Mapping[T, Iterable[str]], Iterable[Tuple[T, Iterable[str]]]],
///                              token_type_match_fallback: bool=False,
///                              use_accepts: bool=True
///                          ) -> Optional[T]:
///         """Allows you to detect what's wrong in the input text by matching
///         against example errors.
///
///         Given a parser instance and a dictionary mapping some label with
///         some malformed syntax examples, it'll return the label for the
///         example that bests matches the current error. The function will
///         iterate the dictionary until it finds a matching error, and
///         return the corresponding value.
///
///         For an example usage, see `examples/error_reporting_lalr.py`
///
///         Parameters:
///             parse_fn: parse function (usually ``lark_instance.parse``)
///             examples: dictionary of ``{'example_string': value}``.
///             use_accepts: Recommended to keep this as ``use_accepts=True``.
///         """
///         assert self.state is not None, "Not supported for this exception"
///
///         if isinstance(examples, Mapping):
///             examples = examples.items()
///
///         candidate = (None, False)
///         for i, (label, example) in enumerate(examples):
///             assert not isinstance(example, str), "Expecting a list"
///
///             for j, malformed in enumerate(example):
///                 try:
///                     parse_fn(malformed)
///                 except UnexpectedInput as ut:
///                     if ut.state == self.state:
///                         if (
///                             use_accepts
///                             and isinstance(self, UnexpectedToken)
///                             and isinstance(ut, UnexpectedToken)
///                             and ut.accepts != self.accepts
///                         ):
///                             logger.debug("Different accepts with same state[%d]: %s != %s at example [%s][%s]" %
///                                          (self.state, self.accepts, ut.accepts, i, j))
///                             continue
///                         if (
///                             isinstance(self, (UnexpectedToken, UnexpectedEOF))
///                             and isinstance(ut, (UnexpectedToken, UnexpectedEOF))
///                         ):
///                             if ut.token == self.token:  # Try exact match first
///                                 logger.debug("Exact Match at example [%s][%s]" % (i, j))
///                                 return label
///
///                             if token_type_match_fallback:
///                                 # Fallback to token types match
///                                 if (ut.token.type == self.token.type) and not candidate[-1]:
///                                     logger.debug("Token Type Fallback at example [%s][%s]" % (i, j))
///                                     candidate = label, True
///
///                         if candidate[0] is None:
///                             logger.debug("Same State match at example [%s][%s]" % (i, j))
///                             candidate = label, False
///
///         return candidate[0]
///
///     def _format_expected(self, expected):
///         if self._terminals_by_name:
///             d = self._terminals_by_name
///             expected = [d[t_name].user_repr() if t_name in d else t_name for t_name in expected]
///         return "Expected one of: \n\t* %s\n" % '\n\t* '.join(expected)
/// ```
final class UnexpectedInput extends PythonClass {
  factory UnexpectedInput() => PythonFfiDart.instance.importClass(
        "lark.exceptions",
        "UnexpectedInput",
        UnexpectedInput.from,
        <Object?>[],
      );

  UnexpectedInput.from(super.pythonClass) : super.from();

  /// ## get_context
  ///
  /// ### python docstring
  ///
  /// Returns a pretty string pinpointing the error in the text,
  /// with span amount of context characters around it.
  ///
  /// Note:
  ///     The parser doesn't hold a copy of the text it has to parse,
  ///     so you have to provide it again
  ///
  /// ### python source
  /// ```py
  /// def get_context(self, text: str, span: int=40) -> str:
  ///         """Returns a pretty string pinpointing the error in the text,
  ///         with span amount of context characters around it.
  ///
  ///         Note:
  ///             The parser doesn't hold a copy of the text it has to parse,
  ///             so you have to provide it again
  ///         """
  ///         assert self.pos_in_stream is not None, self
  ///         pos = self.pos_in_stream
  ///         start = max(pos - span, 0)
  ///         end = pos + span
  ///         if not isinstance(text, bytes):
  ///             before = text[start:pos].rsplit('\n', 1)[-1]
  ///             after = text[pos:end].split('\n', 1)[0]
  ///             return before + after + '\n' + ' ' * len(before.expandtabs()) + '^\n'
  ///         else:
  ///             before = text[start:pos].rsplit(b'\n', 1)[-1]
  ///             after = text[pos:end].split(b'\n', 1)[0]
  ///             return (before + after + b'\n' + b' ' * len(before.expandtabs()) + b'^\n').decode("ascii", "backslashreplace")
  /// ```
  Object? get_context({
    required Object? text,
    Object? span = 40,
  }) =>
      getFunction("get_context").call(
        <Object?>[
          text,
          span,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## match_examples
  ///
  /// ### python docstring
  ///
  /// Allows you to detect what's wrong in the input text by matching
  /// against example errors.
  ///
  /// Given a parser instance and a dictionary mapping some label with
  /// some malformed syntax examples, it'll return the label for the
  /// example that bests matches the current error. The function will
  /// iterate the dictionary until it finds a matching error, and
  /// return the corresponding value.
  ///
  /// For an example usage, see `examples/error_reporting_lalr.py`
  ///
  /// Parameters:
  ///     parse_fn: parse function (usually ``lark_instance.parse``)
  ///     examples: dictionary of ``{'example_string': value}``.
  ///     use_accepts: Recommended to keep this as ``use_accepts=True``.
  ///
  /// ### python source
  /// ```py
  /// def match_examples(self, parse_fn: 'Callable[[str], Tree]',
  ///                              examples: Union[Mapping[T, Iterable[str]], Iterable[Tuple[T, Iterable[str]]]],
  ///                              token_type_match_fallback: bool=False,
  ///                              use_accepts: bool=True
  ///                          ) -> Optional[T]:
  ///         """Allows you to detect what's wrong in the input text by matching
  ///         against example errors.
  ///
  ///         Given a parser instance and a dictionary mapping some label with
  ///         some malformed syntax examples, it'll return the label for the
  ///         example that bests matches the current error. The function will
  ///         iterate the dictionary until it finds a matching error, and
  ///         return the corresponding value.
  ///
  ///         For an example usage, see `examples/error_reporting_lalr.py`
  ///
  ///         Parameters:
  ///             parse_fn: parse function (usually ``lark_instance.parse``)
  ///             examples: dictionary of ``{'example_string': value}``.
  ///             use_accepts: Recommended to keep this as ``use_accepts=True``.
  ///         """
  ///         assert self.state is not None, "Not supported for this exception"
  ///
  ///         if isinstance(examples, Mapping):
  ///             examples = examples.items()
  ///
  ///         candidate = (None, False)
  ///         for i, (label, example) in enumerate(examples):
  ///             assert not isinstance(example, str), "Expecting a list"
  ///
  ///             for j, malformed in enumerate(example):
  ///                 try:
  ///                     parse_fn(malformed)
  ///                 except UnexpectedInput as ut:
  ///                     if ut.state == self.state:
  ///                         if (
  ///                             use_accepts
  ///                             and isinstance(self, UnexpectedToken)
  ///                             and isinstance(ut, UnexpectedToken)
  ///                             and ut.accepts != self.accepts
  ///                         ):
  ///                             logger.debug("Different accepts with same state[%d]: %s != %s at example [%s][%s]" %
  ///                                          (self.state, self.accepts, ut.accepts, i, j))
  ///                             continue
  ///                         if (
  ///                             isinstance(self, (UnexpectedToken, UnexpectedEOF))
  ///                             and isinstance(ut, (UnexpectedToken, UnexpectedEOF))
  ///                         ):
  ///                             if ut.token == self.token:  # Try exact match first
  ///                                 logger.debug("Exact Match at example [%s][%s]" % (i, j))
  ///                                 return label
  ///
  ///                             if token_type_match_fallback:
  ///                                 # Fallback to token types match
  ///                                 if (ut.token.type == self.token.type) and not candidate[-1]:
  ///                                     logger.debug("Token Type Fallback at example [%s][%s]" % (i, j))
  ///                                     candidate = label, True
  ///
  ///                         if candidate[0] is None:
  ///                             logger.debug("Same State match at example [%s][%s]" % (i, j))
  ///                             candidate = label, False
  ///
  ///         return candidate[0]
  /// ```
  Object? match_examples({
    required Object? parse_fn,
    required Object? examples,
    Object? token_type_match_fallback = false,
    Object? use_accepts = true,
  }) =>
      getFunction("match_examples").call(
        <Object?>[
          parse_fn,
          examples,
          token_type_match_fallback,
          use_accepts,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);

  /// ## pos_in_stream (getter)
  Object? get pos_in_stream => getAttribute("pos_in_stream");

  /// ## pos_in_stream (setter)
  set pos_in_stream(Object? pos_in_stream) =>
      setAttribute("pos_in_stream", pos_in_stream);
}

/// ## UnexpectedToken
///
/// ### python docstring
///
/// An exception that is raised by the parser, when the token it received
/// doesn't match any valid step forward.
///
/// Parameters:
///     token: The mismatched token
///     expected: The set of expected tokens
///     considered_rules: Which rules were considered, to deduce the expected tokens
///     state: A value representing the parser state. Do not rely on its value or type.
///     interactive_parser: An instance of ``InteractiveParser``, that is initialized to the point of failture,
///                         and can be used for debugging and error handling.
///
/// Note: These parameters are available as attributes of the instance.
///
/// ### python source
/// ```py
/// class UnexpectedToken(ParseError, UnexpectedInput):
///     """An exception that is raised by the parser, when the token it received
///     doesn't match any valid step forward.
///
///     Parameters:
///         token: The mismatched token
///         expected: The set of expected tokens
///         considered_rules: Which rules were considered, to deduce the expected tokens
///         state: A value representing the parser state. Do not rely on its value or type.
///         interactive_parser: An instance of ``InteractiveParser``, that is initialized to the point of failture,
///                             and can be used for debugging and error handling.
///
///     Note: These parameters are available as attributes of the instance.
///     """
///
///     expected: Set[str]
///     considered_rules: Set[str]
///     interactive_parser: 'InteractiveParser'
///
///     def __init__(self, token, expected, considered_rules=None, state=None, interactive_parser=None, terminals_by_name=None, token_history=None):
///         super(UnexpectedToken, self).__init__()
///
///         # TODO considered_rules and expected can be figured out using state
///         self.line = getattr(token, 'line', '?')
///         self.column = getattr(token, 'column', '?')
///         self.pos_in_stream = getattr(token, 'start_pos', None)
///         self.state = state
///
///         self.token = token
///         self.expected = expected  # XXX deprecate? `accepts` is better
///         self._accepts = NO_VALUE
///         self.considered_rules = considered_rules
///         self.interactive_parser = interactive_parser
///         self._terminals_by_name = terminals_by_name
///         self.token_history = token_history
///
///
///     @property
///     def accepts(self) -> Set[str]:
///         if self._accepts is NO_VALUE:
///             self._accepts = self.interactive_parser and self.interactive_parser.accepts()
///         return self._accepts
///
///     def __str__(self):
///         message = ("Unexpected token %r at line %s, column %s.\n%s"
///                    % (self.token, self.line, self.column, self._format_expected(self.accepts or self.expected)))
///         if self.token_history:
///             message += "Previous tokens: %r\n" % self.token_history
///
///         return message
/// ```
final class UnexpectedToken extends PythonClass {
  factory UnexpectedToken({
    required Object? token,
    required Object? expected,
    Object? considered_rules,
    Object? state,
    Object? interactive_parser,
    Object? terminals_by_name,
    Object? token_history,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.exceptions",
        "UnexpectedToken",
        UnexpectedToken.from,
        <Object?>[
          token,
          expected,
          considered_rules,
          state,
          interactive_parser,
          terminals_by_name,
          token_history,
        ],
        <String, Object?>{},
      );

  UnexpectedToken.from(super.pythonClass) : super.from();

  /// ## get_context
  ///
  /// ### python docstring
  ///
  /// Returns a pretty string pinpointing the error in the text,
  /// with span amount of context characters around it.
  ///
  /// Note:
  ///     The parser doesn't hold a copy of the text it has to parse,
  ///     so you have to provide it again
  ///
  /// ### python source
  /// ```py
  /// def get_context(self, text: str, span: int=40) -> str:
  ///         """Returns a pretty string pinpointing the error in the text,
  ///         with span amount of context characters around it.
  ///
  ///         Note:
  ///             The parser doesn't hold a copy of the text it has to parse,
  ///             so you have to provide it again
  ///         """
  ///         assert self.pos_in_stream is not None, self
  ///         pos = self.pos_in_stream
  ///         start = max(pos - span, 0)
  ///         end = pos + span
  ///         if not isinstance(text, bytes):
  ///             before = text[start:pos].rsplit('\n', 1)[-1]
  ///             after = text[pos:end].split('\n', 1)[0]
  ///             return before + after + '\n' + ' ' * len(before.expandtabs()) + '^\n'
  ///         else:
  ///             before = text[start:pos].rsplit(b'\n', 1)[-1]
  ///             after = text[pos:end].split(b'\n', 1)[0]
  ///             return (before + after + b'\n' + b' ' * len(before.expandtabs()) + b'^\n').decode("ascii", "backslashreplace")
  /// ```
  Object? get_context({
    required Object? text,
    Object? span = 40,
  }) =>
      getFunction("get_context").call(
        <Object?>[
          text,
          span,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## match_examples
  ///
  /// ### python docstring
  ///
  /// Allows you to detect what's wrong in the input text by matching
  /// against example errors.
  ///
  /// Given a parser instance and a dictionary mapping some label with
  /// some malformed syntax examples, it'll return the label for the
  /// example that bests matches the current error. The function will
  /// iterate the dictionary until it finds a matching error, and
  /// return the corresponding value.
  ///
  /// For an example usage, see `examples/error_reporting_lalr.py`
  ///
  /// Parameters:
  ///     parse_fn: parse function (usually ``lark_instance.parse``)
  ///     examples: dictionary of ``{'example_string': value}``.
  ///     use_accepts: Recommended to keep this as ``use_accepts=True``.
  ///
  /// ### python source
  /// ```py
  /// def match_examples(self, parse_fn: 'Callable[[str], Tree]',
  ///                              examples: Union[Mapping[T, Iterable[str]], Iterable[Tuple[T, Iterable[str]]]],
  ///                              token_type_match_fallback: bool=False,
  ///                              use_accepts: bool=True
  ///                          ) -> Optional[T]:
  ///         """Allows you to detect what's wrong in the input text by matching
  ///         against example errors.
  ///
  ///         Given a parser instance and a dictionary mapping some label with
  ///         some malformed syntax examples, it'll return the label for the
  ///         example that bests matches the current error. The function will
  ///         iterate the dictionary until it finds a matching error, and
  ///         return the corresponding value.
  ///
  ///         For an example usage, see `examples/error_reporting_lalr.py`
  ///
  ///         Parameters:
  ///             parse_fn: parse function (usually ``lark_instance.parse``)
  ///             examples: dictionary of ``{'example_string': value}``.
  ///             use_accepts: Recommended to keep this as ``use_accepts=True``.
  ///         """
  ///         assert self.state is not None, "Not supported for this exception"
  ///
  ///         if isinstance(examples, Mapping):
  ///             examples = examples.items()
  ///
  ///         candidate = (None, False)
  ///         for i, (label, example) in enumerate(examples):
  ///             assert not isinstance(example, str), "Expecting a list"
  ///
  ///             for j, malformed in enumerate(example):
  ///                 try:
  ///                     parse_fn(malformed)
  ///                 except UnexpectedInput as ut:
  ///                     if ut.state == self.state:
  ///                         if (
  ///                             use_accepts
  ///                             and isinstance(self, UnexpectedToken)
  ///                             and isinstance(ut, UnexpectedToken)
  ///                             and ut.accepts != self.accepts
  ///                         ):
  ///                             logger.debug("Different accepts with same state[%d]: %s != %s at example [%s][%s]" %
  ///                                          (self.state, self.accepts, ut.accepts, i, j))
  ///                             continue
  ///                         if (
  ///                             isinstance(self, (UnexpectedToken, UnexpectedEOF))
  ///                             and isinstance(ut, (UnexpectedToken, UnexpectedEOF))
  ///                         ):
  ///                             if ut.token == self.token:  # Try exact match first
  ///                                 logger.debug("Exact Match at example [%s][%s]" % (i, j))
  ///                                 return label
  ///
  ///                             if token_type_match_fallback:
  ///                                 # Fallback to token types match
  ///                                 if (ut.token.type == self.token.type) and not candidate[-1]:
  ///                                     logger.debug("Token Type Fallback at example [%s][%s]" % (i, j))
  ///                                     candidate = label, True
  ///
  ///                         if candidate[0] is None:
  ///                             logger.debug("Same State match at example [%s][%s]" % (i, j))
  ///                             candidate = label, False
  ///
  ///         return candidate[0]
  /// ```
  Object? match_examples({
    required Object? parse_fn,
    required Object? examples,
    Object? token_type_match_fallback = false,
    Object? use_accepts = true,
  }) =>
      getFunction("match_examples").call(
        <Object?>[
          parse_fn,
          examples,
          token_type_match_fallback,
          use_accepts,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## accepts (getter)
  Object? get accepts => getAttribute("accepts");

  /// ## accepts (setter)
  set accepts(Object? accepts) => setAttribute("accepts", accepts);

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);

  /// ## pos_in_stream (getter)
  Object? get pos_in_stream => getAttribute("pos_in_stream");

  /// ## pos_in_stream (setter)
  set pos_in_stream(Object? pos_in_stream) =>
      setAttribute("pos_in_stream", pos_in_stream);

  /// ## line (getter)
  Object? get line => getAttribute("line");

  /// ## line (setter)
  set line(Object? line) => setAttribute("line", line);

  /// ## column (getter)
  Object? get column => getAttribute("column");

  /// ## column (setter)
  set column(Object? column) => setAttribute("column", column);

  /// ## state (getter)
  Object? get state => getAttribute("state");

  /// ## state (setter)
  set state(Object? state) => setAttribute("state", state);

  /// ## token (getter)
  Object? get token => getAttribute("token");

  /// ## token (setter)
  set token(Object? token) => setAttribute("token", token);

  /// ## expected (getter)
  Object? get expected => getAttribute("expected");

  /// ## expected (setter)
  set expected(Object? expected) => setAttribute("expected", expected);

  /// ## considered_rules (getter)
  Object? get considered_rules => getAttribute("considered_rules");

  /// ## considered_rules (setter)
  set considered_rules(Object? considered_rules) =>
      setAttribute("considered_rules", considered_rules);

  /// ## interactive_parser (getter)
  Object? get interactive_parser => getAttribute("interactive_parser");

  /// ## interactive_parser (setter)
  set interactive_parser(Object? interactive_parser) =>
      setAttribute("interactive_parser", interactive_parser);

  /// ## token_history (getter)
  Object? get token_history => getAttribute("token_history");

  /// ## token_history (setter)
  set token_history(Object? token_history) =>
      setAttribute("token_history", token_history);
}

/// ## Visitor
///
/// ### python docstring
///
/// Tree visitor, non-recursive (can handle huge trees).
///
/// Visiting a node calls its methods (provided by the user via inheritance) according to ``tree.data``
///
/// ### python source
/// ```py
/// class Visitor(VisitorBase, ABC, Generic[_Leaf_T]):
///     """Tree visitor, non-recursive (can handle huge trees).
///
///     Visiting a node calls its methods (provided by the user via inheritance) according to ``tree.data``
///     """
///
///     def visit(self, tree: Tree[_Leaf_T]) -> Tree[_Leaf_T]:
///         "Visits the tree, starting with the leaves and finally the root (bottom-up)"
///         for subtree in tree.iter_subtrees():
///             self._call_userfunc(subtree)
///         return tree
///
///     def visit_topdown(self, tree: Tree[_Leaf_T]) -> Tree[_Leaf_T]:
///         "Visit the tree, starting at the root, and ending at the leaves (top-down)"
///         for subtree in tree.iter_subtrees_topdown():
///             self._call_userfunc(subtree)
///         return tree
/// ```
final class Visitor extends PythonClass {
  factory Visitor() => PythonFfiDart.instance.importClass(
        "lark.visitors",
        "Visitor",
        Visitor.from,
        <Object?>[],
      );

  Visitor.from(super.pythonClass) : super.from();

  /// ## visit
  ///
  /// ### python docstring
  ///
  /// Visits the tree, starting with the leaves and finally the root (bottom-up)
  ///
  /// ### python source
  /// ```py
  /// def visit(self, tree: Tree[_Leaf_T]) -> Tree[_Leaf_T]:
  ///         "Visits the tree, starting with the leaves and finally the root (bottom-up)"
  ///         for subtree in tree.iter_subtrees():
  ///             self._call_userfunc(subtree)
  ///         return tree
  /// ```
  Object? visit({
    required Object? tree,
  }) =>
      getFunction("visit").call(
        <Object?>[
          tree,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_topdown
  ///
  /// ### python docstring
  ///
  /// Visit the tree, starting at the root, and ending at the leaves (top-down)
  ///
  /// ### python source
  /// ```py
  /// def visit_topdown(self, tree: Tree[_Leaf_T]) -> Tree[_Leaf_T]:
  ///         "Visit the tree, starting at the root, and ending at the leaves (top-down)"
  ///         for subtree in tree.iter_subtrees_topdown():
  ///             self._call_userfunc(subtree)
  ///         return tree
  /// ```
  Object? visit_topdown({
    required Object? tree,
  }) =>
      getFunction("visit_topdown").call(
        <Object?>[
          tree,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## LexerConf
///
/// ### python docstring
///
/// Safe-ish serialization interface that doesn't rely on Pickle
///
/// Attributes:
///     __serialize_fields__ (List[str]): Fields (aka attributes) to serialize.
///     __serialize_namespace__ (list): List of classes that deserialization is allowed to instantiate.
///                                     Should include all field types that aren't builtin types.
///
/// ### python source
/// ```py
/// class LexerConf(Serialize):
///     __serialize_fields__ = 'terminals', 'ignore', 'g_regex_flags', 'use_bytes', 'lexer_type'
///     __serialize_namespace__ = TerminalDef,
///
///     terminals: Collection[TerminalDef]
///     re_module: ModuleType
///     ignore: Collection[str]
///     postlex: 'Optional[PostLex]'
///     callbacks: Dict[str, _Callback]
///     g_regex_flags: int
///     skip_validation: bool
///     use_bytes: bool
///     lexer_type: Optional[_LexerArgType]
///
///     def __init__(self, terminals: Collection[TerminalDef], re_module: ModuleType, ignore: Collection[str]=(), postlex: 'Optional[PostLex]'=None, callbacks: Optional[Dict[str, _Callback]]=None, g_regex_flags: int=0, skip_validation: bool=False, use_bytes: bool=False):
///         self.terminals = terminals
///         self.terminals_by_name = {t.name: t for t in self.terminals}
///         assert len(self.terminals) == len(self.terminals_by_name)
///         self.ignore = ignore
///         self.postlex = postlex
///         self.callbacks = callbacks or {}
///         self.g_regex_flags = g_regex_flags
///         self.re_module = re_module
///         self.skip_validation = skip_validation
///         self.use_bytes = use_bytes
///         self.lexer_type = None
///
///     def _deserialize(self):
///         self.terminals_by_name = {t.name: t for t in self.terminals}
///
///     def __deepcopy__(self, memo=None):
///         return type(self)(
///             deepcopy(self.terminals, memo),
///             self.re_module,
///             deepcopy(self.ignore, memo),
///             deepcopy(self.postlex, memo),
///             deepcopy(self.callbacks, memo),
///             deepcopy(self.g_regex_flags, memo),
///             deepcopy(self.skip_validation, memo),
///             deepcopy(self.use_bytes, memo),
///         )
/// ```
final class LexerConf extends PythonClass {
  factory LexerConf({
    required Object? terminals,
    required Object? re_module,
    Object? ignore = const [],
    Object? postlex,
    Object? callbacks,
    Object? g_regex_flags = 0,
    Object? skip_validation = false,
    Object? use_bytes = false,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.common",
        "LexerConf",
        LexerConf.from,
        <Object?>[
          terminals,
          re_module,
          ignore,
          postlex,
          callbacks,
          g_regex_flags,
          skip_validation,
          use_bytes,
        ],
        <String, Object?>{},
      );

  LexerConf.from(super.pythonClass) : super.from();

  /// ## memo_serialize
  ///
  /// ### python source
  /// ```py
  /// def memo_serialize(self, types_to_memoize: List) -> Any:
  ///         memo = SerializeMemoizer(types_to_memoize)
  ///         return self.serialize(memo), memo.serialize()
  /// ```
  Object? memo_serialize({
    required Object? types_to_memoize,
  }) =>
      getFunction("memo_serialize").call(
        <Object?>[
          types_to_memoize,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## serialize
  ///
  /// ### python source
  /// ```py
  /// def serialize(self, memo = None) -> Dict[str, Any]:
  ///         if memo and memo.in_types(self):
  ///             return {'@': memo.memoized.get(self)}
  ///
  ///         fields = getattr(self, '__serialize_fields__')
  ///         res = {f: _serialize(getattr(self, f), memo) for f in fields}
  ///         res['__type__'] = type(self).__name__
  ///         if hasattr(self, '_serialize'):
  ///             self._serialize(res, memo)  # type: ignore[attr-defined]
  ///         return res
  /// ```
  Object? serialize({
    Object? memo,
  }) =>
      getFunction("serialize").call(
        <Object?>[
          memo,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## deserialize (getter)
  Object? get deserialize => getAttribute("deserialize");

  /// ## deserialize (setter)
  set deserialize(Object? deserialize) =>
      setAttribute("deserialize", deserialize);

  /// ## terminals (getter)
  Object? get terminals => getAttribute("terminals");

  /// ## terminals (setter)
  set terminals(Object? terminals) => setAttribute("terminals", terminals);

  /// ## terminals_by_name (getter)
  Object? get terminals_by_name => getAttribute("terminals_by_name");

  /// ## terminals_by_name (setter)
  set terminals_by_name(Object? terminals_by_name) =>
      setAttribute("terminals_by_name", terminals_by_name);

  /// ## ignore (getter)
  Object? get ignore => getAttribute("ignore");

  /// ## ignore (setter)
  set ignore(Object? ignore) => setAttribute("ignore", ignore);

  /// ## postlex (getter)
  Object? get postlex => getAttribute("postlex");

  /// ## postlex (setter)
  set postlex(Object? postlex) => setAttribute("postlex", postlex);

  /// ## callbacks (getter)
  Object? get callbacks => getAttribute("callbacks");

  /// ## callbacks (setter)
  set callbacks(Object? callbacks) => setAttribute("callbacks", callbacks);

  /// ## g_regex_flags (getter)
  Object? get g_regex_flags => getAttribute("g_regex_flags");

  /// ## g_regex_flags (setter)
  set g_regex_flags(Object? g_regex_flags) =>
      setAttribute("g_regex_flags", g_regex_flags);

  /// ## re_module (getter)
  Object? get re_module => getAttribute("re_module");

  /// ## re_module (setter)
  set re_module(Object? re_module) => setAttribute("re_module", re_module);

  /// ## skip_validation (getter)
  Object? get skip_validation => getAttribute("skip_validation");

  /// ## skip_validation (setter)
  set skip_validation(Object? skip_validation) =>
      setAttribute("skip_validation", skip_validation);

  /// ## use_bytes (getter)
  Object? get use_bytes => getAttribute("use_bytes");

  /// ## use_bytes (setter)
  set use_bytes(Object? use_bytes) => setAttribute("use_bytes", use_bytes);

  /// ## lexer_type (getter)
  Object? get lexer_type => getAttribute("lexer_type");

  /// ## lexer_type (setter)
  set lexer_type(Object? lexer_type) => setAttribute("lexer_type", lexer_type);
}

/// ## ModuleType
final class ModuleType extends PythonClass {
  factory ModuleType() => PythonFfiDart.instance.importClass(
        "builtins",
        "ModuleType",
        ModuleType.from,
        <Object?>[],
      );

  ModuleType.from(super.pythonClass) : super.from();
}

/// ## ParserConf
///
/// ### python docstring
///
/// Safe-ish serialization interface that doesn't rely on Pickle
///
/// Attributes:
///     __serialize_fields__ (List[str]): Fields (aka attributes) to serialize.
///     __serialize_namespace__ (list): List of classes that deserialization is allowed to instantiate.
///                                     Should include all field types that aren't builtin types.
///
/// ### python source
/// ```py
/// class ParserConf(Serialize):
///     __serialize_fields__ = 'rules', 'start', 'parser_type'
///
///     def __init__(self, rules, callbacks, start):
///         assert isinstance(start, list)
///         self.rules = rules
///         self.callbacks = callbacks
///         self.start = start
///
///         self.parser_type = None
/// ```
final class ParserConf extends PythonClass {
  factory ParserConf({
    required Object? rules,
    required Object? callbacks,
    required Object? start,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.common",
        "ParserConf",
        ParserConf.from,
        <Object?>[
          rules,
          callbacks,
          start,
        ],
        <String, Object?>{},
      );

  ParserConf.from(super.pythonClass) : super.from();

  /// ## memo_serialize
  ///
  /// ### python source
  /// ```py
  /// def memo_serialize(self, types_to_memoize: List) -> Any:
  ///         memo = SerializeMemoizer(types_to_memoize)
  ///         return self.serialize(memo), memo.serialize()
  /// ```
  Object? memo_serialize({
    required Object? types_to_memoize,
  }) =>
      getFunction("memo_serialize").call(
        <Object?>[
          types_to_memoize,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## serialize
  ///
  /// ### python source
  /// ```py
  /// def serialize(self, memo = None) -> Dict[str, Any]:
  ///         if memo and memo.in_types(self):
  ///             return {'@': memo.memoized.get(self)}
  ///
  ///         fields = getattr(self, '__serialize_fields__')
  ///         res = {f: _serialize(getattr(self, f), memo) for f in fields}
  ///         res['__type__'] = type(self).__name__
  ///         if hasattr(self, '_serialize'):
  ///             self._serialize(res, memo)  # type: ignore[attr-defined]
  ///         return res
  /// ```
  Object? serialize({
    Object? memo,
  }) =>
      getFunction("serialize").call(
        <Object?>[
          memo,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## deserialize (getter)
  Object? get deserialize => getAttribute("deserialize");

  /// ## deserialize (setter)
  set deserialize(Object? deserialize) =>
      setAttribute("deserialize", deserialize);

  /// ## rules (getter)
  Object? get rules => getAttribute("rules");

  /// ## rules (setter)
  set rules(Object? rules) => setAttribute("rules", rules);

  /// ## callbacks (getter)
  Object? get callbacks => getAttribute("callbacks");

  /// ## callbacks (setter)
  set callbacks(Object? callbacks) => setAttribute("callbacks", callbacks);

  /// ## start (getter)
  Object? get start => getAttribute("start");

  /// ## start (setter)
  set start(Object? start) => setAttribute("start", start);

  /// ## parser_type (getter)
  Object? get parser_type => getAttribute("parser_type");

  /// ## parser_type (setter)
  set parser_type(Object? parser_type) =>
      setAttribute("parser_type", parser_type);
}

/// ## Serialize
///
/// ### python docstring
///
/// Safe-ish serialization interface that doesn't rely on Pickle
///
/// Attributes:
///     __serialize_fields__ (List[str]): Fields (aka attributes) to serialize.
///     __serialize_namespace__ (list): List of classes that deserialization is allowed to instantiate.
///                                     Should include all field types that aren't builtin types.
///
/// ### python source
/// ```py
/// class Serialize:
///     """Safe-ish serialization interface that doesn't rely on Pickle
///
///     Attributes:
///         __serialize_fields__ (List[str]): Fields (aka attributes) to serialize.
///         __serialize_namespace__ (list): List of classes that deserialization is allowed to instantiate.
///                                         Should include all field types that aren't builtin types.
///     """
///
///     def memo_serialize(self, types_to_memoize: List) -> Any:
///         memo = SerializeMemoizer(types_to_memoize)
///         return self.serialize(memo), memo.serialize()
///
///     def serialize(self, memo = None) -> Dict[str, Any]:
///         if memo and memo.in_types(self):
///             return {'@': memo.memoized.get(self)}
///
///         fields = getattr(self, '__serialize_fields__')
///         res = {f: _serialize(getattr(self, f), memo) for f in fields}
///         res['__type__'] = type(self).__name__
///         if hasattr(self, '_serialize'):
///             self._serialize(res, memo)  # type: ignore[attr-defined]
///         return res
///
///     @classmethod
///     def deserialize(cls: Type[_T], data: Dict[str, Any], memo: Dict[int, Any]) -> _T:
///         namespace = getattr(cls, '__serialize_namespace__', [])
///         namespace = {c.__name__:c for c in namespace}
///
///         fields = getattr(cls, '__serialize_fields__')
///
///         if '@' in data:
///             return memo[data['@']]
///
///         inst = cls.__new__(cls)
///         for f in fields:
///             try:
///                 setattr(inst, f, _deserialize(data[f], namespace, memo))
///             except KeyError as e:
///                 raise KeyError("Cannot find key for class", cls, e)
///
///         if hasattr(inst, '_deserialize'):
///             inst._deserialize()  # type: ignore[attr-defined]
///
///         return inst
/// ```
final class Serialize extends PythonClass {
  factory Serialize() => PythonFfiDart.instance.importClass(
        "lark.utils",
        "Serialize",
        Serialize.from,
        <Object?>[],
      );

  Serialize.from(super.pythonClass) : super.from();

  /// ## memo_serialize
  ///
  /// ### python source
  /// ```py
  /// def memo_serialize(self, types_to_memoize: List) -> Any:
  ///         memo = SerializeMemoizer(types_to_memoize)
  ///         return self.serialize(memo), memo.serialize()
  /// ```
  Object? memo_serialize({
    required Object? types_to_memoize,
  }) =>
      getFunction("memo_serialize").call(
        <Object?>[
          types_to_memoize,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## serialize
  ///
  /// ### python source
  /// ```py
  /// def serialize(self, memo = None) -> Dict[str, Any]:
  ///         if memo and memo.in_types(self):
  ///             return {'@': memo.memoized.get(self)}
  ///
  ///         fields = getattr(self, '__serialize_fields__')
  ///         res = {f: _serialize(getattr(self, f), memo) for f in fields}
  ///         res['__type__'] = type(self).__name__
  ///         if hasattr(self, '_serialize'):
  ///             self._serialize(res, memo)  # type: ignore[attr-defined]
  ///         return res
  /// ```
  Object? serialize({
    Object? memo,
  }) =>
      getFunction("serialize").call(
        <Object?>[
          memo,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## deserialize (getter)
  Object? get deserialize => getAttribute("deserialize");

  /// ## deserialize (setter)
  set deserialize(Object? deserialize) =>
      setAttribute("deserialize", deserialize);
}

/// ## TerminalDef
///
/// ### python docstring
///
/// Safe-ish serialization interface that doesn't rely on Pickle
///
/// Attributes:
///     __serialize_fields__ (List[str]): Fields (aka attributes) to serialize.
///     __serialize_namespace__ (list): List of classes that deserialization is allowed to instantiate.
///                                     Should include all field types that aren't builtin types.
///
/// ### python source
/// ```py
/// class TerminalDef(Serialize):
///     __serialize_fields__ = 'name', 'pattern', 'priority'
///     __serialize_namespace__ = PatternStr, PatternRE
///
///     name: str
///     pattern: Pattern
///     priority: int
///
///     def __init__(self, name: str, pattern: Pattern, priority: int=TOKEN_DEFAULT_PRIORITY) -> None:
///         assert isinstance(pattern, Pattern), pattern
///         self.name = name
///         self.pattern = pattern
///         self.priority = priority
///
///     def __repr__(self):
///         return '%s(%r, %r)' % (type(self).__name__, self.name, self.pattern)
///
///     def user_repr(self) -> str:
///         if self.name.startswith('__'): # We represent a generated terminal
///             return self.pattern.raw or self.name
///         else:
///             return self.name
/// ```
final class TerminalDef extends PythonClass {
  factory TerminalDef({
    required Object? name,
    required Object? pattern,
    Object? priority = 0,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.lexer",
        "TerminalDef",
        TerminalDef.from,
        <Object?>[
          name,
          pattern,
          priority,
        ],
        <String, Object?>{},
      );

  TerminalDef.from(super.pythonClass) : super.from();

  /// ## memo_serialize
  ///
  /// ### python source
  /// ```py
  /// def memo_serialize(self, types_to_memoize: List) -> Any:
  ///         memo = SerializeMemoizer(types_to_memoize)
  ///         return self.serialize(memo), memo.serialize()
  /// ```
  Object? memo_serialize({
    required Object? types_to_memoize,
  }) =>
      getFunction("memo_serialize").call(
        <Object?>[
          types_to_memoize,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## serialize
  ///
  /// ### python source
  /// ```py
  /// def serialize(self, memo = None) -> Dict[str, Any]:
  ///         if memo and memo.in_types(self):
  ///             return {'@': memo.memoized.get(self)}
  ///
  ///         fields = getattr(self, '__serialize_fields__')
  ///         res = {f: _serialize(getattr(self, f), memo) for f in fields}
  ///         res['__type__'] = type(self).__name__
  ///         if hasattr(self, '_serialize'):
  ///             self._serialize(res, memo)  # type: ignore[attr-defined]
  ///         return res
  /// ```
  Object? serialize({
    Object? memo,
  }) =>
      getFunction("serialize").call(
        <Object?>[
          memo,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## user_repr
  ///
  /// ### python source
  /// ```py
  /// def user_repr(self) -> str:
  ///         if self.name.startswith('__'): # We represent a generated terminal
  ///             return self.pattern.raw or self.name
  ///         else:
  ///             return self.name
  /// ```
  Object? user_repr() => getFunction("user_repr").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## deserialize (getter)
  Object? get deserialize => getAttribute("deserialize");

  /// ## deserialize (setter)
  set deserialize(Object? deserialize) =>
      setAttribute("deserialize", deserialize);

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);

  /// ## pattern (getter)
  Object? get pattern => getAttribute("pattern");

  /// ## pattern (setter)
  set pattern(Object? pattern) => setAttribute("pattern", pattern);

  /// ## priority (getter)
  Object? get priority => getAttribute("priority");

  /// ## priority (setter)
  set priority(Object? priority) => setAttribute("priority", priority);
}

/// ## Any
///
/// ### python docstring
///
/// Special type indicating an unconstrained type.
///
/// - Any is compatible with every type.
/// - Any assumed to have all methods.
/// - All values assumed to be instances of Any.
///
/// Note that all the above statements are true from the point of view of
/// static type checkers. At runtime, Any should not be used with instance
/// checks.
///
/// ### python source
/// ```py
/// class Any(metaclass=_AnyMeta):
///     """Special type indicating an unconstrained type.
///
///     - Any is compatible with every type.
///     - Any assumed to have all methods.
///     - All values assumed to be instances of Any.
///
///     Note that all the above statements are true from the point of view of
///     static type checkers. At runtime, Any should not be used with instance
///     checks.
///     """
///     def __new__(cls, *args, **kwargs):
///         if cls is Any:
///             raise TypeError("Any cannot be instantiated")
///         return super().__new__(cls, *args, **kwargs)
/// ```
final class Any extends PythonClass {
  factory Any() => PythonFfiDart.instance.importClass(
        "typing",
        "Any",
        Any.from,
        <Object?>[],
      );

  Any.from(super.pythonClass) : super.from();
}

/// ## ConfigurationError
///
/// ### python source
/// ```py
/// class ConfigurationError(LarkError, ValueError):
///     pass
/// ```
final class ConfigurationError extends PythonClass {
  factory ConfigurationError() => PythonFfiDart.instance.importClass(
        "lark.exceptions",
        "ConfigurationError",
        ConfigurationError.from,
        <Object?>[],
      );

  ConfigurationError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## MissingVariableError
///
/// ### python source
/// ```py
/// class MissingVariableError(LarkError):
///     pass
/// ```
final class MissingVariableError extends PythonClass {
  factory MissingVariableError() => PythonFfiDart.instance.importClass(
        "lark.exceptions",
        "MissingVariableError",
        MissingVariableError.from,
        <Object?>[],
      );

  MissingVariableError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## TypeVar
///
/// ### python docstring
///
/// Type variable.
///
/// Usage::
///
///   T = TypeVar('T')  # Can be anything
///   A = TypeVar('A', str, bytes)  # Must be str or bytes
///
/// Type variables exist primarily for the benefit of static type
/// checkers.  They serve as the parameters for generic types as well
/// as for generic function definitions.  See class Generic for more
/// information on generic types.  Generic functions work as follows:
///
///   def repeat(x: T, n: int) -> List[T]:
///       '''Return a list containing n references to x.'''
///       return [x]*n
///
///   def longest(x: A, y: A) -> A:
///       '''Return the longest of two strings.'''
///       return x if len(x) >= len(y) else y
///
/// The latter example's signature is essentially the overloading
/// of (str, str) -> str and (bytes, bytes) -> bytes.  Also note
/// that if the arguments are instances of some subclass of str,
/// the return type is still plain str.
///
/// At runtime, isinstance(x, T) and issubclass(C, T) will raise TypeError.
///
/// Type variables defined with covariant=True or contravariant=True
/// can be used to declare covariant or contravariant generic types.
/// See PEP 484 for more details. By default generic types are invariant
/// in all type variables.
///
/// Type variables can be introspected. e.g.:
///
///   T.__name__ == 'T'
///   T.__constraints__ == ()
///   T.__covariant__ == False
///   T.__contravariant__ = False
///   A.__constraints__ == (str, bytes)
///
/// Note that only type variables defined in global scope can be pickled.
///
/// ### python source
/// ```py
/// class TypeVar(_Final, _Immutable, _BoundVarianceMixin, _PickleUsingNameMixin,
///               _root=True):
///     """Type variable.
///
///     Usage::
///
///       T = TypeVar('T')  # Can be anything
///       A = TypeVar('A', str, bytes)  # Must be str or bytes
///
///     Type variables exist primarily for the benefit of static type
///     checkers.  They serve as the parameters for generic types as well
///     as for generic function definitions.  See class Generic for more
///     information on generic types.  Generic functions work as follows:
///
///       def repeat(x: T, n: int) -> List[T]:
///           '''Return a list containing n references to x.'''
///           return [x]*n
///
///       def longest(x: A, y: A) -> A:
///           '''Return the longest of two strings.'''
///           return x if len(x) >= len(y) else y
///
///     The latter example's signature is essentially the overloading
///     of (str, str) -> str and (bytes, bytes) -> bytes.  Also note
///     that if the arguments are instances of some subclass of str,
///     the return type is still plain str.
///
///     At runtime, isinstance(x, T) and issubclass(C, T) will raise TypeError.
///
///     Type variables defined with covariant=True or contravariant=True
///     can be used to declare covariant or contravariant generic types.
///     See PEP 484 for more details. By default generic types are invariant
///     in all type variables.
///
///     Type variables can be introspected. e.g.:
///
///       T.__name__ == 'T'
///       T.__constraints__ == ()
///       T.__covariant__ == False
///       T.__contravariant__ = False
///       A.__constraints__ == (str, bytes)
///
///     Note that only type variables defined in global scope can be pickled.
///     """
///
///     def __init__(self, name, *constraints, bound=None,
///                  covariant=False, contravariant=False):
///         self.__name__ = name
///         super().__init__(bound, covariant, contravariant)
///         if constraints and bound is not None:
///             raise TypeError("Constraints cannot be combined with bound=...")
///         if constraints and len(constraints) == 1:
///             raise TypeError("A single constraint is not allowed")
///         msg = "TypeVar(name, constraint, ...): constraints must be types."
///         self.__constraints__ = tuple(_type_check(t, msg) for t in constraints)
///         def_mod = _caller()
///         if def_mod != 'typing':
///             self.__module__ = def_mod
///
///     def __typing_subst__(self, arg):
///         msg = "Parameters to generic types must be types."
///         arg = _type_check(arg, msg, is_argument=True)
///         if ((isinstance(arg, _GenericAlias) and arg.__origin__ is Unpack) or
///             (isinstance(arg, GenericAlias) and getattr(arg, '__unpacked__', False))):
///             raise TypeError(f"{arg} is not valid as type argument")
///         return arg
/// ```
final class TypeVar extends PythonClass {
  factory TypeVar({
    List<Object?> constraints = const <Object?>[],
    required Object? name,
    Object? bound,
    Object? $covariant = false,
    Object? contravariant = false,
  }) =>
      PythonFfiDart.instance.importClass(
        "typing",
        "TypeVar",
        TypeVar.from,
        <Object?>[
          name,
          ...constraints,
        ],
        <String, Object?>{
          "bound": bound,
          "covariant": $covariant,
          "contravariant": contravariant,
        },
      );

  TypeVar.from(super.pythonClass) : super.from();
}

/// ## VisitError
///
/// ### python docstring
///
/// VisitError is raised when visitors are interrupted by an exception
///
/// It provides the following attributes for inspection:
///
/// Parameters:
///     rule: the name of the visit rule that failed
///     obj: the tree-node or token that was being processed
///     orig_exc: the exception that cause it to fail
///
/// Note: These parameters are available as attributes
///
/// ### python source
/// ```py
/// class VisitError(LarkError):
///     """VisitError is raised when visitors are interrupted by an exception
///
///     It provides the following attributes for inspection:
///
///     Parameters:
///         rule: the name of the visit rule that failed
///         obj: the tree-node or token that was being processed
///         orig_exc: the exception that cause it to fail
///
///     Note: These parameters are available as attributes
///     """
///
///     obj: 'Union[Tree, Token]'
///     orig_exc: Exception
///
///     def __init__(self, rule, obj, orig_exc):
///         message = 'Error trying to process rule "%s":\n\n%s' % (rule, orig_exc)
///         super(VisitError, self).__init__(message)
///
///         self.rule = rule
///         self.obj = obj
///         self.orig_exc = orig_exc
/// ```
final class VisitError extends PythonClass {
  factory VisitError({
    required Object? rule,
    required Object? obj,
    required Object? orig_exc,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.exceptions",
        "VisitError",
        VisitError.from,
        <Object?>[
          rule,
          obj,
          orig_exc,
        ],
        <String, Object?>{},
      );

  VisitError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);

  /// ## rule (getter)
  Object? get rule => getAttribute("rule");

  /// ## rule (setter)
  set rule(Object? rule) => setAttribute("rule", rule);

  /// ## obj (getter)
  Object? get obj => getAttribute("obj");

  /// ## obj (setter)
  set obj(Object? obj) => setAttribute("obj", obj);

  /// ## orig_exc (getter)
  Object? get orig_exc => getAttribute("orig_exc");

  /// ## orig_exc (setter)
  set orig_exc(Object? orig_exc) => setAttribute("orig_exc", orig_exc);
}

/// ## NonTerminal
///
/// ### python docstring
///
/// Safe-ish serialization interface that doesn't rely on Pickle
///
/// Attributes:
///     __serialize_fields__ (List[str]): Fields (aka attributes) to serialize.
///     __serialize_namespace__ (list): List of classes that deserialization is allowed to instantiate.
///                                     Should include all field types that aren't builtin types.
///
/// ### python source
/// ```py
/// class NonTerminal(Symbol):
///     __serialize_fields__ = 'name',
///
///     is_term: ClassVar[bool] = False
/// ```
final class NonTerminal extends PythonClass {
  factory NonTerminal({
    required Object? name,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.grammar",
        "NonTerminal",
        NonTerminal.from,
        <Object?>[
          name,
        ],
        <String, Object?>{},
      );

  NonTerminal.from(super.pythonClass) : super.from();

  /// ## memo_serialize
  ///
  /// ### python source
  /// ```py
  /// def memo_serialize(self, types_to_memoize: List) -> Any:
  ///         memo = SerializeMemoizer(types_to_memoize)
  ///         return self.serialize(memo), memo.serialize()
  /// ```
  Object? memo_serialize({
    required Object? types_to_memoize,
  }) =>
      getFunction("memo_serialize").call(
        <Object?>[
          types_to_memoize,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## renamed
  ///
  /// ### python source
  /// ```py
  /// def renamed(self, f):
  ///         return type(self)(f(self.name))
  /// ```
  Object? renamed({
    required Object? f,
  }) =>
      getFunction("renamed").call(
        <Object?>[
          f,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## serialize
  ///
  /// ### python source
  /// ```py
  /// def serialize(self, memo = None) -> Dict[str, Any]:
  ///         if memo and memo.in_types(self):
  ///             return {'@': memo.memoized.get(self)}
  ///
  ///         fields = getattr(self, '__serialize_fields__')
  ///         res = {f: _serialize(getattr(self, f), memo) for f in fields}
  ///         res['__type__'] = type(self).__name__
  ///         if hasattr(self, '_serialize'):
  ///             self._serialize(res, memo)  # type: ignore[attr-defined]
  ///         return res
  /// ```
  Object? serialize({
    Object? memo,
  }) =>
      getFunction("serialize").call(
        <Object?>[
          memo,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## fullrepr (getter)
  Object? get fullrepr => getAttribute("fullrepr");

  /// ## fullrepr (setter)
  set fullrepr(Object? fullrepr) => setAttribute("fullrepr", fullrepr);

  /// ## deserialize (getter)
  Object? get deserialize => getAttribute("deserialize");

  /// ## deserialize (setter)
  set deserialize(Object? deserialize) =>
      setAttribute("deserialize", deserialize);

  /// ## is_term (getter)
  Object? get is_term => getAttribute("is_term");

  /// ## is_term (setter)
  set is_term(Object? is_term) => setAttribute("is_term", is_term);

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);
}

/// ## Rule
///
/// ### python docstring
///
/// origin : a symbol
/// expansion : a list of symbols
/// order : index of this expansion amongst all rules of the same name
///
/// ### python source
/// ```py
/// class Rule(Serialize):
///     """
///         origin : a symbol
///         expansion : a list of symbols
///         order : index of this expansion amongst all rules of the same name
///     """
///     __slots__ = ('origin', 'expansion', 'alias', 'options', 'order', '_hash')
///
///     __serialize_fields__ = 'origin', 'expansion', 'order', 'alias', 'options'
///     __serialize_namespace__ = Terminal, NonTerminal, RuleOptions
///
///     def __init__(self, origin, expansion, order=0, alias=None, options=None):
///         self.origin = origin
///         self.expansion = expansion
///         self.alias = alias
///         self.order = order
///         self.options = options or RuleOptions()
///         self._hash = hash((self.origin, tuple(self.expansion)))
///
///     def _deserialize(self):
///         self._hash = hash((self.origin, tuple(self.expansion)))
///
///     def __str__(self):
///         return '<%s : %s>' % (self.origin.name, ' '.join(x.name for x in self.expansion))
///
///     def __repr__(self):
///         return 'Rule(%r, %r, %r, %r)' % (self.origin, self.expansion, self.alias, self.options)
///
///     def __hash__(self):
///         return self._hash
///
///     def __eq__(self, other):
///         if not isinstance(other, Rule):
///             return False
///         return self.origin == other.origin and self.expansion == other.expansion
/// ```
final class Rule extends PythonClass {
  factory Rule({
    required Object? origin,
    required Object? expansion,
    Object? order = 0,
    Object? alias,
    Object? options,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.grammar",
        "Rule",
        Rule.from,
        <Object?>[
          origin,
          expansion,
          order,
          alias,
          options,
        ],
        <String, Object?>{},
      );

  Rule.from(super.pythonClass) : super.from();

  /// ## memo_serialize
  ///
  /// ### python source
  /// ```py
  /// def memo_serialize(self, types_to_memoize: List) -> Any:
  ///         memo = SerializeMemoizer(types_to_memoize)
  ///         return self.serialize(memo), memo.serialize()
  /// ```
  Object? memo_serialize({
    required Object? types_to_memoize,
  }) =>
      getFunction("memo_serialize").call(
        <Object?>[
          types_to_memoize,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## serialize
  ///
  /// ### python source
  /// ```py
  /// def serialize(self, memo = None) -> Dict[str, Any]:
  ///         if memo and memo.in_types(self):
  ///             return {'@': memo.memoized.get(self)}
  ///
  ///         fields = getattr(self, '__serialize_fields__')
  ///         res = {f: _serialize(getattr(self, f), memo) for f in fields}
  ///         res['__type__'] = type(self).__name__
  ///         if hasattr(self, '_serialize'):
  ///             self._serialize(res, memo)  # type: ignore[attr-defined]
  ///         return res
  /// ```
  Object? serialize({
    Object? memo,
  }) =>
      getFunction("serialize").call(
        <Object?>[
          memo,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## deserialize (getter)
  Object? get deserialize => getAttribute("deserialize");

  /// ## deserialize (setter)
  set deserialize(Object? deserialize) =>
      setAttribute("deserialize", deserialize);

  /// ## alias (getter)
  Object? get alias => getAttribute("alias");

  /// ## alias (setter)
  set alias(Object? alias) => setAttribute("alias", alias);

  /// ## expansion (getter)
  Object? get expansion => getAttribute("expansion");

  /// ## expansion (setter)
  set expansion(Object? expansion) => setAttribute("expansion", expansion);

  /// ## options (getter)
  Object? get options => getAttribute("options");

  /// ## options (setter)
  set options(Object? options) => setAttribute("options", options);

  /// ## order (getter)
  Object? get order => getAttribute("order");

  /// ## order (setter)
  set order(Object? order) => setAttribute("order", order);

  /// ## origin (getter)
  Object? get origin => getAttribute("origin");

  /// ## origin (setter)
  set origin(Object? origin) => setAttribute("origin", origin);
}

/// ## RuleOptions
///
/// ### python docstring
///
/// Safe-ish serialization interface that doesn't rely on Pickle
///
/// Attributes:
///     __serialize_fields__ (List[str]): Fields (aka attributes) to serialize.
///     __serialize_namespace__ (list): List of classes that deserialization is allowed to instantiate.
///                                     Should include all field types that aren't builtin types.
///
/// ### python source
/// ```py
/// class RuleOptions(Serialize):
///     __serialize_fields__ = 'keep_all_tokens', 'expand1', 'priority', 'template_source', 'empty_indices'
///
///     keep_all_tokens: bool
///     expand1: bool
///     priority: Optional[int]
///     template_source: Optional[str]
///     empty_indices: Tuple[bool, ...]
///
///     def __init__(self, keep_all_tokens: bool=False, expand1: bool=False, priority: Optional[int]=None, template_source: Optional[str]=None, empty_indices: Tuple[bool, ...]=()) -> None:
///         self.keep_all_tokens = keep_all_tokens
///         self.expand1 = expand1
///         self.priority = priority
///         self.template_source = template_source
///         self.empty_indices = empty_indices
///
///     def __repr__(self):
///         return 'RuleOptions(%r, %r, %r, %r)' % (
///             self.keep_all_tokens,
///             self.expand1,
///             self.priority,
///             self.template_source
///         )
/// ```
final class RuleOptions extends PythonClass {
  factory RuleOptions({
    Object? keep_all_tokens = false,
    Object? expand1 = false,
    Object? priority,
    Object? template_source,
    Object? empty_indices = const [],
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.grammar",
        "RuleOptions",
        RuleOptions.from,
        <Object?>[
          keep_all_tokens,
          expand1,
          priority,
          template_source,
          empty_indices,
        ],
        <String, Object?>{},
      );

  RuleOptions.from(super.pythonClass) : super.from();

  /// ## memo_serialize
  ///
  /// ### python source
  /// ```py
  /// def memo_serialize(self, types_to_memoize: List) -> Any:
  ///         memo = SerializeMemoizer(types_to_memoize)
  ///         return self.serialize(memo), memo.serialize()
  /// ```
  Object? memo_serialize({
    required Object? types_to_memoize,
  }) =>
      getFunction("memo_serialize").call(
        <Object?>[
          types_to_memoize,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## serialize
  ///
  /// ### python source
  /// ```py
  /// def serialize(self, memo = None) -> Dict[str, Any]:
  ///         if memo and memo.in_types(self):
  ///             return {'@': memo.memoized.get(self)}
  ///
  ///         fields = getattr(self, '__serialize_fields__')
  ///         res = {f: _serialize(getattr(self, f), memo) for f in fields}
  ///         res['__type__'] = type(self).__name__
  ///         if hasattr(self, '_serialize'):
  ///             self._serialize(res, memo)  # type: ignore[attr-defined]
  ///         return res
  /// ```
  Object? serialize({
    Object? memo,
  }) =>
      getFunction("serialize").call(
        <Object?>[
          memo,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## deserialize (getter)
  Object? get deserialize => getAttribute("deserialize");

  /// ## deserialize (setter)
  set deserialize(Object? deserialize) =>
      setAttribute("deserialize", deserialize);

  /// ## keep_all_tokens (getter)
  Object? get keep_all_tokens => getAttribute("keep_all_tokens");

  /// ## keep_all_tokens (setter)
  set keep_all_tokens(Object? keep_all_tokens) =>
      setAttribute("keep_all_tokens", keep_all_tokens);

  /// ## expand1 (getter)
  Object? get expand1 => getAttribute("expand1");

  /// ## expand1 (setter)
  set expand1(Object? expand1) => setAttribute("expand1", expand1);

  /// ## priority (getter)
  Object? get priority => getAttribute("priority");

  /// ## priority (setter)
  set priority(Object? priority) => setAttribute("priority", priority);

  /// ## template_source (getter)
  Object? get template_source => getAttribute("template_source");

  /// ## template_source (setter)
  set template_source(Object? template_source) =>
      setAttribute("template_source", template_source);

  /// ## empty_indices (getter)
  Object? get empty_indices => getAttribute("empty_indices");

  /// ## empty_indices (setter)
  set empty_indices(Object? empty_indices) =>
      setAttribute("empty_indices", empty_indices);
}

/// ## Symbol
///
/// ### python docstring
///
/// Safe-ish serialization interface that doesn't rely on Pickle
///
/// Attributes:
///     __serialize_fields__ (List[str]): Fields (aka attributes) to serialize.
///     __serialize_namespace__ (list): List of classes that deserialization is allowed to instantiate.
///                                     Should include all field types that aren't builtin types.
///
/// ### python source
/// ```py
/// class Symbol(Serialize):
///     __slots__ = ('name',)
///
///     name: str
///     is_term: ClassVar[bool] = NotImplemented
///
///     def __init__(self, name: str) -> None:
///         self.name = name
///
///     def __eq__(self, other):
///         assert isinstance(other, Symbol), other
///         return self.is_term == other.is_term and self.name == other.name
///
///     def __ne__(self, other):
///         return not (self == other)
///
///     def __hash__(self):
///         return hash(self.name)
///
///     def __repr__(self):
///         return '%s(%r)' % (type(self).__name__, self.name)
///
///     fullrepr = property(__repr__)
///
///     def renamed(self, f):
///         return type(self)(f(self.name))
/// ```
final class Symbol extends PythonClass {
  factory Symbol({
    required Object? name,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.grammar",
        "Symbol",
        Symbol.from,
        <Object?>[
          name,
        ],
        <String, Object?>{},
      );

  Symbol.from(super.pythonClass) : super.from();

  /// ## memo_serialize
  ///
  /// ### python source
  /// ```py
  /// def memo_serialize(self, types_to_memoize: List) -> Any:
  ///         memo = SerializeMemoizer(types_to_memoize)
  ///         return self.serialize(memo), memo.serialize()
  /// ```
  Object? memo_serialize({
    required Object? types_to_memoize,
  }) =>
      getFunction("memo_serialize").call(
        <Object?>[
          types_to_memoize,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## renamed
  ///
  /// ### python source
  /// ```py
  /// def renamed(self, f):
  ///         return type(self)(f(self.name))
  /// ```
  Object? renamed({
    required Object? f,
  }) =>
      getFunction("renamed").call(
        <Object?>[
          f,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## serialize
  ///
  /// ### python source
  /// ```py
  /// def serialize(self, memo = None) -> Dict[str, Any]:
  ///         if memo and memo.in_types(self):
  ///             return {'@': memo.memoized.get(self)}
  ///
  ///         fields = getattr(self, '__serialize_fields__')
  ///         res = {f: _serialize(getattr(self, f), memo) for f in fields}
  ///         res['__type__'] = type(self).__name__
  ///         if hasattr(self, '_serialize'):
  ///             self._serialize(res, memo)  # type: ignore[attr-defined]
  ///         return res
  /// ```
  Object? serialize({
    Object? memo,
  }) =>
      getFunction("serialize").call(
        <Object?>[
          memo,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## fullrepr (getter)
  Object? get fullrepr => getAttribute("fullrepr");

  /// ## fullrepr (setter)
  set fullrepr(Object? fullrepr) => setAttribute("fullrepr", fullrepr);

  /// ## is_term (getter)
  Object? get is_term => getAttribute("is_term");

  /// ## is_term (setter)
  set is_term(Object? is_term) => setAttribute("is_term", is_term);

  /// ## deserialize (getter)
  Object? get deserialize => getAttribute("deserialize");

  /// ## deserialize (setter)
  set deserialize(Object? deserialize) =>
      setAttribute("deserialize", deserialize);

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);
}

/// ## Terminal
///
/// ### python docstring
///
/// Safe-ish serialization interface that doesn't rely on Pickle
///
/// Attributes:
///     __serialize_fields__ (List[str]): Fields (aka attributes) to serialize.
///     __serialize_namespace__ (list): List of classes that deserialization is allowed to instantiate.
///                                     Should include all field types that aren't builtin types.
///
/// ### python source
/// ```py
/// class Terminal(Symbol):
///     __serialize_fields__ = 'name', 'filter_out'
///
///     is_term: ClassVar[bool] = True
///
///     def __init__(self, name, filter_out=False):
///         self.name = name
///         self.filter_out = filter_out
///
///     @property
///     def fullrepr(self):
///         return '%s(%r, %r)' % (type(self).__name__, self.name, self.filter_out)
///
///     def renamed(self, f):
///         return type(self)(f(self.name), self.filter_out)
/// ```
final class Terminal extends PythonClass {
  factory Terminal({
    required Object? name,
    Object? filter_out = false,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.grammar",
        "Terminal",
        Terminal.from,
        <Object?>[
          name,
          filter_out,
        ],
        <String, Object?>{},
      );

  Terminal.from(super.pythonClass) : super.from();

  /// ## memo_serialize
  ///
  /// ### python source
  /// ```py
  /// def memo_serialize(self, types_to_memoize: List) -> Any:
  ///         memo = SerializeMemoizer(types_to_memoize)
  ///         return self.serialize(memo), memo.serialize()
  /// ```
  Object? memo_serialize({
    required Object? types_to_memoize,
  }) =>
      getFunction("memo_serialize").call(
        <Object?>[
          types_to_memoize,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## renamed
  ///
  /// ### python source
  /// ```py
  /// def renamed(self, f):
  ///         return type(self)(f(self.name), self.filter_out)
  /// ```
  Object? renamed({
    required Object? f,
  }) =>
      getFunction("renamed").call(
        <Object?>[
          f,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## serialize
  ///
  /// ### python source
  /// ```py
  /// def serialize(self, memo = None) -> Dict[str, Any]:
  ///         if memo and memo.in_types(self):
  ///             return {'@': memo.memoized.get(self)}
  ///
  ///         fields = getattr(self, '__serialize_fields__')
  ///         res = {f: _serialize(getattr(self, f), memo) for f in fields}
  ///         res['__type__'] = type(self).__name__
  ///         if hasattr(self, '_serialize'):
  ///             self._serialize(res, memo)  # type: ignore[attr-defined]
  ///         return res
  /// ```
  Object? serialize({
    Object? memo,
  }) =>
      getFunction("serialize").call(
        <Object?>[
          memo,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## fullrepr (getter)
  Object? get fullrepr => getAttribute("fullrepr");

  /// ## fullrepr (setter)
  set fullrepr(Object? fullrepr) => setAttribute("fullrepr", fullrepr);

  /// ## deserialize (getter)
  Object? get deserialize => getAttribute("deserialize");

  /// ## deserialize (setter)
  set deserialize(Object? deserialize) =>
      setAttribute("deserialize", deserialize);

  /// ## is_term (getter)
  Object? get is_term => getAttribute("is_term");

  /// ## is_term (setter)
  set is_term(Object? is_term) => setAttribute("is_term", is_term);

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);

  /// ## filter_out (getter)
  Object? get filter_out => getAttribute("filter_out");

  /// ## filter_out (setter)
  set filter_out(Object? filter_out) => setAttribute("filter_out", filter_out);
}

/// ## ABC
///
/// ### python docstring
///
/// Helper class that provides a standard way to create an ABC using
/// inheritance.
///
/// ### python source
/// ```py
/// class ABC(metaclass=ABCMeta):
///     """Helper class that provides a standard way to create an ABC using
///     inheritance.
///     """
///     __slots__ = ()
/// ```
final class ABC extends PythonClass {
  factory ABC() => PythonFfiDart.instance.importClass(
        "abc",
        "ABC",
        ABC.from,
        <Object?>[],
      );

  ABC.from(super.pythonClass) : super.from();
}

/// ## BasicLexer
///
/// ### python docstring
///
/// Lexer interface
///
/// Method Signatures:
///     lex(self, lexer_state, parser_state) -> Iterator[Token]
///
/// ### python source
/// ```py
/// class BasicLexer(Lexer):
///
///     terminals: Collection[TerminalDef]
///     ignore_types: FrozenSet[str]
///     newline_types: FrozenSet[str]
///     user_callbacks: Dict[str, _Callback]
///     callback: Dict[str, _Callback]
///     re: ModuleType
///
///     def __init__(self, conf: 'LexerConf') -> None:
///         terminals = list(conf.terminals)
///         assert all(isinstance(t, TerminalDef) for t in terminals), terminals
///
///         self.re = conf.re_module
///
///         if not conf.skip_validation:
///             # Sanitization
///             for t in terminals:
///                 try:
///                     self.re.compile(t.pattern.to_regexp(), conf.g_regex_flags)
///                 except self.re.error:
///                     raise LexError("Cannot compile token %s: %s" % (t.name, t.pattern))
///
///                 if t.pattern.min_width == 0:
///                     raise LexError("Lexer does not allow zero-width terminals. (%s: %s)" % (t.name, t.pattern))
///
///             if not (set(conf.ignore) <= {t.name for t in terminals}):
///                 raise LexError("Ignore terminals are not defined: %s" % (set(conf.ignore) - {t.name for t in terminals}))
///
///         # Init
///         self.newline_types = frozenset(t.name for t in terminals if _regexp_has_newline(t.pattern.to_regexp()))
///         self.ignore_types = frozenset(conf.ignore)
///
///         terminals.sort(key=lambda x: (-x.priority, -x.pattern.max_width, -len(x.pattern.value), x.name))
///         self.terminals = terminals
///         self.user_callbacks = conf.callbacks
///         self.g_regex_flags = conf.g_regex_flags
///         self.use_bytes = conf.use_bytes
///         self.terminals_by_name = conf.terminals_by_name
///
///         self._scanner = None
///
///     def _build_scanner(self):
///         terminals, self.callback = _create_unless(self.terminals, self.g_regex_flags, self.re, self.use_bytes)
///         assert all(self.callback.values())
///
///         for type_, f in self.user_callbacks.items():
///             if type_ in self.callback:
///                 # Already a callback there, probably UnlessCallback
///                 self.callback[type_] = CallChain(self.callback[type_], f, lambda t: t.type == type_)
///             else:
///                 self.callback[type_] = f
///
///         self._scanner = Scanner(terminals, self.g_regex_flags, self.re, self.use_bytes)
///
///     @property
///     def scanner(self):
///         if self._scanner is None:
///             self._build_scanner()
///         return self._scanner
///
///     def match(self, text, pos):
///         return self.scanner.match(text, pos)
///
///     def lex(self, state: LexerState, parser_state: Any) -> Iterator[Token]:
///         with suppress(EOFError):
///             while True:
///                 yield self.next_token(state, parser_state)
///
///     def next_token(self, lex_state: LexerState, parser_state: Any=None) -> Token:
///         line_ctr = lex_state.line_ctr
///         while line_ctr.char_pos < len(lex_state.text):
///             res = self.match(lex_state.text, line_ctr.char_pos)
///             if not res:
///                 allowed = self.scanner.allowed_types - self.ignore_types
///                 if not allowed:
///                     allowed = {"<END-OF-FILE>"}
///                 raise UnexpectedCharacters(lex_state.text, line_ctr.char_pos, line_ctr.line, line_ctr.column,
///                                            allowed=allowed, token_history=lex_state.last_token and [lex_state.last_token],
///                                            state=parser_state, terminals_by_name=self.terminals_by_name)
///
///             value, type_ = res
///
///             if type_ not in self.ignore_types:
///                 t = Token(type_, value, line_ctr.char_pos, line_ctr.line, line_ctr.column)
///                 line_ctr.feed(value, type_ in self.newline_types)
///                 t.end_line = line_ctr.line
///                 t.end_column = line_ctr.column
///                 t.end_pos = line_ctr.char_pos
///                 if t.type in self.callback:
///                     t = self.callback[t.type](t)
///                     if not isinstance(t, Token):
///                         raise LexError("Callbacks must return a token (returned %r)" % t)
///                 lex_state.last_token = t
///                 return t
///             else:
///                 if type_ in self.callback:
///                     t2 = Token(type_, value, line_ctr.char_pos, line_ctr.line, line_ctr.column)
///                     self.callback[type_](t2)
///                 line_ctr.feed(value, type_ in self.newline_types)
///
///         # EOF
///         raise EOFError(self)
/// ```
final class BasicLexer extends PythonClass {
  factory BasicLexer({
    required Object? conf,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.lexer",
        "BasicLexer",
        BasicLexer.from,
        <Object?>[
          conf,
        ],
        <String, Object?>{},
      );

  BasicLexer.from(super.pythonClass) : super.from();

  /// ## lex
  ///
  /// ### python source
  /// ```py
  /// def lex(self, state: LexerState, parser_state: Any) -> Iterator[Token]:
  ///         with suppress(EOFError):
  ///             while True:
  ///                 yield self.next_token(state, parser_state)
  /// ```
  Object? lex({
    required Object? state,
    required Object? parser_state,
  }) =>
      getFunction("lex").call(
        <Object?>[
          state,
          parser_state,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## make_lexer_state
  ///
  /// ### python docstring
  ///
  /// Deprecated
  ///
  /// ### python source
  /// ```py
  /// def make_lexer_state(self, text):
  ///         "Deprecated"
  ///         return LexerState(text)
  /// ```
  Object? make_lexer_state({
    required Object? text,
  }) =>
      getFunction("make_lexer_state").call(
        <Object?>[
          text,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## match
  ///
  /// ### python source
  /// ```py
  /// def match(self, text, pos):
  ///         return self.scanner.match(text, pos)
  /// ```
  Object? match({
    required Object? text,
    required Object? pos,
  }) =>
      getFunction("match").call(
        <Object?>[
          text,
          pos,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## next_token
  ///
  /// ### python source
  /// ```py
  /// def next_token(self, lex_state: LexerState, parser_state: Any=None) -> Token:
  ///         line_ctr = lex_state.line_ctr
  ///         while line_ctr.char_pos < len(lex_state.text):
  ///             res = self.match(lex_state.text, line_ctr.char_pos)
  ///             if not res:
  ///                 allowed = self.scanner.allowed_types - self.ignore_types
  ///                 if not allowed:
  ///                     allowed = {"<END-OF-FILE>"}
  ///                 raise UnexpectedCharacters(lex_state.text, line_ctr.char_pos, line_ctr.line, line_ctr.column,
  ///                                            allowed=allowed, token_history=lex_state.last_token and [lex_state.last_token],
  ///                                            state=parser_state, terminals_by_name=self.terminals_by_name)
  ///
  ///             value, type_ = res
  ///
  ///             if type_ not in self.ignore_types:
  ///                 t = Token(type_, value, line_ctr.char_pos, line_ctr.line, line_ctr.column)
  ///                 line_ctr.feed(value, type_ in self.newline_types)
  ///                 t.end_line = line_ctr.line
  ///                 t.end_column = line_ctr.column
  ///                 t.end_pos = line_ctr.char_pos
  ///                 if t.type in self.callback:
  ///                     t = self.callback[t.type](t)
  ///                     if not isinstance(t, Token):
  ///                         raise LexError("Callbacks must return a token (returned %r)" % t)
  ///                 lex_state.last_token = t
  ///                 return t
  ///             else:
  ///                 if type_ in self.callback:
  ///                     t2 = Token(type_, value, line_ctr.char_pos, line_ctr.line, line_ctr.column)
  ///                     self.callback[type_](t2)
  ///                 line_ctr.feed(value, type_ in self.newline_types)
  ///
  ///         # EOF
  ///         raise EOFError(self)
  /// ```
  Object? next_token({
    required Object? lex_state,
    Object? parser_state,
  }) =>
      getFunction("next_token").call(
        <Object?>[
          lex_state,
          parser_state,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## scanner (getter)
  Object? get scanner => getAttribute("scanner");

  /// ## scanner (setter)
  set scanner(Object? scanner) => setAttribute("scanner", scanner);

  /// ## terminals (getter)
  Object? get terminals => getAttribute("terminals");

  /// ## terminals (setter)
  set terminals(Object? terminals) => setAttribute("terminals", terminals);

  /// ## re (getter)
  Object? get re => getAttribute("re");

  /// ## re (setter)
  set re(Object? re) => setAttribute("re", re);

  /// ## g_regex_flags (getter)
  Object? get g_regex_flags => getAttribute("g_regex_flags");

  /// ## g_regex_flags (setter)
  set g_regex_flags(Object? g_regex_flags) =>
      setAttribute("g_regex_flags", g_regex_flags);

  /// ## newline_types (getter)
  Object? get newline_types => getAttribute("newline_types");

  /// ## newline_types (setter)
  set newline_types(Object? newline_types) =>
      setAttribute("newline_types", newline_types);

  /// ## ignore_types (getter)
  Object? get ignore_types => getAttribute("ignore_types");

  /// ## ignore_types (setter)
  set ignore_types(Object? ignore_types) =>
      setAttribute("ignore_types", ignore_types);

  /// ## user_callbacks (getter)
  Object? get user_callbacks => getAttribute("user_callbacks");

  /// ## user_callbacks (setter)
  set user_callbacks(Object? user_callbacks) =>
      setAttribute("user_callbacks", user_callbacks);

  /// ## use_bytes (getter)
  Object? get use_bytes => getAttribute("use_bytes");

  /// ## use_bytes (setter)
  set use_bytes(Object? use_bytes) => setAttribute("use_bytes", use_bytes);

  /// ## terminals_by_name (getter)
  Object? get terminals_by_name => getAttribute("terminals_by_name");

  /// ## terminals_by_name (setter)
  set terminals_by_name(Object? terminals_by_name) =>
      setAttribute("terminals_by_name", terminals_by_name);
}

/// ## FS
///
/// ### python source
/// ```py
/// class FS:
///     exists = staticmethod(os.path.exists)
///
///     @staticmethod
///     def open(name, mode="r", **kwargs):
///         if _has_atomicwrites and "w" in mode:
///             return atomicwrites.atomic_write(name, mode=mode, overwrite=True, **kwargs)
///         else:
///             return open(name, mode, **kwargs)
/// ```
final class FS extends PythonClass {
  factory FS() => PythonFfiDart.instance.importClass(
        "lark.utils",
        "FS",
        FS.from,
        <Object?>[],
      );

  FS.from(super.pythonClass) : super.from();

  /// ## exists
  ///
  /// ### python docstring
  ///
  /// Test whether a path exists.  Returns False for broken symbolic links
  Object? exists() => getFunction("exists").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## open
  ///
  /// ### python source
  /// ```py
  /// @staticmethod
  ///     def open(name, mode="r", **kwargs):
  ///         if _has_atomicwrites and "w" in mode:
  ///             return atomicwrites.atomic_write(name, mode=mode, overwrite=True, **kwargs)
  ///         else:
  ///             return open(name, mode, **kwargs)
  /// ```
  Object? open({
    Object? mode = "r",
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("open").call(
        <Object?>[
          mode,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );
}

/// ## FromPackageLoader
///
/// ### python docstring
///
/// Provides a simple way of creating custom import loaders that load from packages via ``pkgutil.get_data`` instead of using `open`.
/// This allows them to be compatible even from within zip files.
///
/// Relative imports are handled, so you can just freely use them.
///
/// pkg_name: The name of the package. You can probably provide `__name__` most of the time
/// search_paths: All the path that will be search on absolute imports.
///
/// ### python source
/// ```py
/// class FromPackageLoader:
///     """
///     Provides a simple way of creating custom import loaders that load from packages via ``pkgutil.get_data`` instead of using `open`.
///     This allows them to be compatible even from within zip files.
///
///     Relative imports are handled, so you can just freely use them.
///
///     pkg_name: The name of the package. You can probably provide `__name__` most of the time
///     search_paths: All the path that will be search on absolute imports.
///     """
///
///     pkg_name: str
///     search_paths: Sequence[str]
///
///     def __init__(self, pkg_name: str, search_paths: Sequence[str]=("", )) -> None:
///         self.pkg_name = pkg_name
///         self.search_paths = search_paths
///
///     def __repr__(self):
///         return "%s(%r, %r)" % (type(self).__name__, self.pkg_name, self.search_paths)
///
///     def __call__(self, base_path: Union[None, str, PackageResource], grammar_path: str) -> Tuple[PackageResource, str]:
///         if base_path is None:
///             to_try = self.search_paths
///         else:
///             # Check whether or not the importing grammar was loaded by this module.
///             if not isinstance(base_path, PackageResource) or base_path.pkg_name != self.pkg_name:
///                 # Technically false, but FileNotFound doesn't exist in python2.7, and this message should never reach the end user anyway
///                 raise IOError()
///             to_try = [base_path.path]
///
///         err = None
///         for path in to_try:
///             full_path = os.path.join(path, grammar_path)
///             try:
///                 text: Optional[bytes] = pkgutil.get_data(self.pkg_name, full_path)
///             except IOError as e:
///                 err = e
///                 continue
///             else:
///                 return PackageResource(self.pkg_name, full_path), (text.decode() if text else '')
///
///         raise IOError('Cannot find grammar in given paths') from err
/// ```
final class FromPackageLoader extends PythonClass {
  factory FromPackageLoader({
    required Object? pkg_name,
    Object? search_paths = const [""],
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.load_grammar",
        "FromPackageLoader",
        FromPackageLoader.from,
        <Object?>[
          pkg_name,
          search_paths,
        ],
        <String, Object?>{},
      );

  FromPackageLoader.from(super.pythonClass) : super.from();

  /// ## pkg_name (getter)
  Object? get pkg_name => getAttribute("pkg_name");

  /// ## pkg_name (setter)
  set pkg_name(Object? pkg_name) => setAttribute("pkg_name", pkg_name);

  /// ## search_paths (getter)
  Object? get search_paths => getAttribute("search_paths");

  /// ## search_paths (setter)
  set search_paths(Object? search_paths) =>
      setAttribute("search_paths", search_paths);
}

/// ## Grammar
///
/// ### python source
/// ```py
/// class Grammar:
///
///     term_defs: List[Tuple[str, Tuple[Tree, int]]]
///     rule_defs: List[Tuple[str, Tuple[str, ...], Tree, RuleOptions]]
///     ignore: List[str]
///
///     def __init__(self, rule_defs: List[Tuple[str, Tuple[str, ...], Tree, RuleOptions]], term_defs: List[Tuple[str, Tuple[Tree, int]]], ignore: List[str]) -> None:
///         self.term_defs = term_defs
///         self.rule_defs = rule_defs
///         self.ignore = ignore
///
///     def compile(self, start, terminals_to_keep):
///         # We change the trees in-place (to support huge grammars)
///         # So deepcopy allows calling compile more than once.
///         term_defs = [(n, (nr_deepcopy_tree(t), p)) for n, (t, p) in self.term_defs]
///         rule_defs = [(n, p, nr_deepcopy_tree(t), o) for n, p, t, o in self.rule_defs]
///
///         # ===================
///         #  Compile Terminals
///         # ===================
///
///         # Convert terminal-trees to strings/regexps
///
///         for name, (term_tree, priority) in term_defs:
///             if term_tree is None:  # Terminal added through %declare
///                 continue
///             expansions = list(term_tree.find_data('expansion'))
///             if len(expansions) == 1 and not expansions[0].children:
///                 raise GrammarError("Terminals cannot be empty (%s)" % name)
///
///         transformer = PrepareLiterals() * TerminalTreeToPattern()
///         terminals = [TerminalDef(name, transformer.transform(term_tree), priority)
///                      for name, (term_tree, priority) in term_defs if term_tree]
///
///         # =================
///         #  Compile Rules
///         # =================
///
///         # 1. Pre-process terminals
///         anon_tokens_transf = PrepareAnonTerminals(terminals)
///         transformer = PrepareLiterals() * ValidateSymbols() * anon_tokens_transf  # Adds to terminals
///
///         # 2. Inline Templates
///
///         transformer *= ApplyTemplates(rule_defs)
///
///         # 3. Convert EBNF to BNF (and apply step 1 & 2)
///         ebnf_to_bnf = EBNF_to_BNF()
///         rules = []
///         i = 0
///         while i < len(rule_defs):  # We have to do it like this because rule_defs might grow due to templates
///             name, params, rule_tree, options = rule_defs[i]
///             i += 1
///             if len(params) != 0:  # Dont transform templates
///                 continue
///             rule_options = RuleOptions(keep_all_tokens=True) if options and options.keep_all_tokens else None
///             ebnf_to_bnf.rule_options = rule_options
///             ebnf_to_bnf.prefix = name
///             anon_tokens_transf.rule_options = rule_options
///             tree = transformer.transform(rule_tree)
///             res = ebnf_to_bnf.transform(tree)
///             rules.append((name, res, options))
///         rules += ebnf_to_bnf.new_rules
///
///         assert len(rules) == len({name for name, _t, _o in rules}), "Whoops, name collision"
///
///         # 4. Compile tree to Rule objects
///         rule_tree_to_text = RuleTreeToText()
///
///         simplify_rule = SimplifyRule_Visitor()
///         compiled_rules = []
///         for rule_content in rules:
///             name, tree, options = rule_content
///             simplify_rule.visit(tree)
///             expansions = rule_tree_to_text.transform(tree)
///
///             for i, (expansion, alias) in enumerate(expansions):
///                 if alias and name.startswith('_'):
///                     raise GrammarError("Rule %s is marked for expansion (it starts with an underscore) and isn't allowed to have aliases (alias=%s)"% (name, alias))
///
///                 empty_indices = [x==_EMPTY for x in expansion]
///                 if any(empty_indices):
///                     exp_options = copy(options) or RuleOptions()
///                     exp_options.empty_indices = empty_indices
///                     expansion = [x for x in expansion if x!=_EMPTY]
///                 else:
///                     exp_options = options
///
///                 for sym in expansion:
///                     assert isinstance(sym, Symbol)
///                     if sym.is_term and exp_options and exp_options.keep_all_tokens:
///                         sym.filter_out = False
///                 rule = Rule(NonTerminal(name), expansion, i, alias, exp_options)
///                 compiled_rules.append(rule)
///
///         # Remove duplicates of empty rules, throw error for non-empty duplicates
///         if len(set(compiled_rules)) != len(compiled_rules):
///             duplicates = classify(compiled_rules, lambda x: x)
///             for dups in duplicates.values():
///                 if len(dups) > 1:
///                     if dups[0].expansion:
///                         raise GrammarError("Rules defined twice: %s\n\n(Might happen due to colliding expansion of optionals: [] or ?)"
///                                            % ''.join('\n  * %s' % i for i in dups))
///
///                     # Empty rule; assert all other attributes are equal
///                     assert len({(r.alias, r.order, r.options) for r in dups}) == len(dups)
///
///             # Remove duplicates
///             compiled_rules = list(set(compiled_rules))
///
///         # Filter out unused rules
///         while True:
///             c = len(compiled_rules)
///             used_rules = {s for r in compiled_rules
///                             for s in r.expansion
///                             if isinstance(s, NonTerminal)
///                             and s != r.origin}
///             used_rules |= {NonTerminal(s) for s in start}
///             compiled_rules, unused = classify_bool(compiled_rules, lambda r: r.origin in used_rules)
///             for r in unused:
///                 logger.debug("Unused rule: %s", r)
///             if len(compiled_rules) == c:
///                 break
///
///         # Filter out unused terminals
///         if terminals_to_keep != '*':
///             used_terms = {t.name for r in compiled_rules
///                                  for t in r.expansion
///                                  if isinstance(t, Terminal)}
///             terminals, unused = classify_bool(terminals, lambda t: t.name in used_terms or t.name in self.ignore or t.name in terminals_to_keep)
///             if unused:
///                 logger.debug("Unused terminals: %s", [t.name for t in unused])
///
///         return terminals, compiled_rules, self.ignore
/// ```
final class Grammar extends PythonClass {
  factory Grammar({
    required Object? rule_defs,
    required Object? term_defs,
    required Object? ignore,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.load_grammar",
        "Grammar",
        Grammar.from,
        <Object?>[
          rule_defs,
          term_defs,
          ignore,
        ],
        <String, Object?>{},
      );

  Grammar.from(super.pythonClass) : super.from();

  /// ## compile
  ///
  /// ### python source
  /// ```py
  /// def compile(self, start, terminals_to_keep):
  ///         # We change the trees in-place (to support huge grammars)
  ///         # So deepcopy allows calling compile more than once.
  ///         term_defs = [(n, (nr_deepcopy_tree(t), p)) for n, (t, p) in self.term_defs]
  ///         rule_defs = [(n, p, nr_deepcopy_tree(t), o) for n, p, t, o in self.rule_defs]
  ///
  ///         # ===================
  ///         #  Compile Terminals
  ///         # ===================
  ///
  ///         # Convert terminal-trees to strings/regexps
  ///
  ///         for name, (term_tree, priority) in term_defs:
  ///             if term_tree is None:  # Terminal added through %declare
  ///                 continue
  ///             expansions = list(term_tree.find_data('expansion'))
  ///             if len(expansions) == 1 and not expansions[0].children:
  ///                 raise GrammarError("Terminals cannot be empty (%s)" % name)
  ///
  ///         transformer = PrepareLiterals() * TerminalTreeToPattern()
  ///         terminals = [TerminalDef(name, transformer.transform(term_tree), priority)
  ///                      for name, (term_tree, priority) in term_defs if term_tree]
  ///
  ///         # =================
  ///         #  Compile Rules
  ///         # =================
  ///
  ///         # 1. Pre-process terminals
  ///         anon_tokens_transf = PrepareAnonTerminals(terminals)
  ///         transformer = PrepareLiterals() * ValidateSymbols() * anon_tokens_transf  # Adds to terminals
  ///
  ///         # 2. Inline Templates
  ///
  ///         transformer *= ApplyTemplates(rule_defs)
  ///
  ///         # 3. Convert EBNF to BNF (and apply step 1 & 2)
  ///         ebnf_to_bnf = EBNF_to_BNF()
  ///         rules = []
  ///         i = 0
  ///         while i < len(rule_defs):  # We have to do it like this because rule_defs might grow due to templates
  ///             name, params, rule_tree, options = rule_defs[i]
  ///             i += 1
  ///             if len(params) != 0:  # Dont transform templates
  ///                 continue
  ///             rule_options = RuleOptions(keep_all_tokens=True) if options and options.keep_all_tokens else None
  ///             ebnf_to_bnf.rule_options = rule_options
  ///             ebnf_to_bnf.prefix = name
  ///             anon_tokens_transf.rule_options = rule_options
  ///             tree = transformer.transform(rule_tree)
  ///             res = ebnf_to_bnf.transform(tree)
  ///             rules.append((name, res, options))
  ///         rules += ebnf_to_bnf.new_rules
  ///
  ///         assert len(rules) == len({name for name, _t, _o in rules}), "Whoops, name collision"
  ///
  ///         # 4. Compile tree to Rule objects
  ///         rule_tree_to_text = RuleTreeToText()
  ///
  ///         simplify_rule = SimplifyRule_Visitor()
  ///         compiled_rules = []
  ///         for rule_content in rules:
  ///             name, tree, options = rule_content
  ///             simplify_rule.visit(tree)
  ///             expansions = rule_tree_to_text.transform(tree)
  ///
  ///             for i, (expansion, alias) in enumerate(expansions):
  ///                 if alias and name.startswith('_'):
  ///                     raise GrammarError("Rule %s is marked for expansion (it starts with an underscore) and isn't allowed to have aliases (alias=%s)"% (name, alias))
  ///
  ///                 empty_indices = [x==_EMPTY for x in expansion]
  ///                 if any(empty_indices):
  ///                     exp_options = copy(options) or RuleOptions()
  ///                     exp_options.empty_indices = empty_indices
  ///                     expansion = [x for x in expansion if x!=_EMPTY]
  ///                 else:
  ///                     exp_options = options
  ///
  ///                 for sym in expansion:
  ///                     assert isinstance(sym, Symbol)
  ///                     if sym.is_term and exp_options and exp_options.keep_all_tokens:
  ///                         sym.filter_out = False
  ///                 rule = Rule(NonTerminal(name), expansion, i, alias, exp_options)
  ///                 compiled_rules.append(rule)
  ///
  ///         # Remove duplicates of empty rules, throw error for non-empty duplicates
  ///         if len(set(compiled_rules)) != len(compiled_rules):
  ///             duplicates = classify(compiled_rules, lambda x: x)
  ///             for dups in duplicates.values():
  ///                 if len(dups) > 1:
  ///                     if dups[0].expansion:
  ///                         raise GrammarError("Rules defined twice: %s\n\n(Might happen due to colliding expansion of optionals: [] or ?)"
  ///                                            % ''.join('\n  * %s' % i for i in dups))
  ///
  ///                     # Empty rule; assert all other attributes are equal
  ///                     assert len({(r.alias, r.order, r.options) for r in dups}) == len(dups)
  ///
  ///             # Remove duplicates
  ///             compiled_rules = list(set(compiled_rules))
  ///
  ///         # Filter out unused rules
  ///         while True:
  ///             c = len(compiled_rules)
  ///             used_rules = {s for r in compiled_rules
  ///                             for s in r.expansion
  ///                             if isinstance(s, NonTerminal)
  ///                             and s != r.origin}
  ///             used_rules |= {NonTerminal(s) for s in start}
  ///             compiled_rules, unused = classify_bool(compiled_rules, lambda r: r.origin in used_rules)
  ///             for r in unused:
  ///                 logger.debug("Unused rule: %s", r)
  ///             if len(compiled_rules) == c:
  ///                 break
  ///
  ///         # Filter out unused terminals
  ///         if terminals_to_keep != '*':
  ///             used_terms = {t.name for r in compiled_rules
  ///                                  for t in r.expansion
  ///                                  if isinstance(t, Terminal)}
  ///             terminals, unused = classify_bool(terminals, lambda t: t.name in used_terms or t.name in self.ignore or t.name in terminals_to_keep)
  ///             if unused:
  ///                 logger.debug("Unused terminals: %s", [t.name for t in unused])
  ///
  ///         return terminals, compiled_rules, self.ignore
  /// ```
  Object? compile({
    required Object? start,
    required Object? terminals_to_keep,
  }) =>
      getFunction("compile").call(
        <Object?>[
          start,
          terminals_to_keep,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## term_defs (getter)
  Object? get term_defs => getAttribute("term_defs");

  /// ## term_defs (setter)
  set term_defs(Object? term_defs) => setAttribute("term_defs", term_defs);

  /// ## rule_defs (getter)
  Object? get rule_defs => getAttribute("rule_defs");

  /// ## rule_defs (setter)
  set rule_defs(Object? rule_defs) => setAttribute("rule_defs", rule_defs);

  /// ## ignore (getter)
  Object? get ignore => getAttribute("ignore");

  /// ## ignore (setter)
  set ignore(Object? ignore) => setAttribute("ignore", ignore);
}

/// ## IO
///
/// ### python docstring
///
/// Generic base class for TextIO and BinaryIO.
///
/// This is an abstract, generic version of the return of open().
///
/// NOTE: This does not distinguish between the different possible
/// classes (text vs. binary, read vs. write vs. read/write,
/// append-only, unbuffered).  The TextIO and BinaryIO subclasses
/// below capture the distinctions between text vs. binary, which is
/// pervasive in the interface; however we currently do not offer a
/// way to track the other distinctions in the type system.
///
/// ### python source
/// ```py
/// class IO(Generic[AnyStr]):
///     """Generic base class for TextIO and BinaryIO.
///
///     This is an abstract, generic version of the return of open().
///
///     NOTE: This does not distinguish between the different possible
///     classes (text vs. binary, read vs. write vs. read/write,
///     append-only, unbuffered).  The TextIO and BinaryIO subclasses
///     below capture the distinctions between text vs. binary, which is
///     pervasive in the interface; however we currently do not offer a
///     way to track the other distinctions in the type system.
///     """
///
///     __slots__ = ()
///
///     @property
///     @abstractmethod
///     def mode(self) -> str:
///         pass
///
///     @property
///     @abstractmethod
///     def name(self) -> str:
///         pass
///
///     @abstractmethod
///     def close(self) -> None:
///         pass
///
///     @property
///     @abstractmethod
///     def closed(self) -> bool:
///         pass
///
///     @abstractmethod
///     def fileno(self) -> int:
///         pass
///
///     @abstractmethod
///     def flush(self) -> None:
///         pass
///
///     @abstractmethod
///     def isatty(self) -> bool:
///         pass
///
///     @abstractmethod
///     def read(self, n: int = -1) -> AnyStr:
///         pass
///
///     @abstractmethod
///     def readable(self) -> bool:
///         pass
///
///     @abstractmethod
///     def readline(self, limit: int = -1) -> AnyStr:
///         pass
///
///     @abstractmethod
///     def readlines(self, hint: int = -1) -> List[AnyStr]:
///         pass
///
///     @abstractmethod
///     def seek(self, offset: int, whence: int = 0) -> int:
///         pass
///
///     @abstractmethod
///     def seekable(self) -> bool:
///         pass
///
///     @abstractmethod
///     def tell(self) -> int:
///         pass
///
///     @abstractmethod
///     def truncate(self, size: int = None) -> int:
///         pass
///
///     @abstractmethod
///     def writable(self) -> bool:
///         pass
///
///     @abstractmethod
///     def write(self, s: AnyStr) -> int:
///         pass
///
///     @abstractmethod
///     def writelines(self, lines: List[AnyStr]) -> None:
///         pass
///
///     @abstractmethod
///     def __enter__(self) -> 'IO[AnyStr]':
///         pass
///
///     @abstractmethod
///     def __exit__(self, type, value, traceback) -> None:
///         pass
/// ```
final class IO extends PythonClass {
  factory IO() => PythonFfiDart.instance.importClass(
        "typing",
        "IO",
        IO.from,
        <Object?>[],
      );

  IO.from(super.pythonClass) : super.from();

  /// ## close
  ///
  /// ### python source
  /// ```py
  /// @abstractmethod
  ///     def close(self) -> None:
  ///         pass
  /// ```
  Object? close() => getFunction("close").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## fileno
  ///
  /// ### python source
  /// ```py
  /// @abstractmethod
  ///     def fileno(self) -> int:
  ///         pass
  /// ```
  Object? fileno() => getFunction("fileno").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## flush
  ///
  /// ### python source
  /// ```py
  /// @abstractmethod
  ///     def flush(self) -> None:
  ///         pass
  /// ```
  Object? flush() => getFunction("flush").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## isatty
  ///
  /// ### python source
  /// ```py
  /// @abstractmethod
  ///     def isatty(self) -> bool:
  ///         pass
  /// ```
  Object? isatty() => getFunction("isatty").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## read
  ///
  /// ### python source
  /// ```py
  /// @abstractmethod
  ///     def read(self, n: int = -1) -> AnyStr:
  ///         pass
  /// ```
  Object? read({
    Object? n = -1,
  }) =>
      getFunction("read").call(
        <Object?>[
          n,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## readable
  ///
  /// ### python source
  /// ```py
  /// @abstractmethod
  ///     def readable(self) -> bool:
  ///         pass
  /// ```
  Object? readable() => getFunction("readable").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## readline
  ///
  /// ### python source
  /// ```py
  /// @abstractmethod
  ///     def readline(self, limit: int = -1) -> AnyStr:
  ///         pass
  /// ```
  Object? readline({
    Object? limit = -1,
  }) =>
      getFunction("readline").call(
        <Object?>[
          limit,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## readlines
  ///
  /// ### python source
  /// ```py
  /// @abstractmethod
  ///     def readlines(self, hint: int = -1) -> List[AnyStr]:
  ///         pass
  /// ```
  Object? readlines({
    Object? hint = -1,
  }) =>
      getFunction("readlines").call(
        <Object?>[
          hint,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## seek
  ///
  /// ### python source
  /// ```py
  /// @abstractmethod
  ///     def seek(self, offset: int, whence: int = 0) -> int:
  ///         pass
  /// ```
  Object? seek({
    required Object? offset,
    Object? whence = 0,
  }) =>
      getFunction("seek").call(
        <Object?>[
          offset,
          whence,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## seekable
  ///
  /// ### python source
  /// ```py
  /// @abstractmethod
  ///     def seekable(self) -> bool:
  ///         pass
  /// ```
  Object? seekable() => getFunction("seekable").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## tell
  ///
  /// ### python source
  /// ```py
  /// @abstractmethod
  ///     def tell(self) -> int:
  ///         pass
  /// ```
  Object? tell() => getFunction("tell").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## truncate
  ///
  /// ### python source
  /// ```py
  /// @abstractmethod
  ///     def truncate(self, size: int = None) -> int:
  ///         pass
  /// ```
  Object? truncate({
    Object? size,
  }) =>
      getFunction("truncate").call(
        <Object?>[
          size,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## writable
  ///
  /// ### python source
  /// ```py
  /// @abstractmethod
  ///     def writable(self) -> bool:
  ///         pass
  /// ```
  Object? writable() => getFunction("writable").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## write
  ///
  /// ### python source
  /// ```py
  /// @abstractmethod
  ///     def write(self, s: AnyStr) -> int:
  ///         pass
  /// ```
  Object? write({
    required Object? s,
  }) =>
      getFunction("write").call(
        <Object?>[
          s,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## writelines
  ///
  /// ### python source
  /// ```py
  /// @abstractmethod
  ///     def writelines(self, lines: List[AnyStr]) -> None:
  ///         pass
  /// ```
  Object? writelines({
    required Object? lines,
  }) =>
      getFunction("writelines").call(
        <Object?>[
          lines,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## closed (getter)
  Object? get closed => getAttribute("closed");

  /// ## closed (setter)
  set closed(Object? closed) => setAttribute("closed", closed);

  /// ## mode (getter)
  Object? get mode => getAttribute("mode");

  /// ## mode (setter)
  set mode(Object? mode) => setAttribute("mode", mode);

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);
}

/// ## LarkOptions
///
/// ### python docstring
///
/// Specifies the options for Lark
///
///
/// **===  General Options  ===**
///
/// start
///         The start symbol. Either a string, or a list of strings for multiple possible starts (Default: "start")
/// debug
///         Display debug information and extra warnings. Use only when debugging (Default: ``False``)
///         When used with Earley, it generates a forest graph as "sppf.png", if 'dot' is installed.
/// transformer
///         Applies the transformer to every parse tree (equivalent to applying it after the parse, but faster)
/// propagate_positions
///         Propagates (line, column, end_line, end_column) attributes into all tree branches.
///         Accepts ``False``, ``True``, or a callable, which will filter which nodes to ignore when propagating.
/// maybe_placeholders
///         When ``True``, the ``[]`` operator returns ``None`` when not matched.
///         When ``False``,  ``[]`` behaves like the ``?`` operator, and returns no value at all.
///         (default= ``True``)
/// cache
///         Cache the results of the Lark grammar analysis, for x2 to x3 faster loading. LALR only for now.
///
///         - When ``False``, does nothing (default)
///         - When ``True``, caches to a temporary file in the local directory
///         - When given a string, caches to the path pointed by the string
/// regex
///         When True, uses the ``regex`` module instead of the stdlib ``re``.
/// g_regex_flags
///         Flags that are applied to all terminals (both regex and strings)
/// keep_all_tokens
///         Prevent the tree builder from automagically removing "punctuation" tokens (Default: ``False``)
/// tree_class
///         Lark will produce trees comprised of instances of this class instead of the default ``lark.Tree``.
///
/// **=== Algorithm Options ===**
///
/// parser
///         Decides which parser engine to use. Accepts "earley" or "lalr". (Default: "earley").
///         (there is also a "cyk" option for legacy)
/// lexer
///         Decides whether or not to use a lexer stage
///
///         - "auto" (default): Choose for me based on the parser
///         - "basic": Use a basic lexer
///         - "contextual": Stronger lexer (only works with parser="lalr")
///         - "dynamic": Flexible and powerful (only with parser="earley")
///         - "dynamic_complete": Same as dynamic, but tries *every* variation of tokenizing possible.
/// ambiguity
///         Decides how to handle ambiguity in the parse. Only relevant if parser="earley"
///
///         - "resolve": The parser will automatically choose the simplest derivation
///           (it chooses consistently: greedy for tokens, non-greedy for rules)
///         - "explicit": The parser will return all derivations wrapped in "_ambig" tree nodes (i.e. a forest).
///         - "forest": The parser will return the root of the shared packed parse forest.
///
/// **=== Misc. / Domain Specific Options ===**
///
/// postlex
///         Lexer post-processing (Default: ``None``) Only works with the basic and contextual lexers.
/// priority
///         How priorities should be evaluated - "auto", ``None``, "normal", "invert" (Default: "auto")
/// lexer_callbacks
///         Dictionary of callbacks for the lexer. May alter tokens during lexing. Use with caution.
/// use_bytes
///         Accept an input of type ``bytes`` instead of ``str``.
/// edit_terminals
///         A callback for editing the terminals before parse.
/// import_paths
///         A List of either paths or loader functions to specify from where grammars are imported
/// source_path
///         Override the source of from where the grammar was loaded. Useful for relative imports and unconventional grammar loading
/// **=== End of Options ===**
///
/// ### python source
/// ```py
/// class LarkOptions(Serialize):
///     """Specifies the options for Lark
///
///     """
///
///     start: List[str]
///     debug: bool
///     transformer: 'Optional[Transformer]'
///     propagate_positions: Union[bool, str]
///     maybe_placeholders: bool
///     cache: Union[bool, str]
///     regex: bool
///     g_regex_flags: int
///     keep_all_tokens: bool
///     tree_class: Any
///     parser: _ParserArgType
///     lexer: _LexerArgType
///     ambiguity: 'Literal["auto", "resolve", "explicit", "forest"]'
///     postlex: Optional[PostLex]
///     priority: 'Optional[Literal["auto", "normal", "invert"]]'
///     lexer_callbacks: Dict[str, Callable[[Token], Token]]
///     use_bytes: bool
///     edit_terminals: Optional[Callable[[TerminalDef], TerminalDef]]
///     import_paths: 'List[Union[str, Callable[[Union[None, str, PackageResource], str], Tuple[str, str]]]]'
///     source_path: Optional[str]
///
///     OPTIONS_DOC = """
///     **===  General Options  ===**
///
///     start
///             The start symbol. Either a string, or a list of strings for multiple possible starts (Default: "start")
///     debug
///             Display debug information and extra warnings. Use only when debugging (Default: ``False``)
///             When used with Earley, it generates a forest graph as "sppf.png", if 'dot' is installed.
///     transformer
///             Applies the transformer to every parse tree (equivalent to applying it after the parse, but faster)
///     propagate_positions
///             Propagates (line, column, end_line, end_column) attributes into all tree branches.
///             Accepts ``False``, ``True``, or a callable, which will filter which nodes to ignore when propagating.
///     maybe_placeholders
///             When ``True``, the ``[]`` operator returns ``None`` when not matched.
///             When ``False``,  ``[]`` behaves like the ``?`` operator, and returns no value at all.
///             (default= ``True``)
///     cache
///             Cache the results of the Lark grammar analysis, for x2 to x3 faster loading. LALR only for now.
///
///             - When ``False``, does nothing (default)
///             - When ``True``, caches to a temporary file in the local directory
///             - When given a string, caches to the path pointed by the string
///     regex
///             When True, uses the ``regex`` module instead of the stdlib ``re``.
///     g_regex_flags
///             Flags that are applied to all terminals (both regex and strings)
///     keep_all_tokens
///             Prevent the tree builder from automagically removing "punctuation" tokens (Default: ``False``)
///     tree_class
///             Lark will produce trees comprised of instances of this class instead of the default ``lark.Tree``.
///
///     **=== Algorithm Options ===**
///
///     parser
///             Decides which parser engine to use. Accepts "earley" or "lalr". (Default: "earley").
///             (there is also a "cyk" option for legacy)
///     lexer
///             Decides whether or not to use a lexer stage
///
///             - "auto" (default): Choose for me based on the parser
///             - "basic": Use a basic lexer
///             - "contextual": Stronger lexer (only works with parser="lalr")
///             - "dynamic": Flexible and powerful (only with parser="earley")
///             - "dynamic_complete": Same as dynamic, but tries *every* variation of tokenizing possible.
///     ambiguity
///             Decides how to handle ambiguity in the parse. Only relevant if parser="earley"
///
///             - "resolve": The parser will automatically choose the simplest derivation
///               (it chooses consistently: greedy for tokens, non-greedy for rules)
///             - "explicit": The parser will return all derivations wrapped in "_ambig" tree nodes (i.e. a forest).
///             - "forest": The parser will return the root of the shared packed parse forest.
///
///     **=== Misc. / Domain Specific Options ===**
///
///     postlex
///             Lexer post-processing (Default: ``None``) Only works with the basic and contextual lexers.
///     priority
///             How priorities should be evaluated - "auto", ``None``, "normal", "invert" (Default: "auto")
///     lexer_callbacks
///             Dictionary of callbacks for the lexer. May alter tokens during lexing. Use with caution.
///     use_bytes
///             Accept an input of type ``bytes`` instead of ``str``.
///     edit_terminals
///             A callback for editing the terminals before parse.
///     import_paths
///             A List of either paths or loader functions to specify from where grammars are imported
///     source_path
///             Override the source of from where the grammar was loaded. Useful for relative imports and unconventional grammar loading
///     **=== End of Options ===**
///     """
///     if __doc__:
///         __doc__ += OPTIONS_DOC
///
///
///     # Adding a new option needs to be done in multiple places:
///     # - In the dictionary below. This is the primary truth of which options `Lark.__init__` accepts
///     # - In the docstring above. It is used both for the docstring of `LarkOptions` and `Lark`, and in readthedocs
///     # - As an attribute of `LarkOptions` above
///     # - Potentially in `_LOAD_ALLOWED_OPTIONS` below this class, when the option doesn't change how the grammar is loaded
///     # - Potentially in `lark.tools.__init__`, if it makes sense, and it can easily be passed as a cmd argument
///     _defaults: Dict[str, Any] = {
///         'debug': False,
///         'keep_all_tokens': False,
///         'tree_class': None,
///         'cache': False,
///         'postlex': None,
///         'parser': 'earley',
///         'lexer': 'auto',
///         'transformer': None,
///         'start': 'start',
///         'priority': 'auto',
///         'ambiguity': 'auto',
///         'regex': False,
///         'propagate_positions': False,
///         'lexer_callbacks': {},
///         'maybe_placeholders': True,
///         'edit_terminals': None,
///         'g_regex_flags': 0,
///         'use_bytes': False,
///         'import_paths': [],
///         'source_path': None,
///         '_plugins': {},
///     }
///
///     def __init__(self, options_dict: Dict[str, Any]) -> None:
///         o = dict(options_dict)
///
///         options = {}
///         for name, default in self._defaults.items():
///             if name in o:
///                 value = o.pop(name)
///                 if isinstance(default, bool) and name not in ('cache', 'use_bytes', 'propagate_positions'):
///                     value = bool(value)
///             else:
///                 value = default
///
///             options[name] = value
///
///         if isinstance(options['start'], str):
///             options['start'] = [options['start']]
///
///         self.__dict__['options'] = options
///
///
///         assert_config(self.parser, ('earley', 'lalr', 'cyk', None))
///
///         if self.parser == 'earley' and self.transformer:
///             raise ConfigurationError('Cannot specify an embedded transformer when using the Earley algorithm. '
///                              'Please use your transformer on the resulting parse tree, or use a different algorithm (i.e. LALR)')
///
///         if o:
///             raise ConfigurationError("Unknown options: %s" % o.keys())
///
///     def __getattr__(self, name: str) -> Any:
///         try:
///             return self.__dict__['options'][name]
///         except KeyError as e:
///             raise AttributeError(e)
///
///     def __setattr__(self, name: str, value: str) -> None:
///         assert_config(name, self.options.keys(), "%r isn't a valid option. Expected one of: %s")
///         self.options[name] = value
///
///     def serialize(self, memo = None) -> Dict[str, Any]:
///         return self.options
///
///     @classmethod
///     def deserialize(cls, data: Dict[str, Any], memo: Dict[int, Union[TerminalDef, Rule]]) -> "LarkOptions":
///         return cls(data)
/// ```
final class LarkOptions extends PythonClass {
  factory LarkOptions({
    required Object? options_dict,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.lark",
        "LarkOptions",
        LarkOptions.from,
        <Object?>[
          options_dict,
        ],
        <String, Object?>{},
      );

  LarkOptions.from(super.pythonClass) : super.from();

  /// ## memo_serialize
  ///
  /// ### python source
  /// ```py
  /// def memo_serialize(self, types_to_memoize: List) -> Any:
  ///         memo = SerializeMemoizer(types_to_memoize)
  ///         return self.serialize(memo), memo.serialize()
  /// ```
  Object? memo_serialize({
    required Object? types_to_memoize,
  }) =>
      getFunction("memo_serialize").call(
        <Object?>[
          types_to_memoize,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## serialize
  ///
  /// ### python source
  /// ```py
  /// def serialize(self, memo = None) -> Dict[str, Any]:
  ///         return self.options
  /// ```
  Object? serialize({
    Object? memo,
  }) =>
      getFunction("serialize").call(
        <Object?>[
          memo,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## deserialize (getter)
  Object? get deserialize => getAttribute("deserialize");

  /// ## deserialize (setter)
  set deserialize(Object? deserialize) =>
      setAttribute("deserialize", deserialize);

  /// ## OPTIONS_DOC (getter)
  Object? get OPTIONS_DOC => getAttribute("OPTIONS_DOC");

  /// ## OPTIONS_DOC (setter)
  set OPTIONS_DOC(Object? OPTIONS_DOC) =>
      setAttribute("OPTIONS_DOC", OPTIONS_DOC);
}

/// ## Lexer
///
/// ### python docstring
///
/// Lexer interface
///
/// Method Signatures:
///     lex(self, lexer_state, parser_state) -> Iterator[Token]
///
/// ### python source
/// ```py
/// class Lexer(ABC):
///     """Lexer interface
///
///     Method Signatures:
///         lex(self, lexer_state, parser_state) -> Iterator[Token]
///     """
///     @abstractmethod
///     def lex(self, lexer_state: LexerState, parser_state: Any) -> Iterator[Token]:
///         return NotImplemented
///
///     def make_lexer_state(self, text):
///         "Deprecated"
///         return LexerState(text)
/// ```
final class Lexer extends PythonClass {
  factory Lexer() => PythonFfiDart.instance.importClass(
        "lark.lexer",
        "Lexer",
        Lexer.from,
        <Object?>[],
      );

  Lexer.from(super.pythonClass) : super.from();

  /// ## lex
  ///
  /// ### python source
  /// ```py
  /// @abstractmethod
  ///     def lex(self, lexer_state: LexerState, parser_state: Any) -> Iterator[Token]:
  ///         return NotImplemented
  /// ```
  Object? lex({
    required Object? lexer_state,
    required Object? parser_state,
  }) =>
      getFunction("lex").call(
        <Object?>[
          lexer_state,
          parser_state,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## make_lexer_state
  ///
  /// ### python docstring
  ///
  /// Deprecated
  ///
  /// ### python source
  /// ```py
  /// def make_lexer_state(self, text):
  ///         "Deprecated"
  ///         return LexerState(text)
  /// ```
  Object? make_lexer_state({
    required Object? text,
  }) =>
      getFunction("make_lexer_state").call(
        <Object?>[
          text,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## LexerThread
///
/// ### python docstring
///
/// A thread that ties a lexer instance and a lexer state, to be used by the parser
///
/// ### python source
/// ```py
/// class LexerThread:
///     """A thread that ties a lexer instance and a lexer state, to be used by the parser
///     """
///
///     def __init__(self, lexer: 'Lexer', lexer_state: LexerState):
///         self.lexer = lexer
///         self.state = lexer_state
///
///     @classmethod
///     def from_text(cls, lexer: 'Lexer', text: str):
///         return cls(lexer, LexerState(text))
///
///     def lex(self, parser_state):
///         return self.lexer.lex(self.state, parser_state)
///
///     def __copy__(self):
///         return type(self)(self.lexer, copy(self.state))
///
///     _Token = Token
/// ```
final class LexerThread extends PythonClass {
  factory LexerThread({
    required Object? lexer,
    required Object? lexer_state,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.lexer",
        "LexerThread",
        LexerThread.from,
        <Object?>[
          lexer,
          lexer_state,
        ],
        <String, Object?>{},
      );

  LexerThread.from(super.pythonClass) : super.from();

  /// ## lex
  ///
  /// ### python source
  /// ```py
  /// def lex(self, parser_state):
  ///         return self.lexer.lex(self.state, parser_state)
  /// ```
  Object? lex({
    required Object? parser_state,
  }) =>
      getFunction("lex").call(
        <Object?>[
          parser_state,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## from_text (getter)
  Object? get from_text => getAttribute("from_text");

  /// ## from_text (setter)
  set from_text(Object? from_text) => setAttribute("from_text", from_text);

  /// ## lexer (getter)
  Object? get lexer => getAttribute("lexer");

  /// ## lexer (setter)
  set lexer(Object? lexer) => setAttribute("lexer", lexer);

  /// ## state (getter)
  Object? get state => getAttribute("state");

  /// ## state (setter)
  set state(Object? state) => setAttribute("state", state);
}

/// ## PackageResource
///
/// ### python docstring
///
/// PackageResource(pkg_name, path)
final class PackageResource extends PythonClass {
  factory PackageResource() => PythonFfiDart.instance.importClass(
        "lark.load_grammar",
        "PackageResource",
        PackageResource.from,
        <Object?>[],
      );

  PackageResource.from(super.pythonClass) : super.from();

  /// ## path (getter)
  ///
  /// ### python docstring
  ///
  /// Alias for field number 1
  Object? get path => getAttribute("path");

  /// ## path (setter)
  ///
  /// ### python docstring
  ///
  /// Alias for field number 1
  set path(Object? path) => setAttribute("path", path);

  /// ## pkg_name (getter)
  ///
  /// ### python docstring
  ///
  /// Alias for field number 0
  Object? get pkg_name => getAttribute("pkg_name");

  /// ## pkg_name (setter)
  ///
  /// ### python docstring
  ///
  /// Alias for field number 0
  set pkg_name(Object? pkg_name) => setAttribute("pkg_name", pkg_name);

  /// ## count (getter)
  Object? get count => getAttribute("count");

  /// ## count (setter)
  set count(Object? count) => setAttribute("count", count);

  /// ## index (getter)
  Object? get index => getAttribute("index");

  /// ## index (setter)
  set index(Object? index) => setAttribute("index", index);
}

/// ## ParseTreeBuilder
///
/// ### python source
/// ```py
/// class ParseTreeBuilder:
///     def __init__(self, rules, tree_class, propagate_positions=False, ambiguous=False, maybe_placeholders=False):
///         self.tree_class = tree_class
///         self.propagate_positions = propagate_positions
///         self.ambiguous = ambiguous
///         self.maybe_placeholders = maybe_placeholders
///
///         self.rule_builders = list(self._init_builders(rules))
///
///     def _init_builders(self, rules):
///         propagate_positions = make_propagate_positions(self.propagate_positions)
///
///         for rule in rules:
///             options = rule.options
///             keep_all_tokens = options.keep_all_tokens
///             expand_single_child = options.expand1
///
///             wrapper_chain = list(filter(None, [
///                 (expand_single_child and not rule.alias) and ExpandSingleChild,
///                 maybe_create_child_filter(rule.expansion, keep_all_tokens, self.ambiguous, options.empty_indices if self.maybe_placeholders else None),
///                 propagate_positions,
///                 self.ambiguous and maybe_create_ambiguous_expander(self.tree_class, rule.expansion, keep_all_tokens),
///                 self.ambiguous and partial(AmbiguousIntermediateExpander, self.tree_class)
///             ]))
///
///             yield rule, wrapper_chain
///
///     def create_callback(self, transformer=None):
///         callbacks = {}
///
///         default_handler = getattr(transformer, '__default__', None)
///         if default_handler:
///             def default_callback(data, children):
///                 return default_handler(data, children, None)
///         else:
///             default_callback = self.tree_class
///
///         for rule, wrapper_chain in self.rule_builders:
///
///             user_callback_name = rule.alias or rule.options.template_source or rule.origin.name
///             try:
///                 f = getattr(transformer, user_callback_name)
///                 wrapper = getattr(f, 'visit_wrapper', None)
///                 if wrapper is not None:
///                     f = apply_visit_wrapper(f, user_callback_name, wrapper)
///                 elif isinstance(transformer, Transformer_InPlace):
///                     f = inplace_transformer(f)
///             except AttributeError:
///                 f = partial(default_callback, user_callback_name)
///
///             for w in wrapper_chain:
///                 f = w(f)
///
///             if rule in callbacks:
///                 raise GrammarError("Rule '%s' already exists" % (rule,))
///
///             callbacks[rule] = f
///
///         return callbacks
/// ```
final class ParseTreeBuilder extends PythonClass {
  factory ParseTreeBuilder({
    required Object? rules,
    required Object? tree_class,
    Object? propagate_positions = false,
    Object? ambiguous = false,
    Object? maybe_placeholders = false,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parse_tree_builder",
        "ParseTreeBuilder",
        ParseTreeBuilder.from,
        <Object?>[
          rules,
          tree_class,
          propagate_positions,
          ambiguous,
          maybe_placeholders,
        ],
        <String, Object?>{},
      );

  ParseTreeBuilder.from(super.pythonClass) : super.from();

  /// ## create_callback
  ///
  /// ### python source
  /// ```py
  /// def create_callback(self, transformer=None):
  ///         callbacks = {}
  ///
  ///         default_handler = getattr(transformer, '__default__', None)
  ///         if default_handler:
  ///             def default_callback(data, children):
  ///                 return default_handler(data, children, None)
  ///         else:
  ///             default_callback = self.tree_class
  ///
  ///         for rule, wrapper_chain in self.rule_builders:
  ///
  ///             user_callback_name = rule.alias or rule.options.template_source or rule.origin.name
  ///             try:
  ///                 f = getattr(transformer, user_callback_name)
  ///                 wrapper = getattr(f, 'visit_wrapper', None)
  ///                 if wrapper is not None:
  ///                     f = apply_visit_wrapper(f, user_callback_name, wrapper)
  ///                 elif isinstance(transformer, Transformer_InPlace):
  ///                     f = inplace_transformer(f)
  ///             except AttributeError:
  ///                 f = partial(default_callback, user_callback_name)
  ///
  ///             for w in wrapper_chain:
  ///                 f = w(f)
  ///
  ///             if rule in callbacks:
  ///                 raise GrammarError("Rule '%s' already exists" % (rule,))
  ///
  ///             callbacks[rule] = f
  ///
  ///         return callbacks
  /// ```
  Object? create_callback({
    Object? transformer,
  }) =>
      getFunction("create_callback").call(
        <Object?>[
          transformer,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## tree_class (getter)
  Object? get tree_class => getAttribute("tree_class");

  /// ## tree_class (setter)
  set tree_class(Object? tree_class) => setAttribute("tree_class", tree_class);

  /// ## propagate_positions (getter)
  Object? get propagate_positions => getAttribute("propagate_positions");

  /// ## propagate_positions (setter)
  set propagate_positions(Object? propagate_positions) =>
      setAttribute("propagate_positions", propagate_positions);

  /// ## ambiguous (getter)
  Object? get ambiguous => getAttribute("ambiguous");

  /// ## ambiguous (setter)
  set ambiguous(Object? ambiguous) => setAttribute("ambiguous", ambiguous);

  /// ## maybe_placeholders (getter)
  Object? get maybe_placeholders => getAttribute("maybe_placeholders");

  /// ## maybe_placeholders (setter)
  set maybe_placeholders(Object? maybe_placeholders) =>
      setAttribute("maybe_placeholders", maybe_placeholders);

  /// ## rule_builders (getter)
  Object? get rule_builders => getAttribute("rule_builders");

  /// ## rule_builders (setter)
  set rule_builders(Object? rule_builders) =>
      setAttribute("rule_builders", rule_builders);
}

/// ## PostLex
///
/// ### python docstring
///
/// Helper class that provides a standard way to create an ABC using
/// inheritance.
///
/// ### python source
/// ```py
/// class PostLex(ABC):
///     @abstractmethod
///     def process(self, stream: Iterator[Token]) -> Iterator[Token]:
///         return stream
///
///     always_accept: Iterable[str] = ()
/// ```
final class PostLex extends PythonClass {
  factory PostLex() => PythonFfiDart.instance.importClass(
        "lark.lark",
        "PostLex",
        PostLex.from,
        <Object?>[],
      );

  PostLex.from(super.pythonClass) : super.from();

  /// ## process
  ///
  /// ### python source
  /// ```py
  /// @abstractmethod
  ///     def process(self, stream: Iterator[Token]) -> Iterator[Token]:
  ///         return stream
  /// ```
  Object? process({
    required Object? stream,
  }) =>
      getFunction("process").call(
        <Object?>[
          stream,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## always_accept (getter)
  Object? get always_accept => getAttribute("always_accept");

  /// ## always_accept (setter)
  set always_accept(Object? always_accept) =>
      setAttribute("always_accept", always_accept);
}

/// ## SerializeMemoizer
///
/// ### python docstring
///
/// A version of serialize that memoizes objects to reduce space
///
/// ### python source
/// ```py
/// class SerializeMemoizer(Serialize):
///     "A version of serialize that memoizes objects to reduce space"
///
///     __serialize_fields__ = 'memoized',
///
///     def __init__(self, types_to_memoize: List) -> None:
///         self.types_to_memoize = tuple(types_to_memoize)
///         self.memoized = Enumerator()
///
///     def in_types(self, value: Serialize) -> bool:
///         return isinstance(value, self.types_to_memoize)
///
///     def serialize(self) -> Dict[int, Any]:  # type: ignore[override]
///         return _serialize(self.memoized.reversed(), None)
///
///     @classmethod
///     def deserialize(cls, data: Dict[int, Any], namespace: Dict[str, Any], memo: Dict[Any, Any]) -> Dict[int, Any]:  # type: ignore[override]
///         return _deserialize(data, namespace, memo)
/// ```
final class SerializeMemoizer extends PythonClass {
  factory SerializeMemoizer({
    required Object? types_to_memoize,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.utils",
        "SerializeMemoizer",
        SerializeMemoizer.from,
        <Object?>[
          types_to_memoize,
        ],
        <String, Object?>{},
      );

  SerializeMemoizer.from(super.pythonClass) : super.from();

  /// ## in_types
  ///
  /// ### python source
  /// ```py
  /// def in_types(self, value: Serialize) -> bool:
  ///         return isinstance(value, self.types_to_memoize)
  /// ```
  Object? in_types({
    required Object? value,
  }) =>
      getFunction("in_types").call(
        <Object?>[
          value,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## memo_serialize
  ///
  /// ### python source
  /// ```py
  /// def memo_serialize(self, types_to_memoize: List) -> Any:
  ///         memo = SerializeMemoizer(types_to_memoize)
  ///         return self.serialize(memo), memo.serialize()
  /// ```
  Object? memo_serialize({
    required Object? types_to_memoize,
  }) =>
      getFunction("memo_serialize").call(
        <Object?>[
          types_to_memoize,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## serialize
  ///
  /// ### python source
  /// ```py
  /// def serialize(self) -> Dict[int, Any]:  # type: ignore[override]
  ///         return _serialize(self.memoized.reversed(), None)
  /// ```
  Object? serialize() => getFunction("serialize").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## deserialize (getter)
  Object? get deserialize => getAttribute("deserialize");

  /// ## deserialize (setter)
  set deserialize(Object? deserialize) =>
      setAttribute("deserialize", deserialize);

  /// ## types_to_memoize (getter)
  Object? get types_to_memoize => getAttribute("types_to_memoize");

  /// ## types_to_memoize (setter)
  set types_to_memoize(Object? types_to_memoize) =>
      setAttribute("types_to_memoize", types_to_memoize);

  /// ## memoized (getter)
  Object? get memoized => getAttribute("memoized");

  /// ## memoized (setter)
  set memoized(Object? memoized) => setAttribute("memoized", memoized);
}

/// ## GetPassWarning
///
/// ### python source
/// ```py
/// class GetPassWarning(UserWarning): pass
/// ```
final class GetPassWarning extends PythonClass {
  factory GetPassWarning() => PythonFfiDart.instance.importClass(
        "getpass",
        "GetPassWarning",
        GetPassWarning.from,
        <Object?>[],
      );

  GetPassWarning.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## AbstractAsyncContextManager
///
/// ### python docstring
///
/// An abstract base class for asynchronous context managers.
///
/// ### python source
/// ```py
/// class AbstractAsyncContextManager(abc.ABC):
///
///     """An abstract base class for asynchronous context managers."""
///
///     __class_getitem__ = classmethod(GenericAlias)
///
///     async def __aenter__(self):
///         """Return `self` upon entering the runtime context."""
///         return self
///
///     @abc.abstractmethod
///     async def __aexit__(self, exc_type, exc_value, traceback):
///         """Raise any exception triggered within the runtime context."""
///         return None
///
///     @classmethod
///     def __subclasshook__(cls, C):
///         if cls is AbstractAsyncContextManager:
///             return _collections_abc._check_methods(C, "__aenter__",
///                                                    "__aexit__")
///         return NotImplemented
/// ```
final class AbstractAsyncContextManager extends PythonClass {
  factory AbstractAsyncContextManager() => PythonFfiDart.instance.importClass(
        "contextlib",
        "AbstractAsyncContextManager",
        AbstractAsyncContextManager.from,
        <Object?>[],
      );

  AbstractAsyncContextManager.from(super.pythonClass) : super.from();
}

/// ## AbstractContextManager
///
/// ### python docstring
///
/// An abstract base class for context managers.
///
/// ### python source
/// ```py
/// class AbstractContextManager(abc.ABC):
///
///     """An abstract base class for context managers."""
///
///     __class_getitem__ = classmethod(GenericAlias)
///
///     def __enter__(self):
///         """Return `self` upon entering the runtime context."""
///         return self
///
///     @abc.abstractmethod
///     def __exit__(self, exc_type, exc_value, traceback):
///         """Raise any exception triggered within the runtime context."""
///         return None
///
///     @classmethod
///     def __subclasshook__(cls, C):
///         if cls is AbstractContextManager:
///             return _collections_abc._check_methods(C, "__enter__", "__exit__")
///         return NotImplemented
/// ```
final class AbstractContextManager extends PythonClass {
  factory AbstractContextManager() => PythonFfiDart.instance.importClass(
        "contextlib",
        "AbstractContextManager",
        AbstractContextManager.from,
        <Object?>[],
      );

  AbstractContextManager.from(super.pythonClass) : super.from();
}

/// ## AsyncContextDecorator
///
/// ### python docstring
///
/// A base class or mixin that enables async context managers to work as decorators.
///
/// ### python source
/// ```py
/// class AsyncContextDecorator(object):
///     "A base class or mixin that enables async context managers to work as decorators."
///
///     def _recreate_cm(self):
///         """Return a recreated instance of self.
///         """
///         return self
///
///     def __call__(self, func):
///         @wraps(func)
///         async def inner(*args, **kwds):
///             async with self._recreate_cm():
///                 return await func(*args, **kwds)
///         return inner
/// ```
final class AsyncContextDecorator extends PythonClass {
  factory AsyncContextDecorator() => PythonFfiDart.instance.importClass(
        "contextlib",
        "AsyncContextDecorator",
        AsyncContextDecorator.from,
        <Object?>[],
      );

  AsyncContextDecorator.from(super.pythonClass) : super.from();
}

/// ## AsyncExitStack
///
/// ### python docstring
///
/// Async context manager for dynamic management of a stack of exit
/// callbacks.
///
/// For example:
///     async with AsyncExitStack() as stack:
///         connections = [await stack.enter_async_context(get_connection())
///             for i in range(5)]
///         # All opened connections will automatically be released at the
///         # end of the async with statement, even if attempts to open a
///         # connection later in the list raise an exception.
///
/// ### python source
/// ```py
/// class AsyncExitStack(_BaseExitStack, AbstractAsyncContextManager):
///     """Async context manager for dynamic management of a stack of exit
///     callbacks.
///
///     For example:
///         async with AsyncExitStack() as stack:
///             connections = [await stack.enter_async_context(get_connection())
///                 for i in range(5)]
///             # All opened connections will automatically be released at the
///             # end of the async with statement, even if attempts to open a
///             # connection later in the list raise an exception.
///     """
///
///     @staticmethod
///     def _create_async_exit_wrapper(cm, cm_exit):
///         return MethodType(cm_exit, cm)
///
///     @staticmethod
///     def _create_async_cb_wrapper(callback, /, *args, **kwds):
///         async def _exit_wrapper(exc_type, exc, tb):
///             await callback(*args, **kwds)
///         return _exit_wrapper
///
///     async def enter_async_context(self, cm):
///         """Enters the supplied async context manager.
///
///         If successful, also pushes its __aexit__ method as a callback and
///         returns the result of the __aenter__ method.
///         """
///         cls = type(cm)
///         try:
///             _enter = cls.__aenter__
///             _exit = cls.__aexit__
///         except AttributeError:
///             raise TypeError(f"'{cls.__module__}.{cls.__qualname__}' object does "
///                             f"not support the asynchronous context manager protocol"
///                            ) from None
///         result = await _enter(cm)
///         self._push_async_cm_exit(cm, _exit)
///         return result
///
///     def push_async_exit(self, exit):
///         """Registers a coroutine function with the standard __aexit__ method
///         signature.
///
///         Can suppress exceptions the same way __aexit__ method can.
///         Also accepts any object with an __aexit__ method (registering a call
///         to the method instead of the object itself).
///         """
///         _cb_type = type(exit)
///         try:
///             exit_method = _cb_type.__aexit__
///         except AttributeError:
///             # Not an async context manager, so assume it's a coroutine function
///             self._push_exit_callback(exit, False)
///         else:
///             self._push_async_cm_exit(exit, exit_method)
///         return exit  # Allow use as a decorator
///
///     def push_async_callback(self, callback, /, *args, **kwds):
///         """Registers an arbitrary coroutine function and arguments.
///
///         Cannot suppress exceptions.
///         """
///         _exit_wrapper = self._create_async_cb_wrapper(callback, *args, **kwds)
///
///         # We changed the signature, so using @wraps is not appropriate, but
///         # setting __wrapped__ may still help with introspection.
///         _exit_wrapper.__wrapped__ = callback
///         self._push_exit_callback(_exit_wrapper, False)
///         return callback  # Allow use as a decorator
///
///     async def aclose(self):
///         """Immediately unwind the context stack."""
///         await self.__aexit__(None, None, None)
///
///     def _push_async_cm_exit(self, cm, cm_exit):
///         """Helper to correctly register coroutine function to __aexit__
///         method."""
///         _exit_wrapper = self._create_async_exit_wrapper(cm, cm_exit)
///         self._push_exit_callback(_exit_wrapper, False)
///
///     async def __aenter__(self):
///         return self
///
///     async def __aexit__(self, *exc_details):
///         received_exc = exc_details[0] is not None
///
///         # We manipulate the exception state so it behaves as though
///         # we were actually nesting multiple with statements
///         frame_exc = sys.exc_info()[1]
///         def _fix_exception_context(new_exc, old_exc):
///             # Context may not be correct, so find the end of the chain
///             while 1:
///                 exc_context = new_exc.__context__
///                 if exc_context is None or exc_context is old_exc:
///                     # Context is already set correctly (see issue 20317)
///                     return
///                 if exc_context is frame_exc:
///                     break
///                 new_exc = exc_context
///             # Change the end of the chain to point to the exception
///             # we expect it to reference
///             new_exc.__context__ = old_exc
///
///         # Callbacks are invoked in LIFO order to match the behaviour of
///         # nested context managers
///         suppressed_exc = False
///         pending_raise = False
///         while self._exit_callbacks:
///             is_sync, cb = self._exit_callbacks.pop()
///             try:
///                 if is_sync:
///                     cb_suppress = cb(*exc_details)
///                 else:
///                     cb_suppress = await cb(*exc_details)
///
///                 if cb_suppress:
///                     suppressed_exc = True
///                     pending_raise = False
///                     exc_details = (None, None, None)
///             except:
///                 new_exc_details = sys.exc_info()
///                 # simulate the stack of exceptions by setting the context
///                 _fix_exception_context(new_exc_details[1], exc_details[1])
///                 pending_raise = True
///                 exc_details = new_exc_details
///         if pending_raise:
///             try:
///                 # bare "raise exc_details[1]" replaces our carefully
///                 # set-up context
///                 fixed_ctx = exc_details[1].__context__
///                 raise exc_details[1]
///             except BaseException:
///                 exc_details[1].__context__ = fixed_ctx
///                 raise
///         return received_exc and suppressed_exc
/// ```
final class AsyncExitStack extends PythonClass {
  factory AsyncExitStack() => PythonFfiDart.instance.importClass(
        "contextlib",
        "AsyncExitStack",
        AsyncExitStack.from,
        <Object?>[],
        <String, Object?>{},
      );

  AsyncExitStack.from(super.pythonClass) : super.from();

  /// ## aclose
  ///
  /// ### python docstring
  ///
  /// Immediately unwind the context stack.
  ///
  /// ### python source
  /// ```py
  /// async def aclose(self):
  ///         """Immediately unwind the context stack."""
  ///         await self.__aexit__(None, None, None)
  /// ```
  Object? aclose() => getFunction("aclose").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## callback
  ///
  /// ### python docstring
  ///
  /// Registers an arbitrary callback and arguments.
  ///
  /// Cannot suppress exceptions.
  ///
  /// ### python source
  /// ```py
  /// def callback(self, callback, /, *args, **kwds):
  ///         """Registers an arbitrary callback and arguments.
  ///
  ///         Cannot suppress exceptions.
  ///         """
  ///         _exit_wrapper = self._create_cb_wrapper(callback, *args, **kwds)
  ///
  ///         # We changed the signature, so using @wraps is not appropriate, but
  ///         # setting __wrapped__ may still help with introspection.
  ///         _exit_wrapper.__wrapped__ = callback
  ///         self._push_exit_callback(_exit_wrapper)
  ///         return callback  # Allow use as a decorator
  /// ```
  Object? callback(
    Object? callback, {
    List<Object?> args = const <Object?>[],
    Map<String, Object?> kwds = const <String, Object?>{},
  }) =>
      getFunction("callback").call(
        <Object?>[
          callback,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwds,
        },
      );

  /// ## enter_async_context
  ///
  /// ### python docstring
  ///
  /// Enters the supplied async context manager.
  ///
  /// If successful, also pushes its __aexit__ method as a callback and
  /// returns the result of the __aenter__ method.
  ///
  /// ### python source
  /// ```py
  /// async def enter_async_context(self, cm):
  ///         """Enters the supplied async context manager.
  ///
  ///         If successful, also pushes its __aexit__ method as a callback and
  ///         returns the result of the __aenter__ method.
  ///         """
  ///         cls = type(cm)
  ///         try:
  ///             _enter = cls.__aenter__
  ///             _exit = cls.__aexit__
  ///         except AttributeError:
  ///             raise TypeError(f"'{cls.__module__}.{cls.__qualname__}' object does "
  ///                             f"not support the asynchronous context manager protocol"
  ///                            ) from None
  ///         result = await _enter(cm)
  ///         self._push_async_cm_exit(cm, _exit)
  ///         return result
  /// ```
  Object? enter_async_context({
    required Object? cm,
  }) =>
      getFunction("enter_async_context").call(
        <Object?>[
          cm,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## enter_context
  ///
  /// ### python docstring
  ///
  /// Enters the supplied context manager.
  ///
  /// If successful, also pushes its __exit__ method as a callback and
  /// returns the result of the __enter__ method.
  ///
  /// ### python source
  /// ```py
  /// def enter_context(self, cm):
  ///         """Enters the supplied context manager.
  ///
  ///         If successful, also pushes its __exit__ method as a callback and
  ///         returns the result of the __enter__ method.
  ///         """
  ///         # We look up the special methods on the type to match the with
  ///         # statement.
  ///         cls = type(cm)
  ///         try:
  ///             _enter = cls.__enter__
  ///             _exit = cls.__exit__
  ///         except AttributeError:
  ///             raise TypeError(f"'{cls.__module__}.{cls.__qualname__}' object does "
  ///                             f"not support the context manager protocol") from None
  ///         result = _enter(cm)
  ///         self._push_cm_exit(cm, _exit)
  ///         return result
  /// ```
  Object? enter_context({
    required Object? cm,
  }) =>
      getFunction("enter_context").call(
        <Object?>[
          cm,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## pop_all
  ///
  /// ### python docstring
  ///
  /// Preserve the context stack by transferring it to a new instance.
  ///
  /// ### python source
  /// ```py
  /// def pop_all(self):
  ///         """Preserve the context stack by transferring it to a new instance."""
  ///         new_stack = type(self)()
  ///         new_stack._exit_callbacks = self._exit_callbacks
  ///         self._exit_callbacks = deque()
  ///         return new_stack
  /// ```
  Object? pop_all() => getFunction("pop_all").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## push
  ///
  /// ### python docstring
  ///
  /// Registers a callback with the standard __exit__ method signature.
  ///
  /// Can suppress exceptions the same way __exit__ method can.
  /// Also accepts any object with an __exit__ method (registering a call
  /// to the method instead of the object itself).
  ///
  /// ### python source
  /// ```py
  /// def push(self, exit):
  ///         """Registers a callback with the standard __exit__ method signature.
  ///
  ///         Can suppress exceptions the same way __exit__ method can.
  ///         Also accepts any object with an __exit__ method (registering a call
  ///         to the method instead of the object itself).
  ///         """
  ///         # We use an unbound method rather than a bound method to follow
  ///         # the standard lookup behaviour for special methods.
  ///         _cb_type = type(exit)
  ///
  ///         try:
  ///             exit_method = _cb_type.__exit__
  ///         except AttributeError:
  ///             # Not a context manager, so assume it's a callable.
  ///             self._push_exit_callback(exit)
  ///         else:
  ///             self._push_cm_exit(exit, exit_method)
  ///         return exit  # Allow use as a decorator.
  /// ```
  Object? push({
    required Object? exit,
  }) =>
      getFunction("push").call(
        <Object?>[
          exit,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## push_async_callback
  ///
  /// ### python docstring
  ///
  /// Registers an arbitrary coroutine function and arguments.
  ///
  /// Cannot suppress exceptions.
  ///
  /// ### python source
  /// ```py
  /// def push_async_callback(self, callback, /, *args, **kwds):
  ///         """Registers an arbitrary coroutine function and arguments.
  ///
  ///         Cannot suppress exceptions.
  ///         """
  ///         _exit_wrapper = self._create_async_cb_wrapper(callback, *args, **kwds)
  ///
  ///         # We changed the signature, so using @wraps is not appropriate, but
  ///         # setting __wrapped__ may still help with introspection.
  ///         _exit_wrapper.__wrapped__ = callback
  ///         self._push_exit_callback(_exit_wrapper, False)
  ///         return callback  # Allow use as a decorator
  /// ```
  Object? push_async_callback(
    Object? callback, {
    List<Object?> args = const <Object?>[],
    Map<String, Object?> kwds = const <String, Object?>{},
  }) =>
      getFunction("push_async_callback").call(
        <Object?>[
          callback,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwds,
        },
      );

  /// ## push_async_exit
  ///
  /// ### python docstring
  ///
  /// Registers a coroutine function with the standard __aexit__ method
  /// signature.
  ///
  /// Can suppress exceptions the same way __aexit__ method can.
  /// Also accepts any object with an __aexit__ method (registering a call
  /// to the method instead of the object itself).
  ///
  /// ### python source
  /// ```py
  /// def push_async_exit(self, exit):
  ///         """Registers a coroutine function with the standard __aexit__ method
  ///         signature.
  ///
  ///         Can suppress exceptions the same way __aexit__ method can.
  ///         Also accepts any object with an __aexit__ method (registering a call
  ///         to the method instead of the object itself).
  ///         """
  ///         _cb_type = type(exit)
  ///         try:
  ///             exit_method = _cb_type.__aexit__
  ///         except AttributeError:
  ///             # Not an async context manager, so assume it's a coroutine function
  ///             self._push_exit_callback(exit, False)
  ///         else:
  ///             self._push_async_cm_exit(exit, exit_method)
  ///         return exit  # Allow use as a decorator
  /// ```
  Object? push_async_exit({
    required Object? exit,
  }) =>
      getFunction("push_async_exit").call(
        <Object?>[
          exit,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## ContextDecorator
///
/// ### python docstring
///
/// A base class or mixin that enables context managers to work as decorators.
///
/// ### python source
/// ```py
/// class ContextDecorator(object):
///     "A base class or mixin that enables context managers to work as decorators."
///
///     def _recreate_cm(self):
///         """Return a recreated instance of self.
///
///         Allows an otherwise one-shot context manager like
///         _GeneratorContextManager to support use as
///         a decorator via implicit recreation.
///
///         This is a private interface just for _GeneratorContextManager.
///         See issue #11647 for details.
///         """
///         return self
///
///     def __call__(self, func):
///         @wraps(func)
///         def inner(*args, **kwds):
///             with self._recreate_cm():
///                 return func(*args, **kwds)
///         return inner
/// ```
final class ContextDecorator extends PythonClass {
  factory ContextDecorator() => PythonFfiDart.instance.importClass(
        "contextlib",
        "ContextDecorator",
        ContextDecorator.from,
        <Object?>[],
      );

  ContextDecorator.from(super.pythonClass) : super.from();
}

/// ## ExitStack
///
/// ### python docstring
///
/// Context manager for dynamic management of a stack of exit callbacks.
///
/// For example:
///     with ExitStack() as stack:
///         files = [stack.enter_context(open(fname)) for fname in filenames]
///         # All opened files will automatically be closed at the end of
///         # the with statement, even if attempts to open files later
///         # in the list raise an exception.
///
/// ### python source
/// ```py
/// class ExitStack(_BaseExitStack, AbstractContextManager):
///     """Context manager for dynamic management of a stack of exit callbacks.
///
///     For example:
///         with ExitStack() as stack:
///             files = [stack.enter_context(open(fname)) for fname in filenames]
///             # All opened files will automatically be closed at the end of
///             # the with statement, even if attempts to open files later
///             # in the list raise an exception.
///     """
///
///     def __enter__(self):
///         return self
///
///     def __exit__(self, *exc_details):
///         received_exc = exc_details[0] is not None
///
///         # We manipulate the exception state so it behaves as though
///         # we were actually nesting multiple with statements
///         frame_exc = sys.exc_info()[1]
///         def _fix_exception_context(new_exc, old_exc):
///             # Context may not be correct, so find the end of the chain
///             while 1:
///                 exc_context = new_exc.__context__
///                 if exc_context is None or exc_context is old_exc:
///                     # Context is already set correctly (see issue 20317)
///                     return
///                 if exc_context is frame_exc:
///                     break
///                 new_exc = exc_context
///             # Change the end of the chain to point to the exception
///             # we expect it to reference
///             new_exc.__context__ = old_exc
///
///         # Callbacks are invoked in LIFO order to match the behaviour of
///         # nested context managers
///         suppressed_exc = False
///         pending_raise = False
///         while self._exit_callbacks:
///             is_sync, cb = self._exit_callbacks.pop()
///             assert is_sync
///             try:
///                 if cb(*exc_details):
///                     suppressed_exc = True
///                     pending_raise = False
///                     exc_details = (None, None, None)
///             except:
///                 new_exc_details = sys.exc_info()
///                 # simulate the stack of exceptions by setting the context
///                 _fix_exception_context(new_exc_details[1], exc_details[1])
///                 pending_raise = True
///                 exc_details = new_exc_details
///         if pending_raise:
///             try:
///                 # bare "raise exc_details[1]" replaces our carefully
///                 # set-up context
///                 fixed_ctx = exc_details[1].__context__
///                 raise exc_details[1]
///             except BaseException:
///                 exc_details[1].__context__ = fixed_ctx
///                 raise
///         return received_exc and suppressed_exc
///
///     def close(self):
///         """Immediately unwind the context stack."""
///         self.__exit__(None, None, None)
/// ```
final class ExitStack extends PythonClass {
  factory ExitStack() => PythonFfiDart.instance.importClass(
        "contextlib",
        "ExitStack",
        ExitStack.from,
        <Object?>[],
        <String, Object?>{},
      );

  ExitStack.from(super.pythonClass) : super.from();

  /// ## callback
  ///
  /// ### python docstring
  ///
  /// Registers an arbitrary callback and arguments.
  ///
  /// Cannot suppress exceptions.
  ///
  /// ### python source
  /// ```py
  /// def callback(self, callback, /, *args, **kwds):
  ///         """Registers an arbitrary callback and arguments.
  ///
  ///         Cannot suppress exceptions.
  ///         """
  ///         _exit_wrapper = self._create_cb_wrapper(callback, *args, **kwds)
  ///
  ///         # We changed the signature, so using @wraps is not appropriate, but
  ///         # setting __wrapped__ may still help with introspection.
  ///         _exit_wrapper.__wrapped__ = callback
  ///         self._push_exit_callback(_exit_wrapper)
  ///         return callback  # Allow use as a decorator
  /// ```
  Object? callback(
    Object? callback, {
    List<Object?> args = const <Object?>[],
    Map<String, Object?> kwds = const <String, Object?>{},
  }) =>
      getFunction("callback").call(
        <Object?>[
          callback,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwds,
        },
      );

  /// ## close
  ///
  /// ### python docstring
  ///
  /// Immediately unwind the context stack.
  ///
  /// ### python source
  /// ```py
  /// def close(self):
  ///         """Immediately unwind the context stack."""
  ///         self.__exit__(None, None, None)
  /// ```
  Object? close() => getFunction("close").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## enter_context
  ///
  /// ### python docstring
  ///
  /// Enters the supplied context manager.
  ///
  /// If successful, also pushes its __exit__ method as a callback and
  /// returns the result of the __enter__ method.
  ///
  /// ### python source
  /// ```py
  /// def enter_context(self, cm):
  ///         """Enters the supplied context manager.
  ///
  ///         If successful, also pushes its __exit__ method as a callback and
  ///         returns the result of the __enter__ method.
  ///         """
  ///         # We look up the special methods on the type to match the with
  ///         # statement.
  ///         cls = type(cm)
  ///         try:
  ///             _enter = cls.__enter__
  ///             _exit = cls.__exit__
  ///         except AttributeError:
  ///             raise TypeError(f"'{cls.__module__}.{cls.__qualname__}' object does "
  ///                             f"not support the context manager protocol") from None
  ///         result = _enter(cm)
  ///         self._push_cm_exit(cm, _exit)
  ///         return result
  /// ```
  Object? enter_context({
    required Object? cm,
  }) =>
      getFunction("enter_context").call(
        <Object?>[
          cm,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## pop_all
  ///
  /// ### python docstring
  ///
  /// Preserve the context stack by transferring it to a new instance.
  ///
  /// ### python source
  /// ```py
  /// def pop_all(self):
  ///         """Preserve the context stack by transferring it to a new instance."""
  ///         new_stack = type(self)()
  ///         new_stack._exit_callbacks = self._exit_callbacks
  ///         self._exit_callbacks = deque()
  ///         return new_stack
  /// ```
  Object? pop_all() => getFunction("pop_all").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## push
  ///
  /// ### python docstring
  ///
  /// Registers a callback with the standard __exit__ method signature.
  ///
  /// Can suppress exceptions the same way __exit__ method can.
  /// Also accepts any object with an __exit__ method (registering a call
  /// to the method instead of the object itself).
  ///
  /// ### python source
  /// ```py
  /// def push(self, exit):
  ///         """Registers a callback with the standard __exit__ method signature.
  ///
  ///         Can suppress exceptions the same way __exit__ method can.
  ///         Also accepts any object with an __exit__ method (registering a call
  ///         to the method instead of the object itself).
  ///         """
  ///         # We use an unbound method rather than a bound method to follow
  ///         # the standard lookup behaviour for special methods.
  ///         _cb_type = type(exit)
  ///
  ///         try:
  ///             exit_method = _cb_type.__exit__
  ///         except AttributeError:
  ///             # Not a context manager, so assume it's a callable.
  ///             self._push_exit_callback(exit)
  ///         else:
  ///             self._push_cm_exit(exit, exit_method)
  ///         return exit  # Allow use as a decorator.
  /// ```
  Object? push({
    required Object? exit,
  }) =>
      getFunction("push").call(
        <Object?>[
          exit,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## GenericAlias
final class GenericAlias extends PythonClass {
  factory GenericAlias() => PythonFfiDart.instance.importClass(
        "types",
        "GenericAlias",
        GenericAlias.from,
        <Object?>[],
      );

  GenericAlias.from(super.pythonClass) : super.from();
}

/// ## MethodType
final class MethodType extends PythonClass {
  factory MethodType() => PythonFfiDart.instance.importClass(
        "builtins",
        "MethodType",
        MethodType.from,
        <Object?>[],
      );

  MethodType.from(super.pythonClass) : super.from();
}

/// ## ABCMeta
///
/// ### python docstring
///
/// Metaclass for defining Abstract Base Classes (ABCs).
///
/// Use this metaclass to create an ABC.  An ABC can be subclassed
/// directly, and then acts as a mix-in class.  You can also register
/// unrelated concrete classes (even built-in classes) and unrelated
/// ABCs as 'virtual subclasses' -- these and their descendants will
/// be considered subclasses of the registering ABC by the built-in
/// issubclass() function, but the registering ABC won't show up in
/// their MRO (Method Resolution Order) nor will method
/// implementations defined by the registering ABC be callable (not
/// even via super()).
///
/// ### python source
/// ```py
/// class ABCMeta(type):
///         """Metaclass for defining Abstract Base Classes (ABCs).
///
///         Use this metaclass to create an ABC.  An ABC can be subclassed
///         directly, and then acts as a mix-in class.  You can also register
///         unrelated concrete classes (even built-in classes) and unrelated
///         ABCs as 'virtual subclasses' -- these and their descendants will
///         be considered subclasses of the registering ABC by the built-in
///         issubclass() function, but the registering ABC won't show up in
///         their MRO (Method Resolution Order) nor will method
///         implementations defined by the registering ABC be callable (not
///         even via super()).
///         """
///         def __new__(mcls, name, bases, namespace, /, **kwargs):
///             cls = super().__new__(mcls, name, bases, namespace, **kwargs)
///             _abc_init(cls)
///             return cls
///
///         def register(cls, subclass):
///             """Register a virtual subclass of an ABC.
///
///             Returns the subclass, to allow usage as a class decorator.
///             """
///             return _abc_register(cls, subclass)
///
///         def __instancecheck__(cls, instance):
///             """Override for isinstance(instance, cls)."""
///             return _abc_instancecheck(cls, instance)
///
///         def __subclasscheck__(cls, subclass):
///             """Override for issubclass(subclass, cls)."""
///             return _abc_subclasscheck(cls, subclass)
///
///         def _dump_registry(cls, file=None):
///             """Debug helper to print the ABC registry."""
///             print(f"Class: {cls.__module__}.{cls.__qualname__}", file=file)
///             print(f"Inv. counter: {get_cache_token()}", file=file)
///             (_abc_registry, _abc_cache, _abc_negative_cache,
///              _abc_negative_cache_version) = _get_dump(cls)
///             print(f"_abc_registry: {_abc_registry!r}", file=file)
///             print(f"_abc_cache: {_abc_cache!r}", file=file)
///             print(f"_abc_negative_cache: {_abc_negative_cache!r}", file=file)
///             print(f"_abc_negative_cache_version: {_abc_negative_cache_version!r}",
///                   file=file)
///
///         def _abc_registry_clear(cls):
///             """Clear the registry (for debugging or testing)."""
///             _reset_registry(cls)
///
///         def _abc_caches_clear(cls):
///             """Clear the caches (for debugging or testing)."""
///             _reset_caches(cls)
/// ```
final class ABCMeta extends PythonClass {
  factory ABCMeta() => PythonFfiDart.instance.importClass(
        "abc",
        "ABCMeta",
        ABCMeta.from,
        <Object?>[],
      );

  ABCMeta.from(super.pythonClass) : super.from();

  /// ## register
  ///
  /// ### python docstring
  ///
  /// Register a virtual subclass of an ABC.
  ///
  /// Returns the subclass, to allow usage as a class decorator.
  Object? register({
    required Object? subclass,
  }) =>
      getFunction("register").call(
        <Object?>[
          subclass,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## mro (getter)
  Object? get mro => getAttribute("mro");

  /// ## mro (setter)
  set mro(Object? mro) => setAttribute("mro", mro);
}

/// ## abstractclassmethod
///
/// ### python docstring
///
/// A decorator indicating abstract classmethods.
///
/// Deprecated, use 'classmethod' with 'abstractmethod' instead:
///
///     class C(ABC):
///         @classmethod
///         @abstractmethod
///         def my_abstract_classmethod(cls, ...):
///             ...
final class abstractclassmethod extends PythonClass {
  factory abstractclassmethod({
    required Object? callable,
  }) =>
      PythonFfiDart.instance.importClass(
        "abc",
        "abstractclassmethod",
        abstractclassmethod.from,
        <Object?>[
          callable,
        ],
        <String, Object?>{},
      );

  abstractclassmethod.from(super.pythonClass) : super.from();
}

/// ## abstractproperty
///
/// ### python docstring
///
/// A decorator indicating abstract properties.
///
/// Deprecated, use 'property' with 'abstractmethod' instead:
///
///     class C(ABC):
///         @property
///         @abstractmethod
///         def my_abstract_property(self):
///             ...
///
/// ### python source
/// ```py
/// class abstractproperty(property):
///     """A decorator indicating abstract properties.
///
///     Deprecated, use 'property' with 'abstractmethod' instead:
///
///         class C(ABC):
///             @property
///             @abstractmethod
///             def my_abstract_property(self):
///                 ...
///
///     """
///
///     __isabstractmethod__ = True
/// ```
final class abstractproperty extends PythonClass {
  factory abstractproperty() => PythonFfiDart.instance.importClass(
        "abc",
        "abstractproperty",
        abstractproperty.from,
        <Object?>[],
      );

  abstractproperty.from(super.pythonClass) : super.from();

  /// ## fdel (getter)
  Object? get fdel => getAttribute("fdel");

  /// ## fdel (setter)
  set fdel(Object? fdel) => setAttribute("fdel", fdel);

  /// ## fget (getter)
  Object? get fget => getAttribute("fget");

  /// ## fget (setter)
  set fget(Object? fget) => setAttribute("fget", fget);

  /// ## fset (getter)
  Object? get fset => getAttribute("fset");

  /// ## fset (setter)
  set fset(Object? fset) => setAttribute("fset", fset);

  /// ## deleter (getter)
  Object? get deleter => getAttribute("deleter");

  /// ## deleter (setter)
  set deleter(Object? deleter) => setAttribute("deleter", deleter);

  /// ## getter (getter)
  Object? get getter => getAttribute("getter");

  /// ## getter (setter)
  set getter(Object? getter) => setAttribute("getter", getter);

  /// ## setter (getter)
  Object? get setter => getAttribute("setter");

  /// ## setter (setter)
  set setter(Object? setter) => setAttribute("setter", setter);
}

/// ## abstractstaticmethod
///
/// ### python docstring
///
/// A decorator indicating abstract staticmethods.
///
/// Deprecated, use 'staticmethod' with 'abstractmethod' instead:
///
///     class C(ABC):
///         @staticmethod
///         @abstractmethod
///         def my_abstract_staticmethod(...):
///             ...
final class abstractstaticmethod extends PythonClass {
  factory abstractstaticmethod({
    required Object? callable,
  }) =>
      PythonFfiDart.instance.importClass(
        "abc",
        "abstractstaticmethod",
        abstractstaticmethod.from,
        <Object?>[
          callable,
        ],
        <String, Object?>{},
      );

  abstractstaticmethod.from(super.pythonClass) : super.from();
}

/// ## aclosing
///
/// ### python docstring
///
/// Async context manager for safely finalizing an asynchronously cleaned-up
/// resource such as an async generator, calling its ``aclose()`` method.
///
/// Code like this:
///
///     async with aclosing(<module>.fetch(<arguments>)) as agen:
///         <block>
///
/// is equivalent to this:
///
///     agen = <module>.fetch(<arguments>)
///     try:
///         <block>
///     finally:
///         await agen.aclose()
///
/// ### python source
/// ```py
/// class aclosing(AbstractAsyncContextManager):
///     """Async context manager for safely finalizing an asynchronously cleaned-up
///     resource such as an async generator, calling its ``aclose()`` method.
///
///     Code like this:
///
///         async with aclosing(<module>.fetch(<arguments>)) as agen:
///             <block>
///
///     is equivalent to this:
///
///         agen = <module>.fetch(<arguments>)
///         try:
///             <block>
///         finally:
///             await agen.aclose()
///
///     """
///     def __init__(self, thing):
///         self.thing = thing
///     async def __aenter__(self):
///         return self.thing
///     async def __aexit__(self, *exc_info):
///         await self.thing.aclose()
/// ```
final class aclosing extends PythonClass {
  factory aclosing({
    required Object? thing,
  }) =>
      PythonFfiDart.instance.importClass(
        "contextlib",
        "aclosing",
        aclosing.from,
        <Object?>[
          thing,
        ],
        <String, Object?>{},
      );

  aclosing.from(super.pythonClass) : super.from();

  /// ## thing (getter)
  Object? get thing => getAttribute("thing");

  /// ## thing (setter)
  set thing(Object? thing) => setAttribute("thing", thing);
}

/// ## chdir
///
/// ### python docstring
///
/// Non thread-safe context manager to change the current working directory.
///
/// ### python source
/// ```py
/// class chdir(AbstractContextManager):
///     """Non thread-safe context manager to change the current working directory."""
///
///     def __init__(self, path):
///         self.path = path
///         self._old_cwd = []
///
///     def __enter__(self):
///         self._old_cwd.append(os.getcwd())
///         os.chdir(self.path)
///
///     def __exit__(self, *excinfo):
///         os.chdir(self._old_cwd.pop())
/// ```
final class chdir extends PythonClass {
  factory chdir({
    required Object? path,
  }) =>
      PythonFfiDart.instance.importClass(
        "contextlib",
        "chdir",
        chdir.from,
        <Object?>[
          path,
        ],
        <String, Object?>{},
      );

  chdir.from(super.pythonClass) : super.from();

  /// ## path (getter)
  Object? get path => getAttribute("path");

  /// ## path (setter)
  set path(Object? path) => setAttribute("path", path);
}

/// ## closing
///
/// ### python docstring
///
/// Context to automatically close something at the end of a block.
///
/// Code like this:
///
///     with closing(<module>.open(<arguments>)) as f:
///         <block>
///
/// is equivalent to this:
///
///     f = <module>.open(<arguments>)
///     try:
///         <block>
///     finally:
///         f.close()
///
/// ### python source
/// ```py
/// class closing(AbstractContextManager):
///     """Context to automatically close something at the end of a block.
///
///     Code like this:
///
///         with closing(<module>.open(<arguments>)) as f:
///             <block>
///
///     is equivalent to this:
///
///         f = <module>.open(<arguments>)
///         try:
///             <block>
///         finally:
///             f.close()
///
///     """
///     def __init__(self, thing):
///         self.thing = thing
///     def __enter__(self):
///         return self.thing
///     def __exit__(self, *exc_info):
///         self.thing.close()
/// ```
final class closing extends PythonClass {
  factory closing({
    required Object? thing,
  }) =>
      PythonFfiDart.instance.importClass(
        "contextlib",
        "closing",
        closing.from,
        <Object?>[
          thing,
        ],
        <String, Object?>{},
      );

  closing.from(super.pythonClass) : super.from();

  /// ## thing (getter)
  Object? get thing => getAttribute("thing");

  /// ## thing (setter)
  set thing(Object? thing) => setAttribute("thing", thing);
}

/// ## deque
final class deque extends PythonClass {
  factory deque() => PythonFfiDart.instance.importClass(
        "collections",
        "deque",
        deque.from,
        <Object?>[],
      );

  deque.from(super.pythonClass) : super.from();

  /// ## maxlen (getter)
  ///
  /// ### python docstring
  ///
  /// maximum size of a deque or None if unbounded
  Object? get maxlen => getAttribute("maxlen");

  /// ## maxlen (setter)
  ///
  /// ### python docstring
  ///
  /// maximum size of a deque or None if unbounded
  set maxlen(Object? maxlen) => setAttribute("maxlen", maxlen);

  /// ## append (getter)
  Object? get append => getAttribute("append");

  /// ## append (setter)
  set append(Object? append) => setAttribute("append", append);

  /// ## appendleft (getter)
  Object? get appendleft => getAttribute("appendleft");

  /// ## appendleft (setter)
  set appendleft(Object? appendleft) => setAttribute("appendleft", appendleft);

  /// ## clear (getter)
  Object? get clear => getAttribute("clear");

  /// ## clear (setter)
  set clear(Object? clear) => setAttribute("clear", clear);

  /// ## copy (getter)
  Object? get copy => getAttribute("copy");

  /// ## copy (setter)
  set copy(Object? copy) => setAttribute("copy", copy);

  /// ## count (getter)
  Object? get count => getAttribute("count");

  /// ## count (setter)
  set count(Object? count) => setAttribute("count", count);

  /// ## extend (getter)
  Object? get extend => getAttribute("extend");

  /// ## extend (setter)
  set extend(Object? extend) => setAttribute("extend", extend);

  /// ## extendleft (getter)
  Object? get extendleft => getAttribute("extendleft");

  /// ## extendleft (setter)
  set extendleft(Object? extendleft) => setAttribute("extendleft", extendleft);

  /// ## index (getter)
  Object? get index => getAttribute("index");

  /// ## index (setter)
  set index(Object? index) => setAttribute("index", index);

  /// ## insert (getter)
  Object? get insert => getAttribute("insert");

  /// ## insert (setter)
  set insert(Object? insert) => setAttribute("insert", insert);

  /// ## pop (getter)
  Object? get pop => getAttribute("pop");

  /// ## pop (setter)
  set pop(Object? pop) => setAttribute("pop", pop);

  /// ## popleft (getter)
  Object? get popleft => getAttribute("popleft");

  /// ## popleft (setter)
  set popleft(Object? popleft) => setAttribute("popleft", popleft);

  /// ## remove (getter)
  Object? get remove => getAttribute("remove");

  /// ## remove (setter)
  set remove(Object? remove) => setAttribute("remove", remove);

  /// ## reverse (getter)
  Object? get reverse => getAttribute("reverse");

  /// ## reverse (setter)
  set reverse(Object? reverse) => setAttribute("reverse", reverse);

  /// ## rotate (getter)
  Object? get rotate => getAttribute("rotate");

  /// ## rotate (setter)
  set rotate(Object? rotate) => setAttribute("rotate", rotate);
}

/// ## nullcontext
///
/// ### python docstring
///
/// Context manager that does no additional processing.
///
/// Used as a stand-in for a normal context manager, when a particular
/// block of code is only sometimes used with a normal context manager:
///
/// cm = optional_cm if condition else nullcontext()
/// with cm:
///     # Perform operation, using optional_cm if condition is True
///
/// ### python source
/// ```py
/// class nullcontext(AbstractContextManager, AbstractAsyncContextManager):
///     """Context manager that does no additional processing.
///
///     Used as a stand-in for a normal context manager, when a particular
///     block of code is only sometimes used with a normal context manager:
///
///     cm = optional_cm if condition else nullcontext()
///     with cm:
///         # Perform operation, using optional_cm if condition is True
///     """
///
///     def __init__(self, enter_result=None):
///         self.enter_result = enter_result
///
///     def __enter__(self):
///         return self.enter_result
///
///     def __exit__(self, *excinfo):
///         pass
///
///     async def __aenter__(self):
///         return self.enter_result
///
///     async def __aexit__(self, *excinfo):
///         pass
/// ```
final class nullcontext extends PythonClass {
  factory nullcontext({
    Object? enter_result,
  }) =>
      PythonFfiDart.instance.importClass(
        "contextlib",
        "nullcontext",
        nullcontext.from,
        <Object?>[
          enter_result,
        ],
        <String, Object?>{},
      );

  nullcontext.from(super.pythonClass) : super.from();

  /// ## enter_result (getter)
  Object? get enter_result => getAttribute("enter_result");

  /// ## enter_result (setter)
  set enter_result(Object? enter_result) =>
      setAttribute("enter_result", enter_result);
}

/// ## DirEntry
final class DirEntry extends PythonClass {
  factory DirEntry() => PythonFfiDart.instance.importClass(
        "posix",
        "DirEntry",
        DirEntry.from,
        <Object?>[],
      );

  DirEntry.from(super.pythonClass) : super.from();

  /// ## name (getter)
  ///
  /// ### python docstring
  ///
  /// the entry's base filename, relative to scandir() "path" argument
  Object? get name => getAttribute("name");

  /// ## name (setter)
  ///
  /// ### python docstring
  ///
  /// the entry's base filename, relative to scandir() "path" argument
  set name(Object? name) => setAttribute("name", name);

  /// ## path (getter)
  ///
  /// ### python docstring
  ///
  /// the entry's full path name; equivalent to os.path.join(scandir_path, entry.name)
  Object? get path => getAttribute("path");

  /// ## path (setter)
  ///
  /// ### python docstring
  ///
  /// the entry's full path name; equivalent to os.path.join(scandir_path, entry.name)
  set path(Object? path) => setAttribute("path", path);

  /// ## inode (getter)
  Object? get inode => getAttribute("inode");

  /// ## inode (setter)
  set inode(Object? inode) => setAttribute("inode", inode);

  /// ## is_dir (getter)
  Object? get is_dir => getAttribute("is_dir");

  /// ## is_dir (setter)
  set is_dir(Object? is_dir) => setAttribute("is_dir", is_dir);

  /// ## is_file (getter)
  Object? get is_file => getAttribute("is_file");

  /// ## is_file (setter)
  set is_file(Object? is_file) => setAttribute("is_file", is_file);

  /// ## is_symlink (getter)
  Object? get is_symlink => getAttribute("is_symlink");

  /// ## is_symlink (setter)
  set is_symlink(Object? is_symlink) => setAttribute("is_symlink", is_symlink);

  /// ## stat (getter)
  Object? get stat => getAttribute("stat");

  /// ## stat (setter)
  set stat(Object? stat) => setAttribute("stat", stat);
}

/// ## Mapping
///
/// ### python docstring
///
/// A Mapping is a generic container for associating key/value
/// pairs.
///
/// This class provides concrete generic implementations of all
/// methods except for __getitem__, __iter__, and __len__.
final class Mapping extends PythonClass {
  factory Mapping() => PythonFfiDart.instance.importClass(
        "collections.abc",
        "Mapping",
        Mapping.from,
        <Object?>[],
      );

  Mapping.from(super.pythonClass) : super.from();

  /// ## get
  ///
  /// ### python docstring
  ///
  /// D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.
  Object? $get({
    required Object? key,
    Object? $default,
  }) =>
      getFunction("get").call(
        <Object?>[
          key,
          $default,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## items
  ///
  /// ### python docstring
  ///
  /// D.items() -> a set-like object providing a view on D's items
  Object? items() => getFunction("items").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## keys
  ///
  /// ### python docstring
  ///
  /// D.keys() -> a set-like object providing a view on D's keys
  Object? keys() => getFunction("keys").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## values
  ///
  /// ### python docstring
  ///
  /// D.values() -> an object providing a view on D's values
  Object? values() => getFunction("values").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );
}

/// ## MutableMapping
///
/// ### python docstring
///
/// A MutableMapping is a generic container for associating
/// key/value pairs.
///
/// This class provides concrete generic implementations of all
/// methods except for __getitem__, __setitem__, __delitem__,
/// __iter__, and __len__.
final class MutableMapping extends PythonClass {
  factory MutableMapping() => PythonFfiDart.instance.importClass(
        "collections.abc",
        "MutableMapping",
        MutableMapping.from,
        <Object?>[],
      );

  MutableMapping.from(super.pythonClass) : super.from();

  /// ## clear
  ///
  /// ### python docstring
  ///
  /// D.clear() -> None.  Remove all items from D.
  Object? clear() => getFunction("clear").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## get
  ///
  /// ### python docstring
  ///
  /// D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.
  Object? $get({
    required Object? key,
    Object? $default,
  }) =>
      getFunction("get").call(
        <Object?>[
          key,
          $default,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## items
  ///
  /// ### python docstring
  ///
  /// D.items() -> a set-like object providing a view on D's items
  Object? items() => getFunction("items").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## keys
  ///
  /// ### python docstring
  ///
  /// D.keys() -> a set-like object providing a view on D's keys
  Object? keys() => getFunction("keys").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## pop
  ///
  /// ### python docstring
  ///
  /// D.pop(k[,d]) -> v, remove specified key and return the corresponding value.
  /// If key is not found, d is returned if given, otherwise KeyError is raised.
  Object? pop({
    required Object? key,
    Object? $default,
  }) =>
      getFunction("pop").call(
        <Object?>[
          key,
          $default,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## popitem
  ///
  /// ### python docstring
  ///
  /// D.popitem() -> (k, v), remove and return some (key, value) pair
  /// as a 2-tuple; but raise KeyError if D is empty.
  Object? popitem() => getFunction("popitem").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## setdefault
  ///
  /// ### python docstring
  ///
  /// D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D
  Object? setdefault({
    required Object? key,
    Object? $default,
  }) =>
      getFunction("setdefault").call(
        <Object?>[
          key,
          $default,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## update
  ///
  /// ### python docstring
  ///
  /// D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.
  /// If E present and has a .keys() method, does:     for k in E: D[k] = E[k]
  /// If E present and lacks .keys() method, does:     for (k, v) in E: D[k] = v
  /// In either case, this is followed by: for k, v in F.items(): D[k] = v
  Object? update(
    Object? other, {
    Map<String, Object?> kwds = const <String, Object?>{},
  }) =>
      getFunction("update").call(
        <Object?>[
          other,
        ],
        kwargs: <String, Object?>{
          ...kwds,
        },
      );

  /// ## values
  ///
  /// ### python docstring
  ///
  /// D.values() -> an object providing a view on D's values
  Object? values() => getFunction("values").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );
}

/// ## PathLike
///
/// ### python docstring
///
/// Abstract base class for implementing the file system path protocol.
///
/// ### python source
/// ```py
/// class PathLike(abc.ABC):
///
///     """Abstract base class for implementing the file system path protocol."""
///
///     @abc.abstractmethod
///     def __fspath__(self):
///         """Return the file system path representation of the object."""
///         raise NotImplementedError
///
///     @classmethod
///     def __subclasshook__(cls, subclass):
///         if cls is PathLike:
///             return _check_methods(subclass, '__fspath__')
///         return NotImplemented
///
///     __class_getitem__ = classmethod(GenericAlias)
/// ```
final class PathLike extends PythonClass {
  factory PathLike() => PythonFfiDart.instance.importClass(
        "os",
        "PathLike",
        PathLike.from,
        <Object?>[],
      );

  PathLike.from(super.pythonClass) : super.from();
}

/// ## decodekey
final class decodekey extends PythonClass {
  factory decodekey() => PythonFfiDart.instance.importClass(
        "builtins",
        "decodekey",
        decodekey.from,
        <Object?>[],
      );

  decodekey.from(super.pythonClass) : super.from();

  /// ## capitalize (getter)
  Object? get capitalize => getAttribute("capitalize");

  /// ## capitalize (setter)
  set capitalize(Object? capitalize) => setAttribute("capitalize", capitalize);

  /// ## center (getter)
  Object? get center => getAttribute("center");

  /// ## center (setter)
  set center(Object? center) => setAttribute("center", center);

  /// ## count (getter)
  Object? get count => getAttribute("count");

  /// ## count (setter)
  set count(Object? count) => setAttribute("count", count);

  /// ## decode (getter)
  Object? get decode => getAttribute("decode");

  /// ## decode (setter)
  set decode(Object? decode) => setAttribute("decode", decode);

  /// ## endswith (getter)
  Object? get endswith => getAttribute("endswith");

  /// ## endswith (setter)
  set endswith(Object? endswith) => setAttribute("endswith", endswith);

  /// ## expandtabs (getter)
  Object? get expandtabs => getAttribute("expandtabs");

  /// ## expandtabs (setter)
  set expandtabs(Object? expandtabs) => setAttribute("expandtabs", expandtabs);

  /// ## find (getter)
  Object? get find => getAttribute("find");

  /// ## find (setter)
  set find(Object? find) => setAttribute("find", find);

  /// ## hex (getter)
  Object? get hex => getAttribute("hex");

  /// ## hex (setter)
  set hex(Object? hex) => setAttribute("hex", hex);

  /// ## index (getter)
  Object? get index => getAttribute("index");

  /// ## index (setter)
  set index(Object? index) => setAttribute("index", index);

  /// ## isalnum (getter)
  Object? get isalnum => getAttribute("isalnum");

  /// ## isalnum (setter)
  set isalnum(Object? isalnum) => setAttribute("isalnum", isalnum);

  /// ## isalpha (getter)
  Object? get isalpha => getAttribute("isalpha");

  /// ## isalpha (setter)
  set isalpha(Object? isalpha) => setAttribute("isalpha", isalpha);

  /// ## isascii (getter)
  Object? get isascii => getAttribute("isascii");

  /// ## isascii (setter)
  set isascii(Object? isascii) => setAttribute("isascii", isascii);

  /// ## isdigit (getter)
  Object? get isdigit => getAttribute("isdigit");

  /// ## isdigit (setter)
  set isdigit(Object? isdigit) => setAttribute("isdigit", isdigit);

  /// ## islower (getter)
  Object? get islower => getAttribute("islower");

  /// ## islower (setter)
  set islower(Object? islower) => setAttribute("islower", islower);

  /// ## isspace (getter)
  Object? get isspace => getAttribute("isspace");

  /// ## isspace (setter)
  set isspace(Object? isspace) => setAttribute("isspace", isspace);

  /// ## istitle (getter)
  Object? get istitle => getAttribute("istitle");

  /// ## istitle (setter)
  set istitle(Object? istitle) => setAttribute("istitle", istitle);

  /// ## isupper (getter)
  Object? get isupper => getAttribute("isupper");

  /// ## isupper (setter)
  set isupper(Object? isupper) => setAttribute("isupper", isupper);

  /// ## join (getter)
  Object? get join => getAttribute("join");

  /// ## join (setter)
  set join(Object? join) => setAttribute("join", join);

  /// ## ljust (getter)
  Object? get ljust => getAttribute("ljust");

  /// ## ljust (setter)
  set ljust(Object? ljust) => setAttribute("ljust", ljust);

  /// ## lower (getter)
  Object? get lower => getAttribute("lower");

  /// ## lower (setter)
  set lower(Object? lower) => setAttribute("lower", lower);

  /// ## lstrip (getter)
  Object? get lstrip => getAttribute("lstrip");

  /// ## lstrip (setter)
  set lstrip(Object? lstrip) => setAttribute("lstrip", lstrip);

  /// ## partition (getter)
  Object? get partition => getAttribute("partition");

  /// ## partition (setter)
  set partition(Object? partition) => setAttribute("partition", partition);

  /// ## removeprefix (getter)
  Object? get removeprefix => getAttribute("removeprefix");

  /// ## removeprefix (setter)
  set removeprefix(Object? removeprefix) =>
      setAttribute("removeprefix", removeprefix);

  /// ## removesuffix (getter)
  Object? get removesuffix => getAttribute("removesuffix");

  /// ## removesuffix (setter)
  set removesuffix(Object? removesuffix) =>
      setAttribute("removesuffix", removesuffix);

  /// ## replace (getter)
  Object? get replace => getAttribute("replace");

  /// ## replace (setter)
  set replace(Object? replace) => setAttribute("replace", replace);

  /// ## rfind (getter)
  Object? get rfind => getAttribute("rfind");

  /// ## rfind (setter)
  set rfind(Object? rfind) => setAttribute("rfind", rfind);

  /// ## rindex (getter)
  Object? get rindex => getAttribute("rindex");

  /// ## rindex (setter)
  set rindex(Object? rindex) => setAttribute("rindex", rindex);

  /// ## rjust (getter)
  Object? get rjust => getAttribute("rjust");

  /// ## rjust (setter)
  set rjust(Object? rjust) => setAttribute("rjust", rjust);

  /// ## rpartition (getter)
  Object? get rpartition => getAttribute("rpartition");

  /// ## rpartition (setter)
  set rpartition(Object? rpartition) => setAttribute("rpartition", rpartition);

  /// ## rsplit (getter)
  Object? get rsplit => getAttribute("rsplit");

  /// ## rsplit (setter)
  set rsplit(Object? rsplit) => setAttribute("rsplit", rsplit);

  /// ## rstrip (getter)
  Object? get rstrip => getAttribute("rstrip");

  /// ## rstrip (setter)
  set rstrip(Object? rstrip) => setAttribute("rstrip", rstrip);

  /// ## split (getter)
  Object? get split => getAttribute("split");

  /// ## split (setter)
  set split(Object? split) => setAttribute("split", split);

  /// ## splitlines (getter)
  Object? get splitlines => getAttribute("splitlines");

  /// ## splitlines (setter)
  set splitlines(Object? splitlines) => setAttribute("splitlines", splitlines);

  /// ## startswith (getter)
  Object? get startswith => getAttribute("startswith");

  /// ## startswith (setter)
  set startswith(Object? startswith) => setAttribute("startswith", startswith);

  /// ## strip (getter)
  Object? get strip => getAttribute("strip");

  /// ## strip (setter)
  set strip(Object? strip) => setAttribute("strip", strip);

  /// ## swapcase (getter)
  Object? get swapcase => getAttribute("swapcase");

  /// ## swapcase (setter)
  set swapcase(Object? swapcase) => setAttribute("swapcase", swapcase);

  /// ## title (getter)
  Object? get title => getAttribute("title");

  /// ## title (setter)
  set title(Object? title) => setAttribute("title", title);

  /// ## translate (getter)
  Object? get translate => getAttribute("translate");

  /// ## translate (setter)
  set translate(Object? translate) => setAttribute("translate", translate);

  /// ## upper (getter)
  Object? get upper => getAttribute("upper");

  /// ## upper (setter)
  set upper(Object? upper) => setAttribute("upper", upper);

  /// ## zfill (getter)
  Object? get zfill => getAttribute("zfill");

  /// ## zfill (setter)
  set zfill(Object? zfill) => setAttribute("zfill", zfill);
}

/// ## error
final class error extends PythonClass {
  factory error() => PythonFfiDart.instance.importClass(
        "builtins",
        "error",
        error.from,
        <Object?>[],
      );

  error.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## characters_written (getter)
  Object? get characters_written => getAttribute("characters_written");

  /// ## characters_written (setter)
  set characters_written(Object? characters_written) =>
      setAttribute("characters_written", characters_written);

  /// ## errno (getter)
  Object? get errno => getAttribute("errno");

  /// ## errno (setter)
  set errno(Object? errno) => setAttribute("errno", errno);

  /// ## filename (getter)
  Object? get filename => getAttribute("filename");

  /// ## filename (setter)
  set filename(Object? filename) => setAttribute("filename", filename);

  /// ## filename2 (getter)
  Object? get filename2 => getAttribute("filename2");

  /// ## filename2 (setter)
  set filename2(Object? filename2) => setAttribute("filename2", filename2);

  /// ## strerror (getter)
  Object? get strerror => getAttribute("strerror");

  /// ## strerror (setter)
  set strerror(Object? strerror) => setAttribute("strerror", strerror);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## stat_result
final class stat_result extends PythonClass {
  factory stat_result() => PythonFfiDart.instance.importClass(
        "os",
        "stat_result",
        stat_result.from,
        <Object?>[],
      );

  stat_result.from(super.pythonClass) : super.from();

  /// ## st_atime (getter)
  ///
  /// ### python docstring
  ///
  /// time of last access
  Object? get st_atime => getAttribute("st_atime");

  /// ## st_atime (setter)
  ///
  /// ### python docstring
  ///
  /// time of last access
  set st_atime(Object? st_atime) => setAttribute("st_atime", st_atime);

  /// ## st_atime_ns (getter)
  ///
  /// ### python docstring
  ///
  /// time of last access in nanoseconds
  Object? get st_atime_ns => getAttribute("st_atime_ns");

  /// ## st_atime_ns (setter)
  ///
  /// ### python docstring
  ///
  /// time of last access in nanoseconds
  set st_atime_ns(Object? st_atime_ns) =>
      setAttribute("st_atime_ns", st_atime_ns);

  /// ## st_birthtime (getter)
  ///
  /// ### python docstring
  ///
  /// time of creation
  Object? get st_birthtime => getAttribute("st_birthtime");

  /// ## st_birthtime (setter)
  ///
  /// ### python docstring
  ///
  /// time of creation
  set st_birthtime(Object? st_birthtime) =>
      setAttribute("st_birthtime", st_birthtime);

  /// ## st_blksize (getter)
  ///
  /// ### python docstring
  ///
  /// blocksize for filesystem I/O
  Object? get st_blksize => getAttribute("st_blksize");

  /// ## st_blksize (setter)
  ///
  /// ### python docstring
  ///
  /// blocksize for filesystem I/O
  set st_blksize(Object? st_blksize) => setAttribute("st_blksize", st_blksize);

  /// ## st_blocks (getter)
  ///
  /// ### python docstring
  ///
  /// number of blocks allocated
  Object? get st_blocks => getAttribute("st_blocks");

  /// ## st_blocks (setter)
  ///
  /// ### python docstring
  ///
  /// number of blocks allocated
  set st_blocks(Object? st_blocks) => setAttribute("st_blocks", st_blocks);

  /// ## st_ctime (getter)
  ///
  /// ### python docstring
  ///
  /// time of last change
  Object? get st_ctime => getAttribute("st_ctime");

  /// ## st_ctime (setter)
  ///
  /// ### python docstring
  ///
  /// time of last change
  set st_ctime(Object? st_ctime) => setAttribute("st_ctime", st_ctime);

  /// ## st_ctime_ns (getter)
  ///
  /// ### python docstring
  ///
  /// time of last change in nanoseconds
  Object? get st_ctime_ns => getAttribute("st_ctime_ns");

  /// ## st_ctime_ns (setter)
  ///
  /// ### python docstring
  ///
  /// time of last change in nanoseconds
  set st_ctime_ns(Object? st_ctime_ns) =>
      setAttribute("st_ctime_ns", st_ctime_ns);

  /// ## st_dev (getter)
  ///
  /// ### python docstring
  ///
  /// device
  Object? get st_dev => getAttribute("st_dev");

  /// ## st_dev (setter)
  ///
  /// ### python docstring
  ///
  /// device
  set st_dev(Object? st_dev) => setAttribute("st_dev", st_dev);

  /// ## st_flags (getter)
  ///
  /// ### python docstring
  ///
  /// user defined flags for file
  Object? get st_flags => getAttribute("st_flags");

  /// ## st_flags (setter)
  ///
  /// ### python docstring
  ///
  /// user defined flags for file
  set st_flags(Object? st_flags) => setAttribute("st_flags", st_flags);

  /// ## st_gen (getter)
  ///
  /// ### python docstring
  ///
  /// generation number
  Object? get st_gen => getAttribute("st_gen");

  /// ## st_gen (setter)
  ///
  /// ### python docstring
  ///
  /// generation number
  set st_gen(Object? st_gen) => setAttribute("st_gen", st_gen);

  /// ## st_gid (getter)
  ///
  /// ### python docstring
  ///
  /// group ID of owner
  Object? get st_gid => getAttribute("st_gid");

  /// ## st_gid (setter)
  ///
  /// ### python docstring
  ///
  /// group ID of owner
  set st_gid(Object? st_gid) => setAttribute("st_gid", st_gid);

  /// ## st_ino (getter)
  ///
  /// ### python docstring
  ///
  /// inode
  Object? get st_ino => getAttribute("st_ino");

  /// ## st_ino (setter)
  ///
  /// ### python docstring
  ///
  /// inode
  set st_ino(Object? st_ino) => setAttribute("st_ino", st_ino);

  /// ## st_mode (getter)
  ///
  /// ### python docstring
  ///
  /// protection bits
  Object? get st_mode => getAttribute("st_mode");

  /// ## st_mode (setter)
  ///
  /// ### python docstring
  ///
  /// protection bits
  set st_mode(Object? st_mode) => setAttribute("st_mode", st_mode);

  /// ## st_mtime (getter)
  ///
  /// ### python docstring
  ///
  /// time of last modification
  Object? get st_mtime => getAttribute("st_mtime");

  /// ## st_mtime (setter)
  ///
  /// ### python docstring
  ///
  /// time of last modification
  set st_mtime(Object? st_mtime) => setAttribute("st_mtime", st_mtime);

  /// ## st_mtime_ns (getter)
  ///
  /// ### python docstring
  ///
  /// time of last modification in nanoseconds
  Object? get st_mtime_ns => getAttribute("st_mtime_ns");

  /// ## st_mtime_ns (setter)
  ///
  /// ### python docstring
  ///
  /// time of last modification in nanoseconds
  set st_mtime_ns(Object? st_mtime_ns) =>
      setAttribute("st_mtime_ns", st_mtime_ns);

  /// ## st_nlink (getter)
  ///
  /// ### python docstring
  ///
  /// number of hard links
  Object? get st_nlink => getAttribute("st_nlink");

  /// ## st_nlink (setter)
  ///
  /// ### python docstring
  ///
  /// number of hard links
  set st_nlink(Object? st_nlink) => setAttribute("st_nlink", st_nlink);

  /// ## st_rdev (getter)
  ///
  /// ### python docstring
  ///
  /// device type (if inode device)
  Object? get st_rdev => getAttribute("st_rdev");

  /// ## st_rdev (setter)
  ///
  /// ### python docstring
  ///
  /// device type (if inode device)
  set st_rdev(Object? st_rdev) => setAttribute("st_rdev", st_rdev);

  /// ## st_size (getter)
  ///
  /// ### python docstring
  ///
  /// total size, in bytes
  Object? get st_size => getAttribute("st_size");

  /// ## st_size (setter)
  ///
  /// ### python docstring
  ///
  /// total size, in bytes
  set st_size(Object? st_size) => setAttribute("st_size", st_size);

  /// ## st_uid (getter)
  ///
  /// ### python docstring
  ///
  /// user ID of owner
  Object? get st_uid => getAttribute("st_uid");

  /// ## st_uid (setter)
  ///
  /// ### python docstring
  ///
  /// user ID of owner
  set st_uid(Object? st_uid) => setAttribute("st_uid", st_uid);

  /// ## count (getter)
  Object? get count => getAttribute("count");

  /// ## count (setter)
  set count(Object? count) => setAttribute("count", count);

  /// ## index (getter)
  Object? get index => getAttribute("index");

  /// ## index (setter)
  set index(Object? index) => setAttribute("index", index);

  /// ## n_fields (getter)
  Object? get n_fields => getAttribute("n_fields");

  /// ## n_fields (setter)
  set n_fields(Object? n_fields) => setAttribute("n_fields", n_fields);

  /// ## n_sequence_fields (getter)
  Object? get n_sequence_fields => getAttribute("n_sequence_fields");

  /// ## n_sequence_fields (setter)
  set n_sequence_fields(Object? n_sequence_fields) =>
      setAttribute("n_sequence_fields", n_sequence_fields);

  /// ## n_unnamed_fields (getter)
  Object? get n_unnamed_fields => getAttribute("n_unnamed_fields");

  /// ## n_unnamed_fields (setter)
  set n_unnamed_fields(Object? n_unnamed_fields) =>
      setAttribute("n_unnamed_fields", n_unnamed_fields);
}

/// ## statvfs_result
final class statvfs_result extends PythonClass {
  factory statvfs_result() => PythonFfiDart.instance.importClass(
        "os",
        "statvfs_result",
        statvfs_result.from,
        <Object?>[],
      );

  statvfs_result.from(super.pythonClass) : super.from();

  /// ## f_bavail (getter)
  Object? get f_bavail => getAttribute("f_bavail");

  /// ## f_bavail (setter)
  set f_bavail(Object? f_bavail) => setAttribute("f_bavail", f_bavail);

  /// ## f_bfree (getter)
  Object? get f_bfree => getAttribute("f_bfree");

  /// ## f_bfree (setter)
  set f_bfree(Object? f_bfree) => setAttribute("f_bfree", f_bfree);

  /// ## f_blocks (getter)
  Object? get f_blocks => getAttribute("f_blocks");

  /// ## f_blocks (setter)
  set f_blocks(Object? f_blocks) => setAttribute("f_blocks", f_blocks);

  /// ## f_bsize (getter)
  Object? get f_bsize => getAttribute("f_bsize");

  /// ## f_bsize (setter)
  set f_bsize(Object? f_bsize) => setAttribute("f_bsize", f_bsize);

  /// ## f_favail (getter)
  Object? get f_favail => getAttribute("f_favail");

  /// ## f_favail (setter)
  set f_favail(Object? f_favail) => setAttribute("f_favail", f_favail);

  /// ## f_ffree (getter)
  Object? get f_ffree => getAttribute("f_ffree");

  /// ## f_ffree (setter)
  set f_ffree(Object? f_ffree) => setAttribute("f_ffree", f_ffree);

  /// ## f_files (getter)
  Object? get f_files => getAttribute("f_files");

  /// ## f_files (setter)
  set f_files(Object? f_files) => setAttribute("f_files", f_files);

  /// ## f_flag (getter)
  Object? get f_flag => getAttribute("f_flag");

  /// ## f_flag (setter)
  set f_flag(Object? f_flag) => setAttribute("f_flag", f_flag);

  /// ## f_frsize (getter)
  Object? get f_frsize => getAttribute("f_frsize");

  /// ## f_frsize (setter)
  set f_frsize(Object? f_frsize) => setAttribute("f_frsize", f_frsize);

  /// ## f_fsid (getter)
  Object? get f_fsid => getAttribute("f_fsid");

  /// ## f_fsid (setter)
  set f_fsid(Object? f_fsid) => setAttribute("f_fsid", f_fsid);

  /// ## f_namemax (getter)
  Object? get f_namemax => getAttribute("f_namemax");

  /// ## f_namemax (setter)
  set f_namemax(Object? f_namemax) => setAttribute("f_namemax", f_namemax);

  /// ## count (getter)
  Object? get count => getAttribute("count");

  /// ## count (setter)
  set count(Object? count) => setAttribute("count", count);

  /// ## index (getter)
  Object? get index => getAttribute("index");

  /// ## index (setter)
  set index(Object? index) => setAttribute("index", index);

  /// ## n_fields (getter)
  Object? get n_fields => getAttribute("n_fields");

  /// ## n_fields (setter)
  set n_fields(Object? n_fields) => setAttribute("n_fields", n_fields);

  /// ## n_sequence_fields (getter)
  Object? get n_sequence_fields => getAttribute("n_sequence_fields");

  /// ## n_sequence_fields (setter)
  set n_sequence_fields(Object? n_sequence_fields) =>
      setAttribute("n_sequence_fields", n_sequence_fields);

  /// ## n_unnamed_fields (getter)
  Object? get n_unnamed_fields => getAttribute("n_unnamed_fields");

  /// ## n_unnamed_fields (setter)
  set n_unnamed_fields(Object? n_unnamed_fields) =>
      setAttribute("n_unnamed_fields", n_unnamed_fields);
}

/// ## terminal_size
final class terminal_size extends PythonClass {
  factory terminal_size() => PythonFfiDart.instance.importClass(
        "os",
        "terminal_size",
        terminal_size.from,
        <Object?>[],
      );

  terminal_size.from(super.pythonClass) : super.from();

  /// ## columns (getter)
  ///
  /// ### python docstring
  ///
  /// width of the terminal window in characters
  Object? get columns => getAttribute("columns");

  /// ## columns (setter)
  ///
  /// ### python docstring
  ///
  /// width of the terminal window in characters
  set columns(Object? columns) => setAttribute("columns", columns);

  /// ## lines (getter)
  ///
  /// ### python docstring
  ///
  /// height of the terminal window in characters
  Object? get lines => getAttribute("lines");

  /// ## lines (setter)
  ///
  /// ### python docstring
  ///
  /// height of the terminal window in characters
  set lines(Object? lines) => setAttribute("lines", lines);

  /// ## count (getter)
  Object? get count => getAttribute("count");

  /// ## count (setter)
  set count(Object? count) => setAttribute("count", count);

  /// ## index (getter)
  Object? get index => getAttribute("index");

  /// ## index (setter)
  set index(Object? index) => setAttribute("index", index);

  /// ## n_fields (getter)
  Object? get n_fields => getAttribute("n_fields");

  /// ## n_fields (setter)
  set n_fields(Object? n_fields) => setAttribute("n_fields", n_fields);

  /// ## n_sequence_fields (getter)
  Object? get n_sequence_fields => getAttribute("n_sequence_fields");

  /// ## n_sequence_fields (setter)
  set n_sequence_fields(Object? n_sequence_fields) =>
      setAttribute("n_sequence_fields", n_sequence_fields);

  /// ## n_unnamed_fields (getter)
  Object? get n_unnamed_fields => getAttribute("n_unnamed_fields");

  /// ## n_unnamed_fields (setter)
  set n_unnamed_fields(Object? n_unnamed_fields) =>
      setAttribute("n_unnamed_fields", n_unnamed_fields);
}

/// ## times_result
final class times_result extends PythonClass {
  factory times_result() => PythonFfiDart.instance.importClass(
        "posix",
        "times_result",
        times_result.from,
        <Object?>[],
      );

  times_result.from(super.pythonClass) : super.from();

  /// ## children_system (getter)
  ///
  /// ### python docstring
  ///
  /// system time of children
  Object? get children_system => getAttribute("children_system");

  /// ## children_system (setter)
  ///
  /// ### python docstring
  ///
  /// system time of children
  set children_system(Object? children_system) =>
      setAttribute("children_system", children_system);

  /// ## children_user (getter)
  ///
  /// ### python docstring
  ///
  /// user time of children
  Object? get children_user => getAttribute("children_user");

  /// ## children_user (setter)
  ///
  /// ### python docstring
  ///
  /// user time of children
  set children_user(Object? children_user) =>
      setAttribute("children_user", children_user);

  /// ## elapsed (getter)
  ///
  /// ### python docstring
  ///
  /// elapsed time since an arbitrary point in the past
  Object? get elapsed => getAttribute("elapsed");

  /// ## elapsed (setter)
  ///
  /// ### python docstring
  ///
  /// elapsed time since an arbitrary point in the past
  set elapsed(Object? elapsed) => setAttribute("elapsed", elapsed);

  /// ## system (getter)
  ///
  /// ### python docstring
  ///
  /// system time
  Object? get system => getAttribute("system");

  /// ## system (setter)
  ///
  /// ### python docstring
  ///
  /// system time
  set system(Object? system) => setAttribute("system", system);

  /// ## user (getter)
  ///
  /// ### python docstring
  ///
  /// user time
  Object? get user => getAttribute("user");

  /// ## user (setter)
  ///
  /// ### python docstring
  ///
  /// user time
  set user(Object? user) => setAttribute("user", user);

  /// ## count (getter)
  Object? get count => getAttribute("count");

  /// ## count (setter)
  set count(Object? count) => setAttribute("count", count);

  /// ## index (getter)
  Object? get index => getAttribute("index");

  /// ## index (setter)
  set index(Object? index) => setAttribute("index", index);

  /// ## n_fields (getter)
  Object? get n_fields => getAttribute("n_fields");

  /// ## n_fields (setter)
  set n_fields(Object? n_fields) => setAttribute("n_fields", n_fields);

  /// ## n_sequence_fields (getter)
  Object? get n_sequence_fields => getAttribute("n_sequence_fields");

  /// ## n_sequence_fields (setter)
  set n_sequence_fields(Object? n_sequence_fields) =>
      setAttribute("n_sequence_fields", n_sequence_fields);

  /// ## n_unnamed_fields (getter)
  Object? get n_unnamed_fields => getAttribute("n_unnamed_fields");

  /// ## n_unnamed_fields (setter)
  set n_unnamed_fields(Object? n_unnamed_fields) =>
      setAttribute("n_unnamed_fields", n_unnamed_fields);
}

/// ## uname_result
final class uname_result extends PythonClass {
  factory uname_result() => PythonFfiDart.instance.importClass(
        "posix",
        "uname_result",
        uname_result.from,
        <Object?>[],
      );

  uname_result.from(super.pythonClass) : super.from();

  /// ## machine (getter)
  ///
  /// ### python docstring
  ///
  /// hardware identifier
  Object? get machine => getAttribute("machine");

  /// ## machine (setter)
  ///
  /// ### python docstring
  ///
  /// hardware identifier
  set machine(Object? machine) => setAttribute("machine", machine);

  /// ## nodename (getter)
  ///
  /// ### python docstring
  ///
  /// name of machine on network (implementation-defined)
  Object? get nodename => getAttribute("nodename");

  /// ## nodename (setter)
  ///
  /// ### python docstring
  ///
  /// name of machine on network (implementation-defined)
  set nodename(Object? nodename) => setAttribute("nodename", nodename);

  /// ## release (getter)
  ///
  /// ### python docstring
  ///
  /// operating system release
  Object? get release => getAttribute("release");

  /// ## release (setter)
  ///
  /// ### python docstring
  ///
  /// operating system release
  set release(Object? release) => setAttribute("release", release);

  /// ## sysname (getter)
  ///
  /// ### python docstring
  ///
  /// operating system name
  Object? get sysname => getAttribute("sysname");

  /// ## sysname (setter)
  ///
  /// ### python docstring
  ///
  /// operating system name
  set sysname(Object? sysname) => setAttribute("sysname", sysname);

  /// ## version (getter)
  ///
  /// ### python docstring
  ///
  /// operating system version
  Object? get version => getAttribute("version");

  /// ## version (setter)
  ///
  /// ### python docstring
  ///
  /// operating system version
  set version(Object? version) => setAttribute("version", version);

  /// ## count (getter)
  Object? get count => getAttribute("count");

  /// ## count (setter)
  set count(Object? count) => setAttribute("count", count);

  /// ## index (getter)
  Object? get index => getAttribute("index");

  /// ## index (setter)
  set index(Object? index) => setAttribute("index", index);

  /// ## n_fields (getter)
  Object? get n_fields => getAttribute("n_fields");

  /// ## n_fields (setter)
  set n_fields(Object? n_fields) => setAttribute("n_fields", n_fields);

  /// ## n_sequence_fields (getter)
  Object? get n_sequence_fields => getAttribute("n_sequence_fields");

  /// ## n_sequence_fields (setter)
  set n_sequence_fields(Object? n_sequence_fields) =>
      setAttribute("n_sequence_fields", n_sequence_fields);

  /// ## n_unnamed_fields (getter)
  Object? get n_unnamed_fields => getAttribute("n_unnamed_fields");

  /// ## n_unnamed_fields (setter)
  set n_unnamed_fields(Object? n_unnamed_fields) =>
      setAttribute("n_unnamed_fields", n_unnamed_fields);
}

/// ## redirect_stderr
///
/// ### python docstring
///
/// Context manager for temporarily redirecting stderr to another file.
///
/// ### python source
/// ```py
/// class redirect_stderr(_RedirectStream):
///     """Context manager for temporarily redirecting stderr to another file."""
///
///     _stream = "stderr"
/// ```
final class redirect_stderr extends PythonClass {
  factory redirect_stderr({
    required Object? new_target,
  }) =>
      PythonFfiDart.instance.importClass(
        "contextlib",
        "redirect_stderr",
        redirect_stderr.from,
        <Object?>[
          new_target,
        ],
        <String, Object?>{},
      );

  redirect_stderr.from(super.pythonClass) : super.from();
}

/// ## redirect_stdout
///
/// ### python docstring
///
/// Context manager for temporarily redirecting stdout to another file.
///
/// # How to send help() to stderr
/// with redirect_stdout(sys.stderr):
///     help(dir)
///
/// # How to write help() to a file
/// with open('help.txt', 'w') as f:
///     with redirect_stdout(f):
///         help(pow)
///
/// ### python source
/// ```py
/// class redirect_stdout(_RedirectStream):
///     """Context manager for temporarily redirecting stdout to another file.
///
///         # How to send help() to stderr
///         with redirect_stdout(sys.stderr):
///             help(dir)
///
///         # How to write help() to a file
///         with open('help.txt', 'w') as f:
///             with redirect_stdout(f):
///                 help(pow)
///     """
///
///     _stream = "stdout"
/// ```
final class redirect_stdout extends PythonClass {
  factory redirect_stdout({
    required Object? new_target,
  }) =>
      PythonFfiDart.instance.importClass(
        "contextlib",
        "redirect_stdout",
        redirect_stdout.from,
        <Object?>[
          new_target,
        ],
        <String, Object?>{},
      );

  redirect_stdout.from(super.pythonClass) : super.from();
}

/// ## suppress
///
/// ### python docstring
///
/// Context manager to suppress specified exceptions
///
/// After the exception is suppressed, execution proceeds with the next
/// statement following the with statement.
///
///      with suppress(FileNotFoundError):
///          os.remove(somefile)
///      # Execution still resumes here if the file was already removed
///
/// ### python source
/// ```py
/// class suppress(AbstractContextManager):
///     """Context manager to suppress specified exceptions
///
///     After the exception is suppressed, execution proceeds with the next
///     statement following the with statement.
///
///          with suppress(FileNotFoundError):
///              os.remove(somefile)
///          # Execution still resumes here if the file was already removed
///     """
///
///     def __init__(self, *exceptions):
///         self._exceptions = exceptions
///
///     def __enter__(self):
///         pass
///
///     def __exit__(self, exctype, excinst, exctb):
///         # Unlike isinstance and issubclass, CPython exception handling
///         # currently only looks at the concrete type hierarchy (ignoring
///         # the instance and subclass checking hooks). While Guido considers
///         # that a bug rather than a feature, it's a fairly hard one to fix
///         # due to various internal implementation details. suppress provides
///         # the simpler issubclass based semantics, rather than trying to
///         # exactly reproduce the limitations of the CPython interpreter.
///         #
///         # See http://bugs.python.org/issue12029 for more details
///         return exctype is not None and issubclass(exctype, self._exceptions)
/// ```
final class suppress extends PythonClass {
  factory suppress({
    List<Object?> exceptions = const <Object?>[],
  }) =>
      PythonFfiDart.instance.importClass(
        "contextlib",
        "suppress",
        suppress.from,
        <Object?>[
          ...exceptions,
        ],
        <String, Object?>{},
      );

  suppress.from(super.pythonClass) : super.from();
}

/// ## BlockingIOError
final class BlockingIOError extends PythonClass {
  factory BlockingIOError() => PythonFfiDart.instance.importClass(
        "builtins",
        "BlockingIOError",
        BlockingIOError.from,
        <Object?>[],
      );

  BlockingIOError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## characters_written (getter)
  Object? get characters_written => getAttribute("characters_written");

  /// ## characters_written (setter)
  set characters_written(Object? characters_written) =>
      setAttribute("characters_written", characters_written);

  /// ## errno (getter)
  Object? get errno => getAttribute("errno");

  /// ## errno (setter)
  set errno(Object? errno) => setAttribute("errno", errno);

  /// ## filename (getter)
  Object? get filename => getAttribute("filename");

  /// ## filename (setter)
  set filename(Object? filename) => setAttribute("filename", filename);

  /// ## filename2 (getter)
  Object? get filename2 => getAttribute("filename2");

  /// ## filename2 (setter)
  set filename2(Object? filename2) => setAttribute("filename2", filename2);

  /// ## strerror (getter)
  Object? get strerror => getAttribute("strerror");

  /// ## strerror (setter)
  set strerror(Object? strerror) => setAttribute("strerror", strerror);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## BufferedIOBase
///
/// ### python source
/// ```py
/// class BufferedIOBase(_io._BufferedIOBase, IOBase):
///     __doc__ = _io._BufferedIOBase.__doc__
/// ```
final class BufferedIOBase extends PythonClass {
  factory BufferedIOBase() => PythonFfiDart.instance.importClass(
        "io",
        "BufferedIOBase",
        BufferedIOBase.from,
        <Object?>[],
      );

  BufferedIOBase.from(super.pythonClass) : super.from();

  /// ## closed (getter)
  Object? get closed => getAttribute("closed");

  /// ## closed (setter)
  set closed(Object? closed) => setAttribute("closed", closed);

  /// ## close (getter)
  Object? get close => getAttribute("close");

  /// ## close (setter)
  set close(Object? close) => setAttribute("close", close);

  /// ## detach (getter)
  Object? get detach => getAttribute("detach");

  /// ## detach (setter)
  set detach(Object? detach) => setAttribute("detach", detach);

  /// ## fileno (getter)
  Object? get fileno => getAttribute("fileno");

  /// ## fileno (setter)
  set fileno(Object? fileno) => setAttribute("fileno", fileno);

  /// ## flush (getter)
  Object? get flush => getAttribute("flush");

  /// ## flush (setter)
  set flush(Object? flush) => setAttribute("flush", flush);

  /// ## isatty (getter)
  Object? get isatty => getAttribute("isatty");

  /// ## isatty (setter)
  set isatty(Object? isatty) => setAttribute("isatty", isatty);

  /// ## read (getter)
  Object? get read => getAttribute("read");

  /// ## read (setter)
  set read(Object? read) => setAttribute("read", read);

  /// ## read1 (getter)
  Object? get read1 => getAttribute("read1");

  /// ## read1 (setter)
  set read1(Object? read1) => setAttribute("read1", read1);

  /// ## readable (getter)
  Object? get readable => getAttribute("readable");

  /// ## readable (setter)
  set readable(Object? readable) => setAttribute("readable", readable);

  /// ## readinto (getter)
  Object? get readinto => getAttribute("readinto");

  /// ## readinto (setter)
  set readinto(Object? readinto) => setAttribute("readinto", readinto);

  /// ## readinto1 (getter)
  Object? get readinto1 => getAttribute("readinto1");

  /// ## readinto1 (setter)
  set readinto1(Object? readinto1) => setAttribute("readinto1", readinto1);

  /// ## readline (getter)
  Object? get readline => getAttribute("readline");

  /// ## readline (setter)
  set readline(Object? readline) => setAttribute("readline", readline);

  /// ## readlines (getter)
  Object? get readlines => getAttribute("readlines");

  /// ## readlines (setter)
  set readlines(Object? readlines) => setAttribute("readlines", readlines);

  /// ## seek (getter)
  Object? get seek => getAttribute("seek");

  /// ## seek (setter)
  set seek(Object? seek) => setAttribute("seek", seek);

  /// ## seekable (getter)
  Object? get seekable => getAttribute("seekable");

  /// ## seekable (setter)
  set seekable(Object? seekable) => setAttribute("seekable", seekable);

  /// ## tell (getter)
  Object? get tell => getAttribute("tell");

  /// ## tell (setter)
  set tell(Object? tell) => setAttribute("tell", tell);

  /// ## truncate (getter)
  Object? get truncate => getAttribute("truncate");

  /// ## truncate (setter)
  set truncate(Object? truncate) => setAttribute("truncate", truncate);

  /// ## writable (getter)
  Object? get writable => getAttribute("writable");

  /// ## writable (setter)
  set writable(Object? writable) => setAttribute("writable", writable);

  /// ## write (getter)
  Object? get write => getAttribute("write");

  /// ## write (setter)
  set write(Object? write) => setAttribute("write", write);

  /// ## writelines (getter)
  Object? get writelines => getAttribute("writelines");

  /// ## writelines (setter)
  set writelines(Object? writelines) => setAttribute("writelines", writelines);
}

/// ## BufferedRWPair
final class BufferedRWPair extends PythonClass {
  factory BufferedRWPair() => PythonFfiDart.instance.importClass(
        "io",
        "BufferedRWPair",
        BufferedRWPair.from,
        <Object?>[],
      );

  BufferedRWPair.from(super.pythonClass) : super.from();

  /// ## closed (getter)
  Object? get closed => getAttribute("closed");

  /// ## closed (setter)
  set closed(Object? closed) => setAttribute("closed", closed);

  /// ## close (getter)
  Object? get close => getAttribute("close");

  /// ## close (setter)
  set close(Object? close) => setAttribute("close", close);

  /// ## detach (getter)
  Object? get detach => getAttribute("detach");

  /// ## detach (setter)
  set detach(Object? detach) => setAttribute("detach", detach);

  /// ## fileno (getter)
  Object? get fileno => getAttribute("fileno");

  /// ## fileno (setter)
  set fileno(Object? fileno) => setAttribute("fileno", fileno);

  /// ## flush (getter)
  Object? get flush => getAttribute("flush");

  /// ## flush (setter)
  set flush(Object? flush) => setAttribute("flush", flush);

  /// ## isatty (getter)
  Object? get isatty => getAttribute("isatty");

  /// ## isatty (setter)
  set isatty(Object? isatty) => setAttribute("isatty", isatty);

  /// ## peek (getter)
  Object? get peek => getAttribute("peek");

  /// ## peek (setter)
  set peek(Object? peek) => setAttribute("peek", peek);

  /// ## read (getter)
  Object? get read => getAttribute("read");

  /// ## read (setter)
  set read(Object? read) => setAttribute("read", read);

  /// ## read1 (getter)
  Object? get read1 => getAttribute("read1");

  /// ## read1 (setter)
  set read1(Object? read1) => setAttribute("read1", read1);

  /// ## readable (getter)
  Object? get readable => getAttribute("readable");

  /// ## readable (setter)
  set readable(Object? readable) => setAttribute("readable", readable);

  /// ## readinto (getter)
  Object? get readinto => getAttribute("readinto");

  /// ## readinto (setter)
  set readinto(Object? readinto) => setAttribute("readinto", readinto);

  /// ## readinto1 (getter)
  Object? get readinto1 => getAttribute("readinto1");

  /// ## readinto1 (setter)
  set readinto1(Object? readinto1) => setAttribute("readinto1", readinto1);

  /// ## readline (getter)
  Object? get readline => getAttribute("readline");

  /// ## readline (setter)
  set readline(Object? readline) => setAttribute("readline", readline);

  /// ## readlines (getter)
  Object? get readlines => getAttribute("readlines");

  /// ## readlines (setter)
  set readlines(Object? readlines) => setAttribute("readlines", readlines);

  /// ## seek (getter)
  Object? get seek => getAttribute("seek");

  /// ## seek (setter)
  set seek(Object? seek) => setAttribute("seek", seek);

  /// ## seekable (getter)
  Object? get seekable => getAttribute("seekable");

  /// ## seekable (setter)
  set seekable(Object? seekable) => setAttribute("seekable", seekable);

  /// ## tell (getter)
  Object? get tell => getAttribute("tell");

  /// ## tell (setter)
  set tell(Object? tell) => setAttribute("tell", tell);

  /// ## truncate (getter)
  Object? get truncate => getAttribute("truncate");

  /// ## truncate (setter)
  set truncate(Object? truncate) => setAttribute("truncate", truncate);

  /// ## writable (getter)
  Object? get writable => getAttribute("writable");

  /// ## writable (setter)
  set writable(Object? writable) => setAttribute("writable", writable);

  /// ## write (getter)
  Object? get write => getAttribute("write");

  /// ## write (setter)
  set write(Object? write) => setAttribute("write", write);

  /// ## writelines (getter)
  Object? get writelines => getAttribute("writelines");

  /// ## writelines (setter)
  set writelines(Object? writelines) => setAttribute("writelines", writelines);
}

/// ## BufferedRandom
final class BufferedRandom extends PythonClass {
  factory BufferedRandom() => PythonFfiDart.instance.importClass(
        "io",
        "BufferedRandom",
        BufferedRandom.from,
        <Object?>[],
      );

  BufferedRandom.from(super.pythonClass) : super.from();

  /// ## closed (getter)
  Object? get closed => getAttribute("closed");

  /// ## closed (setter)
  set closed(Object? closed) => setAttribute("closed", closed);

  /// ## mode (getter)
  Object? get mode => getAttribute("mode");

  /// ## mode (setter)
  set mode(Object? mode) => setAttribute("mode", mode);

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);

  /// ## raw (getter)
  Object? get raw => getAttribute("raw");

  /// ## raw (setter)
  set raw(Object? raw) => setAttribute("raw", raw);

  /// ## close (getter)
  Object? get close => getAttribute("close");

  /// ## close (setter)
  set close(Object? close) => setAttribute("close", close);

  /// ## detach (getter)
  Object? get detach => getAttribute("detach");

  /// ## detach (setter)
  set detach(Object? detach) => setAttribute("detach", detach);

  /// ## fileno (getter)
  Object? get fileno => getAttribute("fileno");

  /// ## fileno (setter)
  set fileno(Object? fileno) => setAttribute("fileno", fileno);

  /// ## flush (getter)
  Object? get flush => getAttribute("flush");

  /// ## flush (setter)
  set flush(Object? flush) => setAttribute("flush", flush);

  /// ## isatty (getter)
  Object? get isatty => getAttribute("isatty");

  /// ## isatty (setter)
  set isatty(Object? isatty) => setAttribute("isatty", isatty);

  /// ## peek (getter)
  Object? get peek => getAttribute("peek");

  /// ## peek (setter)
  set peek(Object? peek) => setAttribute("peek", peek);

  /// ## read (getter)
  Object? get read => getAttribute("read");

  /// ## read (setter)
  set read(Object? read) => setAttribute("read", read);

  /// ## read1 (getter)
  Object? get read1 => getAttribute("read1");

  /// ## read1 (setter)
  set read1(Object? read1) => setAttribute("read1", read1);

  /// ## readable (getter)
  Object? get readable => getAttribute("readable");

  /// ## readable (setter)
  set readable(Object? readable) => setAttribute("readable", readable);

  /// ## readinto (getter)
  Object? get readinto => getAttribute("readinto");

  /// ## readinto (setter)
  set readinto(Object? readinto) => setAttribute("readinto", readinto);

  /// ## readinto1 (getter)
  Object? get readinto1 => getAttribute("readinto1");

  /// ## readinto1 (setter)
  set readinto1(Object? readinto1) => setAttribute("readinto1", readinto1);

  /// ## readline (getter)
  Object? get readline => getAttribute("readline");

  /// ## readline (setter)
  set readline(Object? readline) => setAttribute("readline", readline);

  /// ## readlines (getter)
  Object? get readlines => getAttribute("readlines");

  /// ## readlines (setter)
  set readlines(Object? readlines) => setAttribute("readlines", readlines);

  /// ## seek (getter)
  Object? get seek => getAttribute("seek");

  /// ## seek (setter)
  set seek(Object? seek) => setAttribute("seek", seek);

  /// ## seekable (getter)
  Object? get seekable => getAttribute("seekable");

  /// ## seekable (setter)
  set seekable(Object? seekable) => setAttribute("seekable", seekable);

  /// ## tell (getter)
  Object? get tell => getAttribute("tell");

  /// ## tell (setter)
  set tell(Object? tell) => setAttribute("tell", tell);

  /// ## truncate (getter)
  Object? get truncate => getAttribute("truncate");

  /// ## truncate (setter)
  set truncate(Object? truncate) => setAttribute("truncate", truncate);

  /// ## writable (getter)
  Object? get writable => getAttribute("writable");

  /// ## writable (setter)
  set writable(Object? writable) => setAttribute("writable", writable);

  /// ## write (getter)
  Object? get write => getAttribute("write");

  /// ## write (setter)
  set write(Object? write) => setAttribute("write", write);

  /// ## writelines (getter)
  Object? get writelines => getAttribute("writelines");

  /// ## writelines (setter)
  set writelines(Object? writelines) => setAttribute("writelines", writelines);
}

/// ## BufferedReader
final class BufferedReader extends PythonClass {
  factory BufferedReader() => PythonFfiDart.instance.importClass(
        "io",
        "BufferedReader",
        BufferedReader.from,
        <Object?>[],
      );

  BufferedReader.from(super.pythonClass) : super.from();

  /// ## closed (getter)
  Object? get closed => getAttribute("closed");

  /// ## closed (setter)
  set closed(Object? closed) => setAttribute("closed", closed);

  /// ## mode (getter)
  Object? get mode => getAttribute("mode");

  /// ## mode (setter)
  set mode(Object? mode) => setAttribute("mode", mode);

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);

  /// ## raw (getter)
  Object? get raw => getAttribute("raw");

  /// ## raw (setter)
  set raw(Object? raw) => setAttribute("raw", raw);

  /// ## close (getter)
  Object? get close => getAttribute("close");

  /// ## close (setter)
  set close(Object? close) => setAttribute("close", close);

  /// ## detach (getter)
  Object? get detach => getAttribute("detach");

  /// ## detach (setter)
  set detach(Object? detach) => setAttribute("detach", detach);

  /// ## fileno (getter)
  Object? get fileno => getAttribute("fileno");

  /// ## fileno (setter)
  set fileno(Object? fileno) => setAttribute("fileno", fileno);

  /// ## flush (getter)
  Object? get flush => getAttribute("flush");

  /// ## flush (setter)
  set flush(Object? flush) => setAttribute("flush", flush);

  /// ## isatty (getter)
  Object? get isatty => getAttribute("isatty");

  /// ## isatty (setter)
  set isatty(Object? isatty) => setAttribute("isatty", isatty);

  /// ## peek (getter)
  Object? get peek => getAttribute("peek");

  /// ## peek (setter)
  set peek(Object? peek) => setAttribute("peek", peek);

  /// ## read (getter)
  Object? get read => getAttribute("read");

  /// ## read (setter)
  set read(Object? read) => setAttribute("read", read);

  /// ## read1 (getter)
  Object? get read1 => getAttribute("read1");

  /// ## read1 (setter)
  set read1(Object? read1) => setAttribute("read1", read1);

  /// ## readable (getter)
  Object? get readable => getAttribute("readable");

  /// ## readable (setter)
  set readable(Object? readable) => setAttribute("readable", readable);

  /// ## readinto (getter)
  Object? get readinto => getAttribute("readinto");

  /// ## readinto (setter)
  set readinto(Object? readinto) => setAttribute("readinto", readinto);

  /// ## readinto1 (getter)
  Object? get readinto1 => getAttribute("readinto1");

  /// ## readinto1 (setter)
  set readinto1(Object? readinto1) => setAttribute("readinto1", readinto1);

  /// ## readline (getter)
  Object? get readline => getAttribute("readline");

  /// ## readline (setter)
  set readline(Object? readline) => setAttribute("readline", readline);

  /// ## readlines (getter)
  Object? get readlines => getAttribute("readlines");

  /// ## readlines (setter)
  set readlines(Object? readlines) => setAttribute("readlines", readlines);

  /// ## seek (getter)
  Object? get seek => getAttribute("seek");

  /// ## seek (setter)
  set seek(Object? seek) => setAttribute("seek", seek);

  /// ## seekable (getter)
  Object? get seekable => getAttribute("seekable");

  /// ## seekable (setter)
  set seekable(Object? seekable) => setAttribute("seekable", seekable);

  /// ## tell (getter)
  Object? get tell => getAttribute("tell");

  /// ## tell (setter)
  set tell(Object? tell) => setAttribute("tell", tell);

  /// ## truncate (getter)
  Object? get truncate => getAttribute("truncate");

  /// ## truncate (setter)
  set truncate(Object? truncate) => setAttribute("truncate", truncate);

  /// ## writable (getter)
  Object? get writable => getAttribute("writable");

  /// ## writable (setter)
  set writable(Object? writable) => setAttribute("writable", writable);

  /// ## write (getter)
  Object? get write => getAttribute("write");

  /// ## write (setter)
  set write(Object? write) => setAttribute("write", write);

  /// ## writelines (getter)
  Object? get writelines => getAttribute("writelines");

  /// ## writelines (setter)
  set writelines(Object? writelines) => setAttribute("writelines", writelines);
}

/// ## BufferedWriter
final class BufferedWriter extends PythonClass {
  factory BufferedWriter() => PythonFfiDart.instance.importClass(
        "io",
        "BufferedWriter",
        BufferedWriter.from,
        <Object?>[],
      );

  BufferedWriter.from(super.pythonClass) : super.from();

  /// ## closed (getter)
  Object? get closed => getAttribute("closed");

  /// ## closed (setter)
  set closed(Object? closed) => setAttribute("closed", closed);

  /// ## mode (getter)
  Object? get mode => getAttribute("mode");

  /// ## mode (setter)
  set mode(Object? mode) => setAttribute("mode", mode);

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);

  /// ## raw (getter)
  Object? get raw => getAttribute("raw");

  /// ## raw (setter)
  set raw(Object? raw) => setAttribute("raw", raw);

  /// ## close (getter)
  Object? get close => getAttribute("close");

  /// ## close (setter)
  set close(Object? close) => setAttribute("close", close);

  /// ## detach (getter)
  Object? get detach => getAttribute("detach");

  /// ## detach (setter)
  set detach(Object? detach) => setAttribute("detach", detach);

  /// ## fileno (getter)
  Object? get fileno => getAttribute("fileno");

  /// ## fileno (setter)
  set fileno(Object? fileno) => setAttribute("fileno", fileno);

  /// ## flush (getter)
  Object? get flush => getAttribute("flush");

  /// ## flush (setter)
  set flush(Object? flush) => setAttribute("flush", flush);

  /// ## isatty (getter)
  Object? get isatty => getAttribute("isatty");

  /// ## isatty (setter)
  set isatty(Object? isatty) => setAttribute("isatty", isatty);

  /// ## read (getter)
  Object? get read => getAttribute("read");

  /// ## read (setter)
  set read(Object? read) => setAttribute("read", read);

  /// ## read1 (getter)
  Object? get read1 => getAttribute("read1");

  /// ## read1 (setter)
  set read1(Object? read1) => setAttribute("read1", read1);

  /// ## readable (getter)
  Object? get readable => getAttribute("readable");

  /// ## readable (setter)
  set readable(Object? readable) => setAttribute("readable", readable);

  /// ## readinto (getter)
  Object? get readinto => getAttribute("readinto");

  /// ## readinto (setter)
  set readinto(Object? readinto) => setAttribute("readinto", readinto);

  /// ## readinto1 (getter)
  Object? get readinto1 => getAttribute("readinto1");

  /// ## readinto1 (setter)
  set readinto1(Object? readinto1) => setAttribute("readinto1", readinto1);

  /// ## readline (getter)
  Object? get readline => getAttribute("readline");

  /// ## readline (setter)
  set readline(Object? readline) => setAttribute("readline", readline);

  /// ## readlines (getter)
  Object? get readlines => getAttribute("readlines");

  /// ## readlines (setter)
  set readlines(Object? readlines) => setAttribute("readlines", readlines);

  /// ## seek (getter)
  Object? get seek => getAttribute("seek");

  /// ## seek (setter)
  set seek(Object? seek) => setAttribute("seek", seek);

  /// ## seekable (getter)
  Object? get seekable => getAttribute("seekable");

  /// ## seekable (setter)
  set seekable(Object? seekable) => setAttribute("seekable", seekable);

  /// ## tell (getter)
  Object? get tell => getAttribute("tell");

  /// ## tell (setter)
  set tell(Object? tell) => setAttribute("tell", tell);

  /// ## truncate (getter)
  Object? get truncate => getAttribute("truncate");

  /// ## truncate (setter)
  set truncate(Object? truncate) => setAttribute("truncate", truncate);

  /// ## writable (getter)
  Object? get writable => getAttribute("writable");

  /// ## writable (setter)
  set writable(Object? writable) => setAttribute("writable", writable);

  /// ## write (getter)
  Object? get write => getAttribute("write");

  /// ## write (setter)
  set write(Object? write) => setAttribute("write", write);

  /// ## writelines (getter)
  Object? get writelines => getAttribute("writelines");

  /// ## writelines (setter)
  set writelines(Object? writelines) => setAttribute("writelines", writelines);
}

/// ## BytesIO
final class BytesIO extends PythonClass {
  factory BytesIO() => PythonFfiDart.instance.importClass(
        "io",
        "BytesIO",
        BytesIO.from,
        <Object?>[],
      );

  BytesIO.from(super.pythonClass) : super.from();

  /// ## closed (getter)
  ///
  /// ### python docstring
  ///
  /// True if the file is closed.
  Object? get closed => getAttribute("closed");

  /// ## closed (setter)
  ///
  /// ### python docstring
  ///
  /// True if the file is closed.
  set closed(Object? closed) => setAttribute("closed", closed);

  /// ## close (getter)
  Object? get close => getAttribute("close");

  /// ## close (setter)
  set close(Object? close) => setAttribute("close", close);

  /// ## detach (getter)
  Object? get detach => getAttribute("detach");

  /// ## detach (setter)
  set detach(Object? detach) => setAttribute("detach", detach);

  /// ## fileno (getter)
  Object? get fileno => getAttribute("fileno");

  /// ## fileno (setter)
  set fileno(Object? fileno) => setAttribute("fileno", fileno);

  /// ## flush (getter)
  Object? get flush => getAttribute("flush");

  /// ## flush (setter)
  set flush(Object? flush) => setAttribute("flush", flush);

  /// ## getbuffer (getter)
  Object? get getbuffer => getAttribute("getbuffer");

  /// ## getbuffer (setter)
  set getbuffer(Object? getbuffer) => setAttribute("getbuffer", getbuffer);

  /// ## getvalue (getter)
  Object? get getvalue => getAttribute("getvalue");

  /// ## getvalue (setter)
  set getvalue(Object? getvalue) => setAttribute("getvalue", getvalue);

  /// ## isatty (getter)
  Object? get isatty => getAttribute("isatty");

  /// ## isatty (setter)
  set isatty(Object? isatty) => setAttribute("isatty", isatty);

  /// ## read (getter)
  Object? get read => getAttribute("read");

  /// ## read (setter)
  set read(Object? read) => setAttribute("read", read);

  /// ## read1 (getter)
  Object? get read1 => getAttribute("read1");

  /// ## read1 (setter)
  set read1(Object? read1) => setAttribute("read1", read1);

  /// ## readable (getter)
  Object? get readable => getAttribute("readable");

  /// ## readable (setter)
  set readable(Object? readable) => setAttribute("readable", readable);

  /// ## readinto (getter)
  Object? get readinto => getAttribute("readinto");

  /// ## readinto (setter)
  set readinto(Object? readinto) => setAttribute("readinto", readinto);

  /// ## readinto1 (getter)
  Object? get readinto1 => getAttribute("readinto1");

  /// ## readinto1 (setter)
  set readinto1(Object? readinto1) => setAttribute("readinto1", readinto1);

  /// ## readline (getter)
  Object? get readline => getAttribute("readline");

  /// ## readline (setter)
  set readline(Object? readline) => setAttribute("readline", readline);

  /// ## readlines (getter)
  Object? get readlines => getAttribute("readlines");

  /// ## readlines (setter)
  set readlines(Object? readlines) => setAttribute("readlines", readlines);

  /// ## seek (getter)
  Object? get seek => getAttribute("seek");

  /// ## seek (setter)
  set seek(Object? seek) => setAttribute("seek", seek);

  /// ## seekable (getter)
  Object? get seekable => getAttribute("seekable");

  /// ## seekable (setter)
  set seekable(Object? seekable) => setAttribute("seekable", seekable);

  /// ## tell (getter)
  Object? get tell => getAttribute("tell");

  /// ## tell (setter)
  set tell(Object? tell) => setAttribute("tell", tell);

  /// ## truncate (getter)
  Object? get truncate => getAttribute("truncate");

  /// ## truncate (setter)
  set truncate(Object? truncate) => setAttribute("truncate", truncate);

  /// ## writable (getter)
  Object? get writable => getAttribute("writable");

  /// ## writable (setter)
  set writable(Object? writable) => setAttribute("writable", writable);

  /// ## write (getter)
  Object? get write => getAttribute("write");

  /// ## write (setter)
  set write(Object? write) => setAttribute("write", write);

  /// ## writelines (getter)
  Object? get writelines => getAttribute("writelines");

  /// ## writelines (setter)
  set writelines(Object? writelines) => setAttribute("writelines", writelines);
}

/// ## FileIO
final class FileIO extends PythonClass {
  factory FileIO() => PythonFfiDart.instance.importClass(
        "io",
        "FileIO",
        FileIO.from,
        <Object?>[],
      );

  FileIO.from(super.pythonClass) : super.from();

  /// ## closed (getter)
  ///
  /// ### python docstring
  ///
  /// True if the file is closed
  Object? get closed => getAttribute("closed");

  /// ## closed (setter)
  ///
  /// ### python docstring
  ///
  /// True if the file is closed
  set closed(Object? closed) => setAttribute("closed", closed);

  /// ## closefd (getter)
  ///
  /// ### python docstring
  ///
  /// True if the file descriptor will be closed by close().
  Object? get closefd => getAttribute("closefd");

  /// ## closefd (setter)
  ///
  /// ### python docstring
  ///
  /// True if the file descriptor will be closed by close().
  set closefd(Object? closefd) => setAttribute("closefd", closefd);

  /// ## mode (getter)
  ///
  /// ### python docstring
  ///
  /// String giving the file mode
  Object? get mode => getAttribute("mode");

  /// ## mode (setter)
  ///
  /// ### python docstring
  ///
  /// String giving the file mode
  set mode(Object? mode) => setAttribute("mode", mode);

  /// ## close (getter)
  Object? get close => getAttribute("close");

  /// ## close (setter)
  set close(Object? close) => setAttribute("close", close);

  /// ## fileno (getter)
  Object? get fileno => getAttribute("fileno");

  /// ## fileno (setter)
  set fileno(Object? fileno) => setAttribute("fileno", fileno);

  /// ## flush (getter)
  Object? get flush => getAttribute("flush");

  /// ## flush (setter)
  set flush(Object? flush) => setAttribute("flush", flush);

  /// ## isatty (getter)
  Object? get isatty => getAttribute("isatty");

  /// ## isatty (setter)
  set isatty(Object? isatty) => setAttribute("isatty", isatty);

  /// ## read (getter)
  Object? get read => getAttribute("read");

  /// ## read (setter)
  set read(Object? read) => setAttribute("read", read);

  /// ## readable (getter)
  Object? get readable => getAttribute("readable");

  /// ## readable (setter)
  set readable(Object? readable) => setAttribute("readable", readable);

  /// ## readall (getter)
  Object? get readall => getAttribute("readall");

  /// ## readall (setter)
  set readall(Object? readall) => setAttribute("readall", readall);

  /// ## readinto (getter)
  Object? get readinto => getAttribute("readinto");

  /// ## readinto (setter)
  set readinto(Object? readinto) => setAttribute("readinto", readinto);

  /// ## readline (getter)
  Object? get readline => getAttribute("readline");

  /// ## readline (setter)
  set readline(Object? readline) => setAttribute("readline", readline);

  /// ## readlines (getter)
  Object? get readlines => getAttribute("readlines");

  /// ## readlines (setter)
  set readlines(Object? readlines) => setAttribute("readlines", readlines);

  /// ## seek (getter)
  Object? get seek => getAttribute("seek");

  /// ## seek (setter)
  set seek(Object? seek) => setAttribute("seek", seek);

  /// ## seekable (getter)
  Object? get seekable => getAttribute("seekable");

  /// ## seekable (setter)
  set seekable(Object? seekable) => setAttribute("seekable", seekable);

  /// ## tell (getter)
  Object? get tell => getAttribute("tell");

  /// ## tell (setter)
  set tell(Object? tell) => setAttribute("tell", tell);

  /// ## truncate (getter)
  Object? get truncate => getAttribute("truncate");

  /// ## truncate (setter)
  set truncate(Object? truncate) => setAttribute("truncate", truncate);

  /// ## writable (getter)
  Object? get writable => getAttribute("writable");

  /// ## writable (setter)
  set writable(Object? writable) => setAttribute("writable", writable);

  /// ## write (getter)
  Object? get write => getAttribute("write");

  /// ## write (setter)
  set write(Object? write) => setAttribute("write", write);

  /// ## writelines (getter)
  Object? get writelines => getAttribute("writelines");

  /// ## writelines (setter)
  set writelines(Object? writelines) => setAttribute("writelines", writelines);
}

/// ## IOBase
///
/// ### python source
/// ```py
/// class IOBase(_io._IOBase, metaclass=abc.ABCMeta):
///     __doc__ = _io._IOBase.__doc__
/// ```
final class IOBase extends PythonClass {
  factory IOBase() => PythonFfiDart.instance.importClass(
        "io",
        "IOBase",
        IOBase.from,
        <Object?>[],
      );

  IOBase.from(super.pythonClass) : super.from();

  /// ## closed (getter)
  Object? get closed => getAttribute("closed");

  /// ## closed (setter)
  set closed(Object? closed) => setAttribute("closed", closed);

  /// ## close (getter)
  Object? get close => getAttribute("close");

  /// ## close (setter)
  set close(Object? close) => setAttribute("close", close);

  /// ## fileno (getter)
  Object? get fileno => getAttribute("fileno");

  /// ## fileno (setter)
  set fileno(Object? fileno) => setAttribute("fileno", fileno);

  /// ## flush (getter)
  Object? get flush => getAttribute("flush");

  /// ## flush (setter)
  set flush(Object? flush) => setAttribute("flush", flush);

  /// ## isatty (getter)
  Object? get isatty => getAttribute("isatty");

  /// ## isatty (setter)
  set isatty(Object? isatty) => setAttribute("isatty", isatty);

  /// ## readable (getter)
  Object? get readable => getAttribute("readable");

  /// ## readable (setter)
  set readable(Object? readable) => setAttribute("readable", readable);

  /// ## readline (getter)
  Object? get readline => getAttribute("readline");

  /// ## readline (setter)
  set readline(Object? readline) => setAttribute("readline", readline);

  /// ## readlines (getter)
  Object? get readlines => getAttribute("readlines");

  /// ## readlines (setter)
  set readlines(Object? readlines) => setAttribute("readlines", readlines);

  /// ## seek (getter)
  Object? get seek => getAttribute("seek");

  /// ## seek (setter)
  set seek(Object? seek) => setAttribute("seek", seek);

  /// ## seekable (getter)
  Object? get seekable => getAttribute("seekable");

  /// ## seekable (setter)
  set seekable(Object? seekable) => setAttribute("seekable", seekable);

  /// ## tell (getter)
  Object? get tell => getAttribute("tell");

  /// ## tell (setter)
  set tell(Object? tell) => setAttribute("tell", tell);

  /// ## truncate (getter)
  Object? get truncate => getAttribute("truncate");

  /// ## truncate (setter)
  set truncate(Object? truncate) => setAttribute("truncate", truncate);

  /// ## writable (getter)
  Object? get writable => getAttribute("writable");

  /// ## writable (setter)
  set writable(Object? writable) => setAttribute("writable", writable);

  /// ## writelines (getter)
  Object? get writelines => getAttribute("writelines");

  /// ## writelines (setter)
  set writelines(Object? writelines) => setAttribute("writelines", writelines);
}

/// ## IncrementalNewlineDecoder
final class IncrementalNewlineDecoder extends PythonClass {
  factory IncrementalNewlineDecoder() => PythonFfiDart.instance.importClass(
        "io",
        "IncrementalNewlineDecoder",
        IncrementalNewlineDecoder.from,
        <Object?>[],
      );

  IncrementalNewlineDecoder.from(super.pythonClass) : super.from();

  /// ## newlines (getter)
  Object? get newlines => getAttribute("newlines");

  /// ## newlines (setter)
  set newlines(Object? newlines) => setAttribute("newlines", newlines);

  /// ## decode (getter)
  Object? get decode => getAttribute("decode");

  /// ## decode (setter)
  set decode(Object? decode) => setAttribute("decode", decode);

  /// ## getstate (getter)
  Object? get getstate => getAttribute("getstate");

  /// ## getstate (setter)
  set getstate(Object? getstate) => setAttribute("getstate", getstate);

  /// ## reset (getter)
  Object? get reset => getAttribute("reset");

  /// ## reset (setter)
  set reset(Object? reset) => setAttribute("reset", reset);

  /// ## setstate (getter)
  Object? get setstate => getAttribute("setstate");

  /// ## setstate (setter)
  set setstate(Object? setstate) => setAttribute("setstate", setstate);
}

/// ## RawIOBase
///
/// ### python source
/// ```py
/// class RawIOBase(_io._RawIOBase, IOBase):
///     __doc__ = _io._RawIOBase.__doc__
/// ```
final class RawIOBase extends PythonClass {
  factory RawIOBase() => PythonFfiDart.instance.importClass(
        "io",
        "RawIOBase",
        RawIOBase.from,
        <Object?>[],
      );

  RawIOBase.from(super.pythonClass) : super.from();

  /// ## closed (getter)
  Object? get closed => getAttribute("closed");

  /// ## closed (setter)
  set closed(Object? closed) => setAttribute("closed", closed);

  /// ## close (getter)
  Object? get close => getAttribute("close");

  /// ## close (setter)
  set close(Object? close) => setAttribute("close", close);

  /// ## fileno (getter)
  Object? get fileno => getAttribute("fileno");

  /// ## fileno (setter)
  set fileno(Object? fileno) => setAttribute("fileno", fileno);

  /// ## flush (getter)
  Object? get flush => getAttribute("flush");

  /// ## flush (setter)
  set flush(Object? flush) => setAttribute("flush", flush);

  /// ## isatty (getter)
  Object? get isatty => getAttribute("isatty");

  /// ## isatty (setter)
  set isatty(Object? isatty) => setAttribute("isatty", isatty);

  /// ## read (getter)
  Object? get read => getAttribute("read");

  /// ## read (setter)
  set read(Object? read) => setAttribute("read", read);

  /// ## readable (getter)
  Object? get readable => getAttribute("readable");

  /// ## readable (setter)
  set readable(Object? readable) => setAttribute("readable", readable);

  /// ## readall (getter)
  Object? get readall => getAttribute("readall");

  /// ## readall (setter)
  set readall(Object? readall) => setAttribute("readall", readall);

  /// ## readinto (getter)
  Object? get readinto => getAttribute("readinto");

  /// ## readinto (setter)
  set readinto(Object? readinto) => setAttribute("readinto", readinto);

  /// ## readline (getter)
  Object? get readline => getAttribute("readline");

  /// ## readline (setter)
  set readline(Object? readline) => setAttribute("readline", readline);

  /// ## readlines (getter)
  Object? get readlines => getAttribute("readlines");

  /// ## readlines (setter)
  set readlines(Object? readlines) => setAttribute("readlines", readlines);

  /// ## seek (getter)
  Object? get seek => getAttribute("seek");

  /// ## seek (setter)
  set seek(Object? seek) => setAttribute("seek", seek);

  /// ## seekable (getter)
  Object? get seekable => getAttribute("seekable");

  /// ## seekable (setter)
  set seekable(Object? seekable) => setAttribute("seekable", seekable);

  /// ## tell (getter)
  Object? get tell => getAttribute("tell");

  /// ## tell (setter)
  set tell(Object? tell) => setAttribute("tell", tell);

  /// ## truncate (getter)
  Object? get truncate => getAttribute("truncate");

  /// ## truncate (setter)
  set truncate(Object? truncate) => setAttribute("truncate", truncate);

  /// ## writable (getter)
  Object? get writable => getAttribute("writable");

  /// ## writable (setter)
  set writable(Object? writable) => setAttribute("writable", writable);

  /// ## write (getter)
  Object? get write => getAttribute("write");

  /// ## write (setter)
  set write(Object? write) => setAttribute("write", write);

  /// ## writelines (getter)
  Object? get writelines => getAttribute("writelines");

  /// ## writelines (setter)
  set writelines(Object? writelines) => setAttribute("writelines", writelines);
}

/// ## StringIO
final class StringIO extends PythonClass {
  factory StringIO() => PythonFfiDart.instance.importClass(
        "io",
        "StringIO",
        StringIO.from,
        <Object?>[],
      );

  StringIO.from(super.pythonClass) : super.from();

  /// ## closed (getter)
  Object? get closed => getAttribute("closed");

  /// ## closed (setter)
  set closed(Object? closed) => setAttribute("closed", closed);

  /// ## encoding (getter)
  Object? get encoding => getAttribute("encoding");

  /// ## encoding (setter)
  set encoding(Object? encoding) => setAttribute("encoding", encoding);

  /// ## errors (getter)
  Object? get errors => getAttribute("errors");

  /// ## errors (setter)
  set errors(Object? errors) => setAttribute("errors", errors);

  /// ## line_buffering (getter)
  Object? get line_buffering => getAttribute("line_buffering");

  /// ## line_buffering (setter)
  set line_buffering(Object? line_buffering) =>
      setAttribute("line_buffering", line_buffering);

  /// ## newlines (getter)
  Object? get newlines => getAttribute("newlines");

  /// ## newlines (setter)
  set newlines(Object? newlines) => setAttribute("newlines", newlines);

  /// ## close (getter)
  Object? get close => getAttribute("close");

  /// ## close (setter)
  set close(Object? close) => setAttribute("close", close);

  /// ## detach (getter)
  Object? get detach => getAttribute("detach");

  /// ## detach (setter)
  set detach(Object? detach) => setAttribute("detach", detach);

  /// ## fileno (getter)
  Object? get fileno => getAttribute("fileno");

  /// ## fileno (setter)
  set fileno(Object? fileno) => setAttribute("fileno", fileno);

  /// ## flush (getter)
  Object? get flush => getAttribute("flush");

  /// ## flush (setter)
  set flush(Object? flush) => setAttribute("flush", flush);

  /// ## getvalue (getter)
  Object? get getvalue => getAttribute("getvalue");

  /// ## getvalue (setter)
  set getvalue(Object? getvalue) => setAttribute("getvalue", getvalue);

  /// ## isatty (getter)
  Object? get isatty => getAttribute("isatty");

  /// ## isatty (setter)
  set isatty(Object? isatty) => setAttribute("isatty", isatty);

  /// ## read (getter)
  Object? get read => getAttribute("read");

  /// ## read (setter)
  set read(Object? read) => setAttribute("read", read);

  /// ## readable (getter)
  Object? get readable => getAttribute("readable");

  /// ## readable (setter)
  set readable(Object? readable) => setAttribute("readable", readable);

  /// ## readline (getter)
  Object? get readline => getAttribute("readline");

  /// ## readline (setter)
  set readline(Object? readline) => setAttribute("readline", readline);

  /// ## readlines (getter)
  Object? get readlines => getAttribute("readlines");

  /// ## readlines (setter)
  set readlines(Object? readlines) => setAttribute("readlines", readlines);

  /// ## seek (getter)
  Object? get seek => getAttribute("seek");

  /// ## seek (setter)
  set seek(Object? seek) => setAttribute("seek", seek);

  /// ## seekable (getter)
  Object? get seekable => getAttribute("seekable");

  /// ## seekable (setter)
  set seekable(Object? seekable) => setAttribute("seekable", seekable);

  /// ## tell (getter)
  Object? get tell => getAttribute("tell");

  /// ## tell (setter)
  set tell(Object? tell) => setAttribute("tell", tell);

  /// ## truncate (getter)
  Object? get truncate => getAttribute("truncate");

  /// ## truncate (setter)
  set truncate(Object? truncate) => setAttribute("truncate", truncate);

  /// ## writable (getter)
  Object? get writable => getAttribute("writable");

  /// ## writable (setter)
  set writable(Object? writable) => setAttribute("writable", writable);

  /// ## write (getter)
  Object? get write => getAttribute("write");

  /// ## write (setter)
  set write(Object? write) => setAttribute("write", write);

  /// ## writelines (getter)
  Object? get writelines => getAttribute("writelines");

  /// ## writelines (setter)
  set writelines(Object? writelines) => setAttribute("writelines", writelines);
}

/// ## TextIOBase
///
/// ### python source
/// ```py
/// class TextIOBase(_io._TextIOBase, IOBase):
///     __doc__ = _io._TextIOBase.__doc__
/// ```
final class TextIOBase extends PythonClass {
  factory TextIOBase() => PythonFfiDart.instance.importClass(
        "io",
        "TextIOBase",
        TextIOBase.from,
        <Object?>[],
      );

  TextIOBase.from(super.pythonClass) : super.from();

  /// ## closed (getter)
  Object? get closed => getAttribute("closed");

  /// ## closed (setter)
  set closed(Object? closed) => setAttribute("closed", closed);

  /// ## encoding (getter)
  Object? get encoding => getAttribute("encoding");

  /// ## encoding (setter)
  set encoding(Object? encoding) => setAttribute("encoding", encoding);

  /// ## errors (getter)
  Object? get errors => getAttribute("errors");

  /// ## errors (setter)
  set errors(Object? errors) => setAttribute("errors", errors);

  /// ## newlines (getter)
  Object? get newlines => getAttribute("newlines");

  /// ## newlines (setter)
  set newlines(Object? newlines) => setAttribute("newlines", newlines);

  /// ## close (getter)
  Object? get close => getAttribute("close");

  /// ## close (setter)
  set close(Object? close) => setAttribute("close", close);

  /// ## detach (getter)
  Object? get detach => getAttribute("detach");

  /// ## detach (setter)
  set detach(Object? detach) => setAttribute("detach", detach);

  /// ## fileno (getter)
  Object? get fileno => getAttribute("fileno");

  /// ## fileno (setter)
  set fileno(Object? fileno) => setAttribute("fileno", fileno);

  /// ## flush (getter)
  Object? get flush => getAttribute("flush");

  /// ## flush (setter)
  set flush(Object? flush) => setAttribute("flush", flush);

  /// ## isatty (getter)
  Object? get isatty => getAttribute("isatty");

  /// ## isatty (setter)
  set isatty(Object? isatty) => setAttribute("isatty", isatty);

  /// ## read (getter)
  Object? get read => getAttribute("read");

  /// ## read (setter)
  set read(Object? read) => setAttribute("read", read);

  /// ## readable (getter)
  Object? get readable => getAttribute("readable");

  /// ## readable (setter)
  set readable(Object? readable) => setAttribute("readable", readable);

  /// ## readline (getter)
  Object? get readline => getAttribute("readline");

  /// ## readline (setter)
  set readline(Object? readline) => setAttribute("readline", readline);

  /// ## readlines (getter)
  Object? get readlines => getAttribute("readlines");

  /// ## readlines (setter)
  set readlines(Object? readlines) => setAttribute("readlines", readlines);

  /// ## seek (getter)
  Object? get seek => getAttribute("seek");

  /// ## seek (setter)
  set seek(Object? seek) => setAttribute("seek", seek);

  /// ## seekable (getter)
  Object? get seekable => getAttribute("seekable");

  /// ## seekable (setter)
  set seekable(Object? seekable) => setAttribute("seekable", seekable);

  /// ## tell (getter)
  Object? get tell => getAttribute("tell");

  /// ## tell (setter)
  set tell(Object? tell) => setAttribute("tell", tell);

  /// ## truncate (getter)
  Object? get truncate => getAttribute("truncate");

  /// ## truncate (setter)
  set truncate(Object? truncate) => setAttribute("truncate", truncate);

  /// ## writable (getter)
  Object? get writable => getAttribute("writable");

  /// ## writable (setter)
  set writable(Object? writable) => setAttribute("writable", writable);

  /// ## write (getter)
  Object? get write => getAttribute("write");

  /// ## write (setter)
  set write(Object? write) => setAttribute("write", write);

  /// ## writelines (getter)
  Object? get writelines => getAttribute("writelines");

  /// ## writelines (setter)
  set writelines(Object? writelines) => setAttribute("writelines", writelines);
}

/// ## TextIOWrapper
final class TextIOWrapper extends PythonClass {
  factory TextIOWrapper() => PythonFfiDart.instance.importClass(
        "io",
        "TextIOWrapper",
        TextIOWrapper.from,
        <Object?>[],
      );

  TextIOWrapper.from(super.pythonClass) : super.from();

  /// ## buffer (getter)
  Object? get buffer => getAttribute("buffer");

  /// ## buffer (setter)
  set buffer(Object? buffer) => setAttribute("buffer", buffer);

  /// ## closed (getter)
  Object? get closed => getAttribute("closed");

  /// ## closed (setter)
  set closed(Object? closed) => setAttribute("closed", closed);

  /// ## encoding (getter)
  Object? get encoding => getAttribute("encoding");

  /// ## encoding (setter)
  set encoding(Object? encoding) => setAttribute("encoding", encoding);

  /// ## errors (getter)
  Object? get errors => getAttribute("errors");

  /// ## errors (setter)
  set errors(Object? errors) => setAttribute("errors", errors);

  /// ## line_buffering (getter)
  Object? get line_buffering => getAttribute("line_buffering");

  /// ## line_buffering (setter)
  set line_buffering(Object? line_buffering) =>
      setAttribute("line_buffering", line_buffering);

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);

  /// ## newlines (getter)
  Object? get newlines => getAttribute("newlines");

  /// ## newlines (setter)
  set newlines(Object? newlines) => setAttribute("newlines", newlines);

  /// ## write_through (getter)
  Object? get write_through => getAttribute("write_through");

  /// ## write_through (setter)
  set write_through(Object? write_through) =>
      setAttribute("write_through", write_through);

  /// ## close (getter)
  Object? get close => getAttribute("close");

  /// ## close (setter)
  set close(Object? close) => setAttribute("close", close);

  /// ## detach (getter)
  Object? get detach => getAttribute("detach");

  /// ## detach (setter)
  set detach(Object? detach) => setAttribute("detach", detach);

  /// ## fileno (getter)
  Object? get fileno => getAttribute("fileno");

  /// ## fileno (setter)
  set fileno(Object? fileno) => setAttribute("fileno", fileno);

  /// ## flush (getter)
  Object? get flush => getAttribute("flush");

  /// ## flush (setter)
  set flush(Object? flush) => setAttribute("flush", flush);

  /// ## isatty (getter)
  Object? get isatty => getAttribute("isatty");

  /// ## isatty (setter)
  set isatty(Object? isatty) => setAttribute("isatty", isatty);

  /// ## read (getter)
  Object? get read => getAttribute("read");

  /// ## read (setter)
  set read(Object? read) => setAttribute("read", read);

  /// ## readable (getter)
  Object? get readable => getAttribute("readable");

  /// ## readable (setter)
  set readable(Object? readable) => setAttribute("readable", readable);

  /// ## readline (getter)
  Object? get readline => getAttribute("readline");

  /// ## readline (setter)
  set readline(Object? readline) => setAttribute("readline", readline);

  /// ## readlines (getter)
  Object? get readlines => getAttribute("readlines");

  /// ## readlines (setter)
  set readlines(Object? readlines) => setAttribute("readlines", readlines);

  /// ## reconfigure (getter)
  Object? get reconfigure => getAttribute("reconfigure");

  /// ## reconfigure (setter)
  set reconfigure(Object? reconfigure) =>
      setAttribute("reconfigure", reconfigure);

  /// ## seek (getter)
  Object? get seek => getAttribute("seek");

  /// ## seek (setter)
  set seek(Object? seek) => setAttribute("seek", seek);

  /// ## seekable (getter)
  Object? get seekable => getAttribute("seekable");

  /// ## seekable (setter)
  set seekable(Object? seekable) => setAttribute("seekable", seekable);

  /// ## tell (getter)
  Object? get tell => getAttribute("tell");

  /// ## tell (setter)
  set tell(Object? tell) => setAttribute("tell", tell);

  /// ## truncate (getter)
  Object? get truncate => getAttribute("truncate");

  /// ## truncate (setter)
  set truncate(Object? truncate) => setAttribute("truncate", truncate);

  /// ## writable (getter)
  Object? get writable => getAttribute("writable");

  /// ## writable (setter)
  set writable(Object? writable) => setAttribute("writable", writable);

  /// ## write (getter)
  Object? get write => getAttribute("write");

  /// ## write (setter)
  set write(Object? write) => setAttribute("write", write);

  /// ## writelines (getter)
  Object? get writelines => getAttribute("writelines");

  /// ## writelines (setter)
  set writelines(Object? writelines) => setAttribute("writelines", writelines);
}

/// ## UnsupportedOperation
final class UnsupportedOperation extends PythonClass {
  factory UnsupportedOperation() => PythonFfiDart.instance.importClass(
        "io",
        "UnsupportedOperation",
        UnsupportedOperation.from,
        <Object?>[],
      );

  UnsupportedOperation.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## characters_written (getter)
  Object? get characters_written => getAttribute("characters_written");

  /// ## characters_written (setter)
  set characters_written(Object? characters_written) =>
      setAttribute("characters_written", characters_written);

  /// ## errno (getter)
  Object? get errno => getAttribute("errno");

  /// ## errno (setter)
  set errno(Object? errno) => setAttribute("errno", errno);

  /// ## filename (getter)
  Object? get filename => getAttribute("filename");

  /// ## filename (setter)
  set filename(Object? filename) => setAttribute("filename", filename);

  /// ## filename2 (getter)
  Object? get filename2 => getAttribute("filename2");

  /// ## filename2 (setter)
  set filename2(Object? filename2) => setAttribute("filename2", filename2);

  /// ## strerror (getter)
  Object? get strerror => getAttribute("strerror");

  /// ## strerror (setter)
  set strerror(Object? strerror) => setAttribute("strerror", strerror);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## WarningMessage
///
/// ### python source
/// ```py
/// class WarningMessage(object):
///
///     _WARNING_DETAILS = ("message", "category", "filename", "lineno", "file",
///                         "line", "source")
///
///     def __init__(self, message, category, filename, lineno, file=None,
///                  line=None, source=None):
///         self.message = message
///         self.category = category
///         self.filename = filename
///         self.lineno = lineno
///         self.file = file
///         self.line = line
///         self.source = source
///         self._category_name = category.__name__ if category else None
///
///     def __str__(self):
///         return ("{message : %r, category : %r, filename : %r, lineno : %s, "
///                     "line : %r}" % (self.message, self._category_name,
///                                     self.filename, self.lineno, self.line))
/// ```
final class WarningMessage extends PythonClass {
  factory WarningMessage({
    required Object? message,
    required Object? category,
    required Object? filename,
    required Object? lineno,
    Object? file,
    Object? line,
    Object? source,
  }) =>
      PythonFfiDart.instance.importClass(
        "warnings",
        "WarningMessage",
        WarningMessage.from,
        <Object?>[
          message,
          category,
          filename,
          lineno,
          file,
          line,
          source,
        ],
        <String, Object?>{},
      );

  WarningMessage.from(super.pythonClass) : super.from();

  /// ## message (getter)
  Object? get message => getAttribute("message");

  /// ## message (setter)
  set message(Object? message) => setAttribute("message", message);

  /// ## category (getter)
  Object? get category => getAttribute("category");

  /// ## category (setter)
  set category(Object? category) => setAttribute("category", category);

  /// ## filename (getter)
  Object? get filename => getAttribute("filename");

  /// ## filename (setter)
  set filename(Object? filename) => setAttribute("filename", filename);

  /// ## lineno (getter)
  Object? get lineno => getAttribute("lineno");

  /// ## lineno (setter)
  set lineno(Object? lineno) => setAttribute("lineno", lineno);

  /// ## file (getter)
  Object? get file => getAttribute("file");

  /// ## file (setter)
  set file(Object? file) => setAttribute("file", file);

  /// ## line (getter)
  Object? get line => getAttribute("line");

  /// ## line (setter)
  set line(Object? line) => setAttribute("line", line);

  /// ## source (getter)
  Object? get source => getAttribute("source");

  /// ## source (setter)
  set source(Object? source) => setAttribute("source", source);
}

/// ## catch_warnings
///
/// ### python docstring
///
/// A context manager that copies and restores the warnings filter upon
/// exiting the context.
///
/// The 'record' argument specifies whether warnings should be captured by a
/// custom implementation of warnings.showwarning() and be appended to a list
/// returned by the context manager. Otherwise None is returned by the context
/// manager. The objects appended to the list are arguments whose attributes
/// mirror the arguments to showwarning().
///
/// The 'module' argument is to specify an alternative module to the module
/// named 'warnings' and imported under that name. This argument is only useful
/// when testing the warnings module itself.
///
/// If the 'action' argument is not None, the remaining arguments are passed
/// to warnings.simplefilter() as if it were called immediately on entering the
/// context.
///
/// ### python source
/// ```py
/// class catch_warnings(object):
///
///     """A context manager that copies and restores the warnings filter upon
///     exiting the context.
///
///     The 'record' argument specifies whether warnings should be captured by a
///     custom implementation of warnings.showwarning() and be appended to a list
///     returned by the context manager. Otherwise None is returned by the context
///     manager. The objects appended to the list are arguments whose attributes
///     mirror the arguments to showwarning().
///
///     The 'module' argument is to specify an alternative module to the module
///     named 'warnings' and imported under that name. This argument is only useful
///     when testing the warnings module itself.
///
///     If the 'action' argument is not None, the remaining arguments are passed
///     to warnings.simplefilter() as if it were called immediately on entering the
///     context.
///     """
///
///     def __init__(self, *, record=False, module=None,
///                  action=None, category=Warning, lineno=0, append=False):
///         """Specify whether to record warnings and if an alternative module
///         should be used other than sys.modules['warnings'].
///
///         For compatibility with Python 3.0, please consider all arguments to be
///         keyword-only.
///
///         """
///         self._record = record
///         self._module = sys.modules['warnings'] if module is None else module
///         self._entered = False
///         if action is None:
///             self._filter = None
///         else:
///             self._filter = (action, category, lineno, append)
///
///     def __repr__(self):
///         args = []
///         if self._record:
///             args.append("record=True")
///         if self._module is not sys.modules['warnings']:
///             args.append("module=%r" % self._module)
///         name = type(self).__name__
///         return "%s(%s)" % (name, ", ".join(args))
///
///     def __enter__(self):
///         if self._entered:
///             raise RuntimeError("Cannot enter %r twice" % self)
///         self._entered = True
///         self._filters = self._module.filters
///         self._module.filters = self._filters[:]
///         self._module._filters_mutated()
///         self._showwarning = self._module.showwarning
///         self._showwarnmsg_impl = self._module._showwarnmsg_impl
///         if self._filter is not None:
///             simplefilter(*self._filter)
///         if self._record:
///             log = []
///             self._module._showwarnmsg_impl = log.append
///             # Reset showwarning() to the default implementation to make sure
///             # that _showwarnmsg() calls _showwarnmsg_impl()
///             self._module.showwarning = self._module._showwarning_orig
///             return log
///         else:
///             return None
///
///     def __exit__(self, *exc_info):
///         if not self._entered:
///             raise RuntimeError("Cannot exit %r without entering first" % self)
///         self._module.filters = self._filters
///         self._module._filters_mutated()
///         self._module.showwarning = self._showwarning
///         self._module._showwarnmsg_impl = self._showwarnmsg_impl
/// ```
final class catch_warnings extends PythonClass {
  factory catch_warnings({
    Object? record = false,
    Object? module,
    Object? action,
    Object? category,
    Object? lineno = 0,
    Object? append = false,
  }) =>
      PythonFfiDart.instance.importClass(
        "warnings",
        "catch_warnings",
        catch_warnings.from,
        <Object?>[],
        <String, Object?>{
          "record": record,
          "module": module,
          "action": action,
          "category": category,
          "lineno": lineno,
          "append": append,
        },
      );

  catch_warnings.from(super.pythonClass) : super.from();
}

/// ## FunctionType
final class FunctionType extends PythonClass {
  factory FunctionType() => PythonFfiDart.instance.importClass(
        "builtins",
        "FunctionType",
        FunctionType.from,
        <Object?>[],
      );

  FunctionType.from(super.pythonClass) : super.from();
}

/// ## PickleBuffer
final class PickleBuffer extends PythonClass {
  factory PickleBuffer() => PythonFfiDart.instance.importClass(
        "pickle",
        "PickleBuffer",
        PickleBuffer.from,
        <Object?>[],
      );

  PickleBuffer.from(super.pythonClass) : super.from();

  /// ## raw (getter)
  Object? get raw => getAttribute("raw");

  /// ## raw (setter)
  set raw(Object? raw) => setAttribute("raw", raw);

  /// ## release (getter)
  Object? get release => getAttribute("release");

  /// ## release (setter)
  set release(Object? release) => setAttribute("release", release);
}

/// ## PickleError
final class PickleError extends PythonClass {
  factory PickleError() => PythonFfiDart.instance.importClass(
        "_pickle",
        "PickleError",
        PickleError.from,
        <Object?>[],
      );

  PickleError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## Pickler
final class Pickler extends PythonClass {
  factory Pickler() => PythonFfiDart.instance.importClass(
        "_pickle",
        "Pickler",
        Pickler.from,
        <Object?>[],
      );

  Pickler.from(super.pythonClass) : super.from();

  /// ## bin (getter)
  Object? get bin => getAttribute("bin");

  /// ## bin (setter)
  set bin(Object? bin) => setAttribute("bin", bin);

  /// ## dispatch_table (getter)
  Object? get dispatch_table => getAttribute("dispatch_table");

  /// ## dispatch_table (setter)
  set dispatch_table(Object? dispatch_table) =>
      setAttribute("dispatch_table", dispatch_table);

  /// ## fast (getter)
  Object? get fast => getAttribute("fast");

  /// ## fast (setter)
  set fast(Object? fast) => setAttribute("fast", fast);

  /// ## memo (getter)
  Object? get memo => getAttribute("memo");

  /// ## memo (setter)
  set memo(Object? memo) => setAttribute("memo", memo);

  /// ## persistent_id (getter)
  Object? get persistent_id => getAttribute("persistent_id");

  /// ## persistent_id (setter)
  set persistent_id(Object? persistent_id) =>
      setAttribute("persistent_id", persistent_id);

  /// ## clear_memo (getter)
  Object? get clear_memo => getAttribute("clear_memo");

  /// ## clear_memo (setter)
  set clear_memo(Object? clear_memo) => setAttribute("clear_memo", clear_memo);

  /// ## dump (getter)
  Object? get dump => getAttribute("dump");

  /// ## dump (setter)
  set dump(Object? dump) => setAttribute("dump", dump);
}

/// ## PicklingError
final class PicklingError extends PythonClass {
  factory PicklingError() => PythonFfiDart.instance.importClass(
        "_pickle",
        "PicklingError",
        PicklingError.from,
        <Object?>[],
      );

  PicklingError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## Unpickler
final class Unpickler extends PythonClass {
  factory Unpickler() => PythonFfiDart.instance.importClass(
        "_pickle",
        "Unpickler",
        Unpickler.from,
        <Object?>[],
      );

  Unpickler.from(super.pythonClass) : super.from();

  /// ## memo (getter)
  Object? get memo => getAttribute("memo");

  /// ## memo (setter)
  set memo(Object? memo) => setAttribute("memo", memo);

  /// ## persistent_load (getter)
  Object? get persistent_load => getAttribute("persistent_load");

  /// ## persistent_load (setter)
  set persistent_load(Object? persistent_load) =>
      setAttribute("persistent_load", persistent_load);

  /// ## find_class (getter)
  Object? get find_class => getAttribute("find_class");

  /// ## find_class (setter)
  set find_class(Object? find_class) => setAttribute("find_class", find_class);

  /// ## load (getter)
  Object? get load => getAttribute("load");

  /// ## load (setter)
  set load(Object? load) => setAttribute("load", load);
}

/// ## UnpicklingError
final class UnpicklingError extends PythonClass {
  factory UnpicklingError() => PythonFfiDart.instance.importClass(
        "_pickle",
        "UnpicklingError",
        UnpicklingError.from,
        <Object?>[],
      );

  UnpicklingError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## BufferedIncrementalDecoder
///
/// ### python docstring
///
/// This subclass of IncrementalDecoder can be used as the baseclass for an
/// incremental decoder if the decoder must be able to handle incomplete
/// byte sequences.
///
/// ### python source
/// ```py
/// class BufferedIncrementalDecoder(IncrementalDecoder):
///     """
///     This subclass of IncrementalDecoder can be used as the baseclass for an
///     incremental decoder if the decoder must be able to handle incomplete
///     byte sequences.
///     """
///     def __init__(self, errors='strict'):
///         IncrementalDecoder.__init__(self, errors)
///         # undecoded input that is kept between calls to decode()
///         self.buffer = b""
///
///     def _buffer_decode(self, input, errors, final):
///         # Overwrite this method in subclasses: It must decode input
///         # and return an (output, length consumed) tuple
///         raise NotImplementedError
///
///     def decode(self, input, final=False):
///         # decode input (taking the buffer into account)
///         data = self.buffer + input
///         (result, consumed) = self._buffer_decode(data, self.errors, final)
///         # keep undecoded input until the next call
///         self.buffer = data[consumed:]
///         return result
///
///     def reset(self):
///         IncrementalDecoder.reset(self)
///         self.buffer = b""
///
///     def getstate(self):
///         # additional state info is always 0
///         return (self.buffer, 0)
///
///     def setstate(self, state):
///         # ignore additional state info
///         self.buffer = state[0]
/// ```
final class BufferedIncrementalDecoder extends PythonClass {
  factory BufferedIncrementalDecoder({
    Object? errors = "strict",
  }) =>
      PythonFfiDart.instance.importClass(
        "codecs",
        "BufferedIncrementalDecoder",
        BufferedIncrementalDecoder.from,
        <Object?>[
          errors,
        ],
        <String, Object?>{},
      );

  BufferedIncrementalDecoder.from(super.pythonClass) : super.from();

  /// ## decode
  ///
  /// ### python docstring
  ///
  /// Decode input and returns the resulting object.
  Object? decode({
    required Object? input,
    Object? $final = false,
  }) =>
      getFunction("decode").call(
        <Object?>[
          input,
          $final,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## getstate
  ///
  /// ### python docstring
  ///
  /// Return the current state of the decoder.
  ///
  /// This must be a (buffered_input, additional_state_info) tuple.
  /// buffered_input must be a bytes object containing bytes that
  /// were passed to decode() that have not yet been converted.
  /// additional_state_info must be a non-negative integer
  /// representing the state of the decoder WITHOUT yet having
  /// processed the contents of buffered_input.  In the initial state
  /// and after reset(), getstate() must return (b"", 0).
  Object? getstate() => getFunction("getstate").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## reset
  ///
  /// ### python docstring
  ///
  /// Reset the decoder to the initial state.
  Object? reset() => getFunction("reset").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## setstate
  ///
  /// ### python docstring
  ///
  /// Set the current state of the decoder.
  ///
  /// state must have been returned by getstate().  The effect of
  /// setstate((b"", 0)) must be equivalent to reset().
  Object? setstate({
    required Object? state,
  }) =>
      getFunction("setstate").call(
        <Object?>[
          state,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## BufferedIncrementalEncoder
///
/// ### python docstring
///
/// This subclass of IncrementalEncoder can be used as the baseclass for an
/// incremental encoder if the encoder must keep some of the output in a
/// buffer between calls to encode().
///
/// ### python source
/// ```py
/// class BufferedIncrementalEncoder(IncrementalEncoder):
///     """
///     This subclass of IncrementalEncoder can be used as the baseclass for an
///     incremental encoder if the encoder must keep some of the output in a
///     buffer between calls to encode().
///     """
///     def __init__(self, errors='strict'):
///         IncrementalEncoder.__init__(self, errors)
///         # unencoded input that is kept between calls to encode()
///         self.buffer = ""
///
///     def _buffer_encode(self, input, errors, final):
///         # Overwrite this method in subclasses: It must encode input
///         # and return an (output, length consumed) tuple
///         raise NotImplementedError
///
///     def encode(self, input, final=False):
///         # encode input (taking the buffer into account)
///         data = self.buffer + input
///         (result, consumed) = self._buffer_encode(data, self.errors, final)
///         # keep unencoded input until the next call
///         self.buffer = data[consumed:]
///         return result
///
///     def reset(self):
///         IncrementalEncoder.reset(self)
///         self.buffer = ""
///
///     def getstate(self):
///         return self.buffer or 0
///
///     def setstate(self, state):
///         self.buffer = state or ""
/// ```
final class BufferedIncrementalEncoder extends PythonClass {
  factory BufferedIncrementalEncoder({
    Object? errors = "strict",
  }) =>
      PythonFfiDart.instance.importClass(
        "codecs",
        "BufferedIncrementalEncoder",
        BufferedIncrementalEncoder.from,
        <Object?>[
          errors,
        ],
        <String, Object?>{},
      );

  BufferedIncrementalEncoder.from(super.pythonClass) : super.from();

  /// ## encode
  ///
  /// ### python docstring
  ///
  /// Encodes input and returns the resulting object.
  Object? encode({
    required Object? input,
    Object? $final = false,
  }) =>
      getFunction("encode").call(
        <Object?>[
          input,
          $final,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## getstate
  ///
  /// ### python docstring
  ///
  /// Return the current state of the encoder.
  Object? getstate() => getFunction("getstate").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## reset
  ///
  /// ### python docstring
  ///
  /// Resets the encoder to the initial state.
  Object? reset() => getFunction("reset").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## setstate
  ///
  /// ### python docstring
  ///
  /// Set the current state of the encoder. state must have been
  /// returned by getstate().
  Object? setstate({
    required Object? state,
  }) =>
      getFunction("setstate").call(
        <Object?>[
          state,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## Codec
///
/// ### python docstring
///
/// Defines the interface for stateless encoders/decoders.
///
/// The .encode()/.decode() methods may use different error
/// handling schemes by providing the errors argument. These
/// string values are predefined:
///
///  'strict' - raise a ValueError error (or a subclass)
///  'ignore' - ignore the character and continue with the next
///  'replace' - replace with a suitable replacement character;
///             Python will use the official U+FFFD REPLACEMENT
///             CHARACTER for the builtin Unicode codecs on
///             decoding and '?' on encoding.
///  'surrogateescape' - replace with private code points U+DCnn.
///  'xmlcharrefreplace' - Replace with the appropriate XML
///                        character reference (only for encoding).
///  'backslashreplace'  - Replace with backslashed escape sequences.
///  'namereplace'       - Replace with \N{...} escape sequences
///                        (only for encoding).
///
/// The set of allowed values can be extended via register_error.
///
/// ### python source
/// ```py
/// class Codec:
///
///     """ Defines the interface for stateless encoders/decoders.
///
///         The .encode()/.decode() methods may use different error
///         handling schemes by providing the errors argument. These
///         string values are predefined:
///
///          'strict' - raise a ValueError error (or a subclass)
///          'ignore' - ignore the character and continue with the next
///          'replace' - replace with a suitable replacement character;
///                     Python will use the official U+FFFD REPLACEMENT
///                     CHARACTER for the builtin Unicode codecs on
///                     decoding and '?' on encoding.
///          'surrogateescape' - replace with private code points U+DCnn.
///          'xmlcharrefreplace' - Replace with the appropriate XML
///                                character reference (only for encoding).
///          'backslashreplace'  - Replace with backslashed escape sequences.
///          'namereplace'       - Replace with \\N{...} escape sequences
///                                (only for encoding).
///
///         The set of allowed values can be extended via register_error.
///
///     """
///     def encode(self, input, errors='strict'):
///
///         """ Encodes the object input and returns a tuple (output
///             object, length consumed).
///
///             errors defines the error handling to apply. It defaults to
///             'strict' handling.
///
///             The method may not store state in the Codec instance. Use
///             StreamWriter for codecs which have to keep state in order to
///             make encoding efficient.
///
///             The encoder must be able to handle zero length input and
///             return an empty object of the output object type in this
///             situation.
///
///         """
///         raise NotImplementedError
///
///     def decode(self, input, errors='strict'):
///
///         """ Decodes the object input and returns a tuple (output
///             object, length consumed).
///
///             input must be an object which provides the bf_getreadbuf
///             buffer slot. Python strings, buffer objects and memory
///             mapped files are examples of objects providing this slot.
///
///             errors defines the error handling to apply. It defaults to
///             'strict' handling.
///
///             The method may not store state in the Codec instance. Use
///             StreamReader for codecs which have to keep state in order to
///             make decoding efficient.
///
///             The decoder must be able to handle zero length input and
///             return an empty object of the output object type in this
///             situation.
///
///         """
///         raise NotImplementedError
/// ```
final class Codec extends PythonClass {
  factory Codec() => PythonFfiDart.instance.importClass(
        "codecs",
        "Codec",
        Codec.from,
        <Object?>[],
      );

  Codec.from(super.pythonClass) : super.from();

  /// ## decode
  ///
  /// ### python docstring
  ///
  /// Decodes the object input and returns a tuple (output
  /// object, length consumed).
  ///
  /// input must be an object which provides the bf_getreadbuf
  /// buffer slot. Python strings, buffer objects and memory
  /// mapped files are examples of objects providing this slot.
  ///
  /// errors defines the error handling to apply. It defaults to
  /// 'strict' handling.
  ///
  /// The method may not store state in the Codec instance. Use
  /// StreamReader for codecs which have to keep state in order to
  /// make decoding efficient.
  ///
  /// The decoder must be able to handle zero length input and
  /// return an empty object of the output object type in this
  /// situation.
  Object? decode({
    required Object? input,
    Object? errors = "strict",
  }) =>
      getFunction("decode").call(
        <Object?>[
          input,
          errors,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## encode
  ///
  /// ### python docstring
  ///
  /// Encodes the object input and returns a tuple (output
  /// object, length consumed).
  ///
  /// errors defines the error handling to apply. It defaults to
  /// 'strict' handling.
  ///
  /// The method may not store state in the Codec instance. Use
  /// StreamWriter for codecs which have to keep state in order to
  /// make encoding efficient.
  ///
  /// The encoder must be able to handle zero length input and
  /// return an empty object of the output object type in this
  /// situation.
  Object? encode({
    required Object? input,
    Object? errors = "strict",
  }) =>
      getFunction("encode").call(
        <Object?>[
          input,
          errors,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## CodecInfo
///
/// ### python docstring
///
/// Codec details when looking up the codec registry
///
/// ### python source
/// ```py
/// class CodecInfo(tuple):
///     """Codec details when looking up the codec registry"""
///
///     # Private API to allow Python 3.4 to denylist the known non-Unicode
///     # codecs in the standard library. A more general mechanism to
///     # reliably distinguish test encodings from other codecs will hopefully
///     # be defined for Python 3.5
///     #
///     # See http://bugs.python.org/issue19619
///     _is_text_encoding = True # Assume codecs are text encodings by default
///
///     def __new__(cls, encode, decode, streamreader=None, streamwriter=None,
///         incrementalencoder=None, incrementaldecoder=None, name=None,
///         *, _is_text_encoding=None):
///         self = tuple.__new__(cls, (encode, decode, streamreader, streamwriter))
///         self.name = name
///         self.encode = encode
///         self.decode = decode
///         self.incrementalencoder = incrementalencoder
///         self.incrementaldecoder = incrementaldecoder
///         self.streamwriter = streamwriter
///         self.streamreader = streamreader
///         if _is_text_encoding is not None:
///             self._is_text_encoding = _is_text_encoding
///         return self
///
///     def __repr__(self):
///         return "<%s.%s object for encoding %s at %#x>" % \
///                 (self.__class__.__module__, self.__class__.__qualname__,
///                  self.name, id(self))
/// ```
final class CodecInfo extends PythonClass {
  factory CodecInfo() => PythonFfiDart.instance.importClass(
        "codecs",
        "CodecInfo",
        CodecInfo.from,
        <Object?>[],
      );

  CodecInfo.from(super.pythonClass) : super.from();

  /// ## count (getter)
  Object? get count => getAttribute("count");

  /// ## count (setter)
  set count(Object? count) => setAttribute("count", count);

  /// ## index (getter)
  Object? get index => getAttribute("index");

  /// ## index (setter)
  set index(Object? index) => setAttribute("index", index);
}

/// ## IncrementalDecoder
///
/// ### python docstring
///
/// An IncrementalDecoder decodes an input in multiple steps. The input can
/// be passed piece by piece to the decode() method. The IncrementalDecoder
/// remembers the state of the decoding process between calls to decode().
///
/// ### python source
/// ```py
/// class IncrementalDecoder(object):
///     """
///     An IncrementalDecoder decodes an input in multiple steps. The input can
///     be passed piece by piece to the decode() method. The IncrementalDecoder
///     remembers the state of the decoding process between calls to decode().
///     """
///     def __init__(self, errors='strict'):
///         """
///         Create an IncrementalDecoder instance.
///
///         The IncrementalDecoder may use different error handling schemes by
///         providing the errors keyword argument. See the module docstring
///         for a list of possible values.
///         """
///         self.errors = errors
///
///     def decode(self, input, final=False):
///         """
///         Decode input and returns the resulting object.
///         """
///         raise NotImplementedError
///
///     def reset(self):
///         """
///         Reset the decoder to the initial state.
///         """
///
///     def getstate(self):
///         """
///         Return the current state of the decoder.
///
///         This must be a (buffered_input, additional_state_info) tuple.
///         buffered_input must be a bytes object containing bytes that
///         were passed to decode() that have not yet been converted.
///         additional_state_info must be a non-negative integer
///         representing the state of the decoder WITHOUT yet having
///         processed the contents of buffered_input.  In the initial state
///         and after reset(), getstate() must return (b"", 0).
///         """
///         return (b"", 0)
///
///     def setstate(self, state):
///         """
///         Set the current state of the decoder.
///
///         state must have been returned by getstate().  The effect of
///         setstate((b"", 0)) must be equivalent to reset().
///         """
/// ```
final class IncrementalDecoder extends PythonClass {
  factory IncrementalDecoder({
    Object? errors = "strict",
  }) =>
      PythonFfiDart.instance.importClass(
        "codecs",
        "IncrementalDecoder",
        IncrementalDecoder.from,
        <Object?>[
          errors,
        ],
        <String, Object?>{},
      );

  IncrementalDecoder.from(super.pythonClass) : super.from();

  /// ## decode
  ///
  /// ### python docstring
  ///
  /// Decode input and returns the resulting object.
  Object? decode({
    required Object? input,
    Object? $final = false,
  }) =>
      getFunction("decode").call(
        <Object?>[
          input,
          $final,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## getstate
  ///
  /// ### python docstring
  ///
  /// Return the current state of the decoder.
  ///
  /// This must be a (buffered_input, additional_state_info) tuple.
  /// buffered_input must be a bytes object containing bytes that
  /// were passed to decode() that have not yet been converted.
  /// additional_state_info must be a non-negative integer
  /// representing the state of the decoder WITHOUT yet having
  /// processed the contents of buffered_input.  In the initial state
  /// and after reset(), getstate() must return (b"", 0).
  Object? getstate() => getFunction("getstate").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## reset
  ///
  /// ### python docstring
  ///
  /// Reset the decoder to the initial state.
  Object? reset() => getFunction("reset").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## setstate
  ///
  /// ### python docstring
  ///
  /// Set the current state of the decoder.
  ///
  /// state must have been returned by getstate().  The effect of
  /// setstate((b"", 0)) must be equivalent to reset().
  Object? setstate({
    required Object? state,
  }) =>
      getFunction("setstate").call(
        <Object?>[
          state,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## IncrementalEncoder
///
/// ### python docstring
///
/// An IncrementalEncoder encodes an input in multiple steps. The input can
/// be passed piece by piece to the encode() method. The IncrementalEncoder
/// remembers the state of the encoding process between calls to encode().
///
/// ### python source
/// ```py
/// class IncrementalEncoder(object):
///     """
///     An IncrementalEncoder encodes an input in multiple steps. The input can
///     be passed piece by piece to the encode() method. The IncrementalEncoder
///     remembers the state of the encoding process between calls to encode().
///     """
///     def __init__(self, errors='strict'):
///         """
///         Creates an IncrementalEncoder instance.
///
///         The IncrementalEncoder may use different error handling schemes by
///         providing the errors keyword argument. See the module docstring
///         for a list of possible values.
///         """
///         self.errors = errors
///         self.buffer = ""
///
///     def encode(self, input, final=False):
///         """
///         Encodes input and returns the resulting object.
///         """
///         raise NotImplementedError
///
///     def reset(self):
///         """
///         Resets the encoder to the initial state.
///         """
///
///     def getstate(self):
///         """
///         Return the current state of the encoder.
///         """
///         return 0
///
///     def setstate(self, state):
///         """
///         Set the current state of the encoder. state must have been
///         returned by getstate().
///         """
/// ```
final class IncrementalEncoder extends PythonClass {
  factory IncrementalEncoder({
    Object? errors = "strict",
  }) =>
      PythonFfiDart.instance.importClass(
        "codecs",
        "IncrementalEncoder",
        IncrementalEncoder.from,
        <Object?>[
          errors,
        ],
        <String, Object?>{},
      );

  IncrementalEncoder.from(super.pythonClass) : super.from();

  /// ## encode
  ///
  /// ### python docstring
  ///
  /// Encodes input and returns the resulting object.
  Object? encode({
    required Object? input,
    Object? $final = false,
  }) =>
      getFunction("encode").call(
        <Object?>[
          input,
          $final,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## getstate
  ///
  /// ### python docstring
  ///
  /// Return the current state of the encoder.
  Object? getstate() => getFunction("getstate").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## reset
  ///
  /// ### python docstring
  ///
  /// Resets the encoder to the initial state.
  Object? reset() => getFunction("reset").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## setstate
  ///
  /// ### python docstring
  ///
  /// Set the current state of the encoder. state must have been
  /// returned by getstate().
  Object? setstate({
    required Object? state,
  }) =>
      getFunction("setstate").call(
        <Object?>[
          state,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## StreamReader
///
/// ### python docstring
///
/// Defines the interface for stateless encoders/decoders.
///
/// The .encode()/.decode() methods may use different error
/// handling schemes by providing the errors argument. These
/// string values are predefined:
///
///  'strict' - raise a ValueError error (or a subclass)
///  'ignore' - ignore the character and continue with the next
///  'replace' - replace with a suitable replacement character;
///             Python will use the official U+FFFD REPLACEMENT
///             CHARACTER for the builtin Unicode codecs on
///             decoding and '?' on encoding.
///  'surrogateescape' - replace with private code points U+DCnn.
///  'xmlcharrefreplace' - Replace with the appropriate XML
///                        character reference (only for encoding).
///  'backslashreplace'  - Replace with backslashed escape sequences.
///  'namereplace'       - Replace with \N{...} escape sequences
///                        (only for encoding).
///
/// The set of allowed values can be extended via register_error.
///
/// ### python source
/// ```py
/// class StreamReader(Codec):
///
///     charbuffertype = str
///
///     def __init__(self, stream, errors='strict'):
///
///         """ Creates a StreamReader instance.
///
///             stream must be a file-like object open for reading.
///
///             The StreamReader may use different error handling
///             schemes by providing the errors keyword argument. These
///             parameters are predefined:
///
///              'strict' - raise a ValueError (or a subclass)
///              'ignore' - ignore the character and continue with the next
///              'replace'- replace with a suitable replacement character
///              'backslashreplace' - Replace with backslashed escape sequences;
///
///             The set of allowed parameter values can be extended via
///             register_error.
///         """
///         self.stream = stream
///         self.errors = errors
///         self.bytebuffer = b""
///         self._empty_charbuffer = self.charbuffertype()
///         self.charbuffer = self._empty_charbuffer
///         self.linebuffer = None
///
///     def decode(self, input, errors='strict'):
///         raise NotImplementedError
///
///     def read(self, size=-1, chars=-1, firstline=False):
///
///         """ Decodes data from the stream self.stream and returns the
///             resulting object.
///
///             chars indicates the number of decoded code points or bytes to
///             return. read() will never return more data than requested,
///             but it might return less, if there is not enough available.
///
///             size indicates the approximate maximum number of decoded
///             bytes or code points to read for decoding. The decoder
///             can modify this setting as appropriate. The default value
///             -1 indicates to read and decode as much as possible.  size
///             is intended to prevent having to decode huge files in one
///             step.
///
///             If firstline is true, and a UnicodeDecodeError happens
///             after the first line terminator in the input only the first line
///             will be returned, the rest of the input will be kept until the
///             next call to read().
///
///             The method should use a greedy read strategy, meaning that
///             it should read as much data as is allowed within the
///             definition of the encoding and the given size, e.g.  if
///             optional encoding endings or state markers are available
///             on the stream, these should be read too.
///         """
///         # If we have lines cached, first merge them back into characters
///         if self.linebuffer:
///             self.charbuffer = self._empty_charbuffer.join(self.linebuffer)
///             self.linebuffer = None
///
///         if chars < 0:
///             # For compatibility with other read() methods that take a
///             # single argument
///             chars = size
///
///         # read until we get the required number of characters (if available)
///         while True:
///             # can the request be satisfied from the character buffer?
///             if chars >= 0:
///                 if len(self.charbuffer) >= chars:
///                     break
///             # we need more data
///             if size < 0:
///                 newdata = self.stream.read()
///             else:
///                 newdata = self.stream.read(size)
///             # decode bytes (those remaining from the last call included)
///             data = self.bytebuffer + newdata
///             if not data:
///                 break
///             try:
///                 newchars, decodedbytes = self.decode(data, self.errors)
///             except UnicodeDecodeError as exc:
///                 if firstline:
///                     newchars, decodedbytes = \
///                         self.decode(data[:exc.start], self.errors)
///                     lines = newchars.splitlines(keepends=True)
///                     if len(lines)<=1:
///                         raise
///                 else:
///                     raise
///             # keep undecoded bytes until the next call
///             self.bytebuffer = data[decodedbytes:]
///             # put new characters in the character buffer
///             self.charbuffer += newchars
///             # there was no data available
///             if not newdata:
///                 break
///         if chars < 0:
///             # Return everything we've got
///             result = self.charbuffer
///             self.charbuffer = self._empty_charbuffer
///         else:
///             # Return the first chars characters
///             result = self.charbuffer[:chars]
///             self.charbuffer = self.charbuffer[chars:]
///         return result
///
///     def readline(self, size=None, keepends=True):
///
///         """ Read one line from the input stream and return the
///             decoded data.
///
///             size, if given, is passed as size argument to the
///             read() method.
///
///         """
///         # If we have lines cached from an earlier read, return
///         # them unconditionally
///         if self.linebuffer:
///             line = self.linebuffer[0]
///             del self.linebuffer[0]
///             if len(self.linebuffer) == 1:
///                 # revert to charbuffer mode; we might need more data
///                 # next time
///                 self.charbuffer = self.linebuffer[0]
///                 self.linebuffer = None
///             if not keepends:
///                 line = line.splitlines(keepends=False)[0]
///             return line
///
///         readsize = size or 72
///         line = self._empty_charbuffer
///         # If size is given, we call read() only once
///         while True:
///             data = self.read(readsize, firstline=True)
///             if data:
///                 # If we're at a "\r" read one extra character (which might
///                 # be a "\n") to get a proper line ending. If the stream is
///                 # temporarily exhausted we return the wrong line ending.
///                 if (isinstance(data, str) and data.endswith("\r")) or \
///                    (isinstance(data, bytes) and data.endswith(b"\r")):
///                     data += self.read(size=1, chars=1)
///
///             line += data
///             lines = line.splitlines(keepends=True)
///             if lines:
///                 if len(lines) > 1:
///                     # More than one line result; the first line is a full line
///                     # to return
///                     line = lines[0]
///                     del lines[0]
///                     if len(lines) > 1:
///                         # cache the remaining lines
///                         lines[-1] += self.charbuffer
///                         self.linebuffer = lines
///                         self.charbuffer = None
///                     else:
///                         # only one remaining line, put it back into charbuffer
///                         self.charbuffer = lines[0] + self.charbuffer
///                     if not keepends:
///                         line = line.splitlines(keepends=False)[0]
///                     break
///                 line0withend = lines[0]
///                 line0withoutend = lines[0].splitlines(keepends=False)[0]
///                 if line0withend != line0withoutend: # We really have a line end
///                     # Put the rest back together and keep it until the next call
///                     self.charbuffer = self._empty_charbuffer.join(lines[1:]) + \
///                                       self.charbuffer
///                     if keepends:
///                         line = line0withend
///                     else:
///                         line = line0withoutend
///                     break
///             # we didn't get anything or this was our only try
///             if not data or size is not None:
///                 if line and not keepends:
///                     line = line.splitlines(keepends=False)[0]
///                 break
///             if readsize < 8000:
///                 readsize *= 2
///         return line
///
///     def readlines(self, sizehint=None, keepends=True):
///
///         """ Read all lines available on the input stream
///             and return them as a list.
///
///             Line breaks are implemented using the codec's decoder
///             method and are included in the list entries.
///
///             sizehint, if given, is ignored since there is no efficient
///             way to finding the true end-of-line.
///
///         """
///         data = self.read()
///         return data.splitlines(keepends)
///
///     def reset(self):
///
///         """ Resets the codec buffers used for keeping internal state.
///
///             Note that no stream repositioning should take place.
///             This method is primarily intended to be able to recover
///             from decoding errors.
///
///         """
///         self.bytebuffer = b""
///         self.charbuffer = self._empty_charbuffer
///         self.linebuffer = None
///
///     def seek(self, offset, whence=0):
///         """ Set the input stream's current position.
///
///             Resets the codec buffers used for keeping state.
///         """
///         self.stream.seek(offset, whence)
///         self.reset()
///
///     def __next__(self):
///
///         """ Return the next decoded line from the input stream."""
///         line = self.readline()
///         if line:
///             return line
///         raise StopIteration
///
///     def __iter__(self):
///         return self
///
///     def __getattr__(self, name,
///                     getattr=getattr):
///
///         """ Inherit all other methods from the underlying stream.
///         """
///         return getattr(self.stream, name)
///
///     def __enter__(self):
///         return self
///
///     def __exit__(self, type, value, tb):
///         self.stream.close()
/// ```
final class StreamReader extends PythonClass {
  factory StreamReader({
    required Object? stream,
    Object? errors = "strict",
  }) =>
      PythonFfiDart.instance.importClass(
        "codecs",
        "StreamReader",
        StreamReader.from,
        <Object?>[
          stream,
          errors,
        ],
        <String, Object?>{},
      );

  StreamReader.from(super.pythonClass) : super.from();

  /// ## decode
  ///
  /// ### python docstring
  ///
  /// Decodes the object input and returns a tuple (output
  /// object, length consumed).
  ///
  /// input must be an object which provides the bf_getreadbuf
  /// buffer slot. Python strings, buffer objects and memory
  /// mapped files are examples of objects providing this slot.
  ///
  /// errors defines the error handling to apply. It defaults to
  /// 'strict' handling.
  ///
  /// The method may not store state in the Codec instance. Use
  /// StreamReader for codecs which have to keep state in order to
  /// make decoding efficient.
  ///
  /// The decoder must be able to handle zero length input and
  /// return an empty object of the output object type in this
  /// situation.
  Object? decode({
    required Object? input,
    Object? errors = "strict",
  }) =>
      getFunction("decode").call(
        <Object?>[
          input,
          errors,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## encode
  ///
  /// ### python docstring
  ///
  /// Encodes the object input and returns a tuple (output
  /// object, length consumed).
  ///
  /// errors defines the error handling to apply. It defaults to
  /// 'strict' handling.
  ///
  /// The method may not store state in the Codec instance. Use
  /// StreamWriter for codecs which have to keep state in order to
  /// make encoding efficient.
  ///
  /// The encoder must be able to handle zero length input and
  /// return an empty object of the output object type in this
  /// situation.
  Object? encode({
    required Object? input,
    Object? errors = "strict",
  }) =>
      getFunction("encode").call(
        <Object?>[
          input,
          errors,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## read
  ///
  /// ### python docstring
  ///
  /// Decodes data from the stream self.stream and returns the
  /// resulting object.
  ///
  /// chars indicates the number of decoded code points or bytes to
  /// return. read() will never return more data than requested,
  /// but it might return less, if there is not enough available.
  ///
  /// size indicates the approximate maximum number of decoded
  /// bytes or code points to read for decoding. The decoder
  /// can modify this setting as appropriate. The default value
  /// -1 indicates to read and decode as much as possible.  size
  /// is intended to prevent having to decode huge files in one
  /// step.
  ///
  /// If firstline is true, and a UnicodeDecodeError happens
  /// after the first line terminator in the input only the first line
  /// will be returned, the rest of the input will be kept until the
  /// next call to read().
  ///
  /// The method should use a greedy read strategy, meaning that
  /// it should read as much data as is allowed within the
  /// definition of the encoding and the given size, e.g.  if
  /// optional encoding endings or state markers are available
  /// on the stream, these should be read too.
  Object? read({
    Object? size = -1,
    Object? chars = -1,
    Object? firstline = false,
  }) =>
      getFunction("read").call(
        <Object?>[
          size,
          chars,
          firstline,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## readline
  ///
  /// ### python docstring
  ///
  /// Read one line from the input stream and return the
  /// decoded data.
  ///
  /// size, if given, is passed as size argument to the
  /// read() method.
  Object? readline({
    Object? size,
    Object? keepends = true,
  }) =>
      getFunction("readline").call(
        <Object?>[
          size,
          keepends,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## readlines
  ///
  /// ### python docstring
  ///
  /// Read all lines available on the input stream
  /// and return them as a list.
  ///
  /// Line breaks are implemented using the codec's decoder
  /// method and are included in the list entries.
  ///
  /// sizehint, if given, is ignored since there is no efficient
  /// way to finding the true end-of-line.
  Object? readlines({
    Object? sizehint,
    Object? keepends = true,
  }) =>
      getFunction("readlines").call(
        <Object?>[
          sizehint,
          keepends,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## reset
  ///
  /// ### python docstring
  ///
  /// Resets the codec buffers used for keeping internal state.
  ///
  /// Note that no stream repositioning should take place.
  /// This method is primarily intended to be able to recover
  /// from decoding errors.
  Object? reset() => getFunction("reset").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## seek
  ///
  /// ### python docstring
  ///
  /// Set the input stream's current position.
  ///
  /// Resets the codec buffers used for keeping state.
  Object? seek({
    required Object? offset,
    Object? whence = 0,
  }) =>
      getFunction("seek").call(
        <Object?>[
          offset,
          whence,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## charbuffertype
final class charbuffertype extends PythonClass {
  factory charbuffertype() => PythonFfiDart.instance.importClass(
        "builtins",
        "charbuffertype",
        charbuffertype.from,
        <Object?>[],
      );

  charbuffertype.from(super.pythonClass) : super.from();

  /// ## capitalize (getter)
  Object? get capitalize => getAttribute("capitalize");

  /// ## capitalize (setter)
  set capitalize(Object? capitalize) => setAttribute("capitalize", capitalize);

  /// ## casefold (getter)
  Object? get casefold => getAttribute("casefold");

  /// ## casefold (setter)
  set casefold(Object? casefold) => setAttribute("casefold", casefold);

  /// ## center (getter)
  Object? get center => getAttribute("center");

  /// ## center (setter)
  set center(Object? center) => setAttribute("center", center);

  /// ## count (getter)
  Object? get count => getAttribute("count");

  /// ## count (setter)
  set count(Object? count) => setAttribute("count", count);

  /// ## encode (getter)
  Object? get encode => getAttribute("encode");

  /// ## encode (setter)
  set encode(Object? encode) => setAttribute("encode", encode);

  /// ## endswith (getter)
  Object? get endswith => getAttribute("endswith");

  /// ## endswith (setter)
  set endswith(Object? endswith) => setAttribute("endswith", endswith);

  /// ## expandtabs (getter)
  Object? get expandtabs => getAttribute("expandtabs");

  /// ## expandtabs (setter)
  set expandtabs(Object? expandtabs) => setAttribute("expandtabs", expandtabs);

  /// ## find (getter)
  Object? get find => getAttribute("find");

  /// ## find (setter)
  set find(Object? find) => setAttribute("find", find);

  /// ## format (getter)
  Object? get format => getAttribute("format");

  /// ## format (setter)
  set format(Object? format) => setAttribute("format", format);

  /// ## format_map (getter)
  Object? get format_map => getAttribute("format_map");

  /// ## format_map (setter)
  set format_map(Object? format_map) => setAttribute("format_map", format_map);

  /// ## index (getter)
  Object? get index => getAttribute("index");

  /// ## index (setter)
  set index(Object? index) => setAttribute("index", index);

  /// ## isalnum (getter)
  Object? get isalnum => getAttribute("isalnum");

  /// ## isalnum (setter)
  set isalnum(Object? isalnum) => setAttribute("isalnum", isalnum);

  /// ## isalpha (getter)
  Object? get isalpha => getAttribute("isalpha");

  /// ## isalpha (setter)
  set isalpha(Object? isalpha) => setAttribute("isalpha", isalpha);

  /// ## isascii (getter)
  Object? get isascii => getAttribute("isascii");

  /// ## isascii (setter)
  set isascii(Object? isascii) => setAttribute("isascii", isascii);

  /// ## isdecimal (getter)
  Object? get isdecimal => getAttribute("isdecimal");

  /// ## isdecimal (setter)
  set isdecimal(Object? isdecimal) => setAttribute("isdecimal", isdecimal);

  /// ## isdigit (getter)
  Object? get isdigit => getAttribute("isdigit");

  /// ## isdigit (setter)
  set isdigit(Object? isdigit) => setAttribute("isdigit", isdigit);

  /// ## isidentifier (getter)
  Object? get isidentifier => getAttribute("isidentifier");

  /// ## isidentifier (setter)
  set isidentifier(Object? isidentifier) =>
      setAttribute("isidentifier", isidentifier);

  /// ## islower (getter)
  Object? get islower => getAttribute("islower");

  /// ## islower (setter)
  set islower(Object? islower) => setAttribute("islower", islower);

  /// ## isnumeric (getter)
  Object? get isnumeric => getAttribute("isnumeric");

  /// ## isnumeric (setter)
  set isnumeric(Object? isnumeric) => setAttribute("isnumeric", isnumeric);

  /// ## isprintable (getter)
  Object? get isprintable => getAttribute("isprintable");

  /// ## isprintable (setter)
  set isprintable(Object? isprintable) =>
      setAttribute("isprintable", isprintable);

  /// ## isspace (getter)
  Object? get isspace => getAttribute("isspace");

  /// ## isspace (setter)
  set isspace(Object? isspace) => setAttribute("isspace", isspace);

  /// ## istitle (getter)
  Object? get istitle => getAttribute("istitle");

  /// ## istitle (setter)
  set istitle(Object? istitle) => setAttribute("istitle", istitle);

  /// ## isupper (getter)
  Object? get isupper => getAttribute("isupper");

  /// ## isupper (setter)
  set isupper(Object? isupper) => setAttribute("isupper", isupper);

  /// ## join (getter)
  Object? get join => getAttribute("join");

  /// ## join (setter)
  set join(Object? join) => setAttribute("join", join);

  /// ## ljust (getter)
  Object? get ljust => getAttribute("ljust");

  /// ## ljust (setter)
  set ljust(Object? ljust) => setAttribute("ljust", ljust);

  /// ## lower (getter)
  Object? get lower => getAttribute("lower");

  /// ## lower (setter)
  set lower(Object? lower) => setAttribute("lower", lower);

  /// ## lstrip (getter)
  Object? get lstrip => getAttribute("lstrip");

  /// ## lstrip (setter)
  set lstrip(Object? lstrip) => setAttribute("lstrip", lstrip);

  /// ## partition (getter)
  Object? get partition => getAttribute("partition");

  /// ## partition (setter)
  set partition(Object? partition) => setAttribute("partition", partition);

  /// ## removeprefix (getter)
  Object? get removeprefix => getAttribute("removeprefix");

  /// ## removeprefix (setter)
  set removeprefix(Object? removeprefix) =>
      setAttribute("removeprefix", removeprefix);

  /// ## removesuffix (getter)
  Object? get removesuffix => getAttribute("removesuffix");

  /// ## removesuffix (setter)
  set removesuffix(Object? removesuffix) =>
      setAttribute("removesuffix", removesuffix);

  /// ## replace (getter)
  Object? get replace => getAttribute("replace");

  /// ## replace (setter)
  set replace(Object? replace) => setAttribute("replace", replace);

  /// ## rfind (getter)
  Object? get rfind => getAttribute("rfind");

  /// ## rfind (setter)
  set rfind(Object? rfind) => setAttribute("rfind", rfind);

  /// ## rindex (getter)
  Object? get rindex => getAttribute("rindex");

  /// ## rindex (setter)
  set rindex(Object? rindex) => setAttribute("rindex", rindex);

  /// ## rjust (getter)
  Object? get rjust => getAttribute("rjust");

  /// ## rjust (setter)
  set rjust(Object? rjust) => setAttribute("rjust", rjust);

  /// ## rpartition (getter)
  Object? get rpartition => getAttribute("rpartition");

  /// ## rpartition (setter)
  set rpartition(Object? rpartition) => setAttribute("rpartition", rpartition);

  /// ## rsplit (getter)
  Object? get rsplit => getAttribute("rsplit");

  /// ## rsplit (setter)
  set rsplit(Object? rsplit) => setAttribute("rsplit", rsplit);

  /// ## rstrip (getter)
  Object? get rstrip => getAttribute("rstrip");

  /// ## rstrip (setter)
  set rstrip(Object? rstrip) => setAttribute("rstrip", rstrip);

  /// ## split (getter)
  Object? get split => getAttribute("split");

  /// ## split (setter)
  set split(Object? split) => setAttribute("split", split);

  /// ## splitlines (getter)
  Object? get splitlines => getAttribute("splitlines");

  /// ## splitlines (setter)
  set splitlines(Object? splitlines) => setAttribute("splitlines", splitlines);

  /// ## startswith (getter)
  Object? get startswith => getAttribute("startswith");

  /// ## startswith (setter)
  set startswith(Object? startswith) => setAttribute("startswith", startswith);

  /// ## strip (getter)
  Object? get strip => getAttribute("strip");

  /// ## strip (setter)
  set strip(Object? strip) => setAttribute("strip", strip);

  /// ## swapcase (getter)
  Object? get swapcase => getAttribute("swapcase");

  /// ## swapcase (setter)
  set swapcase(Object? swapcase) => setAttribute("swapcase", swapcase);

  /// ## title (getter)
  Object? get title => getAttribute("title");

  /// ## title (setter)
  set title(Object? title) => setAttribute("title", title);

  /// ## translate (getter)
  Object? get translate => getAttribute("translate");

  /// ## translate (setter)
  set translate(Object? translate) => setAttribute("translate", translate);

  /// ## upper (getter)
  Object? get upper => getAttribute("upper");

  /// ## upper (setter)
  set upper(Object? upper) => setAttribute("upper", upper);

  /// ## zfill (getter)
  Object? get zfill => getAttribute("zfill");

  /// ## zfill (setter)
  set zfill(Object? zfill) => setAttribute("zfill", zfill);
}

/// ## StreamReaderWriter
///
/// ### python docstring
///
/// StreamReaderWriter instances allow wrapping streams which
/// work in both read and write modes.
///
/// The design is such that one can use the factory functions
/// returned by the codec.lookup() function to construct the
/// instance.
///
/// ### python source
/// ```py
/// class StreamReaderWriter:
///
///     """ StreamReaderWriter instances allow wrapping streams which
///         work in both read and write modes.
///
///         The design is such that one can use the factory functions
///         returned by the codec.lookup() function to construct the
///         instance.
///
///     """
///     # Optional attributes set by the file wrappers below
///     encoding = 'unknown'
///
///     def __init__(self, stream, Reader, Writer, errors='strict'):
///
///         """ Creates a StreamReaderWriter instance.
///
///             stream must be a Stream-like object.
///
///             Reader, Writer must be factory functions or classes
///             providing the StreamReader, StreamWriter interface resp.
///
///             Error handling is done in the same way as defined for the
///             StreamWriter/Readers.
///
///         """
///         self.stream = stream
///         self.reader = Reader(stream, errors)
///         self.writer = Writer(stream, errors)
///         self.errors = errors
///
///     def read(self, size=-1):
///
///         return self.reader.read(size)
///
///     def readline(self, size=None):
///
///         return self.reader.readline(size)
///
///     def readlines(self, sizehint=None):
///
///         return self.reader.readlines(sizehint)
///
///     def __next__(self):
///
///         """ Return the next decoded line from the input stream."""
///         return next(self.reader)
///
///     def __iter__(self):
///         return self
///
///     def write(self, data):
///
///         return self.writer.write(data)
///
///     def writelines(self, list):
///
///         return self.writer.writelines(list)
///
///     def reset(self):
///
///         self.reader.reset()
///         self.writer.reset()
///
///     def seek(self, offset, whence=0):
///         self.stream.seek(offset, whence)
///         self.reader.reset()
///         if whence == 0 and offset == 0:
///             self.writer.reset()
///
///     def __getattr__(self, name,
///                     getattr=getattr):
///
///         """ Inherit all other methods from the underlying stream.
///         """
///         return getattr(self.stream, name)
///
///     # these are needed to make "with StreamReaderWriter(...)" work properly
///
///     def __enter__(self):
///         return self
///
///     def __exit__(self, type, value, tb):
///         self.stream.close()
/// ```
final class StreamReaderWriter extends PythonClass {
  factory StreamReaderWriter({
    required Object? stream,
    required Object? Reader,
    required Object? Writer,
    Object? errors = "strict",
  }) =>
      PythonFfiDart.instance.importClass(
        "codecs",
        "StreamReaderWriter",
        StreamReaderWriter.from,
        <Object?>[
          stream,
          Reader,
          Writer,
          errors,
        ],
        <String, Object?>{},
      );

  StreamReaderWriter.from(super.pythonClass) : super.from();

  /// ## read
  Object? read({
    Object? size = -1,
  }) =>
      getFunction("read").call(
        <Object?>[
          size,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## readline
  Object? readline({
    Object? size,
  }) =>
      getFunction("readline").call(
        <Object?>[
          size,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## readlines
  Object? readlines({
    Object? sizehint,
  }) =>
      getFunction("readlines").call(
        <Object?>[
          sizehint,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## reset
  Object? reset() => getFunction("reset").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## seek
  Object? seek({
    required Object? offset,
    Object? whence = 0,
  }) =>
      getFunction("seek").call(
        <Object?>[
          offset,
          whence,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## write
  Object? write({
    required Object? data,
  }) =>
      getFunction("write").call(
        <Object?>[
          data,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## writelines
  Object? writelines({
    required Object? list,
  }) =>
      getFunction("writelines").call(
        <Object?>[
          list,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## encoding (getter)
  Object? get encoding => getAttribute("encoding");

  /// ## encoding (setter)
  set encoding(Object? encoding) => setAttribute("encoding", encoding);
}

/// ## StreamRecoder
///
/// ### python docstring
///
/// StreamRecoder instances translate data from one encoding to another.
///
/// They use the complete set of APIs returned by the
/// codecs.lookup() function to implement their task.
///
/// Data written to the StreamRecoder is first decoded into an
/// intermediate format (depending on the "decode" codec) and then
/// written to the underlying stream using an instance of the provided
/// Writer class.
///
/// In the other direction, data is read from the underlying stream using
/// a Reader instance and then encoded and returned to the caller.
///
/// ### python source
/// ```py
/// class StreamRecoder:
///
///     """ StreamRecoder instances translate data from one encoding to another.
///
///         They use the complete set of APIs returned by the
///         codecs.lookup() function to implement their task.
///
///         Data written to the StreamRecoder is first decoded into an
///         intermediate format (depending on the "decode" codec) and then
///         written to the underlying stream using an instance of the provided
///         Writer class.
///
///         In the other direction, data is read from the underlying stream using
///         a Reader instance and then encoded and returned to the caller.
///
///     """
///     # Optional attributes set by the file wrappers below
///     data_encoding = 'unknown'
///     file_encoding = 'unknown'
///
///     def __init__(self, stream, encode, decode, Reader, Writer,
///                  errors='strict'):
///
///         """ Creates a StreamRecoder instance which implements a two-way
///             conversion: encode and decode work on the frontend (the
///             data visible to .read() and .write()) while Reader and Writer
///             work on the backend (the data in stream).
///
///             You can use these objects to do transparent
///             transcodings from e.g. latin-1 to utf-8 and back.
///
///             stream must be a file-like object.
///
///             encode and decode must adhere to the Codec interface; Reader and
///             Writer must be factory functions or classes providing the
///             StreamReader and StreamWriter interfaces resp.
///
///             Error handling is done in the same way as defined for the
///             StreamWriter/Readers.
///
///         """
///         self.stream = stream
///         self.encode = encode
///         self.decode = decode
///         self.reader = Reader(stream, errors)
///         self.writer = Writer(stream, errors)
///         self.errors = errors
///
///     def read(self, size=-1):
///
///         data = self.reader.read(size)
///         data, bytesencoded = self.encode(data, self.errors)
///         return data
///
///     def readline(self, size=None):
///
///         if size is None:
///             data = self.reader.readline()
///         else:
///             data = self.reader.readline(size)
///         data, bytesencoded = self.encode(data, self.errors)
///         return data
///
///     def readlines(self, sizehint=None):
///
///         data = self.reader.read()
///         data, bytesencoded = self.encode(data, self.errors)
///         return data.splitlines(keepends=True)
///
///     def __next__(self):
///
///         """ Return the next decoded line from the input stream."""
///         data = next(self.reader)
///         data, bytesencoded = self.encode(data, self.errors)
///         return data
///
///     def __iter__(self):
///         return self
///
///     def write(self, data):
///
///         data, bytesdecoded = self.decode(data, self.errors)
///         return self.writer.write(data)
///
///     def writelines(self, list):
///
///         data = b''.join(list)
///         data, bytesdecoded = self.decode(data, self.errors)
///         return self.writer.write(data)
///
///     def reset(self):
///
///         self.reader.reset()
///         self.writer.reset()
///
///     def seek(self, offset, whence=0):
///         # Seeks must be propagated to both the readers and writers
///         # as they might need to reset their internal buffers.
///         self.reader.seek(offset, whence)
///         self.writer.seek(offset, whence)
///
///     def __getattr__(self, name,
///                     getattr=getattr):
///
///         """ Inherit all other methods from the underlying stream.
///         """
///         return getattr(self.stream, name)
///
///     def __enter__(self):
///         return self
///
///     def __exit__(self, type, value, tb):
///         self.stream.close()
/// ```
final class StreamRecoder extends PythonClass {
  factory StreamRecoder({
    required Object? stream,
    required Object? encode,
    required Object? decode,
    required Object? Reader,
    required Object? Writer,
    Object? errors = "strict",
  }) =>
      PythonFfiDart.instance.importClass(
        "codecs",
        "StreamRecoder",
        StreamRecoder.from,
        <Object?>[
          stream,
          encode,
          decode,
          Reader,
          Writer,
          errors,
        ],
        <String, Object?>{},
      );

  StreamRecoder.from(super.pythonClass) : super.from();

  /// ## read
  Object? read({
    Object? size = -1,
  }) =>
      getFunction("read").call(
        <Object?>[
          size,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## readline
  Object? readline({
    Object? size,
  }) =>
      getFunction("readline").call(
        <Object?>[
          size,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## readlines
  Object? readlines({
    Object? sizehint,
  }) =>
      getFunction("readlines").call(
        <Object?>[
          sizehint,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## reset
  Object? reset() => getFunction("reset").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## seek
  Object? seek({
    required Object? offset,
    Object? whence = 0,
  }) =>
      getFunction("seek").call(
        <Object?>[
          offset,
          whence,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## write
  Object? write({
    required Object? data,
  }) =>
      getFunction("write").call(
        <Object?>[
          data,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## writelines
  Object? writelines({
    required Object? list,
  }) =>
      getFunction("writelines").call(
        <Object?>[
          list,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## data_encoding (getter)
  Object? get data_encoding => getAttribute("data_encoding");

  /// ## data_encoding (setter)
  set data_encoding(Object? data_encoding) =>
      setAttribute("data_encoding", data_encoding);

  /// ## file_encoding (getter)
  Object? get file_encoding => getAttribute("file_encoding");

  /// ## file_encoding (setter)
  set file_encoding(Object? file_encoding) =>
      setAttribute("file_encoding", file_encoding);
}

/// ## StreamWriter
///
/// ### python docstring
///
/// Defines the interface for stateless encoders/decoders.
///
/// The .encode()/.decode() methods may use different error
/// handling schemes by providing the errors argument. These
/// string values are predefined:
///
///  'strict' - raise a ValueError error (or a subclass)
///  'ignore' - ignore the character and continue with the next
///  'replace' - replace with a suitable replacement character;
///             Python will use the official U+FFFD REPLACEMENT
///             CHARACTER for the builtin Unicode codecs on
///             decoding and '?' on encoding.
///  'surrogateescape' - replace with private code points U+DCnn.
///  'xmlcharrefreplace' - Replace with the appropriate XML
///                        character reference (only for encoding).
///  'backslashreplace'  - Replace with backslashed escape sequences.
///  'namereplace'       - Replace with \N{...} escape sequences
///                        (only for encoding).
///
/// The set of allowed values can be extended via register_error.
///
/// ### python source
/// ```py
/// class StreamWriter(Codec):
///
///     def __init__(self, stream, errors='strict'):
///
///         """ Creates a StreamWriter instance.
///
///             stream must be a file-like object open for writing.
///
///             The StreamWriter may use different error handling
///             schemes by providing the errors keyword argument. These
///             parameters are predefined:
///
///              'strict' - raise a ValueError (or a subclass)
///              'ignore' - ignore the character and continue with the next
///              'replace'- replace with a suitable replacement character
///              'xmlcharrefreplace' - Replace with the appropriate XML
///                                    character reference.
///              'backslashreplace'  - Replace with backslashed escape
///                                    sequences.
///              'namereplace'       - Replace with \\N{...} escape sequences.
///
///             The set of allowed parameter values can be extended via
///             register_error.
///         """
///         self.stream = stream
///         self.errors = errors
///
///     def write(self, object):
///
///         """ Writes the object's contents encoded to self.stream.
///         """
///         data, consumed = self.encode(object, self.errors)
///         self.stream.write(data)
///
///     def writelines(self, list):
///
///         """ Writes the concatenated list of strings to the stream
///             using .write().
///         """
///         self.write(''.join(list))
///
///     def reset(self):
///
///         """ Resets the codec buffers used for keeping internal state.
///
///             Calling this method should ensure that the data on the
///             output is put into a clean state, that allows appending
///             of new fresh data without having to rescan the whole
///             stream to recover state.
///
///         """
///         pass
///
///     def seek(self, offset, whence=0):
///         self.stream.seek(offset, whence)
///         if whence == 0 and offset == 0:
///             self.reset()
///
///     def __getattr__(self, name,
///                     getattr=getattr):
///
///         """ Inherit all other methods from the underlying stream.
///         """
///         return getattr(self.stream, name)
///
///     def __enter__(self):
///         return self
///
///     def __exit__(self, type, value, tb):
///         self.stream.close()
/// ```
final class StreamWriter extends PythonClass {
  factory StreamWriter({
    required Object? stream,
    Object? errors = "strict",
  }) =>
      PythonFfiDart.instance.importClass(
        "codecs",
        "StreamWriter",
        StreamWriter.from,
        <Object?>[
          stream,
          errors,
        ],
        <String, Object?>{},
      );

  StreamWriter.from(super.pythonClass) : super.from();

  /// ## decode
  ///
  /// ### python docstring
  ///
  /// Decodes the object input and returns a tuple (output
  /// object, length consumed).
  ///
  /// input must be an object which provides the bf_getreadbuf
  /// buffer slot. Python strings, buffer objects and memory
  /// mapped files are examples of objects providing this slot.
  ///
  /// errors defines the error handling to apply. It defaults to
  /// 'strict' handling.
  ///
  /// The method may not store state in the Codec instance. Use
  /// StreamReader for codecs which have to keep state in order to
  /// make decoding efficient.
  ///
  /// The decoder must be able to handle zero length input and
  /// return an empty object of the output object type in this
  /// situation.
  Object? decode({
    required Object? input,
    Object? errors = "strict",
  }) =>
      getFunction("decode").call(
        <Object?>[
          input,
          errors,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## encode
  ///
  /// ### python docstring
  ///
  /// Encodes the object input and returns a tuple (output
  /// object, length consumed).
  ///
  /// errors defines the error handling to apply. It defaults to
  /// 'strict' handling.
  ///
  /// The method may not store state in the Codec instance. Use
  /// StreamWriter for codecs which have to keep state in order to
  /// make encoding efficient.
  ///
  /// The encoder must be able to handle zero length input and
  /// return an empty object of the output object type in this
  /// situation.
  Object? encode({
    required Object? input,
    Object? errors = "strict",
  }) =>
      getFunction("encode").call(
        <Object?>[
          input,
          errors,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## reset
  ///
  /// ### python docstring
  ///
  /// Resets the codec buffers used for keeping internal state.
  ///
  /// Calling this method should ensure that the data on the
  /// output is put into a clean state, that allows appending
  /// of new fresh data without having to rescan the whole
  /// stream to recover state.
  Object? reset() => getFunction("reset").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## seek
  Object? seek({
    required Object? offset,
    Object? whence = 0,
  }) =>
      getFunction("seek").call(
        <Object?>[
          offset,
          whence,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## write
  ///
  /// ### python docstring
  ///
  /// Writes the object's contents encoded to self.stream.
  Object? write({
    required Object? object,
  }) =>
      getFunction("write").call(
        <Object?>[
          object,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## writelines
  ///
  /// ### python docstring
  ///
  /// Writes the concatenated list of strings to the stream
  /// using .write().
  Object? writelines({
    required Object? list,
  }) =>
      getFunction("writelines").call(
        <Object?>[
          list,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## ArithmeticError
final class ArithmeticError extends PythonClass {
  factory ArithmeticError() => PythonFfiDart.instance.importClass(
        "builtins",
        "ArithmeticError",
        ArithmeticError.from,
        <Object?>[],
      );

  ArithmeticError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## AssertionError
final class AssertionError extends PythonClass {
  factory AssertionError() => PythonFfiDart.instance.importClass(
        "builtins",
        "AssertionError",
        AssertionError.from,
        <Object?>[],
      );

  AssertionError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## AttributeError
final class AttributeError extends PythonClass {
  factory AttributeError() => PythonFfiDart.instance.importClass(
        "builtins",
        "AttributeError",
        AttributeError.from,
        <Object?>[],
      );

  AttributeError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);

  /// ## obj (getter)
  Object? get obj => getAttribute("obj");

  /// ## obj (setter)
  set obj(Object? obj) => setAttribute("obj", obj);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## BaseException
final class BaseException extends PythonClass {
  factory BaseException() => PythonFfiDart.instance.importClass(
        "builtins",
        "BaseException",
        BaseException.from,
        <Object?>[],
      );

  BaseException.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## BaseExceptionGroup
final class BaseExceptionGroup extends PythonClass {
  factory BaseExceptionGroup() => PythonFfiDart.instance.importClass(
        "builtins",
        "BaseExceptionGroup",
        BaseExceptionGroup.from,
        <Object?>[],
      );

  BaseExceptionGroup.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## exceptions (getter)
  Object? get exceptions => getAttribute("exceptions");

  /// ## exceptions (setter)
  set exceptions(Object? exceptions) => setAttribute("exceptions", exceptions);

  /// ## message (getter)
  Object? get message => getAttribute("message");

  /// ## message (setter)
  set message(Object? message) => setAttribute("message", message);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## derive (getter)
  Object? get derive => getAttribute("derive");

  /// ## derive (setter)
  set derive(Object? derive) => setAttribute("derive", derive);

  /// ## split (getter)
  Object? get split => getAttribute("split");

  /// ## split (setter)
  set split(Object? split) => setAttribute("split", split);

  /// ## subgroup (getter)
  Object? get subgroup => getAttribute("subgroup");

  /// ## subgroup (setter)
  set subgroup(Object? subgroup) => setAttribute("subgroup", subgroup);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## BrokenPipeError
final class BrokenPipeError extends PythonClass {
  factory BrokenPipeError() => PythonFfiDart.instance.importClass(
        "builtins",
        "BrokenPipeError",
        BrokenPipeError.from,
        <Object?>[],
      );

  BrokenPipeError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## characters_written (getter)
  Object? get characters_written => getAttribute("characters_written");

  /// ## characters_written (setter)
  set characters_written(Object? characters_written) =>
      setAttribute("characters_written", characters_written);

  /// ## errno (getter)
  Object? get errno => getAttribute("errno");

  /// ## errno (setter)
  set errno(Object? errno) => setAttribute("errno", errno);

  /// ## filename (getter)
  Object? get filename => getAttribute("filename");

  /// ## filename (setter)
  set filename(Object? filename) => setAttribute("filename", filename);

  /// ## filename2 (getter)
  Object? get filename2 => getAttribute("filename2");

  /// ## filename2 (setter)
  set filename2(Object? filename2) => setAttribute("filename2", filename2);

  /// ## strerror (getter)
  Object? get strerror => getAttribute("strerror");

  /// ## strerror (setter)
  set strerror(Object? strerror) => setAttribute("strerror", strerror);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## BufferError
final class BufferError extends PythonClass {
  factory BufferError() => PythonFfiDart.instance.importClass(
        "builtins",
        "BufferError",
        BufferError.from,
        <Object?>[],
      );

  BufferError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## BytesWarning
final class BytesWarning extends PythonClass {
  factory BytesWarning() => PythonFfiDart.instance.importClass(
        "builtins",
        "BytesWarning",
        BytesWarning.from,
        <Object?>[],
      );

  BytesWarning.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## ChildProcessError
final class ChildProcessError extends PythonClass {
  factory ChildProcessError() => PythonFfiDart.instance.importClass(
        "builtins",
        "ChildProcessError",
        ChildProcessError.from,
        <Object?>[],
      );

  ChildProcessError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## characters_written (getter)
  Object? get characters_written => getAttribute("characters_written");

  /// ## characters_written (setter)
  set characters_written(Object? characters_written) =>
      setAttribute("characters_written", characters_written);

  /// ## errno (getter)
  Object? get errno => getAttribute("errno");

  /// ## errno (setter)
  set errno(Object? errno) => setAttribute("errno", errno);

  /// ## filename (getter)
  Object? get filename => getAttribute("filename");

  /// ## filename (setter)
  set filename(Object? filename) => setAttribute("filename", filename);

  /// ## filename2 (getter)
  Object? get filename2 => getAttribute("filename2");

  /// ## filename2 (setter)
  set filename2(Object? filename2) => setAttribute("filename2", filename2);

  /// ## strerror (getter)
  Object? get strerror => getAttribute("strerror");

  /// ## strerror (setter)
  set strerror(Object? strerror) => setAttribute("strerror", strerror);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## ConnectionAbortedError
final class ConnectionAbortedError extends PythonClass {
  factory ConnectionAbortedError() => PythonFfiDart.instance.importClass(
        "builtins",
        "ConnectionAbortedError",
        ConnectionAbortedError.from,
        <Object?>[],
      );

  ConnectionAbortedError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## characters_written (getter)
  Object? get characters_written => getAttribute("characters_written");

  /// ## characters_written (setter)
  set characters_written(Object? characters_written) =>
      setAttribute("characters_written", characters_written);

  /// ## errno (getter)
  Object? get errno => getAttribute("errno");

  /// ## errno (setter)
  set errno(Object? errno) => setAttribute("errno", errno);

  /// ## filename (getter)
  Object? get filename => getAttribute("filename");

  /// ## filename (setter)
  set filename(Object? filename) => setAttribute("filename", filename);

  /// ## filename2 (getter)
  Object? get filename2 => getAttribute("filename2");

  /// ## filename2 (setter)
  set filename2(Object? filename2) => setAttribute("filename2", filename2);

  /// ## strerror (getter)
  Object? get strerror => getAttribute("strerror");

  /// ## strerror (setter)
  set strerror(Object? strerror) => setAttribute("strerror", strerror);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## ConnectionError
final class ConnectionError extends PythonClass {
  factory ConnectionError() => PythonFfiDart.instance.importClass(
        "builtins",
        "ConnectionError",
        ConnectionError.from,
        <Object?>[],
      );

  ConnectionError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## characters_written (getter)
  Object? get characters_written => getAttribute("characters_written");

  /// ## characters_written (setter)
  set characters_written(Object? characters_written) =>
      setAttribute("characters_written", characters_written);

  /// ## errno (getter)
  Object? get errno => getAttribute("errno");

  /// ## errno (setter)
  set errno(Object? errno) => setAttribute("errno", errno);

  /// ## filename (getter)
  Object? get filename => getAttribute("filename");

  /// ## filename (setter)
  set filename(Object? filename) => setAttribute("filename", filename);

  /// ## filename2 (getter)
  Object? get filename2 => getAttribute("filename2");

  /// ## filename2 (setter)
  set filename2(Object? filename2) => setAttribute("filename2", filename2);

  /// ## strerror (getter)
  Object? get strerror => getAttribute("strerror");

  /// ## strerror (setter)
  set strerror(Object? strerror) => setAttribute("strerror", strerror);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## ConnectionRefusedError
final class ConnectionRefusedError extends PythonClass {
  factory ConnectionRefusedError() => PythonFfiDart.instance.importClass(
        "builtins",
        "ConnectionRefusedError",
        ConnectionRefusedError.from,
        <Object?>[],
      );

  ConnectionRefusedError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## characters_written (getter)
  Object? get characters_written => getAttribute("characters_written");

  /// ## characters_written (setter)
  set characters_written(Object? characters_written) =>
      setAttribute("characters_written", characters_written);

  /// ## errno (getter)
  Object? get errno => getAttribute("errno");

  /// ## errno (setter)
  set errno(Object? errno) => setAttribute("errno", errno);

  /// ## filename (getter)
  Object? get filename => getAttribute("filename");

  /// ## filename (setter)
  set filename(Object? filename) => setAttribute("filename", filename);

  /// ## filename2 (getter)
  Object? get filename2 => getAttribute("filename2");

  /// ## filename2 (setter)
  set filename2(Object? filename2) => setAttribute("filename2", filename2);

  /// ## strerror (getter)
  Object? get strerror => getAttribute("strerror");

  /// ## strerror (setter)
  set strerror(Object? strerror) => setAttribute("strerror", strerror);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## ConnectionResetError
final class ConnectionResetError extends PythonClass {
  factory ConnectionResetError() => PythonFfiDart.instance.importClass(
        "builtins",
        "ConnectionResetError",
        ConnectionResetError.from,
        <Object?>[],
      );

  ConnectionResetError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## characters_written (getter)
  Object? get characters_written => getAttribute("characters_written");

  /// ## characters_written (setter)
  set characters_written(Object? characters_written) =>
      setAttribute("characters_written", characters_written);

  /// ## errno (getter)
  Object? get errno => getAttribute("errno");

  /// ## errno (setter)
  set errno(Object? errno) => setAttribute("errno", errno);

  /// ## filename (getter)
  Object? get filename => getAttribute("filename");

  /// ## filename (setter)
  set filename(Object? filename) => setAttribute("filename", filename);

  /// ## filename2 (getter)
  Object? get filename2 => getAttribute("filename2");

  /// ## filename2 (setter)
  set filename2(Object? filename2) => setAttribute("filename2", filename2);

  /// ## strerror (getter)
  Object? get strerror => getAttribute("strerror");

  /// ## strerror (setter)
  set strerror(Object? strerror) => setAttribute("strerror", strerror);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## DeprecationWarning
final class DeprecationWarning extends PythonClass {
  factory DeprecationWarning() => PythonFfiDart.instance.importClass(
        "builtins",
        "DeprecationWarning",
        DeprecationWarning.from,
        <Object?>[],
      );

  DeprecationWarning.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## EOFError
final class EOFError extends PythonClass {
  factory EOFError() => PythonFfiDart.instance.importClass(
        "builtins",
        "EOFError",
        EOFError.from,
        <Object?>[],
      );

  EOFError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## EncodingWarning
final class EncodingWarning extends PythonClass {
  factory EncodingWarning() => PythonFfiDart.instance.importClass(
        "builtins",
        "EncodingWarning",
        EncodingWarning.from,
        <Object?>[],
      );

  EncodingWarning.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## Exception
final class Exception extends PythonClass {
  factory Exception() => PythonFfiDart.instance.importClass(
        "builtins",
        "Exception",
        Exception.from,
        <Object?>[],
      );

  Exception.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## ExceptionGroup
final class ExceptionGroup extends PythonClass {
  factory ExceptionGroup() => PythonFfiDart.instance.importClass(
        "builtins",
        "ExceptionGroup",
        ExceptionGroup.from,
        <Object?>[],
      );

  ExceptionGroup.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## exceptions (getter)
  Object? get exceptions => getAttribute("exceptions");

  /// ## exceptions (setter)
  set exceptions(Object? exceptions) => setAttribute("exceptions", exceptions);

  /// ## message (getter)
  Object? get message => getAttribute("message");

  /// ## message (setter)
  set message(Object? message) => setAttribute("message", message);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## derive (getter)
  Object? get derive => getAttribute("derive");

  /// ## derive (setter)
  set derive(Object? derive) => setAttribute("derive", derive);

  /// ## split (getter)
  Object? get split => getAttribute("split");

  /// ## split (setter)
  set split(Object? split) => setAttribute("split", split);

  /// ## subgroup (getter)
  Object? get subgroup => getAttribute("subgroup");

  /// ## subgroup (setter)
  set subgroup(Object? subgroup) => setAttribute("subgroup", subgroup);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## FileExistsError
final class FileExistsError extends PythonClass {
  factory FileExistsError() => PythonFfiDart.instance.importClass(
        "builtins",
        "FileExistsError",
        FileExistsError.from,
        <Object?>[],
      );

  FileExistsError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## characters_written (getter)
  Object? get characters_written => getAttribute("characters_written");

  /// ## characters_written (setter)
  set characters_written(Object? characters_written) =>
      setAttribute("characters_written", characters_written);

  /// ## errno (getter)
  Object? get errno => getAttribute("errno");

  /// ## errno (setter)
  set errno(Object? errno) => setAttribute("errno", errno);

  /// ## filename (getter)
  Object? get filename => getAttribute("filename");

  /// ## filename (setter)
  set filename(Object? filename) => setAttribute("filename", filename);

  /// ## filename2 (getter)
  Object? get filename2 => getAttribute("filename2");

  /// ## filename2 (setter)
  set filename2(Object? filename2) => setAttribute("filename2", filename2);

  /// ## strerror (getter)
  Object? get strerror => getAttribute("strerror");

  /// ## strerror (setter)
  set strerror(Object? strerror) => setAttribute("strerror", strerror);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## FileNotFoundError
final class FileNotFoundError extends PythonClass {
  factory FileNotFoundError() => PythonFfiDart.instance.importClass(
        "builtins",
        "FileNotFoundError",
        FileNotFoundError.from,
        <Object?>[],
      );

  FileNotFoundError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## characters_written (getter)
  Object? get characters_written => getAttribute("characters_written");

  /// ## characters_written (setter)
  set characters_written(Object? characters_written) =>
      setAttribute("characters_written", characters_written);

  /// ## errno (getter)
  Object? get errno => getAttribute("errno");

  /// ## errno (setter)
  set errno(Object? errno) => setAttribute("errno", errno);

  /// ## filename (getter)
  Object? get filename => getAttribute("filename");

  /// ## filename (setter)
  set filename(Object? filename) => setAttribute("filename", filename);

  /// ## filename2 (getter)
  Object? get filename2 => getAttribute("filename2");

  /// ## filename2 (setter)
  set filename2(Object? filename2) => setAttribute("filename2", filename2);

  /// ## strerror (getter)
  Object? get strerror => getAttribute("strerror");

  /// ## strerror (setter)
  set strerror(Object? strerror) => setAttribute("strerror", strerror);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## FloatingPointError
final class FloatingPointError extends PythonClass {
  factory FloatingPointError() => PythonFfiDart.instance.importClass(
        "builtins",
        "FloatingPointError",
        FloatingPointError.from,
        <Object?>[],
      );

  FloatingPointError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## FutureWarning
final class FutureWarning extends PythonClass {
  factory FutureWarning() => PythonFfiDart.instance.importClass(
        "builtins",
        "FutureWarning",
        FutureWarning.from,
        <Object?>[],
      );

  FutureWarning.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## GeneratorExit
final class GeneratorExit extends PythonClass {
  factory GeneratorExit() => PythonFfiDart.instance.importClass(
        "builtins",
        "GeneratorExit",
        GeneratorExit.from,
        <Object?>[],
      );

  GeneratorExit.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## ImportError
final class ImportError extends PythonClass {
  factory ImportError() => PythonFfiDart.instance.importClass(
        "builtins",
        "ImportError",
        ImportError.from,
        <Object?>[],
      );

  ImportError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## msg (getter)
  Object? get msg => getAttribute("msg");

  /// ## msg (setter)
  set msg(Object? msg) => setAttribute("msg", msg);

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);

  /// ## path (getter)
  Object? get path => getAttribute("path");

  /// ## path (setter)
  set path(Object? path) => setAttribute("path", path);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## ImportWarning
final class ImportWarning extends PythonClass {
  factory ImportWarning() => PythonFfiDart.instance.importClass(
        "builtins",
        "ImportWarning",
        ImportWarning.from,
        <Object?>[],
      );

  ImportWarning.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## IndentationError
final class IndentationError extends PythonClass {
  factory IndentationError() => PythonFfiDart.instance.importClass(
        "builtins",
        "IndentationError",
        IndentationError.from,
        <Object?>[],
      );

  IndentationError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## end_lineno (getter)
  Object? get end_lineno => getAttribute("end_lineno");

  /// ## end_lineno (setter)
  set end_lineno(Object? end_lineno) => setAttribute("end_lineno", end_lineno);

  /// ## end_offset (getter)
  Object? get end_offset => getAttribute("end_offset");

  /// ## end_offset (setter)
  set end_offset(Object? end_offset) => setAttribute("end_offset", end_offset);

  /// ## filename (getter)
  Object? get filename => getAttribute("filename");

  /// ## filename (setter)
  set filename(Object? filename) => setAttribute("filename", filename);

  /// ## lineno (getter)
  Object? get lineno => getAttribute("lineno");

  /// ## lineno (setter)
  set lineno(Object? lineno) => setAttribute("lineno", lineno);

  /// ## msg (getter)
  Object? get msg => getAttribute("msg");

  /// ## msg (setter)
  set msg(Object? msg) => setAttribute("msg", msg);

  /// ## offset (getter)
  Object? get offset => getAttribute("offset");

  /// ## offset (setter)
  set offset(Object? offset) => setAttribute("offset", offset);

  /// ## print_file_and_line (getter)
  Object? get print_file_and_line => getAttribute("print_file_and_line");

  /// ## print_file_and_line (setter)
  set print_file_and_line(Object? print_file_and_line) =>
      setAttribute("print_file_and_line", print_file_and_line);

  /// ## text (getter)
  Object? get text => getAttribute("text");

  /// ## text (setter)
  set text(Object? text) => setAttribute("text", text);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## IndexError
final class IndexError extends PythonClass {
  factory IndexError() => PythonFfiDart.instance.importClass(
        "builtins",
        "IndexError",
        IndexError.from,
        <Object?>[],
      );

  IndexError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## InterruptedError
final class InterruptedError extends PythonClass {
  factory InterruptedError() => PythonFfiDart.instance.importClass(
        "builtins",
        "InterruptedError",
        InterruptedError.from,
        <Object?>[],
      );

  InterruptedError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## characters_written (getter)
  Object? get characters_written => getAttribute("characters_written");

  /// ## characters_written (setter)
  set characters_written(Object? characters_written) =>
      setAttribute("characters_written", characters_written);

  /// ## errno (getter)
  Object? get errno => getAttribute("errno");

  /// ## errno (setter)
  set errno(Object? errno) => setAttribute("errno", errno);

  /// ## filename (getter)
  Object? get filename => getAttribute("filename");

  /// ## filename (setter)
  set filename(Object? filename) => setAttribute("filename", filename);

  /// ## filename2 (getter)
  Object? get filename2 => getAttribute("filename2");

  /// ## filename2 (setter)
  set filename2(Object? filename2) => setAttribute("filename2", filename2);

  /// ## strerror (getter)
  Object? get strerror => getAttribute("strerror");

  /// ## strerror (setter)
  set strerror(Object? strerror) => setAttribute("strerror", strerror);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## IsADirectoryError
final class IsADirectoryError extends PythonClass {
  factory IsADirectoryError() => PythonFfiDart.instance.importClass(
        "builtins",
        "IsADirectoryError",
        IsADirectoryError.from,
        <Object?>[],
      );

  IsADirectoryError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## characters_written (getter)
  Object? get characters_written => getAttribute("characters_written");

  /// ## characters_written (setter)
  set characters_written(Object? characters_written) =>
      setAttribute("characters_written", characters_written);

  /// ## errno (getter)
  Object? get errno => getAttribute("errno");

  /// ## errno (setter)
  set errno(Object? errno) => setAttribute("errno", errno);

  /// ## filename (getter)
  Object? get filename => getAttribute("filename");

  /// ## filename (setter)
  set filename(Object? filename) => setAttribute("filename", filename);

  /// ## filename2 (getter)
  Object? get filename2 => getAttribute("filename2");

  /// ## filename2 (setter)
  set filename2(Object? filename2) => setAttribute("filename2", filename2);

  /// ## strerror (getter)
  Object? get strerror => getAttribute("strerror");

  /// ## strerror (setter)
  set strerror(Object? strerror) => setAttribute("strerror", strerror);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## KeyError
final class KeyError extends PythonClass {
  factory KeyError() => PythonFfiDart.instance.importClass(
        "builtins",
        "KeyError",
        KeyError.from,
        <Object?>[],
      );

  KeyError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## KeyboardInterrupt
final class KeyboardInterrupt extends PythonClass {
  factory KeyboardInterrupt() => PythonFfiDart.instance.importClass(
        "builtins",
        "KeyboardInterrupt",
        KeyboardInterrupt.from,
        <Object?>[],
      );

  KeyboardInterrupt.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## LookupError
final class LookupError extends PythonClass {
  factory LookupError() => PythonFfiDart.instance.importClass(
        "builtins",
        "LookupError",
        LookupError.from,
        <Object?>[],
      );

  LookupError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## MemoryError
final class MemoryError extends PythonClass {
  factory MemoryError() => PythonFfiDart.instance.importClass(
        "builtins",
        "MemoryError",
        MemoryError.from,
        <Object?>[],
      );

  MemoryError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## ModuleNotFoundError
final class ModuleNotFoundError extends PythonClass {
  factory ModuleNotFoundError() => PythonFfiDart.instance.importClass(
        "builtins",
        "ModuleNotFoundError",
        ModuleNotFoundError.from,
        <Object?>[],
      );

  ModuleNotFoundError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## msg (getter)
  Object? get msg => getAttribute("msg");

  /// ## msg (setter)
  set msg(Object? msg) => setAttribute("msg", msg);

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);

  /// ## path (getter)
  Object? get path => getAttribute("path");

  /// ## path (setter)
  set path(Object? path) => setAttribute("path", path);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## NameError
final class NameError extends PythonClass {
  factory NameError() => PythonFfiDart.instance.importClass(
        "builtins",
        "NameError",
        NameError.from,
        <Object?>[],
      );

  NameError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## NotADirectoryError
final class NotADirectoryError extends PythonClass {
  factory NotADirectoryError() => PythonFfiDart.instance.importClass(
        "builtins",
        "NotADirectoryError",
        NotADirectoryError.from,
        <Object?>[],
      );

  NotADirectoryError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## characters_written (getter)
  Object? get characters_written => getAttribute("characters_written");

  /// ## characters_written (setter)
  set characters_written(Object? characters_written) =>
      setAttribute("characters_written", characters_written);

  /// ## errno (getter)
  Object? get errno => getAttribute("errno");

  /// ## errno (setter)
  set errno(Object? errno) => setAttribute("errno", errno);

  /// ## filename (getter)
  Object? get filename => getAttribute("filename");

  /// ## filename (setter)
  set filename(Object? filename) => setAttribute("filename", filename);

  /// ## filename2 (getter)
  Object? get filename2 => getAttribute("filename2");

  /// ## filename2 (setter)
  set filename2(Object? filename2) => setAttribute("filename2", filename2);

  /// ## strerror (getter)
  Object? get strerror => getAttribute("strerror");

  /// ## strerror (setter)
  set strerror(Object? strerror) => setAttribute("strerror", strerror);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## NotImplementedError
final class NotImplementedError extends PythonClass {
  factory NotImplementedError() => PythonFfiDart.instance.importClass(
        "builtins",
        "NotImplementedError",
        NotImplementedError.from,
        <Object?>[],
      );

  NotImplementedError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## OverflowError
final class OverflowError extends PythonClass {
  factory OverflowError() => PythonFfiDart.instance.importClass(
        "builtins",
        "OverflowError",
        OverflowError.from,
        <Object?>[],
      );

  OverflowError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## PendingDeprecationWarning
final class PendingDeprecationWarning extends PythonClass {
  factory PendingDeprecationWarning() => PythonFfiDart.instance.importClass(
        "builtins",
        "PendingDeprecationWarning",
        PendingDeprecationWarning.from,
        <Object?>[],
      );

  PendingDeprecationWarning.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## PermissionError
final class PermissionError extends PythonClass {
  factory PermissionError() => PythonFfiDart.instance.importClass(
        "builtins",
        "PermissionError",
        PermissionError.from,
        <Object?>[],
      );

  PermissionError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## characters_written (getter)
  Object? get characters_written => getAttribute("characters_written");

  /// ## characters_written (setter)
  set characters_written(Object? characters_written) =>
      setAttribute("characters_written", characters_written);

  /// ## errno (getter)
  Object? get errno => getAttribute("errno");

  /// ## errno (setter)
  set errno(Object? errno) => setAttribute("errno", errno);

  /// ## filename (getter)
  Object? get filename => getAttribute("filename");

  /// ## filename (setter)
  set filename(Object? filename) => setAttribute("filename", filename);

  /// ## filename2 (getter)
  Object? get filename2 => getAttribute("filename2");

  /// ## filename2 (setter)
  set filename2(Object? filename2) => setAttribute("filename2", filename2);

  /// ## strerror (getter)
  Object? get strerror => getAttribute("strerror");

  /// ## strerror (setter)
  set strerror(Object? strerror) => setAttribute("strerror", strerror);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## ProcessLookupError
final class ProcessLookupError extends PythonClass {
  factory ProcessLookupError() => PythonFfiDart.instance.importClass(
        "builtins",
        "ProcessLookupError",
        ProcessLookupError.from,
        <Object?>[],
      );

  ProcessLookupError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## characters_written (getter)
  Object? get characters_written => getAttribute("characters_written");

  /// ## characters_written (setter)
  set characters_written(Object? characters_written) =>
      setAttribute("characters_written", characters_written);

  /// ## errno (getter)
  Object? get errno => getAttribute("errno");

  /// ## errno (setter)
  set errno(Object? errno) => setAttribute("errno", errno);

  /// ## filename (getter)
  Object? get filename => getAttribute("filename");

  /// ## filename (setter)
  set filename(Object? filename) => setAttribute("filename", filename);

  /// ## filename2 (getter)
  Object? get filename2 => getAttribute("filename2");

  /// ## filename2 (setter)
  set filename2(Object? filename2) => setAttribute("filename2", filename2);

  /// ## strerror (getter)
  Object? get strerror => getAttribute("strerror");

  /// ## strerror (setter)
  set strerror(Object? strerror) => setAttribute("strerror", strerror);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## RecursionError
final class RecursionError extends PythonClass {
  factory RecursionError() => PythonFfiDart.instance.importClass(
        "builtins",
        "RecursionError",
        RecursionError.from,
        <Object?>[],
      );

  RecursionError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## ReferenceError
final class ReferenceError extends PythonClass {
  factory ReferenceError() => PythonFfiDart.instance.importClass(
        "builtins",
        "ReferenceError",
        ReferenceError.from,
        <Object?>[],
      );

  ReferenceError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## ResourceWarning
final class ResourceWarning extends PythonClass {
  factory ResourceWarning() => PythonFfiDart.instance.importClass(
        "builtins",
        "ResourceWarning",
        ResourceWarning.from,
        <Object?>[],
      );

  ResourceWarning.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## RuntimeError
final class RuntimeError extends PythonClass {
  factory RuntimeError() => PythonFfiDart.instance.importClass(
        "builtins",
        "RuntimeError",
        RuntimeError.from,
        <Object?>[],
      );

  RuntimeError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## RuntimeWarning
final class RuntimeWarning extends PythonClass {
  factory RuntimeWarning() => PythonFfiDart.instance.importClass(
        "builtins",
        "RuntimeWarning",
        RuntimeWarning.from,
        <Object?>[],
      );

  RuntimeWarning.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## StopAsyncIteration
final class StopAsyncIteration extends PythonClass {
  factory StopAsyncIteration() => PythonFfiDart.instance.importClass(
        "builtins",
        "StopAsyncIteration",
        StopAsyncIteration.from,
        <Object?>[],
      );

  StopAsyncIteration.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## StopIteration
final class StopIteration extends PythonClass {
  factory StopIteration() => PythonFfiDart.instance.importClass(
        "builtins",
        "StopIteration",
        StopIteration.from,
        <Object?>[],
      );

  StopIteration.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## value (getter)
  Object? get value => getAttribute("value");

  /// ## value (setter)
  set value(Object? value) => setAttribute("value", value);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## SyntaxError
final class SyntaxError extends PythonClass {
  factory SyntaxError() => PythonFfiDart.instance.importClass(
        "builtins",
        "SyntaxError",
        SyntaxError.from,
        <Object?>[],
      );

  SyntaxError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## end_lineno (getter)
  Object? get end_lineno => getAttribute("end_lineno");

  /// ## end_lineno (setter)
  set end_lineno(Object? end_lineno) => setAttribute("end_lineno", end_lineno);

  /// ## end_offset (getter)
  Object? get end_offset => getAttribute("end_offset");

  /// ## end_offset (setter)
  set end_offset(Object? end_offset) => setAttribute("end_offset", end_offset);

  /// ## filename (getter)
  Object? get filename => getAttribute("filename");

  /// ## filename (setter)
  set filename(Object? filename) => setAttribute("filename", filename);

  /// ## lineno (getter)
  Object? get lineno => getAttribute("lineno");

  /// ## lineno (setter)
  set lineno(Object? lineno) => setAttribute("lineno", lineno);

  /// ## msg (getter)
  Object? get msg => getAttribute("msg");

  /// ## msg (setter)
  set msg(Object? msg) => setAttribute("msg", msg);

  /// ## offset (getter)
  Object? get offset => getAttribute("offset");

  /// ## offset (setter)
  set offset(Object? offset) => setAttribute("offset", offset);

  /// ## print_file_and_line (getter)
  Object? get print_file_and_line => getAttribute("print_file_and_line");

  /// ## print_file_and_line (setter)
  set print_file_and_line(Object? print_file_and_line) =>
      setAttribute("print_file_and_line", print_file_and_line);

  /// ## text (getter)
  Object? get text => getAttribute("text");

  /// ## text (setter)
  set text(Object? text) => setAttribute("text", text);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## SyntaxWarning
final class SyntaxWarning extends PythonClass {
  factory SyntaxWarning() => PythonFfiDart.instance.importClass(
        "builtins",
        "SyntaxWarning",
        SyntaxWarning.from,
        <Object?>[],
      );

  SyntaxWarning.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## SystemError
final class SystemError extends PythonClass {
  factory SystemError() => PythonFfiDart.instance.importClass(
        "builtins",
        "SystemError",
        SystemError.from,
        <Object?>[],
      );

  SystemError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## SystemExit
final class SystemExit extends PythonClass {
  factory SystemExit() => PythonFfiDart.instance.importClass(
        "builtins",
        "SystemExit",
        SystemExit.from,
        <Object?>[],
      );

  SystemExit.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## code (getter)
  Object? get code => getAttribute("code");

  /// ## code (setter)
  set code(Object? code) => setAttribute("code", code);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## TabError
final class TabError extends PythonClass {
  factory TabError() => PythonFfiDart.instance.importClass(
        "builtins",
        "TabError",
        TabError.from,
        <Object?>[],
      );

  TabError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## end_lineno (getter)
  Object? get end_lineno => getAttribute("end_lineno");

  /// ## end_lineno (setter)
  set end_lineno(Object? end_lineno) => setAttribute("end_lineno", end_lineno);

  /// ## end_offset (getter)
  Object? get end_offset => getAttribute("end_offset");

  /// ## end_offset (setter)
  set end_offset(Object? end_offset) => setAttribute("end_offset", end_offset);

  /// ## filename (getter)
  Object? get filename => getAttribute("filename");

  /// ## filename (setter)
  set filename(Object? filename) => setAttribute("filename", filename);

  /// ## lineno (getter)
  Object? get lineno => getAttribute("lineno");

  /// ## lineno (setter)
  set lineno(Object? lineno) => setAttribute("lineno", lineno);

  /// ## msg (getter)
  Object? get msg => getAttribute("msg");

  /// ## msg (setter)
  set msg(Object? msg) => setAttribute("msg", msg);

  /// ## offset (getter)
  Object? get offset => getAttribute("offset");

  /// ## offset (setter)
  set offset(Object? offset) => setAttribute("offset", offset);

  /// ## print_file_and_line (getter)
  Object? get print_file_and_line => getAttribute("print_file_and_line");

  /// ## print_file_and_line (setter)
  set print_file_and_line(Object? print_file_and_line) =>
      setAttribute("print_file_and_line", print_file_and_line);

  /// ## text (getter)
  Object? get text => getAttribute("text");

  /// ## text (setter)
  set text(Object? text) => setAttribute("text", text);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## TimeoutError
final class TimeoutError extends PythonClass {
  factory TimeoutError() => PythonFfiDart.instance.importClass(
        "builtins",
        "TimeoutError",
        TimeoutError.from,
        <Object?>[],
      );

  TimeoutError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## characters_written (getter)
  Object? get characters_written => getAttribute("characters_written");

  /// ## characters_written (setter)
  set characters_written(Object? characters_written) =>
      setAttribute("characters_written", characters_written);

  /// ## errno (getter)
  Object? get errno => getAttribute("errno");

  /// ## errno (setter)
  set errno(Object? errno) => setAttribute("errno", errno);

  /// ## filename (getter)
  Object? get filename => getAttribute("filename");

  /// ## filename (setter)
  set filename(Object? filename) => setAttribute("filename", filename);

  /// ## filename2 (getter)
  Object? get filename2 => getAttribute("filename2");

  /// ## filename2 (setter)
  set filename2(Object? filename2) => setAttribute("filename2", filename2);

  /// ## strerror (getter)
  Object? get strerror => getAttribute("strerror");

  /// ## strerror (setter)
  set strerror(Object? strerror) => setAttribute("strerror", strerror);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## TypeError
final class TypeError extends PythonClass {
  factory TypeError() => PythonFfiDart.instance.importClass(
        "builtins",
        "TypeError",
        TypeError.from,
        <Object?>[],
      );

  TypeError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## UnboundLocalError
final class UnboundLocalError extends PythonClass {
  factory UnboundLocalError() => PythonFfiDart.instance.importClass(
        "builtins",
        "UnboundLocalError",
        UnboundLocalError.from,
        <Object?>[],
      );

  UnboundLocalError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## UnicodeDecodeError
final class UnicodeDecodeError extends PythonClass {
  factory UnicodeDecodeError() => PythonFfiDart.instance.importClass(
        "builtins",
        "UnicodeDecodeError",
        UnicodeDecodeError.from,
        <Object?>[],
      );

  UnicodeDecodeError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## encoding (getter)
  Object? get encoding => getAttribute("encoding");

  /// ## encoding (setter)
  set encoding(Object? encoding) => setAttribute("encoding", encoding);

  /// ## end (getter)
  Object? get end => getAttribute("end");

  /// ## end (setter)
  set end(Object? end) => setAttribute("end", end);

  /// ## object (getter)
  Object? get object => getAttribute("object");

  /// ## object (setter)
  set object(Object? object) => setAttribute("object", object);

  /// ## reason (getter)
  Object? get reason => getAttribute("reason");

  /// ## reason (setter)
  set reason(Object? reason) => setAttribute("reason", reason);

  /// ## start (getter)
  Object? get start => getAttribute("start");

  /// ## start (setter)
  set start(Object? start) => setAttribute("start", start);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## UnicodeEncodeError
final class UnicodeEncodeError extends PythonClass {
  factory UnicodeEncodeError() => PythonFfiDart.instance.importClass(
        "builtins",
        "UnicodeEncodeError",
        UnicodeEncodeError.from,
        <Object?>[],
      );

  UnicodeEncodeError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## encoding (getter)
  Object? get encoding => getAttribute("encoding");

  /// ## encoding (setter)
  set encoding(Object? encoding) => setAttribute("encoding", encoding);

  /// ## end (getter)
  Object? get end => getAttribute("end");

  /// ## end (setter)
  set end(Object? end) => setAttribute("end", end);

  /// ## object (getter)
  Object? get object => getAttribute("object");

  /// ## object (setter)
  set object(Object? object) => setAttribute("object", object);

  /// ## reason (getter)
  Object? get reason => getAttribute("reason");

  /// ## reason (setter)
  set reason(Object? reason) => setAttribute("reason", reason);

  /// ## start (getter)
  Object? get start => getAttribute("start");

  /// ## start (setter)
  set start(Object? start) => setAttribute("start", start);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## UnicodeError
final class UnicodeError extends PythonClass {
  factory UnicodeError() => PythonFfiDart.instance.importClass(
        "builtins",
        "UnicodeError",
        UnicodeError.from,
        <Object?>[],
      );

  UnicodeError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## UnicodeTranslateError
final class UnicodeTranslateError extends PythonClass {
  factory UnicodeTranslateError() => PythonFfiDart.instance.importClass(
        "builtins",
        "UnicodeTranslateError",
        UnicodeTranslateError.from,
        <Object?>[],
      );

  UnicodeTranslateError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## encoding (getter)
  Object? get encoding => getAttribute("encoding");

  /// ## encoding (setter)
  set encoding(Object? encoding) => setAttribute("encoding", encoding);

  /// ## end (getter)
  Object? get end => getAttribute("end");

  /// ## end (setter)
  set end(Object? end) => setAttribute("end", end);

  /// ## object (getter)
  Object? get object => getAttribute("object");

  /// ## object (setter)
  set object(Object? object) => setAttribute("object", object);

  /// ## reason (getter)
  Object? get reason => getAttribute("reason");

  /// ## reason (setter)
  set reason(Object? reason) => setAttribute("reason", reason);

  /// ## start (getter)
  Object? get start => getAttribute("start");

  /// ## start (setter)
  set start(Object? start) => setAttribute("start", start);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## UnicodeWarning
final class UnicodeWarning extends PythonClass {
  factory UnicodeWarning() => PythonFfiDart.instance.importClass(
        "builtins",
        "UnicodeWarning",
        UnicodeWarning.from,
        <Object?>[],
      );

  UnicodeWarning.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## UserWarning
final class UserWarning extends PythonClass {
  factory UserWarning() => PythonFfiDart.instance.importClass(
        "builtins",
        "UserWarning",
        UserWarning.from,
        <Object?>[],
      );

  UserWarning.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## ValueError
final class ValueError extends PythonClass {
  factory ValueError() => PythonFfiDart.instance.importClass(
        "builtins",
        "ValueError",
        ValueError.from,
        <Object?>[],
      );

  ValueError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## Warning
final class Warning extends PythonClass {
  factory Warning() => PythonFfiDart.instance.importClass(
        "builtins",
        "Warning",
        Warning.from,
        <Object?>[],
      );

  Warning.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## ZeroDivisionError
final class ZeroDivisionError extends PythonClass {
  factory ZeroDivisionError() => PythonFfiDart.instance.importClass(
        "builtins",
        "ZeroDivisionError",
        ZeroDivisionError.from,
        <Object?>[],
      );

  ZeroDivisionError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## bool
final class bool extends PythonClass {
  factory bool() => PythonFfiDart.instance.importClass(
        "builtins",
        "bool",
        bool.from,
        <Object?>[],
      );

  bool.from(super.pythonClass) : super.from();

  /// ## denominator (getter)
  ///
  /// ### python docstring
  ///
  /// the denominator of a rational number in lowest terms
  Object? get denominator => getAttribute("denominator");

  /// ## denominator (setter)
  ///
  /// ### python docstring
  ///
  /// the denominator of a rational number in lowest terms
  set denominator(Object? denominator) =>
      setAttribute("denominator", denominator);

  /// ## imag (getter)
  ///
  /// ### python docstring
  ///
  /// the imaginary part of a complex number
  Object? get imag => getAttribute("imag");

  /// ## imag (setter)
  ///
  /// ### python docstring
  ///
  /// the imaginary part of a complex number
  set imag(Object? imag) => setAttribute("imag", imag);

  /// ## numerator (getter)
  ///
  /// ### python docstring
  ///
  /// the numerator of a rational number in lowest terms
  Object? get numerator => getAttribute("numerator");

  /// ## numerator (setter)
  ///
  /// ### python docstring
  ///
  /// the numerator of a rational number in lowest terms
  set numerator(Object? numerator) => setAttribute("numerator", numerator);

  /// ## real (getter)
  ///
  /// ### python docstring
  ///
  /// the real part of a complex number
  Object? get real => getAttribute("real");

  /// ## real (setter)
  ///
  /// ### python docstring
  ///
  /// the real part of a complex number
  set real(Object? real) => setAttribute("real", real);

  /// ## as_integer_ratio (getter)
  Object? get as_integer_ratio => getAttribute("as_integer_ratio");

  /// ## as_integer_ratio (setter)
  set as_integer_ratio(Object? as_integer_ratio) =>
      setAttribute("as_integer_ratio", as_integer_ratio);

  /// ## bit_count (getter)
  Object? get bit_count => getAttribute("bit_count");

  /// ## bit_count (setter)
  set bit_count(Object? bit_count) => setAttribute("bit_count", bit_count);

  /// ## bit_length (getter)
  Object? get bit_length => getAttribute("bit_length");

  /// ## bit_length (setter)
  set bit_length(Object? bit_length) => setAttribute("bit_length", bit_length);

  /// ## conjugate (getter)
  ///
  /// ### python docstring
  ///
  /// Returns self, the complex conjugate of any int.
  Object? get conjugate => getAttribute("conjugate");

  /// ## conjugate (setter)
  ///
  /// ### python docstring
  ///
  /// Returns self, the complex conjugate of any int.
  set conjugate(Object? conjugate) => setAttribute("conjugate", conjugate);

  /// ## to_bytes (getter)
  Object? get to_bytes => getAttribute("to_bytes");

  /// ## to_bytes (setter)
  set to_bytes(Object? to_bytes) => setAttribute("to_bytes", to_bytes);
}

/// ## bytearray
final class bytearray extends PythonClass {
  factory bytearray() => PythonFfiDart.instance.importClass(
        "builtins",
        "bytearray",
        bytearray.from,
        <Object?>[],
      );

  bytearray.from(super.pythonClass) : super.from();

  /// ## append (getter)
  Object? get append => getAttribute("append");

  /// ## append (setter)
  set append(Object? append) => setAttribute("append", append);

  /// ## capitalize (getter)
  Object? get capitalize => getAttribute("capitalize");

  /// ## capitalize (setter)
  set capitalize(Object? capitalize) => setAttribute("capitalize", capitalize);

  /// ## center (getter)
  Object? get center => getAttribute("center");

  /// ## center (setter)
  set center(Object? center) => setAttribute("center", center);

  /// ## clear (getter)
  Object? get clear => getAttribute("clear");

  /// ## clear (setter)
  set clear(Object? clear) => setAttribute("clear", clear);

  /// ## copy (getter)
  Object? get copy => getAttribute("copy");

  /// ## copy (setter)
  set copy(Object? copy) => setAttribute("copy", copy);

  /// ## count (getter)
  Object? get count => getAttribute("count");

  /// ## count (setter)
  set count(Object? count) => setAttribute("count", count);

  /// ## decode (getter)
  Object? get decode => getAttribute("decode");

  /// ## decode (setter)
  set decode(Object? decode) => setAttribute("decode", decode);

  /// ## endswith (getter)
  Object? get endswith => getAttribute("endswith");

  /// ## endswith (setter)
  set endswith(Object? endswith) => setAttribute("endswith", endswith);

  /// ## expandtabs (getter)
  Object? get expandtabs => getAttribute("expandtabs");

  /// ## expandtabs (setter)
  set expandtabs(Object? expandtabs) => setAttribute("expandtabs", expandtabs);

  /// ## extend (getter)
  Object? get extend => getAttribute("extend");

  /// ## extend (setter)
  set extend(Object? extend) => setAttribute("extend", extend);

  /// ## find (getter)
  Object? get find => getAttribute("find");

  /// ## find (setter)
  set find(Object? find) => setAttribute("find", find);

  /// ## hex (getter)
  Object? get hex => getAttribute("hex");

  /// ## hex (setter)
  set hex(Object? hex) => setAttribute("hex", hex);

  /// ## index (getter)
  Object? get index => getAttribute("index");

  /// ## index (setter)
  set index(Object? index) => setAttribute("index", index);

  /// ## insert (getter)
  Object? get insert => getAttribute("insert");

  /// ## insert (setter)
  set insert(Object? insert) => setAttribute("insert", insert);

  /// ## isalnum (getter)
  Object? get isalnum => getAttribute("isalnum");

  /// ## isalnum (setter)
  set isalnum(Object? isalnum) => setAttribute("isalnum", isalnum);

  /// ## isalpha (getter)
  Object? get isalpha => getAttribute("isalpha");

  /// ## isalpha (setter)
  set isalpha(Object? isalpha) => setAttribute("isalpha", isalpha);

  /// ## isascii (getter)
  Object? get isascii => getAttribute("isascii");

  /// ## isascii (setter)
  set isascii(Object? isascii) => setAttribute("isascii", isascii);

  /// ## isdigit (getter)
  Object? get isdigit => getAttribute("isdigit");

  /// ## isdigit (setter)
  set isdigit(Object? isdigit) => setAttribute("isdigit", isdigit);

  /// ## islower (getter)
  Object? get islower => getAttribute("islower");

  /// ## islower (setter)
  set islower(Object? islower) => setAttribute("islower", islower);

  /// ## isspace (getter)
  Object? get isspace => getAttribute("isspace");

  /// ## isspace (setter)
  set isspace(Object? isspace) => setAttribute("isspace", isspace);

  /// ## istitle (getter)
  Object? get istitle => getAttribute("istitle");

  /// ## istitle (setter)
  set istitle(Object? istitle) => setAttribute("istitle", istitle);

  /// ## isupper (getter)
  Object? get isupper => getAttribute("isupper");

  /// ## isupper (setter)
  set isupper(Object? isupper) => setAttribute("isupper", isupper);

  /// ## join (getter)
  Object? get join => getAttribute("join");

  /// ## join (setter)
  set join(Object? join) => setAttribute("join", join);

  /// ## ljust (getter)
  Object? get ljust => getAttribute("ljust");

  /// ## ljust (setter)
  set ljust(Object? ljust) => setAttribute("ljust", ljust);

  /// ## lower (getter)
  Object? get lower => getAttribute("lower");

  /// ## lower (setter)
  set lower(Object? lower) => setAttribute("lower", lower);

  /// ## lstrip (getter)
  Object? get lstrip => getAttribute("lstrip");

  /// ## lstrip (setter)
  set lstrip(Object? lstrip) => setAttribute("lstrip", lstrip);

  /// ## partition (getter)
  Object? get partition => getAttribute("partition");

  /// ## partition (setter)
  set partition(Object? partition) => setAttribute("partition", partition);

  /// ## pop (getter)
  Object? get pop => getAttribute("pop");

  /// ## pop (setter)
  set pop(Object? pop) => setAttribute("pop", pop);

  /// ## remove (getter)
  Object? get remove => getAttribute("remove");

  /// ## remove (setter)
  set remove(Object? remove) => setAttribute("remove", remove);

  /// ## removeprefix (getter)
  Object? get removeprefix => getAttribute("removeprefix");

  /// ## removeprefix (setter)
  set removeprefix(Object? removeprefix) =>
      setAttribute("removeprefix", removeprefix);

  /// ## removesuffix (getter)
  Object? get removesuffix => getAttribute("removesuffix");

  /// ## removesuffix (setter)
  set removesuffix(Object? removesuffix) =>
      setAttribute("removesuffix", removesuffix);

  /// ## replace (getter)
  Object? get replace => getAttribute("replace");

  /// ## replace (setter)
  set replace(Object? replace) => setAttribute("replace", replace);

  /// ## reverse (getter)
  Object? get reverse => getAttribute("reverse");

  /// ## reverse (setter)
  set reverse(Object? reverse) => setAttribute("reverse", reverse);

  /// ## rfind (getter)
  Object? get rfind => getAttribute("rfind");

  /// ## rfind (setter)
  set rfind(Object? rfind) => setAttribute("rfind", rfind);

  /// ## rindex (getter)
  Object? get rindex => getAttribute("rindex");

  /// ## rindex (setter)
  set rindex(Object? rindex) => setAttribute("rindex", rindex);

  /// ## rjust (getter)
  Object? get rjust => getAttribute("rjust");

  /// ## rjust (setter)
  set rjust(Object? rjust) => setAttribute("rjust", rjust);

  /// ## rpartition (getter)
  Object? get rpartition => getAttribute("rpartition");

  /// ## rpartition (setter)
  set rpartition(Object? rpartition) => setAttribute("rpartition", rpartition);

  /// ## rsplit (getter)
  Object? get rsplit => getAttribute("rsplit");

  /// ## rsplit (setter)
  set rsplit(Object? rsplit) => setAttribute("rsplit", rsplit);

  /// ## rstrip (getter)
  Object? get rstrip => getAttribute("rstrip");

  /// ## rstrip (setter)
  set rstrip(Object? rstrip) => setAttribute("rstrip", rstrip);

  /// ## split (getter)
  Object? get split => getAttribute("split");

  /// ## split (setter)
  set split(Object? split) => setAttribute("split", split);

  /// ## splitlines (getter)
  Object? get splitlines => getAttribute("splitlines");

  /// ## splitlines (setter)
  set splitlines(Object? splitlines) => setAttribute("splitlines", splitlines);

  /// ## startswith (getter)
  Object? get startswith => getAttribute("startswith");

  /// ## startswith (setter)
  set startswith(Object? startswith) => setAttribute("startswith", startswith);

  /// ## strip (getter)
  Object? get strip => getAttribute("strip");

  /// ## strip (setter)
  set strip(Object? strip) => setAttribute("strip", strip);

  /// ## swapcase (getter)
  Object? get swapcase => getAttribute("swapcase");

  /// ## swapcase (setter)
  set swapcase(Object? swapcase) => setAttribute("swapcase", swapcase);

  /// ## title (getter)
  Object? get title => getAttribute("title");

  /// ## title (setter)
  set title(Object? title) => setAttribute("title", title);

  /// ## translate (getter)
  Object? get translate => getAttribute("translate");

  /// ## translate (setter)
  set translate(Object? translate) => setAttribute("translate", translate);

  /// ## upper (getter)
  Object? get upper => getAttribute("upper");

  /// ## upper (setter)
  set upper(Object? upper) => setAttribute("upper", upper);

  /// ## zfill (getter)
  Object? get zfill => getAttribute("zfill");

  /// ## zfill (setter)
  set zfill(Object? zfill) => setAttribute("zfill", zfill);
}

/// ## classmethod
final class classmethod extends PythonClass {
  factory classmethod() => PythonFfiDart.instance.importClass(
        "builtins",
        "classmethod",
        classmethod.from,
        <Object?>[],
      );

  classmethod.from(super.pythonClass) : super.from();
}

/// ## complex
final class complex extends PythonClass {
  factory complex() => PythonFfiDart.instance.importClass(
        "builtins",
        "complex",
        complex.from,
        <Object?>[],
      );

  complex.from(super.pythonClass) : super.from();

  /// ## imag (getter)
  ///
  /// ### python docstring
  ///
  /// the imaginary part of a complex number
  Object? get imag => getAttribute("imag");

  /// ## imag (setter)
  ///
  /// ### python docstring
  ///
  /// the imaginary part of a complex number
  set imag(Object? imag) => setAttribute("imag", imag);

  /// ## real (getter)
  ///
  /// ### python docstring
  ///
  /// the real part of a complex number
  Object? get real => getAttribute("real");

  /// ## real (setter)
  ///
  /// ### python docstring
  ///
  /// the real part of a complex number
  set real(Object? real) => setAttribute("real", real);

  /// ## conjugate (getter)
  Object? get conjugate => getAttribute("conjugate");

  /// ## conjugate (setter)
  set conjugate(Object? conjugate) => setAttribute("conjugate", conjugate);
}

/// ## dict
final class dict extends PythonClass {
  factory dict() => PythonFfiDart.instance.importClass(
        "builtins",
        "dict",
        dict.from,
        <Object?>[],
      );

  dict.from(super.pythonClass) : super.from();

  /// ## clear (getter)
  Object? get clear => getAttribute("clear");

  /// ## clear (setter)
  set clear(Object? clear) => setAttribute("clear", clear);

  /// ## copy (getter)
  Object? get copy => getAttribute("copy");

  /// ## copy (setter)
  set copy(Object? copy) => setAttribute("copy", copy);

  /// ## get (getter)
  Object? get $get => getAttribute("get");

  /// ## get (setter)
  set $get(Object? $get) => setAttribute("get", $get);

  /// ## items (getter)
  Object? get items => getAttribute("items");

  /// ## items (setter)
  set items(Object? items) => setAttribute("items", items);

  /// ## keys (getter)
  Object? get keys => getAttribute("keys");

  /// ## keys (setter)
  set keys(Object? keys) => setAttribute("keys", keys);

  /// ## pop (getter)
  Object? get pop => getAttribute("pop");

  /// ## pop (setter)
  set pop(Object? pop) => setAttribute("pop", pop);

  /// ## popitem (getter)
  Object? get popitem => getAttribute("popitem");

  /// ## popitem (setter)
  set popitem(Object? popitem) => setAttribute("popitem", popitem);

  /// ## setdefault (getter)
  Object? get setdefault => getAttribute("setdefault");

  /// ## setdefault (setter)
  set setdefault(Object? setdefault) => setAttribute("setdefault", setdefault);

  /// ## update (getter)
  Object? get update => getAttribute("update");

  /// ## update (setter)
  set update(Object? update) => setAttribute("update", update);

  /// ## values (getter)
  Object? get values => getAttribute("values");

  /// ## values (setter)
  set values(Object? values) => setAttribute("values", values);
}

/// ## enumerate
final class enumerate extends PythonClass {
  factory enumerate() => PythonFfiDart.instance.importClass(
        "builtins",
        "enumerate",
        enumerate.from,
        <Object?>[],
      );

  enumerate.from(super.pythonClass) : super.from();
}

/// ## filter
final class filter extends PythonClass {
  factory filter() => PythonFfiDart.instance.importClass(
        "builtins",
        "filter",
        filter.from,
        <Object?>[],
      );

  filter.from(super.pythonClass) : super.from();
}

/// ## float
final class float extends PythonClass {
  factory float() => PythonFfiDart.instance.importClass(
        "builtins",
        "float",
        float.from,
        <Object?>[],
      );

  float.from(super.pythonClass) : super.from();

  /// ## imag (getter)
  ///
  /// ### python docstring
  ///
  /// the imaginary part of a complex number
  Object? get imag => getAttribute("imag");

  /// ## imag (setter)
  ///
  /// ### python docstring
  ///
  /// the imaginary part of a complex number
  set imag(Object? imag) => setAttribute("imag", imag);

  /// ## real (getter)
  ///
  /// ### python docstring
  ///
  /// the real part of a complex number
  Object? get real => getAttribute("real");

  /// ## real (setter)
  ///
  /// ### python docstring
  ///
  /// the real part of a complex number
  set real(Object? real) => setAttribute("real", real);

  /// ## as_integer_ratio (getter)
  Object? get as_integer_ratio => getAttribute("as_integer_ratio");

  /// ## as_integer_ratio (setter)
  set as_integer_ratio(Object? as_integer_ratio) =>
      setAttribute("as_integer_ratio", as_integer_ratio);

  /// ## conjugate (getter)
  Object? get conjugate => getAttribute("conjugate");

  /// ## conjugate (setter)
  set conjugate(Object? conjugate) => setAttribute("conjugate", conjugate);

  /// ## hex (getter)
  Object? get hex => getAttribute("hex");

  /// ## hex (setter)
  set hex(Object? hex) => setAttribute("hex", hex);

  /// ## is_integer (getter)
  Object? get is_integer => getAttribute("is_integer");

  /// ## is_integer (setter)
  set is_integer(Object? is_integer) => setAttribute("is_integer", is_integer);
}

/// ## frozenset
final class frozenset extends PythonClass {
  factory frozenset() => PythonFfiDart.instance.importClass(
        "builtins",
        "frozenset",
        frozenset.from,
        <Object?>[],
      );

  frozenset.from(super.pythonClass) : super.from();

  /// ## copy (getter)
  Object? get copy => getAttribute("copy");

  /// ## copy (setter)
  set copy(Object? copy) => setAttribute("copy", copy);

  /// ## difference (getter)
  Object? get difference => getAttribute("difference");

  /// ## difference (setter)
  set difference(Object? difference) => setAttribute("difference", difference);

  /// ## intersection (getter)
  Object? get intersection => getAttribute("intersection");

  /// ## intersection (setter)
  set intersection(Object? intersection) =>
      setAttribute("intersection", intersection);

  /// ## isdisjoint (getter)
  Object? get isdisjoint => getAttribute("isdisjoint");

  /// ## isdisjoint (setter)
  set isdisjoint(Object? isdisjoint) => setAttribute("isdisjoint", isdisjoint);

  /// ## issubset (getter)
  Object? get issubset => getAttribute("issubset");

  /// ## issubset (setter)
  set issubset(Object? issubset) => setAttribute("issubset", issubset);

  /// ## issuperset (getter)
  Object? get issuperset => getAttribute("issuperset");

  /// ## issuperset (setter)
  set issuperset(Object? issuperset) => setAttribute("issuperset", issuperset);

  /// ## symmetric_difference (getter)
  Object? get symmetric_difference => getAttribute("symmetric_difference");

  /// ## symmetric_difference (setter)
  set symmetric_difference(Object? symmetric_difference) =>
      setAttribute("symmetric_difference", symmetric_difference);

  /// ## union (getter)
  Object? get union => getAttribute("union");

  /// ## union (setter)
  set union(Object? union) => setAttribute("union", union);
}

/// ## int
final class int extends PythonClass {
  factory int() => PythonFfiDart.instance.importClass(
        "builtins",
        "int",
        int.from,
        <Object?>[],
      );

  int.from(super.pythonClass) : super.from();

  /// ## denominator (getter)
  ///
  /// ### python docstring
  ///
  /// the denominator of a rational number in lowest terms
  Object? get denominator => getAttribute("denominator");

  /// ## denominator (setter)
  ///
  /// ### python docstring
  ///
  /// the denominator of a rational number in lowest terms
  set denominator(Object? denominator) =>
      setAttribute("denominator", denominator);

  /// ## imag (getter)
  ///
  /// ### python docstring
  ///
  /// the imaginary part of a complex number
  Object? get imag => getAttribute("imag");

  /// ## imag (setter)
  ///
  /// ### python docstring
  ///
  /// the imaginary part of a complex number
  set imag(Object? imag) => setAttribute("imag", imag);

  /// ## numerator (getter)
  ///
  /// ### python docstring
  ///
  /// the numerator of a rational number in lowest terms
  Object? get numerator => getAttribute("numerator");

  /// ## numerator (setter)
  ///
  /// ### python docstring
  ///
  /// the numerator of a rational number in lowest terms
  set numerator(Object? numerator) => setAttribute("numerator", numerator);

  /// ## real (getter)
  ///
  /// ### python docstring
  ///
  /// the real part of a complex number
  Object? get real => getAttribute("real");

  /// ## real (setter)
  ///
  /// ### python docstring
  ///
  /// the real part of a complex number
  set real(Object? real) => setAttribute("real", real);

  /// ## as_integer_ratio (getter)
  Object? get as_integer_ratio => getAttribute("as_integer_ratio");

  /// ## as_integer_ratio (setter)
  set as_integer_ratio(Object? as_integer_ratio) =>
      setAttribute("as_integer_ratio", as_integer_ratio);

  /// ## bit_count (getter)
  Object? get bit_count => getAttribute("bit_count");

  /// ## bit_count (setter)
  set bit_count(Object? bit_count) => setAttribute("bit_count", bit_count);

  /// ## bit_length (getter)
  Object? get bit_length => getAttribute("bit_length");

  /// ## bit_length (setter)
  set bit_length(Object? bit_length) => setAttribute("bit_length", bit_length);

  /// ## conjugate (getter)
  ///
  /// ### python docstring
  ///
  /// Returns self, the complex conjugate of any int.
  Object? get conjugate => getAttribute("conjugate");

  /// ## conjugate (setter)
  ///
  /// ### python docstring
  ///
  /// Returns self, the complex conjugate of any int.
  set conjugate(Object? conjugate) => setAttribute("conjugate", conjugate);

  /// ## to_bytes (getter)
  Object? get to_bytes => getAttribute("to_bytes");

  /// ## to_bytes (setter)
  set to_bytes(Object? to_bytes) => setAttribute("to_bytes", to_bytes);
}

/// ## list
final class list extends PythonClass {
  factory list() => PythonFfiDart.instance.importClass(
        "builtins",
        "list",
        list.from,
        <Object?>[],
      );

  list.from(super.pythonClass) : super.from();

  /// ## append (getter)
  Object? get append => getAttribute("append");

  /// ## append (setter)
  set append(Object? append) => setAttribute("append", append);

  /// ## clear (getter)
  Object? get clear => getAttribute("clear");

  /// ## clear (setter)
  set clear(Object? clear) => setAttribute("clear", clear);

  /// ## copy (getter)
  Object? get copy => getAttribute("copy");

  /// ## copy (setter)
  set copy(Object? copy) => setAttribute("copy", copy);

  /// ## count (getter)
  Object? get count => getAttribute("count");

  /// ## count (setter)
  set count(Object? count) => setAttribute("count", count);

  /// ## extend (getter)
  Object? get extend => getAttribute("extend");

  /// ## extend (setter)
  set extend(Object? extend) => setAttribute("extend", extend);

  /// ## index (getter)
  Object? get index => getAttribute("index");

  /// ## index (setter)
  set index(Object? index) => setAttribute("index", index);

  /// ## insert (getter)
  Object? get insert => getAttribute("insert");

  /// ## insert (setter)
  set insert(Object? insert) => setAttribute("insert", insert);

  /// ## pop (getter)
  Object? get pop => getAttribute("pop");

  /// ## pop (setter)
  set pop(Object? pop) => setAttribute("pop", pop);

  /// ## remove (getter)
  Object? get remove => getAttribute("remove");

  /// ## remove (setter)
  set remove(Object? remove) => setAttribute("remove", remove);

  /// ## reverse (getter)
  Object? get reverse => getAttribute("reverse");

  /// ## reverse (setter)
  set reverse(Object? reverse) => setAttribute("reverse", reverse);

  /// ## sort (getter)
  Object? get sort => getAttribute("sort");

  /// ## sort (setter)
  set sort(Object? sort) => setAttribute("sort", sort);
}

/// ## map
final class map extends PythonClass {
  factory map() => PythonFfiDart.instance.importClass(
        "builtins",
        "map",
        map.from,
        <Object?>[],
      );

  map.from(super.pythonClass) : super.from();
}

/// ## memoryview
final class memoryview extends PythonClass {
  factory memoryview() => PythonFfiDart.instance.importClass(
        "builtins",
        "memoryview",
        memoryview.from,
        <Object?>[],
      );

  memoryview.from(super.pythonClass) : super.from();

  /// ## c_contiguous (getter)
  Object? get c_contiguous => getAttribute("c_contiguous");

  /// ## c_contiguous (setter)
  set c_contiguous(Object? c_contiguous) =>
      setAttribute("c_contiguous", c_contiguous);

  /// ## contiguous (getter)
  Object? get contiguous => getAttribute("contiguous");

  /// ## contiguous (setter)
  set contiguous(Object? contiguous) => setAttribute("contiguous", contiguous);

  /// ## f_contiguous (getter)
  Object? get f_contiguous => getAttribute("f_contiguous");

  /// ## f_contiguous (setter)
  set f_contiguous(Object? f_contiguous) =>
      setAttribute("f_contiguous", f_contiguous);

  /// ## format (getter)
  Object? get format => getAttribute("format");

  /// ## format (setter)
  set format(Object? format) => setAttribute("format", format);

  /// ## itemsize (getter)
  Object? get itemsize => getAttribute("itemsize");

  /// ## itemsize (setter)
  set itemsize(Object? itemsize) => setAttribute("itemsize", itemsize);

  /// ## nbytes (getter)
  Object? get nbytes => getAttribute("nbytes");

  /// ## nbytes (setter)
  set nbytes(Object? nbytes) => setAttribute("nbytes", nbytes);

  /// ## ndim (getter)
  Object? get ndim => getAttribute("ndim");

  /// ## ndim (setter)
  set ndim(Object? ndim) => setAttribute("ndim", ndim);

  /// ## obj (getter)
  Object? get obj => getAttribute("obj");

  /// ## obj (setter)
  set obj(Object? obj) => setAttribute("obj", obj);

  /// ## readonly (getter)
  Object? get readonly => getAttribute("readonly");

  /// ## readonly (setter)
  set readonly(Object? readonly) => setAttribute("readonly", readonly);

  /// ## shape (getter)
  Object? get shape => getAttribute("shape");

  /// ## shape (setter)
  set shape(Object? shape) => setAttribute("shape", shape);

  /// ## strides (getter)
  Object? get strides => getAttribute("strides");

  /// ## strides (setter)
  set strides(Object? strides) => setAttribute("strides", strides);

  /// ## suboffsets (getter)
  Object? get suboffsets => getAttribute("suboffsets");

  /// ## suboffsets (setter)
  set suboffsets(Object? suboffsets) => setAttribute("suboffsets", suboffsets);

  /// ## cast (getter)
  Object? get cast => getAttribute("cast");

  /// ## cast (setter)
  set cast(Object? cast) => setAttribute("cast", cast);

  /// ## hex (getter)
  Object? get hex => getAttribute("hex");

  /// ## hex (setter)
  set hex(Object? hex) => setAttribute("hex", hex);

  /// ## release (getter)
  Object? get release => getAttribute("release");

  /// ## release (setter)
  set release(Object? release) => setAttribute("release", release);

  /// ## tobytes (getter)
  Object? get tobytes => getAttribute("tobytes");

  /// ## tobytes (setter)
  set tobytes(Object? tobytes) => setAttribute("tobytes", tobytes);

  /// ## tolist (getter)
  Object? get tolist => getAttribute("tolist");

  /// ## tolist (setter)
  set tolist(Object? tolist) => setAttribute("tolist", tolist);

  /// ## toreadonly (getter)
  Object? get toreadonly => getAttribute("toreadonly");

  /// ## toreadonly (setter)
  set toreadonly(Object? toreadonly) => setAttribute("toreadonly", toreadonly);
}

/// ## object
final class object extends PythonClass {
  factory object() => PythonFfiDart.instance.importClass(
        "builtins",
        "object",
        object.from,
        <Object?>[],
      );

  object.from(super.pythonClass) : super.from();
}

/// ## property
final class property extends PythonClass {
  factory property() => PythonFfiDart.instance.importClass(
        "builtins",
        "property",
        property.from,
        <Object?>[],
      );

  property.from(super.pythonClass) : super.from();

  /// ## fdel (getter)
  Object? get fdel => getAttribute("fdel");

  /// ## fdel (setter)
  set fdel(Object? fdel) => setAttribute("fdel", fdel);

  /// ## fget (getter)
  Object? get fget => getAttribute("fget");

  /// ## fget (setter)
  set fget(Object? fget) => setAttribute("fget", fget);

  /// ## fset (getter)
  Object? get fset => getAttribute("fset");

  /// ## fset (setter)
  set fset(Object? fset) => setAttribute("fset", fset);

  /// ## deleter (getter)
  Object? get deleter => getAttribute("deleter");

  /// ## deleter (setter)
  set deleter(Object? deleter) => setAttribute("deleter", deleter);

  /// ## getter (getter)
  Object? get getter => getAttribute("getter");

  /// ## getter (setter)
  set getter(Object? getter) => setAttribute("getter", getter);

  /// ## setter (getter)
  Object? get setter => getAttribute("setter");

  /// ## setter (setter)
  set setter(Object? setter) => setAttribute("setter", setter);
}

/// ## range
final class range extends PythonClass {
  factory range() => PythonFfiDart.instance.importClass(
        "builtins",
        "range",
        range.from,
        <Object?>[],
      );

  range.from(super.pythonClass) : super.from();

  /// ## start (getter)
  Object? get start => getAttribute("start");

  /// ## start (setter)
  set start(Object? start) => setAttribute("start", start);

  /// ## step (getter)
  Object? get step => getAttribute("step");

  /// ## step (setter)
  set step(Object? step) => setAttribute("step", step);

  /// ## stop (getter)
  Object? get stop => getAttribute("stop");

  /// ## stop (setter)
  set stop(Object? stop) => setAttribute("stop", stop);

  /// ## count (getter)
  Object? get count => getAttribute("count");

  /// ## count (setter)
  set count(Object? count) => setAttribute("count", count);

  /// ## index (getter)
  Object? get index => getAttribute("index");

  /// ## index (setter)
  set index(Object? index) => setAttribute("index", index);
}

/// ## reversed
final class reversed extends PythonClass {
  factory reversed() => PythonFfiDart.instance.importClass(
        "builtins",
        "reversed",
        reversed.from,
        <Object?>[],
      );

  reversed.from(super.pythonClass) : super.from();
}

/// ## set
final class $set extends PythonClass {
  factory $set() => PythonFfiDart.instance.importClass(
        "builtins",
        "set",
        $set.from,
        <Object?>[],
      );

  $set.from(super.pythonClass) : super.from();

  /// ## add (getter)
  Object? get add => getAttribute("add");

  /// ## add (setter)
  set add(Object? add) => setAttribute("add", add);

  /// ## clear (getter)
  Object? get clear => getAttribute("clear");

  /// ## clear (setter)
  set clear(Object? clear) => setAttribute("clear", clear);

  /// ## copy (getter)
  Object? get copy => getAttribute("copy");

  /// ## copy (setter)
  set copy(Object? copy) => setAttribute("copy", copy);

  /// ## difference (getter)
  Object? get difference => getAttribute("difference");

  /// ## difference (setter)
  set difference(Object? difference) => setAttribute("difference", difference);

  /// ## difference_update (getter)
  Object? get difference_update => getAttribute("difference_update");

  /// ## difference_update (setter)
  set difference_update(Object? difference_update) =>
      setAttribute("difference_update", difference_update);

  /// ## discard (getter)
  Object? get discard => getAttribute("discard");

  /// ## discard (setter)
  set discard(Object? discard) => setAttribute("discard", discard);

  /// ## intersection (getter)
  Object? get intersection => getAttribute("intersection");

  /// ## intersection (setter)
  set intersection(Object? intersection) =>
      setAttribute("intersection", intersection);

  /// ## intersection_update (getter)
  Object? get intersection_update => getAttribute("intersection_update");

  /// ## intersection_update (setter)
  set intersection_update(Object? intersection_update) =>
      setAttribute("intersection_update", intersection_update);

  /// ## isdisjoint (getter)
  Object? get isdisjoint => getAttribute("isdisjoint");

  /// ## isdisjoint (setter)
  set isdisjoint(Object? isdisjoint) => setAttribute("isdisjoint", isdisjoint);

  /// ## issubset (getter)
  Object? get issubset => getAttribute("issubset");

  /// ## issubset (setter)
  set issubset(Object? issubset) => setAttribute("issubset", issubset);

  /// ## issuperset (getter)
  Object? get issuperset => getAttribute("issuperset");

  /// ## issuperset (setter)
  set issuperset(Object? issuperset) => setAttribute("issuperset", issuperset);

  /// ## pop (getter)
  Object? get pop => getAttribute("pop");

  /// ## pop (setter)
  set pop(Object? pop) => setAttribute("pop", pop);

  /// ## remove (getter)
  Object? get remove => getAttribute("remove");

  /// ## remove (setter)
  set remove(Object? remove) => setAttribute("remove", remove);

  /// ## symmetric_difference (getter)
  Object? get symmetric_difference => getAttribute("symmetric_difference");

  /// ## symmetric_difference (setter)
  set symmetric_difference(Object? symmetric_difference) =>
      setAttribute("symmetric_difference", symmetric_difference);

  /// ## symmetric_difference_update (getter)
  Object? get symmetric_difference_update =>
      getAttribute("symmetric_difference_update");

  /// ## symmetric_difference_update (setter)
  set symmetric_difference_update(Object? symmetric_difference_update) =>
      setAttribute("symmetric_difference_update", symmetric_difference_update);

  /// ## union (getter)
  Object? get union => getAttribute("union");

  /// ## union (setter)
  set union(Object? union) => setAttribute("union", union);

  /// ## update (getter)
  Object? get update => getAttribute("update");

  /// ## update (setter)
  set update(Object? update) => setAttribute("update", update);
}

/// ## slice
final class slice extends PythonClass {
  factory slice() => PythonFfiDart.instance.importClass(
        "builtins",
        "slice",
        slice.from,
        <Object?>[],
      );

  slice.from(super.pythonClass) : super.from();

  /// ## start (getter)
  Object? get start => getAttribute("start");

  /// ## start (setter)
  set start(Object? start) => setAttribute("start", start);

  /// ## step (getter)
  Object? get step => getAttribute("step");

  /// ## step (setter)
  set step(Object? step) => setAttribute("step", step);

  /// ## stop (getter)
  Object? get stop => getAttribute("stop");

  /// ## stop (setter)
  set stop(Object? stop) => setAttribute("stop", stop);

  /// ## indices (getter)
  Object? get indices => getAttribute("indices");

  /// ## indices (setter)
  set indices(Object? indices) => setAttribute("indices", indices);
}

/// ## staticmethod
final class staticmethod extends PythonClass {
  factory staticmethod() => PythonFfiDart.instance.importClass(
        "builtins",
        "staticmethod",
        staticmethod.from,
        <Object?>[],
      );

  staticmethod.from(super.pythonClass) : super.from();
}

/// ## super
final class $super extends PythonClass {
  factory $super() => PythonFfiDart.instance.importClass(
        "builtins",
        "super",
        $super.from,
        <Object?>[],
      );

  $super.from(super.pythonClass) : super.from();
}

/// ## tuple
final class tuple extends PythonClass {
  factory tuple() => PythonFfiDart.instance.importClass(
        "builtins",
        "tuple",
        tuple.from,
        <Object?>[],
      );

  tuple.from(super.pythonClass) : super.from();

  /// ## count (getter)
  Object? get count => getAttribute("count");

  /// ## count (setter)
  set count(Object? count) => setAttribute("count", count);

  /// ## index (getter)
  Object? get index => getAttribute("index");

  /// ## index (setter)
  set index(Object? index) => setAttribute("index", index);
}

/// ## type
final class type extends PythonClass {
  factory type() => PythonFfiDart.instance.importClass(
        "builtins",
        "type",
        type.from,
        <Object?>[],
      );

  type.from(super.pythonClass) : super.from();

  /// ## mro (getter)
  Object? get mro => getAttribute("mro");

  /// ## mro (setter)
  set mro(Object? mro) => setAttribute("mro", mro);
}

/// ## zip
final class zip extends PythonClass {
  factory zip() => PythonFfiDart.instance.importClass(
        "builtins",
        "zip",
        zip.from,
        <Object?>[],
      );

  zip.from(super.pythonClass) : super.from();
}

/// ## islice
final class islice extends PythonClass {
  factory islice() => PythonFfiDart.instance.importClass(
        "itertools",
        "islice",
        islice.from,
        <Object?>[],
      );

  islice.from(super.pythonClass) : super.from();
}

/// ## partial
///
/// ### python source
/// ```py
/// class partial:
///     """New function with partial application of the given arguments
///     and keywords.
///     """
///
///     __slots__ = "func", "args", "keywords", "__dict__", "__weakref__"
///
///     def __new__(cls, func, /, *args, **keywords):
///         if not callable(func):
///             raise TypeError("the first argument must be callable")
///
///         if hasattr(func, "func"):
///             args = func.args + args
///             keywords = {**func.keywords, **keywords}
///             func = func.func
///
///         self = super(partial, cls).__new__(cls)
///
///         self.func = func
///         self.args = args
///         self.keywords = keywords
///         return self
///
///     def __call__(self, /, *args, **keywords):
///         keywords = {**self.keywords, **keywords}
///         return self.func(*self.args, *args, **keywords)
///
///     @recursive_repr()
///     def __repr__(self):
///         qualname = type(self).__qualname__
///         args = [repr(self.func)]
///         args.extend(repr(x) for x in self.args)
///         args.extend(f"{k}={v!r}" for (k, v) in self.keywords.items())
///         if type(self).__module__ == "functools":
///             return f"functools.{qualname}({', '.join(args)})"
///         return f"{qualname}({', '.join(args)})"
///
///     def __reduce__(self):
///         return type(self), (self.func,), (self.func, self.args,
///                self.keywords or None, self.__dict__ or None)
///
///     def __setstate__(self, state):
///         if not isinstance(state, tuple):
///             raise TypeError("argument to __setstate__ must be a tuple")
///         if len(state) != 4:
///             raise TypeError(f"expected 4 items in state, got {len(state)}")
///         func, args, kwds, namespace = state
///         if (not callable(func) or not isinstance(args, tuple) or
///            (kwds is not None and not isinstance(kwds, dict)) or
///            (namespace is not None and not isinstance(namespace, dict))):
///             raise TypeError("invalid partial state")
///
///         args = tuple(args) # just in case it's a subclass
///         if kwds is None:
///             kwds = {}
///         elif type(kwds) is not dict: # XXX does it need to be *exactly* dict?
///             kwds = dict(kwds)
///         if namespace is None:
///             namespace = {}
///
///         self.__dict__ = namespace
///         self.func = func
///         self.args = args
///         self.keywords = kwds
/// ```
final class partial extends PythonClass {
  factory partial() => PythonFfiDart.instance.importClass(
        "functools",
        "partial",
        partial.from,
        <Object?>[],
      );

  partial.from(super.pythonClass) : super.from();

  /// ## args (getter)
  ///
  /// ### python docstring
  ///
  /// tuple of arguments to future partial calls
  Object? get args => getAttribute("args");

  /// ## args (setter)
  ///
  /// ### python docstring
  ///
  /// tuple of arguments to future partial calls
  set args(Object? args) => setAttribute("args", args);

  /// ## func (getter)
  ///
  /// ### python docstring
  ///
  /// function object to use in future partial calls
  Object? get func => getAttribute("func");

  /// ## func (setter)
  ///
  /// ### python docstring
  ///
  /// function object to use in future partial calls
  set func(Object? func) => setAttribute("func", func);

  /// ## keywords (getter)
  ///
  /// ### python docstring
  ///
  /// dictionary of keyword arguments to future partial calls
  Object? get keywords => getAttribute("keywords");

  /// ## keywords (setter)
  ///
  /// ### python docstring
  ///
  /// dictionary of keyword arguments to future partial calls
  set keywords(Object? keywords) => setAttribute("keywords", keywords);
}

/// ## Match
final class Match extends PythonClass {
  factory Match() => PythonFfiDart.instance.importClass(
        "re",
        "Match",
        Match.from,
        <Object?>[],
      );

  Match.from(super.pythonClass) : super.from();

  /// ## endpos (getter)
  ///
  /// ### python docstring
  ///
  /// The index into the string beyond which the RE engine will not go.
  Object? get endpos => getAttribute("endpos");

  /// ## endpos (setter)
  ///
  /// ### python docstring
  ///
  /// The index into the string beyond which the RE engine will not go.
  set endpos(Object? endpos) => setAttribute("endpos", endpos);

  /// ## lastgroup (getter)
  ///
  /// ### python docstring
  ///
  /// The name of the last matched capturing group.
  Object? get lastgroup => getAttribute("lastgroup");

  /// ## lastgroup (setter)
  ///
  /// ### python docstring
  ///
  /// The name of the last matched capturing group.
  set lastgroup(Object? lastgroup) => setAttribute("lastgroup", lastgroup);

  /// ## lastindex (getter)
  ///
  /// ### python docstring
  ///
  /// The integer index of the last matched capturing group.
  Object? get lastindex => getAttribute("lastindex");

  /// ## lastindex (setter)
  ///
  /// ### python docstring
  ///
  /// The integer index of the last matched capturing group.
  set lastindex(Object? lastindex) => setAttribute("lastindex", lastindex);

  /// ## pos (getter)
  ///
  /// ### python docstring
  ///
  /// The index into the string at which the RE engine started looking for a match.
  Object? get pos => getAttribute("pos");

  /// ## pos (setter)
  ///
  /// ### python docstring
  ///
  /// The index into the string at which the RE engine started looking for a match.
  set pos(Object? pos) => setAttribute("pos", pos);

  /// ## re (getter)
  ///
  /// ### python docstring
  ///
  /// The regular expression object.
  Object? get re => getAttribute("re");

  /// ## re (setter)
  ///
  /// ### python docstring
  ///
  /// The regular expression object.
  set re(Object? re) => setAttribute("re", re);

  /// ## regs (getter)
  Object? get regs => getAttribute("regs");

  /// ## regs (setter)
  set regs(Object? regs) => setAttribute("regs", regs);

  /// ## string (getter)
  ///
  /// ### python docstring
  ///
  /// The string passed to match() or search().
  Object? get string => getAttribute("string");

  /// ## string (setter)
  ///
  /// ### python docstring
  ///
  /// The string passed to match() or search().
  set string(Object? string) => setAttribute("string", string);

  /// ## end (getter)
  Object? get end => getAttribute("end");

  /// ## end (setter)
  set end(Object? end) => setAttribute("end", end);

  /// ## expand (getter)
  Object? get expand => getAttribute("expand");

  /// ## expand (setter)
  set expand(Object? expand) => setAttribute("expand", expand);

  /// ## group (getter)
  Object? get group => getAttribute("group");

  /// ## group (setter)
  set group(Object? group) => setAttribute("group", group);

  /// ## groupdict (getter)
  Object? get groupdict => getAttribute("groupdict");

  /// ## groupdict (setter)
  set groupdict(Object? groupdict) => setAttribute("groupdict", groupdict);

  /// ## groups (getter)
  Object? get groups => getAttribute("groups");

  /// ## groups (setter)
  set groups(Object? groups) => setAttribute("groups", groups);

  /// ## span (getter)
  Object? get span => getAttribute("span");

  /// ## span (setter)
  set span(Object? span) => setAttribute("span", span);

  /// ## start (getter)
  Object? get start => getAttribute("start");

  /// ## start (setter)
  set start(Object? start) => setAttribute("start", start);
}

/// ## Pattern
final class Pattern extends PythonClass {
  factory Pattern() => PythonFfiDart.instance.importClass(
        "re",
        "Pattern",
        Pattern.from,
        <Object?>[],
      );

  Pattern.from(super.pythonClass) : super.from();

  /// ## flags (getter)
  ///
  /// ### python docstring
  ///
  /// The regex matching flags.
  Object? get flags => getAttribute("flags");

  /// ## flags (setter)
  ///
  /// ### python docstring
  ///
  /// The regex matching flags.
  set flags(Object? flags) => setAttribute("flags", flags);

  /// ## groupindex (getter)
  ///
  /// ### python docstring
  ///
  /// A dictionary mapping group names to group numbers.
  Object? get groupindex => getAttribute("groupindex");

  /// ## groupindex (setter)
  ///
  /// ### python docstring
  ///
  /// A dictionary mapping group names to group numbers.
  set groupindex(Object? groupindex) => setAttribute("groupindex", groupindex);

  /// ## groups (getter)
  ///
  /// ### python docstring
  ///
  /// The number of capturing groups in the pattern.
  Object? get groups => getAttribute("groups");

  /// ## groups (setter)
  ///
  /// ### python docstring
  ///
  /// The number of capturing groups in the pattern.
  set groups(Object? groups) => setAttribute("groups", groups);

  /// ## pattern (getter)
  ///
  /// ### python docstring
  ///
  /// The pattern string from which the RE object was compiled.
  Object? get pattern => getAttribute("pattern");

  /// ## pattern (setter)
  ///
  /// ### python docstring
  ///
  /// The pattern string from which the RE object was compiled.
  set pattern(Object? pattern) => setAttribute("pattern", pattern);

  /// ## findall (getter)
  Object? get findall => getAttribute("findall");

  /// ## findall (setter)
  set findall(Object? findall) => setAttribute("findall", findall);

  /// ## finditer (getter)
  Object? get finditer => getAttribute("finditer");

  /// ## finditer (setter)
  set finditer(Object? finditer) => setAttribute("finditer", finditer);

  /// ## fullmatch (getter)
  Object? get fullmatch => getAttribute("fullmatch");

  /// ## fullmatch (setter)
  set fullmatch(Object? fullmatch) => setAttribute("fullmatch", fullmatch);

  /// ## match (getter)
  Object? get match => getAttribute("match");

  /// ## match (setter)
  set match(Object? match) => setAttribute("match", match);

  /// ## scanner (getter)
  Object? get scanner => getAttribute("scanner");

  /// ## scanner (setter)
  set scanner(Object? scanner) => setAttribute("scanner", scanner);

  /// ## search (getter)
  Object? get search => getAttribute("search");

  /// ## search (setter)
  set search(Object? search) => setAttribute("search", search);

  /// ## split (getter)
  Object? get split => getAttribute("split");

  /// ## split (setter)
  set split(Object? split) => setAttribute("split", split);

  /// ## sub (getter)
  Object? get sub => getAttribute("sub");

  /// ## sub (setter)
  set sub(Object? sub) => setAttribute("sub", sub);

  /// ## subn (getter)
  Object? get subn => getAttribute("subn");

  /// ## subn (setter)
  set subn(Object? subn) => setAttribute("subn", subn);
}

/// ## RegexFlag
///
/// ### python docstring
///
/// An enumeration.
///
/// ### python source
/// ```py
/// @enum.global_enum
/// @enum._simple_enum(enum.IntFlag, boundary=enum.KEEP)
/// class RegexFlag:
///     NOFLAG = 0
///     ASCII = A = _compiler.SRE_FLAG_ASCII # assume ascii "locale"
///     IGNORECASE = I = _compiler.SRE_FLAG_IGNORECASE # ignore case
///     LOCALE = L = _compiler.SRE_FLAG_LOCALE # assume current 8-bit locale
///     UNICODE = U = _compiler.SRE_FLAG_UNICODE # assume unicode "locale"
///     MULTILINE = M = _compiler.SRE_FLAG_MULTILINE # make anchors look for newline
///     DOTALL = S = _compiler.SRE_FLAG_DOTALL # make dot match newline
///     VERBOSE = X = _compiler.SRE_FLAG_VERBOSE # ignore whitespace and comments
///     # sre extensions (experimental, don't rely on these)
///     TEMPLATE = T = _compiler.SRE_FLAG_TEMPLATE # unknown purpose, deprecated
///     DEBUG = _compiler.SRE_FLAG_DEBUG # dump pattern after compilation
///     __str__ = object.__str__
///     _numeric_repr_ = hex
/// ```
final class RegexFlag extends PythonClass {
  factory RegexFlag({
    List<Object?> args = const <Object?>[],
    Map<String, Object?> kwds = const <String, Object?>{},
  }) =>
      PythonFfiDart.instance.importClass(
        "re",
        "RegexFlag",
        RegexFlag.from,
        <Object?>[
          ...args,
        ],
        <String, Object?>{
          ...kwds,
        },
      );

  RegexFlag.from(super.pythonClass) : super.from();

  /// ## denominator (getter)
  ///
  /// ### python docstring
  ///
  /// the denominator of a rational number in lowest terms
  Object? get denominator => getAttribute("denominator");

  /// ## denominator (setter)
  ///
  /// ### python docstring
  ///
  /// the denominator of a rational number in lowest terms
  set denominator(Object? denominator) =>
      setAttribute("denominator", denominator);

  /// ## imag (getter)
  ///
  /// ### python docstring
  ///
  /// the imaginary part of a complex number
  Object? get imag => getAttribute("imag");

  /// ## imag (setter)
  ///
  /// ### python docstring
  ///
  /// the imaginary part of a complex number
  set imag(Object? imag) => setAttribute("imag", imag);

  /// ## numerator (getter)
  ///
  /// ### python docstring
  ///
  /// the numerator of a rational number in lowest terms
  Object? get numerator => getAttribute("numerator");

  /// ## numerator (setter)
  ///
  /// ### python docstring
  ///
  /// the numerator of a rational number in lowest terms
  set numerator(Object? numerator) => setAttribute("numerator", numerator);

  /// ## real (getter)
  ///
  /// ### python docstring
  ///
  /// the real part of a complex number
  Object? get real => getAttribute("real");

  /// ## real (setter)
  ///
  /// ### python docstring
  ///
  /// the real part of a complex number
  set real(Object? real) => setAttribute("real", real);

  /// ## as_integer_ratio (getter)
  Object? get as_integer_ratio => getAttribute("as_integer_ratio");

  /// ## as_integer_ratio (setter)
  set as_integer_ratio(Object? as_integer_ratio) =>
      setAttribute("as_integer_ratio", as_integer_ratio);

  /// ## bit_count (getter)
  Object? get bit_count => getAttribute("bit_count");

  /// ## bit_count (setter)
  set bit_count(Object? bit_count) => setAttribute("bit_count", bit_count);

  /// ## bit_length (getter)
  Object? get bit_length => getAttribute("bit_length");

  /// ## bit_length (setter)
  set bit_length(Object? bit_length) => setAttribute("bit_length", bit_length);

  /// ## conjugate (getter)
  ///
  /// ### python docstring
  ///
  /// Returns self, the complex conjugate of any int.
  Object? get conjugate => getAttribute("conjugate");

  /// ## conjugate (setter)
  ///
  /// ### python docstring
  ///
  /// Returns self, the complex conjugate of any int.
  set conjugate(Object? conjugate) => setAttribute("conjugate", conjugate);

  /// ## to_bytes (getter)
  Object? get to_bytes => getAttribute("to_bytes");

  /// ## to_bytes (setter)
  set to_bytes(Object? to_bytes) => setAttribute("to_bytes", to_bytes);

  /// ## ASCII (getter)
  Object? get ASCII => getAttribute("ASCII");

  /// ## ASCII (setter)
  set ASCII(Object? ASCII) => setAttribute("ASCII", ASCII);

  /// ## DEBUG (getter)
  Object? get DEBUG => getAttribute("DEBUG");

  /// ## DEBUG (setter)
  set DEBUG(Object? DEBUG) => setAttribute("DEBUG", DEBUG);

  /// ## DOTALL (getter)
  Object? get DOTALL => getAttribute("DOTALL");

  /// ## DOTALL (setter)
  set DOTALL(Object? DOTALL) => setAttribute("DOTALL", DOTALL);

  /// ## IGNORECASE (getter)
  Object? get IGNORECASE => getAttribute("IGNORECASE");

  /// ## IGNORECASE (setter)
  set IGNORECASE(Object? IGNORECASE) => setAttribute("IGNORECASE", IGNORECASE);

  /// ## LOCALE (getter)
  Object? get LOCALE => getAttribute("LOCALE");

  /// ## LOCALE (setter)
  set LOCALE(Object? LOCALE) => setAttribute("LOCALE", LOCALE);

  /// ## MULTILINE (getter)
  Object? get MULTILINE => getAttribute("MULTILINE");

  /// ## MULTILINE (setter)
  set MULTILINE(Object? MULTILINE) => setAttribute("MULTILINE", MULTILINE);

  /// ## TEMPLATE (getter)
  Object? get TEMPLATE => getAttribute("TEMPLATE");

  /// ## TEMPLATE (setter)
  set TEMPLATE(Object? TEMPLATE) => setAttribute("TEMPLATE", TEMPLATE);

  /// ## UNICODE (getter)
  Object? get UNICODE => getAttribute("UNICODE");

  /// ## UNICODE (setter)
  set UNICODE(Object? UNICODE) => setAttribute("UNICODE", UNICODE);

  /// ## VERBOSE (getter)
  Object? get VERBOSE => getAttribute("VERBOSE");

  /// ## VERBOSE (setter)
  set VERBOSE(Object? VERBOSE) => setAttribute("VERBOSE", VERBOSE);
}

/// ## Scanner
///
/// ### python source
/// ```py
/// class Scanner:
///     def __init__(self, lexicon, flags=0):
///         from ._constants import BRANCH, SUBPATTERN
///         if isinstance(flags, RegexFlag):
///             flags = flags.value
///         self.lexicon = lexicon
///         # combine phrases into a compound pattern
///         p = []
///         s = _parser.State()
///         s.flags = flags
///         for phrase, action in lexicon:
///             gid = s.opengroup()
///             p.append(_parser.SubPattern(s, [
///                 (SUBPATTERN, (gid, 0, 0, _parser.parse(phrase, flags))),
///                 ]))
///             s.closegroup(gid, p[-1])
///         p = _parser.SubPattern(s, [(BRANCH, (None, p))])
///         self.scanner = _compiler.compile(p)
///     def scan(self, string):
///         result = []
///         append = result.append
///         match = self.scanner.scanner(string).match
///         i = 0
///         while True:
///             m = match()
///             if not m:
///                 break
///             j = m.end()
///             if i == j:
///                 break
///             action = self.lexicon[m.lastindex-1][1]
///             if callable(action):
///                 self.match = m
///                 action = action(self, m.group())
///             if action is not None:
///                 append(action)
///             i = j
///         return result, string[i:]
/// ```
final class Scanner extends PythonClass {
  factory Scanner({
    required Object? lexicon,
    Object? flags = 0,
  }) =>
      PythonFfiDart.instance.importClass(
        "re",
        "Scanner",
        Scanner.from,
        <Object?>[
          lexicon,
          flags,
        ],
        <String, Object?>{},
      );

  Scanner.from(super.pythonClass) : super.from();

  /// ## scan
  ///
  /// ### python source
  /// ```py
  /// def scan(self, string):
  ///         result = []
  ///         append = result.append
  ///         match = self.scanner.scanner(string).match
  ///         i = 0
  ///         while True:
  ///             m = match()
  ///             if not m:
  ///                 break
  ///             j = m.end()
  ///             if i == j:
  ///                 break
  ///             action = self.lexicon[m.lastindex-1][1]
  ///             if callable(action):
  ///                 self.match = m
  ///                 action = action(self, m.group())
  ///             if action is not None:
  ///                 append(action)
  ///             i = j
  ///         return result, string[i:]
  /// ```
  Object? scan({
    required Object? string,
  }) =>
      getFunction("scan").call(
        <Object?>[
          string,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## lexicon (getter)
  Object? get lexicon => getAttribute("lexicon");

  /// ## lexicon (setter)
  set lexicon(Object? lexicon) => setAttribute("lexicon", lexicon);

  /// ## scanner (getter)
  Object? get scanner => getAttribute("scanner");

  /// ## scanner (setter)
  set scanner(Object? scanner) => setAttribute("scanner", scanner);
}

/// ## DynamicClassAttribute
///
/// ### python docstring
///
/// Route attribute access on a class to __getattr__.
///
/// This is a descriptor, used to define attributes that act differently when
/// accessed through an instance and through a class.  Instance access remains
/// normal, but access to an attribute through a class will be routed to the
/// class's __getattr__ method; this is done by raising AttributeError.
///
/// This allows one to have properties active on an instance, and have virtual
/// attributes on the class with the same name.  (Enum used this between Python
/// versions 3.4 - 3.9 .)
///
/// Subclass from this to use a different method of accessing virtual attributes
/// and still be treated properly by the inspect module. (Enum uses this since
/// Python 3.10 .)
///
/// ### python source
/// ```py
/// class DynamicClassAttribute:
///     """Route attribute access on a class to __getattr__.
///
///     This is a descriptor, used to define attributes that act differently when
///     accessed through an instance and through a class.  Instance access remains
///     normal, but access to an attribute through a class will be routed to the
///     class's __getattr__ method; this is done by raising AttributeError.
///
///     This allows one to have properties active on an instance, and have virtual
///     attributes on the class with the same name.  (Enum used this between Python
///     versions 3.4 - 3.9 .)
///
///     Subclass from this to use a different method of accessing virtual attributes
///     and still be treated properly by the inspect module. (Enum uses this since
///     Python 3.10 .)
///
///     """
///     def __init__(self, fget=None, fset=None, fdel=None, doc=None):
///         self.fget = fget
///         self.fset = fset
///         self.fdel = fdel
///         # next two lines make DynamicClassAttribute act the same as property
///         self.__doc__ = doc or fget.__doc__
///         self.overwrite_doc = doc is None
///         # support for abstract methods
///         self.__isabstractmethod__ = bool(getattr(fget, '__isabstractmethod__', False))
///
///     def __get__(self, instance, ownerclass=None):
///         if instance is None:
///             if self.__isabstractmethod__:
///                 return self
///             raise AttributeError()
///         elif self.fget is None:
///             raise AttributeError("unreadable attribute")
///         return self.fget(instance)
///
///     def __set__(self, instance, value):
///         if self.fset is None:
///             raise AttributeError("can't set attribute")
///         self.fset(instance, value)
///
///     def __delete__(self, instance):
///         if self.fdel is None:
///             raise AttributeError("can't delete attribute")
///         self.fdel(instance)
///
///     def getter(self, fget):
///         fdoc = fget.__doc__ if self.overwrite_doc else None
///         result = type(self)(fget, self.fset, self.fdel, fdoc or self.__doc__)
///         result.overwrite_doc = self.overwrite_doc
///         return result
///
///     def setter(self, fset):
///         result = type(self)(self.fget, fset, self.fdel, self.__doc__)
///         result.overwrite_doc = self.overwrite_doc
///         return result
///
///     def deleter(self, fdel):
///         result = type(self)(self.fget, self.fset, fdel, self.__doc__)
///         result.overwrite_doc = self.overwrite_doc
///         return result
/// ```
final class DynamicClassAttribute extends PythonClass {
  factory DynamicClassAttribute({
    Object? fget,
    Object? fset,
    Object? fdel,
    Object? doc,
  }) =>
      PythonFfiDart.instance.importClass(
        "types",
        "DynamicClassAttribute",
        DynamicClassAttribute.from,
        <Object?>[
          fget,
          fset,
          fdel,
          doc,
        ],
        <String, Object?>{},
      );

  DynamicClassAttribute.from(super.pythonClass) : super.from();

  /// ## deleter
  ///
  /// ### python source
  /// ```py
  /// def deleter(self, fdel):
  ///         result = type(self)(self.fget, self.fset, fdel, self.__doc__)
  ///         result.overwrite_doc = self.overwrite_doc
  ///         return result
  /// ```
  Object? deleter({
    required Object? fdel,
  }) =>
      getFunction("deleter").call(
        <Object?>[
          fdel,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## getter
  ///
  /// ### python source
  /// ```py
  /// def getter(self, fget):
  ///         fdoc = fget.__doc__ if self.overwrite_doc else None
  ///         result = type(self)(fget, self.fset, self.fdel, fdoc or self.__doc__)
  ///         result.overwrite_doc = self.overwrite_doc
  ///         return result
  /// ```
  Object? getter({
    required Object? fget,
  }) =>
      getFunction("getter").call(
        <Object?>[
          fget,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## setter
  ///
  /// ### python source
  /// ```py
  /// def setter(self, fset):
  ///         result = type(self)(self.fget, fset, self.fdel, self.__doc__)
  ///         result.overwrite_doc = self.overwrite_doc
  ///         return result
  /// ```
  Object? setter({
    required Object? fset,
  }) =>
      getFunction("setter").call(
        <Object?>[
          fset,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## fget (getter)
  Object? get fget => getAttribute("fget");

  /// ## fget (setter)
  set fget(Object? fget) => setAttribute("fget", fget);

  /// ## fset (getter)
  Object? get fset => getAttribute("fset");

  /// ## fset (setter)
  set fset(Object? fset) => setAttribute("fset", fset);

  /// ## fdel (getter)
  Object? get fdel => getAttribute("fdel");

  /// ## fdel (setter)
  set fdel(Object? fdel) => setAttribute("fdel", fdel);

  /// ## overwrite_doc (getter)
  Object? get overwrite_doc => getAttribute("overwrite_doc");

  /// ## overwrite_doc (setter)
  set overwrite_doc(Object? overwrite_doc) =>
      setAttribute("overwrite_doc", overwrite_doc);
}

/// ## Enum
///
/// ### python docstring
///
/// Create a collection of name/value pairs.
///
/// Example enumeration:
///
/// >>> class Color(Enum):
/// ...     RED = 1
/// ...     BLUE = 2
/// ...     GREEN = 3
///
/// Access them by:
///
/// - attribute access::
///
/// >>> Color.RED
/// <Color.RED: 1>
///
/// - value lookup:
///
/// >>> Color(1)
/// <Color.RED: 1>
///
/// - name lookup:
///
/// >>> Color['RED']
/// <Color.RED: 1>
///
/// Enumerations can be iterated over, and know how many members they have:
///
/// >>> len(Color)
/// 3
///
/// >>> list(Color)
/// [<Color.RED: 1>, <Color.BLUE: 2>, <Color.GREEN: 3>]
///
/// Methods can be added to enumerations, and members can have their own
/// attributes -- see the documentation for details.
///
/// ### python source
/// ```py
/// class Enum(metaclass=EnumType):
///     """
///     Create a collection of name/value pairs.
///
///     Example enumeration:
///
///     >>> class Color(Enum):
///     ...     RED = 1
///     ...     BLUE = 2
///     ...     GREEN = 3
///
///     Access them by:
///
///     - attribute access::
///
///     >>> Color.RED
///     <Color.RED: 1>
///
///     - value lookup:
///
///     >>> Color(1)
///     <Color.RED: 1>
///
///     - name lookup:
///
///     >>> Color['RED']
///     <Color.RED: 1>
///
///     Enumerations can be iterated over, and know how many members they have:
///
///     >>> len(Color)
///     3
///
///     >>> list(Color)
///     [<Color.RED: 1>, <Color.BLUE: 2>, <Color.GREEN: 3>]
///
///     Methods can be added to enumerations, and members can have their own
///     attributes -- see the documentation for details.
///     """
///
///     def __new__(cls, value):
///         # all enum instances are actually created during class construction
///         # without calling this method; this method is called by the metaclass'
///         # __call__ (i.e. Color(3) ), and by pickle
///         if type(value) is cls:
///             # For lookups like Color(Color.RED)
///             return value
///         # by-value search for a matching enum member
///         # see if it's in the reverse mapping (for hashable values)
///         try:
///             return cls._value2member_map_[value]
///         except KeyError:
///             # Not found, no need to do long O(n) search
///             pass
///         except TypeError:
///             # not there, now do long search -- O(n) behavior
///             for member in cls._member_map_.values():
///                 if member._value_ == value:
///                     return member
///         # still not found -- try _missing_ hook
///         try:
///             exc = None
///             result = cls._missing_(value)
///         except Exception as e:
///             exc = e
///             result = None
///         try:
///             if isinstance(result, cls):
///                 return result
///             elif (
///                     Flag is not None and issubclass(cls, Flag)
///                     and cls._boundary_ is EJECT and isinstance(result, int)
///                 ):
///                 return result
///             else:
///                 ve_exc = ValueError("%r is not a valid %s" % (value, cls.__qualname__))
///                 if result is None and exc is None:
///                     raise ve_exc
///                 elif exc is None:
///                     exc = TypeError(
///                             'error in %s._missing_: returned %r instead of None or a valid member'
///                             % (cls.__name__, result)
///                             )
///                 if not isinstance(exc, ValueError):
///                     exc.__context__ = ve_exc
///                 raise exc
///         finally:
///             # ensure all variables that could hold an exception are destroyed
///             exc = None
///             ve_exc = None
///
///     def __init__(self, *args, **kwds):
///         pass
///
///     def _generate_next_value_(name, start, count, last_values):
///         """
///         Generate the next value when not given.
///
///         name: the name of the member
///         start: the initial start value or None
///         count: the number of existing members
///         last_values: the list of values assigned
///         """
///         if not last_values:
///             return start
///         try:
///             last = last_values[-1]
///             last_values.sort()
///             if last == last_values[-1]:
///                 # no difference between old and new methods
///                 return last + 1
///             else:
///                 # trigger old method (with warning)
///                 raise TypeError
///         except TypeError:
///             import warnings
///             warnings.warn(
///                     "In 3.13 the default `auto()`/`_generate_next_value_` will require all values to be sortable and support adding +1\n"
///                     "and the value returned will be the largest value in the enum incremented by 1",
///                     DeprecationWarning,
///                     stacklevel=3,
///                     )
///             for v in last_values:
///                 try:
///                     return v + 1
///                 except TypeError:
///                     pass
///             return start
///
///     @classmethod
///     def _missing_(cls, value):
///         return None
///
///     def __repr__(self):
///         v_repr = self.__class__._value_repr_ or repr
///         return "<%s.%s: %s>" % (self.__class__.__name__, self._name_, v_repr(self._value_))
///
///     def __str__(self):
///         return "%s.%s" % (self.__class__.__name__, self._name_, )
///
///     def __dir__(self):
///         """
///         Returns all members and all public methods
///         """
///         if self.__class__._member_type_ is object:
///             interesting = set(['__class__', '__doc__', '__eq__', '__hash__', '__module__', 'name', 'value'])
///         else:
///             interesting = set(object.__dir__(self))
///         for name in getattr(self, '__dict__', []):
///             if name[0] != '_':
///                 interesting.add(name)
///         for cls in self.__class__.mro():
///             for name, obj in cls.__dict__.items():
///                 if name[0] == '_':
///                     continue
///                 if isinstance(obj, property):
///                     # that's an enum.property
///                     if obj.fget is not None or name not in self._member_map_:
///                         interesting.add(name)
///                     else:
///                         # in case it was added by `dir(self)`
///                         interesting.discard(name)
///                 else:
///                     interesting.add(name)
///         names = sorted(
///                 set(['__class__', '__doc__', '__eq__', '__hash__', '__module__'])
///                 | interesting
///                 )
///         return names
///
///     def __format__(self, format_spec):
///         return str.__format__(str(self), format_spec)
///
///     def __hash__(self):
///         return hash(self._name_)
///
///     def __reduce_ex__(self, proto):
///         return getattr, (self.__class__, self._name_)
///
///     # enum.property is used to provide access to the `name` and
///     # `value` attributes of enum members while keeping some measure of
///     # protection from modification, while still allowing for an enumeration
///     # to have members named `name` and `value`.  This works because enumeration
///     # members are not set directly on the enum class; they are kept in a
///     # separate structure, _member_map_, which is where enum.property looks for
///     # them
///
///     @property
///     def name(self):
///         """The name of the Enum member."""
///         return self._name_
///
///     @property
///     def value(self):
///         """The value of the Enum member."""
///         return self._value_
/// ```
final class Enum extends PythonClass {
  factory Enum() => PythonFfiDart.instance.importClass(
        "enum",
        "Enum",
        Enum.from,
        <Object?>[],
      );

  Enum.from(super.pythonClass) : super.from();
}

/// ## EnumCheck
///
/// ### python docstring
///
/// various conditions to check an enumeration for
///
/// ### python source
/// ```py
/// @_simple_enum(StrEnum)
/// class EnumCheck:
///     """
///     various conditions to check an enumeration for
///     """
///     CONTINUOUS = "no skipped integer values"
///     NAMED_FLAGS = "multi-flag aliases may not contain unnamed flags"
///     UNIQUE = "one name per value"
/// ```
final class EnumCheck extends PythonClass {
  factory EnumCheck({
    List<Object?> args = const <Object?>[],
    Map<String, Object?> kwds = const <String, Object?>{},
  }) =>
      PythonFfiDart.instance.importClass(
        "enum",
        "EnumCheck",
        EnumCheck.from,
        <Object?>[
          ...args,
        ],
        <String, Object?>{
          ...kwds,
        },
      );

  EnumCheck.from(super.pythonClass) : super.from();

  /// ## capitalize (getter)
  Object? get capitalize => getAttribute("capitalize");

  /// ## capitalize (setter)
  set capitalize(Object? capitalize) => setAttribute("capitalize", capitalize);

  /// ## casefold (getter)
  Object? get casefold => getAttribute("casefold");

  /// ## casefold (setter)
  set casefold(Object? casefold) => setAttribute("casefold", casefold);

  /// ## center (getter)
  Object? get center => getAttribute("center");

  /// ## center (setter)
  set center(Object? center) => setAttribute("center", center);

  /// ## count (getter)
  Object? get count => getAttribute("count");

  /// ## count (setter)
  set count(Object? count) => setAttribute("count", count);

  /// ## encode (getter)
  Object? get encode => getAttribute("encode");

  /// ## encode (setter)
  set encode(Object? encode) => setAttribute("encode", encode);

  /// ## endswith (getter)
  Object? get endswith => getAttribute("endswith");

  /// ## endswith (setter)
  set endswith(Object? endswith) => setAttribute("endswith", endswith);

  /// ## expandtabs (getter)
  Object? get expandtabs => getAttribute("expandtabs");

  /// ## expandtabs (setter)
  set expandtabs(Object? expandtabs) => setAttribute("expandtabs", expandtabs);

  /// ## find (getter)
  Object? get find => getAttribute("find");

  /// ## find (setter)
  set find(Object? find) => setAttribute("find", find);

  /// ## format (getter)
  Object? get format => getAttribute("format");

  /// ## format (setter)
  set format(Object? format) => setAttribute("format", format);

  /// ## format_map (getter)
  Object? get format_map => getAttribute("format_map");

  /// ## format_map (setter)
  set format_map(Object? format_map) => setAttribute("format_map", format_map);

  /// ## index (getter)
  Object? get index => getAttribute("index");

  /// ## index (setter)
  set index(Object? index) => setAttribute("index", index);

  /// ## isalnum (getter)
  Object? get isalnum => getAttribute("isalnum");

  /// ## isalnum (setter)
  set isalnum(Object? isalnum) => setAttribute("isalnum", isalnum);

  /// ## isalpha (getter)
  Object? get isalpha => getAttribute("isalpha");

  /// ## isalpha (setter)
  set isalpha(Object? isalpha) => setAttribute("isalpha", isalpha);

  /// ## isascii (getter)
  Object? get isascii => getAttribute("isascii");

  /// ## isascii (setter)
  set isascii(Object? isascii) => setAttribute("isascii", isascii);

  /// ## isdecimal (getter)
  Object? get isdecimal => getAttribute("isdecimal");

  /// ## isdecimal (setter)
  set isdecimal(Object? isdecimal) => setAttribute("isdecimal", isdecimal);

  /// ## isdigit (getter)
  Object? get isdigit => getAttribute("isdigit");

  /// ## isdigit (setter)
  set isdigit(Object? isdigit) => setAttribute("isdigit", isdigit);

  /// ## isidentifier (getter)
  Object? get isidentifier => getAttribute("isidentifier");

  /// ## isidentifier (setter)
  set isidentifier(Object? isidentifier) =>
      setAttribute("isidentifier", isidentifier);

  /// ## islower (getter)
  Object? get islower => getAttribute("islower");

  /// ## islower (setter)
  set islower(Object? islower) => setAttribute("islower", islower);

  /// ## isnumeric (getter)
  Object? get isnumeric => getAttribute("isnumeric");

  /// ## isnumeric (setter)
  set isnumeric(Object? isnumeric) => setAttribute("isnumeric", isnumeric);

  /// ## isprintable (getter)
  Object? get isprintable => getAttribute("isprintable");

  /// ## isprintable (setter)
  set isprintable(Object? isprintable) =>
      setAttribute("isprintable", isprintable);

  /// ## isspace (getter)
  Object? get isspace => getAttribute("isspace");

  /// ## isspace (setter)
  set isspace(Object? isspace) => setAttribute("isspace", isspace);

  /// ## istitle (getter)
  Object? get istitle => getAttribute("istitle");

  /// ## istitle (setter)
  set istitle(Object? istitle) => setAttribute("istitle", istitle);

  /// ## isupper (getter)
  Object? get isupper => getAttribute("isupper");

  /// ## isupper (setter)
  set isupper(Object? isupper) => setAttribute("isupper", isupper);

  /// ## join (getter)
  Object? get join => getAttribute("join");

  /// ## join (setter)
  set join(Object? join) => setAttribute("join", join);

  /// ## ljust (getter)
  Object? get ljust => getAttribute("ljust");

  /// ## ljust (setter)
  set ljust(Object? ljust) => setAttribute("ljust", ljust);

  /// ## lower (getter)
  Object? get lower => getAttribute("lower");

  /// ## lower (setter)
  set lower(Object? lower) => setAttribute("lower", lower);

  /// ## lstrip (getter)
  Object? get lstrip => getAttribute("lstrip");

  /// ## lstrip (setter)
  set lstrip(Object? lstrip) => setAttribute("lstrip", lstrip);

  /// ## partition (getter)
  Object? get partition => getAttribute("partition");

  /// ## partition (setter)
  set partition(Object? partition) => setAttribute("partition", partition);

  /// ## removeprefix (getter)
  Object? get removeprefix => getAttribute("removeprefix");

  /// ## removeprefix (setter)
  set removeprefix(Object? removeprefix) =>
      setAttribute("removeprefix", removeprefix);

  /// ## removesuffix (getter)
  Object? get removesuffix => getAttribute("removesuffix");

  /// ## removesuffix (setter)
  set removesuffix(Object? removesuffix) =>
      setAttribute("removesuffix", removesuffix);

  /// ## replace (getter)
  Object? get replace => getAttribute("replace");

  /// ## replace (setter)
  set replace(Object? replace) => setAttribute("replace", replace);

  /// ## rfind (getter)
  Object? get rfind => getAttribute("rfind");

  /// ## rfind (setter)
  set rfind(Object? rfind) => setAttribute("rfind", rfind);

  /// ## rindex (getter)
  Object? get rindex => getAttribute("rindex");

  /// ## rindex (setter)
  set rindex(Object? rindex) => setAttribute("rindex", rindex);

  /// ## rjust (getter)
  Object? get rjust => getAttribute("rjust");

  /// ## rjust (setter)
  set rjust(Object? rjust) => setAttribute("rjust", rjust);

  /// ## rpartition (getter)
  Object? get rpartition => getAttribute("rpartition");

  /// ## rpartition (setter)
  set rpartition(Object? rpartition) => setAttribute("rpartition", rpartition);

  /// ## rsplit (getter)
  Object? get rsplit => getAttribute("rsplit");

  /// ## rsplit (setter)
  set rsplit(Object? rsplit) => setAttribute("rsplit", rsplit);

  /// ## rstrip (getter)
  Object? get rstrip => getAttribute("rstrip");

  /// ## rstrip (setter)
  set rstrip(Object? rstrip) => setAttribute("rstrip", rstrip);

  /// ## split (getter)
  Object? get split => getAttribute("split");

  /// ## split (setter)
  set split(Object? split) => setAttribute("split", split);

  /// ## splitlines (getter)
  Object? get splitlines => getAttribute("splitlines");

  /// ## splitlines (setter)
  set splitlines(Object? splitlines) => setAttribute("splitlines", splitlines);

  /// ## startswith (getter)
  Object? get startswith => getAttribute("startswith");

  /// ## startswith (setter)
  set startswith(Object? startswith) => setAttribute("startswith", startswith);

  /// ## strip (getter)
  Object? get strip => getAttribute("strip");

  /// ## strip (setter)
  set strip(Object? strip) => setAttribute("strip", strip);

  /// ## swapcase (getter)
  Object? get swapcase => getAttribute("swapcase");

  /// ## swapcase (setter)
  set swapcase(Object? swapcase) => setAttribute("swapcase", swapcase);

  /// ## title (getter)
  Object? get title => getAttribute("title");

  /// ## title (setter)
  set title(Object? title) => setAttribute("title", title);

  /// ## translate (getter)
  Object? get translate => getAttribute("translate");

  /// ## translate (setter)
  set translate(Object? translate) => setAttribute("translate", translate);

  /// ## upper (getter)
  Object? get upper => getAttribute("upper");

  /// ## upper (setter)
  set upper(Object? upper) => setAttribute("upper", upper);

  /// ## zfill (getter)
  Object? get zfill => getAttribute("zfill");

  /// ## zfill (setter)
  set zfill(Object? zfill) => setAttribute("zfill", zfill);

  /// ## CONTINUOUS (getter)
  Object? get CONTINUOUS => getAttribute("CONTINUOUS");

  /// ## CONTINUOUS (setter)
  set CONTINUOUS(Object? CONTINUOUS) => setAttribute("CONTINUOUS", CONTINUOUS);

  /// ## NAMED_FLAGS (getter)
  Object? get NAMED_FLAGS => getAttribute("NAMED_FLAGS");

  /// ## NAMED_FLAGS (setter)
  set NAMED_FLAGS(Object? NAMED_FLAGS) =>
      setAttribute("NAMED_FLAGS", NAMED_FLAGS);

  /// ## UNIQUE (getter)
  Object? get UNIQUE => getAttribute("UNIQUE");

  /// ## UNIQUE (setter)
  set UNIQUE(Object? UNIQUE) => setAttribute("UNIQUE", UNIQUE);
}

/// ## EnumMeta
///
/// ### python docstring
///
/// Metaclass for Enum
///
/// ### python source
/// ```py
/// class EnumType(type):
///     """
///     Metaclass for Enum
///     """
///
///     @classmethod
///     def __prepare__(metacls, cls, bases, **kwds):
///         # check that previous enum members do not exist
///         metacls._check_for_existing_members_(cls, bases)
///         # create the namespace dict
///         enum_dict = _EnumDict()
///         enum_dict._cls_name = cls
///         # inherit previous flags and _generate_next_value_ function
///         member_type, first_enum = metacls._get_mixins_(cls, bases)
///         if first_enum is not None:
///             enum_dict['_generate_next_value_'] = getattr(
///                     first_enum, '_generate_next_value_', None,
///                     )
///         return enum_dict
///
///     def __new__(metacls, cls, bases, classdict, *, boundary=None, _simple=False, **kwds):
///         # an Enum class is final once enumeration items have been defined; it
///         # cannot be mixed with other types (int, float, etc.) if it has an
///         # inherited __new__ unless a new __new__ is defined (or the resulting
///         # class will fail).
///         #
///         if _simple:
///             return super().__new__(metacls, cls, bases, classdict, **kwds)
///         #
///         # remove any keys listed in _ignore_
///         classdict.setdefault('_ignore_', []).append('_ignore_')
///         ignore = classdict['_ignore_']
///         for key in ignore:
///             classdict.pop(key, None)
///         #
///         # grab member names
///         member_names = classdict._member_names
///         #
///         # check for illegal enum names (any others?)
///         invalid_names = set(member_names) & {'mro', ''}
///         if invalid_names:
///             raise ValueError('invalid enum member name(s) %s'  % (
///                     ','.join(repr(n) for n in invalid_names)
///                     ))
///         #
///         # adjust the sunders
///         _order_ = classdict.pop('_order_', None)
///         # convert to normal dict
///         classdict = dict(classdict.items())
///         #
///         # data type of member and the controlling Enum class
///         member_type, first_enum = metacls._get_mixins_(cls, bases)
///         __new__, save_new, use_args = metacls._find_new_(
///                 classdict, member_type, first_enum,
///                 )
///         classdict['_new_member_'] = __new__
///         classdict['_use_args_'] = use_args
///         #
///         # convert future enum members into temporary _proto_members
///         # and record integer values in case this will be a Flag
///         flag_mask = 0
///         for name in member_names:
///             value = classdict[name]
///             if isinstance(value, int):
///                 flag_mask |= value
///             classdict[name] = _proto_member(value)
///         #
///         # house-keeping structures
///         classdict['_member_names_'] = []
///         classdict['_member_map_'] = {}
///         classdict['_value2member_map_'] = {}
///         classdict['_unhashable_values_'] = []
///         classdict['_member_type_'] = member_type
///         # now set the __repr__ for the value
///         classdict['_value_repr_'] = metacls._find_data_repr_(cls, bases)
///         #
///         # Flag structures (will be removed if final class is not a Flag
///         classdict['_boundary_'] = (
///                 boundary
///                 or getattr(first_enum, '_boundary_', None)
///                 )
///         classdict['_flag_mask_'] = flag_mask
///         classdict['_all_bits_'] = 2 ** ((flag_mask).bit_length()) - 1
///         classdict['_inverted_'] = None
///         try:
///             exc = None
///             enum_class = super().__new__(metacls, cls, bases, classdict, **kwds)
///         except RuntimeError as e:
///             # any exceptions raised by member.__new__ will get converted to a
///             # RuntimeError, so get that original exception back and raise it instead
///             exc = e.__cause__ or e
///         if exc is not None:
///             raise exc
///         #
///         # update classdict with any changes made by __init_subclass__
///         classdict.update(enum_class.__dict__)
///         #
///         # double check that repr and friends are not the mixin's or various
///         # things break (such as pickle)
///         # however, if the method is defined in the Enum itself, don't replace
///         # it
///         #
///         # Also, special handling for ReprEnum
///         if ReprEnum is not None and ReprEnum in bases:
///             if member_type is object:
///                 raise TypeError(
///                         'ReprEnum subclasses must be mixed with a data type (i.e.'
///                         ' int, str, float, etc.)'
///                         )
///             if '__format__' not in classdict:
///                 enum_class.__format__ = member_type.__format__
///                 classdict['__format__'] = enum_class.__format__
///             if '__str__' not in classdict:
///                 method = member_type.__str__
///                 if method is object.__str__:
///                     # if member_type does not define __str__, object.__str__ will use
///                     # its __repr__ instead, so we'll also use its __repr__
///                     method = member_type.__repr__
///                 enum_class.__str__ = method
///                 classdict['__str__'] = enum_class.__str__
///         for name in ('__repr__', '__str__', '__format__', '__reduce_ex__'):
///             if name not in classdict:
///                 # check for mixin overrides before replacing
///                 enum_method = getattr(first_enum, name)
///                 found_method = getattr(enum_class, name)
///                 object_method = getattr(object, name)
///                 data_type_method = getattr(member_type, name)
///                 if found_method in (data_type_method, object_method):
///                     setattr(enum_class, name, enum_method)
///         #
///         # for Flag, add __or__, __and__, __xor__, and __invert__
///         if Flag is not None and issubclass(enum_class, Flag):
///             for name in (
///                     '__or__', '__and__', '__xor__',
///                     '__ror__', '__rand__', '__rxor__',
///                     '__invert__'
///                 ):
///                 if name not in classdict:
///                     enum_method = getattr(Flag, name)
///                     setattr(enum_class, name, enum_method)
///                     classdict[name] = enum_method
///         #
///         # replace any other __new__ with our own (as long as Enum is not None,
///         # anyway) -- again, this is to support pickle
///         if Enum is not None:
///             # if the user defined their own __new__, save it before it gets
///             # clobbered in case they subclass later
///             if save_new:
///                 enum_class.__new_member__ = __new__
///             enum_class.__new__ = Enum.__new__
///         #
///         # py3 support for definition order (helps keep py2/py3 code in sync)
///         #
///         # _order_ checking is spread out into three/four steps
///         # - if enum_class is a Flag:
///         #   - remove any non-single-bit flags from _order_
///         # - remove any aliases from _order_
///         # - check that _order_ and _member_names_ match
///         #
///         # step 1: ensure we have a list
///         if _order_ is not None:
///             if isinstance(_order_, str):
///                 _order_ = _order_.replace(',', ' ').split()
///         #
///         # remove Flag structures if final class is not a Flag
///         if (
///                 Flag is None and cls != 'Flag'
///                 or Flag is not None and not issubclass(enum_class, Flag)
///             ):
///             delattr(enum_class, '_boundary_')
///             delattr(enum_class, '_flag_mask_')
///             delattr(enum_class, '_all_bits_')
///             delattr(enum_class, '_inverted_')
///         elif Flag is not None and issubclass(enum_class, Flag):
///             # ensure _all_bits_ is correct and there are no missing flags
///             single_bit_total = 0
///             multi_bit_total = 0
///             for flag in enum_class._member_map_.values():
///                 flag_value = flag._value_
///                 if _is_single_bit(flag_value):
///                     single_bit_total |= flag_value
///                 else:
///                     # multi-bit flags are considered aliases
///                     multi_bit_total |= flag_value
///             enum_class._flag_mask_ = single_bit_total
///             #
///             # set correct __iter__
///             member_list = [m._value_ for m in enum_class]
///             if member_list != sorted(member_list):
///                 enum_class._iter_member_ = enum_class._iter_member_by_def_
///             if _order_:
///                 # _order_ step 2: remove any items from _order_ that are not single-bit
///                 _order_ = [
///                         o
///                         for o in _order_
///                         if o not in enum_class._member_map_ or _is_single_bit(enum_class[o]._value_)
///                         ]
///         #
///         if _order_:
///             # _order_ step 3: remove aliases from _order_
///             _order_ = [
///                     o
///                     for o in _order_
///                     if (
///                         o not in enum_class._member_map_
///                         or
///                         (o in enum_class._member_map_ and o in enum_class._member_names_)
///                         )]
///             # _order_ step 4: verify that _order_ and _member_names_ match
///             if _order_ != enum_class._member_names_:
///                 raise TypeError(
///                         'member order does not match _order_:\n  %r\n  %r'
///                         % (enum_class._member_names_, _order_)
///                         )
///
///         return enum_class
///
///     def __bool__(cls):
///         """
///         classes/types should always be True.
///         """
///         return True
///
///     def __call__(cls, value, names=None, *, module=None, qualname=None, type=None, start=1, boundary=None):
///         """
///         Either returns an existing member, or creates a new enum class.
///
///         This method is used both when an enum class is given a value to match
///         to an enumeration member (i.e. Color(3)) and for the functional API
///         (i.e. Color = Enum('Color', names='RED GREEN BLUE')).
///
///         When used for the functional API:
///
///         `value` will be the name of the new class.
///
///         `names` should be either a string of white-space/comma delimited names
///         (values will start at `start`), or an iterator/mapping of name, value pairs.
///
///         `module` should be set to the module this class is being created in;
///         if it is not set, an attempt to find that module will be made, but if
///         it fails the class will not be picklable.
///
///         `qualname` should be set to the actual location this class can be found
///         at in its module; by default it is set to the global scope.  If this is
///         not correct, unpickling will fail in some circumstances.
///
///         `type`, if set, will be mixed in as the first base class.
///         """
///         if names is None:  # simple value lookup
///             return cls.__new__(cls, value)
///         # otherwise, functional API: we're creating a new Enum type
///         return cls._create_(
///                 value,
///                 names,
///                 module=module,
///                 qualname=qualname,
///                 type=type,
///                 start=start,
///                 boundary=boundary,
///                 )
///
///     def __contains__(cls, member):
///         """
///         Return True if member is a member of this enum
///         raises TypeError if member is not an enum member
///
///         note: in 3.12 TypeError will no longer be raised, and True will also be
///         returned if member is the value of a member in this enum
///         """
///         if not isinstance(member, Enum):
///             import warnings
///             warnings.warn(
///                     "in 3.12 __contains__ will no longer raise TypeError, but will return True or\n"
///                     "False depending on whether the value is a member or the value of a member",
///                     DeprecationWarning,
///                     stacklevel=2,
///                     )
///             raise TypeError(
///                 "unsupported operand type(s) for 'in': '%s' and '%s'" % (
///                     type(member).__qualname__, cls.__class__.__qualname__))
///         return isinstance(member, cls) and member._name_ in cls._member_map_
///
///     def __delattr__(cls, attr):
///         # nicer error message when someone tries to delete an attribute
///         # (see issue19025).
///         if attr in cls._member_map_:
///             raise AttributeError("%r cannot delete member %r." % (cls.__name__, attr))
///         super().__delattr__(attr)
///
///     def __dir__(cls):
///         interesting = set([
///                 '__class__', '__contains__', '__doc__', '__getitem__',
///                 '__iter__', '__len__', '__members__', '__module__',
///                 '__name__', '__qualname__',
///                 ]
///                 + cls._member_names_
///                 )
///         if cls._new_member_ is not object.__new__:
///             interesting.add('__new__')
///         if cls.__init_subclass__ is not object.__init_subclass__:
///             interesting.add('__init_subclass__')
///         if cls._member_type_ is object:
///             return sorted(interesting)
///         else:
///             # return whatever mixed-in data type has
///             return sorted(set(dir(cls._member_type_)) | interesting)
///
///     def __getattr__(cls, name):
///         """
///         Return the enum member matching `name`
///
///         We use __getattr__ instead of descriptors or inserting into the enum
///         class' __dict__ in order to support `name` and `value` being both
///         properties for enum members (which live in the class' __dict__) and
///         enum members themselves.
///         """
///         if _is_dunder(name):
///             raise AttributeError(name)
///         try:
///             return cls._member_map_[name]
///         except KeyError:
///             raise AttributeError(name) from None
///
///     def __getitem__(cls, name):
///         """
///         Return the member matching `name`.
///         """
///         return cls._member_map_[name]
///
///     def __iter__(cls):
///         """
///         Return members in definition order.
///         """
///         return (cls._member_map_[name] for name in cls._member_names_)
///
///     def __len__(cls):
///         """
///         Return the number of members (no aliases)
///         """
///         return len(cls._member_names_)
///
///     @bltns.property
///     def __members__(cls):
///         """
///         Returns a mapping of member name->value.
///
///         This mapping lists all enum members, including aliases. Note that this
///         is a read-only view of the internal mapping.
///         """
///         return MappingProxyType(cls._member_map_)
///
///     def __repr__(cls):
///         if Flag is not None and issubclass(cls, Flag):
///             return "<flag %r>" % cls.__name__
///         else:
///             return "<enum %r>" % cls.__name__
///
///     def __reversed__(cls):
///         """
///         Return members in reverse definition order.
///         """
///         return (cls._member_map_[name] for name in reversed(cls._member_names_))
///
///     def __setattr__(cls, name, value):
///         """
///         Block attempts to reassign Enum members.
///
///         A simple assignment to the class namespace only changes one of the
///         several possible ways to get an Enum member from the Enum class,
///         resulting in an inconsistent Enumeration.
///         """
///         member_map = cls.__dict__.get('_member_map_', {})
///         if name in member_map:
///             raise AttributeError('cannot reassign member %r' % (name, ))
///         super().__setattr__(name, value)
///
///     def _create_(cls, class_name, names, *, module=None, qualname=None, type=None, start=1, boundary=None):
///         """
///         Convenience method to create a new Enum class.
///
///         `names` can be:
///
///         * A string containing member names, separated either with spaces or
///           commas.  Values are incremented by 1 from `start`.
///         * An iterable of member names.  Values are incremented by 1 from `start`.
///         * An iterable of (member name, value) pairs.
///         * A mapping of member name -> value pairs.
///         """
///         metacls = cls.__class__
///         bases = (cls, ) if type is None else (type, cls)
///         _, first_enum = cls._get_mixins_(class_name, bases)
///         classdict = metacls.__prepare__(class_name, bases)
///
///         # special processing needed for names?
///         if isinstance(names, str):
///             names = names.replace(',', ' ').split()
///         if isinstance(names, (tuple, list)) and names and isinstance(names[0], str):
///             original_names, names = names, []
///             last_values = []
///             for count, name in enumerate(original_names):
///                 value = first_enum._generate_next_value_(name, start, count, last_values[:])
///                 last_values.append(value)
///                 names.append((name, value))
///
///         # Here, names is either an iterable of (name, value) or a mapping.
///         for item in names:
///             if isinstance(item, str):
///                 member_name, member_value = item, names[item]
///             else:
///                 member_name, member_value = item
///             classdict[member_name] = member_value
///
///         # TODO: replace the frame hack if a blessed way to know the calling
///         # module is ever developed
///         if module is None:
///             try:
///                 module = sys._getframe(2).f_globals['__name__']
///             except (AttributeError, ValueError, KeyError):
///                 pass
///         if module is None:
///             _make_class_unpicklable(classdict)
///         else:
///             classdict['__module__'] = module
///         if qualname is not None:
///             classdict['__qualname__'] = qualname
///
///         return metacls.__new__(metacls, class_name, bases, classdict, boundary=boundary)
///
///     def _convert_(cls, name, module, filter, source=None, *, boundary=None, as_global=False):
///         """
///         Create a new Enum subclass that replaces a collection of global constants
///         """
///         # convert all constants from source (or module) that pass filter() to
///         # a new Enum called name, and export the enum and its members back to
///         # module;
///         # also, replace the __reduce_ex__ method so unpickling works in
///         # previous Python versions
///         module_globals = sys.modules[module].__dict__
///         if source:
///             source = source.__dict__
///         else:
///             source = module_globals
///         # _value2member_map_ is populated in the same order every time
///         # for a consistent reverse mapping of number to name when there
///         # are multiple names for the same number.
///         members = [
///                 (name, value)
///                 for name, value in source.items()
///                 if filter(name)]
///         try:
///             # sort by value
///             members.sort(key=lambda t: (t[1], t[0]))
///         except TypeError:
///             # unless some values aren't comparable, in which case sort by name
///             members.sort(key=lambda t: t[0])
///         body = {t[0]: t[1] for t in members}
///         body['__module__'] = module
///         tmp_cls = type(name, (object, ), body)
///         cls = _simple_enum(etype=cls, boundary=boundary or KEEP)(tmp_cls)
///         cls.__reduce_ex__ = _reduce_ex_by_global_name
///         if as_global:
///             global_enum(cls)
///         else:
///             sys.modules[cls.__module__].__dict__.update(cls.__members__)
///         module_globals[name] = cls
///         return cls
///
///     @classmethod
///     def _check_for_existing_members_(mcls, class_name, bases):
///         for chain in bases:
///             for base in chain.__mro__:
///                 if isinstance(base, EnumType) and base._member_names_:
///                     raise TypeError(
///                             "<enum %r> cannot extend %r"
///                             % (class_name, base)
///                             )
///
///     @classmethod
///     def _get_mixins_(mcls, class_name, bases):
///         """
///         Returns the type for creating enum members, and the first inherited
///         enum class.
///
///         bases: the tuple of bases that was given to __new__
///         """
///         if not bases:
///             return object, Enum
///
///         mcls._check_for_existing_members_(class_name, bases)
///
///         # ensure final parent class is an Enum derivative, find any concrete
///         # data type, and check that Enum has no members
///         first_enum = bases[-1]
///         if not isinstance(first_enum, EnumType):
///             raise TypeError("new enumerations should be created as "
///                     "`EnumName([mixin_type, ...] [data_type,] enum_type)`")
///         member_type = mcls._find_data_type_(class_name, bases) or object
///         return member_type, first_enum
///
///     @classmethod
///     def _find_data_repr_(mcls, class_name, bases):
///         for chain in bases:
///             for base in chain.__mro__:
///                 if base is object:
///                     continue
///                 elif isinstance(base, EnumType):
///                     # if we hit an Enum, use it's _value_repr_
///                     return base._value_repr_
///                 elif '__repr__' in base.__dict__:
///                     # this is our data repr
///                     return base.__dict__['__repr__']
///         return None
///
///     @classmethod
///     def _find_data_type_(mcls, class_name, bases):
///         data_types = set()
///         base_chain = set()
///         for chain in bases:
///             candidate = None
///             for base in chain.__mro__:
///                 base_chain.add(base)
///                 if base is object:
///                     continue
///                 elif isinstance(base, EnumType):
///                     if base._member_type_ is not object:
///                         data_types.add(base._member_type_)
///                         break
///                 elif '__new__' in base.__dict__ or '__init__' in base.__dict__:
///                     if isinstance(base, EnumType):
///                         continue
///                     data_types.add(candidate or base)
///                     break
///                 else:
///                     candidate = candidate or base
///         if len(data_types) > 1:
///             raise TypeError('too many data types for %r: %r' % (class_name, data_types))
///         elif data_types:
///             return data_types.pop()
///         else:
///             return None
///
///     @classmethod
///     def _find_new_(mcls, classdict, member_type, first_enum):
///         """
///         Returns the __new__ to be used for creating the enum members.
///
///         classdict: the class dictionary given to __new__
///         member_type: the data type whose __new__ will be used by default
///         first_enum: enumeration to check for an overriding __new__
///         """
///         # now find the correct __new__, checking to see of one was defined
///         # by the user; also check earlier enum classes in case a __new__ was
///         # saved as __new_member__
///         __new__ = classdict.get('__new__', None)
///
///         # should __new__ be saved as __new_member__ later?
///         save_new = first_enum is not None and __new__ is not None
///
///         if __new__ is None:
///             # check all possibles for __new_member__ before falling back to
///             # __new__
///             for method in ('__new_member__', '__new__'):
///                 for possible in (member_type, first_enum):
///                     target = getattr(possible, method, None)
///                     if target not in {
///                             None,
///                             None.__new__,
///                             object.__new__,
///                             Enum.__new__,
///                             }:
///                         __new__ = target
///                         break
///                 if __new__ is not None:
///                     break
///             else:
///                 __new__ = object.__new__
///
///         # if a non-object.__new__ is used then whatever value/tuple was
///         # assigned to the enum member name will be passed to __new__ and to the
///         # new enum member's __init__
///         if first_enum is None or __new__ in (Enum.__new__, object.__new__):
///             use_args = False
///         else:
///             use_args = True
///         return __new__, save_new, use_args
/// ```
final class EnumMeta extends PythonClass {
  factory EnumMeta() => PythonFfiDart.instance.importClass(
        "enum",
        "EnumMeta",
        EnumMeta.from,
        <Object?>[],
      );

  EnumMeta.from(super.pythonClass) : super.from();

  /// ## mro (getter)
  Object? get mro => getAttribute("mro");

  /// ## mro (setter)
  set mro(Object? mro) => setAttribute("mro", mro);
}

/// ## Flag
///
/// ### python docstring
///
/// Support for flags
///
/// ### python source
/// ```py
/// class Flag(Enum, boundary=CONFORM):
///     """
///     Support for flags
///     """
///
///     def __reduce_ex__(self, proto):
///         cls = self.__class__
///         unknown = self._value_ & ~cls._flag_mask_
///         member_value = self._value_ & cls._flag_mask_
///         if unknown and member_value:
///             return _or_, (cls(member_value), unknown)
///         for val in _iter_bits_lsb(member_value):
///             rest = member_value & ~val
///             if rest:
///                 return _or_, (cls(rest), cls._value2member_map_.get(val))
///             else:
///                 break
///         if self._name_ is None:
///             return cls, (self._value_,)
///         else:
///             return getattr, (cls, self._name_)
///
///     _numeric_repr_ = repr
///
///     def _generate_next_value_(name, start, count, last_values):
///         """
///         Generate the next value when not given.
///
///         name: the name of the member
///         start: the initial start value or None
///         count: the number of existing members
///         last_values: the last value assigned or None
///         """
///         if not count:
///             return start if start is not None else 1
///         last_value = max(last_values)
///         try:
///             high_bit = _high_bit(last_value)
///         except Exception:
///             raise TypeError('invalid flag value %r' % last_value) from None
///         return 2 ** (high_bit+1)
///
///     @classmethod
///     def _iter_member_by_value_(cls, value):
///         """
///         Extract all members from the value in definition (i.e. increasing value) order.
///         """
///         for val in _iter_bits_lsb(value & cls._flag_mask_):
///             yield cls._value2member_map_.get(val)
///
///     _iter_member_ = _iter_member_by_value_
///
///     @classmethod
///     def _iter_member_by_def_(cls, value):
///         """
///         Extract all members from the value in definition order.
///         """
///         yield from sorted(
///                 cls._iter_member_by_value_(value),
///                 key=lambda m: m._sort_order_,
///                 )
///
///     @classmethod
///     def _missing_(cls, value):
///         """
///         Create a composite member containing all canonical members present in `value`.
///
///         If non-member values are present, result depends on `_boundary_` setting.
///         """
///         if not isinstance(value, int):
///             raise ValueError(
///                     "%r is not a valid %s" % (value, cls.__qualname__)
///                     )
///         # check boundaries
///         # - value must be in range (e.g. -16 <-> +15, i.e. ~15 <-> 15)
///         # - value must not include any skipped flags (e.g. if bit 2 is not
///         #   defined, then 0d10 is invalid)
///         flag_mask = cls._flag_mask_
///         all_bits = cls._all_bits_
///         neg_value = None
///         if (
///                 not ~all_bits <= value <= all_bits
///                 or value & (all_bits ^ flag_mask)
///             ):
///             if cls._boundary_ is STRICT:
///                 max_bits = max(value.bit_length(), flag_mask.bit_length())
///                 raise ValueError(
///                         "%r invalid value %r\n    given %s\n  allowed %s" % (
///                             cls, value, bin(value, max_bits), bin(flag_mask, max_bits),
///                             ))
///             elif cls._boundary_ is CONFORM:
///                 value = value & flag_mask
///             elif cls._boundary_ is EJECT:
///                 return value
///             elif cls._boundary_ is KEEP:
///                 if value < 0:
///                     value = (
///                             max(all_bits+1, 2**(value.bit_length()))
///                             + value
///                             )
///             else:
///                 raise ValueError(
///                         '%r unknown flag boundary %r' % (cls, cls._boundary_, )
///                         )
///         if value < 0:
///             neg_value = value
///             value = all_bits + 1 + value
///         # get members and unknown
///         unknown = value & ~flag_mask
///         member_value = value & flag_mask
///         if unknown and cls._boundary_ is not KEEP:
///             raise ValueError(
///                     '%s(%r) -->  unknown values %r [%s]'
///                     % (cls.__name__, value, unknown, bin(unknown))
///                     )
///         # normal Flag?
///         if cls._member_type_ is object:
///             # construct a singleton enum pseudo-member
///             pseudo_member = object.__new__(cls)
///         else:
///             pseudo_member = cls._member_type_.__new__(cls, value)
///         if not hasattr(pseudo_member, '_value_'):
///             pseudo_member._value_ = value
///         if member_value:
///             pseudo_member._name_ = '|'.join([
///                 m._name_ for m in cls._iter_member_(member_value)
///                 ])
///             if unknown:
///                 pseudo_member._name_ += '|%s' % cls._numeric_repr_(unknown)
///         else:
///             pseudo_member._name_ = None
///         # use setdefault in case another thread already created a composite
///         # with this value, but only if all members are known
///         # note: zero is a special case -- add it
///         if not unknown:
///             pseudo_member = cls._value2member_map_.setdefault(value, pseudo_member)
///             if neg_value is not None:
///                 cls._value2member_map_[neg_value] = pseudo_member
///         return pseudo_member
///
///     def __contains__(self, other):
///         """
///         Returns True if self has at least the same flags set as other.
///         """
///         if not isinstance(other, self.__class__):
///             raise TypeError(
///                 "unsupported operand type(s) for 'in': %r and %r" % (
///                     type(other).__qualname__, self.__class__.__qualname__))
///         return other._value_ & self._value_ == other._value_
///
///     def __iter__(self):
///         """
///         Returns flags in definition order.
///         """
///         yield from self._iter_member_(self._value_)
///
///     def __len__(self):
///         return self._value_.bit_count()
///
///     def __repr__(self):
///         cls_name = self.__class__.__name__
///         v_repr = self.__class__._value_repr_ or repr
///         if self._name_ is None:
///             return "<%s: %s>" % (cls_name, v_repr(self._value_))
///         else:
///             return "<%s.%s: %s>" % (cls_name, self._name_, v_repr(self._value_))
///
///     def __str__(self):
///         cls_name = self.__class__.__name__
///         if self._name_ is None:
///             return '%s(%r)' % (cls_name, self._value_)
///         else:
///             return "%s.%s" % (cls_name, self._name_)
///
///     def __bool__(self):
///         return bool(self._value_)
///
///     def __or__(self, other):
///         if isinstance(other, self.__class__):
///             other = other._value_
///         elif self._member_type_ is not object and isinstance(other, self._member_type_):
///             other = other
///         else:
///             return NotImplemented
///         value = self._value_
///         return self.__class__(value | other)
///
///     def __and__(self, other):
///         if isinstance(other, self.__class__):
///             other = other._value_
///         elif self._member_type_ is not object and isinstance(other, self._member_type_):
///             other = other
///         else:
///             return NotImplemented
///         value = self._value_
///         return self.__class__(value & other)
///
///     def __xor__(self, other):
///         if isinstance(other, self.__class__):
///             other = other._value_
///         elif self._member_type_ is not object and isinstance(other, self._member_type_):
///             other = other
///         else:
///             return NotImplemented
///         value = self._value_
///         return self.__class__(value ^ other)
///
///     def __invert__(self):
///         if self._inverted_ is None:
///             if self._boundary_ is KEEP:
///                 # use all bits
///                 self._inverted_ = self.__class__(~self._value_)
///             else:
///                 # calculate flags not in this member
///                 self._inverted_ = self.__class__(self._flag_mask_ ^ self._value_)
///             if isinstance(self._inverted_, self.__class__):
///                 self._inverted_._inverted_ = self
///         return self._inverted_
///
///     __rand__ = __and__
///     __ror__ = __or__
///     __rxor__ = __xor__
/// ```
final class Flag extends PythonClass {
  factory Flag() => PythonFfiDart.instance.importClass(
        "enum",
        "Flag",
        Flag.from,
        <Object?>[],
      );

  Flag.from(super.pythonClass) : super.from();

  /// ## name (getter)
  ///
  /// ### python docstring
  ///
  /// The name of the Enum member.
  Object? get name => getAttribute("name");

  /// ## name (setter)
  ///
  /// ### python docstring
  ///
  /// The name of the Enum member.
  set name(Object? name) => setAttribute("name", name);

  /// ## value (getter)
  ///
  /// ### python docstring
  ///
  /// The value of the Enum member.
  Object? get value => getAttribute("value");

  /// ## value (setter)
  ///
  /// ### python docstring
  ///
  /// The value of the Enum member.
  set value(Object? value) => setAttribute("value", value);
}

/// ## FlagBoundary
///
/// ### python docstring
///
/// control how out of range values are handled
/// "strict" -> error is raised
/// "conform" -> extra bits are discarded   [default for Flag]
/// "eject" -> lose flag status
/// "keep" -> keep flag status and all bits [default for IntFlag]
///
/// ### python source
/// ```py
/// class FlagBoundary(StrEnum):
///     """
///     control how out of range values are handled
///     "strict" -> error is raised
///     "conform" -> extra bits are discarded   [default for Flag]
///     "eject" -> lose flag status
///     "keep" -> keep flag status and all bits [default for IntFlag]
///     """
///     STRICT = auto()
///     CONFORM = auto()
///     EJECT = auto()
///     KEEP = auto()
/// ```
final class FlagBoundary extends PythonClass {
  factory FlagBoundary({
    List<Object?> args = const <Object?>[],
    Map<String, Object?> kwds = const <String, Object?>{},
  }) =>
      PythonFfiDart.instance.importClass(
        "enum",
        "FlagBoundary",
        FlagBoundary.from,
        <Object?>[
          ...args,
        ],
        <String, Object?>{
          ...kwds,
        },
      );

  FlagBoundary.from(super.pythonClass) : super.from();

  /// ## capitalize (getter)
  Object? get capitalize => getAttribute("capitalize");

  /// ## capitalize (setter)
  set capitalize(Object? capitalize) => setAttribute("capitalize", capitalize);

  /// ## casefold (getter)
  Object? get casefold => getAttribute("casefold");

  /// ## casefold (setter)
  set casefold(Object? casefold) => setAttribute("casefold", casefold);

  /// ## center (getter)
  Object? get center => getAttribute("center");

  /// ## center (setter)
  set center(Object? center) => setAttribute("center", center);

  /// ## count (getter)
  Object? get count => getAttribute("count");

  /// ## count (setter)
  set count(Object? count) => setAttribute("count", count);

  /// ## encode (getter)
  Object? get encode => getAttribute("encode");

  /// ## encode (setter)
  set encode(Object? encode) => setAttribute("encode", encode);

  /// ## endswith (getter)
  Object? get endswith => getAttribute("endswith");

  /// ## endswith (setter)
  set endswith(Object? endswith) => setAttribute("endswith", endswith);

  /// ## expandtabs (getter)
  Object? get expandtabs => getAttribute("expandtabs");

  /// ## expandtabs (setter)
  set expandtabs(Object? expandtabs) => setAttribute("expandtabs", expandtabs);

  /// ## find (getter)
  Object? get find => getAttribute("find");

  /// ## find (setter)
  set find(Object? find) => setAttribute("find", find);

  /// ## format (getter)
  Object? get format => getAttribute("format");

  /// ## format (setter)
  set format(Object? format) => setAttribute("format", format);

  /// ## format_map (getter)
  Object? get format_map => getAttribute("format_map");

  /// ## format_map (setter)
  set format_map(Object? format_map) => setAttribute("format_map", format_map);

  /// ## index (getter)
  Object? get index => getAttribute("index");

  /// ## index (setter)
  set index(Object? index) => setAttribute("index", index);

  /// ## isalnum (getter)
  Object? get isalnum => getAttribute("isalnum");

  /// ## isalnum (setter)
  set isalnum(Object? isalnum) => setAttribute("isalnum", isalnum);

  /// ## isalpha (getter)
  Object? get isalpha => getAttribute("isalpha");

  /// ## isalpha (setter)
  set isalpha(Object? isalpha) => setAttribute("isalpha", isalpha);

  /// ## isascii (getter)
  Object? get isascii => getAttribute("isascii");

  /// ## isascii (setter)
  set isascii(Object? isascii) => setAttribute("isascii", isascii);

  /// ## isdecimal (getter)
  Object? get isdecimal => getAttribute("isdecimal");

  /// ## isdecimal (setter)
  set isdecimal(Object? isdecimal) => setAttribute("isdecimal", isdecimal);

  /// ## isdigit (getter)
  Object? get isdigit => getAttribute("isdigit");

  /// ## isdigit (setter)
  set isdigit(Object? isdigit) => setAttribute("isdigit", isdigit);

  /// ## isidentifier (getter)
  Object? get isidentifier => getAttribute("isidentifier");

  /// ## isidentifier (setter)
  set isidentifier(Object? isidentifier) =>
      setAttribute("isidentifier", isidentifier);

  /// ## islower (getter)
  Object? get islower => getAttribute("islower");

  /// ## islower (setter)
  set islower(Object? islower) => setAttribute("islower", islower);

  /// ## isnumeric (getter)
  Object? get isnumeric => getAttribute("isnumeric");

  /// ## isnumeric (setter)
  set isnumeric(Object? isnumeric) => setAttribute("isnumeric", isnumeric);

  /// ## isprintable (getter)
  Object? get isprintable => getAttribute("isprintable");

  /// ## isprintable (setter)
  set isprintable(Object? isprintable) =>
      setAttribute("isprintable", isprintable);

  /// ## isspace (getter)
  Object? get isspace => getAttribute("isspace");

  /// ## isspace (setter)
  set isspace(Object? isspace) => setAttribute("isspace", isspace);

  /// ## istitle (getter)
  Object? get istitle => getAttribute("istitle");

  /// ## istitle (setter)
  set istitle(Object? istitle) => setAttribute("istitle", istitle);

  /// ## isupper (getter)
  Object? get isupper => getAttribute("isupper");

  /// ## isupper (setter)
  set isupper(Object? isupper) => setAttribute("isupper", isupper);

  /// ## join (getter)
  Object? get join => getAttribute("join");

  /// ## join (setter)
  set join(Object? join) => setAttribute("join", join);

  /// ## ljust (getter)
  Object? get ljust => getAttribute("ljust");

  /// ## ljust (setter)
  set ljust(Object? ljust) => setAttribute("ljust", ljust);

  /// ## lower (getter)
  Object? get lower => getAttribute("lower");

  /// ## lower (setter)
  set lower(Object? lower) => setAttribute("lower", lower);

  /// ## lstrip (getter)
  Object? get lstrip => getAttribute("lstrip");

  /// ## lstrip (setter)
  set lstrip(Object? lstrip) => setAttribute("lstrip", lstrip);

  /// ## partition (getter)
  Object? get partition => getAttribute("partition");

  /// ## partition (setter)
  set partition(Object? partition) => setAttribute("partition", partition);

  /// ## removeprefix (getter)
  Object? get removeprefix => getAttribute("removeprefix");

  /// ## removeprefix (setter)
  set removeprefix(Object? removeprefix) =>
      setAttribute("removeprefix", removeprefix);

  /// ## removesuffix (getter)
  Object? get removesuffix => getAttribute("removesuffix");

  /// ## removesuffix (setter)
  set removesuffix(Object? removesuffix) =>
      setAttribute("removesuffix", removesuffix);

  /// ## replace (getter)
  Object? get replace => getAttribute("replace");

  /// ## replace (setter)
  set replace(Object? replace) => setAttribute("replace", replace);

  /// ## rfind (getter)
  Object? get rfind => getAttribute("rfind");

  /// ## rfind (setter)
  set rfind(Object? rfind) => setAttribute("rfind", rfind);

  /// ## rindex (getter)
  Object? get rindex => getAttribute("rindex");

  /// ## rindex (setter)
  set rindex(Object? rindex) => setAttribute("rindex", rindex);

  /// ## rjust (getter)
  Object? get rjust => getAttribute("rjust");

  /// ## rjust (setter)
  set rjust(Object? rjust) => setAttribute("rjust", rjust);

  /// ## rpartition (getter)
  Object? get rpartition => getAttribute("rpartition");

  /// ## rpartition (setter)
  set rpartition(Object? rpartition) => setAttribute("rpartition", rpartition);

  /// ## rsplit (getter)
  Object? get rsplit => getAttribute("rsplit");

  /// ## rsplit (setter)
  set rsplit(Object? rsplit) => setAttribute("rsplit", rsplit);

  /// ## rstrip (getter)
  Object? get rstrip => getAttribute("rstrip");

  /// ## rstrip (setter)
  set rstrip(Object? rstrip) => setAttribute("rstrip", rstrip);

  /// ## split (getter)
  Object? get split => getAttribute("split");

  /// ## split (setter)
  set split(Object? split) => setAttribute("split", split);

  /// ## splitlines (getter)
  Object? get splitlines => getAttribute("splitlines");

  /// ## splitlines (setter)
  set splitlines(Object? splitlines) => setAttribute("splitlines", splitlines);

  /// ## startswith (getter)
  Object? get startswith => getAttribute("startswith");

  /// ## startswith (setter)
  set startswith(Object? startswith) => setAttribute("startswith", startswith);

  /// ## strip (getter)
  Object? get strip => getAttribute("strip");

  /// ## strip (setter)
  set strip(Object? strip) => setAttribute("strip", strip);

  /// ## swapcase (getter)
  Object? get swapcase => getAttribute("swapcase");

  /// ## swapcase (setter)
  set swapcase(Object? swapcase) => setAttribute("swapcase", swapcase);

  /// ## title (getter)
  Object? get title => getAttribute("title");

  /// ## title (setter)
  set title(Object? title) => setAttribute("title", title);

  /// ## translate (getter)
  Object? get translate => getAttribute("translate");

  /// ## translate (setter)
  set translate(Object? translate) => setAttribute("translate", translate);

  /// ## upper (getter)
  Object? get upper => getAttribute("upper");

  /// ## upper (setter)
  set upper(Object? upper) => setAttribute("upper", upper);

  /// ## zfill (getter)
  Object? get zfill => getAttribute("zfill");

  /// ## zfill (setter)
  set zfill(Object? zfill) => setAttribute("zfill", zfill);

  /// ## CONFORM (getter)
  Object? get CONFORM => getAttribute("CONFORM");

  /// ## CONFORM (setter)
  set CONFORM(Object? CONFORM) => setAttribute("CONFORM", CONFORM);

  /// ## EJECT (getter)
  Object? get EJECT => getAttribute("EJECT");

  /// ## EJECT (setter)
  set EJECT(Object? EJECT) => setAttribute("EJECT", EJECT);

  /// ## KEEP (getter)
  Object? get KEEP => getAttribute("KEEP");

  /// ## KEEP (setter)
  set KEEP(Object? KEEP) => setAttribute("KEEP", KEEP);

  /// ## STRICT (getter)
  Object? get STRICT => getAttribute("STRICT");

  /// ## STRICT (setter)
  set STRICT(Object? STRICT) => setAttribute("STRICT", STRICT);
}

/// ## IntEnum
///
/// ### python docstring
///
/// Enum where members are also (and must be) ints
///
/// ### python source
/// ```py
/// class IntEnum(int, ReprEnum):
///     """
///     Enum where members are also (and must be) ints
///     """
/// ```
final class IntEnum extends PythonClass {
  factory IntEnum({
    List<Object?> args = const <Object?>[],
    Map<String, Object?> kwds = const <String, Object?>{},
  }) =>
      PythonFfiDart.instance.importClass(
        "enum",
        "IntEnum",
        IntEnum.from,
        <Object?>[
          ...args,
        ],
        <String, Object?>{
          ...kwds,
        },
      );

  IntEnum.from(super.pythonClass) : super.from();

  /// ## denominator (getter)
  ///
  /// ### python docstring
  ///
  /// the denominator of a rational number in lowest terms
  Object? get denominator => getAttribute("denominator");

  /// ## denominator (setter)
  ///
  /// ### python docstring
  ///
  /// the denominator of a rational number in lowest terms
  set denominator(Object? denominator) =>
      setAttribute("denominator", denominator);

  /// ## imag (getter)
  ///
  /// ### python docstring
  ///
  /// the imaginary part of a complex number
  Object? get imag => getAttribute("imag");

  /// ## imag (setter)
  ///
  /// ### python docstring
  ///
  /// the imaginary part of a complex number
  set imag(Object? imag) => setAttribute("imag", imag);

  /// ## numerator (getter)
  ///
  /// ### python docstring
  ///
  /// the numerator of a rational number in lowest terms
  Object? get numerator => getAttribute("numerator");

  /// ## numerator (setter)
  ///
  /// ### python docstring
  ///
  /// the numerator of a rational number in lowest terms
  set numerator(Object? numerator) => setAttribute("numerator", numerator);

  /// ## real (getter)
  ///
  /// ### python docstring
  ///
  /// the real part of a complex number
  Object? get real => getAttribute("real");

  /// ## real (setter)
  ///
  /// ### python docstring
  ///
  /// the real part of a complex number
  set real(Object? real) => setAttribute("real", real);

  /// ## as_integer_ratio (getter)
  Object? get as_integer_ratio => getAttribute("as_integer_ratio");

  /// ## as_integer_ratio (setter)
  set as_integer_ratio(Object? as_integer_ratio) =>
      setAttribute("as_integer_ratio", as_integer_ratio);

  /// ## bit_count (getter)
  Object? get bit_count => getAttribute("bit_count");

  /// ## bit_count (setter)
  set bit_count(Object? bit_count) => setAttribute("bit_count", bit_count);

  /// ## bit_length (getter)
  Object? get bit_length => getAttribute("bit_length");

  /// ## bit_length (setter)
  set bit_length(Object? bit_length) => setAttribute("bit_length", bit_length);

  /// ## conjugate (getter)
  ///
  /// ### python docstring
  ///
  /// Returns self, the complex conjugate of any int.
  Object? get conjugate => getAttribute("conjugate");

  /// ## conjugate (setter)
  ///
  /// ### python docstring
  ///
  /// Returns self, the complex conjugate of any int.
  set conjugate(Object? conjugate) => setAttribute("conjugate", conjugate);

  /// ## to_bytes (getter)
  Object? get to_bytes => getAttribute("to_bytes");

  /// ## to_bytes (setter)
  set to_bytes(Object? to_bytes) => setAttribute("to_bytes", to_bytes);
}

/// ## IntFlag
///
/// ### python docstring
///
/// Support for integer-based Flags
///
/// ### python source
/// ```py
/// class IntFlag(int, ReprEnum, Flag, boundary=KEEP):
///     """
///     Support for integer-based Flags
///     """
/// ```
final class IntFlag extends PythonClass {
  factory IntFlag({
    List<Object?> args = const <Object?>[],
    Map<String, Object?> kwds = const <String, Object?>{},
  }) =>
      PythonFfiDart.instance.importClass(
        "enum",
        "IntFlag",
        IntFlag.from,
        <Object?>[
          ...args,
        ],
        <String, Object?>{
          ...kwds,
        },
      );

  IntFlag.from(super.pythonClass) : super.from();

  /// ## denominator (getter)
  ///
  /// ### python docstring
  ///
  /// the denominator of a rational number in lowest terms
  Object? get denominator => getAttribute("denominator");

  /// ## denominator (setter)
  ///
  /// ### python docstring
  ///
  /// the denominator of a rational number in lowest terms
  set denominator(Object? denominator) =>
      setAttribute("denominator", denominator);

  /// ## imag (getter)
  ///
  /// ### python docstring
  ///
  /// the imaginary part of a complex number
  Object? get imag => getAttribute("imag");

  /// ## imag (setter)
  ///
  /// ### python docstring
  ///
  /// the imaginary part of a complex number
  set imag(Object? imag) => setAttribute("imag", imag);

  /// ## numerator (getter)
  ///
  /// ### python docstring
  ///
  /// the numerator of a rational number in lowest terms
  Object? get numerator => getAttribute("numerator");

  /// ## numerator (setter)
  ///
  /// ### python docstring
  ///
  /// the numerator of a rational number in lowest terms
  set numerator(Object? numerator) => setAttribute("numerator", numerator);

  /// ## real (getter)
  ///
  /// ### python docstring
  ///
  /// the real part of a complex number
  Object? get real => getAttribute("real");

  /// ## real (setter)
  ///
  /// ### python docstring
  ///
  /// the real part of a complex number
  set real(Object? real) => setAttribute("real", real);

  /// ## as_integer_ratio (getter)
  Object? get as_integer_ratio => getAttribute("as_integer_ratio");

  /// ## as_integer_ratio (setter)
  set as_integer_ratio(Object? as_integer_ratio) =>
      setAttribute("as_integer_ratio", as_integer_ratio);

  /// ## bit_count (getter)
  Object? get bit_count => getAttribute("bit_count");

  /// ## bit_count (setter)
  set bit_count(Object? bit_count) => setAttribute("bit_count", bit_count);

  /// ## bit_length (getter)
  Object? get bit_length => getAttribute("bit_length");

  /// ## bit_length (setter)
  set bit_length(Object? bit_length) => setAttribute("bit_length", bit_length);

  /// ## conjugate (getter)
  ///
  /// ### python docstring
  ///
  /// Returns self, the complex conjugate of any int.
  Object? get conjugate => getAttribute("conjugate");

  /// ## conjugate (setter)
  ///
  /// ### python docstring
  ///
  /// Returns self, the complex conjugate of any int.
  set conjugate(Object? conjugate) => setAttribute("conjugate", conjugate);

  /// ## to_bytes (getter)
  Object? get to_bytes => getAttribute("to_bytes");

  /// ## to_bytes (setter)
  set to_bytes(Object? to_bytes) => setAttribute("to_bytes", to_bytes);
}

/// ## MappingProxyType
final class MappingProxyType extends PythonClass {
  factory MappingProxyType() => PythonFfiDart.instance.importClass(
        "builtins",
        "MappingProxyType",
        MappingProxyType.from,
        <Object?>[],
      );

  MappingProxyType.from(super.pythonClass) : super.from();

  /// ## copy (getter)
  Object? get copy => getAttribute("copy");

  /// ## copy (setter)
  set copy(Object? copy) => setAttribute("copy", copy);

  /// ## get (getter)
  Object? get $get => getAttribute("get");

  /// ## get (setter)
  set $get(Object? $get) => setAttribute("get", $get);

  /// ## items (getter)
  Object? get items => getAttribute("items");

  /// ## items (setter)
  set items(Object? items) => setAttribute("items", items);

  /// ## keys (getter)
  Object? get keys => getAttribute("keys");

  /// ## keys (setter)
  set keys(Object? keys) => setAttribute("keys", keys);

  /// ## values (getter)
  Object? get values => getAttribute("values");

  /// ## values (setter)
  set values(Object? values) => setAttribute("values", values);
}

/// ## ReprEnum
///
/// ### python docstring
///
/// Only changes the repr(), leaving str() and format() to the mixed-in type.
///
/// ### python source
/// ```py
/// class ReprEnum(Enum):
///     """
///     Only changes the repr(), leaving str() and format() to the mixed-in type.
///     """
/// ```
final class ReprEnum extends PythonClass {
  factory ReprEnum() => PythonFfiDart.instance.importClass(
        "enum",
        "ReprEnum",
        ReprEnum.from,
        <Object?>[],
      );

  ReprEnum.from(super.pythonClass) : super.from();

  /// ## name (getter)
  ///
  /// ### python docstring
  ///
  /// The name of the Enum member.
  Object? get name => getAttribute("name");

  /// ## name (setter)
  ///
  /// ### python docstring
  ///
  /// The name of the Enum member.
  set name(Object? name) => setAttribute("name", name);

  /// ## value (getter)
  ///
  /// ### python docstring
  ///
  /// The value of the Enum member.
  Object? get value => getAttribute("value");

  /// ## value (setter)
  ///
  /// ### python docstring
  ///
  /// The value of the Enum member.
  set value(Object? value) => setAttribute("value", value);
}

/// ## StrEnum
///
/// ### python docstring
///
/// Enum where members are also (and must be) strings
///
/// ### python source
/// ```py
/// class StrEnum(str, ReprEnum):
///     """
///     Enum where members are also (and must be) strings
///     """
///
///     def __new__(cls, *values):
///         "values must already be of type `str`"
///         if len(values) > 3:
///             raise TypeError('too many arguments for str(): %r' % (values, ))
///         if len(values) == 1:
///             # it must be a string
///             if not isinstance(values[0], str):
///                 raise TypeError('%r is not a string' % (values[0], ))
///         if len(values) >= 2:
///             # check that encoding argument is a string
///             if not isinstance(values[1], str):
///                 raise TypeError('encoding must be a string, not %r' % (values[1], ))
///         if len(values) == 3:
///             # check that errors argument is a string
///             if not isinstance(values[2], str):
///                 raise TypeError('errors must be a string, not %r' % (values[2]))
///         value = str(*values)
///         member = str.__new__(cls, value)
///         member._value_ = value
///         return member
///
///     def _generate_next_value_(name, start, count, last_values):
///         """
///         Return the lower-cased version of the member name.
///         """
///         return name.lower()
/// ```
final class StrEnum extends PythonClass {
  factory StrEnum({
    List<Object?> args = const <Object?>[],
    Map<String, Object?> kwds = const <String, Object?>{},
  }) =>
      PythonFfiDart.instance.importClass(
        "enum",
        "StrEnum",
        StrEnum.from,
        <Object?>[
          ...args,
        ],
        <String, Object?>{
          ...kwds,
        },
      );

  StrEnum.from(super.pythonClass) : super.from();

  /// ## capitalize (getter)
  Object? get capitalize => getAttribute("capitalize");

  /// ## capitalize (setter)
  set capitalize(Object? capitalize) => setAttribute("capitalize", capitalize);

  /// ## casefold (getter)
  Object? get casefold => getAttribute("casefold");

  /// ## casefold (setter)
  set casefold(Object? casefold) => setAttribute("casefold", casefold);

  /// ## center (getter)
  Object? get center => getAttribute("center");

  /// ## center (setter)
  set center(Object? center) => setAttribute("center", center);

  /// ## count (getter)
  Object? get count => getAttribute("count");

  /// ## count (setter)
  set count(Object? count) => setAttribute("count", count);

  /// ## encode (getter)
  Object? get encode => getAttribute("encode");

  /// ## encode (setter)
  set encode(Object? encode) => setAttribute("encode", encode);

  /// ## endswith (getter)
  Object? get endswith => getAttribute("endswith");

  /// ## endswith (setter)
  set endswith(Object? endswith) => setAttribute("endswith", endswith);

  /// ## expandtabs (getter)
  Object? get expandtabs => getAttribute("expandtabs");

  /// ## expandtabs (setter)
  set expandtabs(Object? expandtabs) => setAttribute("expandtabs", expandtabs);

  /// ## find (getter)
  Object? get find => getAttribute("find");

  /// ## find (setter)
  set find(Object? find) => setAttribute("find", find);

  /// ## format (getter)
  Object? get format => getAttribute("format");

  /// ## format (setter)
  set format(Object? format) => setAttribute("format", format);

  /// ## format_map (getter)
  Object? get format_map => getAttribute("format_map");

  /// ## format_map (setter)
  set format_map(Object? format_map) => setAttribute("format_map", format_map);

  /// ## index (getter)
  Object? get index => getAttribute("index");

  /// ## index (setter)
  set index(Object? index) => setAttribute("index", index);

  /// ## isalnum (getter)
  Object? get isalnum => getAttribute("isalnum");

  /// ## isalnum (setter)
  set isalnum(Object? isalnum) => setAttribute("isalnum", isalnum);

  /// ## isalpha (getter)
  Object? get isalpha => getAttribute("isalpha");

  /// ## isalpha (setter)
  set isalpha(Object? isalpha) => setAttribute("isalpha", isalpha);

  /// ## isascii (getter)
  Object? get isascii => getAttribute("isascii");

  /// ## isascii (setter)
  set isascii(Object? isascii) => setAttribute("isascii", isascii);

  /// ## isdecimal (getter)
  Object? get isdecimal => getAttribute("isdecimal");

  /// ## isdecimal (setter)
  set isdecimal(Object? isdecimal) => setAttribute("isdecimal", isdecimal);

  /// ## isdigit (getter)
  Object? get isdigit => getAttribute("isdigit");

  /// ## isdigit (setter)
  set isdigit(Object? isdigit) => setAttribute("isdigit", isdigit);

  /// ## isidentifier (getter)
  Object? get isidentifier => getAttribute("isidentifier");

  /// ## isidentifier (setter)
  set isidentifier(Object? isidentifier) =>
      setAttribute("isidentifier", isidentifier);

  /// ## islower (getter)
  Object? get islower => getAttribute("islower");

  /// ## islower (setter)
  set islower(Object? islower) => setAttribute("islower", islower);

  /// ## isnumeric (getter)
  Object? get isnumeric => getAttribute("isnumeric");

  /// ## isnumeric (setter)
  set isnumeric(Object? isnumeric) => setAttribute("isnumeric", isnumeric);

  /// ## isprintable (getter)
  Object? get isprintable => getAttribute("isprintable");

  /// ## isprintable (setter)
  set isprintable(Object? isprintable) =>
      setAttribute("isprintable", isprintable);

  /// ## isspace (getter)
  Object? get isspace => getAttribute("isspace");

  /// ## isspace (setter)
  set isspace(Object? isspace) => setAttribute("isspace", isspace);

  /// ## istitle (getter)
  Object? get istitle => getAttribute("istitle");

  /// ## istitle (setter)
  set istitle(Object? istitle) => setAttribute("istitle", istitle);

  /// ## isupper (getter)
  Object? get isupper => getAttribute("isupper");

  /// ## isupper (setter)
  set isupper(Object? isupper) => setAttribute("isupper", isupper);

  /// ## join (getter)
  Object? get join => getAttribute("join");

  /// ## join (setter)
  set join(Object? join) => setAttribute("join", join);

  /// ## ljust (getter)
  Object? get ljust => getAttribute("ljust");

  /// ## ljust (setter)
  set ljust(Object? ljust) => setAttribute("ljust", ljust);

  /// ## lower (getter)
  Object? get lower => getAttribute("lower");

  /// ## lower (setter)
  set lower(Object? lower) => setAttribute("lower", lower);

  /// ## lstrip (getter)
  Object? get lstrip => getAttribute("lstrip");

  /// ## lstrip (setter)
  set lstrip(Object? lstrip) => setAttribute("lstrip", lstrip);

  /// ## partition (getter)
  Object? get partition => getAttribute("partition");

  /// ## partition (setter)
  set partition(Object? partition) => setAttribute("partition", partition);

  /// ## removeprefix (getter)
  Object? get removeprefix => getAttribute("removeprefix");

  /// ## removeprefix (setter)
  set removeprefix(Object? removeprefix) =>
      setAttribute("removeprefix", removeprefix);

  /// ## removesuffix (getter)
  Object? get removesuffix => getAttribute("removesuffix");

  /// ## removesuffix (setter)
  set removesuffix(Object? removesuffix) =>
      setAttribute("removesuffix", removesuffix);

  /// ## replace (getter)
  Object? get replace => getAttribute("replace");

  /// ## replace (setter)
  set replace(Object? replace) => setAttribute("replace", replace);

  /// ## rfind (getter)
  Object? get rfind => getAttribute("rfind");

  /// ## rfind (setter)
  set rfind(Object? rfind) => setAttribute("rfind", rfind);

  /// ## rindex (getter)
  Object? get rindex => getAttribute("rindex");

  /// ## rindex (setter)
  set rindex(Object? rindex) => setAttribute("rindex", rindex);

  /// ## rjust (getter)
  Object? get rjust => getAttribute("rjust");

  /// ## rjust (setter)
  set rjust(Object? rjust) => setAttribute("rjust", rjust);

  /// ## rpartition (getter)
  Object? get rpartition => getAttribute("rpartition");

  /// ## rpartition (setter)
  set rpartition(Object? rpartition) => setAttribute("rpartition", rpartition);

  /// ## rsplit (getter)
  Object? get rsplit => getAttribute("rsplit");

  /// ## rsplit (setter)
  set rsplit(Object? rsplit) => setAttribute("rsplit", rsplit);

  /// ## rstrip (getter)
  Object? get rstrip => getAttribute("rstrip");

  /// ## rstrip (setter)
  set rstrip(Object? rstrip) => setAttribute("rstrip", rstrip);

  /// ## split (getter)
  Object? get split => getAttribute("split");

  /// ## split (setter)
  set split(Object? split) => setAttribute("split", split);

  /// ## splitlines (getter)
  Object? get splitlines => getAttribute("splitlines");

  /// ## splitlines (setter)
  set splitlines(Object? splitlines) => setAttribute("splitlines", splitlines);

  /// ## startswith (getter)
  Object? get startswith => getAttribute("startswith");

  /// ## startswith (setter)
  set startswith(Object? startswith) => setAttribute("startswith", startswith);

  /// ## strip (getter)
  Object? get strip => getAttribute("strip");

  /// ## strip (setter)
  set strip(Object? strip) => setAttribute("strip", strip);

  /// ## swapcase (getter)
  Object? get swapcase => getAttribute("swapcase");

  /// ## swapcase (setter)
  set swapcase(Object? swapcase) => setAttribute("swapcase", swapcase);

  /// ## title (getter)
  Object? get title => getAttribute("title");

  /// ## title (setter)
  set title(Object? title) => setAttribute("title", title);

  /// ## translate (getter)
  Object? get translate => getAttribute("translate");

  /// ## translate (setter)
  set translate(Object? translate) => setAttribute("translate", translate);

  /// ## upper (getter)
  Object? get upper => getAttribute("upper");

  /// ## upper (setter)
  set upper(Object? upper) => setAttribute("upper", upper);

  /// ## zfill (getter)
  Object? get zfill => getAttribute("zfill");

  /// ## zfill (setter)
  set zfill(Object? zfill) => setAttribute("zfill", zfill);
}

/// ## auto
///
/// ### python docstring
///
/// Instances are replaced with an appropriate value in Enum class suites.
///
/// ### python source
/// ```py
/// class auto:
///     """
///     Instances are replaced with an appropriate value in Enum class suites.
///     """
///     def __init__(self, value=_auto_null):
///         self.value = value
///
///     def __repr__(self):
///         return "auto(%r)" % self.value
/// ```
final class auto extends PythonClass {
  factory auto({
    Object? value,
  }) =>
      PythonFfiDart.instance.importClass(
        "enum",
        "auto",
        auto.from,
        <Object?>[
          value,
        ],
        <String, Object?>{},
      );

  auto.from(super.pythonClass) : super.from();

  /// ## value (getter)
  Object? get value => getAttribute("value");

  /// ## value (setter)
  set value(Object? value) => setAttribute("value", value);
}

/// ## member
///
/// ### python docstring
///
/// Forces item to become an Enum member during class creation.
///
/// ### python source
/// ```py
/// class member(object):
///     """
///     Forces item to become an Enum member during class creation.
///     """
///     def __init__(self, value):
///         self.value = value
/// ```
final class member extends PythonClass {
  factory member({
    required Object? value,
  }) =>
      PythonFfiDart.instance.importClass(
        "enum",
        "member",
        member.from,
        <Object?>[
          value,
        ],
        <String, Object?>{},
      );

  member.from(super.pythonClass) : super.from();

  /// ## value (getter)
  Object? get value => getAttribute("value");

  /// ## value (setter)
  set value(Object? value) => setAttribute("value", value);
}

/// ## nonmember
///
/// ### python docstring
///
/// Protects item from becoming an Enum member during class creation.
///
/// ### python source
/// ```py
/// class nonmember(object):
///     """
///     Protects item from becoming an Enum member during class creation.
///     """
///     def __init__(self, value):
///         self.value = value
/// ```
final class nonmember extends PythonClass {
  factory nonmember({
    required Object? value,
  }) =>
      PythonFfiDart.instance.importClass(
        "enum",
        "nonmember",
        nonmember.from,
        <Object?>[
          value,
        ],
        <String, Object?>{},
      );

  nonmember.from(super.pythonClass) : super.from();

  /// ## value (getter)
  Object? get value => getAttribute("value");

  /// ## value (setter)
  set value(Object? value) => setAttribute("value", value);
}

/// ## verify
///
/// ### python docstring
///
/// Check an enumeration for various constraints. (see EnumCheck)
///
/// ### python source
/// ```py
/// class verify:
///     """
///     Check an enumeration for various constraints. (see EnumCheck)
///     """
///     def __init__(self, *checks):
///         self.checks = checks
///     def __call__(self, enumeration):
///         checks = self.checks
///         cls_name = enumeration.__name__
///         if Flag is not None and issubclass(enumeration, Flag):
///             enum_type = 'flag'
///         elif issubclass(enumeration, Enum):
///             enum_type = 'enum'
///         else:
///             raise TypeError("the 'verify' decorator only works with Enum and Flag")
///         for check in checks:
///             if check is UNIQUE:
///                 # check for duplicate names
///                 duplicates = []
///                 for name, member in enumeration.__members__.items():
///                     if name != member.name:
///                         duplicates.append((name, member.name))
///                 if duplicates:
///                     alias_details = ', '.join(
///                             ["%s -> %s" % (alias, name) for (alias, name) in duplicates])
///                     raise ValueError('aliases found in %r: %s' %
///                             (enumeration, alias_details))
///             elif check is CONTINUOUS:
///                 values = set(e.value for e in enumeration)
///                 if len(values) < 2:
///                     continue
///                 low, high = min(values), max(values)
///                 missing = []
///                 if enum_type == 'flag':
///                     # check for powers of two
///                     for i in range(_high_bit(low)+1, _high_bit(high)):
///                         if 2**i not in values:
///                             missing.append(2**i)
///                 elif enum_type == 'enum':
///                     # check for powers of one
///                     for i in range(low+1, high):
///                         if i not in values:
///                             missing.append(i)
///                 else:
///                     raise Exception('verify: unknown type %r' % enum_type)
///                 if missing:
///                     raise ValueError(('invalid %s %r: missing values %s' % (
///                             enum_type, cls_name, ', '.join((str(m) for m in missing)))
///                             )[:256])
///                             # limit max length to protect against DOS attacks
///             elif check is NAMED_FLAGS:
///                 # examine each alias and check for unnamed flags
///                 member_names = enumeration._member_names_
///                 member_values = [m.value for m in enumeration]
///                 missing_names = []
///                 missing_value = 0
///                 for name, alias in enumeration._member_map_.items():
///                     if name in member_names:
///                         # not an alias
///                         continue
///                     if alias.value < 0:
///                         # negative numbers are not checked
///                         continue
///                     values = list(_iter_bits_lsb(alias.value))
///                     missed = [v for v in values if v not in member_values]
///                     if missed:
///                         missing_names.append(name)
///                         missing_value |= reduce(_or_, missed)
///                 if missing_names:
///                     if len(missing_names) == 1:
///                         alias = 'alias %s is missing' % missing_names[0]
///                     else:
///                         alias = 'aliases %s and %s are missing' % (
///                                 ', '.join(missing_names[:-1]), missing_names[-1]
///                                 )
///                     if _is_single_bit(missing_value):
///                         value = 'value 0x%x' % missing_value
///                     else:
///                         value = 'combined values of 0x%x' % missing_value
///                     raise ValueError(
///                             'invalid Flag %r: %s %s [use enum.show_flag_values(value) for details]'
///                             % (cls_name, alias, value)
///                             )
///         return enumeration
/// ```
final class $verify extends PythonClass {
  factory $verify({
    List<Object?> checks = const <Object?>[],
  }) =>
      PythonFfiDart.instance.importClass(
        "enum",
        "verify",
        $verify.from,
        <Object?>[
          ...checks,
        ],
        <String, Object?>{},
      );

  $verify.from(super.pythonClass) : super.from();

  /// ## checks (getter)
  Object? get checks => getAttribute("checks");

  /// ## checks (setter)
  set checks(Object? checks) => setAttribute("checks", checks);
}

/// ## RLock
final class RLock extends PythonClass {
  factory RLock() => PythonFfiDart.instance.importClass(
        "_thread",
        "RLock",
        RLock.from,
        <Object?>[],
      );

  RLock.from(super.pythonClass) : super.from();

  /// ## acquire (getter)
  Object? get acquire => getAttribute("acquire");

  /// ## acquire (setter)
  set acquire(Object? acquire) => setAttribute("acquire", acquire);

  /// ## release (getter)
  Object? get release => getAttribute("release");

  /// ## release (setter)
  set release(Object? release) => setAttribute("release", release);
}

/// ## cached_property
///
/// ### python source
/// ```py
/// class cached_property:
///     def __init__(self, func):
///         self.func = func
///         self.attrname = None
///         self.__doc__ = func.__doc__
///         self.lock = RLock()
///
///     def __set_name__(self, owner, name):
///         if self.attrname is None:
///             self.attrname = name
///         elif name != self.attrname:
///             raise TypeError(
///                 "Cannot assign the same cached_property to two different names "
///                 f"({self.attrname!r} and {name!r})."
///             )
///
///     def __get__(self, instance, owner=None):
///         if instance is None:
///             return self
///         if self.attrname is None:
///             raise TypeError(
///                 "Cannot use cached_property instance without calling __set_name__ on it.")
///         try:
///             cache = instance.__dict__
///         except AttributeError:  # not all objects have __dict__ (e.g. class defines slots)
///             msg = (
///                 f"No '__dict__' attribute on {type(instance).__name__!r} "
///                 f"instance to cache {self.attrname!r} property."
///             )
///             raise TypeError(msg) from None
///         val = cache.get(self.attrname, _NOT_FOUND)
///         if val is _NOT_FOUND:
///             with self.lock:
///                 # check if another thread filled cache while we awaited lock
///                 val = cache.get(self.attrname, _NOT_FOUND)
///                 if val is _NOT_FOUND:
///                     val = self.func(instance)
///                     try:
///                         cache[self.attrname] = val
///                     except TypeError:
///                         msg = (
///                             f"The '__dict__' attribute on {type(instance).__name__!r} instance "
///                             f"does not support item assignment for caching {self.attrname!r} property."
///                         )
///                         raise TypeError(msg) from None
///         return val
///
///     __class_getitem__ = classmethod(GenericAlias)
/// ```
final class cached_property extends PythonClass {
  factory cached_property({
    required Object? func,
  }) =>
      PythonFfiDart.instance.importClass(
        "functools",
        "cached_property",
        cached_property.from,
        <Object?>[
          func,
        ],
        <String, Object?>{},
      );

  cached_property.from(super.pythonClass) : super.from();

  /// ## func (getter)
  Object? get func => getAttribute("func");

  /// ## func (setter)
  set func(Object? func) => setAttribute("func", func);

  /// ## attrname (getter)
  Object? get attrname => getAttribute("attrname");

  /// ## attrname (setter)
  set attrname(Object? attrname) => setAttribute("attrname", attrname);

  /// ## lock (getter)
  Object? get lock => getAttribute("lock");

  /// ## lock (setter)
  set lock(Object? lock) => setAttribute("lock", lock);
}

/// ## partialmethod
///
/// ### python docstring
///
/// Method descriptor with partial application of the given arguments
/// and keywords.
///
/// Supports wrapping existing descriptors and handles non-descriptor
/// callables as instance methods.
///
/// ### python source
/// ```py
/// class partialmethod(object):
///     """Method descriptor with partial application of the given arguments
///     and keywords.
///
///     Supports wrapping existing descriptors and handles non-descriptor
///     callables as instance methods.
///     """
///
///     def __init__(self, func, /, *args, **keywords):
///         if not callable(func) and not hasattr(func, "__get__"):
///             raise TypeError("{!r} is not callable or a descriptor"
///                                  .format(func))
///
///         # func could be a descriptor like classmethod which isn't callable,
///         # so we can't inherit from partial (it verifies func is callable)
///         if isinstance(func, partialmethod):
///             # flattening is mandatory in order to place cls/self before all
///             # other arguments
///             # it's also more efficient since only one function will be called
///             self.func = func.func
///             self.args = func.args + args
///             self.keywords = {**func.keywords, **keywords}
///         else:
///             self.func = func
///             self.args = args
///             self.keywords = keywords
///
///     def __repr__(self):
///         args = ", ".join(map(repr, self.args))
///         keywords = ", ".join("{}={!r}".format(k, v)
///                                  for k, v in self.keywords.items())
///         format_string = "{module}.{cls}({func}, {args}, {keywords})"
///         return format_string.format(module=self.__class__.__module__,
///                                     cls=self.__class__.__qualname__,
///                                     func=self.func,
///                                     args=args,
///                                     keywords=keywords)
///
///     def _make_unbound_method(self):
///         def _method(cls_or_self, /, *args, **keywords):
///             keywords = {**self.keywords, **keywords}
///             return self.func(cls_or_self, *self.args, *args, **keywords)
///         _method.__isabstractmethod__ = self.__isabstractmethod__
///         _method._partialmethod = self
///         return _method
///
///     def __get__(self, obj, cls=None):
///         get = getattr(self.func, "__get__", None)
///         result = None
///         if get is not None:
///             new_func = get(obj, cls)
///             if new_func is not self.func:
///                 # Assume __get__ returning something new indicates the
///                 # creation of an appropriate callable
///                 result = partial(new_func, *self.args, **self.keywords)
///                 try:
///                     result.__self__ = new_func.__self__
///                 except AttributeError:
///                     pass
///         if result is None:
///             # If the underlying descriptor didn't do anything, treat this
///             # like an instance method
///             result = self._make_unbound_method().__get__(obj, cls)
///         return result
///
///     @property
///     def __isabstractmethod__(self):
///         return getattr(self.func, "__isabstractmethod__", False)
///
///     __class_getitem__ = classmethod(GenericAlias)
/// ```
final class partialmethod extends PythonClass {
  factory partialmethod(
    Object? func, {
    List<Object?> args = const <Object?>[],
    Map<String, Object?> keywords = const <String, Object?>{},
  }) =>
      PythonFfiDart.instance.importClass(
        "functools",
        "partialmethod",
        partialmethod.from,
        <Object?>[
          func,
          ...args,
        ],
        <String, Object?>{
          ...keywords,
        },
      );

  partialmethod.from(super.pythonClass) : super.from();

  /// ## func (getter)
  Object? get func => getAttribute("func");

  /// ## func (setter)
  set func(Object? func) => setAttribute("func", func);

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## keywords (getter)
  Object? get keywords => getAttribute("keywords");

  /// ## keywords (setter)
  set keywords(Object? keywords) => setAttribute("keywords", keywords);
}

/// ## singledispatchmethod
///
/// ### python docstring
///
/// Single-dispatch generic method descriptor.
///
/// Supports wrapping existing descriptors and handles non-descriptor
/// callables as instance methods.
///
/// ### python source
/// ```py
/// class singledispatchmethod:
///     """Single-dispatch generic method descriptor.
///
///     Supports wrapping existing descriptors and handles non-descriptor
///     callables as instance methods.
///     """
///
///     def __init__(self, func):
///         if not callable(func) and not hasattr(func, "__get__"):
///             raise TypeError(f"{func!r} is not callable or a descriptor")
///
///         self.dispatcher = singledispatch(func)
///         self.func = func
///
///     def register(self, cls, method=None):
///         """generic_method.register(cls, func) -> func
///
///         Registers a new implementation for the given *cls* on a *generic_method*.
///         """
///         return self.dispatcher.register(cls, func=method)
///
///     def __get__(self, obj, cls=None):
///         def _method(*args, **kwargs):
///             method = self.dispatcher.dispatch(args[0].__class__)
///             return method.__get__(obj, cls)(*args, **kwargs)
///
///         _method.__isabstractmethod__ = self.__isabstractmethod__
///         _method.register = self.register
///         update_wrapper(_method, self.func)
///         return _method
///
///     @property
///     def __isabstractmethod__(self):
///         return getattr(self.func, '__isabstractmethod__', False)
/// ```
final class singledispatchmethod extends PythonClass {
  factory singledispatchmethod({
    required Object? func,
  }) =>
      PythonFfiDart.instance.importClass(
        "functools",
        "singledispatchmethod",
        singledispatchmethod.from,
        <Object?>[
          func,
        ],
        <String, Object?>{},
      );

  singledispatchmethod.from(super.pythonClass) : super.from();

  /// ## register
  ///
  /// ### python docstring
  ///
  /// generic_method.register(cls, func) -> func
  ///
  /// Registers a new implementation for the given *cls* on a *generic_method*.
  ///
  /// ### python source
  /// ```py
  /// def register(self, cls, method=None):
  ///         """generic_method.register(cls, func) -> func
  ///
  ///         Registers a new implementation for the given *cls* on a *generic_method*.
  ///         """
  ///         return self.dispatcher.register(cls, func=method)
  /// ```
  Object? register({
    required Object? cls,
    Object? method,
  }) =>
      getFunction("register").call(
        <Object?>[
          cls,
          method,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## dispatcher (getter)
  Object? get dispatcher => getAttribute("dispatcher");

  /// ## dispatcher (setter)
  set dispatcher(Object? dispatcher) => setAttribute("dispatcher", dispatcher);

  /// ## func (getter)
  Object? get func => getAttribute("func");

  /// ## func (setter)
  set func(Object? func) => setAttribute("func", func);
}

/// ## SpooledTemporaryFile
///
/// ### python docstring
///
/// Temporary file wrapper, specialized to switch from BytesIO
/// or StringIO to a real file when it exceeds a certain size or
/// when a fileno is needed.
///
/// ### python source
/// ```py
/// class SpooledTemporaryFile(_io.IOBase):
///     """Temporary file wrapper, specialized to switch from BytesIO
///     or StringIO to a real file when it exceeds a certain size or
///     when a fileno is needed.
///     """
///     _rolled = False
///
///     def __init__(self, max_size=0, mode='w+b', buffering=-1,
///                  encoding=None, newline=None,
///                  suffix=None, prefix=None, dir=None, *, errors=None):
///         if 'b' in mode:
///             self._file = _io.BytesIO()
///         else:
///             encoding = _io.text_encoding(encoding)
///             self._file = _io.TextIOWrapper(_io.BytesIO(),
///                             encoding=encoding, errors=errors,
///                             newline=newline)
///         self._max_size = max_size
///         self._rolled = False
///         self._TemporaryFileArgs = {'mode': mode, 'buffering': buffering,
///                                    'suffix': suffix, 'prefix': prefix,
///                                    'encoding': encoding, 'newline': newline,
///                                    'dir': dir, 'errors': errors}
///
///     __class_getitem__ = classmethod(_types.GenericAlias)
///
///     def _check(self, file):
///         if self._rolled: return
///         max_size = self._max_size
///         if max_size and file.tell() > max_size:
///             self.rollover()
///
///     def rollover(self):
///         if self._rolled: return
///         file = self._file
///         newfile = self._file = TemporaryFile(**self._TemporaryFileArgs)
///         del self._TemporaryFileArgs
///
///         pos = file.tell()
///         if hasattr(newfile, 'buffer'):
///             newfile.buffer.write(file.detach().getvalue())
///         else:
///             newfile.write(file.getvalue())
///         newfile.seek(pos, 0)
///
///         self._rolled = True
///
///     # The method caching trick from NamedTemporaryFile
///     # won't work here, because _file may change from a
///     # BytesIO/StringIO instance to a real file. So we list
///     # all the methods directly.
///
///     # Context management protocol
///     def __enter__(self):
///         if self._file.closed:
///             raise ValueError("Cannot enter context with closed file")
///         return self
///
///     def __exit__(self, exc, value, tb):
///         self._file.close()
///
///     # file protocol
///     def __iter__(self):
///         return self._file.__iter__()
///
///     def __del__(self):
///         if not self.closed:
///             _warnings.warn(
///                 "Unclosed file {!r}".format(self),
///                 ResourceWarning,
///                 stacklevel=2,
///                 source=self
///             )
///             self.close()
///
///     def close(self):
///         self._file.close()
///
///     @property
///     def closed(self):
///         return self._file.closed
///
///     @property
///     def encoding(self):
///         return self._file.encoding
///
///     @property
///     def errors(self):
///         return self._file.errors
///
///     def fileno(self):
///         self.rollover()
///         return self._file.fileno()
///
///     def flush(self):
///         self._file.flush()
///
///     def isatty(self):
///         return self._file.isatty()
///
///     @property
///     def mode(self):
///         try:
///             return self._file.mode
///         except AttributeError:
///             return self._TemporaryFileArgs['mode']
///
///     @property
///     def name(self):
///         try:
///             return self._file.name
///         except AttributeError:
///             return None
///
///     @property
///     def newlines(self):
///         return self._file.newlines
///
///     def readable(self):
///         return self._file.readable()
///
///     def read(self, *args):
///         return self._file.read(*args)
///
///     def read1(self, *args):
///         return self._file.read1(*args)
///
///     def readinto(self, b):
///         return self._file.readinto(b)
///
///     def readinto1(self, b):
///         return self._file.readinto1(b)
///
///     def readline(self, *args):
///         return self._file.readline(*args)
///
///     def readlines(self, *args):
///         return self._file.readlines(*args)
///
///     def seekable(self):
///         return self._file.seekable()
///
///     def seek(self, *args):
///         return self._file.seek(*args)
///
///     def tell(self):
///         return self._file.tell()
///
///     def truncate(self, size=None):
///         if size is None:
///             return self._file.truncate()
///         else:
///             if size > self._max_size:
///                 self.rollover()
///             return self._file.truncate(size)
///
///     def writable(self):
///         return self._file.writable()
///
///     def write(self, s):
///         file = self._file
///         rv = file.write(s)
///         self._check(file)
///         return rv
///
///     def writelines(self, iterable):
///         file = self._file
///         rv = file.writelines(iterable)
///         self._check(file)
///         return rv
///
///     def detach(self):
///         return self._file.detach()
/// ```
final class SpooledTemporaryFile extends PythonClass {
  factory SpooledTemporaryFile({
    Object? max_size = 0,
    Object? mode = "w+b",
    Object? buffering = -1,
    Object? encoding,
    Object? newline,
    Object? suffix,
    Object? prefix,
    Object? dir,
    Object? errors,
  }) =>
      PythonFfiDart.instance.importClass(
        "tempfile",
        "SpooledTemporaryFile",
        SpooledTemporaryFile.from,
        <Object?>[
          max_size,
          mode,
          buffering,
          encoding,
          newline,
          suffix,
          prefix,
          dir,
        ],
        <String, Object?>{
          "errors": errors,
        },
      );

  SpooledTemporaryFile.from(super.pythonClass) : super.from();

  /// ## close
  ///
  /// ### python source
  /// ```py
  /// def close(self):
  ///         self._file.close()
  /// ```
  Object? close() => getFunction("close").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## detach
  ///
  /// ### python source
  /// ```py
  /// def detach(self):
  ///         return self._file.detach()
  /// ```
  Object? detach() => getFunction("detach").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## fileno
  ///
  /// ### python source
  /// ```py
  /// def fileno(self):
  ///         self.rollover()
  ///         return self._file.fileno()
  /// ```
  Object? fileno() => getFunction("fileno").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## flush
  ///
  /// ### python source
  /// ```py
  /// def flush(self):
  ///         self._file.flush()
  /// ```
  Object? flush() => getFunction("flush").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## isatty
  ///
  /// ### python source
  /// ```py
  /// def isatty(self):
  ///         return self._file.isatty()
  /// ```
  Object? isatty() => getFunction("isatty").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## read
  ///
  /// ### python source
  /// ```py
  /// def read(self, *args):
  ///         return self._file.read(*args)
  /// ```
  Object? read({
    List<Object?> args = const <Object?>[],
  }) =>
      getFunction("read").call(
        <Object?>[
          ...args,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## read1
  ///
  /// ### python source
  /// ```py
  /// def read1(self, *args):
  ///         return self._file.read1(*args)
  /// ```
  Object? read1({
    List<Object?> args = const <Object?>[],
  }) =>
      getFunction("read1").call(
        <Object?>[
          ...args,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## readable
  ///
  /// ### python source
  /// ```py
  /// def readable(self):
  ///         return self._file.readable()
  /// ```
  Object? readable() => getFunction("readable").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## readinto
  ///
  /// ### python source
  /// ```py
  /// def readinto(self, b):
  ///         return self._file.readinto(b)
  /// ```
  Object? readinto({
    required Object? b,
  }) =>
      getFunction("readinto").call(
        <Object?>[
          b,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## readinto1
  ///
  /// ### python source
  /// ```py
  /// def readinto1(self, b):
  ///         return self._file.readinto1(b)
  /// ```
  Object? readinto1({
    required Object? b,
  }) =>
      getFunction("readinto1").call(
        <Object?>[
          b,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## readline
  ///
  /// ### python source
  /// ```py
  /// def readline(self, *args):
  ///         return self._file.readline(*args)
  /// ```
  Object? readline({
    List<Object?> args = const <Object?>[],
  }) =>
      getFunction("readline").call(
        <Object?>[
          ...args,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## readlines
  ///
  /// ### python source
  /// ```py
  /// def readlines(self, *args):
  ///         return self._file.readlines(*args)
  /// ```
  Object? readlines({
    List<Object?> args = const <Object?>[],
  }) =>
      getFunction("readlines").call(
        <Object?>[
          ...args,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## rollover
  ///
  /// ### python source
  /// ```py
  /// def rollover(self):
  ///         if self._rolled: return
  ///         file = self._file
  ///         newfile = self._file = TemporaryFile(**self._TemporaryFileArgs)
  ///         del self._TemporaryFileArgs
  ///
  ///         pos = file.tell()
  ///         if hasattr(newfile, 'buffer'):
  ///             newfile.buffer.write(file.detach().getvalue())
  ///         else:
  ///             newfile.write(file.getvalue())
  ///         newfile.seek(pos, 0)
  ///
  ///         self._rolled = True
  /// ```
  Object? rollover() => getFunction("rollover").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## seek
  ///
  /// ### python source
  /// ```py
  /// def seek(self, *args):
  ///         return self._file.seek(*args)
  /// ```
  Object? seek({
    List<Object?> args = const <Object?>[],
  }) =>
      getFunction("seek").call(
        <Object?>[
          ...args,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## seekable
  ///
  /// ### python source
  /// ```py
  /// def seekable(self):
  ///         return self._file.seekable()
  /// ```
  Object? seekable() => getFunction("seekable").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## tell
  ///
  /// ### python source
  /// ```py
  /// def tell(self):
  ///         return self._file.tell()
  /// ```
  Object? tell() => getFunction("tell").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## truncate
  ///
  /// ### python source
  /// ```py
  /// def truncate(self, size=None):
  ///         if size is None:
  ///             return self._file.truncate()
  ///         else:
  ///             if size > self._max_size:
  ///                 self.rollover()
  ///             return self._file.truncate(size)
  /// ```
  Object? truncate({
    Object? size,
  }) =>
      getFunction("truncate").call(
        <Object?>[
          size,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## writable
  ///
  /// ### python source
  /// ```py
  /// def writable(self):
  ///         return self._file.writable()
  /// ```
  Object? writable() => getFunction("writable").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## write
  ///
  /// ### python source
  /// ```py
  /// def write(self, s):
  ///         file = self._file
  ///         rv = file.write(s)
  ///         self._check(file)
  ///         return rv
  /// ```
  Object? write({
    required Object? s,
  }) =>
      getFunction("write").call(
        <Object?>[
          s,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## writelines
  ///
  /// ### python source
  /// ```py
  /// def writelines(self, iterable):
  ///         file = self._file
  ///         rv = file.writelines(iterable)
  ///         self._check(file)
  ///         return rv
  /// ```
  Object? writelines({
    required Object? iterable,
  }) =>
      getFunction("writelines").call(
        <Object?>[
          iterable,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## closed (getter)
  Object? get closed => getAttribute("closed");

  /// ## closed (setter)
  set closed(Object? closed) => setAttribute("closed", closed);

  /// ## encoding (getter)
  Object? get encoding => getAttribute("encoding");

  /// ## encoding (setter)
  set encoding(Object? encoding) => setAttribute("encoding", encoding);

  /// ## errors (getter)
  Object? get errors => getAttribute("errors");

  /// ## errors (setter)
  set errors(Object? errors) => setAttribute("errors", errors);

  /// ## mode (getter)
  Object? get mode => getAttribute("mode");

  /// ## mode (setter)
  set mode(Object? mode) => setAttribute("mode", mode);

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);

  /// ## newlines (getter)
  Object? get newlines => getAttribute("newlines");

  /// ## newlines (setter)
  set newlines(Object? newlines) => setAttribute("newlines", newlines);
}

/// ## TemporaryDirectory
///
/// ### python docstring
///
/// Create and return a temporary directory.  This has the same
/// behavior as mkdtemp but can be used as a context manager.  For
/// example:
///
///     with TemporaryDirectory() as tmpdir:
///         ...
///
/// Upon exiting the context, the directory and everything contained
/// in it are removed.
///
/// ### python source
/// ```py
/// class TemporaryDirectory:
///     """Create and return a temporary directory.  This has the same
///     behavior as mkdtemp but can be used as a context manager.  For
///     example:
///
///         with TemporaryDirectory() as tmpdir:
///             ...
///
///     Upon exiting the context, the directory and everything contained
///     in it are removed.
///     """
///
///     def __init__(self, suffix=None, prefix=None, dir=None,
///                  ignore_cleanup_errors=False):
///         self.name = mkdtemp(suffix, prefix, dir)
///         self._ignore_cleanup_errors = ignore_cleanup_errors
///         self._finalizer = _weakref.finalize(
///             self, self._cleanup, self.name,
///             warn_message="Implicitly cleaning up {!r}".format(self),
///             ignore_errors=self._ignore_cleanup_errors)
///
///     @classmethod
///     def _rmtree(cls, name, ignore_errors=False):
///         def onerror(func, path, exc_info):
///             if issubclass(exc_info[0], PermissionError):
///                 def resetperms(path):
///                     try:
///                         _os.chflags(path, 0)
///                     except AttributeError:
///                         pass
///                     _os.chmod(path, 0o700)
///
///                 try:
///                     if path != name:
///                         resetperms(_os.path.dirname(path))
///                     resetperms(path)
///
///                     try:
///                         _os.unlink(path)
///                     # PermissionError is raised on FreeBSD for directories
///                     except (IsADirectoryError, PermissionError):
///                         cls._rmtree(path, ignore_errors=ignore_errors)
///                 except FileNotFoundError:
///                     pass
///             elif issubclass(exc_info[0], FileNotFoundError):
///                 pass
///             else:
///                 if not ignore_errors:
///                     raise
///
///         _shutil.rmtree(name, onerror=onerror)
///
///     @classmethod
///     def _cleanup(cls, name, warn_message, ignore_errors=False):
///         cls._rmtree(name, ignore_errors=ignore_errors)
///         _warnings.warn(warn_message, ResourceWarning)
///
///     def __repr__(self):
///         return "<{} {!r}>".format(self.__class__.__name__, self.name)
///
///     def __enter__(self):
///         return self.name
///
///     def __exit__(self, exc, value, tb):
///         self.cleanup()
///
///     def cleanup(self):
///         if self._finalizer.detach() or _os.path.exists(self.name):
///             self._rmtree(self.name, ignore_errors=self._ignore_cleanup_errors)
///
///     __class_getitem__ = classmethod(_types.GenericAlias)
/// ```
final class TemporaryDirectory extends PythonClass {
  factory TemporaryDirectory({
    Object? suffix,
    Object? prefix,
    Object? dir,
    Object? ignore_cleanup_errors = false,
  }) =>
      PythonFfiDart.instance.importClass(
        "tempfile",
        "TemporaryDirectory",
        TemporaryDirectory.from,
        <Object?>[
          suffix,
          prefix,
          dir,
          ignore_cleanup_errors,
        ],
        <String, Object?>{},
      );

  TemporaryDirectory.from(super.pythonClass) : super.from();

  /// ## cleanup
  ///
  /// ### python source
  /// ```py
  /// def cleanup(self):
  ///         if self._finalizer.detach() or _os.path.exists(self.name):
  ///             self._rmtree(self.name, ignore_errors=self._ignore_cleanup_errors)
  /// ```
  Object? cleanup() => getFunction("cleanup").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);
}

/// ## AsyncGeneratorType
final class AsyncGeneratorType extends PythonClass {
  factory AsyncGeneratorType() => PythonFfiDart.instance.importClass(
        "builtins",
        "AsyncGeneratorType",
        AsyncGeneratorType.from,
        <Object?>[],
      );

  AsyncGeneratorType.from(super.pythonClass) : super.from();

  /// ## ag_await (getter)
  Object? get ag_await => getAttribute("ag_await");

  /// ## ag_await (setter)
  set ag_await(Object? ag_await) => setAttribute("ag_await", ag_await);

  /// ## ag_code (getter)
  Object? get ag_code => getAttribute("ag_code");

  /// ## ag_code (setter)
  set ag_code(Object? ag_code) => setAttribute("ag_code", ag_code);

  /// ## ag_frame (getter)
  Object? get ag_frame => getAttribute("ag_frame");

  /// ## ag_frame (setter)
  set ag_frame(Object? ag_frame) => setAttribute("ag_frame", ag_frame);

  /// ## ag_running (getter)
  Object? get ag_running => getAttribute("ag_running");

  /// ## ag_running (setter)
  set ag_running(Object? ag_running) => setAttribute("ag_running", ag_running);

  /// ## aclose (getter)
  Object? get aclose => getAttribute("aclose");

  /// ## aclose (setter)
  set aclose(Object? aclose) => setAttribute("aclose", aclose);

  /// ## asend (getter)
  Object? get asend => getAttribute("asend");

  /// ## asend (setter)
  set asend(Object? asend) => setAttribute("asend", asend);

  /// ## athrow (getter)
  Object? get athrow => getAttribute("athrow");

  /// ## athrow (setter)
  set athrow(Object? athrow) => setAttribute("athrow", athrow);
}

/// ## BuiltinFunctionType
final class BuiltinFunctionType extends PythonClass {
  factory BuiltinFunctionType() => PythonFfiDart.instance.importClass(
        "builtins",
        "BuiltinFunctionType",
        BuiltinFunctionType.from,
        <Object?>[],
      );

  BuiltinFunctionType.from(super.pythonClass) : super.from();
}

/// ## CellType
final class CellType extends PythonClass {
  factory CellType() => PythonFfiDart.instance.importClass(
        "builtins",
        "CellType",
        CellType.from,
        <Object?>[],
      );

  CellType.from(super.pythonClass) : super.from();

  /// ## cell_contents (getter)
  Object? get cell_contents => getAttribute("cell_contents");

  /// ## cell_contents (setter)
  set cell_contents(Object? cell_contents) =>
      setAttribute("cell_contents", cell_contents);
}

/// ## ClassMethodDescriptorType
final class ClassMethodDescriptorType extends PythonClass {
  factory ClassMethodDescriptorType() => PythonFfiDart.instance.importClass(
        "builtins",
        "ClassMethodDescriptorType",
        ClassMethodDescriptorType.from,
        <Object?>[],
      );

  ClassMethodDescriptorType.from(super.pythonClass) : super.from();
}

/// ## CodeType
final class CodeType extends PythonClass {
  factory CodeType() => PythonFfiDart.instance.importClass(
        "builtins",
        "CodeType",
        CodeType.from,
        <Object?>[],
      );

  CodeType.from(super.pythonClass) : super.from();

  /// ## co_argcount (getter)
  Object? get co_argcount => getAttribute("co_argcount");

  /// ## co_argcount (setter)
  set co_argcount(Object? co_argcount) =>
      setAttribute("co_argcount", co_argcount);

  /// ## co_cellvars (getter)
  Object? get co_cellvars => getAttribute("co_cellvars");

  /// ## co_cellvars (setter)
  set co_cellvars(Object? co_cellvars) =>
      setAttribute("co_cellvars", co_cellvars);

  /// ## co_code (getter)
  Object? get co_code => getAttribute("co_code");

  /// ## co_code (setter)
  set co_code(Object? co_code) => setAttribute("co_code", co_code);

  /// ## co_consts (getter)
  Object? get co_consts => getAttribute("co_consts");

  /// ## co_consts (setter)
  set co_consts(Object? co_consts) => setAttribute("co_consts", co_consts);

  /// ## co_exceptiontable (getter)
  Object? get co_exceptiontable => getAttribute("co_exceptiontable");

  /// ## co_exceptiontable (setter)
  set co_exceptiontable(Object? co_exceptiontable) =>
      setAttribute("co_exceptiontable", co_exceptiontable);

  /// ## co_filename (getter)
  Object? get co_filename => getAttribute("co_filename");

  /// ## co_filename (setter)
  set co_filename(Object? co_filename) =>
      setAttribute("co_filename", co_filename);

  /// ## co_firstlineno (getter)
  Object? get co_firstlineno => getAttribute("co_firstlineno");

  /// ## co_firstlineno (setter)
  set co_firstlineno(Object? co_firstlineno) =>
      setAttribute("co_firstlineno", co_firstlineno);

  /// ## co_flags (getter)
  Object? get co_flags => getAttribute("co_flags");

  /// ## co_flags (setter)
  set co_flags(Object? co_flags) => setAttribute("co_flags", co_flags);

  /// ## co_freevars (getter)
  Object? get co_freevars => getAttribute("co_freevars");

  /// ## co_freevars (setter)
  set co_freevars(Object? co_freevars) =>
      setAttribute("co_freevars", co_freevars);

  /// ## co_kwonlyargcount (getter)
  Object? get co_kwonlyargcount => getAttribute("co_kwonlyargcount");

  /// ## co_kwonlyargcount (setter)
  set co_kwonlyargcount(Object? co_kwonlyargcount) =>
      setAttribute("co_kwonlyargcount", co_kwonlyargcount);

  /// ## co_linetable (getter)
  Object? get co_linetable => getAttribute("co_linetable");

  /// ## co_linetable (setter)
  set co_linetable(Object? co_linetable) =>
      setAttribute("co_linetable", co_linetable);

  /// ## co_lnotab (getter)
  Object? get co_lnotab => getAttribute("co_lnotab");

  /// ## co_lnotab (setter)
  set co_lnotab(Object? co_lnotab) => setAttribute("co_lnotab", co_lnotab);

  /// ## co_name (getter)
  Object? get co_name => getAttribute("co_name");

  /// ## co_name (setter)
  set co_name(Object? co_name) => setAttribute("co_name", co_name);

  /// ## co_names (getter)
  Object? get co_names => getAttribute("co_names");

  /// ## co_names (setter)
  set co_names(Object? co_names) => setAttribute("co_names", co_names);

  /// ## co_nlocals (getter)
  Object? get co_nlocals => getAttribute("co_nlocals");

  /// ## co_nlocals (setter)
  set co_nlocals(Object? co_nlocals) => setAttribute("co_nlocals", co_nlocals);

  /// ## co_posonlyargcount (getter)
  Object? get co_posonlyargcount => getAttribute("co_posonlyargcount");

  /// ## co_posonlyargcount (setter)
  set co_posonlyargcount(Object? co_posonlyargcount) =>
      setAttribute("co_posonlyargcount", co_posonlyargcount);

  /// ## co_qualname (getter)
  Object? get co_qualname => getAttribute("co_qualname");

  /// ## co_qualname (setter)
  set co_qualname(Object? co_qualname) =>
      setAttribute("co_qualname", co_qualname);

  /// ## co_stacksize (getter)
  Object? get co_stacksize => getAttribute("co_stacksize");

  /// ## co_stacksize (setter)
  set co_stacksize(Object? co_stacksize) =>
      setAttribute("co_stacksize", co_stacksize);

  /// ## co_varnames (getter)
  Object? get co_varnames => getAttribute("co_varnames");

  /// ## co_varnames (setter)
  set co_varnames(Object? co_varnames) =>
      setAttribute("co_varnames", co_varnames);

  /// ## co_lines (getter)
  Object? get co_lines => getAttribute("co_lines");

  /// ## co_lines (setter)
  set co_lines(Object? co_lines) => setAttribute("co_lines", co_lines);

  /// ## co_positions (getter)
  Object? get co_positions => getAttribute("co_positions");

  /// ## co_positions (setter)
  set co_positions(Object? co_positions) =>
      setAttribute("co_positions", co_positions);

  /// ## replace (getter)
  Object? get replace => getAttribute("replace");

  /// ## replace (setter)
  set replace(Object? replace) => setAttribute("replace", replace);
}

/// ## CoroutineType
final class CoroutineType extends PythonClass {
  factory CoroutineType() => PythonFfiDart.instance.importClass(
        "builtins",
        "CoroutineType",
        CoroutineType.from,
        <Object?>[],
      );

  CoroutineType.from(super.pythonClass) : super.from();

  /// ## cr_await (getter)
  Object? get cr_await => getAttribute("cr_await");

  /// ## cr_await (setter)
  set cr_await(Object? cr_await) => setAttribute("cr_await", cr_await);

  /// ## cr_code (getter)
  Object? get cr_code => getAttribute("cr_code");

  /// ## cr_code (setter)
  set cr_code(Object? cr_code) => setAttribute("cr_code", cr_code);

  /// ## cr_frame (getter)
  Object? get cr_frame => getAttribute("cr_frame");

  /// ## cr_frame (setter)
  set cr_frame(Object? cr_frame) => setAttribute("cr_frame", cr_frame);

  /// ## cr_origin (getter)
  Object? get cr_origin => getAttribute("cr_origin");

  /// ## cr_origin (setter)
  set cr_origin(Object? cr_origin) => setAttribute("cr_origin", cr_origin);

  /// ## cr_running (getter)
  Object? get cr_running => getAttribute("cr_running");

  /// ## cr_running (setter)
  set cr_running(Object? cr_running) => setAttribute("cr_running", cr_running);

  /// ## cr_suspended (getter)
  Object? get cr_suspended => getAttribute("cr_suspended");

  /// ## cr_suspended (setter)
  set cr_suspended(Object? cr_suspended) =>
      setAttribute("cr_suspended", cr_suspended);

  /// ## close (getter)
  Object? get close => getAttribute("close");

  /// ## close (setter)
  set close(Object? close) => setAttribute("close", close);

  /// ## send (getter)
  Object? get send => getAttribute("send");

  /// ## send (setter)
  set send(Object? send) => setAttribute("send", send);

  /// ## throw (getter)
  Object? get $throw => getAttribute("throw");

  /// ## throw (setter)
  set $throw(Object? $throw) => setAttribute("throw", $throw);
}

/// ## EllipsisType
final class EllipsisType extends PythonClass {
  factory EllipsisType() => PythonFfiDart.instance.importClass(
        "builtins",
        "EllipsisType",
        EllipsisType.from,
        <Object?>[],
      );

  EllipsisType.from(super.pythonClass) : super.from();
}

/// ## FrameType
final class FrameType extends PythonClass {
  factory FrameType() => PythonFfiDart.instance.importClass(
        "builtins",
        "FrameType",
        FrameType.from,
        <Object?>[],
      );

  FrameType.from(super.pythonClass) : super.from();

  /// ## f_back (getter)
  Object? get f_back => getAttribute("f_back");

  /// ## f_back (setter)
  set f_back(Object? f_back) => setAttribute("f_back", f_back);

  /// ## f_builtins (getter)
  Object? get f_builtins => getAttribute("f_builtins");

  /// ## f_builtins (setter)
  set f_builtins(Object? f_builtins) => setAttribute("f_builtins", f_builtins);

  /// ## f_code (getter)
  Object? get f_code => getAttribute("f_code");

  /// ## f_code (setter)
  set f_code(Object? f_code) => setAttribute("f_code", f_code);

  /// ## f_globals (getter)
  Object? get f_globals => getAttribute("f_globals");

  /// ## f_globals (setter)
  set f_globals(Object? f_globals) => setAttribute("f_globals", f_globals);

  /// ## f_lasti (getter)
  Object? get f_lasti => getAttribute("f_lasti");

  /// ## f_lasti (setter)
  set f_lasti(Object? f_lasti) => setAttribute("f_lasti", f_lasti);

  /// ## f_lineno (getter)
  Object? get f_lineno => getAttribute("f_lineno");

  /// ## f_lineno (setter)
  set f_lineno(Object? f_lineno) => setAttribute("f_lineno", f_lineno);

  /// ## f_locals (getter)
  Object? get f_locals => getAttribute("f_locals");

  /// ## f_locals (setter)
  set f_locals(Object? f_locals) => setAttribute("f_locals", f_locals);

  /// ## f_trace (getter)
  Object? get f_trace => getAttribute("f_trace");

  /// ## f_trace (setter)
  set f_trace(Object? f_trace) => setAttribute("f_trace", f_trace);

  /// ## f_trace_lines (getter)
  Object? get f_trace_lines => getAttribute("f_trace_lines");

  /// ## f_trace_lines (setter)
  set f_trace_lines(Object? f_trace_lines) =>
      setAttribute("f_trace_lines", f_trace_lines);

  /// ## f_trace_opcodes (getter)
  Object? get f_trace_opcodes => getAttribute("f_trace_opcodes");

  /// ## f_trace_opcodes (setter)
  set f_trace_opcodes(Object? f_trace_opcodes) =>
      setAttribute("f_trace_opcodes", f_trace_opcodes);

  /// ## clear (getter)
  Object? get clear => getAttribute("clear");

  /// ## clear (setter)
  set clear(Object? clear) => setAttribute("clear", clear);
}

/// ## GeneratorType
final class GeneratorType extends PythonClass {
  factory GeneratorType() => PythonFfiDart.instance.importClass(
        "builtins",
        "GeneratorType",
        GeneratorType.from,
        <Object?>[],
      );

  GeneratorType.from(super.pythonClass) : super.from();

  /// ## gi_code (getter)
  Object? get gi_code => getAttribute("gi_code");

  /// ## gi_code (setter)
  set gi_code(Object? gi_code) => setAttribute("gi_code", gi_code);

  /// ## gi_frame (getter)
  Object? get gi_frame => getAttribute("gi_frame");

  /// ## gi_frame (setter)
  set gi_frame(Object? gi_frame) => setAttribute("gi_frame", gi_frame);

  /// ## gi_running (getter)
  Object? get gi_running => getAttribute("gi_running");

  /// ## gi_running (setter)
  set gi_running(Object? gi_running) => setAttribute("gi_running", gi_running);

  /// ## gi_suspended (getter)
  Object? get gi_suspended => getAttribute("gi_suspended");

  /// ## gi_suspended (setter)
  set gi_suspended(Object? gi_suspended) =>
      setAttribute("gi_suspended", gi_suspended);

  /// ## gi_yieldfrom (getter)
  Object? get gi_yieldfrom => getAttribute("gi_yieldfrom");

  /// ## gi_yieldfrom (setter)
  set gi_yieldfrom(Object? gi_yieldfrom) =>
      setAttribute("gi_yieldfrom", gi_yieldfrom);

  /// ## close (getter)
  Object? get close => getAttribute("close");

  /// ## close (setter)
  set close(Object? close) => setAttribute("close", close);

  /// ## send (getter)
  Object? get send => getAttribute("send");

  /// ## send (setter)
  set send(Object? send) => setAttribute("send", send);

  /// ## throw (getter)
  Object? get $throw => getAttribute("throw");

  /// ## throw (setter)
  set $throw(Object? $throw) => setAttribute("throw", $throw);
}

/// ## GetSetDescriptorType
final class GetSetDescriptorType extends PythonClass {
  factory GetSetDescriptorType() => PythonFfiDart.instance.importClass(
        "builtins",
        "GetSetDescriptorType",
        GetSetDescriptorType.from,
        <Object?>[],
      );

  GetSetDescriptorType.from(super.pythonClass) : super.from();
}

/// ## MemberDescriptorType
final class MemberDescriptorType extends PythonClass {
  factory MemberDescriptorType() => PythonFfiDart.instance.importClass(
        "builtins",
        "MemberDescriptorType",
        MemberDescriptorType.from,
        <Object?>[],
      );

  MemberDescriptorType.from(super.pythonClass) : super.from();
}

/// ## MethodDescriptorType
final class MethodDescriptorType extends PythonClass {
  factory MethodDescriptorType() => PythonFfiDart.instance.importClass(
        "builtins",
        "MethodDescriptorType",
        MethodDescriptorType.from,
        <Object?>[],
      );

  MethodDescriptorType.from(super.pythonClass) : super.from();
}

/// ## MethodWrapperType
final class MethodWrapperType extends PythonClass {
  factory MethodWrapperType() => PythonFfiDart.instance.importClass(
        "builtins",
        "MethodWrapperType",
        MethodWrapperType.from,
        <Object?>[],
      );

  MethodWrapperType.from(super.pythonClass) : super.from();
}

/// ## NoneType
final class NoneType extends PythonClass {
  factory NoneType() => PythonFfiDart.instance.importClass(
        "builtins",
        "NoneType",
        NoneType.from,
        <Object?>[],
      );

  NoneType.from(super.pythonClass) : super.from();
}

/// ## NotImplementedType
final class NotImplementedType extends PythonClass {
  factory NotImplementedType() => PythonFfiDart.instance.importClass(
        "builtins",
        "NotImplementedType",
        NotImplementedType.from,
        <Object?>[],
      );

  NotImplementedType.from(super.pythonClass) : super.from();
}

/// ## SimpleNamespace
final class SimpleNamespace extends PythonClass {
  factory SimpleNamespace() => PythonFfiDart.instance.importClass(
        "types",
        "SimpleNamespace",
        SimpleNamespace.from,
        <Object?>[],
      );

  SimpleNamespace.from(super.pythonClass) : super.from();
}

/// ## TracebackType
final class TracebackType extends PythonClass {
  factory TracebackType() => PythonFfiDart.instance.importClass(
        "builtins",
        "TracebackType",
        TracebackType.from,
        <Object?>[],
      );

  TracebackType.from(super.pythonClass) : super.from();

  /// ## tb_frame (getter)
  Object? get tb_frame => getAttribute("tb_frame");

  /// ## tb_frame (setter)
  set tb_frame(Object? tb_frame) => setAttribute("tb_frame", tb_frame);

  /// ## tb_lasti (getter)
  Object? get tb_lasti => getAttribute("tb_lasti");

  /// ## tb_lasti (setter)
  set tb_lasti(Object? tb_lasti) => setAttribute("tb_lasti", tb_lasti);

  /// ## tb_lineno (getter)
  Object? get tb_lineno => getAttribute("tb_lineno");

  /// ## tb_lineno (setter)
  set tb_lineno(Object? tb_lineno) => setAttribute("tb_lineno", tb_lineno);

  /// ## tb_next (getter)
  Object? get tb_next => getAttribute("tb_next");

  /// ## tb_next (setter)
  set tb_next(Object? tb_next) => setAttribute("tb_next", tb_next);
}

/// ## UnionType
final class UnionType extends PythonClass {
  factory UnionType() => PythonFfiDart.instance.importClass(
        "types",
        "UnionType",
        UnionType.from,
        <Object?>[],
      );

  UnionType.from(super.pythonClass) : super.from();
}

/// ## WrapperDescriptorType
final class WrapperDescriptorType extends PythonClass {
  factory WrapperDescriptorType() => PythonFfiDart.instance.importClass(
        "builtins",
        "WrapperDescriptorType",
        WrapperDescriptorType.from,
        <Object?>[],
      );

  WrapperDescriptorType.from(super.pythonClass) : super.from();
}

/// ## CallChain
///
/// ### python source
/// ```py
/// class CallChain:
///     def __init__(self, callback1, callback2, cond):
///         self.callback1 = callback1
///         self.callback2 = callback2
///         self.cond = cond
///
///     def __call__(self, t):
///         t2 = self.callback1(t)
///         return self.callback2(t) if self.cond(t2) else t2
/// ```
final class CallChain extends PythonClass {
  factory CallChain({
    required Object? callback1,
    required Object? callback2,
    required Object? cond,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.lexer",
        "CallChain",
        CallChain.from,
        <Object?>[
          callback1,
          callback2,
          cond,
        ],
        <String, Object?>{},
      );

  CallChain.from(super.pythonClass) : super.from();

  /// ## callback1 (getter)
  Object? get callback1 => getAttribute("callback1");

  /// ## callback1 (setter)
  set callback1(Object? callback1) => setAttribute("callback1", callback1);

  /// ## callback2 (getter)
  Object? get callback2 => getAttribute("callback2");

  /// ## callback2 (setter)
  set callback2(Object? callback2) => setAttribute("callback2", callback2);

  /// ## cond (getter)
  Object? get cond => getAttribute("cond");

  /// ## cond (setter)
  set cond(Object? cond) => setAttribute("cond", cond);
}

/// ## ContextualLexer
///
/// ### python docstring
///
/// Lexer interface
///
/// Method Signatures:
///     lex(self, lexer_state, parser_state) -> Iterator[Token]
///
/// ### python source
/// ```py
/// class ContextualLexer(Lexer):
///
///     lexers: Dict[str, BasicLexer]
///     root_lexer: BasicLexer
///
///     def __init__(self, conf: 'LexerConf', states: Dict[str, Collection[str]], always_accept: Collection[str]=()) -> None:
///         terminals = list(conf.terminals)
///         terminals_by_name = conf.terminals_by_name
///
///         trad_conf = copy(conf)
///         trad_conf.terminals = terminals
///
///         lexer_by_tokens: Dict[FrozenSet[str], BasicLexer] = {}
///         self.lexers = {}
///         for state, accepts in states.items():
///             key = frozenset(accepts)
///             try:
///                 lexer = lexer_by_tokens[key]
///             except KeyError:
///                 accepts = set(accepts) | set(conf.ignore) | set(always_accept)
///                 lexer_conf = copy(trad_conf)
///                 lexer_conf.terminals = [terminals_by_name[n] for n in accepts if n in terminals_by_name]
///                 lexer = BasicLexer(lexer_conf)
///                 lexer_by_tokens[key] = lexer
///
///             self.lexers[state] = lexer
///
///         assert trad_conf.terminals is terminals
///         self.root_lexer = BasicLexer(trad_conf)
///
///     def lex(self, lexer_state: LexerState, parser_state: Any) -> Iterator[Token]:
///         try:
///             while True:
///                 lexer = self.lexers[parser_state.position]
///                 yield lexer.next_token(lexer_state, parser_state)
///         except EOFError:
///             pass
///         except UnexpectedCharacters as e:
///             # In the contextual lexer, UnexpectedCharacters can mean that the terminal is defined, but not in the current context.
///             # This tests the input against the global context, to provide a nicer error.
///             try:
///                 last_token = lexer_state.last_token  # Save last_token. Calling root_lexer.next_token will change this to the wrong token
///                 token = self.root_lexer.next_token(lexer_state, parser_state)
///                 raise UnexpectedToken(token, e.allowed, state=parser_state, token_history=[last_token], terminals_by_name=self.root_lexer.terminals_by_name)
///             except UnexpectedCharacters:
///                 raise e  # Raise the original UnexpectedCharacters. The root lexer raises it with the wrong expected set.
/// ```
final class ContextualLexer extends PythonClass {
  factory ContextualLexer({
    required Object? conf,
    required Object? states,
    Object? always_accept = const [],
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.lexer",
        "ContextualLexer",
        ContextualLexer.from,
        <Object?>[
          conf,
          states,
          always_accept,
        ],
        <String, Object?>{},
      );

  ContextualLexer.from(super.pythonClass) : super.from();

  /// ## lex
  ///
  /// ### python source
  /// ```py
  /// def lex(self, lexer_state: LexerState, parser_state: Any) -> Iterator[Token]:
  ///         try:
  ///             while True:
  ///                 lexer = self.lexers[parser_state.position]
  ///                 yield lexer.next_token(lexer_state, parser_state)
  ///         except EOFError:
  ///             pass
  ///         except UnexpectedCharacters as e:
  ///             # In the contextual lexer, UnexpectedCharacters can mean that the terminal is defined, but not in the current context.
  ///             # This tests the input against the global context, to provide a nicer error.
  ///             try:
  ///                 last_token = lexer_state.last_token  # Save last_token. Calling root_lexer.next_token will change this to the wrong token
  ///                 token = self.root_lexer.next_token(lexer_state, parser_state)
  ///                 raise UnexpectedToken(token, e.allowed, state=parser_state, token_history=[last_token], terminals_by_name=self.root_lexer.terminals_by_name)
  ///             except UnexpectedCharacters:
  ///                 raise e  # Raise the original UnexpectedCharacters. The root lexer raises it with the wrong expected set.
  /// ```
  Object? lex({
    required Object? lexer_state,
    required Object? parser_state,
  }) =>
      getFunction("lex").call(
        <Object?>[
          lexer_state,
          parser_state,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## make_lexer_state
  ///
  /// ### python docstring
  ///
  /// Deprecated
  ///
  /// ### python source
  /// ```py
  /// def make_lexer_state(self, text):
  ///         "Deprecated"
  ///         return LexerState(text)
  /// ```
  Object? make_lexer_state({
    required Object? text,
  }) =>
      getFunction("make_lexer_state").call(
        <Object?>[
          text,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## lexers (getter)
  Object? get lexers => getAttribute("lexers");

  /// ## lexers (setter)
  set lexers(Object? lexers) => setAttribute("lexers", lexers);

  /// ## root_lexer (getter)
  Object? get root_lexer => getAttribute("root_lexer");

  /// ## root_lexer (setter)
  set root_lexer(Object? root_lexer) => setAttribute("root_lexer", root_lexer);
}

/// ## LexerState
///
/// ### python docstring
///
/// Represents the current state of the lexer as it scans the text
/// (Lexer objects are only instanciated per grammar, not per text)
///
/// ### python source
/// ```py
/// class LexerState:
///     """Represents the current state of the lexer as it scans the text
///     (Lexer objects are only instanciated per grammar, not per text)
///     """
///
///     __slots__ = 'text', 'line_ctr', 'last_token'
///
///     def __init__(self, text, line_ctr=None, last_token=None):
///         self.text = text
///         self.line_ctr = line_ctr or LineCounter(b'\n' if isinstance(text, bytes) else '\n')
///         self.last_token = last_token
///
///     def __eq__(self, other):
///         if not isinstance(other, LexerState):
///             return NotImplemented
///
///         return self.text is other.text and self.line_ctr == other.line_ctr and self.last_token == other.last_token
///
///     def __copy__(self):
///         return type(self)(self.text, copy(self.line_ctr), self.last_token)
/// ```
final class LexerState extends PythonClass {
  factory LexerState({
    required Object? text,
    Object? line_ctr,
    Object? last_token,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.lexer",
        "LexerState",
        LexerState.from,
        <Object?>[
          text,
          line_ctr,
          last_token,
        ],
        <String, Object?>{},
      );

  LexerState.from(super.pythonClass) : super.from();

  /// ## last_token (getter)
  Object? get last_token => getAttribute("last_token");

  /// ## last_token (setter)
  set last_token(Object? last_token) => setAttribute("last_token", last_token);

  /// ## line_ctr (getter)
  Object? get line_ctr => getAttribute("line_ctr");

  /// ## line_ctr (setter)
  set line_ctr(Object? line_ctr) => setAttribute("line_ctr", line_ctr);

  /// ## text (getter)
  Object? get text => getAttribute("text");

  /// ## text (setter)
  set text(Object? text) => setAttribute("text", text);
}

/// ## LineCounter
///
/// ### python source
/// ```py
/// class LineCounter:
///     __slots__ = 'char_pos', 'line', 'column', 'line_start_pos', 'newline_char'
///
///     def __init__(self, newline_char):
///         self.newline_char = newline_char
///         self.char_pos = 0
///         self.line = 1
///         self.column = 1
///         self.line_start_pos = 0
///
///     def __eq__(self, other):
///         if not isinstance(other, LineCounter):
///             return NotImplemented
///
///         return self.char_pos == other.char_pos and self.newline_char == other.newline_char
///
///     def feed(self, token: Token, test_newline=True):
///         """Consume a token and calculate the new line & column.
///
///         As an optional optimization, set test_newline=False if token doesn't contain a newline.
///         """
///         if test_newline:
///             newlines = token.count(self.newline_char)
///             if newlines:
///                 self.line += newlines
///                 self.line_start_pos = self.char_pos + token.rindex(self.newline_char) + 1
///
///         self.char_pos += len(token)
///         self.column = self.char_pos - self.line_start_pos + 1
/// ```
final class LineCounter extends PythonClass {
  factory LineCounter({
    required Object? newline_char,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.lexer",
        "LineCounter",
        LineCounter.from,
        <Object?>[
          newline_char,
        ],
        <String, Object?>{},
      );

  LineCounter.from(super.pythonClass) : super.from();

  /// ## feed
  ///
  /// ### python docstring
  ///
  /// Consume a token and calculate the new line & column.
  ///
  /// As an optional optimization, set test_newline=False if token doesn't contain a newline.
  ///
  /// ### python source
  /// ```py
  /// def feed(self, token: Token, test_newline=True):
  ///         """Consume a token and calculate the new line & column.
  ///
  ///         As an optional optimization, set test_newline=False if token doesn't contain a newline.
  ///         """
  ///         if test_newline:
  ///             newlines = token.count(self.newline_char)
  ///             if newlines:
  ///                 self.line += newlines
  ///                 self.line_start_pos = self.char_pos + token.rindex(self.newline_char) + 1
  ///
  ///         self.char_pos += len(token)
  ///         self.column = self.char_pos - self.line_start_pos + 1
  /// ```
  Object? feed({
    required Object? token,
    Object? test_newline = true,
  }) =>
      getFunction("feed").call(
        <Object?>[
          token,
          test_newline,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## char_pos (getter)
  Object? get char_pos => getAttribute("char_pos");

  /// ## char_pos (setter)
  set char_pos(Object? char_pos) => setAttribute("char_pos", char_pos);

  /// ## column (getter)
  Object? get column => getAttribute("column");

  /// ## column (setter)
  set column(Object? column) => setAttribute("column", column);

  /// ## line (getter)
  Object? get line => getAttribute("line");

  /// ## line (setter)
  set line(Object? line) => setAttribute("line", line);

  /// ## line_start_pos (getter)
  Object? get line_start_pos => getAttribute("line_start_pos");

  /// ## line_start_pos (setter)
  set line_start_pos(Object? line_start_pos) =>
      setAttribute("line_start_pos", line_start_pos);

  /// ## newline_char (getter)
  Object? get newline_char => getAttribute("newline_char");

  /// ## newline_char (setter)
  set newline_char(Object? newline_char) =>
      setAttribute("newline_char", newline_char);
}

/// ## PatternRE
///
/// ### python docstring
///
/// Safe-ish serialization interface that doesn't rely on Pickle
///
/// Attributes:
///     __serialize_fields__ (List[str]): Fields (aka attributes) to serialize.
///     __serialize_namespace__ (list): List of classes that deserialization is allowed to instantiate.
///                                     Should include all field types that aren't builtin types.
///
/// ### python source
/// ```py
/// class PatternRE(Pattern):
///     __serialize_fields__ = 'value', 'flags', '_width'
///
///     type: ClassVar[str] = "re"
///
///     def to_regexp(self) -> str:
///         return self._get_flags(self.value)
///
///     _width = None
///     def _get_width(self):
///         if self._width is None:
///             self._width = get_regexp_width(self.to_regexp())
///         return self._width
///
///     @property
///     def min_width(self) -> int:
///         return self._get_width()[0]
///
///     @property
///     def max_width(self) -> int:
///         return self._get_width()[1]
/// ```
final class PatternRE extends PythonClass {
  factory PatternRE({
    required Object? value,
    Object? flags = const [],
    Object? raw,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.lexer",
        "PatternRE",
        PatternRE.from,
        <Object?>[
          value,
          flags,
          raw,
        ],
        <String, Object?>{},
      );

  PatternRE.from(super.pythonClass) : super.from();

  /// ## memo_serialize
  ///
  /// ### python source
  /// ```py
  /// def memo_serialize(self, types_to_memoize: List) -> Any:
  ///         memo = SerializeMemoizer(types_to_memoize)
  ///         return self.serialize(memo), memo.serialize()
  /// ```
  Object? memo_serialize({
    required Object? types_to_memoize,
  }) =>
      getFunction("memo_serialize").call(
        <Object?>[
          types_to_memoize,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## serialize
  ///
  /// ### python source
  /// ```py
  /// def serialize(self, memo = None) -> Dict[str, Any]:
  ///         if memo and memo.in_types(self):
  ///             return {'@': memo.memoized.get(self)}
  ///
  ///         fields = getattr(self, '__serialize_fields__')
  ///         res = {f: _serialize(getattr(self, f), memo) for f in fields}
  ///         res['__type__'] = type(self).__name__
  ///         if hasattr(self, '_serialize'):
  ///             self._serialize(res, memo)  # type: ignore[attr-defined]
  ///         return res
  /// ```
  Object? serialize({
    Object? memo,
  }) =>
      getFunction("serialize").call(
        <Object?>[
          memo,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## to_regexp
  ///
  /// ### python source
  /// ```py
  /// def to_regexp(self) -> str:
  ///         return self._get_flags(self.value)
  /// ```
  Object? to_regexp() => getFunction("to_regexp").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## max_width (getter)
  Object? get max_width => getAttribute("max_width");

  /// ## max_width (setter)
  set max_width(Object? max_width) => setAttribute("max_width", max_width);

  /// ## min_width (getter)
  Object? get min_width => getAttribute("min_width");

  /// ## min_width (setter)
  set min_width(Object? min_width) => setAttribute("min_width", min_width);

  /// ## deserialize (getter)
  Object? get deserialize => getAttribute("deserialize");

  /// ## deserialize (setter)
  set deserialize(Object? deserialize) =>
      setAttribute("deserialize", deserialize);

  /// ## type (getter)
  Object? get type => getAttribute("type");

  /// ## type (setter)
  set type(Object? type) => setAttribute("type", type);

  /// ## value (getter)
  Object? get value => getAttribute("value");

  /// ## value (setter)
  set value(Object? value) => setAttribute("value", value);

  /// ## flags (getter)
  Object? get flags => getAttribute("flags");

  /// ## flags (setter)
  set flags(Object? flags) => setAttribute("flags", flags);

  /// ## raw (getter)
  Object? get raw => getAttribute("raw");

  /// ## raw (setter)
  set raw(Object? raw) => setAttribute("raw", raw);
}

/// ## PatternStr
///
/// ### python docstring
///
/// Safe-ish serialization interface that doesn't rely on Pickle
///
/// Attributes:
///     __serialize_fields__ (List[str]): Fields (aka attributes) to serialize.
///     __serialize_namespace__ (list): List of classes that deserialization is allowed to instantiate.
///                                     Should include all field types that aren't builtin types.
///
/// ### python source
/// ```py
/// class PatternStr(Pattern):
///     __serialize_fields__ = 'value', 'flags'
///
///     type: ClassVar[str] = "str"
///
///     def to_regexp(self) -> str:
///         return self._get_flags(re.escape(self.value))
///
///     @property
///     def min_width(self) -> int:
///         return len(self.value)
///
///     @property
///     def max_width(self) -> int:
///         return len(self.value)
/// ```
final class PatternStr extends PythonClass {
  factory PatternStr({
    required Object? value,
    Object? flags = const [],
    Object? raw,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.lexer",
        "PatternStr",
        PatternStr.from,
        <Object?>[
          value,
          flags,
          raw,
        ],
        <String, Object?>{},
      );

  PatternStr.from(super.pythonClass) : super.from();

  /// ## memo_serialize
  ///
  /// ### python source
  /// ```py
  /// def memo_serialize(self, types_to_memoize: List) -> Any:
  ///         memo = SerializeMemoizer(types_to_memoize)
  ///         return self.serialize(memo), memo.serialize()
  /// ```
  Object? memo_serialize({
    required Object? types_to_memoize,
  }) =>
      getFunction("memo_serialize").call(
        <Object?>[
          types_to_memoize,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## serialize
  ///
  /// ### python source
  /// ```py
  /// def serialize(self, memo = None) -> Dict[str, Any]:
  ///         if memo and memo.in_types(self):
  ///             return {'@': memo.memoized.get(self)}
  ///
  ///         fields = getattr(self, '__serialize_fields__')
  ///         res = {f: _serialize(getattr(self, f), memo) for f in fields}
  ///         res['__type__'] = type(self).__name__
  ///         if hasattr(self, '_serialize'):
  ///             self._serialize(res, memo)  # type: ignore[attr-defined]
  ///         return res
  /// ```
  Object? serialize({
    Object? memo,
  }) =>
      getFunction("serialize").call(
        <Object?>[
          memo,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## to_regexp
  ///
  /// ### python source
  /// ```py
  /// def to_regexp(self) -> str:
  ///         return self._get_flags(re.escape(self.value))
  /// ```
  Object? to_regexp() => getFunction("to_regexp").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## max_width (getter)
  Object? get max_width => getAttribute("max_width");

  /// ## max_width (setter)
  set max_width(Object? max_width) => setAttribute("max_width", max_width);

  /// ## min_width (getter)
  Object? get min_width => getAttribute("min_width");

  /// ## min_width (setter)
  set min_width(Object? min_width) => setAttribute("min_width", min_width);

  /// ## deserialize (getter)
  Object? get deserialize => getAttribute("deserialize");

  /// ## deserialize (setter)
  set deserialize(Object? deserialize) =>
      setAttribute("deserialize", deserialize);

  /// ## type (getter)
  Object? get type => getAttribute("type");

  /// ## type (setter)
  set type(Object? type) => setAttribute("type", type);

  /// ## value (getter)
  Object? get value => getAttribute("value");

  /// ## value (setter)
  set value(Object? value) => setAttribute("value", value);

  /// ## flags (getter)
  Object? get flags => getAttribute("flags");

  /// ## flags (setter)
  set flags(Object? flags) => setAttribute("flags", flags);

  /// ## raw (getter)
  Object? get raw => getAttribute("raw");

  /// ## raw (setter)
  set raw(Object? raw) => setAttribute("raw", raw);
}

/// ## UnlessCallback
///
/// ### python source
/// ```py
/// class UnlessCallback:
///     def __init__(self, scanner):
///         self.scanner = scanner
///
///     def __call__(self, t):
///         res = self.scanner.match(t.value, 0)
///         if res:
///             _value, t.type = res
///         return t
/// ```
final class UnlessCallback extends PythonClass {
  factory UnlessCallback({
    required Object? scanner,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.lexer",
        "UnlessCallback",
        UnlessCallback.from,
        <Object?>[
          scanner,
        ],
        <String, Object?>{},
      );

  UnlessCallback.from(super.pythonClass) : super.from();

  /// ## scanner (getter)
  Object? get scanner => getAttribute("scanner");

  /// ## scanner (setter)
  set scanner(Object? scanner) => setAttribute("scanner", scanner);
}

/// ## ApplyTemplates
///
/// ### python docstring
///
/// Apply the templates, creating new rules that represent the used templates
///
/// ### python source
/// ```py
/// class ApplyTemplates(Transformer_InPlace):
///     """Apply the templates, creating new rules that represent the used templates"""
///
///     def __init__(self, rule_defs):
///         self.rule_defs = rule_defs
///         self.replacer = _ReplaceSymbols()
///         self.created_templates = set()
///
///     def template_usage(self, c):
///         name = c[0].name
///         args = c[1:]
///         result_name = "%s{%s}" % (name, ",".join(a.name for a in args))
///         if result_name not in self.created_templates:
///             self.created_templates.add(result_name)
///             (_n, params, tree, options) ,= (t for t in self.rule_defs if t[0] == name)
///             assert len(params) == len(args), args
///             result_tree = deepcopy(tree)
///             self.replacer.names = dict(zip(params, args))
///             self.replacer.transform(result_tree)
///             self.rule_defs.append((result_name, [], result_tree, deepcopy(options)))
///         return NonTerminal(result_name)
/// ```
final class ApplyTemplates extends PythonClass {
  factory ApplyTemplates({
    required Object? rule_defs,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.load_grammar",
        "ApplyTemplates",
        ApplyTemplates.from,
        <Object?>[
          rule_defs,
        ],
        <String, Object?>{},
      );

  ApplyTemplates.from(super.pythonClass) : super.from();

  /// ## template_usage
  ///
  /// ### python source
  /// ```py
  /// def template_usage(self, c):
  ///         name = c[0].name
  ///         args = c[1:]
  ///         result_name = "%s{%s}" % (name, ",".join(a.name for a in args))
  ///         if result_name not in self.created_templates:
  ///             self.created_templates.add(result_name)
  ///             (_n, params, tree, options) ,= (t for t in self.rule_defs if t[0] == name)
  ///             assert len(params) == len(args), args
  ///             result_tree = deepcopy(tree)
  ///             self.replacer.names = dict(zip(params, args))
  ///             self.replacer.transform(result_tree)
  ///             self.rule_defs.append((result_name, [], result_tree, deepcopy(options)))
  ///         return NonTerminal(result_name)
  /// ```
  Object? template_usage({
    required Object? c,
  }) =>
      getFunction("template_usage").call(
        <Object?>[
          c,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## transform
  ///
  /// ### python docstring
  ///
  /// Transform the given tree, and return the final result
  ///
  /// ### python source
  /// ```py
  /// def transform(self, tree: Tree[_Leaf_T]) -> _Return_T:
  ///         for subtree in tree.iter_subtrees():
  ///             subtree.children = list(self._transform_children(subtree.children))
  ///
  ///         return self._transform_tree(tree)
  /// ```
  Object? transform({
    required Object? tree,
  }) =>
      getFunction("transform").call(
        <Object?>[
          tree,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## rule_defs (getter)
  Object? get rule_defs => getAttribute("rule_defs");

  /// ## rule_defs (setter)
  set rule_defs(Object? rule_defs) => setAttribute("rule_defs", rule_defs);

  /// ## replacer (getter)
  Object? get replacer => getAttribute("replacer");

  /// ## replacer (setter)
  set replacer(Object? replacer) => setAttribute("replacer", replacer);

  /// ## created_templates (getter)
  Object? get created_templates => getAttribute("created_templates");

  /// ## created_templates (setter)
  set created_templates(Object? created_templates) =>
      setAttribute("created_templates", created_templates);
}

/// ## Definition
///
/// ### python source
/// ```py
/// class Definition:
///     def __init__(self, is_term, tree, params=(), options=None):
///         self.is_term = is_term
///         self.tree = tree
///         self.params = tuple(params)
///         self.options = options
/// ```
final class Definition extends PythonClass {
  factory Definition({
    required Object? is_term,
    required Object? tree,
    Object? params = const [],
    Object? options,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.load_grammar",
        "Definition",
        Definition.from,
        <Object?>[
          is_term,
          tree,
          params,
          options,
        ],
        <String, Object?>{},
      );

  Definition.from(super.pythonClass) : super.from();

  /// ## is_term (getter)
  Object? get is_term => getAttribute("is_term");

  /// ## is_term (setter)
  set is_term(Object? is_term) => setAttribute("is_term", is_term);

  /// ## tree (getter)
  Object? get tree => getAttribute("tree");

  /// ## tree (setter)
  set tree(Object? tree) => setAttribute("tree", tree);

  /// ## params (getter)
  Object? get params => getAttribute("params");

  /// ## params (setter)
  set params(Object? params) => setAttribute("params", params);

  /// ## options (getter)
  Object? get options => getAttribute("options");

  /// ## options (setter)
  set options(Object? options) => setAttribute("options", options);
}

/// ## EBNF_to_BNF
///
/// ### python docstring
///
/// Same as Transformer, but non-recursive, and changes the tree in-place instead of returning new instances
///
/// Useful for huge trees. Conservative in memory.
///
/// ### python source
/// ```py
/// @inline_args
/// class EBNF_to_BNF(Transformer_InPlace):
///     def __init__(self):
///         self.new_rules = []
///         self.rules_cache = {}
///         self.prefix = 'anon'
///         self.i = 0
///         self.rule_options = None
///
///     def _name_rule(self, inner):
///         new_name = '__%s_%s_%d' % (self.prefix, inner, self.i)
///         self.i += 1
///         return new_name
///
///     def _add_rule(self, key, name, expansions):
///         t = NonTerminal(name)
///         self.new_rules.append((name, expansions, self.rule_options))
///         self.rules_cache[key] = t
///         return t
///
///     def _add_recurse_rule(self, type_, expr):
///         try:
///             return self.rules_cache[expr]
///         except KeyError:
///             new_name = self._name_rule(type_)
///             t = NonTerminal(new_name)
///             tree = ST('expansions', [
///                 ST('expansion', [expr]),
///                 ST('expansion', [t, expr])
///             ])
///             return self._add_rule(expr, new_name, tree)
///
///     def _add_repeat_rule(self, a, b, target, atom):
///         """Generate a rule that repeats target ``a`` times, and repeats atom ``b`` times.
///
///         When called recursively (into target), it repeats atom for x(n) times, where:
///             x(0) = 1
///             x(n) = a(n) * x(n-1) + b
///
///         Example rule when a=3, b=4:
///
///             new_rule: target target target atom atom atom atom
///
///         """
///         key = (a, b, target, atom)
///         try:
///             return self.rules_cache[key]
///         except KeyError:
///             new_name = self._name_rule('repeat_a%d_b%d' % (a, b))
///             tree = ST('expansions', [ST('expansion', [target] * a + [atom] * b)])
///             return self._add_rule(key, new_name, tree)
///
///     def _add_repeat_opt_rule(self, a, b, target, target_opt, atom):
///         """Creates a rule that matches atom 0 to (a*n+b)-1 times.
///
///         When target matches n times atom, and target_opt 0 to n-1 times target_opt,
///
///         First we generate target * i followed by target_opt, for i from 0 to a-1
///         These match 0 to n*a - 1 times atom
///
///         Then we generate target * a followed by atom * i, for i from 0 to b-1
///         These match n*a to n*a + b-1 times atom
///
///         The created rule will not have any shift/reduce conflicts so that it can be used with lalr
///
///         Example rule when a=3, b=4:
///
///             new_rule: target_opt
///                     | target target_opt
///                     | target target target_opt
///
///                     | target target target
///                     | target target target atom
///                     | target target target atom atom
///                     | target target target atom atom atom
///
///         """
///         key = (a, b, target, atom, "opt")
///         try:
///             return self.rules_cache[key]
///         except KeyError:
///             new_name = self._name_rule('repeat_a%d_b%d_opt' % (a, b))
///             tree = ST('expansions', [
///                 ST('expansion', [target]*i + [target_opt]) for i in range(a)
///             ] + [
///                 ST('expansion', [target]*a + [atom]*i) for i in range(b)
///             ])
///             return self._add_rule(key, new_name, tree)
///
///     def _generate_repeats(self, rule, mn, mx):
///         """Generates a rule tree that repeats ``rule`` exactly between ``mn`` to ``mx`` times.
///         """
///         # For a small number of repeats, we can take the naive approach
///         if mx < REPEAT_BREAK_THRESHOLD:
///             return ST('expansions', [ST('expansion', [rule] * n) for n in range(mn, mx + 1)])
///
///         # For large repeat values, we break the repetition into sub-rules.
///         # We treat ``rule~mn..mx`` as ``rule~mn rule~0..(diff=mx-mn)``.
///         # We then use small_factors to split up mn and diff up into values [(a, b), ...]
///         # This values are used with the help of _add_repeat_rule and _add_repeat_rule_opt
///         # to generate a complete rule/expression that matches the corresponding number of repeats
///         mn_target = rule
///         for a, b in small_factors(mn, SMALL_FACTOR_THRESHOLD):
///             mn_target = self._add_repeat_rule(a, b, mn_target, rule)
///         if mx == mn:
///             return mn_target
///
///         diff = mx - mn + 1  # We add one because _add_repeat_opt_rule generates rules that match one less
///         diff_factors = small_factors(diff, SMALL_FACTOR_THRESHOLD)
///         diff_target = rule  # Match rule 1 times
///         diff_opt_target = ST('expansion', [])  # match rule 0 times (e.g. up to 1 -1 times)
///         for a, b in diff_factors[:-1]:
///             diff_opt_target = self._add_repeat_opt_rule(a, b, diff_target, diff_opt_target, rule)
///             diff_target = self._add_repeat_rule(a, b, diff_target, rule)
///
///         a, b = diff_factors[-1]
///         diff_opt_target = self._add_repeat_opt_rule(a, b, diff_target, diff_opt_target, rule)
///
///         return ST('expansions', [ST('expansion', [mn_target] + [diff_opt_target])])
///
///     def expr(self, rule, op, *args):
///         if op.value == '?':
///             empty = ST('expansion', [])
///             return ST('expansions', [rule, empty])
///         elif op.value == '+':
///             # a : b c+ d
///             #   -->
///             # a : b _c d
///             # _c : _c c | c;
///             return self._add_recurse_rule('plus', rule)
///         elif op.value == '*':
///             # a : b c* d
///             #   -->
///             # a : b _c? d
///             # _c : _c c | c;
///             new_name = self._add_recurse_rule('star', rule)
///             return ST('expansions', [new_name, ST('expansion', [])])
///         elif op.value == '~':
///             if len(args) == 1:
///                 mn = mx = int(args[0])
///             else:
///                 mn, mx = map(int, args)
///                 if mx < mn or mn < 0:
///                     raise GrammarError("Bad Range for %s (%d..%d isn't allowed)" % (rule, mn, mx))
///
///             return self._generate_repeats(rule, mn, mx)
///
///         assert False, op
///
///     def maybe(self, rule):
///         keep_all_tokens = self.rule_options and self.rule_options.keep_all_tokens
///         rule_size = FindRuleSize(keep_all_tokens).transform(rule)
///         empty = ST('expansion', [_EMPTY] * rule_size)
///         return ST('expansions', [rule, empty])
/// ```
final class EBNF_to_BNF extends PythonClass {
  factory EBNF_to_BNF() => PythonFfiDart.instance.importClass(
        "lark.load_grammar",
        "EBNF_to_BNF",
        EBNF_to_BNF.from,
        <Object?>[],
        <String, Object?>{},
      );

  EBNF_to_BNF.from(super.pythonClass) : super.from();

  /// ## transform
  ///
  /// ### python docstring
  ///
  /// Transform the given tree, and return the final result
  ///
  /// ### python source
  /// ```py
  /// def transform(self, tree: Tree[_Leaf_T]) -> _Return_T:
  ///         for subtree in tree.iter_subtrees():
  ///             subtree.children = list(self._transform_children(subtree.children))
  ///
  ///         return self._transform_tree(tree)
  /// ```
  Object? transform({
    required Object? tree,
  }) =>
      getFunction("transform").call(
        <Object?>[
          tree,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## expr (getter)
  Object? get expr => getAttribute("expr");

  /// ## expr (setter)
  set expr(Object? expr) => setAttribute("expr", expr);

  /// ## maybe (getter)
  Object? get maybe => getAttribute("maybe");

  /// ## maybe (setter)
  set maybe(Object? maybe) => setAttribute("maybe", maybe);

  /// ## new_rules (getter)
  Object? get new_rules => getAttribute("new_rules");

  /// ## new_rules (setter)
  set new_rules(Object? new_rules) => setAttribute("new_rules", new_rules);

  /// ## rules_cache (getter)
  Object? get rules_cache => getAttribute("rules_cache");

  /// ## rules_cache (setter)
  set rules_cache(Object? rules_cache) =>
      setAttribute("rules_cache", rules_cache);

  /// ## prefix (getter)
  Object? get prefix => getAttribute("prefix");

  /// ## prefix (setter)
  set prefix(Object? prefix) => setAttribute("prefix", prefix);

  /// ## i (getter)
  Object? get i => getAttribute("i");

  /// ## i (setter)
  set i(Object? i) => setAttribute("i", i);

  /// ## rule_options (getter)
  Object? get rule_options => getAttribute("rule_options");

  /// ## rule_options (setter)
  set rule_options(Object? rule_options) =>
      setAttribute("rule_options", rule_options);
}

/// ## FindRuleSize
///
/// ### python docstring
///
/// Transformers work bottom-up (or depth-first), starting with visiting the leaves and working
/// their way up until ending at the root of the tree.
///
/// For each node visited, the transformer will call the appropriate method (callbacks), according to the
/// node's ``data``, and use the returned value to replace the node, thereby creating a new tree structure.
///
/// Transformers can be used to implement map & reduce patterns. Because nodes are reduced from leaf to root,
/// at any point the callbacks may assume the children have already been transformed (if applicable).
///
/// If the transformer cannot find a method with the right name, it will instead call ``__default__``, which by
/// default creates a copy of the node.
///
/// To discard a node, return Discard (``lark.visitors.Discard``).
///
/// ``Transformer`` can do anything ``Visitor`` can do, but because it reconstructs the tree,
/// it is slightly less efficient.
///
/// A transformer without methods essentially performs a non-memoized partial deepcopy.
///
/// All these classes implement the transformer interface:
///
/// - ``Transformer`` - Recursively transforms the tree. This is the one you probably want.
/// - ``Transformer_InPlace`` - Non-recursive. Changes the tree in-place instead of returning new instances
/// - ``Transformer_InPlaceRecursive`` - Recursive. Changes the tree in-place instead of returning new instances
///
/// Parameters:
///     visit_tokens (bool, optional): Should the transformer visit tokens in addition to rules.
///                                    Setting this to ``False`` is slightly faster. Defaults to ``True``.
///                                    (For processing ignored tokens, use the ``lexer_callbacks`` options)
///
/// ### python source
/// ```py
/// class FindRuleSize(Transformer):
///     def __init__(self, keep_all_tokens):
///         self.keep_all_tokens = keep_all_tokens
///
///     def _will_not_get_removed(self, sym):
///         if isinstance(sym, NonTerminal):
///             return not sym.name.startswith('_')
///         if isinstance(sym, Terminal):
///             return self.keep_all_tokens or not sym.filter_out
///         if sym is _EMPTY:
///             return False
///         assert False, sym
///
///     def _args_as_int(self, args):
///         for a in args:
///             if isinstance(a, int):
///                 yield a
///             elif isinstance(a, Symbol):
///                 yield 1 if self._will_not_get_removed(a) else 0
///             else:
///                 assert False
///
///     def expansion(self, args):
///         return sum(self._args_as_int(args))
///
///     def expansions(self, args):
///         return max(self._args_as_int(args))
/// ```
final class FindRuleSize extends PythonClass {
  factory FindRuleSize({
    required Object? keep_all_tokens,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.load_grammar",
        "FindRuleSize",
        FindRuleSize.from,
        <Object?>[
          keep_all_tokens,
        ],
        <String, Object?>{},
      );

  FindRuleSize.from(super.pythonClass) : super.from();

  /// ## expansion
  ///
  /// ### python source
  /// ```py
  /// def expansion(self, args):
  ///         return sum(self._args_as_int(args))
  /// ```
  Object? expansion({
    required Object? args,
  }) =>
      getFunction("expansion").call(
        <Object?>[
          args,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## expansions
  ///
  /// ### python source
  /// ```py
  /// def expansions(self, args):
  ///         return max(self._args_as_int(args))
  /// ```
  Object? expansions({
    required Object? args,
  }) =>
      getFunction("expansions").call(
        <Object?>[
          args,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## transform
  ///
  /// ### python docstring
  ///
  /// Transform the given tree, and return the final result
  ///
  /// ### python source
  /// ```py
  /// def transform(self, tree: Tree[_Leaf_T]) -> _Return_T:
  ///         "Transform the given tree, and return the final result"
  ///         return self._transform_tree(tree)
  /// ```
  Object? transform({
    required Object? tree,
  }) =>
      getFunction("transform").call(
        <Object?>[
          tree,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## keep_all_tokens (getter)
  Object? get keep_all_tokens => getAttribute("keep_all_tokens");

  /// ## keep_all_tokens (setter)
  set keep_all_tokens(Object? keep_all_tokens) =>
      setAttribute("keep_all_tokens", keep_all_tokens);
}

/// ## GrammarBuilder
///
/// ### python source
/// ```py
/// class GrammarBuilder:
///
///     global_keep_all_tokens: bool
///     import_paths: List[Union[str, Callable]]
///     used_files: Dict[str, str]
///
///     _definitions: Dict[str, Definition]
///     _ignore_names: List[str]
///
///     def __init__(self, global_keep_all_tokens: bool=False, import_paths: Optional[List[Union[str, Callable]]]=None, used_files: Optional[Dict[str, str]]=None) -> None:
///         self.global_keep_all_tokens = global_keep_all_tokens
///         self.import_paths = import_paths or []
///         self.used_files = used_files or {}
///
///         self._definitions: Dict[str, Definition] = {}
///         self._ignore_names: List[str] = []
///
///     def _grammar_error(self, is_term, msg, *names):
///         args = {}
///         for i, name in enumerate(names, start=1):
///             postfix = '' if i == 1 else str(i)
///             args['name' + postfix] = name
///             args['type' + postfix] = lowercase_type = ("rule", "terminal")[is_term]
///             args['Type' + postfix] = lowercase_type.title()
///         raise GrammarError(msg.format(**args))
///
///     def _check_options(self, is_term, options):
///         if is_term:
///             if options is None:
///                 options = 1
///             elif not isinstance(options, int):
///                 raise GrammarError("Terminal require a single int as 'options' (e.g. priority), got %s" % (type(options),))
///         else:
///             if options is None:
///                 options = RuleOptions()
///             elif not isinstance(options, RuleOptions):
///                 raise GrammarError("Rules require a RuleOptions instance as 'options'")
///             if self.global_keep_all_tokens:
///                 options.keep_all_tokens = True
///         return options
///
///
///     def _define(self, name, is_term, exp, params=(), options=None, *, override=False):
///         if name in self._definitions:
///             if not override:
///                 self._grammar_error(is_term, "{Type} '{name}' defined more than once", name)
///         elif override:
///             self._grammar_error(is_term, "Cannot override a nonexisting {type} {name}", name)
///
///         if name.startswith('__'):
///             self._grammar_error(is_term, 'Names starting with double-underscore are reserved (Error at {name})', name)
///
///         self._definitions[name] = Definition(is_term, exp, params, self._check_options(is_term, options))
///
///     def _extend(self, name, is_term, exp, params=(), options=None):
///         if name not in self._definitions:
///             self._grammar_error(is_term, "Can't extend {type} {name} as it wasn't defined before", name)
///
///         d = self._definitions[name]
///
///         if is_term != d.is_term:
///             self._grammar_error(is_term, "Cannot extend {type} {name} - one is a terminal, while the other is not.", name)
///         if tuple(params) != d.params:
///             self._grammar_error(is_term, "Cannot extend {type} with different parameters: {name}", name)
///
///         if d.tree is None:
///             self._grammar_error(is_term, "Can't extend {type} {name} - it is abstract.", name)
///
///         # TODO: think about what to do with 'options'
///         base = d.tree
///
///         assert isinstance(base, Tree) and base.data == 'expansions'
///         base.children.insert(0, exp)
///
///     def _ignore(self, exp_or_name):
///         if isinstance(exp_or_name, str):
///             self._ignore_names.append(exp_or_name)
///         else:
///             assert isinstance(exp_or_name, Tree)
///             t = exp_or_name
///             if t.data == 'expansions' and len(t.children) == 1:
///                 t2 ,= t.children
///                 if t2.data=='expansion' and len(t2.children) == 1:
///                     item ,= t2.children
///                     if item.data == 'value':
///                         item ,= item.children
///                         if isinstance(item, Terminal):
///                             # Keep terminal name, no need to create a new definition
///                             self._ignore_names.append(item.name)
///                             return
///
///             name = '__IGNORE_%d'% len(self._ignore_names)
///             self._ignore_names.append(name)
///             self._definitions[name] = Definition(True, t, options=TOKEN_DEFAULT_PRIORITY)
///
///     def _unpack_import(self, stmt, grammar_name):
///         if len(stmt.children) > 1:
///             path_node, arg1 = stmt.children
///         else:
///             path_node, = stmt.children
///             arg1 = None
///
///         if isinstance(arg1, Tree):  # Multi import
///             dotted_path = tuple(path_node.children)
///             names = arg1.children
///             aliases = dict(zip(names, names))  # Can't have aliased multi import, so all aliases will be the same as names
///         else:  # Single import
///             dotted_path = tuple(path_node.children[:-1])
///             if not dotted_path:
///                 name ,= path_node.children
///                 raise GrammarError("Nothing was imported from grammar `%s`" % name)
///             name = path_node.children[-1]  # Get name from dotted path
///             aliases = {name.value: (arg1 or name).value}  # Aliases if exist
///
///         if path_node.data == 'import_lib':  # Import from library
///             base_path = None
///         else:  # Relative import
///             if grammar_name == '<string>':  # Import relative to script file path if grammar is coded in script
///                 try:
///                     base_file = os.path.abspath(sys.modules['__main__'].__file__)
///                 except AttributeError:
///                     base_file = None
///             else:
///                 base_file = grammar_name  # Import relative to grammar file path if external grammar file
///             if base_file:
///                 if isinstance(base_file, PackageResource):
///                     base_path = PackageResource(base_file.pkg_name, os.path.split(base_file.path)[0])
///                 else:
///                     base_path = os.path.split(base_file)[0]
///             else:
///                 base_path = os.path.abspath(os.path.curdir)
///
///         return dotted_path, base_path, aliases
///
///     def _unpack_definition(self, tree, mangle):
///
///         if tree.data == 'rule':
///             name, params, exp, opts = _make_rule_tuple(*tree.children)
///             is_term = False
///         else:
///             name = tree.children[0].value
///             params = ()     # TODO terminal templates
///             opts = int(tree.children[1]) if len(tree.children) == 3 else TOKEN_DEFAULT_PRIORITY # priority
///             exp = tree.children[-1]
///             is_term = True
///
///         if mangle is not None:
///             params = tuple(mangle(p) for p in params)
///             name = mangle(name)
///
///         exp = _mangle_definition_tree(exp, mangle)
///         return name, is_term, exp, params, opts
///
///
///     def load_grammar(self, grammar_text: str, grammar_name: str="<?>", mangle: Optional[Callable[[str], str]]=None) -> None:
///         tree = _parse_grammar(grammar_text, grammar_name)
///
///         imports: Dict[Tuple[str, ...], Tuple[Optional[str], Dict[str, str]]] = {}
///
///         for stmt in tree.children:
///             if stmt.data == 'import':
///                 dotted_path, base_path, aliases = self._unpack_import(stmt, grammar_name)
///                 try:
///                     import_base_path, import_aliases = imports[dotted_path]
///                     assert base_path == import_base_path, 'Inconsistent base_path for %s.' % '.'.join(dotted_path)
///                     import_aliases.update(aliases)
///                 except KeyError:
///                     imports[dotted_path] = base_path, aliases
///
///         for dotted_path, (base_path, aliases) in imports.items():
///             self.do_import(dotted_path, base_path, aliases, mangle)
///
///         for stmt in tree.children:
///             if stmt.data in ('term', 'rule'):
///                 self._define(*self._unpack_definition(stmt, mangle))
///             elif stmt.data == 'override':
///                 r ,= stmt.children
///                 self._define(*self._unpack_definition(r, mangle), override=True)
///             elif stmt.data == 'extend':
///                 r ,= stmt.children
///                 self._extend(*self._unpack_definition(r, mangle))
///             elif stmt.data == 'ignore':
///                 # if mangle is not None, we shouldn't apply ignore, since we aren't in a toplevel grammar
///                 if mangle is None:
///                     self._ignore(*stmt.children)
///             elif stmt.data == 'declare':
///                 for symbol in stmt.children:
///                     assert isinstance(symbol, Symbol), symbol
///                     is_term = isinstance(symbol, Terminal)
///                     if mangle is None:
///                         name = symbol.name
///                     else:
///                         name = mangle(symbol.name)
///                     self._define(name, is_term, None)
///             elif stmt.data == 'import':
///                 pass
///             else:
///                 assert False, stmt
///
///
///         term_defs = { name: d.tree
///             for name, d in self._definitions.items()
///             if d.is_term
///         }
///         resolve_term_references(term_defs)
///
///
///     def _remove_unused(self, used):
///         def rule_dependencies(symbol):
///             try:
///                 d = self._definitions[symbol]
///             except KeyError:
///                 return []
///             if d.is_term:
///                 return []
///             return _find_used_symbols(d.tree) - set(d.params)
///
///         _used = set(bfs(used, rule_dependencies))
///         self._definitions = {k: v for k, v in self._definitions.items() if k in _used}
///
///
///     def do_import(self, dotted_path: Tuple[str, ...], base_path: Optional[str], aliases: Dict[str, str], base_mangle: Optional[Callable[[str], str]]=None) -> None:
///         assert dotted_path
///         mangle = _get_mangle('__'.join(dotted_path), aliases, base_mangle)
///         grammar_path = os.path.join(*dotted_path) + EXT
///         to_try = self.import_paths + ([base_path] if base_path is not None else []) + [stdlib_loader]
///         for source in to_try:
///             try:
///                 if callable(source):
///                     joined_path, text = source(base_path, grammar_path)
///                 else:
///                     joined_path = os.path.join(source, grammar_path)
///                     with open(joined_path, encoding='utf8') as f:
///                         text = f.read()
///             except IOError:
///                 continue
///             else:
///                 h = md5_digest(text)
///                 if self.used_files.get(joined_path, h) != h:
///                     raise RuntimeError("Grammar file was changed during importing")
///                 self.used_files[joined_path] = h
///
///                 gb = GrammarBuilder(self.global_keep_all_tokens, self.import_paths, self.used_files)
///                 gb.load_grammar(text, joined_path, mangle)
///                 gb._remove_unused(map(mangle, aliases))
///                 for name in gb._definitions:
///                     if name in self._definitions:
///                         raise GrammarError("Cannot import '%s' from '%s': Symbol already defined." % (name, grammar_path))
///
///                 self._definitions.update(**gb._definitions)
///                 break
///         else:
///             # Search failed. Make Python throw a nice error.
///             open(grammar_path, encoding='utf8')
///             assert False, "Couldn't import grammar %s, but a corresponding file was found at a place where lark doesn't search for it" % (dotted_path,)
///
///
///     def validate(self) -> None:
///         for name, d in self._definitions.items():
///             params = d.params
///             exp = d.tree
///
///             for i, p in enumerate(params):
///                 if p in self._definitions:
///                     raise GrammarError("Template Parameter conflicts with rule %s (in template %s)" % (p, name))
///                 if p in params[:i]:
///                     raise GrammarError("Duplicate Template Parameter %s (in template %s)" % (p, name))
///
///             if exp is None: # Remaining checks don't apply to abstract rules/terminals (created with %declare)
///                 continue
///
///             for temp in exp.find_data('template_usage'):
///                 sym = temp.children[0].name
///                 args = temp.children[1:]
///                 if sym not in params:
///                     if sym not in self._definitions:
///                         self._grammar_error(d.is_term, "Template '%s' used but not defined (in {type} {name})" % sym, name)
///                     if len(args) != len(self._definitions[sym].params):
///                         expected, actual = len(self._definitions[sym].params), len(args)
///                         self._grammar_error(d.is_term, "Wrong number of template arguments used for {name} "
///                                             "(expected %s, got %s) (in {type2} {name2})" % (expected, actual), sym, name)
///
///             for sym in _find_used_symbols(exp):
///                 if sym not in self._definitions and sym not in params:
///                     self._grammar_error(d.is_term, "{Type} '{name}' used but not defined (in {type2} {name2})", sym, name)
///
///         if not set(self._definitions).issuperset(self._ignore_names):
///             raise GrammarError("Terminals %s were marked to ignore but were not defined!" % (set(self._ignore_names) - set(self._definitions)))
///
///     def build(self) -> Grammar:
///         self.validate()
///         rule_defs = []
///         term_defs = []
///         for name, d in self._definitions.items():
///             (params, exp, options) = d.params, d.tree, d.options
///             if d.is_term:
///                 assert len(params) == 0
///                 term_defs.append((name, (exp, options)))
///             else:
///                 rule_defs.append((name, params, exp, options))
///         # resolve_term_references(term_defs)
///         return Grammar(rule_defs, term_defs, self._ignore_names)
/// ```
final class GrammarBuilder extends PythonClass {
  factory GrammarBuilder({
    Object? global_keep_all_tokens = false,
    Object? import_paths,
    Object? used_files,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.load_grammar",
        "GrammarBuilder",
        GrammarBuilder.from,
        <Object?>[
          global_keep_all_tokens,
          import_paths,
          used_files,
        ],
        <String, Object?>{},
      );

  GrammarBuilder.from(super.pythonClass) : super.from();

  /// ## build
  ///
  /// ### python source
  /// ```py
  /// def build(self) -> Grammar:
  ///         self.validate()
  ///         rule_defs = []
  ///         term_defs = []
  ///         for name, d in self._definitions.items():
  ///             (params, exp, options) = d.params, d.tree, d.options
  ///             if d.is_term:
  ///                 assert len(params) == 0
  ///                 term_defs.append((name, (exp, options)))
  ///             else:
  ///                 rule_defs.append((name, params, exp, options))
  ///         # resolve_term_references(term_defs)
  ///         return Grammar(rule_defs, term_defs, self._ignore_names)
  /// ```
  Object? build() => getFunction("build").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## do_import
  ///
  /// ### python source
  /// ```py
  /// def do_import(self, dotted_path: Tuple[str, ...], base_path: Optional[str], aliases: Dict[str, str], base_mangle: Optional[Callable[[str], str]]=None) -> None:
  ///         assert dotted_path
  ///         mangle = _get_mangle('__'.join(dotted_path), aliases, base_mangle)
  ///         grammar_path = os.path.join(*dotted_path) + EXT
  ///         to_try = self.import_paths + ([base_path] if base_path is not None else []) + [stdlib_loader]
  ///         for source in to_try:
  ///             try:
  ///                 if callable(source):
  ///                     joined_path, text = source(base_path, grammar_path)
  ///                 else:
  ///                     joined_path = os.path.join(source, grammar_path)
  ///                     with open(joined_path, encoding='utf8') as f:
  ///                         text = f.read()
  ///             except IOError:
  ///                 continue
  ///             else:
  ///                 h = md5_digest(text)
  ///                 if self.used_files.get(joined_path, h) != h:
  ///                     raise RuntimeError("Grammar file was changed during importing")
  ///                 self.used_files[joined_path] = h
  ///
  ///                 gb = GrammarBuilder(self.global_keep_all_tokens, self.import_paths, self.used_files)
  ///                 gb.load_grammar(text, joined_path, mangle)
  ///                 gb._remove_unused(map(mangle, aliases))
  ///                 for name in gb._definitions:
  ///                     if name in self._definitions:
  ///                         raise GrammarError("Cannot import '%s' from '%s': Symbol already defined." % (name, grammar_path))
  ///
  ///                 self._definitions.update(**gb._definitions)
  ///                 break
  ///         else:
  ///             # Search failed. Make Python throw a nice error.
  ///             open(grammar_path, encoding='utf8')
  ///             assert False, "Couldn't import grammar %s, but a corresponding file was found at a place where lark doesn't search for it" % (dotted_path,)
  /// ```
  Object? do_import({
    required Object? dotted_path,
    required Object? base_path,
    required Object? aliases,
    Object? base_mangle,
  }) =>
      getFunction("do_import").call(
        <Object?>[
          dotted_path,
          base_path,
          aliases,
          base_mangle,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## load_grammar
  ///
  /// ### python source
  /// ```py
  /// def load_grammar(self, grammar_text: str, grammar_name: str="<?>", mangle: Optional[Callable[[str], str]]=None) -> None:
  ///         tree = _parse_grammar(grammar_text, grammar_name)
  ///
  ///         imports: Dict[Tuple[str, ...], Tuple[Optional[str], Dict[str, str]]] = {}
  ///
  ///         for stmt in tree.children:
  ///             if stmt.data == 'import':
  ///                 dotted_path, base_path, aliases = self._unpack_import(stmt, grammar_name)
  ///                 try:
  ///                     import_base_path, import_aliases = imports[dotted_path]
  ///                     assert base_path == import_base_path, 'Inconsistent base_path for %s.' % '.'.join(dotted_path)
  ///                     import_aliases.update(aliases)
  ///                 except KeyError:
  ///                     imports[dotted_path] = base_path, aliases
  ///
  ///         for dotted_path, (base_path, aliases) in imports.items():
  ///             self.do_import(dotted_path, base_path, aliases, mangle)
  ///
  ///         for stmt in tree.children:
  ///             if stmt.data in ('term', 'rule'):
  ///                 self._define(*self._unpack_definition(stmt, mangle))
  ///             elif stmt.data == 'override':
  ///                 r ,= stmt.children
  ///                 self._define(*self._unpack_definition(r, mangle), override=True)
  ///             elif stmt.data == 'extend':
  ///                 r ,= stmt.children
  ///                 self._extend(*self._unpack_definition(r, mangle))
  ///             elif stmt.data == 'ignore':
  ///                 # if mangle is not None, we shouldn't apply ignore, since we aren't in a toplevel grammar
  ///                 if mangle is None:
  ///                     self._ignore(*stmt.children)
  ///             elif stmt.data == 'declare':
  ///                 for symbol in stmt.children:
  ///                     assert isinstance(symbol, Symbol), symbol
  ///                     is_term = isinstance(symbol, Terminal)
  ///                     if mangle is None:
  ///                         name = symbol.name
  ///                     else:
  ///                         name = mangle(symbol.name)
  ///                     self._define(name, is_term, None)
  ///             elif stmt.data == 'import':
  ///                 pass
  ///             else:
  ///                 assert False, stmt
  ///
  ///
  ///         term_defs = { name: d.tree
  ///             for name, d in self._definitions.items()
  ///             if d.is_term
  ///         }
  ///         resolve_term_references(term_defs)
  /// ```
  Object? load_grammar({
    required Object? grammar_text,
    Object? grammar_name = "<?>",
    Object? mangle,
  }) =>
      getFunction("load_grammar").call(
        <Object?>[
          grammar_text,
          grammar_name,
          mangle,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## validate
  ///
  /// ### python source
  /// ```py
  /// def validate(self) -> None:
  ///         for name, d in self._definitions.items():
  ///             params = d.params
  ///             exp = d.tree
  ///
  ///             for i, p in enumerate(params):
  ///                 if p in self._definitions:
  ///                     raise GrammarError("Template Parameter conflicts with rule %s (in template %s)" % (p, name))
  ///                 if p in params[:i]:
  ///                     raise GrammarError("Duplicate Template Parameter %s (in template %s)" % (p, name))
  ///
  ///             if exp is None: # Remaining checks don't apply to abstract rules/terminals (created with %declare)
  ///                 continue
  ///
  ///             for temp in exp.find_data('template_usage'):
  ///                 sym = temp.children[0].name
  ///                 args = temp.children[1:]
  ///                 if sym not in params:
  ///                     if sym not in self._definitions:
  ///                         self._grammar_error(d.is_term, "Template '%s' used but not defined (in {type} {name})" % sym, name)
  ///                     if len(args) != len(self._definitions[sym].params):
  ///                         expected, actual = len(self._definitions[sym].params), len(args)
  ///                         self._grammar_error(d.is_term, "Wrong number of template arguments used for {name} "
  ///                                             "(expected %s, got %s) (in {type2} {name2})" % (expected, actual), sym, name)
  ///
  ///             for sym in _find_used_symbols(exp):
  ///                 if sym not in self._definitions and sym not in params:
  ///                     self._grammar_error(d.is_term, "{Type} '{name}' used but not defined (in {type2} {name2})", sym, name)
  ///
  ///         if not set(self._definitions).issuperset(self._ignore_names):
  ///             raise GrammarError("Terminals %s were marked to ignore but were not defined!" % (set(self._ignore_names) - set(self._definitions)))
  /// ```
  Object? validate() => getFunction("validate").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## global_keep_all_tokens (getter)
  Object? get global_keep_all_tokens => getAttribute("global_keep_all_tokens");

  /// ## global_keep_all_tokens (setter)
  set global_keep_all_tokens(Object? global_keep_all_tokens) =>
      setAttribute("global_keep_all_tokens", global_keep_all_tokens);

  /// ## import_paths (getter)
  Object? get import_paths => getAttribute("import_paths");

  /// ## import_paths (setter)
  set import_paths(Object? import_paths) =>
      setAttribute("import_paths", import_paths);

  /// ## used_files (getter)
  Object? get used_files => getAttribute("used_files");

  /// ## used_files (setter)
  set used_files(Object? used_files) => setAttribute("used_files", used_files);
}

/// ## ParsingFrontend
///
/// ### python docstring
///
/// Safe-ish serialization interface that doesn't rely on Pickle
///
/// Attributes:
///     __serialize_fields__ (List[str]): Fields (aka attributes) to serialize.
///     __serialize_namespace__ (list): List of classes that deserialization is allowed to instantiate.
///                                     Should include all field types that aren't builtin types.
///
/// ### python source
/// ```py
/// class ParsingFrontend(Serialize):
///     __serialize_fields__ = 'lexer_conf', 'parser_conf', 'parser'
///
///     def __init__(self, lexer_conf, parser_conf, options, parser=None):
///         self.parser_conf = parser_conf
///         self.lexer_conf = lexer_conf
///         self.options = options
///
///         # Set-up parser
///         if parser:  # From cache
///             self.parser = parser
///         else:
///             create_parser = _parser_creators.get(parser_conf.parser_type)
///             assert create_parser is not None, "{} is not supported in standalone mode".format(
///                     parser_conf.parser_type
///                 )
///             self.parser = create_parser(lexer_conf, parser_conf, options)
///
///         # Set-up lexer
///         lexer_type = lexer_conf.lexer_type
///         self.skip_lexer = False
///         if lexer_type in ('dynamic', 'dynamic_complete'):
///             assert lexer_conf.postlex is None
///             self.skip_lexer = True
///             return
///
///         try:
///             create_lexer = {
///                 'basic': create_basic_lexer,
///                 'contextual': create_contextual_lexer,
///             }[lexer_type]
///         except KeyError:
///             assert issubclass(lexer_type, Lexer), lexer_type
///             self.lexer = _wrap_lexer(lexer_type)(lexer_conf)
///         else:
///             self.lexer = create_lexer(lexer_conf, self.parser, lexer_conf.postlex, options)
///
///         if lexer_conf.postlex:
///             self.lexer = PostLexConnector(self.lexer, lexer_conf.postlex)
///
///     def _verify_start(self, start=None):
///         if start is None:
///             start_decls = self.parser_conf.start
///             if len(start_decls) > 1:
///                 raise ConfigurationError("Lark initialized with more than 1 possible start rule. Must specify which start rule to parse", start_decls)
///             start ,= start_decls
///         elif start not in self.parser_conf.start:
///             raise ConfigurationError("Unknown start rule %s. Must be one of %r" % (start, self.parser_conf.start))
///         return start
///
///     def _make_lexer_thread(self, text):
///         cls = (self.options and self.options._plugins.get('LexerThread')) or LexerThread
///         return text if self.skip_lexer else cls.from_text(self.lexer, text)
///
///     def parse(self, text, start=None, on_error=None):
///         chosen_start = self._verify_start(start)
///         kw = {} if on_error is None else {'on_error': on_error}
///         stream = self._make_lexer_thread(text)
///         return self.parser.parse(stream, chosen_start, **kw)
///
///     def parse_interactive(self, text=None, start=None):
///         chosen_start = self._verify_start(start)
///         if self.parser_conf.parser_type != 'lalr':
///             raise ConfigurationError("parse_interactive() currently only works with parser='lalr' ")
///         stream = self._make_lexer_thread(text)
///         return self.parser.parse_interactive(stream, chosen_start)
/// ```
final class ParsingFrontend extends PythonClass {
  factory ParsingFrontend({
    required Object? lexer_conf,
    required Object? parser_conf,
    required Object? options,
    Object? parser,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parser_frontends",
        "ParsingFrontend",
        ParsingFrontend.from,
        <Object?>[
          lexer_conf,
          parser_conf,
          options,
          parser,
        ],
        <String, Object?>{},
      );

  ParsingFrontend.from(super.pythonClass) : super.from();

  /// ## memo_serialize
  ///
  /// ### python source
  /// ```py
  /// def memo_serialize(self, types_to_memoize: List) -> Any:
  ///         memo = SerializeMemoizer(types_to_memoize)
  ///         return self.serialize(memo), memo.serialize()
  /// ```
  Object? memo_serialize({
    required Object? types_to_memoize,
  }) =>
      getFunction("memo_serialize").call(
        <Object?>[
          types_to_memoize,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## parse
  ///
  /// ### python source
  /// ```py
  /// def parse(self, text, start=None, on_error=None):
  ///         chosen_start = self._verify_start(start)
  ///         kw = {} if on_error is None else {'on_error': on_error}
  ///         stream = self._make_lexer_thread(text)
  ///         return self.parser.parse(stream, chosen_start, **kw)
  /// ```
  Object? parse({
    required Object? text,
    Object? start,
    Object? on_error,
  }) =>
      getFunction("parse").call(
        <Object?>[
          text,
          start,
          on_error,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## parse_interactive
  ///
  /// ### python source
  /// ```py
  /// def parse_interactive(self, text=None, start=None):
  ///         chosen_start = self._verify_start(start)
  ///         if self.parser_conf.parser_type != 'lalr':
  ///             raise ConfigurationError("parse_interactive() currently only works with parser='lalr' ")
  ///         stream = self._make_lexer_thread(text)
  ///         return self.parser.parse_interactive(stream, chosen_start)
  /// ```
  Object? parse_interactive({
    Object? text,
    Object? start,
  }) =>
      getFunction("parse_interactive").call(
        <Object?>[
          text,
          start,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## serialize
  ///
  /// ### python source
  /// ```py
  /// def serialize(self, memo = None) -> Dict[str, Any]:
  ///         if memo and memo.in_types(self):
  ///             return {'@': memo.memoized.get(self)}
  ///
  ///         fields = getattr(self, '__serialize_fields__')
  ///         res = {f: _serialize(getattr(self, f), memo) for f in fields}
  ///         res['__type__'] = type(self).__name__
  ///         if hasattr(self, '_serialize'):
  ///             self._serialize(res, memo)  # type: ignore[attr-defined]
  ///         return res
  /// ```
  Object? serialize({
    Object? memo,
  }) =>
      getFunction("serialize").call(
        <Object?>[
          memo,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## deserialize (getter)
  Object? get deserialize => getAttribute("deserialize");

  /// ## deserialize (setter)
  set deserialize(Object? deserialize) =>
      setAttribute("deserialize", deserialize);

  /// ## parser_conf (getter)
  Object? get parser_conf => getAttribute("parser_conf");

  /// ## parser_conf (setter)
  set parser_conf(Object? parser_conf) =>
      setAttribute("parser_conf", parser_conf);

  /// ## lexer_conf (getter)
  Object? get lexer_conf => getAttribute("lexer_conf");

  /// ## lexer_conf (setter)
  set lexer_conf(Object? lexer_conf) => setAttribute("lexer_conf", lexer_conf);

  /// ## options (getter)
  Object? get options => getAttribute("options");

  /// ## options (setter)
  set options(Object? options) => setAttribute("options", options);

  /// ## parser (getter)
  Object? get parser => getAttribute("parser");

  /// ## parser (setter)
  set parser(Object? parser) => setAttribute("parser", parser);

  /// ## skip_lexer (getter)
  Object? get skip_lexer => getAttribute("skip_lexer");

  /// ## skip_lexer (setter)
  set skip_lexer(Object? skip_lexer) => setAttribute("skip_lexer", skip_lexer);

  /// ## lexer (getter)
  Object? get lexer => getAttribute("lexer");

  /// ## lexer (setter)
  set lexer(Object? lexer) => setAttribute("lexer", lexer);
}

/// ## PrepareAnonTerminals
///
/// ### python docstring
///
/// Create a unique list of anonymous terminals. Attempt to give meaningful names to them when we add them
///
/// ### python source
/// ```py
/// class PrepareAnonTerminals(Transformer_InPlace):
///     """Create a unique list of anonymous terminals. Attempt to give meaningful names to them when we add them"""
///
///     def __init__(self, terminals):
///         self.terminals = terminals
///         self.term_set = {td.name for td in self.terminals}
///         self.term_reverse = {td.pattern: td for td in terminals}
///         self.i = 0
///         self.rule_options = None
///
///     @inline_args
///     def pattern(self, p):
///         value = p.value
///         if p in self.term_reverse and p.flags != self.term_reverse[p].pattern.flags:
///             raise GrammarError(u'Conflicting flags for the same terminal: %s' % p)
///
///         term_name = None
///
///         if isinstance(p, PatternStr):
///             try:
///                 # If already defined, use the user-defined terminal name
///                 term_name = self.term_reverse[p].name
///             except KeyError:
///                 # Try to assign an indicative anon-terminal name
///                 try:
///                     term_name = _TERMINAL_NAMES[value]
///                 except KeyError:
///                     if value and is_id_continue(value) and is_id_start(value[0]) and value.upper() not in self.term_set:
///                         term_name = value.upper()
///
///                 if term_name in self.term_set:
///                     term_name = None
///
///         elif isinstance(p, PatternRE):
///             if p in self.term_reverse:  # Kind of a weird placement.name
///                 term_name = self.term_reverse[p].name
///         else:
///             assert False, p
///
///         if term_name is None:
///             term_name = '__ANON_%d' % self.i
///             self.i += 1
///
///         if term_name not in self.term_set:
///             assert p not in self.term_reverse
///             self.term_set.add(term_name)
///             termdef = TerminalDef(term_name, p)
///             self.term_reverse[p] = termdef
///             self.terminals.append(termdef)
///
///         filter_out = False if self.rule_options and self.rule_options.keep_all_tokens else isinstance(p, PatternStr)
///
///         return Terminal(term_name, filter_out=filter_out)
/// ```
final class PrepareAnonTerminals extends PythonClass {
  factory PrepareAnonTerminals({
    required Object? terminals,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.load_grammar",
        "PrepareAnonTerminals",
        PrepareAnonTerminals.from,
        <Object?>[
          terminals,
        ],
        <String, Object?>{},
      );

  PrepareAnonTerminals.from(super.pythonClass) : super.from();

  /// ## transform
  ///
  /// ### python docstring
  ///
  /// Transform the given tree, and return the final result
  ///
  /// ### python source
  /// ```py
  /// def transform(self, tree: Tree[_Leaf_T]) -> _Return_T:
  ///         for subtree in tree.iter_subtrees():
  ///             subtree.children = list(self._transform_children(subtree.children))
  ///
  ///         return self._transform_tree(tree)
  /// ```
  Object? transform({
    required Object? tree,
  }) =>
      getFunction("transform").call(
        <Object?>[
          tree,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## pattern (getter)
  Object? get pattern => getAttribute("pattern");

  /// ## pattern (setter)
  set pattern(Object? pattern) => setAttribute("pattern", pattern);

  /// ## terminals (getter)
  Object? get terminals => getAttribute("terminals");

  /// ## terminals (setter)
  set terminals(Object? terminals) => setAttribute("terminals", terminals);

  /// ## term_set (getter)
  Object? get term_set => getAttribute("term_set");

  /// ## term_set (setter)
  set term_set(Object? term_set) => setAttribute("term_set", term_set);

  /// ## term_reverse (getter)
  Object? get term_reverse => getAttribute("term_reverse");

  /// ## term_reverse (setter)
  set term_reverse(Object? term_reverse) =>
      setAttribute("term_reverse", term_reverse);

  /// ## i (getter)
  Object? get i => getAttribute("i");

  /// ## i (setter)
  set i(Object? i) => setAttribute("i", i);

  /// ## rule_options (getter)
  Object? get rule_options => getAttribute("rule_options");

  /// ## rule_options (setter)
  set rule_options(Object? rule_options) =>
      setAttribute("rule_options", rule_options);
}

/// ## PrepareGrammar
///
/// ### python docstring
///
/// Same as Transformer, but non-recursive, and changes the tree in-place instead of returning new instances
///
/// Useful for huge trees. Conservative in memory.
///
/// ### python source
/// ```py
/// @inline_args
/// class PrepareGrammar(Transformer_InPlace):
///     def terminal(self, name):
///         return Terminal(str(name), filter_out=name.startswith('_'))
///
///     def nonterminal(self, name):
///         return NonTerminal(name.value)
/// ```
final class PrepareGrammar extends PythonClass {
  factory PrepareGrammar({
    Object? visit_tokens = true,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.load_grammar",
        "PrepareGrammar",
        PrepareGrammar.from,
        <Object?>[
          visit_tokens,
        ],
        <String, Object?>{},
      );

  PrepareGrammar.from(super.pythonClass) : super.from();

  /// ## transform
  ///
  /// ### python docstring
  ///
  /// Transform the given tree, and return the final result
  ///
  /// ### python source
  /// ```py
  /// def transform(self, tree: Tree[_Leaf_T]) -> _Return_T:
  ///         for subtree in tree.iter_subtrees():
  ///             subtree.children = list(self._transform_children(subtree.children))
  ///
  ///         return self._transform_tree(tree)
  /// ```
  Object? transform({
    required Object? tree,
  }) =>
      getFunction("transform").call(
        <Object?>[
          tree,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## nonterminal (getter)
  Object? get nonterminal => getAttribute("nonterminal");

  /// ## nonterminal (setter)
  set nonterminal(Object? nonterminal) =>
      setAttribute("nonterminal", nonterminal);

  /// ## terminal (getter)
  Object? get terminal => getAttribute("terminal");

  /// ## terminal (setter)
  set terminal(Object? terminal) => setAttribute("terminal", terminal);
}

/// ## PrepareLiterals
///
/// ### python docstring
///
/// Same as Transformer, but non-recursive, and changes the tree in-place instead of returning new instances
///
/// Useful for huge trees. Conservative in memory.
///
/// ### python source
/// ```py
/// @inline_args
/// class PrepareLiterals(Transformer_InPlace):
///     def literal(self, literal):
///         return ST('pattern', [_literal_to_pattern(literal)])
///
///     def range(self, start, end):
///         assert start.type == end.type == 'STRING'
///         start = start.value[1:-1]
///         end = end.value[1:-1]
///         assert len(eval_escaping(start)) == len(eval_escaping(end)) == 1
///         regexp = '[%s-%s]' % (start, end)
///         return ST('pattern', [PatternRE(regexp)])
/// ```
final class PrepareLiterals extends PythonClass {
  factory PrepareLiterals({
    Object? visit_tokens = true,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.load_grammar",
        "PrepareLiterals",
        PrepareLiterals.from,
        <Object?>[
          visit_tokens,
        ],
        <String, Object?>{},
      );

  PrepareLiterals.from(super.pythonClass) : super.from();

  /// ## transform
  ///
  /// ### python docstring
  ///
  /// Transform the given tree, and return the final result
  ///
  /// ### python source
  /// ```py
  /// def transform(self, tree: Tree[_Leaf_T]) -> _Return_T:
  ///         for subtree in tree.iter_subtrees():
  ///             subtree.children = list(self._transform_children(subtree.children))
  ///
  ///         return self._transform_tree(tree)
  /// ```
  Object? transform({
    required Object? tree,
  }) =>
      getFunction("transform").call(
        <Object?>[
          tree,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## literal (getter)
  Object? get literal => getAttribute("literal");

  /// ## literal (setter)
  set literal(Object? literal) => setAttribute("literal", literal);

  /// ## range (getter)
  Object? get range => getAttribute("range");

  /// ## range (setter)
  set range(Object? range) => setAttribute("range", range);
}

/// ## RuleTreeToText
///
/// ### python docstring
///
/// Transformers work bottom-up (or depth-first), starting with visiting the leaves and working
/// their way up until ending at the root of the tree.
///
/// For each node visited, the transformer will call the appropriate method (callbacks), according to the
/// node's ``data``, and use the returned value to replace the node, thereby creating a new tree structure.
///
/// Transformers can be used to implement map & reduce patterns. Because nodes are reduced from leaf to root,
/// at any point the callbacks may assume the children have already been transformed (if applicable).
///
/// If the transformer cannot find a method with the right name, it will instead call ``__default__``, which by
/// default creates a copy of the node.
///
/// To discard a node, return Discard (``lark.visitors.Discard``).
///
/// ``Transformer`` can do anything ``Visitor`` can do, but because it reconstructs the tree,
/// it is slightly less efficient.
///
/// A transformer without methods essentially performs a non-memoized partial deepcopy.
///
/// All these classes implement the transformer interface:
///
/// - ``Transformer`` - Recursively transforms the tree. This is the one you probably want.
/// - ``Transformer_InPlace`` - Non-recursive. Changes the tree in-place instead of returning new instances
/// - ``Transformer_InPlaceRecursive`` - Recursive. Changes the tree in-place instead of returning new instances
///
/// Parameters:
///     visit_tokens (bool, optional): Should the transformer visit tokens in addition to rules.
///                                    Setting this to ``False`` is slightly faster. Defaults to ``True``.
///                                    (For processing ignored tokens, use the ``lexer_callbacks`` options)
///
/// ### python source
/// ```py
/// class RuleTreeToText(Transformer):
///     def expansions(self, x):
///         return x
///
///     def expansion(self, symbols):
///         return symbols, None
///
///     def alias(self, x):
///         (expansion, _alias), alias = x
///         assert _alias is None, (alias, expansion, '-', _alias)  # Double alias not allowed
///         return expansion, alias.name
/// ```
final class RuleTreeToText extends PythonClass {
  factory RuleTreeToText({
    Object? visit_tokens = true,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.load_grammar",
        "RuleTreeToText",
        RuleTreeToText.from,
        <Object?>[
          visit_tokens,
        ],
        <String, Object?>{},
      );

  RuleTreeToText.from(super.pythonClass) : super.from();

  /// ## alias
  ///
  /// ### python source
  /// ```py
  /// def alias(self, x):
  ///         (expansion, _alias), alias = x
  ///         assert _alias is None, (alias, expansion, '-', _alias)  # Double alias not allowed
  ///         return expansion, alias.name
  /// ```
  Object? alias({
    required Object? x,
  }) =>
      getFunction("alias").call(
        <Object?>[
          x,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## expansion
  ///
  /// ### python source
  /// ```py
  /// def expansion(self, symbols):
  ///         return symbols, None
  /// ```
  Object? expansion({
    required Object? symbols,
  }) =>
      getFunction("expansion").call(
        <Object?>[
          symbols,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## expansions
  ///
  /// ### python source
  /// ```py
  /// def expansions(self, x):
  ///         return x
  /// ```
  Object? expansions({
    required Object? x,
  }) =>
      getFunction("expansions").call(
        <Object?>[
          x,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## transform
  ///
  /// ### python docstring
  ///
  /// Transform the given tree, and return the final result
  ///
  /// ### python source
  /// ```py
  /// def transform(self, tree: Tree[_Leaf_T]) -> _Return_T:
  ///         "Transform the given tree, and return the final result"
  ///         return self._transform_tree(tree)
  /// ```
  Object? transform({
    required Object? tree,
  }) =>
      getFunction("transform").call(
        <Object?>[
          tree,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## ST
///
/// ### python docstring
///
/// The main tree class.
///
/// Creates a new tree, and stores "data" and "children" in attributes of the same name.
/// Trees can be hashed and compared.
///
/// Parameters:
///     data: The name of the rule or alias
///     children: List of matched sub-rules and terminals
///     meta: Line & Column numbers (if ``propagate_positions`` is enabled).
///         meta attributes: line, column, start_pos, end_line, end_column, end_pos
///
/// ### python source
/// ```py
/// class SlottedTree(Tree):
///     __slots__ = 'data', 'children', 'rule', '_meta'
/// ```
final class ST extends PythonClass {
  factory ST({
    required Object? data,
    required Object? children,
    Object? meta,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.tree",
        "ST",
        ST.from,
        <Object?>[
          data,
          children,
          meta,
        ],
        <String, Object?>{},
      );

  ST.from(super.pythonClass) : super.from();

  /// ## copy
  ///
  /// ### python source
  /// ```py
  /// def copy(self) -> 'Tree[_Leaf_T]':
  ///         return type(self)(self.data, self.children)
  /// ```
  Object? copy() => getFunction("copy").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## expand_kids_by_data
  ///
  /// ### python docstring
  ///
  /// Expand (inline) children with any of the given data values. Returns True if anything changed
  ///
  /// ### python source
  /// ```py
  /// def expand_kids_by_data(self, *data_values):
  ///         """Expand (inline) children with any of the given data values. Returns True if anything changed"""
  ///         changed = False
  ///         for i in range(len(self.children)-1, -1, -1):
  ///             child = self.children[i]
  ///             if isinstance(child, Tree) and child.data in data_values:
  ///                 self.children[i:i+1] = child.children
  ///                 changed = True
  ///         return changed
  /// ```
  Object? expand_kids_by_data({
    List<Object?> data_values = const <Object?>[],
  }) =>
      getFunction("expand_kids_by_data").call(
        <Object?>[
          ...data_values,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## find_data
  ///
  /// ### python docstring
  ///
  /// Returns all nodes of the tree whose data equals the given data.
  ///
  /// ### python source
  /// ```py
  /// def find_data(self, data: str) -> 'Iterator[Tree[_Leaf_T]]':
  ///         """Returns all nodes of the tree whose data equals the given data."""
  ///         return self.find_pred(lambda t: t.data == data)
  /// ```
  Object? find_data({
    required Object? data,
  }) =>
      getFunction("find_data").call(
        <Object?>[
          data,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## find_pred
  ///
  /// ### python docstring
  ///
  /// Returns all nodes of the tree that evaluate pred(node) as true.
  ///
  /// ### python source
  /// ```py
  /// def find_pred(self, pred: 'Callable[[Tree[_Leaf_T]], bool]') -> 'Iterator[Tree[_Leaf_T]]':
  ///         """Returns all nodes of the tree that evaluate pred(node) as true."""
  ///         return filter(pred, self.iter_subtrees())
  /// ```
  Object? find_pred({
    required Object? pred,
  }) =>
      getFunction("find_pred").call(
        <Object?>[
          pred,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## iter_subtrees
  ///
  /// ### python docstring
  ///
  /// Depth-first iteration.
  ///
  /// Iterates over all the subtrees, never returning to the same node twice (Lark's parse-tree is actually a DAG).
  ///
  /// ### python source
  /// ```py
  /// def iter_subtrees(self) -> 'Iterator[Tree[_Leaf_T]]':
  ///         """Depth-first iteration.
  ///
  ///         Iterates over all the subtrees, never returning to the same node twice (Lark's parse-tree is actually a DAG).
  ///         """
  ///         queue = [self]
  ///         subtrees = OrderedDict()
  ///         for subtree in queue:
  ///             subtrees[id(subtree)] = subtree
  ///             # Reason for type ignore https://github.com/python/mypy/issues/10999
  ///             queue += [c for c in reversed(subtree.children)  # type: ignore[misc]
  ///                       if isinstance(c, Tree) and id(c) not in subtrees]
  ///
  ///         del queue
  ///         return reversed(list(subtrees.values()))
  /// ```
  Object? iter_subtrees() => getFunction("iter_subtrees").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## iter_subtrees_topdown
  ///
  /// ### python docstring
  ///
  /// Breadth-first iteration.
  ///
  /// Iterates over all the subtrees, return nodes in order like pretty() does.
  ///
  /// ### python source
  /// ```py
  /// def iter_subtrees_topdown(self):
  ///         """Breadth-first iteration.
  ///
  ///         Iterates over all the subtrees, return nodes in order like pretty() does.
  ///         """
  ///         stack = [self]
  ///         stack_append = stack.append
  ///         stack_pop = stack.pop
  ///         while stack:
  ///             node = stack_pop()
  ///             if not isinstance(node, Tree):
  ///                 continue
  ///             yield node
  ///             for child in reversed(node.children):
  ///                 stack_append(child)
  /// ```
  Object? iter_subtrees_topdown() => getFunction("iter_subtrees_topdown").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## pretty
  ///
  /// ### python docstring
  ///
  /// Returns an indented string representation of the tree.
  ///
  /// Great for debugging.
  ///
  /// ### python source
  /// ```py
  /// def pretty(self, indent_str: str='  ') -> str:
  ///         """Returns an indented string representation of the tree.
  ///
  ///         Great for debugging.
  ///         """
  ///         return ''.join(self._pretty(0, indent_str))
  /// ```
  Object? pretty({
    Object? indent_str = "  ",
  }) =>
      getFunction("pretty").call(
        <Object?>[
          indent_str,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## scan_values
  ///
  /// ### python docstring
  ///
  /// Return all values in the tree that evaluate pred(value) as true.
  ///
  /// This can be used to find all the tokens in the tree.
  ///
  /// Example:
  ///     >>> all_tokens = tree.scan_values(lambda v: isinstance(v, Token))
  ///
  /// ### python source
  /// ```py
  /// def scan_values(self, pred: 'Callable[[Branch[_Leaf_T]], bool]') -> Iterator[_Leaf_T]:
  ///         """Return all values in the tree that evaluate pred(value) as true.
  ///
  ///         This can be used to find all the tokens in the tree.
  ///
  ///         Example:
  ///             >>> all_tokens = tree.scan_values(lambda v: isinstance(v, Token))
  ///         """
  ///         for c in self.children:
  ///             if isinstance(c, Tree):
  ///                 for t in c.scan_values(pred):
  ///                     yield t
  ///             else:
  ///                 if pred(c):
  ///                     yield c
  /// ```
  Object? scan_values({
    required Object? pred,
  }) =>
      getFunction("scan_values").call(
        <Object?>[
          pred,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## set
  ///
  /// ### python source
  /// ```py
  /// def set(self, data: str, children: 'List[Branch[_Leaf_T]]') -> None:
  ///         self.data = data
  ///         self.children = children
  /// ```
  Object? $set({
    required Object? data,
    required Object? children,
  }) =>
      getFunction("set").call(
        <Object?>[
          data,
          children,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## meta (getter)
  Object? get meta => getAttribute("meta");

  /// ## meta (setter)
  set meta(Object? meta) => setAttribute("meta", meta);

  /// ## rule (getter)
  Object? get rule => getAttribute("rule");

  /// ## rule (setter)
  set rule(Object? rule) => setAttribute("rule", rule);

  /// ## children (getter)
  Object? get children => getAttribute("children");

  /// ## children (setter)
  set children(Object? children) => setAttribute("children", children);

  /// ## data (getter)
  Object? get data => getAttribute("data");

  /// ## data (setter)
  set data(Object? data) => setAttribute("data", data);
}

/// ## SimplifyRule_Visitor
///
/// ### python docstring
///
/// Tree visitor, non-recursive (can handle huge trees).
///
/// Visiting a node calls its methods (provided by the user via inheritance) according to ``tree.data``
///
/// ### python source
/// ```py
/// class SimplifyRule_Visitor(Visitor):
///
///     @staticmethod
///     def _flatten(tree):
///         while tree.expand_kids_by_data(tree.data):
///             pass
///
///     def expansion(self, tree):
///         # rules_list unpacking
///         # a : b (c|d) e
///         #  -->
///         # a : b c e | b d e
///         #
///         # In AST terms:
///         # expansion(b, expansions(c, d), e)
///         #   -->
///         # expansions( expansion(b, c, e), expansion(b, d, e) )
///
///         self._flatten(tree)
///
///         for i, child in enumerate(tree.children):
///             if isinstance(child, Tree) and child.data == 'expansions':
///                 tree.data = 'expansions'
///                 tree.children = [self.visit(ST('expansion', [option if i == j else other
///                                                              for j, other in enumerate(tree.children)]))
///                                  for option in dedup_list(child.children)]
///                 self._flatten(tree)
///                 break
///
///     def alias(self, tree):
///         rule, alias_name = tree.children
///         if rule.data == 'expansions':
///             aliases = []
///             for child in tree.children[0].children:
///                 aliases.append(ST('alias', [child, alias_name]))
///             tree.data = 'expansions'
///             tree.children = aliases
///
///     def expansions(self, tree):
///         self._flatten(tree)
///         # Ensure all children are unique
///         if len(set(tree.children)) != len(tree.children):
///             tree.children = dedup_list(tree.children)   # dedup is expensive, so try to minimize its use
/// ```
final class SimplifyRule_Visitor extends PythonClass {
  factory SimplifyRule_Visitor() => PythonFfiDart.instance.importClass(
        "lark.load_grammar",
        "SimplifyRule_Visitor",
        SimplifyRule_Visitor.from,
        <Object?>[],
      );

  SimplifyRule_Visitor.from(super.pythonClass) : super.from();

  /// ## alias
  ///
  /// ### python source
  /// ```py
  /// def alias(self, tree):
  ///         rule, alias_name = tree.children
  ///         if rule.data == 'expansions':
  ///             aliases = []
  ///             for child in tree.children[0].children:
  ///                 aliases.append(ST('alias', [child, alias_name]))
  ///             tree.data = 'expansions'
  ///             tree.children = aliases
  /// ```
  Object? alias({
    required Object? tree,
  }) =>
      getFunction("alias").call(
        <Object?>[
          tree,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## expansion
  ///
  /// ### python source
  /// ```py
  /// def expansion(self, tree):
  ///         # rules_list unpacking
  ///         # a : b (c|d) e
  ///         #  -->
  ///         # a : b c e | b d e
  ///         #
  ///         # In AST terms:
  ///         # expansion(b, expansions(c, d), e)
  ///         #   -->
  ///         # expansions( expansion(b, c, e), expansion(b, d, e) )
  ///
  ///         self._flatten(tree)
  ///
  ///         for i, child in enumerate(tree.children):
  ///             if isinstance(child, Tree) and child.data == 'expansions':
  ///                 tree.data = 'expansions'
  ///                 tree.children = [self.visit(ST('expansion', [option if i == j else other
  ///                                                              for j, other in enumerate(tree.children)]))
  ///                                  for option in dedup_list(child.children)]
  ///                 self._flatten(tree)
  ///                 break
  /// ```
  Object? expansion({
    required Object? tree,
  }) =>
      getFunction("expansion").call(
        <Object?>[
          tree,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## expansions
  ///
  /// ### python source
  /// ```py
  /// def expansions(self, tree):
  ///         self._flatten(tree)
  ///         # Ensure all children are unique
  ///         if len(set(tree.children)) != len(tree.children):
  ///             tree.children = dedup_list(tree.children)   # dedup is expensive, so try to minimize its use
  /// ```
  Object? expansions({
    required Object? tree,
  }) =>
      getFunction("expansions").call(
        <Object?>[
          tree,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit
  ///
  /// ### python docstring
  ///
  /// Visits the tree, starting with the leaves and finally the root (bottom-up)
  ///
  /// ### python source
  /// ```py
  /// def visit(self, tree: Tree[_Leaf_T]) -> Tree[_Leaf_T]:
  ///         "Visits the tree, starting with the leaves and finally the root (bottom-up)"
  ///         for subtree in tree.iter_subtrees():
  ///             self._call_userfunc(subtree)
  ///         return tree
  /// ```
  Object? visit({
    required Object? tree,
  }) =>
      getFunction("visit").call(
        <Object?>[
          tree,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_topdown
  ///
  /// ### python docstring
  ///
  /// Visit the tree, starting at the root, and ending at the leaves (top-down)
  ///
  /// ### python source
  /// ```py
  /// def visit_topdown(self, tree: Tree[_Leaf_T]) -> Tree[_Leaf_T]:
  ///         "Visit the tree, starting at the root, and ending at the leaves (top-down)"
  ///         for subtree in tree.iter_subtrees_topdown():
  ///             self._call_userfunc(subtree)
  ///         return tree
  /// ```
  Object? visit_topdown({
    required Object? tree,
  }) =>
      getFunction("visit_topdown").call(
        <Object?>[
          tree,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## TerminalTreeToPattern
///
/// ### python docstring
///
/// Same as Transformer but non-recursive.
///
/// Like Transformer, it doesn't change the original tree.
///
/// Useful for huge trees.
///
/// ### python source
/// ```py
/// class TerminalTreeToPattern(Transformer_NonRecursive):
///     def pattern(self, ps):
///         p ,= ps
///         return p
///
///     def expansion(self, items):
///         assert items
///         if len(items) == 1:
///             return items[0]
///
///         pattern = ''.join(i.to_regexp() for i in items)
///         return _make_joined_pattern(pattern, {i.flags for i in items})
///
///     def expansions(self, exps):
///         if len(exps) == 1:
///             return exps[0]
///
///         # Do a bit of sorting to make sure that the longest option is returned
///         # (Python's re module otherwise prefers just 'l' when given (l|ll) and both could match)
///         exps.sort(key=lambda x: (-x.max_width, -x.min_width, -len(x.value)))
///
///         pattern = '(?:%s)' % ('|'.join(i.to_regexp() for i in exps))
///         return _make_joined_pattern(pattern, {i.flags for i in exps})
///
///     def expr(self, args):
///         inner, op = args[:2]
///         if op == '~':
///             if len(args) == 3:
///                 op = "{%d}" % int(args[2])
///             else:
///                 mn, mx = map(int, args[2:])
///                 if mx < mn:
///                     raise GrammarError("Bad Range for %s (%d..%d isn't allowed)" % (inner, mn, mx))
///                 op = "{%d,%d}" % (mn, mx)
///         else:
///             assert len(args) == 2
///         return PatternRE('(?:%s)%s' % (inner.to_regexp(), op), inner.flags)
///
///     def maybe(self, expr):
///         return self.expr(expr + ['?'])
///
///     def alias(self, t):
///         raise GrammarError("Aliasing not allowed in terminals (You used -> in the wrong place)")
///
///     def value(self, v):
///         return v[0]
/// ```
final class TerminalTreeToPattern extends PythonClass {
  factory TerminalTreeToPattern({
    Object? visit_tokens = true,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.load_grammar",
        "TerminalTreeToPattern",
        TerminalTreeToPattern.from,
        <Object?>[
          visit_tokens,
        ],
        <String, Object?>{},
      );

  TerminalTreeToPattern.from(super.pythonClass) : super.from();

  /// ## alias
  ///
  /// ### python source
  /// ```py
  /// def alias(self, t):
  ///         raise GrammarError("Aliasing not allowed in terminals (You used -> in the wrong place)")
  /// ```
  Object? alias({
    required Object? t,
  }) =>
      getFunction("alias").call(
        <Object?>[
          t,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## expansion
  ///
  /// ### python source
  /// ```py
  /// def expansion(self, items):
  ///         assert items
  ///         if len(items) == 1:
  ///             return items[0]
  ///
  ///         pattern = ''.join(i.to_regexp() for i in items)
  ///         return _make_joined_pattern(pattern, {i.flags for i in items})
  /// ```
  Object? expansion({
    required Object? items,
  }) =>
      getFunction("expansion").call(
        <Object?>[
          items,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## expansions
  ///
  /// ### python source
  /// ```py
  /// def expansions(self, exps):
  ///         if len(exps) == 1:
  ///             return exps[0]
  ///
  ///         # Do a bit of sorting to make sure that the longest option is returned
  ///         # (Python's re module otherwise prefers just 'l' when given (l|ll) and both could match)
  ///         exps.sort(key=lambda x: (-x.max_width, -x.min_width, -len(x.value)))
  ///
  ///         pattern = '(?:%s)' % ('|'.join(i.to_regexp() for i in exps))
  ///         return _make_joined_pattern(pattern, {i.flags for i in exps})
  /// ```
  Object? expansions({
    required Object? exps,
  }) =>
      getFunction("expansions").call(
        <Object?>[
          exps,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## expr
  ///
  /// ### python source
  /// ```py
  /// def expr(self, args):
  ///         inner, op = args[:2]
  ///         if op == '~':
  ///             if len(args) == 3:
  ///                 op = "{%d}" % int(args[2])
  ///             else:
  ///                 mn, mx = map(int, args[2:])
  ///                 if mx < mn:
  ///                     raise GrammarError("Bad Range for %s (%d..%d isn't allowed)" % (inner, mn, mx))
  ///                 op = "{%d,%d}" % (mn, mx)
  ///         else:
  ///             assert len(args) == 2
  ///         return PatternRE('(?:%s)%s' % (inner.to_regexp(), op), inner.flags)
  /// ```
  Object? expr({
    required Object? args,
  }) =>
      getFunction("expr").call(
        <Object?>[
          args,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## maybe
  ///
  /// ### python source
  /// ```py
  /// def maybe(self, expr):
  ///         return self.expr(expr + ['?'])
  /// ```
  Object? maybe({
    required Object? expr,
  }) =>
      getFunction("maybe").call(
        <Object?>[
          expr,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## pattern
  ///
  /// ### python source
  /// ```py
  /// def pattern(self, ps):
  ///         p ,= ps
  ///         return p
  /// ```
  Object? pattern({
    required Object? ps,
  }) =>
      getFunction("pattern").call(
        <Object?>[
          ps,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## transform
  ///
  /// ### python docstring
  ///
  /// Transform the given tree, and return the final result
  ///
  /// ### python source
  /// ```py
  /// def transform(self, tree: Tree[_Leaf_T]) -> _Return_T:
  ///         # Tree to postfix
  ///         rev_postfix = []
  ///         q: List[Branch[_Leaf_T]] = [tree]
  ///         while q:
  ///             t = q.pop()
  ///             rev_postfix.append(t)
  ///             if isinstance(t, Tree):
  ///                 q += t.children
  ///
  ///         # Postfix to tree
  ///         stack: List = []
  ///         for x in reversed(rev_postfix):
  ///             if isinstance(x, Tree):
  ///                 size = len(x.children)
  ///                 if size:
  ///                     args = stack[-size:]
  ///                     del stack[-size:]
  ///                 else:
  ///                     args = []
  ///
  ///                 res = self._call_userfunc(x, args)
  ///                 if res is not Discard:
  ///                     stack.append(res)
  ///
  ///             elif self.__visit_tokens__ and isinstance(x, Token):
  ///                 res = self._call_userfunc_token(x)
  ///                 if res is not Discard:
  ///                     stack.append(res)
  ///             else:
  ///                 stack.append(x)
  ///
  ///         result, = stack  # We should have only one tree remaining
  ///         # There are no guarantees on the type of the value produced by calling a user func for a
  ///         # child will produce. This means type system can't statically know that the final result is
  ///         # _Return_T. As a result a cast is required.
  ///         return cast(_Return_T, result)
  /// ```
  Object? transform({
    required Object? tree,
  }) =>
      getFunction("transform").call(
        <Object?>[
          tree,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## value
  ///
  /// ### python source
  /// ```py
  /// def value(self, v):
  ///         return v[0]
  /// ```
  Object? value({
    required Object? v,
  }) =>
      getFunction("value").call(
        <Object?>[
          v,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## Transformer_InPlace
///
/// ### python docstring
///
/// Same as Transformer, but non-recursive, and changes the tree in-place instead of returning new instances
///
/// Useful for huge trees. Conservative in memory.
///
/// ### python source
/// ```py
/// class Transformer_InPlace(Transformer):
///     """Same as Transformer, but non-recursive, and changes the tree in-place instead of returning new instances
///
///     Useful for huge trees. Conservative in memory.
///     """
///     def _transform_tree(self, tree):           # Cancel recursion
///         return self._call_userfunc(tree)
///
///     def transform(self, tree: Tree[_Leaf_T]) -> _Return_T:
///         for subtree in tree.iter_subtrees():
///             subtree.children = list(self._transform_children(subtree.children))
///
///         return self._transform_tree(tree)
/// ```
final class Transformer_InPlace extends PythonClass {
  factory Transformer_InPlace({
    Object? visit_tokens = true,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.visitors",
        "Transformer_InPlace",
        Transformer_InPlace.from,
        <Object?>[
          visit_tokens,
        ],
        <String, Object?>{},
      );

  Transformer_InPlace.from(super.pythonClass) : super.from();

  /// ## transform
  ///
  /// ### python docstring
  ///
  /// Transform the given tree, and return the final result
  ///
  /// ### python source
  /// ```py
  /// def transform(self, tree: Tree[_Leaf_T]) -> _Return_T:
  ///         for subtree in tree.iter_subtrees():
  ///             subtree.children = list(self._transform_children(subtree.children))
  ///
  ///         return self._transform_tree(tree)
  /// ```
  Object? transform({
    required Object? tree,
  }) =>
      getFunction("transform").call(
        <Object?>[
          tree,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## ValidateSymbols
///
/// ### python docstring
///
/// Same as Transformer, but non-recursive, and changes the tree in-place instead of returning new instances
///
/// Useful for huge trees. Conservative in memory.
///
/// ### python source
/// ```py
/// class ValidateSymbols(Transformer_InPlace):
///     def value(self, v):
///         v ,= v
///         assert isinstance(v, (Tree, Symbol))
///         return v
/// ```
final class ValidateSymbols extends PythonClass {
  factory ValidateSymbols({
    Object? visit_tokens = true,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.load_grammar",
        "ValidateSymbols",
        ValidateSymbols.from,
        <Object?>[
          visit_tokens,
        ],
        <String, Object?>{},
      );

  ValidateSymbols.from(super.pythonClass) : super.from();

  /// ## transform
  ///
  /// ### python docstring
  ///
  /// Transform the given tree, and return the final result
  ///
  /// ### python source
  /// ```py
  /// def transform(self, tree: Tree[_Leaf_T]) -> _Return_T:
  ///         for subtree in tree.iter_subtrees():
  ///             subtree.children = list(self._transform_children(subtree.children))
  ///
  ///         return self._transform_tree(tree)
  /// ```
  Object? transform({
    required Object? tree,
  }) =>
      getFunction("transform").call(
        <Object?>[
          tree,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## value
  ///
  /// ### python source
  /// ```py
  /// def value(self, v):
  ///         v ,= v
  ///         assert isinstance(v, (Tree, Symbol))
  ///         return v
  /// ```
  Object? value({
    required Object? v,
  }) =>
      getFunction("value").call(
        <Object?>[
          v,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## blake2b
final class blake2b extends PythonClass {
  factory blake2b() => PythonFfiDart.instance.importClass(
        "_blake2",
        "blake2b",
        blake2b.from,
        <Object?>[],
      );

  blake2b.from(super.pythonClass) : super.from();

  /// ## block_size (getter)
  Object? get block_size => getAttribute("block_size");

  /// ## block_size (setter)
  set block_size(Object? block_size) => setAttribute("block_size", block_size);

  /// ## digest_size (getter)
  Object? get digest_size => getAttribute("digest_size");

  /// ## digest_size (setter)
  set digest_size(Object? digest_size) =>
      setAttribute("digest_size", digest_size);

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);

  /// ## copy (getter)
  Object? get copy => getAttribute("copy");

  /// ## copy (setter)
  set copy(Object? copy) => setAttribute("copy", copy);

  /// ## digest (getter)
  Object? get digest => getAttribute("digest");

  /// ## digest (setter)
  set digest(Object? digest) => setAttribute("digest", digest);

  /// ## hexdigest (getter)
  Object? get hexdigest => getAttribute("hexdigest");

  /// ## hexdigest (setter)
  set hexdigest(Object? hexdigest) => setAttribute("hexdigest", hexdigest);

  /// ## update (getter)
  Object? get update => getAttribute("update");

  /// ## update (setter)
  set update(Object? update) => setAttribute("update", update);

  /// ## MAX_DIGEST_SIZE (getter)
  Object? get MAX_DIGEST_SIZE => getAttribute("MAX_DIGEST_SIZE");

  /// ## MAX_DIGEST_SIZE (setter)
  set MAX_DIGEST_SIZE(Object? MAX_DIGEST_SIZE) =>
      setAttribute("MAX_DIGEST_SIZE", MAX_DIGEST_SIZE);

  /// ## MAX_KEY_SIZE (getter)
  Object? get MAX_KEY_SIZE => getAttribute("MAX_KEY_SIZE");

  /// ## MAX_KEY_SIZE (setter)
  set MAX_KEY_SIZE(Object? MAX_KEY_SIZE) =>
      setAttribute("MAX_KEY_SIZE", MAX_KEY_SIZE);

  /// ## PERSON_SIZE (getter)
  Object? get PERSON_SIZE => getAttribute("PERSON_SIZE");

  /// ## PERSON_SIZE (setter)
  set PERSON_SIZE(Object? PERSON_SIZE) =>
      setAttribute("PERSON_SIZE", PERSON_SIZE);

  /// ## SALT_SIZE (getter)
  Object? get SALT_SIZE => getAttribute("SALT_SIZE");

  /// ## SALT_SIZE (setter)
  set SALT_SIZE(Object? SALT_SIZE) => setAttribute("SALT_SIZE", SALT_SIZE);
}

/// ## blake2s
final class blake2s extends PythonClass {
  factory blake2s() => PythonFfiDart.instance.importClass(
        "_blake2",
        "blake2s",
        blake2s.from,
        <Object?>[],
      );

  blake2s.from(super.pythonClass) : super.from();

  /// ## block_size (getter)
  Object? get block_size => getAttribute("block_size");

  /// ## block_size (setter)
  set block_size(Object? block_size) => setAttribute("block_size", block_size);

  /// ## digest_size (getter)
  Object? get digest_size => getAttribute("digest_size");

  /// ## digest_size (setter)
  set digest_size(Object? digest_size) =>
      setAttribute("digest_size", digest_size);

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);

  /// ## copy (getter)
  Object? get copy => getAttribute("copy");

  /// ## copy (setter)
  set copy(Object? copy) => setAttribute("copy", copy);

  /// ## digest (getter)
  Object? get digest => getAttribute("digest");

  /// ## digest (setter)
  set digest(Object? digest) => setAttribute("digest", digest);

  /// ## hexdigest (getter)
  Object? get hexdigest => getAttribute("hexdigest");

  /// ## hexdigest (setter)
  set hexdigest(Object? hexdigest) => setAttribute("hexdigest", hexdigest);

  /// ## update (getter)
  Object? get update => getAttribute("update");

  /// ## update (setter)
  set update(Object? update) => setAttribute("update", update);

  /// ## MAX_DIGEST_SIZE (getter)
  Object? get MAX_DIGEST_SIZE => getAttribute("MAX_DIGEST_SIZE");

  /// ## MAX_DIGEST_SIZE (setter)
  set MAX_DIGEST_SIZE(Object? MAX_DIGEST_SIZE) =>
      setAttribute("MAX_DIGEST_SIZE", MAX_DIGEST_SIZE);

  /// ## MAX_KEY_SIZE (getter)
  Object? get MAX_KEY_SIZE => getAttribute("MAX_KEY_SIZE");

  /// ## MAX_KEY_SIZE (setter)
  set MAX_KEY_SIZE(Object? MAX_KEY_SIZE) =>
      setAttribute("MAX_KEY_SIZE", MAX_KEY_SIZE);

  /// ## PERSON_SIZE (getter)
  Object? get PERSON_SIZE => getAttribute("PERSON_SIZE");

  /// ## PERSON_SIZE (setter)
  set PERSON_SIZE(Object? PERSON_SIZE) =>
      setAttribute("PERSON_SIZE", PERSON_SIZE);

  /// ## SALT_SIZE (getter)
  Object? get SALT_SIZE => getAttribute("SALT_SIZE");

  /// ## SALT_SIZE (setter)
  set SALT_SIZE(Object? SALT_SIZE) => setAttribute("SALT_SIZE", SALT_SIZE);
}

/// ## sha3_224
final class sha3_224 extends PythonClass {
  factory sha3_224() => PythonFfiDart.instance.importClass(
        "_sha3",
        "sha3_224",
        sha3_224.from,
        <Object?>[],
      );

  sha3_224.from(super.pythonClass) : super.from();

  /// ## block_size (getter)
  Object? get block_size => getAttribute("block_size");

  /// ## block_size (setter)
  set block_size(Object? block_size) => setAttribute("block_size", block_size);

  /// ## digest_size (getter)
  Object? get digest_size => getAttribute("digest_size");

  /// ## digest_size (setter)
  set digest_size(Object? digest_size) =>
      setAttribute("digest_size", digest_size);

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);

  /// ## copy (getter)
  Object? get copy => getAttribute("copy");

  /// ## copy (setter)
  set copy(Object? copy) => setAttribute("copy", copy);

  /// ## digest (getter)
  Object? get digest => getAttribute("digest");

  /// ## digest (setter)
  set digest(Object? digest) => setAttribute("digest", digest);

  /// ## hexdigest (getter)
  Object? get hexdigest => getAttribute("hexdigest");

  /// ## hexdigest (setter)
  set hexdigest(Object? hexdigest) => setAttribute("hexdigest", hexdigest);

  /// ## update (getter)
  Object? get update => getAttribute("update");

  /// ## update (setter)
  set update(Object? update) => setAttribute("update", update);
}

/// ## sha3_256
final class sha3_256 extends PythonClass {
  factory sha3_256() => PythonFfiDart.instance.importClass(
        "_sha3",
        "sha3_256",
        sha3_256.from,
        <Object?>[],
      );

  sha3_256.from(super.pythonClass) : super.from();

  /// ## block_size (getter)
  Object? get block_size => getAttribute("block_size");

  /// ## block_size (setter)
  set block_size(Object? block_size) => setAttribute("block_size", block_size);

  /// ## digest_size (getter)
  Object? get digest_size => getAttribute("digest_size");

  /// ## digest_size (setter)
  set digest_size(Object? digest_size) =>
      setAttribute("digest_size", digest_size);

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);

  /// ## copy (getter)
  Object? get copy => getAttribute("copy");

  /// ## copy (setter)
  set copy(Object? copy) => setAttribute("copy", copy);

  /// ## digest (getter)
  Object? get digest => getAttribute("digest");

  /// ## digest (setter)
  set digest(Object? digest) => setAttribute("digest", digest);

  /// ## hexdigest (getter)
  Object? get hexdigest => getAttribute("hexdigest");

  /// ## hexdigest (setter)
  set hexdigest(Object? hexdigest) => setAttribute("hexdigest", hexdigest);

  /// ## update (getter)
  Object? get update => getAttribute("update");

  /// ## update (setter)
  set update(Object? update) => setAttribute("update", update);
}

/// ## sha3_384
final class sha3_384 extends PythonClass {
  factory sha3_384() => PythonFfiDart.instance.importClass(
        "_sha3",
        "sha3_384",
        sha3_384.from,
        <Object?>[],
      );

  sha3_384.from(super.pythonClass) : super.from();

  /// ## block_size (getter)
  Object? get block_size => getAttribute("block_size");

  /// ## block_size (setter)
  set block_size(Object? block_size) => setAttribute("block_size", block_size);

  /// ## digest_size (getter)
  Object? get digest_size => getAttribute("digest_size");

  /// ## digest_size (setter)
  set digest_size(Object? digest_size) =>
      setAttribute("digest_size", digest_size);

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);

  /// ## copy (getter)
  Object? get copy => getAttribute("copy");

  /// ## copy (setter)
  set copy(Object? copy) => setAttribute("copy", copy);

  /// ## digest (getter)
  Object? get digest => getAttribute("digest");

  /// ## digest (setter)
  set digest(Object? digest) => setAttribute("digest", digest);

  /// ## hexdigest (getter)
  Object? get hexdigest => getAttribute("hexdigest");

  /// ## hexdigest (setter)
  set hexdigest(Object? hexdigest) => setAttribute("hexdigest", hexdigest);

  /// ## update (getter)
  Object? get update => getAttribute("update");

  /// ## update (setter)
  set update(Object? update) => setAttribute("update", update);
}

/// ## sha3_512
final class sha3_512 extends PythonClass {
  factory sha3_512() => PythonFfiDart.instance.importClass(
        "_sha3",
        "sha3_512",
        sha3_512.from,
        <Object?>[],
      );

  sha3_512.from(super.pythonClass) : super.from();

  /// ## block_size (getter)
  Object? get block_size => getAttribute("block_size");

  /// ## block_size (setter)
  set block_size(Object? block_size) => setAttribute("block_size", block_size);

  /// ## digest_size (getter)
  Object? get digest_size => getAttribute("digest_size");

  /// ## digest_size (setter)
  set digest_size(Object? digest_size) =>
      setAttribute("digest_size", digest_size);

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);

  /// ## copy (getter)
  Object? get copy => getAttribute("copy");

  /// ## copy (setter)
  set copy(Object? copy) => setAttribute("copy", copy);

  /// ## digest (getter)
  Object? get digest => getAttribute("digest");

  /// ## digest (setter)
  set digest(Object? digest) => setAttribute("digest", digest);

  /// ## hexdigest (getter)
  Object? get hexdigest => getAttribute("hexdigest");

  /// ## hexdigest (setter)
  set hexdigest(Object? hexdigest) => setAttribute("hexdigest", hexdigest);

  /// ## update (getter)
  Object? get update => getAttribute("update");

  /// ## update (setter)
  set update(Object? update) => setAttribute("update", update);
}

/// ## shake_128
final class shake_128 extends PythonClass {
  factory shake_128() => PythonFfiDart.instance.importClass(
        "_sha3",
        "shake_128",
        shake_128.from,
        <Object?>[],
      );

  shake_128.from(super.pythonClass) : super.from();

  /// ## block_size (getter)
  Object? get block_size => getAttribute("block_size");

  /// ## block_size (setter)
  set block_size(Object? block_size) => setAttribute("block_size", block_size);

  /// ## digest_size (getter)
  Object? get digest_size => getAttribute("digest_size");

  /// ## digest_size (setter)
  set digest_size(Object? digest_size) =>
      setAttribute("digest_size", digest_size);

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);

  /// ## copy (getter)
  Object? get copy => getAttribute("copy");

  /// ## copy (setter)
  set copy(Object? copy) => setAttribute("copy", copy);

  /// ## digest (getter)
  Object? get digest => getAttribute("digest");

  /// ## digest (setter)
  set digest(Object? digest) => setAttribute("digest", digest);

  /// ## hexdigest (getter)
  Object? get hexdigest => getAttribute("hexdigest");

  /// ## hexdigest (setter)
  set hexdigest(Object? hexdigest) => setAttribute("hexdigest", hexdigest);

  /// ## update (getter)
  Object? get update => getAttribute("update");

  /// ## update (setter)
  set update(Object? update) => setAttribute("update", update);
}

/// ## shake_256
final class shake_256 extends PythonClass {
  factory shake_256() => PythonFfiDart.instance.importClass(
        "_sha3",
        "shake_256",
        shake_256.from,
        <Object?>[],
      );

  shake_256.from(super.pythonClass) : super.from();

  /// ## block_size (getter)
  Object? get block_size => getAttribute("block_size");

  /// ## block_size (setter)
  set block_size(Object? block_size) => setAttribute("block_size", block_size);

  /// ## digest_size (getter)
  Object? get digest_size => getAttribute("digest_size");

  /// ## digest_size (setter)
  set digest_size(Object? digest_size) =>
      setAttribute("digest_size", digest_size);

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);

  /// ## copy (getter)
  Object? get copy => getAttribute("copy");

  /// ## copy (setter)
  set copy(Object? copy) => setAttribute("copy", copy);

  /// ## digest (getter)
  Object? get digest => getAttribute("digest");

  /// ## digest (setter)
  set digest(Object? digest) => setAttribute("digest", digest);

  /// ## hexdigest (getter)
  Object? get hexdigest => getAttribute("hexdigest");

  /// ## hexdigest (setter)
  set hexdigest(Object? hexdigest) => setAttribute("hexdigest", hexdigest);

  /// ## update (getter)
  Object? get update => getAttribute("update");

  /// ## update (setter)
  set update(Object? update) => setAttribute("update", update);
}

/// ## ImpImporter
///
/// ### python docstring
///
/// PEP 302 Finder that wraps Python's "classic" import algorithm
///
/// ImpImporter(dirname) produces a PEP 302 finder that searches that
/// directory.  ImpImporter(None) produces a PEP 302 finder that searches
/// the current sys.path, plus any modules that are frozen or built-in.
///
/// Note that ImpImporter does not currently support being used by placement
/// on sys.meta_path.
///
/// ### python source
/// ```py
/// class ImpImporter:
///     """PEP 302 Finder that wraps Python's "classic" import algorithm
///
///     ImpImporter(dirname) produces a PEP 302 finder that searches that
///     directory.  ImpImporter(None) produces a PEP 302 finder that searches
///     the current sys.path, plus any modules that are frozen or built-in.
///
///     Note that ImpImporter does not currently support being used by placement
///     on sys.meta_path.
///     """
///
///     def __init__(self, path=None):
///         global imp
///         warnings.warn("This emulation is deprecated and slated for removal "
///                       "in Python 3.12; use 'importlib' instead",
///              DeprecationWarning)
///         _import_imp()
///         self.path = path
///
///     def find_module(self, fullname, path=None):
///         # Note: we ignore 'path' argument since it is only used via meta_path
///         subname = fullname.split(".")[-1]
///         if subname != fullname and self.path is None:
///             return None
///         if self.path is None:
///             path = None
///         else:
///             path = [os.path.realpath(self.path)]
///         try:
///             file, filename, etc = imp.find_module(subname, path)
///         except ImportError:
///             return None
///         return ImpLoader(fullname, file, filename, etc)
///
///     def iter_modules(self, prefix=''):
///         if self.path is None or not os.path.isdir(self.path):
///             return
///
///         yielded = {}
///         import inspect
///         try:
///             filenames = os.listdir(self.path)
///         except OSError:
///             # ignore unreadable directories like import does
///             filenames = []
///         filenames.sort()  # handle packages before same-named modules
///
///         for fn in filenames:
///             modname = inspect.getmodulename(fn)
///             if modname=='__init__' or modname in yielded:
///                 continue
///
///             path = os.path.join(self.path, fn)
///             ispkg = False
///
///             if not modname and os.path.isdir(path) and '.' not in fn:
///                 modname = fn
///                 try:
///                     dircontents = os.listdir(path)
///                 except OSError:
///                     # ignore unreadable directories like import does
///                     dircontents = []
///                 for fn in dircontents:
///                     subname = inspect.getmodulename(fn)
///                     if subname=='__init__':
///                         ispkg = True
///                         break
///                 else:
///                     continue    # not a package
///
///             if modname and '.' not in modname:
///                 yielded[modname] = 1
///                 yield prefix + modname, ispkg
/// ```
final class ImpImporter extends PythonClass {
  factory ImpImporter({
    Object? path,
  }) =>
      PythonFfiDart.instance.importClass(
        "pkgutil",
        "ImpImporter",
        ImpImporter.from,
        <Object?>[
          path,
        ],
        <String, Object?>{},
      );

  ImpImporter.from(super.pythonClass) : super.from();

  /// ## find_module
  ///
  /// ### python source
  /// ```py
  /// def find_module(self, fullname, path=None):
  ///         # Note: we ignore 'path' argument since it is only used via meta_path
  ///         subname = fullname.split(".")[-1]
  ///         if subname != fullname and self.path is None:
  ///             return None
  ///         if self.path is None:
  ///             path = None
  ///         else:
  ///             path = [os.path.realpath(self.path)]
  ///         try:
  ///             file, filename, etc = imp.find_module(subname, path)
  ///         except ImportError:
  ///             return None
  ///         return ImpLoader(fullname, file, filename, etc)
  /// ```
  Object? find_module({
    required Object? fullname,
    Object? path,
  }) =>
      getFunction("find_module").call(
        <Object?>[
          fullname,
          path,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## iter_modules
  ///
  /// ### python source
  /// ```py
  /// def iter_modules(self, prefix=''):
  ///         if self.path is None or not os.path.isdir(self.path):
  ///             return
  ///
  ///         yielded = {}
  ///         import inspect
  ///         try:
  ///             filenames = os.listdir(self.path)
  ///         except OSError:
  ///             # ignore unreadable directories like import does
  ///             filenames = []
  ///         filenames.sort()  # handle packages before same-named modules
  ///
  ///         for fn in filenames:
  ///             modname = inspect.getmodulename(fn)
  ///             if modname=='__init__' or modname in yielded:
  ///                 continue
  ///
  ///             path = os.path.join(self.path, fn)
  ///             ispkg = False
  ///
  ///             if not modname and os.path.isdir(path) and '.' not in fn:
  ///                 modname = fn
  ///                 try:
  ///                     dircontents = os.listdir(path)
  ///                 except OSError:
  ///                     # ignore unreadable directories like import does
  ///                     dircontents = []
  ///                 for fn in dircontents:
  ///                     subname = inspect.getmodulename(fn)
  ///                     if subname=='__init__':
  ///                         ispkg = True
  ///                         break
  ///                 else:
  ///                     continue    # not a package
  ///
  ///             if modname and '.' not in modname:
  ///                 yielded[modname] = 1
  ///                 yield prefix + modname, ispkg
  /// ```
  Object? iter_modules({
    Object? prefix = "",
  }) =>
      getFunction("iter_modules").call(
        <Object?>[
          prefix,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## path (getter)
  Object? get path => getAttribute("path");

  /// ## path (setter)
  set path(Object? path) => setAttribute("path", path);
}

/// ## ImpLoader
///
/// ### python docstring
///
/// PEP 302 Loader that wraps Python's "classic" import algorithm
///
/// ### python source
/// ```py
/// class ImpLoader:
///     """PEP 302 Loader that wraps Python's "classic" import algorithm
///     """
///     code = source = None
///
///     def __init__(self, fullname, file, filename, etc):
///         warnings.warn("This emulation is deprecated and slated for removal in "
///                       "Python 3.12; use 'importlib' instead",
///                       DeprecationWarning)
///         _import_imp()
///         self.file = file
///         self.filename = filename
///         self.fullname = fullname
///         self.etc = etc
///
///     def load_module(self, fullname):
///         self._reopen()
///         try:
///             mod = imp.load_module(fullname, self.file, self.filename, self.etc)
///         finally:
///             if self.file:
///                 self.file.close()
///         # Note: we don't set __loader__ because we want the module to look
///         # normal; i.e. this is just a wrapper for standard import machinery
///         return mod
///
///     def get_data(self, pathname):
///         with open(pathname, "rb") as file:
///             return file.read()
///
///     def _reopen(self):
///         if self.file and self.file.closed:
///             mod_type = self.etc[2]
///             if mod_type==imp.PY_SOURCE:
///                 self.file = open(self.filename, 'r')
///             elif mod_type in (imp.PY_COMPILED, imp.C_EXTENSION):
///                 self.file = open(self.filename, 'rb')
///
///     def _fix_name(self, fullname):
///         if fullname is None:
///             fullname = self.fullname
///         elif fullname != self.fullname:
///             raise ImportError("Loader for module %s cannot handle "
///                               "module %s" % (self.fullname, fullname))
///         return fullname
///
///     def is_package(self, fullname):
///         fullname = self._fix_name(fullname)
///         return self.etc[2]==imp.PKG_DIRECTORY
///
///     def get_code(self, fullname=None):
///         fullname = self._fix_name(fullname)
///         if self.code is None:
///             mod_type = self.etc[2]
///             if mod_type==imp.PY_SOURCE:
///                 source = self.get_source(fullname)
///                 self.code = compile(source, self.filename, 'exec')
///             elif mod_type==imp.PY_COMPILED:
///                 self._reopen()
///                 try:
///                     self.code = read_code(self.file)
///                 finally:
///                     self.file.close()
///             elif mod_type==imp.PKG_DIRECTORY:
///                 self.code = self._get_delegate().get_code()
///         return self.code
///
///     def get_source(self, fullname=None):
///         fullname = self._fix_name(fullname)
///         if self.source is None:
///             mod_type = self.etc[2]
///             if mod_type==imp.PY_SOURCE:
///                 self._reopen()
///                 try:
///                     self.source = self.file.read()
///                 finally:
///                     self.file.close()
///             elif mod_type==imp.PY_COMPILED:
///                 if os.path.exists(self.filename[:-1]):
///                     with open(self.filename[:-1], 'r') as f:
///                         self.source = f.read()
///             elif mod_type==imp.PKG_DIRECTORY:
///                 self.source = self._get_delegate().get_source()
///         return self.source
///
///     def _get_delegate(self):
///         finder = ImpImporter(self.filename)
///         spec = _get_spec(finder, '__init__')
///         return spec.loader
///
///     def get_filename(self, fullname=None):
///         fullname = self._fix_name(fullname)
///         mod_type = self.etc[2]
///         if mod_type==imp.PKG_DIRECTORY:
///             return self._get_delegate().get_filename()
///         elif mod_type in (imp.PY_SOURCE, imp.PY_COMPILED, imp.C_EXTENSION):
///             return self.filename
///         return None
/// ```
final class ImpLoader extends PythonClass {
  factory ImpLoader({
    required Object? fullname,
    required Object? file,
    required Object? filename,
    required Object? etc,
  }) =>
      PythonFfiDart.instance.importClass(
        "pkgutil",
        "ImpLoader",
        ImpLoader.from,
        <Object?>[
          fullname,
          file,
          filename,
          etc,
        ],
        <String, Object?>{},
      );

  ImpLoader.from(super.pythonClass) : super.from();

  /// ## get_code
  ///
  /// ### python source
  /// ```py
  /// def get_code(self, fullname=None):
  ///         fullname = self._fix_name(fullname)
  ///         if self.code is None:
  ///             mod_type = self.etc[2]
  ///             if mod_type==imp.PY_SOURCE:
  ///                 source = self.get_source(fullname)
  ///                 self.code = compile(source, self.filename, 'exec')
  ///             elif mod_type==imp.PY_COMPILED:
  ///                 self._reopen()
  ///                 try:
  ///                     self.code = read_code(self.file)
  ///                 finally:
  ///                     self.file.close()
  ///             elif mod_type==imp.PKG_DIRECTORY:
  ///                 self.code = self._get_delegate().get_code()
  ///         return self.code
  /// ```
  Object? get_code({
    Object? fullname,
  }) =>
      getFunction("get_code").call(
        <Object?>[
          fullname,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## get_data
  ///
  /// ### python source
  /// ```py
  /// def get_data(self, pathname):
  ///         with open(pathname, "rb") as file:
  ///             return file.read()
  /// ```
  Object? get_data({
    required Object? pathname,
  }) =>
      getFunction("get_data").call(
        <Object?>[
          pathname,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## get_filename
  ///
  /// ### python source
  /// ```py
  /// def get_filename(self, fullname=None):
  ///         fullname = self._fix_name(fullname)
  ///         mod_type = self.etc[2]
  ///         if mod_type==imp.PKG_DIRECTORY:
  ///             return self._get_delegate().get_filename()
  ///         elif mod_type in (imp.PY_SOURCE, imp.PY_COMPILED, imp.C_EXTENSION):
  ///             return self.filename
  ///         return None
  /// ```
  Object? get_filename({
    Object? fullname,
  }) =>
      getFunction("get_filename").call(
        <Object?>[
          fullname,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## get_source
  ///
  /// ### python source
  /// ```py
  /// def get_source(self, fullname=None):
  ///         fullname = self._fix_name(fullname)
  ///         if self.source is None:
  ///             mod_type = self.etc[2]
  ///             if mod_type==imp.PY_SOURCE:
  ///                 self._reopen()
  ///                 try:
  ///                     self.source = self.file.read()
  ///                 finally:
  ///                     self.file.close()
  ///             elif mod_type==imp.PY_COMPILED:
  ///                 if os.path.exists(self.filename[:-1]):
  ///                     with open(self.filename[:-1], 'r') as f:
  ///                         self.source = f.read()
  ///             elif mod_type==imp.PKG_DIRECTORY:
  ///                 self.source = self._get_delegate().get_source()
  ///         return self.source
  /// ```
  Object? get_source({
    Object? fullname,
  }) =>
      getFunction("get_source").call(
        <Object?>[
          fullname,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## is_package
  ///
  /// ### python source
  /// ```py
  /// def is_package(self, fullname):
  ///         fullname = self._fix_name(fullname)
  ///         return self.etc[2]==imp.PKG_DIRECTORY
  /// ```
  Object? is_package({
    required Object? fullname,
  }) =>
      getFunction("is_package").call(
        <Object?>[
          fullname,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## load_module
  ///
  /// ### python source
  /// ```py
  /// def load_module(self, fullname):
  ///         self._reopen()
  ///         try:
  ///             mod = imp.load_module(fullname, self.file, self.filename, self.etc)
  ///         finally:
  ///             if self.file:
  ///                 self.file.close()
  ///         # Note: we don't set __loader__ because we want the module to look
  ///         # normal; i.e. this is just a wrapper for standard import machinery
  ///         return mod
  /// ```
  Object? load_module({
    required Object? fullname,
  }) =>
      getFunction("load_module").call(
        <Object?>[
          fullname,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## code (getter)
  Object? get code => getAttribute("code");

  /// ## code (setter)
  set code(Object? code) => setAttribute("code", code);

  /// ## source (getter)
  Object? get source => getAttribute("source");

  /// ## source (setter)
  set source(Object? source) => setAttribute("source", source);

  /// ## file (getter)
  Object? get file => getAttribute("file");

  /// ## file (setter)
  set file(Object? file) => setAttribute("file", file);

  /// ## filename (getter)
  Object? get filename => getAttribute("filename");

  /// ## filename (setter)
  set filename(Object? filename) => setAttribute("filename", filename);

  /// ## fullname (getter)
  Object? get fullname => getAttribute("fullname");

  /// ## fullname (setter)
  set fullname(Object? fullname) => setAttribute("fullname", fullname);

  /// ## etc (getter)
  Object? get etc => getAttribute("etc");

  /// ## etc (setter)
  set etc(Object? etc) => setAttribute("etc", etc);
}

/// ## ModuleInfo
///
/// ### python docstring
///
/// A namedtuple with minimal info about a module.
final class ModuleInfo extends PythonClass {
  factory ModuleInfo() => PythonFfiDart.instance.importClass(
        "pkgutil",
        "ModuleInfo",
        ModuleInfo.from,
        <Object?>[],
      );

  ModuleInfo.from(super.pythonClass) : super.from();

  /// ## ispkg (getter)
  ///
  /// ### python docstring
  ///
  /// Alias for field number 2
  Object? get ispkg => getAttribute("ispkg");

  /// ## ispkg (setter)
  ///
  /// ### python docstring
  ///
  /// Alias for field number 2
  set ispkg(Object? ispkg) => setAttribute("ispkg", ispkg);

  /// ## module_finder (getter)
  ///
  /// ### python docstring
  ///
  /// Alias for field number 0
  Object? get module_finder => getAttribute("module_finder");

  /// ## module_finder (setter)
  ///
  /// ### python docstring
  ///
  /// Alias for field number 0
  set module_finder(Object? module_finder) =>
      setAttribute("module_finder", module_finder);

  /// ## name (getter)
  ///
  /// ### python docstring
  ///
  /// Alias for field number 1
  Object? get name => getAttribute("name");

  /// ## name (setter)
  ///
  /// ### python docstring
  ///
  /// Alias for field number 1
  set name(Object? name) => setAttribute("name", name);

  /// ## count (getter)
  Object? get count => getAttribute("count");

  /// ## count (setter)
  set count(Object? count) => setAttribute("count", count);

  /// ## index (getter)
  Object? get index => getAttribute("index");

  /// ## index (setter)
  set index(Object? index) => setAttribute("index", index);
}

/// ## BuiltinImporter
///
/// ### python docstring
///
/// Meta path import for built-in modules.
///
/// All methods are either class or static methods to avoid the need to
/// instantiate the class.
///
/// ### python source
/// ```py
/// class BuiltinImporter:
///
///     """Meta path import for built-in modules.
///
///     All methods are either class or static methods to avoid the need to
///     instantiate the class.
///
///     """
///
///     _ORIGIN = "built-in"
///
///     @staticmethod
///     def module_repr(module):
///         """Return repr for the module.
///
///         The method is deprecated.  The import machinery does the job itself.
///
///         """
///         _warnings.warn("BuiltinImporter.module_repr() is deprecated and "
///                        "slated for removal in Python 3.12", DeprecationWarning)
///         return f'<module {module.__name__!r} ({BuiltinImporter._ORIGIN})>'
///
///     @classmethod
///     def find_spec(cls, fullname, path=None, target=None):
///         if path is not None:
///             return None
///         if _imp.is_builtin(fullname):
///             return spec_from_loader(fullname, cls, origin=cls._ORIGIN)
///         else:
///             return None
///
///     @classmethod
///     def find_module(cls, fullname, path=None):
///         """Find the built-in module.
///
///         If 'path' is ever specified then the search is considered a failure.
///
///         This method is deprecated.  Use find_spec() instead.
///
///         """
///         _warnings.warn("BuiltinImporter.find_module() is deprecated and "
///                        "slated for removal in Python 3.12; use find_spec() instead",
///                        DeprecationWarning)
///         spec = cls.find_spec(fullname, path)
///         return spec.loader if spec is not None else None
///
///     @staticmethod
///     def create_module(spec):
///         """Create a built-in module"""
///         if spec.name not in sys.builtin_module_names:
///             raise ImportError('{!r} is not a built-in module'.format(spec.name),
///                               name=spec.name)
///         return _call_with_frames_removed(_imp.create_builtin, spec)
///
///     @staticmethod
///     def exec_module(module):
///         """Exec a built-in module"""
///         _call_with_frames_removed(_imp.exec_builtin, module)
///
///     @classmethod
///     @_requires_builtin
///     def get_code(cls, fullname):
///         """Return None as built-in modules do not have code objects."""
///         return None
///
///     @classmethod
///     @_requires_builtin
///     def get_source(cls, fullname):
///         """Return None as built-in modules do not have source code."""
///         return None
///
///     @classmethod
///     @_requires_builtin
///     def is_package(cls, fullname):
///         """Return False as built-in modules are never packages."""
///         return False
///
///     load_module = classmethod(_load_module_shim)
/// ```
final class BuiltinImporter extends PythonClass {
  factory BuiltinImporter() => PythonFfiDart.instance.importClass(
        "importlib._bootstrap",
        "BuiltinImporter",
        BuiltinImporter.from,
        <Object?>[],
      );

  BuiltinImporter.from(super.pythonClass) : super.from();

  /// ## create_module
  ///
  /// ### python docstring
  ///
  /// Create a built-in module
  Object? create_module() => getFunction("create_module").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## exec_module
  ///
  /// ### python docstring
  ///
  /// Exec a built-in module
  Object? exec_module() => getFunction("exec_module").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## module_repr
  ///
  /// ### python docstring
  ///
  /// Return repr for the module.
  ///
  /// The method is deprecated.  The import machinery does the job itself.
  Object? module_repr() => getFunction("module_repr").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## find_module (getter)
  ///
  /// ### python docstring
  ///
  /// Find the built-in module.
  ///
  /// If 'path' is ever specified then the search is considered a failure.
  ///
  /// This method is deprecated.  Use find_spec() instead.
  Object? get find_module => getAttribute("find_module");

  /// ## find_module (setter)
  ///
  /// ### python docstring
  ///
  /// Find the built-in module.
  ///
  /// If 'path' is ever specified then the search is considered a failure.
  ///
  /// This method is deprecated.  Use find_spec() instead.
  set find_module(Object? find_module) =>
      setAttribute("find_module", find_module);

  /// ## find_spec (getter)
  Object? get find_spec => getAttribute("find_spec");

  /// ## find_spec (setter)
  set find_spec(Object? find_spec) => setAttribute("find_spec", find_spec);

  /// ## get_code (getter)
  ///
  /// ### python docstring
  ///
  /// Return None as built-in modules do not have code objects.
  Object? get get_code => getAttribute("get_code");

  /// ## get_code (setter)
  ///
  /// ### python docstring
  ///
  /// Return None as built-in modules do not have code objects.
  set get_code(Object? get_code) => setAttribute("get_code", get_code);

  /// ## get_source (getter)
  ///
  /// ### python docstring
  ///
  /// Return None as built-in modules do not have source code.
  Object? get get_source => getAttribute("get_source");

  /// ## get_source (setter)
  ///
  /// ### python docstring
  ///
  /// Return None as built-in modules do not have source code.
  set get_source(Object? get_source) => setAttribute("get_source", get_source);

  /// ## is_package (getter)
  ///
  /// ### python docstring
  ///
  /// Return False as built-in modules are never packages.
  Object? get is_package => getAttribute("is_package");

  /// ## is_package (setter)
  ///
  /// ### python docstring
  ///
  /// Return False as built-in modules are never packages.
  set is_package(Object? is_package) => setAttribute("is_package", is_package);

  /// ## load_module (getter)
  ///
  /// ### python docstring
  ///
  /// Load the specified module into sys.modules and return it.
  ///
  /// This method is deprecated.  Use loader.exec_module() instead.
  Object? get load_module => getAttribute("load_module");

  /// ## load_module (setter)
  ///
  /// ### python docstring
  ///
  /// Load the specified module into sys.modules and return it.
  ///
  /// This method is deprecated.  Use loader.exec_module() instead.
  set load_module(Object? load_module) =>
      setAttribute("load_module", load_module);
}

/// ## ExtensionFileLoader
///
/// ### python docstring
///
/// Loader for extension modules.
///
/// The constructor is designed to work with FileFinder.
///
/// ### python source
/// ```py
/// class ExtensionFileLoader(FileLoader, _LoaderBasics):
///
///     """Loader for extension modules.
///
///     The constructor is designed to work with FileFinder.
///
///     """
///
///     def __init__(self, name, path):
///         self.name = name
///         self.path = path
///
///     def __eq__(self, other):
///         return (self.__class__ == other.__class__ and
///                 self.__dict__ == other.__dict__)
///
///     def __hash__(self):
///         return hash(self.name) ^ hash(self.path)
///
///     def create_module(self, spec):
///         """Create an uninitialized extension module"""
///         module = _bootstrap._call_with_frames_removed(
///             _imp.create_dynamic, spec)
///         _bootstrap._verbose_message('extension module {!r} loaded from {!r}',
///                          spec.name, self.path)
///         return module
///
///     def exec_module(self, module):
///         """Initialize an extension module"""
///         _bootstrap._call_with_frames_removed(_imp.exec_dynamic, module)
///         _bootstrap._verbose_message('extension module {!r} executed from {!r}',
///                          self.name, self.path)
///
///     def is_package(self, fullname):
///         """Return True if the extension module is a package."""
///         file_name = _path_split(self.path)[1]
///         return any(file_name == '__init__' + suffix
///                    for suffix in EXTENSION_SUFFIXES)
///
///     def get_code(self, fullname):
///         """Return None as an extension module cannot create a code object."""
///         return None
///
///     def get_source(self, fullname):
///         """Return None as extension modules have no source code."""
///         return None
///
///     @_check_name
///     def get_filename(self, fullname):
///         """Return the path to the source file as found by the finder."""
///         return self.path
/// ```
final class ExtensionFileLoader extends PythonClass {
  factory ExtensionFileLoader({
    required Object? name,
    required Object? path,
  }) =>
      PythonFfiDart.instance.importClass(
        "importlib._bootstrap_external",
        "ExtensionFileLoader",
        ExtensionFileLoader.from,
        <Object?>[
          name,
          path,
        ],
        <String, Object?>{},
      );

  ExtensionFileLoader.from(super.pythonClass) : super.from();

  /// ## create_module
  ///
  /// ### python docstring
  ///
  /// Create an uninitialized extension module
  Object? create_module({
    required Object? spec,
  }) =>
      getFunction("create_module").call(
        <Object?>[
          spec,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## exec_module
  ///
  /// ### python docstring
  ///
  /// Initialize an extension module
  Object? exec_module({
    required Object? module,
  }) =>
      getFunction("exec_module").call(
        <Object?>[
          module,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## get_code
  ///
  /// ### python docstring
  ///
  /// Return None as an extension module cannot create a code object.
  Object? get_code({
    required Object? fullname,
  }) =>
      getFunction("get_code").call(
        <Object?>[
          fullname,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## get_data
  ///
  /// ### python docstring
  ///
  /// Return the data from path as raw bytes.
  Object? get_data({
    required Object? path,
  }) =>
      getFunction("get_data").call(
        <Object?>[
          path,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## get_filename
  ///
  /// ### python docstring
  ///
  /// Return the path to the source file as found by the finder.
  Object? get_filename({
    List<Object?> args = const <Object?>[],
    Object? name,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("get_filename").call(
        <Object?>[
          name,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## get_resource_reader
  Object? get_resource_reader({
    List<Object?> args = const <Object?>[],
    Object? name,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("get_resource_reader").call(
        <Object?>[
          name,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## get_source
  ///
  /// ### python docstring
  ///
  /// Return None as extension modules have no source code.
  Object? get_source({
    required Object? fullname,
  }) =>
      getFunction("get_source").call(
        <Object?>[
          fullname,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## is_package
  ///
  /// ### python docstring
  ///
  /// Return True if the extension module is a package.
  Object? is_package({
    required Object? fullname,
  }) =>
      getFunction("is_package").call(
        <Object?>[
          fullname,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## load_module
  ///
  /// ### python docstring
  ///
  /// Load a module from a file.
  ///
  /// This method is deprecated.  Use exec_module() instead.
  Object? load_module({
    List<Object?> args = const <Object?>[],
    Object? name,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("load_module").call(
        <Object?>[
          name,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );
}

/// ## FileFinder
///
/// ### python docstring
///
/// File-based finder.
///
/// Interactions with the file system are cached for performance, being
/// refreshed when the directory the finder is handling has been modified.
///
/// ### python source
/// ```py
/// class FileFinder:
///
///     """File-based finder.
///
///     Interactions with the file system are cached for performance, being
///     refreshed when the directory the finder is handling has been modified.
///
///     """
///
///     def __init__(self, path, *loader_details):
///         """Initialize with the path to search on and a variable number of
///         2-tuples containing the loader and the file suffixes the loader
///         recognizes."""
///         loaders = []
///         for loader, suffixes in loader_details:
///             loaders.extend((suffix, loader) for suffix in suffixes)
///         self._loaders = loaders
///         # Base (directory) path
///         if not path or path == '.':
///             self.path = _os.getcwd()
///         elif not _path_isabs(path):
///             self.path = _path_join(_os.getcwd(), path)
///         else:
///             self.path = path
///         self._path_mtime = -1
///         self._path_cache = set()
///         self._relaxed_path_cache = set()
///
///     def invalidate_caches(self):
///         """Invalidate the directory mtime."""
///         self._path_mtime = -1
///
///     find_module = _find_module_shim
///
///     def find_loader(self, fullname):
///         """Try to find a loader for the specified module, or the namespace
///         package portions. Returns (loader, list-of-portions).
///
///         This method is deprecated.  Use find_spec() instead.
///
///         """
///         _warnings.warn("FileFinder.find_loader() is deprecated and "
///                        "slated for removal in Python 3.12; use find_spec() instead",
///                        DeprecationWarning)
///         spec = self.find_spec(fullname)
///         if spec is None:
///             return None, []
///         return spec.loader, spec.submodule_search_locations or []
///
///     def _get_spec(self, loader_class, fullname, path, smsl, target):
///         loader = loader_class(fullname, path)
///         return spec_from_file_location(fullname, path, loader=loader,
///                                        submodule_search_locations=smsl)
///
///     def find_spec(self, fullname, target=None):
///         """Try to find a spec for the specified module.
///
///         Returns the matching spec, or None if not found.
///         """
///         is_namespace = False
///         tail_module = fullname.rpartition('.')[2]
///         try:
///             mtime = _path_stat(self.path or _os.getcwd()).st_mtime
///         except OSError:
///             mtime = -1
///         if mtime != self._path_mtime:
///             self._fill_cache()
///             self._path_mtime = mtime
///         # tail_module keeps the original casing, for __file__ and friends
///         if _relax_case():
///             cache = self._relaxed_path_cache
///             cache_module = tail_module.lower()
///         else:
///             cache = self._path_cache
///             cache_module = tail_module
///         # Check if the module is the name of a directory (and thus a package).
///         if cache_module in cache:
///             base_path = _path_join(self.path, tail_module)
///             for suffix, loader_class in self._loaders:
///                 init_filename = '__init__' + suffix
///                 full_path = _path_join(base_path, init_filename)
///                 if _path_isfile(full_path):
///                     return self._get_spec(loader_class, fullname, full_path, [base_path], target)
///             else:
///                 # If a namespace package, return the path if we don't
///                 #  find a module in the next section.
///                 is_namespace = _path_isdir(base_path)
///         # Check for a file w/ a proper suffix exists.
///         for suffix, loader_class in self._loaders:
///             try:
///                 full_path = _path_join(self.path, tail_module + suffix)
///             except ValueError:
///                 return None
///             _bootstrap._verbose_message('trying {}', full_path, verbosity=2)
///             if cache_module + suffix in cache:
///                 if _path_isfile(full_path):
///                     return self._get_spec(loader_class, fullname, full_path,
///                                           None, target)
///         if is_namespace:
///             _bootstrap._verbose_message('possible namespace for {}', base_path)
///             spec = _bootstrap.ModuleSpec(fullname, None)
///             spec.submodule_search_locations = [base_path]
///             return spec
///         return None
///
///     def _fill_cache(self):
///         """Fill the cache of potential modules and packages for this directory."""
///         path = self.path
///         try:
///             contents = _os.listdir(path or _os.getcwd())
///         except (FileNotFoundError, PermissionError, NotADirectoryError):
///             # Directory has either been removed, turned into a file, or made
///             # unreadable.
///             contents = []
///         # We store two cached versions, to handle runtime changes of the
///         # PYTHONCASEOK environment variable.
///         if not sys.platform.startswith('win'):
///             self._path_cache = set(contents)
///         else:
///             # Windows users can import modules with case-insensitive file
///             # suffixes (for legacy reasons). Make the suffix lowercase here
///             # so it's done once instead of for every import. This is safe as
///             # the specified suffixes to check against are always specified in a
///             # case-sensitive manner.
///             lower_suffix_contents = set()
///             for item in contents:
///                 name, dot, suffix = item.partition('.')
///                 if dot:
///                     new_name = '{}.{}'.format(name, suffix.lower())
///                 else:
///                     new_name = name
///                 lower_suffix_contents.add(new_name)
///             self._path_cache = lower_suffix_contents
///         if sys.platform.startswith(_CASE_INSENSITIVE_PLATFORMS):
///             self._relaxed_path_cache = {fn.lower() for fn in contents}
///
///     @classmethod
///     def path_hook(cls, *loader_details):
///         """A class method which returns a closure to use on sys.path_hook
///         which will return an instance using the specified loaders and the path
///         called on the closure.
///
///         If the path called on the closure is not a directory, ImportError is
///         raised.
///
///         """
///         def path_hook_for_FileFinder(path):
///             """Path hook for importlib.machinery.FileFinder."""
///             if not _path_isdir(path):
///                 raise ImportError('only directories are supported', path=path)
///             return cls(path, *loader_details)
///
///         return path_hook_for_FileFinder
///
///     def __repr__(self):
///         return 'FileFinder({!r})'.format(self.path)
/// ```
final class FileFinder extends PythonClass {
  factory FileFinder({
    List<Object?> loader_details = const <Object?>[],
    required Object? path,
  }) =>
      PythonFfiDart.instance.importClass(
        "importlib._bootstrap_external",
        "FileFinder",
        FileFinder.from,
        <Object?>[
          path,
          ...loader_details,
        ],
        <String, Object?>{},
      );

  FileFinder.from(super.pythonClass) : super.from();

  /// ## find_loader
  ///
  /// ### python docstring
  ///
  /// Try to find a loader for the specified module, or the namespace
  /// package portions. Returns (loader, list-of-portions).
  ///
  /// This method is deprecated.  Use find_spec() instead.
  Object? find_loader({
    required Object? fullname,
  }) =>
      getFunction("find_loader").call(
        <Object?>[
          fullname,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## find_module
  ///
  /// ### python docstring
  ///
  /// Try to find a loader for the specified module by delegating to
  /// self.find_loader().
  ///
  /// This method is deprecated in favor of finder.find_spec().
  Object? find_module({
    required Object? fullname,
  }) =>
      getFunction("find_module").call(
        <Object?>[
          fullname,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## find_spec
  ///
  /// ### python docstring
  ///
  /// Try to find a spec for the specified module.
  ///
  /// Returns the matching spec, or None if not found.
  Object? find_spec({
    required Object? fullname,
    Object? target,
  }) =>
      getFunction("find_spec").call(
        <Object?>[
          fullname,
          target,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## invalidate_caches
  ///
  /// ### python docstring
  ///
  /// Invalidate the directory mtime.
  Object? invalidate_caches() => getFunction("invalidate_caches").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## path_hook (getter)
  ///
  /// ### python docstring
  ///
  /// A class method which returns a closure to use on sys.path_hook
  /// which will return an instance using the specified loaders and the path
  /// called on the closure.
  ///
  /// If the path called on the closure is not a directory, ImportError is
  /// raised.
  Object? get path_hook => getAttribute("path_hook");

  /// ## path_hook (setter)
  ///
  /// ### python docstring
  ///
  /// A class method which returns a closure to use on sys.path_hook
  /// which will return an instance using the specified loaders and the path
  /// called on the closure.
  ///
  /// If the path called on the closure is not a directory, ImportError is
  /// raised.
  set path_hook(Object? path_hook) => setAttribute("path_hook", path_hook);
}

/// ## FrozenImporter
///
/// ### python docstring
///
/// Meta path import for frozen modules.
///
/// All methods are either class or static methods to avoid the need to
/// instantiate the class.
///
/// ### python source
/// ```py
/// class FrozenImporter:
///
///     """Meta path import for frozen modules.
///
///     All methods are either class or static methods to avoid the need to
///     instantiate the class.
///
///     """
///
///     _ORIGIN = "frozen"
///
///     @staticmethod
///     def module_repr(m):
///         """Return repr for the module.
///
///         The method is deprecated.  The import machinery does the job itself.
///
///         """
///         _warnings.warn("FrozenImporter.module_repr() is deprecated and "
///                        "slated for removal in Python 3.12", DeprecationWarning)
///         return '<module {!r} ({})>'.format(m.__name__, FrozenImporter._ORIGIN)
///
///     @classmethod
///     def _fix_up_module(cls, module):
///         spec = module.__spec__
///         state = spec.loader_state
///         if state is None:
///             # The module is missing FrozenImporter-specific values.
///
///             # Fix up the spec attrs.
///             origname = vars(module).pop('__origname__', None)
///             assert origname, 'see PyImport_ImportFrozenModuleObject()'
///             ispkg = hasattr(module, '__path__')
///             assert _imp.is_frozen_package(module.__name__) == ispkg, ispkg
///             filename, pkgdir = cls._resolve_filename(origname, spec.name, ispkg)
///             spec.loader_state = type(sys.implementation)(
///                 filename=filename,
///                 origname=origname,
///             )
///             __path__ = spec.submodule_search_locations
///             if ispkg:
///                 assert __path__ == [], __path__
///                 if pkgdir:
///                     spec.submodule_search_locations.insert(0, pkgdir)
///             else:
///                 assert __path__ is None, __path__
///
///             # Fix up the module attrs (the bare minimum).
///             assert not hasattr(module, '__file__'), module.__file__
///             if filename:
///                 try:
///                     module.__file__ = filename
///                 except AttributeError:
///                     pass
///             if ispkg:
///                 if module.__path__ != __path__:
///                     assert module.__path__ == [], module.__path__
///                     module.__path__.extend(__path__)
///         else:
///             # These checks ensure that _fix_up_module() is only called
///             # in the right places.
///             __path__ = spec.submodule_search_locations
///             ispkg = __path__ is not None
///             # Check the loader state.
///             assert sorted(vars(state)) == ['filename', 'origname'], state
///             if state.origname:
///                 # The only frozen modules with "origname" set are stdlib modules.
///                 (__file__, pkgdir,
///                  ) = cls._resolve_filename(state.origname, spec.name, ispkg)
///                 assert state.filename == __file__, (state.filename, __file__)
///                 if pkgdir:
///                     assert __path__ == [pkgdir], (__path__, pkgdir)
///                 else:
///                     assert __path__ == ([] if ispkg else None), __path__
///             else:
///                 __file__ = None
///                 assert state.filename is None, state.filename
///                 assert __path__ == ([] if ispkg else None), __path__
///             # Check the file attrs.
///             if __file__:
///                 assert hasattr(module, '__file__')
///                 assert module.__file__ == __file__, (module.__file__, __file__)
///             else:
///                 assert not hasattr(module, '__file__'), module.__file__
///             if ispkg:
///                 assert hasattr(module, '__path__')
///                 assert module.__path__ == __path__, (module.__path__, __path__)
///             else:
///                 assert not hasattr(module, '__path__'), module.__path__
///         assert not spec.has_location
///
///     @classmethod
///     def _resolve_filename(cls, fullname, alias=None, ispkg=False):
///         if not fullname or not getattr(sys, '_stdlib_dir', None):
///             return None, None
///         try:
///             sep = cls._SEP
///         except AttributeError:
///             sep = cls._SEP = '\\' if sys.platform == 'win32' else '/'
///
///         if fullname != alias:
///             if fullname.startswith('<'):
///                 fullname = fullname[1:]
///                 if not ispkg:
///                     fullname = f'{fullname}.__init__'
///             else:
///                 ispkg = False
///         relfile = fullname.replace('.', sep)
///         if ispkg:
///             pkgdir = f'{sys._stdlib_dir}{sep}{relfile}'
///             filename = f'{pkgdir}{sep}__init__.py'
///         else:
///             pkgdir = None
///             filename = f'{sys._stdlib_dir}{sep}{relfile}.py'
///         return filename, pkgdir
///
///     @classmethod
///     def find_spec(cls, fullname, path=None, target=None):
///         info = _call_with_frames_removed(_imp.find_frozen, fullname)
///         if info is None:
///             return None
///         # We get the marshaled data in exec_module() (the loader
///         # part of the importer), instead of here (the finder part).
///         # The loader is the usual place to get the data that will
///         # be loaded into the module.  (For example, see _LoaderBasics
///         # in _bootstra_external.py.)  Most importantly, this importer
///         # is simpler if we wait to get the data.
///         # However, getting as much data in the finder as possible
///         # to later load the module is okay, and sometimes important.
///         # (That's why ModuleSpec.loader_state exists.)  This is
///         # especially true if it avoids throwing away expensive data
///         # the loader would otherwise duplicate later and can be done
///         # efficiently.  In this case it isn't worth it.
///         _, ispkg, origname = info
///         spec = spec_from_loader(fullname, cls,
///                                 origin=cls._ORIGIN,
///                                 is_package=ispkg)
///         filename, pkgdir = cls._resolve_filename(origname, fullname, ispkg)
///         spec.loader_state = type(sys.implementation)(
///             filename=filename,
///             origname=origname,
///         )
///         if pkgdir:
///             spec.submodule_search_locations.insert(0, pkgdir)
///         return spec
///
///     @classmethod
///     def find_module(cls, fullname, path=None):
///         """Find a frozen module.
///
///         This method is deprecated.  Use find_spec() instead.
///
///         """
///         _warnings.warn("FrozenImporter.find_module() is deprecated and "
///                        "slated for removal in Python 3.12; use find_spec() instead",
///                        DeprecationWarning)
///         return cls if _imp.is_frozen(fullname) else None
///
///     @staticmethod
///     def create_module(spec):
///         """Set __file__, if able."""
///         module = _new_module(spec.name)
///         try:
///             filename = spec.loader_state.filename
///         except AttributeError:
///             pass
///         else:
///             if filename:
///                 module.__file__ = filename
///         return module
///
///     @staticmethod
///     def exec_module(module):
///         spec = module.__spec__
///         name = spec.name
///         code = _call_with_frames_removed(_imp.get_frozen_object, name)
///         exec(code, module.__dict__)
///
///     @classmethod
///     def load_module(cls, fullname):
///         """Load a frozen module.
///
///         This method is deprecated.  Use exec_module() instead.
///
///         """
///         # Warning about deprecation implemented in _load_module_shim().
///         module = _load_module_shim(cls, fullname)
///         info = _imp.find_frozen(fullname)
///         assert info is not None
///         _, ispkg, origname = info
///         module.__origname__ = origname
///         vars(module).pop('__file__', None)
///         if ispkg:
///             module.__path__ = []
///         cls._fix_up_module(module)
///         return module
///
///     @classmethod
///     @_requires_frozen
///     def get_code(cls, fullname):
///         """Return the code object for the frozen module."""
///         return _imp.get_frozen_object(fullname)
///
///     @classmethod
///     @_requires_frozen
///     def get_source(cls, fullname):
///         """Return None as frozen modules do not have source code."""
///         return None
///
///     @classmethod
///     @_requires_frozen
///     def is_package(cls, fullname):
///         """Return True if the frozen module is a package."""
///         return _imp.is_frozen_package(fullname)
/// ```
final class FrozenImporter extends PythonClass {
  factory FrozenImporter() => PythonFfiDart.instance.importClass(
        "importlib._bootstrap",
        "FrozenImporter",
        FrozenImporter.from,
        <Object?>[],
      );

  FrozenImporter.from(super.pythonClass) : super.from();

  /// ## create_module
  ///
  /// ### python docstring
  ///
  /// Set __file__, if able.
  Object? create_module() => getFunction("create_module").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## exec_module
  Object? exec_module() => getFunction("exec_module").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## module_repr
  ///
  /// ### python docstring
  ///
  /// Return repr for the module.
  ///
  /// The method is deprecated.  The import machinery does the job itself.
  Object? module_repr() => getFunction("module_repr").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## find_module (getter)
  ///
  /// ### python docstring
  ///
  /// Find a frozen module.
  ///
  /// This method is deprecated.  Use find_spec() instead.
  Object? get find_module => getAttribute("find_module");

  /// ## find_module (setter)
  ///
  /// ### python docstring
  ///
  /// Find a frozen module.
  ///
  /// This method is deprecated.  Use find_spec() instead.
  set find_module(Object? find_module) =>
      setAttribute("find_module", find_module);

  /// ## find_spec (getter)
  Object? get find_spec => getAttribute("find_spec");

  /// ## find_spec (setter)
  set find_spec(Object? find_spec) => setAttribute("find_spec", find_spec);

  /// ## get_code (getter)
  ///
  /// ### python docstring
  ///
  /// Return the code object for the frozen module.
  Object? get get_code => getAttribute("get_code");

  /// ## get_code (setter)
  ///
  /// ### python docstring
  ///
  /// Return the code object for the frozen module.
  set get_code(Object? get_code) => setAttribute("get_code", get_code);

  /// ## get_source (getter)
  ///
  /// ### python docstring
  ///
  /// Return None as frozen modules do not have source code.
  Object? get get_source => getAttribute("get_source");

  /// ## get_source (setter)
  ///
  /// ### python docstring
  ///
  /// Return None as frozen modules do not have source code.
  set get_source(Object? get_source) => setAttribute("get_source", get_source);

  /// ## is_package (getter)
  ///
  /// ### python docstring
  ///
  /// Return True if the frozen module is a package.
  Object? get is_package => getAttribute("is_package");

  /// ## is_package (setter)
  ///
  /// ### python docstring
  ///
  /// Return True if the frozen module is a package.
  set is_package(Object? is_package) => setAttribute("is_package", is_package);

  /// ## load_module (getter)
  ///
  /// ### python docstring
  ///
  /// Load a frozen module.
  ///
  /// This method is deprecated.  Use exec_module() instead.
  Object? get load_module => getAttribute("load_module");

  /// ## load_module (setter)
  ///
  /// ### python docstring
  ///
  /// Load a frozen module.
  ///
  /// This method is deprecated.  Use exec_module() instead.
  set load_module(Object? load_module) =>
      setAttribute("load_module", load_module);
}

/// ## ModuleSpec
///
/// ### python docstring
///
/// The specification for a module, used for loading.
///
/// A module's spec is the source for information about the module.  For
/// data associated with the module, including source, use the spec's
/// loader.
///
/// `name` is the absolute name of the module.  `loader` is the loader
/// to use when loading the module.  `parent` is the name of the
/// package the module is in.  The parent is derived from the name.
///
/// `is_package` determines if the module is considered a package or
/// not.  On modules this is reflected by the `__path__` attribute.
///
/// `origin` is the specific location used by the loader from which to
/// load the module, if that information is available.  When filename is
/// set, origin will match.
///
/// `has_location` indicates that a spec's "origin" reflects a location.
/// When this is True, `__file__` attribute of the module is set.
///
/// `cached` is the location of the cached bytecode file, if any.  It
/// corresponds to the `__cached__` attribute.
///
/// `submodule_search_locations` is the sequence of path entries to
/// search when importing submodules.  If set, is_package should be
/// True--and False otherwise.
///
/// Packages are simply modules that (may) have submodules.  If a spec
/// has a non-None value in `submodule_search_locations`, the import
/// system will consider modules loaded from the spec as packages.
///
/// Only finders (see importlib.abc.MetaPathFinder and
/// importlib.abc.PathEntryFinder) should modify ModuleSpec instances.
///
/// ### python source
/// ```py
/// class ModuleSpec:
///     """The specification for a module, used for loading.
///
///     A module's spec is the source for information about the module.  For
///     data associated with the module, including source, use the spec's
///     loader.
///
///     `name` is the absolute name of the module.  `loader` is the loader
///     to use when loading the module.  `parent` is the name of the
///     package the module is in.  The parent is derived from the name.
///
///     `is_package` determines if the module is considered a package or
///     not.  On modules this is reflected by the `__path__` attribute.
///
///     `origin` is the specific location used by the loader from which to
///     load the module, if that information is available.  When filename is
///     set, origin will match.
///
///     `has_location` indicates that a spec's "origin" reflects a location.
///     When this is True, `__file__` attribute of the module is set.
///
///     `cached` is the location of the cached bytecode file, if any.  It
///     corresponds to the `__cached__` attribute.
///
///     `submodule_search_locations` is the sequence of path entries to
///     search when importing submodules.  If set, is_package should be
///     True--and False otherwise.
///
///     Packages are simply modules that (may) have submodules.  If a spec
///     has a non-None value in `submodule_search_locations`, the import
///     system will consider modules loaded from the spec as packages.
///
///     Only finders (see importlib.abc.MetaPathFinder and
///     importlib.abc.PathEntryFinder) should modify ModuleSpec instances.
///
///     """
///
///     def __init__(self, name, loader, *, origin=None, loader_state=None,
///                  is_package=None):
///         self.name = name
///         self.loader = loader
///         self.origin = origin
///         self.loader_state = loader_state
///         self.submodule_search_locations = [] if is_package else None
///         self._uninitialized_submodules = []
///
///         # file-location attributes
///         self._set_fileattr = False
///         self._cached = None
///
///     def __repr__(self):
///         args = ['name={!r}'.format(self.name),
///                 'loader={!r}'.format(self.loader)]
///         if self.origin is not None:
///             args.append('origin={!r}'.format(self.origin))
///         if self.submodule_search_locations is not None:
///             args.append('submodule_search_locations={}'
///                         .format(self.submodule_search_locations))
///         return '{}({})'.format(self.__class__.__name__, ', '.join(args))
///
///     def __eq__(self, other):
///         smsl = self.submodule_search_locations
///         try:
///             return (self.name == other.name and
///                     self.loader == other.loader and
///                     self.origin == other.origin and
///                     smsl == other.submodule_search_locations and
///                     self.cached == other.cached and
///                     self.has_location == other.has_location)
///         except AttributeError:
///             return NotImplemented
///
///     @property
///     def cached(self):
///         if self._cached is None:
///             if self.origin is not None and self._set_fileattr:
///                 if _bootstrap_external is None:
///                     raise NotImplementedError
///                 self._cached = _bootstrap_external._get_cached(self.origin)
///         return self._cached
///
///     @cached.setter
///     def cached(self, cached):
///         self._cached = cached
///
///     @property
///     def parent(self):
///         """The name of the module's parent."""
///         if self.submodule_search_locations is None:
///             return self.name.rpartition('.')[0]
///         else:
///             return self.name
///
///     @property
///     def has_location(self):
///         return self._set_fileattr
///
///     @has_location.setter
///     def has_location(self, value):
///         self._set_fileattr = bool(value)
/// ```
final class ModuleSpec extends PythonClass {
  factory ModuleSpec({
    required Object? name,
    required Object? loader,
    Object? origin,
    Object? loader_state,
    Object? is_package,
  }) =>
      PythonFfiDart.instance.importClass(
        "importlib._bootstrap",
        "ModuleSpec",
        ModuleSpec.from,
        <Object?>[
          name,
          loader,
        ],
        <String, Object?>{
          "origin": origin,
          "loader_state": loader_state,
          "is_package": is_package,
        },
      );

  ModuleSpec.from(super.pythonClass) : super.from();

  /// ## cached (getter)
  Object? get cached => getAttribute("cached");

  /// ## cached (setter)
  set cached(Object? cached) => setAttribute("cached", cached);

  /// ## has_location (getter)
  Object? get has_location => getAttribute("has_location");

  /// ## has_location (setter)
  set has_location(Object? has_location) =>
      setAttribute("has_location", has_location);

  /// ## parent (getter)
  ///
  /// ### python docstring
  ///
  /// The name of the module's parent.
  Object? get parent => getAttribute("parent");

  /// ## parent (setter)
  ///
  /// ### python docstring
  ///
  /// The name of the module's parent.
  set parent(Object? parent) => setAttribute("parent", parent);
}

/// ## NamespaceLoader
///
/// ### python source
/// ```py
/// class NamespaceLoader:
///     def __init__(self, name, path, path_finder):
///         self._path = _NamespacePath(name, path, path_finder)
///
///     @staticmethod
///     def module_repr(module):
///         """Return repr for the module.
///
///         The method is deprecated.  The import machinery does the job itself.
///
///         """
///         _warnings.warn("NamespaceLoader.module_repr() is deprecated and "
///                        "slated for removal in Python 3.12", DeprecationWarning)
///         return '<module {!r} (namespace)>'.format(module.__name__)
///
///     def is_package(self, fullname):
///         return True
///
///     def get_source(self, fullname):
///         return ''
///
///     def get_code(self, fullname):
///         return compile('', '<string>', 'exec', dont_inherit=True)
///
///     def create_module(self, spec):
///         """Use default semantics for module creation."""
///
///     def exec_module(self, module):
///         pass
///
///     def load_module(self, fullname):
///         """Load a namespace module.
///
///         This method is deprecated.  Use exec_module() instead.
///
///         """
///         # The import system never calls this method.
///         _bootstrap._verbose_message('namespace module loaded with path {!r}',
///                                     self._path)
///         # Warning implemented in _load_module_shim().
///         return _bootstrap._load_module_shim(self, fullname)
///
///     def get_resource_reader(self, module):
///         from importlib.readers import NamespaceReader
///         return NamespaceReader(self._path)
/// ```
final class NamespaceLoader extends PythonClass {
  factory NamespaceLoader({
    required Object? name,
    required Object? path,
    required Object? path_finder,
  }) =>
      PythonFfiDart.instance.importClass(
        "importlib._bootstrap_external",
        "NamespaceLoader",
        NamespaceLoader.from,
        <Object?>[
          name,
          path,
          path_finder,
        ],
        <String, Object?>{},
      );

  NamespaceLoader.from(super.pythonClass) : super.from();

  /// ## create_module
  ///
  /// ### python docstring
  ///
  /// Use default semantics for module creation.
  Object? create_module({
    required Object? spec,
  }) =>
      getFunction("create_module").call(
        <Object?>[
          spec,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## exec_module
  Object? exec_module({
    required Object? module,
  }) =>
      getFunction("exec_module").call(
        <Object?>[
          module,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## get_code
  Object? get_code({
    required Object? fullname,
  }) =>
      getFunction("get_code").call(
        <Object?>[
          fullname,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## get_resource_reader
  Object? get_resource_reader({
    required Object? module,
  }) =>
      getFunction("get_resource_reader").call(
        <Object?>[
          module,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## get_source
  Object? get_source({
    required Object? fullname,
  }) =>
      getFunction("get_source").call(
        <Object?>[
          fullname,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## is_package
  Object? is_package({
    required Object? fullname,
  }) =>
      getFunction("is_package").call(
        <Object?>[
          fullname,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## load_module
  ///
  /// ### python docstring
  ///
  /// Load a namespace module.
  ///
  /// This method is deprecated.  Use exec_module() instead.
  Object? load_module({
    required Object? fullname,
  }) =>
      getFunction("load_module").call(
        <Object?>[
          fullname,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## module_repr
  ///
  /// ### python docstring
  ///
  /// Return repr for the module.
  ///
  /// The method is deprecated.  The import machinery does the job itself.
  Object? module_repr() => getFunction("module_repr").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );
}

/// ## PathFinder
///
/// ### python docstring
///
/// Meta path finder for sys.path and package __path__ attributes.
///
/// ### python source
/// ```py
/// class PathFinder:
///
///     """Meta path finder for sys.path and package __path__ attributes."""
///
///     @staticmethod
///     def invalidate_caches():
///         """Call the invalidate_caches() method on all path entry finders
///         stored in sys.path_importer_caches (where implemented)."""
///         for name, finder in list(sys.path_importer_cache.items()):
///             # Drop entry if finder name is a relative path. The current
///             # working directory may have changed.
///             if finder is None or not _path_isabs(name):
///                 del sys.path_importer_cache[name]
///             elif hasattr(finder, 'invalidate_caches'):
///                 finder.invalidate_caches()
///         # Also invalidate the caches of _NamespacePaths
///         # https://bugs.python.org/issue45703
///         _NamespacePath._epoch += 1
///
///     @staticmethod
///     def _path_hooks(path):
///         """Search sys.path_hooks for a finder for 'path'."""
///         if sys.path_hooks is not None and not sys.path_hooks:
///             _warnings.warn('sys.path_hooks is empty', ImportWarning)
///         for hook in sys.path_hooks:
///             try:
///                 return hook(path)
///             except ImportError:
///                 continue
///         else:
///             return None
///
///     @classmethod
///     def _path_importer_cache(cls, path):
///         """Get the finder for the path entry from sys.path_importer_cache.
///
///         If the path entry is not in the cache, find the appropriate finder
///         and cache it. If no finder is available, store None.
///
///         """
///         if path == '':
///             try:
///                 path = _os.getcwd()
///             except FileNotFoundError:
///                 # Don't cache the failure as the cwd can easily change to
///                 # a valid directory later on.
///                 return None
///         try:
///             finder = sys.path_importer_cache[path]
///         except KeyError:
///             finder = cls._path_hooks(path)
///             sys.path_importer_cache[path] = finder
///         return finder
///
///     @classmethod
///     def _legacy_get_spec(cls, fullname, finder):
///         # This would be a good place for a DeprecationWarning if
///         # we ended up going that route.
///         if hasattr(finder, 'find_loader'):
///             msg = (f"{_bootstrap._object_name(finder)}.find_spec() not found; "
///                     "falling back to find_loader()")
///             _warnings.warn(msg, ImportWarning)
///             loader, portions = finder.find_loader(fullname)
///         else:
///             msg = (f"{_bootstrap._object_name(finder)}.find_spec() not found; "
///                     "falling back to find_module()")
///             _warnings.warn(msg, ImportWarning)
///             loader = finder.find_module(fullname)
///             portions = []
///         if loader is not None:
///             return _bootstrap.spec_from_loader(fullname, loader)
///         spec = _bootstrap.ModuleSpec(fullname, None)
///         spec.submodule_search_locations = portions
///         return spec
///
///     @classmethod
///     def _get_spec(cls, fullname, path, target=None):
///         """Find the loader or namespace_path for this module/package name."""
///         # If this ends up being a namespace package, namespace_path is
///         #  the list of paths that will become its __path__
///         namespace_path = []
///         for entry in path:
///             if not isinstance(entry, str):
///                 continue
///             finder = cls._path_importer_cache(entry)
///             if finder is not None:
///                 if hasattr(finder, 'find_spec'):
///                     spec = finder.find_spec(fullname, target)
///                 else:
///                     spec = cls._legacy_get_spec(fullname, finder)
///                 if spec is None:
///                     continue
///                 if spec.loader is not None:
///                     return spec
///                 portions = spec.submodule_search_locations
///                 if portions is None:
///                     raise ImportError('spec missing loader')
///                 # This is possibly part of a namespace package.
///                 #  Remember these path entries (if any) for when we
///                 #  create a namespace package, and continue iterating
///                 #  on path.
///                 namespace_path.extend(portions)
///         else:
///             spec = _bootstrap.ModuleSpec(fullname, None)
///             spec.submodule_search_locations = namespace_path
///             return spec
///
///     @classmethod
///     def find_spec(cls, fullname, path=None, target=None):
///         """Try to find a spec for 'fullname' on sys.path or 'path'.
///
///         The search is based on sys.path_hooks and sys.path_importer_cache.
///         """
///         if path is None:
///             path = sys.path
///         spec = cls._get_spec(fullname, path, target)
///         if spec is None:
///             return None
///         elif spec.loader is None:
///             namespace_path = spec.submodule_search_locations
///             if namespace_path:
///                 # We found at least one namespace path.  Return a spec which
///                 # can create the namespace package.
///                 spec.origin = None
///                 spec.submodule_search_locations = _NamespacePath(fullname, namespace_path, cls._get_spec)
///                 return spec
///             else:
///                 return None
///         else:
///             return spec
///
///     @classmethod
///     def find_module(cls, fullname, path=None):
///         """find the module on sys.path or 'path' based on sys.path_hooks and
///         sys.path_importer_cache.
///
///         This method is deprecated.  Use find_spec() instead.
///
///         """
///         _warnings.warn("PathFinder.find_module() is deprecated and "
///                        "slated for removal in Python 3.12; use find_spec() instead",
///                        DeprecationWarning)
///         spec = cls.find_spec(fullname, path)
///         if spec is None:
///             return None
///         return spec.loader
///
///     @staticmethod
///     def find_distributions(*args, **kwargs):
///         """
///         Find distributions.
///
///         Return an iterable of all Distribution instances capable of
///         loading the metadata for packages matching ``context.name``
///         (or all names if ``None`` indicated) along the paths in the list
///         of directories ``context.path``.
///         """
///         from importlib.metadata import MetadataPathFinder
///         return MetadataPathFinder.find_distributions(*args, **kwargs)
/// ```
final class PathFinder extends PythonClass {
  factory PathFinder() => PythonFfiDart.instance.importClass(
        "importlib._bootstrap_external",
        "PathFinder",
        PathFinder.from,
        <Object?>[],
      );

  PathFinder.from(super.pythonClass) : super.from();

  /// ## find_distributions
  ///
  /// ### python docstring
  ///
  /// Find distributions.
  ///
  /// Return an iterable of all Distribution instances capable of
  /// loading the metadata for packages matching ``context.name``
  /// (or all names if ``None`` indicated) along the paths in the list
  /// of directories ``context.path``.
  Object? find_distributions({
    List<Object?> args = const <Object?>[],
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("find_distributions").call(
        <Object?>[
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## invalidate_caches
  ///
  /// ### python docstring
  ///
  /// Call the invalidate_caches() method on all path entry finders
  /// stored in sys.path_importer_caches (where implemented).
  Object? invalidate_caches() => getFunction("invalidate_caches").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## find_module (getter)
  ///
  /// ### python docstring
  ///
  /// find the module on sys.path or 'path' based on sys.path_hooks and
  /// sys.path_importer_cache.
  ///
  /// This method is deprecated.  Use find_spec() instead.
  Object? get find_module => getAttribute("find_module");

  /// ## find_module (setter)
  ///
  /// ### python docstring
  ///
  /// find the module on sys.path or 'path' based on sys.path_hooks and
  /// sys.path_importer_cache.
  ///
  /// This method is deprecated.  Use find_spec() instead.
  set find_module(Object? find_module) =>
      setAttribute("find_module", find_module);

  /// ## find_spec (getter)
  ///
  /// ### python docstring
  ///
  /// Try to find a spec for 'fullname' on sys.path or 'path'.
  ///
  /// The search is based on sys.path_hooks and sys.path_importer_cache.
  Object? get find_spec => getAttribute("find_spec");

  /// ## find_spec (setter)
  ///
  /// ### python docstring
  ///
  /// Try to find a spec for 'fullname' on sys.path or 'path'.
  ///
  /// The search is based on sys.path_hooks and sys.path_importer_cache.
  set find_spec(Object? find_spec) => setAttribute("find_spec", find_spec);
}

/// ## SourceFileLoader
///
/// ### python docstring
///
/// Concrete implementation of SourceLoader using the file system.
///
/// ### python source
/// ```py
/// class SourceFileLoader(FileLoader, SourceLoader):
///
///     """Concrete implementation of SourceLoader using the file system."""
///
///     def path_stats(self, path):
///         """Return the metadata for the path."""
///         st = _path_stat(path)
///         return {'mtime': st.st_mtime, 'size': st.st_size}
///
///     def _cache_bytecode(self, source_path, bytecode_path, data):
///         # Adapt between the two APIs
///         mode = _calc_mode(source_path)
///         return self.set_data(bytecode_path, data, _mode=mode)
///
///     def set_data(self, path, data, *, _mode=0o666):
///         """Write bytes data to a file."""
///         parent, filename = _path_split(path)
///         path_parts = []
///         # Figure out what directories are missing.
///         while parent and not _path_isdir(parent):
///             parent, part = _path_split(parent)
///             path_parts.append(part)
///         # Create needed directories.
///         for part in reversed(path_parts):
///             parent = _path_join(parent, part)
///             try:
///                 _os.mkdir(parent)
///             except FileExistsError:
///                 # Probably another Python process already created the dir.
///                 continue
///             except OSError as exc:
///                 # Could be a permission error, read-only filesystem: just forget
///                 # about writing the data.
///                 _bootstrap._verbose_message('could not create {!r}: {!r}',
///                                             parent, exc)
///                 return
///         try:
///             _write_atomic(path, data, _mode)
///             _bootstrap._verbose_message('created {!r}', path)
///         except OSError as exc:
///             # Same as above: just don't write the bytecode.
///             _bootstrap._verbose_message('could not create {!r}: {!r}', path,
///                                         exc)
/// ```
final class SourceFileLoader extends PythonClass {
  factory SourceFileLoader({
    required Object? fullname,
    required Object? path,
  }) =>
      PythonFfiDart.instance.importClass(
        "importlib._bootstrap_external",
        "SourceFileLoader",
        SourceFileLoader.from,
        <Object?>[
          fullname,
          path,
        ],
        <String, Object?>{},
      );

  SourceFileLoader.from(super.pythonClass) : super.from();

  /// ## create_module
  ///
  /// ### python docstring
  ///
  /// Use default semantics for module creation.
  Object? create_module({
    required Object? spec,
  }) =>
      getFunction("create_module").call(
        <Object?>[
          spec,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## exec_module
  ///
  /// ### python docstring
  ///
  /// Execute the module.
  Object? exec_module({
    required Object? module,
  }) =>
      getFunction("exec_module").call(
        <Object?>[
          module,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## get_code
  ///
  /// ### python docstring
  ///
  /// Concrete implementation of InspectLoader.get_code.
  ///
  /// Reading of bytecode requires path_stats to be implemented. To write
  /// bytecode, set_data must also be implemented.
  Object? get_code({
    required Object? fullname,
  }) =>
      getFunction("get_code").call(
        <Object?>[
          fullname,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## get_data
  ///
  /// ### python docstring
  ///
  /// Return the data from path as raw bytes.
  Object? get_data({
    required Object? path,
  }) =>
      getFunction("get_data").call(
        <Object?>[
          path,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## get_filename
  ///
  /// ### python docstring
  ///
  /// Return the path to the source file as found by the finder.
  Object? get_filename({
    List<Object?> args = const <Object?>[],
    Object? name,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("get_filename").call(
        <Object?>[
          name,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## get_resource_reader
  Object? get_resource_reader({
    List<Object?> args = const <Object?>[],
    Object? name,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("get_resource_reader").call(
        <Object?>[
          name,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## get_source
  ///
  /// ### python docstring
  ///
  /// Concrete implementation of InspectLoader.get_source.
  Object? get_source({
    required Object? fullname,
  }) =>
      getFunction("get_source").call(
        <Object?>[
          fullname,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## is_package
  ///
  /// ### python docstring
  ///
  /// Concrete implementation of InspectLoader.is_package by checking if
  /// the path returned by get_filename has a filename of '__init__.py'.
  Object? is_package({
    required Object? fullname,
  }) =>
      getFunction("is_package").call(
        <Object?>[
          fullname,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## load_module
  ///
  /// ### python docstring
  ///
  /// Load a module from a file.
  ///
  /// This method is deprecated.  Use exec_module() instead.
  Object? load_module({
    List<Object?> args = const <Object?>[],
    Object? name,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("load_module").call(
        <Object?>[
          name,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## path_mtime
  ///
  /// ### python docstring
  ///
  /// Optional method that returns the modification time (an int) for the
  /// specified path (a str).
  ///
  /// Raises OSError when the path cannot be handled.
  Object? path_mtime({
    required Object? path,
  }) =>
      getFunction("path_mtime").call(
        <Object?>[
          path,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## path_stats
  ///
  /// ### python docstring
  ///
  /// Return the metadata for the path.
  Object? path_stats({
    required Object? path,
  }) =>
      getFunction("path_stats").call(
        <Object?>[
          path,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## set_data
  ///
  /// ### python docstring
  ///
  /// Write bytes data to a file.
  Object? set_data({
    required Object? path,
    required Object? data,
    Object? $_mode = 438,
  }) =>
      getFunction("set_data").call(
        <Object?>[
          path,
          data,
        ],
        kwargs: <String, Object?>{
          "_mode": $_mode,
        },
      );

  /// ## source_to_code
  ///
  /// ### python docstring
  ///
  /// Return the code object compiled from source.
  ///
  /// The 'data' argument can be any object type that compile() supports.
  Object? source_to_code({
    required Object? data,
    required Object? path,
    Object? $_optimize = -1,
  }) =>
      getFunction("source_to_code").call(
        <Object?>[
          data,
          path,
        ],
        kwargs: <String, Object?>{
          "_optimize": $_optimize,
        },
      );
}

/// ## SourcelessFileLoader
///
/// ### python docstring
///
/// Loader which handles sourceless file imports.
///
/// ### python source
/// ```py
/// class SourcelessFileLoader(FileLoader, _LoaderBasics):
///
///     """Loader which handles sourceless file imports."""
///
///     def get_code(self, fullname):
///         path = self.get_filename(fullname)
///         data = self.get_data(path)
///         # Call _classify_pyc to do basic validation of the pyc but ignore the
///         # result. There's no source to check against.
///         exc_details = {
///             'name': fullname,
///             'path': path,
///         }
///         _classify_pyc(data, fullname, exc_details)
///         return _compile_bytecode(
///             memoryview(data)[16:],
///             name=fullname,
///             bytecode_path=path,
///         )
///
///     def get_source(self, fullname):
///         """Return None as there is no source code."""
///         return None
/// ```
final class SourcelessFileLoader extends PythonClass {
  factory SourcelessFileLoader({
    required Object? fullname,
    required Object? path,
  }) =>
      PythonFfiDart.instance.importClass(
        "importlib._bootstrap_external",
        "SourcelessFileLoader",
        SourcelessFileLoader.from,
        <Object?>[
          fullname,
          path,
        ],
        <String, Object?>{},
      );

  SourcelessFileLoader.from(super.pythonClass) : super.from();

  /// ## create_module
  ///
  /// ### python docstring
  ///
  /// Use default semantics for module creation.
  Object? create_module({
    required Object? spec,
  }) =>
      getFunction("create_module").call(
        <Object?>[
          spec,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## exec_module
  ///
  /// ### python docstring
  ///
  /// Execute the module.
  Object? exec_module({
    required Object? module,
  }) =>
      getFunction("exec_module").call(
        <Object?>[
          module,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## get_code
  Object? get_code({
    required Object? fullname,
  }) =>
      getFunction("get_code").call(
        <Object?>[
          fullname,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## get_data
  ///
  /// ### python docstring
  ///
  /// Return the data from path as raw bytes.
  Object? get_data({
    required Object? path,
  }) =>
      getFunction("get_data").call(
        <Object?>[
          path,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## get_filename
  ///
  /// ### python docstring
  ///
  /// Return the path to the source file as found by the finder.
  Object? get_filename({
    List<Object?> args = const <Object?>[],
    Object? name,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("get_filename").call(
        <Object?>[
          name,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## get_resource_reader
  Object? get_resource_reader({
    List<Object?> args = const <Object?>[],
    Object? name,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("get_resource_reader").call(
        <Object?>[
          name,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## get_source
  ///
  /// ### python docstring
  ///
  /// Return None as there is no source code.
  Object? get_source({
    required Object? fullname,
  }) =>
      getFunction("get_source").call(
        <Object?>[
          fullname,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## is_package
  ///
  /// ### python docstring
  ///
  /// Concrete implementation of InspectLoader.is_package by checking if
  /// the path returned by get_filename has a filename of '__init__.py'.
  Object? is_package({
    required Object? fullname,
  }) =>
      getFunction("is_package").call(
        <Object?>[
          fullname,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## load_module
  ///
  /// ### python docstring
  ///
  /// Load a module from a file.
  ///
  /// This method is deprecated.  Use exec_module() instead.
  Object? load_module({
    List<Object?> args = const <Object?>[],
    Object? name,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("load_module").call(
        <Object?>[
          name,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );
}

/// ## WindowsRegistryFinder
///
/// ### python docstring
///
/// Meta path finder for modules declared in the Windows registry.
///
/// ### python source
/// ```py
/// class WindowsRegistryFinder:
///
///     """Meta path finder for modules declared in the Windows registry."""
///
///     REGISTRY_KEY = (
///         'Software\\Python\\PythonCore\\{sys_version}'
///         '\\Modules\\{fullname}')
///     REGISTRY_KEY_DEBUG = (
///         'Software\\Python\\PythonCore\\{sys_version}'
///         '\\Modules\\{fullname}\\Debug')
///     DEBUG_BUILD = (_MS_WINDOWS and '_d.pyd' in EXTENSION_SUFFIXES)
///
///     @staticmethod
///     def _open_registry(key):
///         try:
///             return winreg.OpenKey(winreg.HKEY_CURRENT_USER, key)
///         except OSError:
///             return winreg.OpenKey(winreg.HKEY_LOCAL_MACHINE, key)
///
///     @classmethod
///     def _search_registry(cls, fullname):
///         if cls.DEBUG_BUILD:
///             registry_key = cls.REGISTRY_KEY_DEBUG
///         else:
///             registry_key = cls.REGISTRY_KEY
///         key = registry_key.format(fullname=fullname,
///                                   sys_version='%d.%d' % sys.version_info[:2])
///         try:
///             with cls._open_registry(key) as hkey:
///                 filepath = winreg.QueryValue(hkey, '')
///         except OSError:
///             return None
///         return filepath
///
///     @classmethod
///     def find_spec(cls, fullname, path=None, target=None):
///         filepath = cls._search_registry(fullname)
///         if filepath is None:
///             return None
///         try:
///             _path_stat(filepath)
///         except OSError:
///             return None
///         for loader, suffixes in _get_supported_file_loaders():
///             if filepath.endswith(tuple(suffixes)):
///                 spec = _bootstrap.spec_from_loader(fullname,
///                                                    loader(fullname, filepath),
///                                                    origin=filepath)
///                 return spec
///
///     @classmethod
///     def find_module(cls, fullname, path=None):
///         """Find module named in the registry.
///
///         This method is deprecated.  Use find_spec() instead.
///
///         """
///         _warnings.warn("WindowsRegistryFinder.find_module() is deprecated and "
///                        "slated for removal in Python 3.12; use find_spec() instead",
///                        DeprecationWarning)
///         spec = cls.find_spec(fullname, path)
///         if spec is not None:
///             return spec.loader
///         else:
///             return None
/// ```
final class WindowsRegistryFinder extends PythonClass {
  factory WindowsRegistryFinder() => PythonFfiDart.instance.importClass(
        "importlib._bootstrap_external",
        "WindowsRegistryFinder",
        WindowsRegistryFinder.from,
        <Object?>[],
      );

  WindowsRegistryFinder.from(super.pythonClass) : super.from();

  /// ## find_module (getter)
  ///
  /// ### python docstring
  ///
  /// Find module named in the registry.
  ///
  /// This method is deprecated.  Use find_spec() instead.
  Object? get find_module => getAttribute("find_module");

  /// ## find_module (setter)
  ///
  /// ### python docstring
  ///
  /// Find module named in the registry.
  ///
  /// This method is deprecated.  Use find_spec() instead.
  set find_module(Object? find_module) =>
      setAttribute("find_module", find_module);

  /// ## find_spec (getter)
  Object? get find_spec => getAttribute("find_spec");

  /// ## find_spec (setter)
  set find_spec(Object? find_spec) => setAttribute("find_spec", find_spec);

  /// ## DEBUG_BUILD (getter)
  Object? get DEBUG_BUILD => getAttribute("DEBUG_BUILD");

  /// ## DEBUG_BUILD (setter)
  set DEBUG_BUILD(Object? DEBUG_BUILD) =>
      setAttribute("DEBUG_BUILD", DEBUG_BUILD);

  /// ## REGISTRY_KEY (getter)
  Object? get REGISTRY_KEY => getAttribute("REGISTRY_KEY");

  /// ## REGISTRY_KEY (setter)
  set REGISTRY_KEY(Object? REGISTRY_KEY) =>
      setAttribute("REGISTRY_KEY", REGISTRY_KEY);

  /// ## REGISTRY_KEY_DEBUG (getter)
  Object? get REGISTRY_KEY_DEBUG => getAttribute("REGISTRY_KEY_DEBUG");

  /// ## REGISTRY_KEY_DEBUG (setter)
  set REGISTRY_KEY_DEBUG(Object? REGISTRY_KEY_DEBUG) =>
      setAttribute("REGISTRY_KEY_DEBUG", REGISTRY_KEY_DEBUG);
}

/// ## LazyLoader
///
/// ### python docstring
///
/// A loader that creates a module which defers loading until attribute access.
///
/// ### python source
/// ```py
/// class LazyLoader(Loader):
///
///     """A loader that creates a module which defers loading until attribute access."""
///
///     @staticmethod
///     def __check_eager_loader(loader):
///         if not hasattr(loader, 'exec_module'):
///             raise TypeError('loader must define exec_module()')
///
///     @classmethod
///     def factory(cls, loader):
///         """Construct a callable which returns the eager loader made lazy."""
///         cls.__check_eager_loader(loader)
///         return lambda *args, **kwargs: cls(loader(*args, **kwargs))
///
///     def __init__(self, loader):
///         self.__check_eager_loader(loader)
///         self.loader = loader
///
///     def create_module(self, spec):
///         return self.loader.create_module(spec)
///
///     def exec_module(self, module):
///         """Make the module load lazily."""
///         module.__spec__.loader = self.loader
///         module.__loader__ = self.loader
///         # Don't need to worry about deep-copying as trying to set an attribute
///         # on an object would have triggered the load,
///         # e.g. ``module.__spec__.loader = None`` would trigger a load from
///         # trying to access module.__spec__.
///         loader_state = {}
///         loader_state['__dict__'] = module.__dict__.copy()
///         loader_state['__class__'] = module.__class__
///         module.__spec__.loader_state = loader_state
///         module.__class__ = _LazyModule
/// ```
final class LazyLoader extends PythonClass {
  factory LazyLoader({
    required Object? loader,
  }) =>
      PythonFfiDart.instance.importClass(
        "importlib.util",
        "LazyLoader",
        LazyLoader.from,
        <Object?>[
          loader,
        ],
        <String, Object?>{},
      );

  LazyLoader.from(super.pythonClass) : super.from();

  /// ## create_module
  ///
  /// ### python docstring
  ///
  /// Return a module to initialize and into which to load.
  ///
  /// This method should raise ImportError if anything prevents it
  /// from creating a new module.  It may return None to indicate
  /// that the spec should create the new module.
  Object? create_module({
    required Object? spec,
  }) =>
      getFunction("create_module").call(
        <Object?>[
          spec,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## exec_module
  ///
  /// ### python docstring
  ///
  /// Make the module load lazily.
  Object? exec_module({
    required Object? module,
  }) =>
      getFunction("exec_module").call(
        <Object?>[
          module,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## load_module
  ///
  /// ### python docstring
  ///
  /// Return the loaded module.
  ///
  /// The module must be added to sys.modules and have import-related
  /// attributes set properly.  The fullname is a str.
  ///
  /// ImportError is raised on failure.
  ///
  /// This method is deprecated in favor of loader.exec_module(). If
  /// exec_module() exists then it is used to provide a backwards-compatible
  /// functionality for this method.
  ///
  /// ### python source
  /// ```py
  /// def load_module(self, fullname):
  ///         """Return the loaded module.
  ///
  ///         The module must be added to sys.modules and have import-related
  ///         attributes set properly.  The fullname is a str.
  ///
  ///         ImportError is raised on failure.
  ///
  ///         This method is deprecated in favor of loader.exec_module(). If
  ///         exec_module() exists then it is used to provide a backwards-compatible
  ///         functionality for this method.
  ///
  ///         """
  ///         if not hasattr(self, 'exec_module'):
  ///             raise ImportError
  ///         # Warning implemented in _load_module_shim().
  ///         return _bootstrap._load_module_shim(self, fullname)
  /// ```
  Object? load_module({
    required Object? fullname,
  }) =>
      getFunction("load_module").call(
        <Object?>[
          fullname,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## module_repr
  ///
  /// ### python docstring
  ///
  /// Return a module's repr.
  ///
  /// Used by the module type when the method does not raise
  /// NotImplementedError.
  ///
  /// This method is deprecated.
  ///
  /// ### python source
  /// ```py
  /// def module_repr(self, module):
  ///         """Return a module's repr.
  ///
  ///         Used by the module type when the method does not raise
  ///         NotImplementedError.
  ///
  ///         This method is deprecated.
  ///
  ///         """
  ///         warnings.warn("importlib.abc.Loader.module_repr() is deprecated and "
  ///                       "slated for removal in Python 3.12", DeprecationWarning)
  ///         # The exception will cause ModuleType.__repr__ to ignore this method.
  ///         raise NotImplementedError
  /// ```
  Object? module_repr({
    required Object? module,
  }) =>
      getFunction("module_repr").call(
        <Object?>[
          module,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## factory (getter)
  ///
  /// ### python docstring
  ///
  /// Construct a callable which returns the eager loader made lazy.
  Object? get $factory => getAttribute("factory");

  /// ## factory (setter)
  ///
  /// ### python docstring
  ///
  /// Construct a callable which returns the eager loader made lazy.
  set $factory(Object? $factory) => setAttribute("factory", $factory);
}

/// ## Loader
///
/// ### python docstring
///
/// Abstract base class for import loaders.
///
/// ### python source
/// ```py
/// class Loader(metaclass=abc.ABCMeta):
///
///     """Abstract base class for import loaders."""
///
///     def create_module(self, spec):
///         """Return a module to initialize and into which to load.
///
///         This method should raise ImportError if anything prevents it
///         from creating a new module.  It may return None to indicate
///         that the spec should create the new module.
///         """
///         # By default, defer to default semantics for the new module.
///         return None
///
///     # We don't define exec_module() here since that would break
///     # hasattr checks we do to support backward compatibility.
///
///     def load_module(self, fullname):
///         """Return the loaded module.
///
///         The module must be added to sys.modules and have import-related
///         attributes set properly.  The fullname is a str.
///
///         ImportError is raised on failure.
///
///         This method is deprecated in favor of loader.exec_module(). If
///         exec_module() exists then it is used to provide a backwards-compatible
///         functionality for this method.
///
///         """
///         if not hasattr(self, 'exec_module'):
///             raise ImportError
///         # Warning implemented in _load_module_shim().
///         return _bootstrap._load_module_shim(self, fullname)
///
///     def module_repr(self, module):
///         """Return a module's repr.
///
///         Used by the module type when the method does not raise
///         NotImplementedError.
///
///         This method is deprecated.
///
///         """
///         warnings.warn("importlib.abc.Loader.module_repr() is deprecated and "
///                       "slated for removal in Python 3.12", DeprecationWarning)
///         # The exception will cause ModuleType.__repr__ to ignore this method.
///         raise NotImplementedError
/// ```
final class Loader extends PythonClass {
  factory Loader() => PythonFfiDart.instance.importClass(
        "importlib._abc",
        "Loader",
        Loader.from,
        <Object?>[],
      );

  Loader.from(super.pythonClass) : super.from();

  /// ## create_module
  ///
  /// ### python docstring
  ///
  /// Return a module to initialize and into which to load.
  ///
  /// This method should raise ImportError if anything prevents it
  /// from creating a new module.  It may return None to indicate
  /// that the spec should create the new module.
  ///
  /// ### python source
  /// ```py
  /// def create_module(self, spec):
  ///         """Return a module to initialize and into which to load.
  ///
  ///         This method should raise ImportError if anything prevents it
  ///         from creating a new module.  It may return None to indicate
  ///         that the spec should create the new module.
  ///         """
  ///         # By default, defer to default semantics for the new module.
  ///         return None
  /// ```
  Object? create_module({
    required Object? spec,
  }) =>
      getFunction("create_module").call(
        <Object?>[
          spec,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## load_module
  ///
  /// ### python docstring
  ///
  /// Return the loaded module.
  ///
  /// The module must be added to sys.modules and have import-related
  /// attributes set properly.  The fullname is a str.
  ///
  /// ImportError is raised on failure.
  ///
  /// This method is deprecated in favor of loader.exec_module(). If
  /// exec_module() exists then it is used to provide a backwards-compatible
  /// functionality for this method.
  ///
  /// ### python source
  /// ```py
  /// def load_module(self, fullname):
  ///         """Return the loaded module.
  ///
  ///         The module must be added to sys.modules and have import-related
  ///         attributes set properly.  The fullname is a str.
  ///
  ///         ImportError is raised on failure.
  ///
  ///         This method is deprecated in favor of loader.exec_module(). If
  ///         exec_module() exists then it is used to provide a backwards-compatible
  ///         functionality for this method.
  ///
  ///         """
  ///         if not hasattr(self, 'exec_module'):
  ///             raise ImportError
  ///         # Warning implemented in _load_module_shim().
  ///         return _bootstrap._load_module_shim(self, fullname)
  /// ```
  Object? load_module({
    required Object? fullname,
  }) =>
      getFunction("load_module").call(
        <Object?>[
          fullname,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## module_repr
  ///
  /// ### python docstring
  ///
  /// Return a module's repr.
  ///
  /// Used by the module type when the method does not raise
  /// NotImplementedError.
  ///
  /// This method is deprecated.
  ///
  /// ### python source
  /// ```py
  /// def module_repr(self, module):
  ///         """Return a module's repr.
  ///
  ///         Used by the module type when the method does not raise
  ///         NotImplementedError.
  ///
  ///         This method is deprecated.
  ///
  ///         """
  ///         warnings.warn("importlib.abc.Loader.module_repr() is deprecated and "
  ///                       "slated for removal in Python 3.12", DeprecationWarning)
  ///         # The exception will cause ModuleType.__repr__ to ignore this method.
  ///         raise NotImplementedError
  /// ```
  Object? module_repr({
    required Object? module,
  }) =>
      getFunction("module_repr").call(
        <Object?>[
          module,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## ZipImportError
///
/// ### python source
/// ```py
/// class ZipImportError(ImportError):
///     pass
/// ```
final class ZipImportError extends PythonClass {
  factory ZipImportError() => PythonFfiDart.instance.importClass(
        "zipimport",
        "ZipImportError",
        ZipImportError.from,
        <Object?>[],
      );

  ZipImportError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## msg (getter)
  Object? get msg => getAttribute("msg");

  /// ## msg (setter)
  set msg(Object? msg) => setAttribute("msg", msg);

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);

  /// ## path (getter)
  Object? get path => getAttribute("path");

  /// ## path (setter)
  set path(Object? path) => setAttribute("path", path);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## struct_time
///
/// ### python docstring
///
/// The time value as returned by gmtime(), localtime(), and strptime(), and
/// accepted by asctime(), mktime() and strftime().  May be considered as a
/// sequence of 9 integers.
///
/// Note that several fields' values are not the same as those defined by
/// the C language standard for struct tm.  For example, the value of the
/// field tm_year is the actual year, not year - 1900.  See individual
/// fields' descriptions for details.
final class struct_time extends PythonClass {
  factory struct_time() => PythonFfiDart.instance.importClass(
        "time",
        "struct_time",
        struct_time.from,
        <Object?>[],
      );

  struct_time.from(super.pythonClass) : super.from();

  /// ## tm_gmtoff (getter)
  ///
  /// ### python docstring
  ///
  /// offset from UTC in seconds
  Object? get tm_gmtoff => getAttribute("tm_gmtoff");

  /// ## tm_gmtoff (setter)
  ///
  /// ### python docstring
  ///
  /// offset from UTC in seconds
  set tm_gmtoff(Object? tm_gmtoff) => setAttribute("tm_gmtoff", tm_gmtoff);

  /// ## tm_hour (getter)
  ///
  /// ### python docstring
  ///
  /// hours, range [0, 23]
  Object? get tm_hour => getAttribute("tm_hour");

  /// ## tm_hour (setter)
  ///
  /// ### python docstring
  ///
  /// hours, range [0, 23]
  set tm_hour(Object? tm_hour) => setAttribute("tm_hour", tm_hour);

  /// ## tm_isdst (getter)
  ///
  /// ### python docstring
  ///
  /// 1 if summer time is in effect, 0 if not, and -1 if unknown
  Object? get tm_isdst => getAttribute("tm_isdst");

  /// ## tm_isdst (setter)
  ///
  /// ### python docstring
  ///
  /// 1 if summer time is in effect, 0 if not, and -1 if unknown
  set tm_isdst(Object? tm_isdst) => setAttribute("tm_isdst", tm_isdst);

  /// ## tm_mday (getter)
  ///
  /// ### python docstring
  ///
  /// day of month, range [1, 31]
  Object? get tm_mday => getAttribute("tm_mday");

  /// ## tm_mday (setter)
  ///
  /// ### python docstring
  ///
  /// day of month, range [1, 31]
  set tm_mday(Object? tm_mday) => setAttribute("tm_mday", tm_mday);

  /// ## tm_min (getter)
  ///
  /// ### python docstring
  ///
  /// minutes, range [0, 59]
  Object? get tm_min => getAttribute("tm_min");

  /// ## tm_min (setter)
  ///
  /// ### python docstring
  ///
  /// minutes, range [0, 59]
  set tm_min(Object? tm_min) => setAttribute("tm_min", tm_min);

  /// ## tm_mon (getter)
  ///
  /// ### python docstring
  ///
  /// month of year, range [1, 12]
  Object? get tm_mon => getAttribute("tm_mon");

  /// ## tm_mon (setter)
  ///
  /// ### python docstring
  ///
  /// month of year, range [1, 12]
  set tm_mon(Object? tm_mon) => setAttribute("tm_mon", tm_mon);

  /// ## tm_sec (getter)
  ///
  /// ### python docstring
  ///
  /// seconds, range [0, 61])
  Object? get tm_sec => getAttribute("tm_sec");

  /// ## tm_sec (setter)
  ///
  /// ### python docstring
  ///
  /// seconds, range [0, 61])
  set tm_sec(Object? tm_sec) => setAttribute("tm_sec", tm_sec);

  /// ## tm_wday (getter)
  ///
  /// ### python docstring
  ///
  /// day of week, range [0, 6], Monday is 0
  Object? get tm_wday => getAttribute("tm_wday");

  /// ## tm_wday (setter)
  ///
  /// ### python docstring
  ///
  /// day of week, range [0, 6], Monday is 0
  set tm_wday(Object? tm_wday) => setAttribute("tm_wday", tm_wday);

  /// ## tm_yday (getter)
  ///
  /// ### python docstring
  ///
  /// day of year, range [1, 366]
  Object? get tm_yday => getAttribute("tm_yday");

  /// ## tm_yday (setter)
  ///
  /// ### python docstring
  ///
  /// day of year, range [1, 366]
  set tm_yday(Object? tm_yday) => setAttribute("tm_yday", tm_yday);

  /// ## tm_year (getter)
  ///
  /// ### python docstring
  ///
  /// year, for example, 1993
  Object? get tm_year => getAttribute("tm_year");

  /// ## tm_year (setter)
  ///
  /// ### python docstring
  ///
  /// year, for example, 1993
  set tm_year(Object? tm_year) => setAttribute("tm_year", tm_year);

  /// ## tm_zone (getter)
  ///
  /// ### python docstring
  ///
  /// abbreviation of timezone name
  Object? get tm_zone => getAttribute("tm_zone");

  /// ## tm_zone (setter)
  ///
  /// ### python docstring
  ///
  /// abbreviation of timezone name
  set tm_zone(Object? tm_zone) => setAttribute("tm_zone", tm_zone);

  /// ## count (getter)
  Object? get count => getAttribute("count");

  /// ## count (setter)
  set count(Object? count) => setAttribute("count", count);

  /// ## index (getter)
  Object? get index => getAttribute("index");

  /// ## index (setter)
  set index(Object? index) => setAttribute("index", index);

  /// ## n_fields (getter)
  Object? get n_fields => getAttribute("n_fields");

  /// ## n_fields (setter)
  set n_fields(Object? n_fields) => setAttribute("n_fields", n_fields);

  /// ## n_sequence_fields (getter)
  Object? get n_sequence_fields => getAttribute("n_sequence_fields");

  /// ## n_sequence_fields (setter)
  set n_sequence_fields(Object? n_sequence_fields) =>
      setAttribute("n_sequence_fields", n_sequence_fields);

  /// ## n_unnamed_fields (getter)
  Object? get n_unnamed_fields => getAttribute("n_unnamed_fields");

  /// ## n_unnamed_fields (setter)
  set n_unnamed_fields(Object? n_unnamed_fields) =>
      setAttribute("n_unnamed_fields", n_unnamed_fields);
}

/// ## zipimporter
///
/// ### python docstring
///
/// zipimporter(archivepath) -> zipimporter object
///
/// Create a new zipimporter instance. 'archivepath' must be a path to
/// a zipfile, or to a specific path inside a zipfile. For example, it can be
/// '/tmp/myimport.zip', or '/tmp/myimport.zip/mydirectory', if mydirectory is a
/// valid directory inside the archive.
///
/// 'ZipImportError is raised if 'archivepath' doesn't point to a valid Zip
/// archive.
///
/// The 'archive' attribute of zipimporter objects contains the name of the
/// zipfile targeted.
///
/// ### python source
/// ```py
/// class zipimporter(_bootstrap_external._LoaderBasics):
///     """zipimporter(archivepath) -> zipimporter object
///
///     Create a new zipimporter instance. 'archivepath' must be a path to
///     a zipfile, or to a specific path inside a zipfile. For example, it can be
///     '/tmp/myimport.zip', or '/tmp/myimport.zip/mydirectory', if mydirectory is a
///     valid directory inside the archive.
///
///     'ZipImportError is raised if 'archivepath' doesn't point to a valid Zip
///     archive.
///
///     The 'archive' attribute of zipimporter objects contains the name of the
///     zipfile targeted.
///     """
///
///     # Split the "subdirectory" from the Zip archive path, lookup a matching
///     # entry in sys.path_importer_cache, fetch the file directory from there
///     # if found, or else read it from the archive.
///     def __init__(self, path):
///         if not isinstance(path, str):
///             raise TypeError(f"expected str, not {type(path)!r}")
///         if not path:
///             raise ZipImportError('archive path is empty', path=path)
///         if alt_path_sep:
///             path = path.replace(alt_path_sep, path_sep)
///
///         prefix = []
///         while True:
///             try:
///                 st = _bootstrap_external._path_stat(path)
///             except (OSError, ValueError):
///                 # On Windows a ValueError is raised for too long paths.
///                 # Back up one path element.
///                 dirname, basename = _bootstrap_external._path_split(path)
///                 if dirname == path:
///                     raise ZipImportError('not a Zip file', path=path)
///                 path = dirname
///                 prefix.append(basename)
///             else:
///                 # it exists
///                 if (st.st_mode & 0o170000) != 0o100000:  # stat.S_ISREG
///                     # it's a not file
///                     raise ZipImportError('not a Zip file', path=path)
///                 break
///
///         try:
///             files = _zip_directory_cache[path]
///         except KeyError:
///             files = _read_directory(path)
///             _zip_directory_cache[path] = files
///         self._files = files
///         self.archive = path
///         # a prefix directory following the ZIP file path.
///         self.prefix = _bootstrap_external._path_join(*prefix[::-1])
///         if self.prefix:
///             self.prefix += path_sep
///
///
///     # Check whether we can satisfy the import of the module named by
///     # 'fullname', or whether it could be a portion of a namespace
///     # package. Return self if we can load it, a string containing the
///     # full path if it's a possible namespace portion, None if we
///     # can't load it.
///     def find_loader(self, fullname, path=None):
///         """find_loader(fullname, path=None) -> self, str or None.
///
///         Search for a module specified by 'fullname'. 'fullname' must be the
///         fully qualified (dotted) module name. It returns the zipimporter
///         instance itself if the module was found, a string containing the
///         full path name if it's possibly a portion of a namespace package,
///         or None otherwise. The optional 'path' argument is ignored -- it's
///         there for compatibility with the importer protocol.
///
///         Deprecated since Python 3.10. Use find_spec() instead.
///         """
///         _warnings.warn("zipimporter.find_loader() is deprecated and slated for "
///                        "removal in Python 3.12; use find_spec() instead",
///                        DeprecationWarning)
///         mi = _get_module_info(self, fullname)
///         if mi is not None:
///             # This is a module or package.
///             return self, []
///
///         # Not a module or regular package. See if this is a directory, and
///         # therefore possibly a portion of a namespace package.
///
///         # We're only interested in the last path component of fullname
///         # earlier components are recorded in self.prefix.
///         modpath = _get_module_path(self, fullname)
///         if _is_dir(self, modpath):
///             # This is possibly a portion of a namespace
///             # package. Return the string representing its path,
///             # without a trailing separator.
///             return None, [f'{self.archive}{path_sep}{modpath}']
///
///         return None, []
///
///
///     # Check whether we can satisfy the import of the module named by
///     # 'fullname'. Return self if we can, None if we can't.
///     def find_module(self, fullname, path=None):
///         """find_module(fullname, path=None) -> self or None.
///
///         Search for a module specified by 'fullname'. 'fullname' must be the
///         fully qualified (dotted) module name. It returns the zipimporter
///         instance itself if the module was found, or None if it wasn't.
///         The optional 'path' argument is ignored -- it's there for compatibility
///         with the importer protocol.
///
///         Deprecated since Python 3.10. Use find_spec() instead.
///         """
///         _warnings.warn("zipimporter.find_module() is deprecated and slated for "
///                        "removal in Python 3.12; use find_spec() instead",
///                        DeprecationWarning)
///         return self.find_loader(fullname, path)[0]
///
///     def find_spec(self, fullname, target=None):
///         """Create a ModuleSpec for the specified module.
///
///         Returns None if the module cannot be found.
///         """
///         module_info = _get_module_info(self, fullname)
///         if module_info is not None:
///             return _bootstrap.spec_from_loader(fullname, self, is_package=module_info)
///         else:
///             # Not a module or regular package. See if this is a directory, and
///             # therefore possibly a portion of a namespace package.
///
///             # We're only interested in the last path component of fullname
///             # earlier components are recorded in self.prefix.
///             modpath = _get_module_path(self, fullname)
///             if _is_dir(self, modpath):
///                 # This is possibly a portion of a namespace
///                 # package. Return the string representing its path,
///                 # without a trailing separator.
///                 path = f'{self.archive}{path_sep}{modpath}'
///                 spec = _bootstrap.ModuleSpec(name=fullname, loader=None,
///                                              is_package=True)
///                 spec.submodule_search_locations.append(path)
///                 return spec
///             else:
///                 return None
///
///     def get_code(self, fullname):
///         """get_code(fullname) -> code object.
///
///         Return the code object for the specified module. Raise ZipImportError
///         if the module couldn't be imported.
///         """
///         code, ispackage, modpath = _get_module_code(self, fullname)
///         return code
///
///
///     def get_data(self, pathname):
///         """get_data(pathname) -> string with file data.
///
///         Return the data associated with 'pathname'. Raise OSError if
///         the file wasn't found.
///         """
///         if alt_path_sep:
///             pathname = pathname.replace(alt_path_sep, path_sep)
///
///         key = pathname
///         if pathname.startswith(self.archive + path_sep):
///             key = pathname[len(self.archive + path_sep):]
///
///         try:
///             toc_entry = self._files[key]
///         except KeyError:
///             raise OSError(0, '', key)
///         return _get_data(self.archive, toc_entry)
///
///
///     # Return a string matching __file__ for the named module
///     def get_filename(self, fullname):
///         """get_filename(fullname) -> filename string.
///
///         Return the filename for the specified module or raise ZipImportError
///         if it couldn't be imported.
///         """
///         # Deciding the filename requires working out where the code
///         # would come from if the module was actually loaded
///         code, ispackage, modpath = _get_module_code(self, fullname)
///         return modpath
///
///
///     def get_source(self, fullname):
///         """get_source(fullname) -> source string.
///
///         Return the source code for the specified module. Raise ZipImportError
///         if the module couldn't be found, return None if the archive does
///         contain the module, but has no source for it.
///         """
///         mi = _get_module_info(self, fullname)
///         if mi is None:
///             raise ZipImportError(f"can't find module {fullname!r}", name=fullname)
///
///         path = _get_module_path(self, fullname)
///         if mi:
///             fullpath = _bootstrap_external._path_join(path, '__init__.py')
///         else:
///             fullpath = f'{path}.py'
///
///         try:
///             toc_entry = self._files[fullpath]
///         except KeyError:
///             # we have the module, but no source
///             return None
///         return _get_data(self.archive, toc_entry).decode()
///
///
///     # Return a bool signifying whether the module is a package or not.
///     def is_package(self, fullname):
///         """is_package(fullname) -> bool.
///
///         Return True if the module specified by fullname is a package.
///         Raise ZipImportError if the module couldn't be found.
///         """
///         mi = _get_module_info(self, fullname)
///         if mi is None:
///             raise ZipImportError(f"can't find module {fullname!r}", name=fullname)
///         return mi
///
///
///     # Load and return the module named by 'fullname'.
///     def load_module(self, fullname):
///         """load_module(fullname) -> module.
///
///         Load the module specified by 'fullname'. 'fullname' must be the
///         fully qualified (dotted) module name. It returns the imported
///         module, or raises ZipImportError if it could not be imported.
///
///         Deprecated since Python 3.10. Use exec_module() instead.
///         """
///         msg = ("zipimport.zipimporter.load_module() is deprecated and slated for "
///                "removal in Python 3.12; use exec_module() instead")
///         _warnings.warn(msg, DeprecationWarning)
///         code, ispackage, modpath = _get_module_code(self, fullname)
///         mod = sys.modules.get(fullname)
///         if mod is None or not isinstance(mod, _module_type):
///             mod = _module_type(fullname)
///             sys.modules[fullname] = mod
///         mod.__loader__ = self
///
///         try:
///             if ispackage:
///                 # add __path__ to the module *before* the code gets
///                 # executed
///                 path = _get_module_path(self, fullname)
///                 fullpath = _bootstrap_external._path_join(self.archive, path)
///                 mod.__path__ = [fullpath]
///
///             if not hasattr(mod, '__builtins__'):
///                 mod.__builtins__ = __builtins__
///             _bootstrap_external._fix_up_module(mod.__dict__, fullname, modpath)
///             exec(code, mod.__dict__)
///         except:
///             del sys.modules[fullname]
///             raise
///
///         try:
///             mod = sys.modules[fullname]
///         except KeyError:
///             raise ImportError(f'Loaded module {fullname!r} not found in sys.modules')
///         _bootstrap._verbose_message('import {} # loaded from Zip {}', fullname, modpath)
///         return mod
///
///
///     def get_resource_reader(self, fullname):
///         """Return the ResourceReader for a package in a zip file.
///
///         If 'fullname' is a package within the zip file, return the
///         'ResourceReader' object for the package.  Otherwise return None.
///         """
///         try:
///             if not self.is_package(fullname):
///                 return None
///         except ZipImportError:
///             return None
///         from importlib.readers import ZipReader
///         return ZipReader(self, fullname)
///
///
///     def invalidate_caches(self):
///         """Reload the file data of the archive path."""
///         try:
///             self._files = _read_directory(self.archive)
///             _zip_directory_cache[self.archive] = self._files
///         except ZipImportError:
///             _zip_directory_cache.pop(self.archive, None)
///             self._files = {}
///
///
///     def __repr__(self):
///         return f'<zipimporter object "{self.archive}{path_sep}{self.prefix}">'
/// ```
final class zipimporter extends PythonClass {
  factory zipimporter({
    required Object? path,
  }) =>
      PythonFfiDart.instance.importClass(
        "zipimport",
        "zipimporter",
        zipimporter.from,
        <Object?>[
          path,
        ],
        <String, Object?>{},
      );

  zipimporter.from(super.pythonClass) : super.from();

  /// ## create_module
  ///
  /// ### python docstring
  ///
  /// Use default semantics for module creation.
  Object? create_module({
    required Object? spec,
  }) =>
      getFunction("create_module").call(
        <Object?>[
          spec,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## exec_module
  ///
  /// ### python docstring
  ///
  /// Execute the module.
  Object? exec_module({
    required Object? module,
  }) =>
      getFunction("exec_module").call(
        <Object?>[
          module,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## find_loader
  ///
  /// ### python docstring
  ///
  /// find_loader(fullname, path=None) -> self, str or None.
  ///
  /// Search for a module specified by 'fullname'. 'fullname' must be the
  /// fully qualified (dotted) module name. It returns the zipimporter
  /// instance itself if the module was found, a string containing the
  /// full path name if it's possibly a portion of a namespace package,
  /// or None otherwise. The optional 'path' argument is ignored -- it's
  /// there for compatibility with the importer protocol.
  ///
  /// Deprecated since Python 3.10. Use find_spec() instead.!
  Object? find_loader({
    required Object? fullname,
    Object? path,
  }) =>
      getFunction("find_loader").call(
        <Object?>[
          fullname,
          path,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## find_module
  ///
  /// ### python docstring
  ///
  /// find_module(fullname, path=None) -> self or None.
  ///
  /// Search for a module specified by 'fullname'. 'fullname' must be the
  /// fully qualified (dotted) module name. It returns the zipimporter
  /// instance itself if the module was found, or None if it wasn't.
  /// The optional 'path' argument is ignored -- it's there for compatibility
  /// with the importer protocol.
  ///
  /// Deprecated since Python 3.10. Use find_spec() instead.
  Object? find_module({
    required Object? fullname,
    Object? path,
  }) =>
      getFunction("find_module").call(
        <Object?>[
          fullname,
          path,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## find_spec
  ///
  /// ### python docstring
  ///
  /// Create a ModuleSpec for the specified module.
  ///
  /// Returns None if the module cannot be found.
  Object? find_spec({
    required Object? fullname,
    Object? target,
  }) =>
      getFunction("find_spec").call(
        <Object?>[
          fullname,
          target,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## get_code
  ///
  /// ### python docstring
  ///
  /// get_code(fullname) -> code object.
  ///
  /// Return the code object for the specified module. Raise ZipImportError
  /// if the module couldn't be imported.
  Object? get_code({
    required Object? fullname,
  }) =>
      getFunction("get_code").call(
        <Object?>[
          fullname,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## get_data
  ///
  /// ### python docstring
  ///
  /// get_data(pathname) -> string with file data.
  ///
  /// Return the data associated with 'pathname'. Raise OSError if
  /// the file wasn't found.
  Object? get_data({
    required Object? pathname,
  }) =>
      getFunction("get_data").call(
        <Object?>[
          pathname,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## get_filename
  ///
  /// ### python docstring
  ///
  /// get_filename(fullname) -> filename string.
  ///
  /// Return the filename for the specified module or raise ZipImportError
  /// if it couldn't be imported.
  Object? get_filename({
    required Object? fullname,
  }) =>
      getFunction("get_filename").call(
        <Object?>[
          fullname,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## get_resource_reader
  ///
  /// ### python docstring
  ///
  /// Return the ResourceReader for a package in a zip file.
  ///
  /// If 'fullname' is a package within the zip file, return the
  /// 'ResourceReader' object for the package.  Otherwise return None.
  Object? get_resource_reader({
    required Object? fullname,
  }) =>
      getFunction("get_resource_reader").call(
        <Object?>[
          fullname,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## get_source
  ///
  /// ### python docstring
  ///
  /// get_source(fullname) -> source string.
  ///
  /// Return the source code for the specified module. Raise ZipImportError
  /// if the module couldn't be found, return None if the archive does
  /// contain the module, but has no source for it.
  Object? get_source({
    required Object? fullname,
  }) =>
      getFunction("get_source").call(
        <Object?>[
          fullname,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## invalidate_caches
  ///
  /// ### python docstring
  ///
  /// Reload the file data of the archive path.
  Object? invalidate_caches() => getFunction("invalidate_caches").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## is_package
  ///
  /// ### python docstring
  ///
  /// is_package(fullname) -> bool.
  ///
  /// Return True if the module specified by fullname is a package.
  /// Raise ZipImportError if the module couldn't be found.
  Object? is_package({
    required Object? fullname,
  }) =>
      getFunction("is_package").call(
        <Object?>[
          fullname,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## load_module
  ///
  /// ### python docstring
  ///
  /// load_module(fullname) -> module.
  ///
  /// Load the module specified by 'fullname'. 'fullname' must be the
  /// fully qualified (dotted) module name. It returns the imported
  /// module, or raises ZipImportError if it could not be imported.
  ///
  /// Deprecated since Python 3.10. Use exec_module() instead.
  Object? load_module({
    required Object? fullname,
  }) =>
      getFunction("load_module").call(
        <Object?>[
          fullname,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## AmbiguousExpander
///
/// ### python docstring
///
/// Deal with the case where we're expanding children ('_rule') into a parent but the children
/// are ambiguous. i.e. (parent->_ambig->_expand_this_rule). In this case, make the parent itself
/// ambiguous with as many copies as there are ambiguous children, and then copy the ambiguous children
/// into the right parents in the right places, essentially shifting the ambiguity up the tree.
final class AmbiguousExpander extends PythonClass {
  factory AmbiguousExpander({
    required Object? to_expand,
    required Object? tree_class,
    required Object? node_builder,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parse_tree_builder",
        "AmbiguousExpander",
        AmbiguousExpander.from,
        <Object?>[
          to_expand,
          tree_class,
          node_builder,
        ],
        <String, Object?>{},
      );

  AmbiguousExpander.from(super.pythonClass) : super.from();

  /// ## node_builder (getter)
  Object? get node_builder => getAttribute("node_builder");

  /// ## node_builder (setter)
  set node_builder(Object? node_builder) =>
      setAttribute("node_builder", node_builder);

  /// ## tree_class (getter)
  Object? get tree_class => getAttribute("tree_class");

  /// ## tree_class (setter)
  set tree_class(Object? tree_class) => setAttribute("tree_class", tree_class);

  /// ## to_expand (getter)
  Object? get to_expand => getAttribute("to_expand");

  /// ## to_expand (setter)
  set to_expand(Object? to_expand) => setAttribute("to_expand", to_expand);
}

/// ## AmbiguousIntermediateExpander
///
/// ### python docstring
///
/// Propagate ambiguous intermediate nodes and their derivations up to the
/// current rule.
///
/// In general, converts
///
/// rule
///   _iambig
///     _inter
///       someChildren1
///       ...
///     _inter
///       someChildren2
///       ...
///   someChildren3
///   ...
///
/// to
///
/// _ambig
///   rule
///     someChildren1
///     ...
///     someChildren3
///     ...
///   rule
///     someChildren2
///     ...
///     someChildren3
///     ...
///   rule
///     childrenFromNestedIambigs
///     ...
///     someChildren3
///     ...
///   ...
///
/// propagating up any nested '_iambig' nodes along the way.
///
/// ### python source
/// ```py
/// class AmbiguousIntermediateExpander:
///     """
///     Propagate ambiguous intermediate nodes and their derivations up to the
///     current rule.
///
///     In general, converts
///
///     rule
///       _iambig
///         _inter
///           someChildren1
///           ...
///         _inter
///           someChildren2
///           ...
///       someChildren3
///       ...
///
///     to
///
///     _ambig
///       rule
///         someChildren1
///         ...
///         someChildren3
///         ...
///       rule
///         someChildren2
///         ...
///         someChildren3
///         ...
///       rule
///         childrenFromNestedIambigs
///         ...
///         someChildren3
///         ...
///       ...
///
///     propagating up any nested '_iambig' nodes along the way.
///     """
///
///     def __init__(self, tree_class, node_builder):
///         self.node_builder = node_builder
///         self.tree_class = tree_class
///
///     def __call__(self, children):
///         def _is_iambig_tree(child):
///             return hasattr(child, 'data') and child.data == '_iambig'
///
///         def _collapse_iambig(children):
///             """
///             Recursively flatten the derivations of the parent of an '_iambig'
///             node. Returns a list of '_inter' nodes guaranteed not
///             to contain any nested '_iambig' nodes, or None if children does
///             not contain an '_iambig' node.
///             """
///
///             # Due to the structure of the SPPF,
///             # an '_iambig' node can only appear as the first child
///             if children and _is_iambig_tree(children[0]):
///                 iambig_node = children[0]
///                 result = []
///                 for grandchild in iambig_node.children:
///                     collapsed = _collapse_iambig(grandchild.children)
///                     if collapsed:
///                         for child in collapsed:
///                             child.children += children[1:]
///                         result += collapsed
///                     else:
///                         new_tree = self.tree_class('_inter', grandchild.children + children[1:])
///                         result.append(new_tree)
///                 return result
///
///         collapsed = _collapse_iambig(children)
///         if collapsed:
///             processed_nodes = [self.node_builder(c.children) for c in collapsed]
///             return self.tree_class('_ambig', processed_nodes)
///
///         return self.node_builder(children)
/// ```
final class AmbiguousIntermediateExpander extends PythonClass {
  factory AmbiguousIntermediateExpander({
    required Object? tree_class,
    required Object? node_builder,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parse_tree_builder",
        "AmbiguousIntermediateExpander",
        AmbiguousIntermediateExpander.from,
        <Object?>[
          tree_class,
          node_builder,
        ],
        <String, Object?>{},
      );

  AmbiguousIntermediateExpander.from(super.pythonClass) : super.from();

  /// ## node_builder (getter)
  Object? get node_builder => getAttribute("node_builder");

  /// ## node_builder (setter)
  set node_builder(Object? node_builder) =>
      setAttribute("node_builder", node_builder);

  /// ## tree_class (getter)
  Object? get tree_class => getAttribute("tree_class");

  /// ## tree_class (setter)
  set tree_class(Object? tree_class) => setAttribute("tree_class", tree_class);
}

/// ## ChildFilter
///
/// ### python source
/// ```py
/// class ChildFilter:
///     def __init__(self, to_include, append_none, node_builder):
///         self.node_builder = node_builder
///         self.to_include = to_include
///         self.append_none = append_none
///
///     def __call__(self, children):
///         filtered = []
///
///         for i, to_expand, add_none in self.to_include:
///             if add_none:
///                 filtered += [None] * add_none
///             if to_expand:
///                 filtered += children[i].children
///             else:
///                 filtered.append(children[i])
///
///         if self.append_none:
///             filtered += [None] * self.append_none
///
///         return self.node_builder(filtered)
/// ```
final class ChildFilter extends PythonClass {
  factory ChildFilter({
    required Object? to_include,
    required Object? append_none,
    required Object? node_builder,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parse_tree_builder",
        "ChildFilter",
        ChildFilter.from,
        <Object?>[
          to_include,
          append_none,
          node_builder,
        ],
        <String, Object?>{},
      );

  ChildFilter.from(super.pythonClass) : super.from();

  /// ## node_builder (getter)
  Object? get node_builder => getAttribute("node_builder");

  /// ## node_builder (setter)
  set node_builder(Object? node_builder) =>
      setAttribute("node_builder", node_builder);

  /// ## to_include (getter)
  Object? get to_include => getAttribute("to_include");

  /// ## to_include (setter)
  set to_include(Object? to_include) => setAttribute("to_include", to_include);

  /// ## append_none (getter)
  Object? get append_none => getAttribute("append_none");

  /// ## append_none (setter)
  set append_none(Object? append_none) =>
      setAttribute("append_none", append_none);
}

/// ## ChildFilterLALR
///
/// ### python docstring
///
/// Optimized childfilter for LALR (assumes no duplication in parse tree, so it's safe to change it)
///
/// ### python source
/// ```py
/// class ChildFilterLALR(ChildFilter):
///     """Optimized childfilter for LALR (assumes no duplication in parse tree, so it's safe to change it)"""
///
///     def __call__(self, children):
///         filtered = []
///         for i, to_expand, add_none in self.to_include:
///             if add_none:
///                 filtered += [None] * add_none
///             if to_expand:
///                 if filtered:
///                     filtered += children[i].children
///                 else:   # Optimize for left-recursion
///                     filtered = children[i].children
///             else:
///                 filtered.append(children[i])
///
///         if self.append_none:
///             filtered += [None] * self.append_none
///
///         return self.node_builder(filtered)
/// ```
final class ChildFilterLALR extends PythonClass {
  factory ChildFilterLALR({
    required Object? to_include,
    required Object? append_none,
    required Object? node_builder,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parse_tree_builder",
        "ChildFilterLALR",
        ChildFilterLALR.from,
        <Object?>[
          to_include,
          append_none,
          node_builder,
        ],
        <String, Object?>{},
      );

  ChildFilterLALR.from(super.pythonClass) : super.from();

  /// ## node_builder (getter)
  Object? get node_builder => getAttribute("node_builder");

  /// ## node_builder (setter)
  set node_builder(Object? node_builder) =>
      setAttribute("node_builder", node_builder);

  /// ## to_include (getter)
  Object? get to_include => getAttribute("to_include");

  /// ## to_include (setter)
  set to_include(Object? to_include) => setAttribute("to_include", to_include);

  /// ## append_none (getter)
  Object? get append_none => getAttribute("append_none");

  /// ## append_none (setter)
  set append_none(Object? append_none) =>
      setAttribute("append_none", append_none);
}

/// ## ChildFilterLALR_NoPlaceholders
///
/// ### python docstring
///
/// Optimized childfilter for LALR (assumes no duplication in parse tree, so it's safe to change it)
///
/// ### python source
/// ```py
/// class ChildFilterLALR_NoPlaceholders(ChildFilter):
///     "Optimized childfilter for LALR (assumes no duplication in parse tree, so it's safe to change it)"
///     def __init__(self, to_include, node_builder):
///         self.node_builder = node_builder
///         self.to_include = to_include
///
///     def __call__(self, children):
///         filtered = []
///         for i, to_expand in self.to_include:
///             if to_expand:
///                 if filtered:
///                     filtered += children[i].children
///                 else:   # Optimize for left-recursion
///                     filtered = children[i].children
///             else:
///                 filtered.append(children[i])
///         return self.node_builder(filtered)
/// ```
final class ChildFilterLALR_NoPlaceholders extends PythonClass {
  factory ChildFilterLALR_NoPlaceholders({
    required Object? to_include,
    required Object? node_builder,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parse_tree_builder",
        "ChildFilterLALR_NoPlaceholders",
        ChildFilterLALR_NoPlaceholders.from,
        <Object?>[
          to_include,
          node_builder,
        ],
        <String, Object?>{},
      );

  ChildFilterLALR_NoPlaceholders.from(super.pythonClass) : super.from();

  /// ## node_builder (getter)
  Object? get node_builder => getAttribute("node_builder");

  /// ## node_builder (setter)
  set node_builder(Object? node_builder) =>
      setAttribute("node_builder", node_builder);

  /// ## to_include (getter)
  Object? get to_include => getAttribute("to_include");

  /// ## to_include (setter)
  set to_include(Object? to_include) => setAttribute("to_include", to_include);
}

/// ## ExpandSingleChild
///
/// ### python source
/// ```py
/// class ExpandSingleChild:
///     def __init__(self, node_builder):
///         self.node_builder = node_builder
///
///     def __call__(self, children):
///         if len(children) == 1:
///             return children[0]
///         else:
///             return self.node_builder(children)
/// ```
final class ExpandSingleChild extends PythonClass {
  factory ExpandSingleChild({
    required Object? node_builder,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parse_tree_builder",
        "ExpandSingleChild",
        ExpandSingleChild.from,
        <Object?>[
          node_builder,
        ],
        <String, Object?>{},
      );

  ExpandSingleChild.from(super.pythonClass) : super.from();

  /// ## node_builder (getter)
  Object? get node_builder => getAttribute("node_builder");

  /// ## node_builder (setter)
  set node_builder(Object? node_builder) =>
      setAttribute("node_builder", node_builder);
}

/// ## PropagatePositions
///
/// ### python source
/// ```py
/// class PropagatePositions:
///     def __init__(self, node_builder, node_filter=None):
///         self.node_builder = node_builder
///         self.node_filter = node_filter
///
///     def __call__(self, children):
///         res = self.node_builder(children)
///
///         if isinstance(res, Tree):
///             # Calculate positions while the tree is streaming, according to the rule:
///             # - nodes start at the start of their first child's container,
///             #   and end at the end of their last child's container.
///             # Containers are nodes that take up space in text, but have been inlined in the tree.
///
///             res_meta = res.meta
///
///             first_meta = self._pp_get_meta(children)
///             if first_meta is not None:
///                 if not hasattr(res_meta, 'line'):
///                     # meta was already set, probably because the rule has been inlined (e.g. `?rule`)
///                     res_meta.line = getattr(first_meta, 'container_line', first_meta.line)
///                     res_meta.column = getattr(first_meta, 'container_column', first_meta.column)
///                     res_meta.start_pos = getattr(first_meta, 'container_start_pos', first_meta.start_pos)
///                     res_meta.empty = False
///
///                 res_meta.container_line = getattr(first_meta, 'container_line', first_meta.line)
///                 res_meta.container_column = getattr(first_meta, 'container_column', first_meta.column)
///
///             last_meta = self._pp_get_meta(reversed(children))
///             if last_meta is not None:
///                 if not hasattr(res_meta, 'end_line'):
///                     res_meta.end_line = getattr(last_meta, 'container_end_line', last_meta.end_line)
///                     res_meta.end_column = getattr(last_meta, 'container_end_column', last_meta.end_column)
///                     res_meta.end_pos = getattr(last_meta, 'container_end_pos', last_meta.end_pos)
///                     res_meta.empty = False
///
///                 res_meta.container_end_line = getattr(last_meta, 'container_end_line', last_meta.end_line)
///                 res_meta.container_end_column = getattr(last_meta, 'container_end_column', last_meta.end_column)
///
///         return res
///
///     def _pp_get_meta(self, children):
///         for c in children:
///             if self.node_filter is not None and not self.node_filter(c):
///                 continue
///             if isinstance(c, Tree):
///                 if not c.meta.empty:
///                     return c.meta
///             elif isinstance(c, Token):
///                 return c
///             elif hasattr(c, '__lark_meta__'):
///                 return c.__lark_meta__()
/// ```
final class PropagatePositions extends PythonClass {
  factory PropagatePositions({
    required Object? node_builder,
    Object? node_filter,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parse_tree_builder",
        "PropagatePositions",
        PropagatePositions.from,
        <Object?>[
          node_builder,
          node_filter,
        ],
        <String, Object?>{},
      );

  PropagatePositions.from(super.pythonClass) : super.from();

  /// ## node_builder (getter)
  Object? get node_builder => getAttribute("node_builder");

  /// ## node_builder (setter)
  set node_builder(Object? node_builder) =>
      setAttribute("node_builder", node_builder);

  /// ## node_filter (getter)
  Object? get node_filter => getAttribute("node_filter");

  /// ## node_filter (setter)
  set node_filter(Object? node_filter) =>
      setAttribute("node_filter", node_filter);
}

/// ## product
final class product extends PythonClass {
  factory product() => PythonFfiDart.instance.importClass(
        "itertools",
        "product",
        product.from,
        <Object?>[],
      );

  product.from(super.pythonClass) : super.from();
}

/// ## CYK_FrontEnd
///
/// ### python source
/// ```py
/// class CYK_FrontEnd:
///     def __init__(self, lexer_conf, parser_conf, options=None):
///         self._analysis = GrammarAnalyzer(parser_conf)
///         self.parser = cyk.Parser(parser_conf.rules)
///
///         self.callbacks = parser_conf.callbacks
///
///     def parse(self, lexer_thread, start):
///         tokens = list(lexer_thread.lex(None))
///         tree = self.parser.parse(tokens, start)
///         return self._transform(tree)
///
///     def _transform(self, tree):
///         subtrees = list(tree.iter_subtrees())
///         for subtree in subtrees:
///             subtree.children = [self._apply_callback(c) if isinstance(c, Tree) else c for c in subtree.children]
///
///         return self._apply_callback(tree)
///
///     def _apply_callback(self, tree):
///         return self.callbacks[tree.rule](tree.children)
/// ```
final class CYK_FrontEnd extends PythonClass {
  factory CYK_FrontEnd({
    required Object? lexer_conf,
    required Object? parser_conf,
    Object? options,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parser_frontends",
        "CYK_FrontEnd",
        CYK_FrontEnd.from,
        <Object?>[
          lexer_conf,
          parser_conf,
          options,
        ],
        <String, Object?>{},
      );

  CYK_FrontEnd.from(super.pythonClass) : super.from();

  /// ## parse
  ///
  /// ### python source
  /// ```py
  /// def parse(self, lexer_thread, start):
  ///         tokens = list(lexer_thread.lex(None))
  ///         tree = self.parser.parse(tokens, start)
  ///         return self._transform(tree)
  /// ```
  Object? parse({
    required Object? lexer_thread,
    required Object? start,
  }) =>
      getFunction("parse").call(
        <Object?>[
          lexer_thread,
          start,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## parser (getter)
  Object? get parser => getAttribute("parser");

  /// ## parser (setter)
  set parser(Object? parser) => setAttribute("parser", parser);

  /// ## callbacks (getter)
  Object? get callbacks => getAttribute("callbacks");

  /// ## callbacks (setter)
  set callbacks(Object? callbacks) => setAttribute("callbacks", callbacks);
}

/// ## EarleyRegexpMatcher
///
/// ### python source
/// ```py
/// class EarleyRegexpMatcher:
///     def __init__(self, lexer_conf):
///         self.regexps = {}
///         for t in lexer_conf.terminals:
///             regexp = t.pattern.to_regexp()
///             try:
///                 width = get_regexp_width(regexp)[0]
///             except ValueError:
///                 raise GrammarError("Bad regexp in token %s: %s" % (t.name, regexp))
///             else:
///                 if width == 0:
///                     raise GrammarError("Dynamic Earley doesn't allow zero-width regexps", t)
///             if lexer_conf.use_bytes:
///                 regexp = regexp.encode('utf-8')
///
///             self.regexps[t.name] = lexer_conf.re_module.compile(regexp, lexer_conf.g_regex_flags)
///
///     def match(self, term, text, index=0):
///         return self.regexps[term.name].match(text, index)
/// ```
final class EarleyRegexpMatcher extends PythonClass {
  factory EarleyRegexpMatcher({
    required Object? lexer_conf,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parser_frontends",
        "EarleyRegexpMatcher",
        EarleyRegexpMatcher.from,
        <Object?>[
          lexer_conf,
        ],
        <String, Object?>{},
      );

  EarleyRegexpMatcher.from(super.pythonClass) : super.from();

  /// ## match
  ///
  /// ### python source
  /// ```py
  /// def match(self, term, text, index=0):
  ///         return self.regexps[term.name].match(text, index)
  /// ```
  Object? match({
    required Object? term,
    required Object? text,
    Object? index = 0,
  }) =>
      getFunction("match").call(
        <Object?>[
          term,
          text,
          index,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## regexps (getter)
  Object? get regexps => getAttribute("regexps");

  /// ## regexps (setter)
  set regexps(Object? regexps) => setAttribute("regexps", regexps);
}

/// ## GrammarAnalyzer
///
/// ### python source
/// ```py
/// class GrammarAnalyzer:
///     def __init__(self, parser_conf, debug=False):
///         self.debug = debug
///
///         root_rules = {start: Rule(NonTerminal('$root_' + start), [NonTerminal(start), Terminal('$END')])
///                       for start in parser_conf.start}
///
///         rules = parser_conf.rules + list(root_rules.values())
///         self.rules_by_origin = classify(rules, lambda r: r.origin)
///
///         if len(rules) != len(set(rules)):
///             duplicates = [item for item, count in Counter(rules).items() if count > 1]
///             raise GrammarError("Rules defined twice: %s" % ', '.join(str(i) for i in duplicates))
///
///         for r in rules:
///             for sym in r.expansion:
///                 if not (sym.is_term or sym in self.rules_by_origin):
///                     raise GrammarError("Using an undefined rule: %s" % sym)
///
///         self.start_states = {start: self.expand_rule(root_rule.origin)
///                              for start, root_rule in root_rules.items()}
///
///         self.end_states = {start: fzset({RulePtr(root_rule, len(root_rule.expansion))})
///                            for start, root_rule in root_rules.items()}
///
///         lr0_root_rules = {start: Rule(NonTerminal('$root_' + start), [NonTerminal(start)])
///                 for start in parser_conf.start}
///
///         lr0_rules = parser_conf.rules + list(lr0_root_rules.values())
///         assert(len(lr0_rules) == len(set(lr0_rules)))
///
///         self.lr0_rules_by_origin = classify(lr0_rules, lambda r: r.origin)
///
///         # cache RulePtr(r, 0) in r (no duplicate RulePtr objects)
///         self.lr0_start_states = {start: LR0ItemSet([RulePtr(root_rule, 0)], self.expand_rule(root_rule.origin, self.lr0_rules_by_origin))
///                 for start, root_rule in lr0_root_rules.items()}
///
///         self.FIRST, self.FOLLOW, self.NULLABLE = calculate_sets(rules)
///
///     def expand_rule(self, source_rule, rules_by_origin=None):
///         "Returns all init_ptrs accessible by rule (recursive)"
///
///         if rules_by_origin is None:
///             rules_by_origin = self.rules_by_origin
///
///         init_ptrs = set()
///         def _expand_rule(rule):
///             assert not rule.is_term, rule
///
///             for r in rules_by_origin[rule]:
///                 init_ptr = RulePtr(r, 0)
///                 init_ptrs.add(init_ptr)
///
///                 if r.expansion: # if not empty rule
///                     new_r = init_ptr.next
///                     if not new_r.is_term:
///                         yield new_r
///
///         for _ in bfs([source_rule], _expand_rule):
///             pass
///
///         return fzset(init_ptrs)
/// ```
final class GrammarAnalyzer extends PythonClass {
  factory GrammarAnalyzer({
    required Object? parser_conf,
    Object? debug = false,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parsers.grammar_analysis",
        "GrammarAnalyzer",
        GrammarAnalyzer.from,
        <Object?>[
          parser_conf,
          debug,
        ],
        <String, Object?>{},
      );

  GrammarAnalyzer.from(super.pythonClass) : super.from();

  /// ## expand_rule
  ///
  /// ### python docstring
  ///
  /// Returns all init_ptrs accessible by rule (recursive)
  ///
  /// ### python source
  /// ```py
  /// def expand_rule(self, source_rule, rules_by_origin=None):
  ///         "Returns all init_ptrs accessible by rule (recursive)"
  ///
  ///         if rules_by_origin is None:
  ///             rules_by_origin = self.rules_by_origin
  ///
  ///         init_ptrs = set()
  ///         def _expand_rule(rule):
  ///             assert not rule.is_term, rule
  ///
  ///             for r in rules_by_origin[rule]:
  ///                 init_ptr = RulePtr(r, 0)
  ///                 init_ptrs.add(init_ptr)
  ///
  ///                 if r.expansion: # if not empty rule
  ///                     new_r = init_ptr.next
  ///                     if not new_r.is_term:
  ///                         yield new_r
  ///
  ///         for _ in bfs([source_rule], _expand_rule):
  ///             pass
  ///
  ///         return fzset(init_ptrs)
  /// ```
  Object? expand_rule({
    required Object? source_rule,
    Object? rules_by_origin,
  }) =>
      getFunction("expand_rule").call(
        <Object?>[
          source_rule,
          rules_by_origin,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## debug (getter)
  Object? get debug => getAttribute("debug");

  /// ## debug (setter)
  set debug(Object? debug) => setAttribute("debug", debug);

  /// ## rules_by_origin (getter)
  Object? get rules_by_origin => getAttribute("rules_by_origin");

  /// ## rules_by_origin (setter)
  set rules_by_origin(Object? rules_by_origin) =>
      setAttribute("rules_by_origin", rules_by_origin);

  /// ## start_states (getter)
  Object? get start_states => getAttribute("start_states");

  /// ## start_states (setter)
  set start_states(Object? start_states) =>
      setAttribute("start_states", start_states);

  /// ## end_states (getter)
  Object? get end_states => getAttribute("end_states");

  /// ## end_states (setter)
  set end_states(Object? end_states) => setAttribute("end_states", end_states);

  /// ## lr0_rules_by_origin (getter)
  Object? get lr0_rules_by_origin => getAttribute("lr0_rules_by_origin");

  /// ## lr0_rules_by_origin (setter)
  set lr0_rules_by_origin(Object? lr0_rules_by_origin) =>
      setAttribute("lr0_rules_by_origin", lr0_rules_by_origin);

  /// ## lr0_start_states (getter)
  Object? get lr0_start_states => getAttribute("lr0_start_states");

  /// ## lr0_start_states (setter)
  set lr0_start_states(Object? lr0_start_states) =>
      setAttribute("lr0_start_states", lr0_start_states);
}

/// ## LALR_Parser
///
/// ### python docstring
///
/// Safe-ish serialization interface that doesn't rely on Pickle
///
/// Attributes:
///     __serialize_fields__ (List[str]): Fields (aka attributes) to serialize.
///     __serialize_namespace__ (list): List of classes that deserialization is allowed to instantiate.
///                                     Should include all field types that aren't builtin types.
///
/// ### python source
/// ```py
/// class LALR_Parser(Serialize):
///     def __init__(self, parser_conf, debug=False):
///         analysis = LALR_Analyzer(parser_conf, debug=debug)
///         analysis.compute_lalr()
///         callbacks = parser_conf.callbacks
///
///         self._parse_table = analysis.parse_table
///         self.parser_conf = parser_conf
///         self.parser = _Parser(analysis.parse_table, callbacks, debug)
///
///     @classmethod
///     def deserialize(cls, data, memo, callbacks, debug=False):
///         inst = cls.__new__(cls)
///         inst._parse_table = IntParseTable.deserialize(data, memo)
///         inst.parser = _Parser(inst._parse_table, callbacks, debug)
///         return inst
///
///     def serialize(self, memo: Any = None) -> Dict[str, Any]:
///         return self._parse_table.serialize(memo)
///
///     def parse_interactive(self, lexer, start):
///         return self.parser.parse(lexer, start, start_interactive=True)
///
///     def parse(self, lexer, start, on_error=None):
///         try:
///             return self.parser.parse(lexer, start)
///         except UnexpectedInput as e:
///             if on_error is None:
///                 raise
///
///             while True:
///                 if isinstance(e, UnexpectedCharacters):
///                     s = e.interactive_parser.lexer_thread.state
///                     p = s.line_ctr.char_pos
///
///                 if not on_error(e):
///                     raise e
///
///                 if isinstance(e, UnexpectedCharacters):
///                     # If user didn't change the character position, then we should
///                     if p == s.line_ctr.char_pos:
///                         s.line_ctr.feed(s.text[p:p+1])
///
///                 try:
///                     return e.interactive_parser.resume_parse()
///                 except UnexpectedToken as e2:
///                     if (isinstance(e, UnexpectedToken)
///                         and e.token.type == e2.token.type == '$END'
///                         and e.interactive_parser == e2.interactive_parser):
///                         # Prevent infinite loop
///                         raise e2
///                     e = e2
///                 except UnexpectedCharacters as e2:
///                     e = e2
/// ```
final class LALR_Parser extends PythonClass {
  factory LALR_Parser({
    required Object? parser_conf,
    Object? debug = false,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parsers.lalr_parser",
        "LALR_Parser",
        LALR_Parser.from,
        <Object?>[
          parser_conf,
          debug,
        ],
        <String, Object?>{},
      );

  LALR_Parser.from(super.pythonClass) : super.from();

  /// ## memo_serialize
  ///
  /// ### python source
  /// ```py
  /// def memo_serialize(self, types_to_memoize: List) -> Any:
  ///         memo = SerializeMemoizer(types_to_memoize)
  ///         return self.serialize(memo), memo.serialize()
  /// ```
  Object? memo_serialize({
    required Object? types_to_memoize,
  }) =>
      getFunction("memo_serialize").call(
        <Object?>[
          types_to_memoize,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## parse
  ///
  /// ### python source
  /// ```py
  /// def parse(self, lexer, start, on_error=None):
  ///         try:
  ///             return self.parser.parse(lexer, start)
  ///         except UnexpectedInput as e:
  ///             if on_error is None:
  ///                 raise
  ///
  ///             while True:
  ///                 if isinstance(e, UnexpectedCharacters):
  ///                     s = e.interactive_parser.lexer_thread.state
  ///                     p = s.line_ctr.char_pos
  ///
  ///                 if not on_error(e):
  ///                     raise e
  ///
  ///                 if isinstance(e, UnexpectedCharacters):
  ///                     # If user didn't change the character position, then we should
  ///                     if p == s.line_ctr.char_pos:
  ///                         s.line_ctr.feed(s.text[p:p+1])
  ///
  ///                 try:
  ///                     return e.interactive_parser.resume_parse()
  ///                 except UnexpectedToken as e2:
  ///                     if (isinstance(e, UnexpectedToken)
  ///                         and e.token.type == e2.token.type == '$END'
  ///                         and e.interactive_parser == e2.interactive_parser):
  ///                         # Prevent infinite loop
  ///                         raise e2
  ///                     e = e2
  ///                 except UnexpectedCharacters as e2:
  ///                     e = e2
  /// ```
  Object? parse({
    required Object? lexer,
    required Object? start,
    Object? on_error,
  }) =>
      getFunction("parse").call(
        <Object?>[
          lexer,
          start,
          on_error,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## parse_interactive
  ///
  /// ### python source
  /// ```py
  /// def parse_interactive(self, lexer, start):
  ///         return self.parser.parse(lexer, start, start_interactive=True)
  /// ```
  Object? parse_interactive({
    required Object? lexer,
    required Object? start,
  }) =>
      getFunction("parse_interactive").call(
        <Object?>[
          lexer,
          start,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## serialize
  ///
  /// ### python source
  /// ```py
  /// def serialize(self, memo: Any = None) -> Dict[str, Any]:
  ///         return self._parse_table.serialize(memo)
  /// ```
  Object? serialize({
    Object? memo,
  }) =>
      getFunction("serialize").call(
        <Object?>[
          memo,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## deserialize (getter)
  Object? get deserialize => getAttribute("deserialize");

  /// ## deserialize (setter)
  set deserialize(Object? deserialize) =>
      setAttribute("deserialize", deserialize);

  /// ## parser_conf (getter)
  Object? get parser_conf => getAttribute("parser_conf");

  /// ## parser_conf (setter)
  set parser_conf(Object? parser_conf) =>
      setAttribute("parser_conf", parser_conf);

  /// ## parser (getter)
  Object? get parser => getAttribute("parser");

  /// ## parser (setter)
  set parser(Object? parser) => setAttribute("parser", parser);
}

/// ## PostLexConnector
///
/// ### python source
/// ```py
/// class PostLexConnector:
///     def __init__(self, lexer, postlexer):
///         self.lexer = lexer
///         self.postlexer = postlexer
///
///     def lex(self, lexer_state, parser_state):
///         i = self.lexer.lex(lexer_state, parser_state)
///         return self.postlexer.process(i)
/// ```
final class PostLexConnector extends PythonClass {
  factory PostLexConnector({
    required Object? lexer,
    required Object? postlexer,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parser_frontends",
        "PostLexConnector",
        PostLexConnector.from,
        <Object?>[
          lexer,
          postlexer,
        ],
        <String, Object?>{},
      );

  PostLexConnector.from(super.pythonClass) : super.from();

  /// ## lex
  ///
  /// ### python source
  /// ```py
  /// def lex(self, lexer_state, parser_state):
  ///         i = self.lexer.lex(lexer_state, parser_state)
  ///         return self.postlexer.process(i)
  /// ```
  Object? lex({
    required Object? lexer_state,
    required Object? parser_state,
  }) =>
      getFunction("lex").call(
        <Object?>[
          lexer_state,
          parser_state,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## lexer (getter)
  Object? get lexer => getAttribute("lexer");

  /// ## lexer (setter)
  set lexer(Object? lexer) => setAttribute("lexer", lexer);

  /// ## postlexer (getter)
  Object? get postlexer => getAttribute("postlexer");

  /// ## postlexer (setter)
  set postlexer(Object? postlexer) => setAttribute("postlexer", postlexer);
}

/// ## CnfWrapper
///
/// ### python docstring
///
/// CNF wrapper for grammar.
///
/// Validates that the input grammar is CNF and provides helper data structures.
///
/// ### python source
/// ```py
/// class CnfWrapper:
///     """CNF wrapper for grammar.
/// ```
final class CnfWrapper extends PythonClass {
  factory CnfWrapper({
    required Object? grammar,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parsers.cyk",
        "CnfWrapper",
        CnfWrapper.from,
        <Object?>[
          grammar,
        ],
        <String, Object?>{},
      );

  CnfWrapper.from(super.pythonClass) : super.from();

  /// ## grammar (getter)
  Object? get grammar => getAttribute("grammar");

  /// ## grammar (setter)
  set grammar(Object? grammar) => setAttribute("grammar", grammar);

  /// ## rules (getter)
  Object? get rules => getAttribute("rules");

  /// ## rules (setter)
  set rules(Object? rules) => setAttribute("rules", rules);

  /// ## terminal_rules (getter)
  Object? get terminal_rules => getAttribute("terminal_rules");

  /// ## terminal_rules (setter)
  set terminal_rules(Object? terminal_rules) =>
      setAttribute("terminal_rules", terminal_rules);

  /// ## nonterminal_rules (getter)
  Object? get nonterminal_rules => getAttribute("nonterminal_rules");

  /// ## nonterminal_rules (setter)
  set nonterminal_rules(Object? nonterminal_rules) =>
      setAttribute("nonterminal_rules", nonterminal_rules);
}

/// ## Parser
///
/// ### python docstring
///
/// Parser wrapper.
///
/// ### python source
/// ```py
/// class Parser:
///     """Parser wrapper."""
///
///     def __init__(self, rules):
///         super(Parser, self).__init__()
///         self.orig_rules = {rule: rule for rule in rules}
///         rules = [self._to_rule(rule) for rule in rules]
///         self.grammar = to_cnf(Grammar(rules))
///
///     def _to_rule(self, lark_rule):
///         """Converts a lark rule, (lhs, rhs, callback, options), to a Rule."""
///         assert isinstance(lark_rule.origin, NT)
///         assert all(isinstance(x, Symbol) for x in lark_rule.expansion)
///         return Rule(
///             lark_rule.origin, lark_rule.expansion,
///             weight=lark_rule.options.priority if lark_rule.options.priority else 0,
///             alias=lark_rule)
///
///     def parse(self, tokenized, start):  # pylint: disable=invalid-name
///         """Parses input, which is a list of tokens."""
///         assert start
///         start = NT(start)
///
///         table, trees = _parse(tokenized, self.grammar)
///         # Check if the parse succeeded.
///         if all(r.lhs != start for r in table[(0, len(tokenized) - 1)]):
///             raise ParseError('Parsing failed.')
///         parse = trees[(0, len(tokenized) - 1)][start]
///         return self._to_tree(revert_cnf(parse))
///
///     def _to_tree(self, rule_node):
///         """Converts a RuleNode parse tree to a lark Tree."""
///         orig_rule = self.orig_rules[rule_node.rule.alias]
///         children = []
///         for child in rule_node.children:
///             if isinstance(child, RuleNode):
///                 children.append(self._to_tree(child))
///             else:
///                 assert isinstance(child.name, Token)
///                 children.append(child.name)
///         t = Tree(orig_rule.origin, children)
///         t.rule=orig_rule
///         return t
/// ```
final class Parser extends PythonClass {
  factory Parser({
    required Object? rules,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parsers.cyk",
        "Parser",
        Parser.from,
        <Object?>[
          rules,
        ],
        <String, Object?>{},
      );

  Parser.from(super.pythonClass) : super.from();

  /// ## parse
  ///
  /// ### python docstring
  ///
  /// Parses input, which is a list of tokens.
  ///
  /// ### python source
  /// ```py
  /// def parse(self, tokenized, start):  # pylint: disable=invalid-name
  ///         """Parses input, which is a list of tokens."""
  ///         assert start
  ///         start = NT(start)
  ///
  ///         table, trees = _parse(tokenized, self.grammar)
  ///         # Check if the parse succeeded.
  ///         if all(r.lhs != start for r in table[(0, len(tokenized) - 1)]):
  ///             raise ParseError('Parsing failed.')
  ///         parse = trees[(0, len(tokenized) - 1)][start]
  ///         return self._to_tree(revert_cnf(parse))
  /// ```
  Object? parse({
    required Object? tokenized,
    required Object? start,
  }) =>
      getFunction("parse").call(
        <Object?>[
          tokenized,
          start,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## orig_rules (getter)
  Object? get orig_rules => getAttribute("orig_rules");

  /// ## orig_rules (setter)
  set orig_rules(Object? orig_rules) => setAttribute("orig_rules", orig_rules);

  /// ## grammar (getter)
  Object? get grammar => getAttribute("grammar");

  /// ## grammar (setter)
  set grammar(Object? grammar) => setAttribute("grammar", grammar);
}

/// ## RuleNode
///
/// ### python docstring
///
/// A node in the parse tree, which also contains the full rhs rule.
///
/// ### python source
/// ```py
/// class RuleNode:
///     """A node in the parse tree, which also contains the full rhs rule."""
///
///     def __init__(self, rule, children, weight=0):
///         self.rule = rule
///         self.children = children
///         self.weight = weight
///
///     def __repr__(self):
///         return 'RuleNode(%s, [%s])' % (repr(self.rule.lhs), ', '.join(str(x) for x in self.children))
/// ```
final class RuleNode extends PythonClass {
  factory RuleNode({
    required Object? rule,
    required Object? children,
    Object? weight = 0,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parsers.cyk",
        "RuleNode",
        RuleNode.from,
        <Object?>[
          rule,
          children,
          weight,
        ],
        <String, Object?>{},
      );

  RuleNode.from(super.pythonClass) : super.from();

  /// ## rule (getter)
  Object? get rule => getAttribute("rule");

  /// ## rule (setter)
  set rule(Object? rule) => setAttribute("rule", rule);

  /// ## children (getter)
  Object? get children => getAttribute("children");

  /// ## children (setter)
  set children(Object? children) => setAttribute("children", children);

  /// ## weight (getter)
  Object? get weight => getAttribute("weight");

  /// ## weight (setter)
  set weight(Object? weight) => setAttribute("weight", weight);
}

/// ## UnitSkipRule
///
/// ### python docstring
///
/// A rule that records NTs that were skipped during transformation.
///
/// ### python source
/// ```py
/// class UnitSkipRule(Rule):
///     """A rule that records NTs that were skipped during transformation."""
///
///     def __init__(self, lhs, rhs, skipped_rules, weight, alias):
///         super(UnitSkipRule, self).__init__(lhs, rhs, weight, alias)
///         self.skipped_rules = skipped_rules
///
///     def __eq__(self, other):
///         return isinstance(other, type(self)) and self.skipped_rules == other.skipped_rules
///
///     __hash__ = Rule.__hash__
/// ```
final class UnitSkipRule extends PythonClass {
  factory UnitSkipRule({
    required Object? lhs,
    required Object? rhs,
    required Object? skipped_rules,
    required Object? weight,
    required Object? alias,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parsers.cyk",
        "UnitSkipRule",
        UnitSkipRule.from,
        <Object?>[
          lhs,
          rhs,
          skipped_rules,
          weight,
          alias,
        ],
        <String, Object?>{},
      );

  UnitSkipRule.from(super.pythonClass) : super.from();

  /// ## skipped_rules (getter)
  Object? get skipped_rules => getAttribute("skipped_rules");

  /// ## skipped_rules (setter)
  set skipped_rules(Object? skipped_rules) =>
      setAttribute("skipped_rules", skipped_rules);
}

/// ## defaultdict
final class defaultdict extends PythonClass {
  factory defaultdict() => PythonFfiDart.instance.importClass(
        "collections",
        "defaultdict",
        defaultdict.from,
        <Object?>[],
      );

  defaultdict.from(super.pythonClass) : super.from();

  /// ## default_factory (getter)
  Object? get default_factory => getAttribute("default_factory");

  /// ## default_factory (setter)
  set default_factory(Object? default_factory) =>
      setAttribute("default_factory", default_factory);

  /// ## clear (getter)
  Object? get clear => getAttribute("clear");

  /// ## clear (setter)
  set clear(Object? clear) => setAttribute("clear", clear);

  /// ## copy (getter)
  Object? get copy => getAttribute("copy");

  /// ## copy (setter)
  set copy(Object? copy) => setAttribute("copy", copy);

  /// ## get (getter)
  Object? get $get => getAttribute("get");

  /// ## get (setter)
  set $get(Object? $get) => setAttribute("get", $get);

  /// ## items (getter)
  Object? get items => getAttribute("items");

  /// ## items (setter)
  set items(Object? items) => setAttribute("items", items);

  /// ## keys (getter)
  Object? get keys => getAttribute("keys");

  /// ## keys (setter)
  set keys(Object? keys) => setAttribute("keys", keys);

  /// ## pop (getter)
  Object? get pop => getAttribute("pop");

  /// ## pop (setter)
  set pop(Object? pop) => setAttribute("pop", pop);

  /// ## popitem (getter)
  Object? get popitem => getAttribute("popitem");

  /// ## popitem (setter)
  set popitem(Object? popitem) => setAttribute("popitem", popitem);

  /// ## setdefault (getter)
  Object? get setdefault => getAttribute("setdefault");

  /// ## setdefault (setter)
  set setdefault(Object? setdefault) => setAttribute("setdefault", setdefault);

  /// ## update (getter)
  Object? get update => getAttribute("update");

  /// ## update (setter)
  set update(Object? update) => setAttribute("update", update);

  /// ## values (getter)
  Object? get values => getAttribute("values");

  /// ## values (setter)
  set values(Object? values) => setAttribute("values", values);
}

/// ## accumulate
final class accumulate extends PythonClass {
  factory accumulate() => PythonFfiDart.instance.importClass(
        "itertools",
        "accumulate",
        accumulate.from,
        <Object?>[],
      );

  accumulate.from(super.pythonClass) : super.from();
}

/// ## chain
final class chain extends PythonClass {
  factory chain() => PythonFfiDart.instance.importClass(
        "itertools",
        "chain",
        chain.from,
        <Object?>[],
      );

  chain.from(super.pythonClass) : super.from();
}

/// ## combinations
final class combinations extends PythonClass {
  factory combinations() => PythonFfiDart.instance.importClass(
        "itertools",
        "combinations",
        combinations.from,
        <Object?>[],
      );

  combinations.from(super.pythonClass) : super.from();
}

/// ## combinations_with_replacement
final class combinations_with_replacement extends PythonClass {
  factory combinations_with_replacement() => PythonFfiDart.instance.importClass(
        "itertools",
        "combinations_with_replacement",
        combinations_with_replacement.from,
        <Object?>[],
      );

  combinations_with_replacement.from(super.pythonClass) : super.from();
}

/// ## compress
final class compress extends PythonClass {
  factory compress() => PythonFfiDart.instance.importClass(
        "itertools",
        "compress",
        compress.from,
        <Object?>[],
      );

  compress.from(super.pythonClass) : super.from();
}

/// ## count
final class count extends PythonClass {
  factory count() => PythonFfiDart.instance.importClass(
        "itertools",
        "count",
        count.from,
        <Object?>[],
      );

  count.from(super.pythonClass) : super.from();
}

/// ## cycle
final class cycle extends PythonClass {
  factory cycle() => PythonFfiDart.instance.importClass(
        "itertools",
        "cycle",
        cycle.from,
        <Object?>[],
      );

  cycle.from(super.pythonClass) : super.from();
}

/// ## dropwhile
final class dropwhile extends PythonClass {
  factory dropwhile() => PythonFfiDart.instance.importClass(
        "itertools",
        "dropwhile",
        dropwhile.from,
        <Object?>[],
      );

  dropwhile.from(super.pythonClass) : super.from();
}

/// ## filterfalse
final class filterfalse extends PythonClass {
  factory filterfalse() => PythonFfiDart.instance.importClass(
        "itertools",
        "filterfalse",
        filterfalse.from,
        <Object?>[],
      );

  filterfalse.from(super.pythonClass) : super.from();
}

/// ## groupby
final class groupby extends PythonClass {
  factory groupby() => PythonFfiDart.instance.importClass(
        "itertools",
        "groupby",
        groupby.from,
        <Object?>[],
      );

  groupby.from(super.pythonClass) : super.from();
}

/// ## pairwise
final class pairwise extends PythonClass {
  factory pairwise() => PythonFfiDart.instance.importClass(
        "itertools",
        "pairwise",
        pairwise.from,
        <Object?>[],
      );

  pairwise.from(super.pythonClass) : super.from();
}

/// ## permutations
final class permutations extends PythonClass {
  factory permutations() => PythonFfiDart.instance.importClass(
        "itertools",
        "permutations",
        permutations.from,
        <Object?>[],
      );

  permutations.from(super.pythonClass) : super.from();
}

/// ## repeat
final class repeat extends PythonClass {
  factory repeat() => PythonFfiDart.instance.importClass(
        "itertools",
        "repeat",
        repeat.from,
        <Object?>[],
      );

  repeat.from(super.pythonClass) : super.from();
}

/// ## starmap
final class starmap extends PythonClass {
  factory starmap() => PythonFfiDart.instance.importClass(
        "itertools",
        "starmap",
        starmap.from,
        <Object?>[],
      );

  starmap.from(super.pythonClass) : super.from();
}

/// ## takewhile
final class takewhile extends PythonClass {
  factory takewhile() => PythonFfiDart.instance.importClass(
        "itertools",
        "takewhile",
        takewhile.from,
        <Object?>[],
      );

  takewhile.from(super.pythonClass) : super.from();
}

/// ## zip_longest
final class zip_longest extends PythonClass {
  factory zip_longest() => PythonFfiDart.instance.importClass(
        "itertools",
        "zip_longest",
        zip_longest.from,
        <Object?>[],
      );

  zip_longest.from(super.pythonClass) : super.from();
}

/// ## ForestSumVisitor
///
/// ### python docstring
///
/// A visitor for prioritizing ambiguous parts of the Forest.
///
/// This visitor is used when support for explicit priorities on
/// rules is requested (whether normal, or invert). It walks the
/// forest (or subsets thereof) and cascades properties upwards
/// from the leaves.
///
/// It would be ideal to do this during parsing, however this would
/// require processing each Earley item multiple times. That's
/// a big performance drawback; so running a forest walk is the
/// lesser of two evils: there can be significantly more Earley
/// items created during parsing than there are SPPF nodes in the
/// final tree.
///
/// ### python source
/// ```py
/// class ForestSumVisitor(ForestVisitor):
///     """
///     A visitor for prioritizing ambiguous parts of the Forest.
///
///     This visitor is used when support for explicit priorities on
///     rules is requested (whether normal, or invert). It walks the
///     forest (or subsets thereof) and cascades properties upwards
///     from the leaves.
///
///     It would be ideal to do this during parsing, however this would
///     require processing each Earley item multiple times. That's
///     a big performance drawback; so running a forest walk is the
///     lesser of two evils: there can be significantly more Earley
///     items created during parsing than there are SPPF nodes in the
///     final tree.
///     """
///     def __init__(self):
///         super(ForestSumVisitor, self).__init__(single_visit=True)
///
///     def visit_packed_node_in(self, node):
///         yield node.left
///         yield node.right
///
///     def visit_symbol_node_in(self, node):
///         return iter(node.children)
///
///     def visit_packed_node_out(self, node):
///         priority = node.rule.options.priority if not node.parent.is_intermediate and node.rule.options.priority else 0
///         priority += getattr(node.right, 'priority', 0)
///         priority += getattr(node.left, 'priority', 0)
///         node.priority = priority
///
///     def visit_symbol_node_out(self, node):
///         node.priority = max(child.priority for child in node.children)
/// ```
final class ForestSumVisitor extends PythonClass {
  factory ForestSumVisitor() => PythonFfiDart.instance.importClass(
        "lark.parsers.earley_forest",
        "ForestSumVisitor",
        ForestSumVisitor.from,
        <Object?>[],
        <String, Object?>{},
      );

  ForestSumVisitor.from(super.pythonClass) : super.from();

  /// ## get_cycle_in_path
  ///
  /// ### python docstring
  ///
  /// A utility function for use in ``on_cycle`` to obtain a slice of
  /// ``path`` that only contains the nodes that make up the cycle.
  ///
  /// ### python source
  /// ```py
  /// def get_cycle_in_path(self, node, path):
  ///         """A utility function for use in ``on_cycle`` to obtain a slice of
  ///         ``path`` that only contains the nodes that make up the cycle."""
  ///         index = len(path) - 1
  ///         while id(path[index]) != id(node):
  ///             index -= 1
  ///         return path[index:]
  /// ```
  Object? get_cycle_in_path({
    required Object? node,
    required Object? path,
  }) =>
      getFunction("get_cycle_in_path").call(
        <Object?>[
          node,
          path,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## on_cycle
  ///
  /// ### python docstring
  ///
  /// Called when a cycle is encountered.
  ///
  /// Parameters:
  ///     node: The node that causes a cycle.
  ///     path: The list of nodes being visited: nodes that have been
  ///         entered but not exited. The first element is the root in a forest
  ///         visit, and the last element is the node visited most recently.
  ///         ``path`` should be treated as read-only.
  ///
  /// ### python source
  /// ```py
  /// def on_cycle(self, node, path):
  ///         """Called when a cycle is encountered.
  ///
  ///         Parameters:
  ///             node: The node that causes a cycle.
  ///             path: The list of nodes being visited: nodes that have been
  ///                 entered but not exited. The first element is the root in a forest
  ///                 visit, and the last element is the node visited most recently.
  ///                 ``path`` should be treated as read-only.
  ///         """
  ///         pass
  /// ```
  Object? on_cycle({
    required Object? node,
    required Object? path,
  }) =>
      getFunction("on_cycle").call(
        <Object?>[
          node,
          path,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit
  ///
  /// ### python source
  /// ```py
  /// def visit(self, root):
  ///         # Visiting is a list of IDs of all symbol/intermediate nodes currently in
  ///         # the stack. It serves two purposes: to detect when we 'recurse' in and out
  ///         # of a symbol/intermediate so that we can process both up and down. Also,
  ///         # since the SPPF can have cycles it allows us to detect if we're trying
  ///         # to recurse into a node that's already on the stack (infinite recursion).
  ///         visiting = set()
  ///
  ///         # set of all nodes that have been visited
  ///         visited = set()
  ///
  ///         # a list of nodes that are currently being visited
  ///         # used for the `on_cycle` callback
  ///         path = []
  ///
  ///         # We do not use recursion here to walk the Forest due to the limited
  ///         # stack size in python. Therefore input_stack is essentially our stack.
  ///         input_stack = deque([root])
  ///
  ///         # It is much faster to cache these as locals since they are called
  ///         # many times in large parses.
  ///         vpno = getattr(self, 'visit_packed_node_out')
  ///         vpni = getattr(self, 'visit_packed_node_in')
  ///         vsno = getattr(self, 'visit_symbol_node_out')
  ///         vsni = getattr(self, 'visit_symbol_node_in')
  ///         vino = getattr(self, 'visit_intermediate_node_out', vsno)
  ///         vini = getattr(self, 'visit_intermediate_node_in', vsni)
  ///         vtn = getattr(self, 'visit_token_node')
  ///         oc = getattr(self, 'on_cycle')
  ///
  ///         while input_stack:
  ///             current = next(reversed(input_stack))
  ///             try:
  ///                 next_node = next(current)
  ///             except StopIteration:
  ///                 input_stack.pop()
  ///                 continue
  ///             except TypeError:
  ///                 ### If the current object is not an iterator, pass through to Token/SymbolNode
  ///                 pass
  ///             else:
  ///                 if next_node is None:
  ///                     continue
  ///
  ///                 if id(next_node) in visiting:
  ///                     oc(next_node, path)
  ///                     continue
  ///
  ///                 input_stack.append(next_node)
  ///                 continue
  ///
  ///             if isinstance(current, TokenNode):
  ///                 vtn(current.token)
  ///                 input_stack.pop()
  ///                 continue
  ///
  ///             current_id = id(current)
  ///             if current_id in visiting:
  ///                 if isinstance(current, PackedNode):
  ///                     vpno(current)
  ///                 elif current.is_intermediate:
  ///                     vino(current)
  ///                 else:
  ///                     vsno(current)
  ///                 input_stack.pop()
  ///                 path.pop()
  ///                 visiting.remove(current_id)
  ///                 visited.add(current_id)
  ///             elif self.single_visit and current_id in visited:
  ///                 input_stack.pop()
  ///             else:
  ///                 visiting.add(current_id)
  ///                 path.append(current)
  ///                 if isinstance(current, PackedNode):
  ///                     next_node = vpni(current)
  ///                 elif current.is_intermediate:
  ///                     next_node = vini(current)
  ///                 else:
  ///                     next_node = vsni(current)
  ///                 if next_node is None:
  ///                     continue
  ///
  ///                 if not isinstance(next_node, ForestNode):
  ///                     next_node = iter(next_node)
  ///                 elif id(next_node) in visiting:
  ///                     oc(next_node, path)
  ///                     continue
  ///
  ///                 input_stack.append(next_node)
  /// ```
  Object? visit({
    required Object? root,
  }) =>
      getFunction("visit").call(
        <Object?>[
          root,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_packed_node_in
  ///
  /// ### python docstring
  ///
  /// Called when a packed node is visited. Nodes that are returned
  /// will be scheduled to be visited.
  ///
  /// ### python source
  /// ```py
  /// def visit_packed_node_in(self, node):
  ///         yield node.left
  ///         yield node.right
  /// ```
  Object? visit_packed_node_in({
    required Object? node,
  }) =>
      getFunction("visit_packed_node_in").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_packed_node_out
  ///
  /// ### python docstring
  ///
  /// Called after all nodes returned from a corresponding ``visit_packed_node_in``
  /// call have been visited.
  ///
  /// ### python source
  /// ```py
  /// def visit_packed_node_out(self, node):
  ///         priority = node.rule.options.priority if not node.parent.is_intermediate and node.rule.options.priority else 0
  ///         priority += getattr(node.right, 'priority', 0)
  ///         priority += getattr(node.left, 'priority', 0)
  ///         node.priority = priority
  /// ```
  Object? visit_packed_node_out({
    required Object? node,
  }) =>
      getFunction("visit_packed_node_out").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_symbol_node_in
  ///
  /// ### python docstring
  ///
  /// Called when a symbol node is visited. Nodes that are returned
  /// will be scheduled to be visited. If ``visit_intermediate_node_in``
  /// is not implemented, this function will be called for intermediate
  /// nodes as well.
  ///
  /// ### python source
  /// ```py
  /// def visit_symbol_node_in(self, node):
  ///         return iter(node.children)
  /// ```
  Object? visit_symbol_node_in({
    required Object? node,
  }) =>
      getFunction("visit_symbol_node_in").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_symbol_node_out
  ///
  /// ### python docstring
  ///
  /// Called after all nodes returned from a corresponding ``visit_symbol_node_in``
  /// call have been visited. If ``visit_intermediate_node_out``
  /// is not implemented, this function will be called for intermediate
  /// nodes as well.
  ///
  /// ### python source
  /// ```py
  /// def visit_symbol_node_out(self, node):
  ///         node.priority = max(child.priority for child in node.children)
  /// ```
  Object? visit_symbol_node_out({
    required Object? node,
  }) =>
      getFunction("visit_symbol_node_out").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_token_node
  ///
  /// ### python docstring
  ///
  /// Called when a ``Token`` is visited. ``Token`` nodes are always leaves.
  ///
  /// ### python source
  /// ```py
  /// def visit_token_node(self, node):
  ///         """Called when a ``Token`` is visited. ``Token`` nodes are always leaves."""
  ///         pass
  /// ```
  Object? visit_token_node({
    required Object? node,
  }) =>
      getFunction("visit_token_node").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## ForestToParseTree
///
/// ### python docstring
///
/// Used by the earley parser when ambiguity equals 'resolve' or
/// 'explicit'. Transforms an SPPF into an (ambiguous) parse tree.
///
/// Parameters:
///     tree_class: The tree class to use for construction
///     callbacks: A dictionary of rules to functions that output a tree
///     prioritizer: A ``ForestVisitor`` that manipulates the priorities of ForestNodes
///     resolve_ambiguity: If True, ambiguities will be resolved based on
///                     priorities. Otherwise, `_ambig` nodes will be in the resulting tree.
///     use_cache: If True, the results of packed node transformations will be cached.
///
/// ### python source
/// ```py
/// class ForestToParseTree(ForestTransformer):
///     """Used by the earley parser when ambiguity equals 'resolve' or
///     'explicit'. Transforms an SPPF into an (ambiguous) parse tree.
///
///     Parameters:
///         tree_class: The tree class to use for construction
///         callbacks: A dictionary of rules to functions that output a tree
///         prioritizer: A ``ForestVisitor`` that manipulates the priorities of ForestNodes
///         resolve_ambiguity: If True, ambiguities will be resolved based on
///                         priorities. Otherwise, `_ambig` nodes will be in the resulting tree.
///         use_cache: If True, the results of packed node transformations will be cached.
///     """
///
///     def __init__(self, tree_class=Tree, callbacks=dict(), prioritizer=ForestSumVisitor(), resolve_ambiguity=True, use_cache=True):
///         super(ForestToParseTree, self).__init__()
///         self.tree_class = tree_class
///         self.callbacks = callbacks
///         self.prioritizer = prioritizer
///         self.resolve_ambiguity = resolve_ambiguity
///         self._use_cache = use_cache
///         self._cache = {}
///         self._on_cycle_retreat = False
///         self._cycle_node = None
///         self._successful_visits = set()
///
///     def visit(self, root):
///         if self.prioritizer:
///             self.prioritizer.visit(root)
///         super(ForestToParseTree, self).visit(root)
///         self._cache = {}
///
///     def on_cycle(self, node, path):
///         logger.debug("Cycle encountered in the SPPF at node: %s. "
///                 "As infinite ambiguities cannot be represented in a tree, "
///                 "this family of derivations will be discarded.", node)
///         self._cycle_node = node
///         self._on_cycle_retreat = True
///
///     def _check_cycle(self, node):
///         if self._on_cycle_retreat:
///             if id(node) == id(self._cycle_node) or id(node) in self._successful_visits:
///                 self._cycle_node = None
///                 self._on_cycle_retreat = False
///             else:
///                 return Discard
///
///     def _collapse_ambig(self, children):
///         new_children = []
///         for child in children:
///             if hasattr(child, 'data') and child.data == '_ambig':
///                 new_children += child.children
///             else:
///                 new_children.append(child)
///         return new_children
///
///     def _call_rule_func(self, node, data):
///         # called when transforming children of symbol nodes
///         # data is a list of trees or tokens that correspond to the
///         # symbol's rule expansion
///         return self.callbacks[node.rule](data)
///
///     def _call_ambig_func(self, node, data):
///         # called when transforming a symbol node
///         # data is a list of trees where each tree's data is
///         # equal to the name of the symbol or one of its aliases.
///         if len(data) > 1:
///             return self.tree_class('_ambig', data)
///         elif data:
///             return data[0]
///         return Discard
///
///     def transform_symbol_node(self, node, data):
///         if id(node) not in self._successful_visits:
///             return Discard
///         r = self._check_cycle(node)
///         if r is Discard:
///             return r
///         self._successful_visits.remove(id(node))
///         data = self._collapse_ambig(data)
///         return self._call_ambig_func(node, data)
///
///     def transform_intermediate_node(self, node, data):
///         if id(node) not in self._successful_visits:
///             return Discard
///         r = self._check_cycle(node)
///         if r is Discard:
///             return r
///         self._successful_visits.remove(id(node))
///         if len(data) > 1:
///             children = [self.tree_class('_inter', c) for c in data]
///             return self.tree_class('_iambig', children)
///         return data[0]
///
///     def transform_packed_node(self, node, data):
///         r = self._check_cycle(node)
///         if r is Discard:
///             return r
///         if self.resolve_ambiguity and id(node.parent) in self._successful_visits:
///             return Discard
///         if self._use_cache and id(node) in self._cache:
///             return self._cache[id(node)]
///         children = []
///         assert len(data) <= 2
///         data = PackedData(node, data)
///         if data.left is not PackedData.NO_DATA:
///             if node.left.is_intermediate and isinstance(data.left, list):
///                 children += data.left
///             else:
///                 children.append(data.left)
///         if data.right is not PackedData.NO_DATA:
///             children.append(data.right)
///         if node.parent.is_intermediate:
///             return self._cache.setdefault(id(node), children)
///         return self._cache.setdefault(id(node), self._call_rule_func(node, children))
///
///     def visit_symbol_node_in(self, node):
///         super(ForestToParseTree, self).visit_symbol_node_in(node)
///         if self._on_cycle_retreat:
///             return
///         return node.children
///
///     def visit_packed_node_in(self, node):
///         self._on_cycle_retreat = False
///         to_visit = super(ForestToParseTree, self).visit_packed_node_in(node)
///         if not self.resolve_ambiguity or id(node.parent) not in self._successful_visits:
///             if not self._use_cache or id(node) not in self._cache:
///                 return to_visit
///
///     def visit_packed_node_out(self, node):
///         super(ForestToParseTree, self).visit_packed_node_out(node)
///         if not self._on_cycle_retreat:
///             self._successful_visits.add(id(node.parent))
/// ```
final class ForestToParseTree extends PythonClass {
  factory ForestToParseTree({
    Object? tree_class,
    Object? callbacks = const {},
    Object? prioritizer,
    Object? resolve_ambiguity = true,
    Object? use_cache = true,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parsers.earley_forest",
        "ForestToParseTree",
        ForestToParseTree.from,
        <Object?>[
          tree_class,
          callbacks,
          prioritizer,
          resolve_ambiguity,
          use_cache,
        ],
        <String, Object?>{},
      );

  ForestToParseTree.from(super.pythonClass) : super.from();

  /// ## get_cycle_in_path
  ///
  /// ### python docstring
  ///
  /// A utility function for use in ``on_cycle`` to obtain a slice of
  /// ``path`` that only contains the nodes that make up the cycle.
  ///
  /// ### python source
  /// ```py
  /// def get_cycle_in_path(self, node, path):
  ///         """A utility function for use in ``on_cycle`` to obtain a slice of
  ///         ``path`` that only contains the nodes that make up the cycle."""
  ///         index = len(path) - 1
  ///         while id(path[index]) != id(node):
  ///             index -= 1
  ///         return path[index:]
  /// ```
  Object? get_cycle_in_path({
    required Object? node,
    required Object? path,
  }) =>
      getFunction("get_cycle_in_path").call(
        <Object?>[
          node,
          path,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## on_cycle
  ///
  /// ### python docstring
  ///
  /// Called when a cycle is encountered.
  ///
  /// Parameters:
  ///     node: The node that causes a cycle.
  ///     path: The list of nodes being visited: nodes that have been
  ///         entered but not exited. The first element is the root in a forest
  ///         visit, and the last element is the node visited most recently.
  ///         ``path`` should be treated as read-only.
  ///
  /// ### python source
  /// ```py
  /// def on_cycle(self, node, path):
  ///         logger.debug("Cycle encountered in the SPPF at node: %s. "
  ///                 "As infinite ambiguities cannot be represented in a tree, "
  ///                 "this family of derivations will be discarded.", node)
  ///         self._cycle_node = node
  ///         self._on_cycle_retreat = True
  /// ```
  Object? on_cycle({
    required Object? node,
    required Object? path,
  }) =>
      getFunction("on_cycle").call(
        <Object?>[
          node,
          path,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## transform
  ///
  /// ### python docstring
  ///
  /// Perform a transformation on an SPPF.
  ///
  /// ### python source
  /// ```py
  /// def transform(self, root):
  ///         """Perform a transformation on an SPPF."""
  ///         self.node_stack.append('result')
  ///         self.data['result'] = []
  ///         self.visit(root)
  ///         assert len(self.data['result']) <= 1
  ///         if self.data['result']:
  ///             return self.data['result'][0]
  /// ```
  Object? transform({
    required Object? root,
  }) =>
      getFunction("transform").call(
        <Object?>[
          root,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## transform_intermediate_node
  ///
  /// ### python docstring
  ///
  /// Transform an intermediate node.
  ///
  /// ### python source
  /// ```py
  /// def transform_intermediate_node(self, node, data):
  ///         if id(node) not in self._successful_visits:
  ///             return Discard
  ///         r = self._check_cycle(node)
  ///         if r is Discard:
  ///             return r
  ///         self._successful_visits.remove(id(node))
  ///         if len(data) > 1:
  ///             children = [self.tree_class('_inter', c) for c in data]
  ///             return self.tree_class('_iambig', children)
  ///         return data[0]
  /// ```
  Object? transform_intermediate_node({
    required Object? node,
    required Object? data,
  }) =>
      getFunction("transform_intermediate_node").call(
        <Object?>[
          node,
          data,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## transform_packed_node
  ///
  /// ### python docstring
  ///
  /// Transform a packed node.
  ///
  /// ### python source
  /// ```py
  /// def transform_packed_node(self, node, data):
  ///         r = self._check_cycle(node)
  ///         if r is Discard:
  ///             return r
  ///         if self.resolve_ambiguity and id(node.parent) in self._successful_visits:
  ///             return Discard
  ///         if self._use_cache and id(node) in self._cache:
  ///             return self._cache[id(node)]
  ///         children = []
  ///         assert len(data) <= 2
  ///         data = PackedData(node, data)
  ///         if data.left is not PackedData.NO_DATA:
  ///             if node.left.is_intermediate and isinstance(data.left, list):
  ///                 children += data.left
  ///             else:
  ///                 children.append(data.left)
  ///         if data.right is not PackedData.NO_DATA:
  ///             children.append(data.right)
  ///         if node.parent.is_intermediate:
  ///             return self._cache.setdefault(id(node), children)
  ///         return self._cache.setdefault(id(node), self._call_rule_func(node, children))
  /// ```
  Object? transform_packed_node({
    required Object? node,
    required Object? data,
  }) =>
      getFunction("transform_packed_node").call(
        <Object?>[
          node,
          data,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## transform_symbol_node
  ///
  /// ### python docstring
  ///
  /// Transform a symbol node.
  ///
  /// ### python source
  /// ```py
  /// def transform_symbol_node(self, node, data):
  ///         if id(node) not in self._successful_visits:
  ///             return Discard
  ///         r = self._check_cycle(node)
  ///         if r is Discard:
  ///             return r
  ///         self._successful_visits.remove(id(node))
  ///         data = self._collapse_ambig(data)
  ///         return self._call_ambig_func(node, data)
  /// ```
  Object? transform_symbol_node({
    required Object? node,
    required Object? data,
  }) =>
      getFunction("transform_symbol_node").call(
        <Object?>[
          node,
          data,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## transform_token_node
  ///
  /// ### python docstring
  ///
  /// Transform a ``Token``.
  ///
  /// ### python source
  /// ```py
  /// def transform_token_node(self, node):
  ///         """Transform a ``Token``."""
  ///         return node
  /// ```
  Object? transform_token_node({
    required Object? node,
  }) =>
      getFunction("transform_token_node").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit
  ///
  /// ### python source
  /// ```py
  /// def visit(self, root):
  ///         if self.prioritizer:
  ///             self.prioritizer.visit(root)
  ///         super(ForestToParseTree, self).visit(root)
  ///         self._cache = {}
  /// ```
  Object? visit({
    required Object? root,
  }) =>
      getFunction("visit").call(
        <Object?>[
          root,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_intermediate_node_out
  ///
  /// ### python source
  /// ```py
  /// def visit_intermediate_node_out(self, node):
  ///         self._visit_node_out_helper(node, self.transform_intermediate_node)
  /// ```
  Object? visit_intermediate_node_out({
    required Object? node,
  }) =>
      getFunction("visit_intermediate_node_out").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_packed_node_in
  ///
  /// ### python docstring
  ///
  /// Called when a packed node is visited. Nodes that are returned
  /// will be scheduled to be visited.
  ///
  /// ### python source
  /// ```py
  /// def visit_packed_node_in(self, node):
  ///         self._on_cycle_retreat = False
  ///         to_visit = super(ForestToParseTree, self).visit_packed_node_in(node)
  ///         if not self.resolve_ambiguity or id(node.parent) not in self._successful_visits:
  ///             if not self._use_cache or id(node) not in self._cache:
  ///                 return to_visit
  /// ```
  Object? visit_packed_node_in({
    required Object? node,
  }) =>
      getFunction("visit_packed_node_in").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_packed_node_out
  ///
  /// ### python docstring
  ///
  /// Called after all nodes returned from a corresponding ``visit_packed_node_in``
  /// call have been visited.
  ///
  /// ### python source
  /// ```py
  /// def visit_packed_node_out(self, node):
  ///         super(ForestToParseTree, self).visit_packed_node_out(node)
  ///         if not self._on_cycle_retreat:
  ///             self._successful_visits.add(id(node.parent))
  /// ```
  Object? visit_packed_node_out({
    required Object? node,
  }) =>
      getFunction("visit_packed_node_out").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_symbol_node_in
  ///
  /// ### python docstring
  ///
  /// Called when a symbol node is visited. Nodes that are returned
  /// will be scheduled to be visited. If ``visit_intermediate_node_in``
  /// is not implemented, this function will be called for intermediate
  /// nodes as well.
  ///
  /// ### python source
  /// ```py
  /// def visit_symbol_node_in(self, node):
  ///         super(ForestToParseTree, self).visit_symbol_node_in(node)
  ///         if self._on_cycle_retreat:
  ///             return
  ///         return node.children
  /// ```
  Object? visit_symbol_node_in({
    required Object? node,
  }) =>
      getFunction("visit_symbol_node_in").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_symbol_node_out
  ///
  /// ### python docstring
  ///
  /// Called after all nodes returned from a corresponding ``visit_symbol_node_in``
  /// call have been visited. If ``visit_intermediate_node_out``
  /// is not implemented, this function will be called for intermediate
  /// nodes as well.
  ///
  /// ### python source
  /// ```py
  /// def visit_symbol_node_out(self, node):
  ///         self._visit_node_out_helper(node, self.transform_symbol_node)
  /// ```
  Object? visit_symbol_node_out({
    required Object? node,
  }) =>
      getFunction("visit_symbol_node_out").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_token_node
  ///
  /// ### python docstring
  ///
  /// Called when a ``Token`` is visited. ``Token`` nodes are always leaves.
  ///
  /// ### python source
  /// ```py
  /// def visit_token_node(self, node):
  ///         transformed = self.transform_token_node(node)
  ///         if transformed is not Discard:
  ///             self.data[self.node_stack[-1]].append(transformed)
  /// ```
  Object? visit_token_node({
    required Object? node,
  }) =>
      getFunction("visit_token_node").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## tree_class (getter)
  Object? get tree_class => getAttribute("tree_class");

  /// ## tree_class (setter)
  set tree_class(Object? tree_class) => setAttribute("tree_class", tree_class);

  /// ## callbacks (getter)
  Object? get callbacks => getAttribute("callbacks");

  /// ## callbacks (setter)
  set callbacks(Object? callbacks) => setAttribute("callbacks", callbacks);

  /// ## prioritizer (getter)
  Object? get prioritizer => getAttribute("prioritizer");

  /// ## prioritizer (setter)
  set prioritizer(Object? prioritizer) =>
      setAttribute("prioritizer", prioritizer);

  /// ## resolve_ambiguity (getter)
  Object? get resolve_ambiguity => getAttribute("resolve_ambiguity");

  /// ## resolve_ambiguity (setter)
  set resolve_ambiguity(Object? resolve_ambiguity) =>
      setAttribute("resolve_ambiguity", resolve_ambiguity);
}

/// ## Item
///
/// ### python docstring
///
/// An Earley Item, the atom of the algorithm.
///
/// ### python source
/// ```py
/// class Item:
///     "An Earley Item, the atom of the algorithm."
///
///     __slots__ = ('s', 'rule', 'ptr', 'start', 'is_complete', 'expect', 'previous', 'node', '_hash')
///     def __init__(self, rule, ptr, start):
///         self.is_complete = len(rule.expansion) == ptr
///         self.rule = rule    # rule
///         self.ptr = ptr      # ptr
///         self.start = start  # j
///         self.node = None    # w
///         if self.is_complete:
///             self.s = rule.origin
///             self.expect = None
///             self.previous = rule.expansion[ptr - 1] if ptr > 0 and len(rule.expansion) else None
///         else:
///             self.s = (rule, ptr)
///             self.expect = rule.expansion[ptr]
///             self.previous = rule.expansion[ptr - 1] if ptr > 0 and len(rule.expansion) else None
///         self._hash = hash((self.s, self.start))
///
///     def advance(self):
///         return Item(self.rule, self.ptr + 1, self.start)
///
///     def __eq__(self, other):
///         return self is other or (self.s == other.s and self.start == other.start)
///
///     def __hash__(self):
///         return self._hash
///
///     def __repr__(self):
///         before = ( expansion.name for expansion in self.rule.expansion[:self.ptr] )
///         after = ( expansion.name for expansion in self.rule.expansion[self.ptr:] )
///         symbol = "{} ::= {}* {}".format(self.rule.origin.name, ' '.join(before), ' '.join(after))
///         return '%s (%d)' % (symbol, self.start)
/// ```
final class Item extends PythonClass {
  factory Item({
    required Object? rule,
    required Object? ptr,
    required Object? start,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parsers.earley_common",
        "Item",
        Item.from,
        <Object?>[
          rule,
          ptr,
          start,
        ],
        <String, Object?>{},
      );

  Item.from(super.pythonClass) : super.from();

  /// ## advance
  ///
  /// ### python source
  /// ```py
  /// def advance(self):
  ///         return Item(self.rule, self.ptr + 1, self.start)
  /// ```
  Object? advance() => getFunction("advance").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## expect (getter)
  Object? get expect => getAttribute("expect");

  /// ## expect (setter)
  set expect(Object? expect) => setAttribute("expect", expect);

  /// ## is_complete (getter)
  Object? get is_complete => getAttribute("is_complete");

  /// ## is_complete (setter)
  set is_complete(Object? is_complete) =>
      setAttribute("is_complete", is_complete);

  /// ## node (getter)
  Object? get node => getAttribute("node");

  /// ## node (setter)
  set node(Object? node) => setAttribute("node", node);

  /// ## previous (getter)
  Object? get previous => getAttribute("previous");

  /// ## previous (setter)
  set previous(Object? previous) => setAttribute("previous", previous);

  /// ## ptr (getter)
  Object? get ptr => getAttribute("ptr");

  /// ## ptr (setter)
  set ptr(Object? ptr) => setAttribute("ptr", ptr);

  /// ## rule (getter)
  Object? get rule => getAttribute("rule");

  /// ## rule (setter)
  set rule(Object? rule) => setAttribute("rule", rule);

  /// ## s (getter)
  Object? get s => getAttribute("s");

  /// ## s (setter)
  set s(Object? s) => setAttribute("s", s);

  /// ## start (getter)
  Object? get start => getAttribute("start");

  /// ## start (setter)
  set start(Object? start) => setAttribute("start", start);
}

/// ## SymbolNode
///
/// ### python docstring
///
/// A Symbol Node represents a symbol (or Intermediate LR0).
///
/// Symbol nodes are keyed by the symbol (s). For intermediate nodes
/// s will be an LR0, stored as a tuple of (rule, ptr). For completed symbol
/// nodes, s will be a string representing the non-terminal origin (i.e.
/// the left hand side of the rule).
///
/// The children of a Symbol or Intermediate Node will always be Packed Nodes;
/// with each Packed Node child representing a single derivation of a production.
///
/// Hence a Symbol Node with a single child is unambiguous.
///
/// Parameters:
///     s: A Symbol, or a tuple of (rule, ptr) for an intermediate node.
///     start: The index of the start of the substring matched by this symbol (inclusive).
///     end: The index of the end of the substring matched by this symbol (exclusive).
///
/// Properties:
///     is_intermediate: True if this node is an intermediate node.
///     priority: The priority of the node's symbol.
///
/// ### python source
/// ```py
/// class SymbolNode(ForestNode):
///     """
///     A Symbol Node represents a symbol (or Intermediate LR0).
///
///     Symbol nodes are keyed by the symbol (s). For intermediate nodes
///     s will be an LR0, stored as a tuple of (rule, ptr). For completed symbol
///     nodes, s will be a string representing the non-terminal origin (i.e.
///     the left hand side of the rule).
///
///     The children of a Symbol or Intermediate Node will always be Packed Nodes;
///     with each Packed Node child representing a single derivation of a production.
///
///     Hence a Symbol Node with a single child is unambiguous.
///
///     Parameters:
///         s: A Symbol, or a tuple of (rule, ptr) for an intermediate node.
///         start: The index of the start of the substring matched by this symbol (inclusive).
///         end: The index of the end of the substring matched by this symbol (exclusive).
///
///     Properties:
///         is_intermediate: True if this node is an intermediate node.
///         priority: The priority of the node's symbol.
///     """
///     __slots__ = ('s', 'start', 'end', '_children', 'paths', 'paths_loaded', 'priority', 'is_intermediate', '_hash')
///     def __init__(self, s, start, end):
///         self.s = s
///         self.start = start
///         self.end = end
///         self._children = set()
///         self.paths = set()
///         self.paths_loaded = False
///
///         ### We use inf here as it can be safely negated without resorting to conditionals,
///         #   unlike None or float('NaN'), and sorts appropriately.
///         self.priority = float('-inf')
///         self.is_intermediate = isinstance(s, tuple)
///         self._hash = hash((self.s, self.start, self.end))
///
///     def add_family(self, lr0, rule, start, left, right):
///         self._children.add(PackedNode(self, lr0, rule, start, left, right))
///
///     def add_path(self, transitive, node):
///         self.paths.add((transitive, node))
///
///     def load_paths(self):
///         for transitive, node in self.paths:
///             if transitive.next_titem is not None:
///                 vn = SymbolNode(transitive.next_titem.s, transitive.next_titem.start, self.end)
///                 vn.add_path(transitive.next_titem, node)
///                 self.add_family(transitive.reduction.rule.origin, transitive.reduction.rule, transitive.reduction.start, transitive.reduction.node, vn)
///             else:
///                 self.add_family(transitive.reduction.rule.origin, transitive.reduction.rule, transitive.reduction.start, transitive.reduction.node, node)
///         self.paths_loaded = True
///
///     @property
///     def is_ambiguous(self):
///         """Returns True if this node is ambiguous."""
///         return len(self.children) > 1
///
///     @property
///     def children(self):
///         """Returns a list of this node's children sorted from greatest to
///         least priority."""
///         if not self.paths_loaded: self.load_paths()
///         return sorted(self._children, key=attrgetter('sort_key'))
///
///     def __iter__(self):
///         return iter(self._children)
///
///     def __eq__(self, other):
///         if not isinstance(other, SymbolNode):
///             return False
///         return self is other or (type(self.s) == type(other.s) and self.s == other.s and self.start == other.start and self.end is other.end)
///
///     def __hash__(self):
///         return self._hash
///
///     def __repr__(self):
///         if self.is_intermediate:
///             rule = self.s[0]
///             ptr = self.s[1]
///             before = ( expansion.name for expansion in rule.expansion[:ptr] )
///             after = ( expansion.name for expansion in rule.expansion[ptr:] )
///             symbol = "{} ::= {}* {}".format(rule.origin.name, ' '.join(before), ' '.join(after))
///         else:
///             symbol = self.s.name
///         return "({}, {}, {}, {})".format(symbol, self.start, self.end, self.priority)
/// ```
final class SymbolNode extends PythonClass {
  factory SymbolNode({
    required Object? s,
    required Object? start,
    required Object? end,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parsers.earley_forest",
        "SymbolNode",
        SymbolNode.from,
        <Object?>[
          s,
          start,
          end,
        ],
        <String, Object?>{},
      );

  SymbolNode.from(super.pythonClass) : super.from();

  /// ## add_family
  ///
  /// ### python source
  /// ```py
  /// def add_family(self, lr0, rule, start, left, right):
  ///         self._children.add(PackedNode(self, lr0, rule, start, left, right))
  /// ```
  Object? add_family({
    required Object? lr0,
    required Object? rule,
    required Object? start,
    required Object? left,
    required Object? right,
  }) =>
      getFunction("add_family").call(
        <Object?>[
          lr0,
          rule,
          start,
          left,
          right,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## add_path
  ///
  /// ### python source
  /// ```py
  /// def add_path(self, transitive, node):
  ///         self.paths.add((transitive, node))
  /// ```
  Object? add_path({
    required Object? transitive,
    required Object? node,
  }) =>
      getFunction("add_path").call(
        <Object?>[
          transitive,
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## load_paths
  ///
  /// ### python source
  /// ```py
  /// def load_paths(self):
  ///         for transitive, node in self.paths:
  ///             if transitive.next_titem is not None:
  ///                 vn = SymbolNode(transitive.next_titem.s, transitive.next_titem.start, self.end)
  ///                 vn.add_path(transitive.next_titem, node)
  ///                 self.add_family(transitive.reduction.rule.origin, transitive.reduction.rule, transitive.reduction.start, transitive.reduction.node, vn)
  ///             else:
  ///                 self.add_family(transitive.reduction.rule.origin, transitive.reduction.rule, transitive.reduction.start, transitive.reduction.node, node)
  ///         self.paths_loaded = True
  /// ```
  Object? load_paths() => getFunction("load_paths").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## children (getter)
  ///
  /// ### python docstring
  ///
  /// Returns a list of this node's children sorted from greatest to
  /// least priority.
  Object? get children => getAttribute("children");

  /// ## children (setter)
  ///
  /// ### python docstring
  ///
  /// Returns a list of this node's children sorted from greatest to
  /// least priority.
  set children(Object? children) => setAttribute("children", children);

  /// ## is_ambiguous (getter)
  ///
  /// ### python docstring
  ///
  /// Returns True if this node is ambiguous.
  Object? get is_ambiguous => getAttribute("is_ambiguous");

  /// ## is_ambiguous (setter)
  ///
  /// ### python docstring
  ///
  /// Returns True if this node is ambiguous.
  set is_ambiguous(Object? is_ambiguous) =>
      setAttribute("is_ambiguous", is_ambiguous);

  /// ## end (getter)
  Object? get end => getAttribute("end");

  /// ## end (setter)
  set end(Object? end) => setAttribute("end", end);

  /// ## is_intermediate (getter)
  Object? get is_intermediate => getAttribute("is_intermediate");

  /// ## is_intermediate (setter)
  set is_intermediate(Object? is_intermediate) =>
      setAttribute("is_intermediate", is_intermediate);

  /// ## paths (getter)
  Object? get paths => getAttribute("paths");

  /// ## paths (setter)
  set paths(Object? paths) => setAttribute("paths", paths);

  /// ## paths_loaded (getter)
  Object? get paths_loaded => getAttribute("paths_loaded");

  /// ## paths_loaded (setter)
  set paths_loaded(Object? paths_loaded) =>
      setAttribute("paths_loaded", paths_loaded);

  /// ## priority (getter)
  Object? get priority => getAttribute("priority");

  /// ## priority (setter)
  set priority(Object? priority) => setAttribute("priority", priority);

  /// ## s (getter)
  Object? get s => getAttribute("s");

  /// ## s (setter)
  set s(Object? s) => setAttribute("s", s);

  /// ## start (getter)
  Object? get start => getAttribute("start");

  /// ## start (setter)
  set start(Object? start) => setAttribute("start", start);
}

/// ## TokenNode
///
/// ### python docstring
///
/// A Token Node represents a matched terminal and is always a leaf node.
///
/// Parameters:
///     token: The Token associated with this node.
///     term: The TerminalDef matched by the token.
///     priority: The priority of this node.
///
/// ### python source
/// ```py
/// class TokenNode(ForestNode):
///     """
///     A Token Node represents a matched terminal and is always a leaf node.
///
///     Parameters:
///         token: The Token associated with this node.
///         term: The TerminalDef matched by the token.
///         priority: The priority of this node.
///     """
///     __slots__ = ('token', 'term', 'priority', '_hash')
///     def __init__(self, token, term, priority=None):
///         self.token = token
///         self.term = term
///         if priority is not None:
///             self.priority = priority
///         else:
///             self.priority = term.priority if term is not None else 0
///         self._hash = hash(token)
///
///     def __eq__(self, other):
///         if not isinstance(other, TokenNode):
///             return False
///         return self is other or (self.token == other.token)
///
///     def __hash__(self):
///         return self._hash
///
///     def __repr__(self):
///         return repr(self.token)
/// ```
final class TokenNode extends PythonClass {
  factory TokenNode({
    required Object? token,
    required Object? term,
    Object? priority,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parsers.earley_forest",
        "TokenNode",
        TokenNode.from,
        <Object?>[
          token,
          term,
          priority,
        ],
        <String, Object?>{},
      );

  TokenNode.from(super.pythonClass) : super.from();

  /// ## priority (getter)
  Object? get priority => getAttribute("priority");

  /// ## priority (setter)
  set priority(Object? priority) => setAttribute("priority", priority);

  /// ## term (getter)
  Object? get term => getAttribute("term");

  /// ## term (setter)
  set term(Object? term) => setAttribute("term", term);

  /// ## token (getter)
  Object? get token => getAttribute("token");

  /// ## token (setter)
  set token(Object? token) => setAttribute("token", token);
}

/// ## ForestNode
///
/// ### python source
/// ```py
/// class ForestNode:
///     pass
/// ```
final class ForestNode extends PythonClass {
  factory ForestNode() => PythonFfiDart.instance.importClass(
        "lark.parsers.earley_forest",
        "ForestNode",
        ForestNode.from,
        <Object?>[],
      );

  ForestNode.from(super.pythonClass) : super.from();
}

/// ## ForestToPyDotVisitor
///
/// ### python docstring
///
/// A Forest visitor which writes the SPPF to a PNG.
///
/// The SPPF can get really large, really quickly because
/// of the amount of meta-data it stores, so this is probably
/// only useful for trivial trees and learning how the SPPF
/// is structured.
///
/// ### python source
/// ```py
/// class ForestToPyDotVisitor(ForestVisitor):
///     """
///     A Forest visitor which writes the SPPF to a PNG.
///
///     The SPPF can get really large, really quickly because
///     of the amount of meta-data it stores, so this is probably
///     only useful for trivial trees and learning how the SPPF
///     is structured.
///     """
///     def __init__(self, rankdir="TB"):
///         super(ForestToPyDotVisitor, self).__init__(single_visit=True)
///         self.pydot = import_module('pydot')
///         self.graph = self.pydot.Dot(graph_type='digraph', rankdir=rankdir)
///
///     def visit(self, root, filename):
///         super(ForestToPyDotVisitor, self).visit(root)
///         try:
///             self.graph.write_png(filename)
///         except FileNotFoundError as e:
///             logger.error("Could not write png: ", e)
///
///     def visit_token_node(self, node):
///         graph_node_id = str(id(node))
///         graph_node_label = "\"{}\"".format(node.value.replace('"', '\\"'))
///         graph_node_color = 0x808080
///         graph_node_style = "\"filled,rounded\""
///         graph_node_shape = "diamond"
///         graph_node = self.pydot.Node(graph_node_id, style=graph_node_style, fillcolor="#{:06x}".format(graph_node_color), shape=graph_node_shape, label=graph_node_label)
///         self.graph.add_node(graph_node)
///
///     def visit_packed_node_in(self, node):
///         graph_node_id = str(id(node))
///         graph_node_label = repr(node)
///         graph_node_color = 0x808080
///         graph_node_style = "filled"
///         graph_node_shape = "diamond"
///         graph_node = self.pydot.Node(graph_node_id, style=graph_node_style, fillcolor="#{:06x}".format(graph_node_color), shape=graph_node_shape, label=graph_node_label)
///         self.graph.add_node(graph_node)
///         yield node.left
///         yield node.right
///
///     def visit_packed_node_out(self, node):
///         graph_node_id = str(id(node))
///         graph_node = self.graph.get_node(graph_node_id)[0]
///         for child in [node.left, node.right]:
///             if child is not None:
///                 child_graph_node_id = str(id(child.token if isinstance(child, TokenNode) else child))
///                 child_graph_node = self.graph.get_node(child_graph_node_id)[0]
///                 self.graph.add_edge(self.pydot.Edge(graph_node, child_graph_node))
///             else:
///                 #### Try and be above the Python object ID range; probably impl. specific, but maybe this is okay.
///                 child_graph_node_id = str(randint(100000000000000000000000000000,123456789012345678901234567890))
///                 child_graph_node_style = "invis"
///                 child_graph_node = self.pydot.Node(child_graph_node_id, style=child_graph_node_style, label="None")
///                 child_edge_style = "invis"
///                 self.graph.add_node(child_graph_node)
///                 self.graph.add_edge(self.pydot.Edge(graph_node, child_graph_node, style=child_edge_style))
///
///     def visit_symbol_node_in(self, node):
///         graph_node_id = str(id(node))
///         graph_node_label = repr(node)
///         graph_node_color = 0x808080
///         graph_node_style = "\"filled\""
///         if node.is_intermediate:
///             graph_node_shape = "ellipse"
///         else:
///             graph_node_shape = "rectangle"
///         graph_node = self.pydot.Node(graph_node_id, style=graph_node_style, fillcolor="#{:06x}".format(graph_node_color), shape=graph_node_shape, label=graph_node_label)
///         self.graph.add_node(graph_node)
///         return iter(node.children)
///
///     def visit_symbol_node_out(self, node):
///         graph_node_id = str(id(node))
///         graph_node = self.graph.get_node(graph_node_id)[0]
///         for child in node.children:
///             child_graph_node_id = str(id(child))
///             child_graph_node = self.graph.get_node(child_graph_node_id)[0]
///             self.graph.add_edge(self.pydot.Edge(graph_node, child_graph_node))
/// ```
final class ForestToPyDotVisitor extends PythonClass {
  factory ForestToPyDotVisitor({
    Object? rankdir = "TB",
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parsers.earley_forest",
        "ForestToPyDotVisitor",
        ForestToPyDotVisitor.from,
        <Object?>[
          rankdir,
        ],
        <String, Object?>{},
      );

  ForestToPyDotVisitor.from(super.pythonClass) : super.from();

  /// ## get_cycle_in_path
  ///
  /// ### python docstring
  ///
  /// A utility function for use in ``on_cycle`` to obtain a slice of
  /// ``path`` that only contains the nodes that make up the cycle.
  ///
  /// ### python source
  /// ```py
  /// def get_cycle_in_path(self, node, path):
  ///         """A utility function for use in ``on_cycle`` to obtain a slice of
  ///         ``path`` that only contains the nodes that make up the cycle."""
  ///         index = len(path) - 1
  ///         while id(path[index]) != id(node):
  ///             index -= 1
  ///         return path[index:]
  /// ```
  Object? get_cycle_in_path({
    required Object? node,
    required Object? path,
  }) =>
      getFunction("get_cycle_in_path").call(
        <Object?>[
          node,
          path,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## on_cycle
  ///
  /// ### python docstring
  ///
  /// Called when a cycle is encountered.
  ///
  /// Parameters:
  ///     node: The node that causes a cycle.
  ///     path: The list of nodes being visited: nodes that have been
  ///         entered but not exited. The first element is the root in a forest
  ///         visit, and the last element is the node visited most recently.
  ///         ``path`` should be treated as read-only.
  ///
  /// ### python source
  /// ```py
  /// def on_cycle(self, node, path):
  ///         """Called when a cycle is encountered.
  ///
  ///         Parameters:
  ///             node: The node that causes a cycle.
  ///             path: The list of nodes being visited: nodes that have been
  ///                 entered but not exited. The first element is the root in a forest
  ///                 visit, and the last element is the node visited most recently.
  ///                 ``path`` should be treated as read-only.
  ///         """
  ///         pass
  /// ```
  Object? on_cycle({
    required Object? node,
    required Object? path,
  }) =>
      getFunction("on_cycle").call(
        <Object?>[
          node,
          path,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit
  ///
  /// ### python source
  /// ```py
  /// def visit(self, root, filename):
  ///         super(ForestToPyDotVisitor, self).visit(root)
  ///         try:
  ///             self.graph.write_png(filename)
  ///         except FileNotFoundError as e:
  ///             logger.error("Could not write png: ", e)
  /// ```
  Object? visit({
    required Object? root,
    required Object? filename,
  }) =>
      getFunction("visit").call(
        <Object?>[
          root,
          filename,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_packed_node_in
  ///
  /// ### python docstring
  ///
  /// Called when a packed node is visited. Nodes that are returned
  /// will be scheduled to be visited.
  ///
  /// ### python source
  /// ```py
  /// def visit_packed_node_in(self, node):
  ///         graph_node_id = str(id(node))
  ///         graph_node_label = repr(node)
  ///         graph_node_color = 0x808080
  ///         graph_node_style = "filled"
  ///         graph_node_shape = "diamond"
  ///         graph_node = self.pydot.Node(graph_node_id, style=graph_node_style, fillcolor="#{:06x}".format(graph_node_color), shape=graph_node_shape, label=graph_node_label)
  ///         self.graph.add_node(graph_node)
  ///         yield node.left
  ///         yield node.right
  /// ```
  Object? visit_packed_node_in({
    required Object? node,
  }) =>
      getFunction("visit_packed_node_in").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_packed_node_out
  ///
  /// ### python docstring
  ///
  /// Called after all nodes returned from a corresponding ``visit_packed_node_in``
  /// call have been visited.
  ///
  /// ### python source
  /// ```py
  /// def visit_packed_node_out(self, node):
  ///         graph_node_id = str(id(node))
  ///         graph_node = self.graph.get_node(graph_node_id)[0]
  ///         for child in [node.left, node.right]:
  ///             if child is not None:
  ///                 child_graph_node_id = str(id(child.token if isinstance(child, TokenNode) else child))
  ///                 child_graph_node = self.graph.get_node(child_graph_node_id)[0]
  ///                 self.graph.add_edge(self.pydot.Edge(graph_node, child_graph_node))
  ///             else:
  ///                 #### Try and be above the Python object ID range; probably impl. specific, but maybe this is okay.
  ///                 child_graph_node_id = str(randint(100000000000000000000000000000,123456789012345678901234567890))
  ///                 child_graph_node_style = "invis"
  ///                 child_graph_node = self.pydot.Node(child_graph_node_id, style=child_graph_node_style, label="None")
  ///                 child_edge_style = "invis"
  ///                 self.graph.add_node(child_graph_node)
  ///                 self.graph.add_edge(self.pydot.Edge(graph_node, child_graph_node, style=child_edge_style))
  /// ```
  Object? visit_packed_node_out({
    required Object? node,
  }) =>
      getFunction("visit_packed_node_out").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_symbol_node_in
  ///
  /// ### python docstring
  ///
  /// Called when a symbol node is visited. Nodes that are returned
  /// will be scheduled to be visited. If ``visit_intermediate_node_in``
  /// is not implemented, this function will be called for intermediate
  /// nodes as well.
  ///
  /// ### python source
  /// ```py
  /// def visit_symbol_node_in(self, node):
  ///         graph_node_id = str(id(node))
  ///         graph_node_label = repr(node)
  ///         graph_node_color = 0x808080
  ///         graph_node_style = "\"filled\""
  ///         if node.is_intermediate:
  ///             graph_node_shape = "ellipse"
  ///         else:
  ///             graph_node_shape = "rectangle"
  ///         graph_node = self.pydot.Node(graph_node_id, style=graph_node_style, fillcolor="#{:06x}".format(graph_node_color), shape=graph_node_shape, label=graph_node_label)
  ///         self.graph.add_node(graph_node)
  ///         return iter(node.children)
  /// ```
  Object? visit_symbol_node_in({
    required Object? node,
  }) =>
      getFunction("visit_symbol_node_in").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_symbol_node_out
  ///
  /// ### python docstring
  ///
  /// Called after all nodes returned from a corresponding ``visit_symbol_node_in``
  /// call have been visited. If ``visit_intermediate_node_out``
  /// is not implemented, this function will be called for intermediate
  /// nodes as well.
  ///
  /// ### python source
  /// ```py
  /// def visit_symbol_node_out(self, node):
  ///         graph_node_id = str(id(node))
  ///         graph_node = self.graph.get_node(graph_node_id)[0]
  ///         for child in node.children:
  ///             child_graph_node_id = str(id(child))
  ///             child_graph_node = self.graph.get_node(child_graph_node_id)[0]
  ///             self.graph.add_edge(self.pydot.Edge(graph_node, child_graph_node))
  /// ```
  Object? visit_symbol_node_out({
    required Object? node,
  }) =>
      getFunction("visit_symbol_node_out").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_token_node
  ///
  /// ### python docstring
  ///
  /// Called when a ``Token`` is visited. ``Token`` nodes are always leaves.
  ///
  /// ### python source
  /// ```py
  /// def visit_token_node(self, node):
  ///         graph_node_id = str(id(node))
  ///         graph_node_label = "\"{}\"".format(node.value.replace('"', '\\"'))
  ///         graph_node_color = 0x808080
  ///         graph_node_style = "\"filled,rounded\""
  ///         graph_node_shape = "diamond"
  ///         graph_node = self.pydot.Node(graph_node_id, style=graph_node_style, fillcolor="#{:06x}".format(graph_node_color), shape=graph_node_shape, label=graph_node_label)
  ///         self.graph.add_node(graph_node)
  /// ```
  Object? visit_token_node({
    required Object? node,
  }) =>
      getFunction("visit_token_node").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## pydot (getter)
  Object? get pydot => getAttribute("pydot");

  /// ## pydot (setter)
  set pydot(Object? pydot) => setAttribute("pydot", pydot);

  /// ## graph (getter)
  Object? get graph => getAttribute("graph");

  /// ## graph (setter)
  set graph(Object? graph) => setAttribute("graph", graph);
}

/// ## ForestTransformer
///
/// ### python docstring
///
/// The base class for a bottom-up forest transformation. Most users will
/// want to use ``TreeForestTransformer`` instead as it has a friendlier
/// interface and covers most use cases.
///
/// Transformations are applied via inheritance and overriding of the
/// ``transform*node`` methods.
///
/// ``transform_token_node`` receives a ``Token`` as an argument.
/// All other methods receive the node that is being transformed and
/// a list of the results of the transformations of that node's children.
/// The return value of these methods are the resulting transformations.
///
/// If ``Discard`` is raised in a node's transformation, no data from that node
/// will be passed to its parent's transformation.
///
/// ### python source
/// ```py
/// class ForestTransformer(ForestVisitor):
///     """The base class for a bottom-up forest transformation. Most users will
///     want to use ``TreeForestTransformer`` instead as it has a friendlier
///     interface and covers most use cases.
///
///     Transformations are applied via inheritance and overriding of the
///     ``transform*node`` methods.
///
///     ``transform_token_node`` receives a ``Token`` as an argument.
///     All other methods receive the node that is being transformed and
///     a list of the results of the transformations of that node's children.
///     The return value of these methods are the resulting transformations.
///
///     If ``Discard`` is raised in a node's transformation, no data from that node
///     will be passed to its parent's transformation.
///     """
///
///     def __init__(self):
///         super(ForestTransformer, self).__init__()
///         # results of transformations
///         self.data = dict()
///         # used to track parent nodes
///         self.node_stack = deque()
///
///     def transform(self, root):
///         """Perform a transformation on an SPPF."""
///         self.node_stack.append('result')
///         self.data['result'] = []
///         self.visit(root)
///         assert len(self.data['result']) <= 1
///         if self.data['result']:
///             return self.data['result'][0]
///
///     def transform_symbol_node(self, node, data):
///         """Transform a symbol node."""
///         return node
///
///     def transform_intermediate_node(self, node, data):
///         """Transform an intermediate node."""
///         return node
///
///     def transform_packed_node(self, node, data):
///         """Transform a packed node."""
///         return node
///
///     def transform_token_node(self, node):
///         """Transform a ``Token``."""
///         return node
///
///     def visit_symbol_node_in(self, node):
///         self.node_stack.append(id(node))
///         self.data[id(node)] = []
///         return node.children
///
///     def visit_packed_node_in(self, node):
///         self.node_stack.append(id(node))
///         self.data[id(node)] = []
///         return node.children
///
///     def visit_token_node(self, node):
///         transformed = self.transform_token_node(node)
///         if transformed is not Discard:
///             self.data[self.node_stack[-1]].append(transformed)
///
///     def _visit_node_out_helper(self, node, method):
///         self.node_stack.pop()
///         transformed = method(node, self.data[id(node)])
///         if transformed is not Discard:
///             self.data[self.node_stack[-1]].append(transformed)
///         del self.data[id(node)]
///
///     def visit_symbol_node_out(self, node):
///         self._visit_node_out_helper(node, self.transform_symbol_node)
///
///     def visit_intermediate_node_out(self, node):
///         self._visit_node_out_helper(node, self.transform_intermediate_node)
///
///     def visit_packed_node_out(self, node):
///         self._visit_node_out_helper(node, self.transform_packed_node)
/// ```
final class ForestTransformer extends PythonClass {
  factory ForestTransformer() => PythonFfiDart.instance.importClass(
        "lark.parsers.earley_forest",
        "ForestTransformer",
        ForestTransformer.from,
        <Object?>[],
        <String, Object?>{},
      );

  ForestTransformer.from(super.pythonClass) : super.from();

  /// ## get_cycle_in_path
  ///
  /// ### python docstring
  ///
  /// A utility function for use in ``on_cycle`` to obtain a slice of
  /// ``path`` that only contains the nodes that make up the cycle.
  ///
  /// ### python source
  /// ```py
  /// def get_cycle_in_path(self, node, path):
  ///         """A utility function for use in ``on_cycle`` to obtain a slice of
  ///         ``path`` that only contains the nodes that make up the cycle."""
  ///         index = len(path) - 1
  ///         while id(path[index]) != id(node):
  ///             index -= 1
  ///         return path[index:]
  /// ```
  Object? get_cycle_in_path({
    required Object? node,
    required Object? path,
  }) =>
      getFunction("get_cycle_in_path").call(
        <Object?>[
          node,
          path,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## on_cycle
  ///
  /// ### python docstring
  ///
  /// Called when a cycle is encountered.
  ///
  /// Parameters:
  ///     node: The node that causes a cycle.
  ///     path: The list of nodes being visited: nodes that have been
  ///         entered but not exited. The first element is the root in a forest
  ///         visit, and the last element is the node visited most recently.
  ///         ``path`` should be treated as read-only.
  ///
  /// ### python source
  /// ```py
  /// def on_cycle(self, node, path):
  ///         """Called when a cycle is encountered.
  ///
  ///         Parameters:
  ///             node: The node that causes a cycle.
  ///             path: The list of nodes being visited: nodes that have been
  ///                 entered but not exited. The first element is the root in a forest
  ///                 visit, and the last element is the node visited most recently.
  ///                 ``path`` should be treated as read-only.
  ///         """
  ///         pass
  /// ```
  Object? on_cycle({
    required Object? node,
    required Object? path,
  }) =>
      getFunction("on_cycle").call(
        <Object?>[
          node,
          path,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## transform
  ///
  /// ### python docstring
  ///
  /// Perform a transformation on an SPPF.
  ///
  /// ### python source
  /// ```py
  /// def transform(self, root):
  ///         """Perform a transformation on an SPPF."""
  ///         self.node_stack.append('result')
  ///         self.data['result'] = []
  ///         self.visit(root)
  ///         assert len(self.data['result']) <= 1
  ///         if self.data['result']:
  ///             return self.data['result'][0]
  /// ```
  Object? transform({
    required Object? root,
  }) =>
      getFunction("transform").call(
        <Object?>[
          root,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## transform_intermediate_node
  ///
  /// ### python docstring
  ///
  /// Transform an intermediate node.
  ///
  /// ### python source
  /// ```py
  /// def transform_intermediate_node(self, node, data):
  ///         """Transform an intermediate node."""
  ///         return node
  /// ```
  Object? transform_intermediate_node({
    required Object? node,
    required Object? data,
  }) =>
      getFunction("transform_intermediate_node").call(
        <Object?>[
          node,
          data,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## transform_packed_node
  ///
  /// ### python docstring
  ///
  /// Transform a packed node.
  ///
  /// ### python source
  /// ```py
  /// def transform_packed_node(self, node, data):
  ///         """Transform a packed node."""
  ///         return node
  /// ```
  Object? transform_packed_node({
    required Object? node,
    required Object? data,
  }) =>
      getFunction("transform_packed_node").call(
        <Object?>[
          node,
          data,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## transform_symbol_node
  ///
  /// ### python docstring
  ///
  /// Transform a symbol node.
  ///
  /// ### python source
  /// ```py
  /// def transform_symbol_node(self, node, data):
  ///         """Transform a symbol node."""
  ///         return node
  /// ```
  Object? transform_symbol_node({
    required Object? node,
    required Object? data,
  }) =>
      getFunction("transform_symbol_node").call(
        <Object?>[
          node,
          data,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## transform_token_node
  ///
  /// ### python docstring
  ///
  /// Transform a ``Token``.
  ///
  /// ### python source
  /// ```py
  /// def transform_token_node(self, node):
  ///         """Transform a ``Token``."""
  ///         return node
  /// ```
  Object? transform_token_node({
    required Object? node,
  }) =>
      getFunction("transform_token_node").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit
  ///
  /// ### python source
  /// ```py
  /// def visit(self, root):
  ///         # Visiting is a list of IDs of all symbol/intermediate nodes currently in
  ///         # the stack. It serves two purposes: to detect when we 'recurse' in and out
  ///         # of a symbol/intermediate so that we can process both up and down. Also,
  ///         # since the SPPF can have cycles it allows us to detect if we're trying
  ///         # to recurse into a node that's already on the stack (infinite recursion).
  ///         visiting = set()
  ///
  ///         # set of all nodes that have been visited
  ///         visited = set()
  ///
  ///         # a list of nodes that are currently being visited
  ///         # used for the `on_cycle` callback
  ///         path = []
  ///
  ///         # We do not use recursion here to walk the Forest due to the limited
  ///         # stack size in python. Therefore input_stack is essentially our stack.
  ///         input_stack = deque([root])
  ///
  ///         # It is much faster to cache these as locals since they are called
  ///         # many times in large parses.
  ///         vpno = getattr(self, 'visit_packed_node_out')
  ///         vpni = getattr(self, 'visit_packed_node_in')
  ///         vsno = getattr(self, 'visit_symbol_node_out')
  ///         vsni = getattr(self, 'visit_symbol_node_in')
  ///         vino = getattr(self, 'visit_intermediate_node_out', vsno)
  ///         vini = getattr(self, 'visit_intermediate_node_in', vsni)
  ///         vtn = getattr(self, 'visit_token_node')
  ///         oc = getattr(self, 'on_cycle')
  ///
  ///         while input_stack:
  ///             current = next(reversed(input_stack))
  ///             try:
  ///                 next_node = next(current)
  ///             except StopIteration:
  ///                 input_stack.pop()
  ///                 continue
  ///             except TypeError:
  ///                 ### If the current object is not an iterator, pass through to Token/SymbolNode
  ///                 pass
  ///             else:
  ///                 if next_node is None:
  ///                     continue
  ///
  ///                 if id(next_node) in visiting:
  ///                     oc(next_node, path)
  ///                     continue
  ///
  ///                 input_stack.append(next_node)
  ///                 continue
  ///
  ///             if isinstance(current, TokenNode):
  ///                 vtn(current.token)
  ///                 input_stack.pop()
  ///                 continue
  ///
  ///             current_id = id(current)
  ///             if current_id in visiting:
  ///                 if isinstance(current, PackedNode):
  ///                     vpno(current)
  ///                 elif current.is_intermediate:
  ///                     vino(current)
  ///                 else:
  ///                     vsno(current)
  ///                 input_stack.pop()
  ///                 path.pop()
  ///                 visiting.remove(current_id)
  ///                 visited.add(current_id)
  ///             elif self.single_visit and current_id in visited:
  ///                 input_stack.pop()
  ///             else:
  ///                 visiting.add(current_id)
  ///                 path.append(current)
  ///                 if isinstance(current, PackedNode):
  ///                     next_node = vpni(current)
  ///                 elif current.is_intermediate:
  ///                     next_node = vini(current)
  ///                 else:
  ///                     next_node = vsni(current)
  ///                 if next_node is None:
  ///                     continue
  ///
  ///                 if not isinstance(next_node, ForestNode):
  ///                     next_node = iter(next_node)
  ///                 elif id(next_node) in visiting:
  ///                     oc(next_node, path)
  ///                     continue
  ///
  ///                 input_stack.append(next_node)
  /// ```
  Object? visit({
    required Object? root,
  }) =>
      getFunction("visit").call(
        <Object?>[
          root,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_intermediate_node_out
  ///
  /// ### python source
  /// ```py
  /// def visit_intermediate_node_out(self, node):
  ///         self._visit_node_out_helper(node, self.transform_intermediate_node)
  /// ```
  Object? visit_intermediate_node_out({
    required Object? node,
  }) =>
      getFunction("visit_intermediate_node_out").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_packed_node_in
  ///
  /// ### python docstring
  ///
  /// Called when a packed node is visited. Nodes that are returned
  /// will be scheduled to be visited.
  ///
  /// ### python source
  /// ```py
  /// def visit_packed_node_in(self, node):
  ///         self.node_stack.append(id(node))
  ///         self.data[id(node)] = []
  ///         return node.children
  /// ```
  Object? visit_packed_node_in({
    required Object? node,
  }) =>
      getFunction("visit_packed_node_in").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_packed_node_out
  ///
  /// ### python docstring
  ///
  /// Called after all nodes returned from a corresponding ``visit_packed_node_in``
  /// call have been visited.
  ///
  /// ### python source
  /// ```py
  /// def visit_packed_node_out(self, node):
  ///         self._visit_node_out_helper(node, self.transform_packed_node)
  /// ```
  Object? visit_packed_node_out({
    required Object? node,
  }) =>
      getFunction("visit_packed_node_out").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_symbol_node_in
  ///
  /// ### python docstring
  ///
  /// Called when a symbol node is visited. Nodes that are returned
  /// will be scheduled to be visited. If ``visit_intermediate_node_in``
  /// is not implemented, this function will be called for intermediate
  /// nodes as well.
  ///
  /// ### python source
  /// ```py
  /// def visit_symbol_node_in(self, node):
  ///         self.node_stack.append(id(node))
  ///         self.data[id(node)] = []
  ///         return node.children
  /// ```
  Object? visit_symbol_node_in({
    required Object? node,
  }) =>
      getFunction("visit_symbol_node_in").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_symbol_node_out
  ///
  /// ### python docstring
  ///
  /// Called after all nodes returned from a corresponding ``visit_symbol_node_in``
  /// call have been visited. If ``visit_intermediate_node_out``
  /// is not implemented, this function will be called for intermediate
  /// nodes as well.
  ///
  /// ### python source
  /// ```py
  /// def visit_symbol_node_out(self, node):
  ///         self._visit_node_out_helper(node, self.transform_symbol_node)
  /// ```
  Object? visit_symbol_node_out({
    required Object? node,
  }) =>
      getFunction("visit_symbol_node_out").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_token_node
  ///
  /// ### python docstring
  ///
  /// Called when a ``Token`` is visited. ``Token`` nodes are always leaves.
  ///
  /// ### python source
  /// ```py
  /// def visit_token_node(self, node):
  ///         transformed = self.transform_token_node(node)
  ///         if transformed is not Discard:
  ///             self.data[self.node_stack[-1]].append(transformed)
  /// ```
  Object? visit_token_node({
    required Object? node,
  }) =>
      getFunction("visit_token_node").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## data (getter)
  Object? get data => getAttribute("data");

  /// ## data (setter)
  set data(Object? data) => setAttribute("data", data);

  /// ## node_stack (getter)
  Object? get node_stack => getAttribute("node_stack");

  /// ## node_stack (setter)
  set node_stack(Object? node_stack) => setAttribute("node_stack", node_stack);
}

/// ## ForestVisitor
///
/// ### python docstring
///
/// An abstract base class for building forest visitors.
///
/// This class performs a controllable depth-first walk of an SPPF.
/// The visitor will not enter cycles and will backtrack if one is encountered.
/// Subclasses are notified of cycles through the ``on_cycle`` method.
///
/// Behavior for visit events is defined by overriding the
/// ``visit*node*`` functions.
///
/// The walk is controlled by the return values of the ``visit*node_in``
/// methods. Returning a node(s) will schedule them to be visited. The visitor
/// will begin to backtrack if no nodes are returned.
///
/// Parameters:
///     single_visit: If ``True``, non-Token nodes will only be visited once.
///
/// ### python source
/// ```py
/// class ForestVisitor:
///     """
///     An abstract base class for building forest visitors.
///
///     This class performs a controllable depth-first walk of an SPPF.
///     The visitor will not enter cycles and will backtrack if one is encountered.
///     Subclasses are notified of cycles through the ``on_cycle`` method.
///
///     Behavior for visit events is defined by overriding the
///     ``visit*node*`` functions.
///
///     The walk is controlled by the return values of the ``visit*node_in``
///     methods. Returning a node(s) will schedule them to be visited. The visitor
///     will begin to backtrack if no nodes are returned.
///
///     Parameters:
///         single_visit: If ``True``, non-Token nodes will only be visited once.
///     """
///
///     def __init__(self, single_visit=False):
///         self.single_visit = single_visit
///
///     def visit_token_node(self, node):
///         """Called when a ``Token`` is visited. ``Token`` nodes are always leaves."""
///         pass
///
///     def visit_symbol_node_in(self, node):
///         """Called when a symbol node is visited. Nodes that are returned
///         will be scheduled to be visited. If ``visit_intermediate_node_in``
///         is not implemented, this function will be called for intermediate
///         nodes as well."""
///         pass
///
///     def visit_symbol_node_out(self, node):
///         """Called after all nodes returned from a corresponding ``visit_symbol_node_in``
///         call have been visited. If ``visit_intermediate_node_out``
///         is not implemented, this function will be called for intermediate
///         nodes as well."""
///         pass
///
///     def visit_packed_node_in(self, node):
///         """Called when a packed node is visited. Nodes that are returned
///         will be scheduled to be visited. """
///         pass
///
///     def visit_packed_node_out(self, node):
///         """Called after all nodes returned from a corresponding ``visit_packed_node_in``
///         call have been visited."""
///         pass
///
///     def on_cycle(self, node, path):
///         """Called when a cycle is encountered.
///
///         Parameters:
///             node: The node that causes a cycle.
///             path: The list of nodes being visited: nodes that have been
///                 entered but not exited. The first element is the root in a forest
///                 visit, and the last element is the node visited most recently.
///                 ``path`` should be treated as read-only.
///         """
///         pass
///
///     def get_cycle_in_path(self, node, path):
///         """A utility function for use in ``on_cycle`` to obtain a slice of
///         ``path`` that only contains the nodes that make up the cycle."""
///         index = len(path) - 1
///         while id(path[index]) != id(node):
///             index -= 1
///         return path[index:]
///
///     def visit(self, root):
///         # Visiting is a list of IDs of all symbol/intermediate nodes currently in
///         # the stack. It serves two purposes: to detect when we 'recurse' in and out
///         # of a symbol/intermediate so that we can process both up and down. Also,
///         # since the SPPF can have cycles it allows us to detect if we're trying
///         # to recurse into a node that's already on the stack (infinite recursion).
///         visiting = set()
///
///         # set of all nodes that have been visited
///         visited = set()
///
///         # a list of nodes that are currently being visited
///         # used for the `on_cycle` callback
///         path = []
///
///         # We do not use recursion here to walk the Forest due to the limited
///         # stack size in python. Therefore input_stack is essentially our stack.
///         input_stack = deque([root])
///
///         # It is much faster to cache these as locals since they are called
///         # many times in large parses.
///         vpno = getattr(self, 'visit_packed_node_out')
///         vpni = getattr(self, 'visit_packed_node_in')
///         vsno = getattr(self, 'visit_symbol_node_out')
///         vsni = getattr(self, 'visit_symbol_node_in')
///         vino = getattr(self, 'visit_intermediate_node_out', vsno)
///         vini = getattr(self, 'visit_intermediate_node_in', vsni)
///         vtn = getattr(self, 'visit_token_node')
///         oc = getattr(self, 'on_cycle')
///
///         while input_stack:
///             current = next(reversed(input_stack))
///             try:
///                 next_node = next(current)
///             except StopIteration:
///                 input_stack.pop()
///                 continue
///             except TypeError:
///                 ### If the current object is not an iterator, pass through to Token/SymbolNode
///                 pass
///             else:
///                 if next_node is None:
///                     continue
///
///                 if id(next_node) in visiting:
///                     oc(next_node, path)
///                     continue
///
///                 input_stack.append(next_node)
///                 continue
///
///             if isinstance(current, TokenNode):
///                 vtn(current.token)
///                 input_stack.pop()
///                 continue
///
///             current_id = id(current)
///             if current_id in visiting:
///                 if isinstance(current, PackedNode):
///                     vpno(current)
///                 elif current.is_intermediate:
///                     vino(current)
///                 else:
///                     vsno(current)
///                 input_stack.pop()
///                 path.pop()
///                 visiting.remove(current_id)
///                 visited.add(current_id)
///             elif self.single_visit and current_id in visited:
///                 input_stack.pop()
///             else:
///                 visiting.add(current_id)
///                 path.append(current)
///                 if isinstance(current, PackedNode):
///                     next_node = vpni(current)
///                 elif current.is_intermediate:
///                     next_node = vini(current)
///                 else:
///                     next_node = vsni(current)
///                 if next_node is None:
///                     continue
///
///                 if not isinstance(next_node, ForestNode):
///                     next_node = iter(next_node)
///                 elif id(next_node) in visiting:
///                     oc(next_node, path)
///                     continue
///
///                 input_stack.append(next_node)
/// ```
final class ForestVisitor extends PythonClass {
  factory ForestVisitor({
    Object? single_visit = false,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parsers.earley_forest",
        "ForestVisitor",
        ForestVisitor.from,
        <Object?>[
          single_visit,
        ],
        <String, Object?>{},
      );

  ForestVisitor.from(super.pythonClass) : super.from();

  /// ## get_cycle_in_path
  ///
  /// ### python docstring
  ///
  /// A utility function for use in ``on_cycle`` to obtain a slice of
  /// ``path`` that only contains the nodes that make up the cycle.
  ///
  /// ### python source
  /// ```py
  /// def get_cycle_in_path(self, node, path):
  ///         """A utility function for use in ``on_cycle`` to obtain a slice of
  ///         ``path`` that only contains the nodes that make up the cycle."""
  ///         index = len(path) - 1
  ///         while id(path[index]) != id(node):
  ///             index -= 1
  ///         return path[index:]
  /// ```
  Object? get_cycle_in_path({
    required Object? node,
    required Object? path,
  }) =>
      getFunction("get_cycle_in_path").call(
        <Object?>[
          node,
          path,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## on_cycle
  ///
  /// ### python docstring
  ///
  /// Called when a cycle is encountered.
  ///
  /// Parameters:
  ///     node: The node that causes a cycle.
  ///     path: The list of nodes being visited: nodes that have been
  ///         entered but not exited. The first element is the root in a forest
  ///         visit, and the last element is the node visited most recently.
  ///         ``path`` should be treated as read-only.
  ///
  /// ### python source
  /// ```py
  /// def on_cycle(self, node, path):
  ///         """Called when a cycle is encountered.
  ///
  ///         Parameters:
  ///             node: The node that causes a cycle.
  ///             path: The list of nodes being visited: nodes that have been
  ///                 entered but not exited. The first element is the root in a forest
  ///                 visit, and the last element is the node visited most recently.
  ///                 ``path`` should be treated as read-only.
  ///         """
  ///         pass
  /// ```
  Object? on_cycle({
    required Object? node,
    required Object? path,
  }) =>
      getFunction("on_cycle").call(
        <Object?>[
          node,
          path,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit
  ///
  /// ### python source
  /// ```py
  /// def visit(self, root):
  ///         # Visiting is a list of IDs of all symbol/intermediate nodes currently in
  ///         # the stack. It serves two purposes: to detect when we 'recurse' in and out
  ///         # of a symbol/intermediate so that we can process both up and down. Also,
  ///         # since the SPPF can have cycles it allows us to detect if we're trying
  ///         # to recurse into a node that's already on the stack (infinite recursion).
  ///         visiting = set()
  ///
  ///         # set of all nodes that have been visited
  ///         visited = set()
  ///
  ///         # a list of nodes that are currently being visited
  ///         # used for the `on_cycle` callback
  ///         path = []
  ///
  ///         # We do not use recursion here to walk the Forest due to the limited
  ///         # stack size in python. Therefore input_stack is essentially our stack.
  ///         input_stack = deque([root])
  ///
  ///         # It is much faster to cache these as locals since they are called
  ///         # many times in large parses.
  ///         vpno = getattr(self, 'visit_packed_node_out')
  ///         vpni = getattr(self, 'visit_packed_node_in')
  ///         vsno = getattr(self, 'visit_symbol_node_out')
  ///         vsni = getattr(self, 'visit_symbol_node_in')
  ///         vino = getattr(self, 'visit_intermediate_node_out', vsno)
  ///         vini = getattr(self, 'visit_intermediate_node_in', vsni)
  ///         vtn = getattr(self, 'visit_token_node')
  ///         oc = getattr(self, 'on_cycle')
  ///
  ///         while input_stack:
  ///             current = next(reversed(input_stack))
  ///             try:
  ///                 next_node = next(current)
  ///             except StopIteration:
  ///                 input_stack.pop()
  ///                 continue
  ///             except TypeError:
  ///                 ### If the current object is not an iterator, pass through to Token/SymbolNode
  ///                 pass
  ///             else:
  ///                 if next_node is None:
  ///                     continue
  ///
  ///                 if id(next_node) in visiting:
  ///                     oc(next_node, path)
  ///                     continue
  ///
  ///                 input_stack.append(next_node)
  ///                 continue
  ///
  ///             if isinstance(current, TokenNode):
  ///                 vtn(current.token)
  ///                 input_stack.pop()
  ///                 continue
  ///
  ///             current_id = id(current)
  ///             if current_id in visiting:
  ///                 if isinstance(current, PackedNode):
  ///                     vpno(current)
  ///                 elif current.is_intermediate:
  ///                     vino(current)
  ///                 else:
  ///                     vsno(current)
  ///                 input_stack.pop()
  ///                 path.pop()
  ///                 visiting.remove(current_id)
  ///                 visited.add(current_id)
  ///             elif self.single_visit and current_id in visited:
  ///                 input_stack.pop()
  ///             else:
  ///                 visiting.add(current_id)
  ///                 path.append(current)
  ///                 if isinstance(current, PackedNode):
  ///                     next_node = vpni(current)
  ///                 elif current.is_intermediate:
  ///                     next_node = vini(current)
  ///                 else:
  ///                     next_node = vsni(current)
  ///                 if next_node is None:
  ///                     continue
  ///
  ///                 if not isinstance(next_node, ForestNode):
  ///                     next_node = iter(next_node)
  ///                 elif id(next_node) in visiting:
  ///                     oc(next_node, path)
  ///                     continue
  ///
  ///                 input_stack.append(next_node)
  /// ```
  Object? visit({
    required Object? root,
  }) =>
      getFunction("visit").call(
        <Object?>[
          root,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_packed_node_in
  ///
  /// ### python docstring
  ///
  /// Called when a packed node is visited. Nodes that are returned
  /// will be scheduled to be visited.
  ///
  /// ### python source
  /// ```py
  /// def visit_packed_node_in(self, node):
  ///         """Called when a packed node is visited. Nodes that are returned
  ///         will be scheduled to be visited. """
  ///         pass
  /// ```
  Object? visit_packed_node_in({
    required Object? node,
  }) =>
      getFunction("visit_packed_node_in").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_packed_node_out
  ///
  /// ### python docstring
  ///
  /// Called after all nodes returned from a corresponding ``visit_packed_node_in``
  /// call have been visited.
  ///
  /// ### python source
  /// ```py
  /// def visit_packed_node_out(self, node):
  ///         """Called after all nodes returned from a corresponding ``visit_packed_node_in``
  ///         call have been visited."""
  ///         pass
  /// ```
  Object? visit_packed_node_out({
    required Object? node,
  }) =>
      getFunction("visit_packed_node_out").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_symbol_node_in
  ///
  /// ### python docstring
  ///
  /// Called when a symbol node is visited. Nodes that are returned
  /// will be scheduled to be visited. If ``visit_intermediate_node_in``
  /// is not implemented, this function will be called for intermediate
  /// nodes as well.
  ///
  /// ### python source
  /// ```py
  /// def visit_symbol_node_in(self, node):
  ///         """Called when a symbol node is visited. Nodes that are returned
  ///         will be scheduled to be visited. If ``visit_intermediate_node_in``
  ///         is not implemented, this function will be called for intermediate
  ///         nodes as well."""
  ///         pass
  /// ```
  Object? visit_symbol_node_in({
    required Object? node,
  }) =>
      getFunction("visit_symbol_node_in").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_symbol_node_out
  ///
  /// ### python docstring
  ///
  /// Called after all nodes returned from a corresponding ``visit_symbol_node_in``
  /// call have been visited. If ``visit_intermediate_node_out``
  /// is not implemented, this function will be called for intermediate
  /// nodes as well.
  ///
  /// ### python source
  /// ```py
  /// def visit_symbol_node_out(self, node):
  ///         """Called after all nodes returned from a corresponding ``visit_symbol_node_in``
  ///         call have been visited. If ``visit_intermediate_node_out``
  ///         is not implemented, this function will be called for intermediate
  ///         nodes as well."""
  ///         pass
  /// ```
  Object? visit_symbol_node_out({
    required Object? node,
  }) =>
      getFunction("visit_symbol_node_out").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_token_node
  ///
  /// ### python docstring
  ///
  /// Called when a ``Token`` is visited. ``Token`` nodes are always leaves.
  ///
  /// ### python source
  /// ```py
  /// def visit_token_node(self, node):
  ///         """Called when a ``Token`` is visited. ``Token`` nodes are always leaves."""
  ///         pass
  /// ```
  Object? visit_token_node({
    required Object? node,
  }) =>
      getFunction("visit_token_node").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## single_visit (getter)
  Object? get single_visit => getAttribute("single_visit");

  /// ## single_visit (setter)
  set single_visit(Object? single_visit) =>
      setAttribute("single_visit", single_visit);
}

/// ## PackedData
///
/// ### python docstring
///
/// Used in transformationss of packed nodes to distinguish the data
/// that comes from the left child and the right child.
///
/// ### python source
/// ```py
/// class PackedData():
///     """Used in transformationss of packed nodes to distinguish the data
///     that comes from the left child and the right child.
///     """
///
///     class _NoData():
///         pass
///
///     NO_DATA = _NoData()
///
///     def __init__(self, node, data):
///         self.left = self.NO_DATA
///         self.right = self.NO_DATA
///         if data:
///             if node.left is not None:
///                 self.left = data[0]
///                 if len(data) > 1:
///                     self.right = data[1]
///             else:
///                 self.right = data[0]
/// ```
final class PackedData extends PythonClass {
  factory PackedData({
    required Object? node,
    required Object? data,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parsers.earley_forest",
        "PackedData",
        PackedData.from,
        <Object?>[
          node,
          data,
        ],
        <String, Object?>{},
      );

  PackedData.from(super.pythonClass) : super.from();

  /// ## NO_DATA (getter)
  Object? get NO_DATA => getAttribute("NO_DATA");

  /// ## NO_DATA (setter)
  set NO_DATA(Object? NO_DATA) => setAttribute("NO_DATA", NO_DATA);

  /// ## left (getter)
  Object? get left => getAttribute("left");

  /// ## left (setter)
  set left(Object? left) => setAttribute("left", left);

  /// ## right (getter)
  Object? get right => getAttribute("right");

  /// ## right (setter)
  set right(Object? right) => setAttribute("right", right);
}

/// ## PackedNode
///
/// ### python docstring
///
/// A Packed Node represents a single derivation in a symbol node.
///
/// Parameters:
///     rule: The rule associated with this node.
///     parent: The parent of this node.
///     left: The left child of this node. ``None`` if one does not exist.
///     right: The right child of this node. ``None`` if one does not exist.
///     priority: The priority of this node.
///
/// ### python source
/// ```py
/// class PackedNode(ForestNode):
///     """
///     A Packed Node represents a single derivation in a symbol node.
///
///     Parameters:
///         rule: The rule associated with this node.
///         parent: The parent of this node.
///         left: The left child of this node. ``None`` if one does not exist.
///         right: The right child of this node. ``None`` if one does not exist.
///         priority: The priority of this node.
///     """
///     __slots__ = ('parent', 's', 'rule', 'start', 'left', 'right', 'priority', '_hash')
///     def __init__(self, parent, s, rule, start, left, right):
///         self.parent = parent
///         self.s = s
///         self.start = start
///         self.rule = rule
///         self.left = left
///         self.right = right
///         self.priority = float('-inf')
///         self._hash = hash((self.left, self.right))
///
///     @property
///     def is_empty(self):
///         return self.left is None and self.right is None
///
///     @property
///     def sort_key(self):
///         """
///         Used to sort PackedNode children of SymbolNodes.
///         A SymbolNode has multiple PackedNodes if it matched
///         ambiguously. Hence, we use the sort order to identify
///         the order in which ambiguous children should be considered.
///         """
///         return self.is_empty, -self.priority, self.rule.order
///
///     @property
///     def children(self):
///         """Returns a list of this node's children."""
///         return [x for x in [self.left, self.right] if x is not None]
///
///     def __iter__(self):
///         yield self.left
///         yield self.right
///
///     def __eq__(self, other):
///         if not isinstance(other, PackedNode):
///             return False
///         return self is other or (self.left == other.left and self.right == other.right)
///
///     def __hash__(self):
///         return self._hash
///
///     def __repr__(self):
///         if isinstance(self.s, tuple):
///             rule = self.s[0]
///             ptr = self.s[1]
///             before = ( expansion.name for expansion in rule.expansion[:ptr] )
///             after = ( expansion.name for expansion in rule.expansion[ptr:] )
///             symbol = "{} ::= {}* {}".format(rule.origin.name, ' '.join(before), ' '.join(after))
///         else:
///             symbol = self.s.name
///         return "({}, {}, {}, {})".format(symbol, self.start, self.priority, self.rule.order)
/// ```
final class PackedNode extends PythonClass {
  factory PackedNode({
    required Object? parent,
    required Object? s,
    required Object? rule,
    required Object? start,
    required Object? left,
    required Object? right,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parsers.earley_forest",
        "PackedNode",
        PackedNode.from,
        <Object?>[
          parent,
          s,
          rule,
          start,
          left,
          right,
        ],
        <String, Object?>{},
      );

  PackedNode.from(super.pythonClass) : super.from();

  /// ## children (getter)
  ///
  /// ### python docstring
  ///
  /// Returns a list of this node's children.
  Object? get children => getAttribute("children");

  /// ## children (setter)
  ///
  /// ### python docstring
  ///
  /// Returns a list of this node's children.
  set children(Object? children) => setAttribute("children", children);

  /// ## is_empty (getter)
  Object? get is_empty => getAttribute("is_empty");

  /// ## is_empty (setter)
  set is_empty(Object? is_empty) => setAttribute("is_empty", is_empty);

  /// ## sort_key (getter)
  ///
  /// ### python docstring
  ///
  /// Used to sort PackedNode children of SymbolNodes.
  /// A SymbolNode has multiple PackedNodes if it matched
  /// ambiguously. Hence, we use the sort order to identify
  /// the order in which ambiguous children should be considered.
  Object? get sort_key => getAttribute("sort_key");

  /// ## sort_key (setter)
  ///
  /// ### python docstring
  ///
  /// Used to sort PackedNode children of SymbolNodes.
  /// A SymbolNode has multiple PackedNodes if it matched
  /// ambiguously. Hence, we use the sort order to identify
  /// the order in which ambiguous children should be considered.
  set sort_key(Object? sort_key) => setAttribute("sort_key", sort_key);

  /// ## left (getter)
  Object? get left => getAttribute("left");

  /// ## left (setter)
  set left(Object? left) => setAttribute("left", left);

  /// ## parent (getter)
  Object? get parent => getAttribute("parent");

  /// ## parent (setter)
  set parent(Object? parent) => setAttribute("parent", parent);

  /// ## priority (getter)
  Object? get priority => getAttribute("priority");

  /// ## priority (setter)
  set priority(Object? priority) => setAttribute("priority", priority);

  /// ## right (getter)
  Object? get right => getAttribute("right");

  /// ## right (setter)
  set right(Object? right) => setAttribute("right", right);

  /// ## rule (getter)
  Object? get rule => getAttribute("rule");

  /// ## rule (setter)
  set rule(Object? rule) => setAttribute("rule", rule);

  /// ## s (getter)
  Object? get s => getAttribute("s");

  /// ## s (setter)
  set s(Object? s) => setAttribute("s", s);

  /// ## start (getter)
  Object? get start => getAttribute("start");

  /// ## start (setter)
  set start(Object? start) => setAttribute("start", start);
}

/// ## TreeForestTransformer
///
/// ### python docstring
///
/// A ``ForestTransformer`` with a tree ``Transformer``-like interface.
/// By default, it will construct a tree.
///
/// Methods provided via inheritance are called based on the rule/symbol
/// names of nodes in the forest.
///
/// Methods that act on rules will receive a list of the results of the
/// transformations of the rule's children. By default, trees and tokens.
///
/// Methods that act on tokens will receive a token.
///
/// Alternatively, methods that act on rules may be annotated with
/// ``handles_ambiguity``. In this case, the function will receive a list
/// of all the transformations of all the derivations of the rule.
/// By default, a list of trees where each tree.data is equal to the
/// rule name or one of its aliases.
///
/// Non-tree transformations are made possible by override of
/// ``__default__``, ``__default_token__``, and ``__default_ambig__``.
///
/// Note:
///     Tree shaping features such as inlined rules and token filtering are
///     not built into the transformation. Positions are also not propagated.
///
/// Parameters:
///     tree_class: The tree class to use for construction
///     prioritizer: A ``ForestVisitor`` that manipulates the priorities of nodes in the SPPF.
///     resolve_ambiguity: If True, ambiguities will be resolved based on priorities.
///     use_cache (bool): If True, caches the results of some transformations,
///                       potentially improving performance when ``resolve_ambiguity==False``.
///                       Only use if you know what you are doing: i.e. All transformation
///                       functions are pure and referentially transparent.
///
/// ### python source
/// ```py
/// class TreeForestTransformer(ForestToParseTree):
///     """A ``ForestTransformer`` with a tree ``Transformer``-like interface.
///     By default, it will construct a tree.
///
///     Methods provided via inheritance are called based on the rule/symbol
///     names of nodes in the forest.
///
///     Methods that act on rules will receive a list of the results of the
///     transformations of the rule's children. By default, trees and tokens.
///
///     Methods that act on tokens will receive a token.
///
///     Alternatively, methods that act on rules may be annotated with
///     ``handles_ambiguity``. In this case, the function will receive a list
///     of all the transformations of all the derivations of the rule.
///     By default, a list of trees where each tree.data is equal to the
///     rule name or one of its aliases.
///
///     Non-tree transformations are made possible by override of
///     ``__default__``, ``__default_token__``, and ``__default_ambig__``.
///
///     Note:
///         Tree shaping features such as inlined rules and token filtering are
///         not built into the transformation. Positions are also not propagated.
///
///     Parameters:
///         tree_class: The tree class to use for construction
///         prioritizer: A ``ForestVisitor`` that manipulates the priorities of nodes in the SPPF.
///         resolve_ambiguity: If True, ambiguities will be resolved based on priorities.
///         use_cache (bool): If True, caches the results of some transformations,
///                           potentially improving performance when ``resolve_ambiguity==False``.
///                           Only use if you know what you are doing: i.e. All transformation
///                           functions are pure and referentially transparent.
///     """
///
///     def __init__(self, tree_class=Tree, prioritizer=ForestSumVisitor(), resolve_ambiguity=True, use_cache=False):
///         super(TreeForestTransformer, self).__init__(tree_class, dict(), prioritizer, resolve_ambiguity, use_cache)
///
///     def __default__(self, name, data):
///         """Default operation on tree (for override).
///
///         Returns a tree with name with data as children.
///         """
///         return self.tree_class(name, data)
///
///     def __default_ambig__(self, name, data):
///         """Default operation on ambiguous rule (for override).
///
///         Wraps data in an '_ambig_' node if it contains more than
///         one element.
///         """
///         if len(data) > 1:
///             return self.tree_class('_ambig', data)
///         elif data:
///             return data[0]
///         return Discard
///
///     def __default_token__(self, node):
///         """Default operation on ``Token`` (for override).
///
///         Returns ``node``.
///         """
///         return node
///
///     def transform_token_node(self, node):
///         return getattr(self, node.type, self.__default_token__)(node)
///
///     def _call_rule_func(self, node, data):
///         name = node.rule.alias or node.rule.options.template_source or node.rule.origin.name
///         user_func = getattr(self, name, self.__default__)
///         if user_func == self.__default__ or hasattr(user_func, 'handles_ambiguity'):
///             user_func = partial(self.__default__, name)
///         if not self.resolve_ambiguity:
///             wrapper = partial(AmbiguousIntermediateExpander, self.tree_class)
///             user_func = wrapper(user_func)
///         return user_func(data)
///
///     def _call_ambig_func(self, node, data):
///         name = node.s.name
///         user_func = getattr(self, name, self.__default_ambig__)
///         if user_func == self.__default_ambig__ or not hasattr(user_func, 'handles_ambiguity'):
///             user_func = partial(self.__default_ambig__, name)
///         return user_func(data)
/// ```
final class TreeForestTransformer extends PythonClass {
  factory TreeForestTransformer({
    Object? tree_class,
    Object? prioritizer,
    Object? resolve_ambiguity = true,
    Object? use_cache = false,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parsers.earley_forest",
        "TreeForestTransformer",
        TreeForestTransformer.from,
        <Object?>[
          tree_class,
          prioritizer,
          resolve_ambiguity,
          use_cache,
        ],
        <String, Object?>{},
      );

  TreeForestTransformer.from(super.pythonClass) : super.from();

  /// ## get_cycle_in_path
  ///
  /// ### python docstring
  ///
  /// A utility function for use in ``on_cycle`` to obtain a slice of
  /// ``path`` that only contains the nodes that make up the cycle.
  ///
  /// ### python source
  /// ```py
  /// def get_cycle_in_path(self, node, path):
  ///         """A utility function for use in ``on_cycle`` to obtain a slice of
  ///         ``path`` that only contains the nodes that make up the cycle."""
  ///         index = len(path) - 1
  ///         while id(path[index]) != id(node):
  ///             index -= 1
  ///         return path[index:]
  /// ```
  Object? get_cycle_in_path({
    required Object? node,
    required Object? path,
  }) =>
      getFunction("get_cycle_in_path").call(
        <Object?>[
          node,
          path,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## on_cycle
  ///
  /// ### python docstring
  ///
  /// Called when a cycle is encountered.
  ///
  /// Parameters:
  ///     node: The node that causes a cycle.
  ///     path: The list of nodes being visited: nodes that have been
  ///         entered but not exited. The first element is the root in a forest
  ///         visit, and the last element is the node visited most recently.
  ///         ``path`` should be treated as read-only.
  ///
  /// ### python source
  /// ```py
  /// def on_cycle(self, node, path):
  ///         logger.debug("Cycle encountered in the SPPF at node: %s. "
  ///                 "As infinite ambiguities cannot be represented in a tree, "
  ///                 "this family of derivations will be discarded.", node)
  ///         self._cycle_node = node
  ///         self._on_cycle_retreat = True
  /// ```
  Object? on_cycle({
    required Object? node,
    required Object? path,
  }) =>
      getFunction("on_cycle").call(
        <Object?>[
          node,
          path,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## transform
  ///
  /// ### python docstring
  ///
  /// Perform a transformation on an SPPF.
  ///
  /// ### python source
  /// ```py
  /// def transform(self, root):
  ///         """Perform a transformation on an SPPF."""
  ///         self.node_stack.append('result')
  ///         self.data['result'] = []
  ///         self.visit(root)
  ///         assert len(self.data['result']) <= 1
  ///         if self.data['result']:
  ///             return self.data['result'][0]
  /// ```
  Object? transform({
    required Object? root,
  }) =>
      getFunction("transform").call(
        <Object?>[
          root,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## transform_intermediate_node
  ///
  /// ### python docstring
  ///
  /// Transform an intermediate node.
  ///
  /// ### python source
  /// ```py
  /// def transform_intermediate_node(self, node, data):
  ///         if id(node) not in self._successful_visits:
  ///             return Discard
  ///         r = self._check_cycle(node)
  ///         if r is Discard:
  ///             return r
  ///         self._successful_visits.remove(id(node))
  ///         if len(data) > 1:
  ///             children = [self.tree_class('_inter', c) for c in data]
  ///             return self.tree_class('_iambig', children)
  ///         return data[0]
  /// ```
  Object? transform_intermediate_node({
    required Object? node,
    required Object? data,
  }) =>
      getFunction("transform_intermediate_node").call(
        <Object?>[
          node,
          data,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## transform_packed_node
  ///
  /// ### python docstring
  ///
  /// Transform a packed node.
  ///
  /// ### python source
  /// ```py
  /// def transform_packed_node(self, node, data):
  ///         r = self._check_cycle(node)
  ///         if r is Discard:
  ///             return r
  ///         if self.resolve_ambiguity and id(node.parent) in self._successful_visits:
  ///             return Discard
  ///         if self._use_cache and id(node) in self._cache:
  ///             return self._cache[id(node)]
  ///         children = []
  ///         assert len(data) <= 2
  ///         data = PackedData(node, data)
  ///         if data.left is not PackedData.NO_DATA:
  ///             if node.left.is_intermediate and isinstance(data.left, list):
  ///                 children += data.left
  ///             else:
  ///                 children.append(data.left)
  ///         if data.right is not PackedData.NO_DATA:
  ///             children.append(data.right)
  ///         if node.parent.is_intermediate:
  ///             return self._cache.setdefault(id(node), children)
  ///         return self._cache.setdefault(id(node), self._call_rule_func(node, children))
  /// ```
  Object? transform_packed_node({
    required Object? node,
    required Object? data,
  }) =>
      getFunction("transform_packed_node").call(
        <Object?>[
          node,
          data,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## transform_symbol_node
  ///
  /// ### python docstring
  ///
  /// Transform a symbol node.
  ///
  /// ### python source
  /// ```py
  /// def transform_symbol_node(self, node, data):
  ///         if id(node) not in self._successful_visits:
  ///             return Discard
  ///         r = self._check_cycle(node)
  ///         if r is Discard:
  ///             return r
  ///         self._successful_visits.remove(id(node))
  ///         data = self._collapse_ambig(data)
  ///         return self._call_ambig_func(node, data)
  /// ```
  Object? transform_symbol_node({
    required Object? node,
    required Object? data,
  }) =>
      getFunction("transform_symbol_node").call(
        <Object?>[
          node,
          data,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## transform_token_node
  ///
  /// ### python docstring
  ///
  /// Transform a ``Token``.
  ///
  /// ### python source
  /// ```py
  /// def transform_token_node(self, node):
  ///         return getattr(self, node.type, self.__default_token__)(node)
  /// ```
  Object? transform_token_node({
    required Object? node,
  }) =>
      getFunction("transform_token_node").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit
  ///
  /// ### python source
  /// ```py
  /// def visit(self, root):
  ///         if self.prioritizer:
  ///             self.prioritizer.visit(root)
  ///         super(ForestToParseTree, self).visit(root)
  ///         self._cache = {}
  /// ```
  Object? visit({
    required Object? root,
  }) =>
      getFunction("visit").call(
        <Object?>[
          root,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_intermediate_node_out
  ///
  /// ### python source
  /// ```py
  /// def visit_intermediate_node_out(self, node):
  ///         self._visit_node_out_helper(node, self.transform_intermediate_node)
  /// ```
  Object? visit_intermediate_node_out({
    required Object? node,
  }) =>
      getFunction("visit_intermediate_node_out").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_packed_node_in
  ///
  /// ### python docstring
  ///
  /// Called when a packed node is visited. Nodes that are returned
  /// will be scheduled to be visited.
  ///
  /// ### python source
  /// ```py
  /// def visit_packed_node_in(self, node):
  ///         self._on_cycle_retreat = False
  ///         to_visit = super(ForestToParseTree, self).visit_packed_node_in(node)
  ///         if not self.resolve_ambiguity or id(node.parent) not in self._successful_visits:
  ///             if not self._use_cache or id(node) not in self._cache:
  ///                 return to_visit
  /// ```
  Object? visit_packed_node_in({
    required Object? node,
  }) =>
      getFunction("visit_packed_node_in").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_packed_node_out
  ///
  /// ### python docstring
  ///
  /// Called after all nodes returned from a corresponding ``visit_packed_node_in``
  /// call have been visited.
  ///
  /// ### python source
  /// ```py
  /// def visit_packed_node_out(self, node):
  ///         super(ForestToParseTree, self).visit_packed_node_out(node)
  ///         if not self._on_cycle_retreat:
  ///             self._successful_visits.add(id(node.parent))
  /// ```
  Object? visit_packed_node_out({
    required Object? node,
  }) =>
      getFunction("visit_packed_node_out").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_symbol_node_in
  ///
  /// ### python docstring
  ///
  /// Called when a symbol node is visited. Nodes that are returned
  /// will be scheduled to be visited. If ``visit_intermediate_node_in``
  /// is not implemented, this function will be called for intermediate
  /// nodes as well.
  ///
  /// ### python source
  /// ```py
  /// def visit_symbol_node_in(self, node):
  ///         super(ForestToParseTree, self).visit_symbol_node_in(node)
  ///         if self._on_cycle_retreat:
  ///             return
  ///         return node.children
  /// ```
  Object? visit_symbol_node_in({
    required Object? node,
  }) =>
      getFunction("visit_symbol_node_in").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_symbol_node_out
  ///
  /// ### python docstring
  ///
  /// Called after all nodes returned from a corresponding ``visit_symbol_node_in``
  /// call have been visited. If ``visit_intermediate_node_out``
  /// is not implemented, this function will be called for intermediate
  /// nodes as well.
  ///
  /// ### python source
  /// ```py
  /// def visit_symbol_node_out(self, node):
  ///         self._visit_node_out_helper(node, self.transform_symbol_node)
  /// ```
  Object? visit_symbol_node_out({
    required Object? node,
  }) =>
      getFunction("visit_symbol_node_out").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_token_node
  ///
  /// ### python docstring
  ///
  /// Called when a ``Token`` is visited. ``Token`` nodes are always leaves.
  ///
  /// ### python source
  /// ```py
  /// def visit_token_node(self, node):
  ///         transformed = self.transform_token_node(node)
  ///         if transformed is not Discard:
  ///             self.data[self.node_stack[-1]].append(transformed)
  /// ```
  Object? visit_token_node({
    required Object? node,
  }) =>
      getFunction("visit_token_node").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## attrgetter
///
/// ### python source
/// ```py
/// class attrgetter:
///     """
///     Return a callable object that fetches the given attribute(s) from its operand.
///     After f = attrgetter('name'), the call f(r) returns r.name.
///     After g = attrgetter('name', 'date'), the call g(r) returns (r.name, r.date).
///     After h = attrgetter('name.first', 'name.last'), the call h(r) returns
///     (r.name.first, r.name.last).
///     """
///     __slots__ = ('_attrs', '_call')
///
///     def __init__(self, attr, *attrs):
///         if not attrs:
///             if not isinstance(attr, str):
///                 raise TypeError('attribute name must be a string')
///             self._attrs = (attr,)
///             names = attr.split('.')
///             def func(obj):
///                 for name in names:
///                     obj = getattr(obj, name)
///                 return obj
///             self._call = func
///         else:
///             self._attrs = (attr,) + attrs
///             getters = tuple(map(attrgetter, self._attrs))
///             def func(obj):
///                 return tuple(getter(obj) for getter in getters)
///             self._call = func
///
///     def __call__(self, obj):
///         return self._call(obj)
///
///     def __repr__(self):
///         return '%s.%s(%s)' % (self.__class__.__module__,
///                               self.__class__.__qualname__,
///                               ', '.join(map(repr, self._attrs)))
///
///     def __reduce__(self):
///         return self.__class__, self._attrs
/// ```
final class attrgetter extends PythonClass {
  factory attrgetter() => PythonFfiDart.instance.importClass(
        "operator",
        "attrgetter",
        attrgetter.from,
        <Object?>[],
      );

  attrgetter.from(super.pythonClass) : super.from();
}

/// ## Counter
///
/// ### python docstring
///
/// Dict subclass for counting hashable items.  Sometimes called a bag
/// or multiset.  Elements are stored as dictionary keys and their counts
/// are stored as dictionary values.
///
/// >>> c = Counter('abcdeabcdabcaba')  # count elements from a string
///
/// >>> c.most_common(3)                # three most common elements
/// [('a', 5), ('b', 4), ('c', 3)]
/// >>> sorted(c)                       # list all unique elements
/// ['a', 'b', 'c', 'd', 'e']
/// >>> ''.join(sorted(c.elements()))   # list elements with repetitions
/// 'aaaaabbbbcccdde'
/// >>> sum(c.values())                 # total of all counts
/// 15
///
/// >>> c['a']                          # count of letter 'a'
/// 5
/// >>> for elem in 'shazam':           # update counts from an iterable
/// ...     c[elem] += 1                # by adding 1 to each element's count
/// >>> c['a']                          # now there are seven 'a'
/// 7
/// >>> del c['b']                      # remove all 'b'
/// >>> c['b']                          # now there are zero 'b'
/// 0
///
/// >>> d = Counter('simsalabim')       # make another counter
/// >>> c.update(d)                     # add in the second counter
/// >>> c['a']                          # now there are nine 'a'
/// 9
///
/// >>> c.clear()                       # empty the counter
/// >>> c
/// Counter()
///
/// Note:  If a count is set to zero or reduced to zero, it will remain
/// in the counter until the entry is deleted or the counter is cleared:
///
/// >>> c = Counter('aaabbc')
/// >>> c['b'] -= 2                     # reduce the count of 'b' by two
/// >>> c.most_common()                 # 'b' is still in, but its count is zero
/// [('a', 3), ('c', 1), ('b', 0)]
///
/// ### python source
/// ```py
/// class Counter(dict):
///     '''Dict subclass for counting hashable items.  Sometimes called a bag
///     or multiset.  Elements are stored as dictionary keys and their counts
///     are stored as dictionary values.
///
///     >>> c = Counter('abcdeabcdabcaba')  # count elements from a string
///
///     >>> c.most_common(3)                # three most common elements
///     [('a', 5), ('b', 4), ('c', 3)]
///     >>> sorted(c)                       # list all unique elements
///     ['a', 'b', 'c', 'd', 'e']
///     >>> ''.join(sorted(c.elements()))   # list elements with repetitions
///     'aaaaabbbbcccdde'
///     >>> sum(c.values())                 # total of all counts
///     15
///
///     >>> c['a']                          # count of letter 'a'
///     5
///     >>> for elem in 'shazam':           # update counts from an iterable
///     ...     c[elem] += 1                # by adding 1 to each element's count
///     >>> c['a']                          # now there are seven 'a'
///     7
///     >>> del c['b']                      # remove all 'b'
///     >>> c['b']                          # now there are zero 'b'
///     0
///
///     >>> d = Counter('simsalabim')       # make another counter
///     >>> c.update(d)                     # add in the second counter
///     >>> c['a']                          # now there are nine 'a'
///     9
///
///     >>> c.clear()                       # empty the counter
///     >>> c
///     Counter()
///
///     Note:  If a count is set to zero or reduced to zero, it will remain
///     in the counter until the entry is deleted or the counter is cleared:
///
///     >>> c = Counter('aaabbc')
///     >>> c['b'] -= 2                     # reduce the count of 'b' by two
///     >>> c.most_common()                 # 'b' is still in, but its count is zero
///     [('a', 3), ('c', 1), ('b', 0)]
///
///     '''
///     # References:
///     #   http://en.wikipedia.org/wiki/Multiset
///     #   http://www.gnu.org/software/smalltalk/manual-base/html_node/Bag.html
///     #   http://www.demo2s.com/Tutorial/Cpp/0380__set-multiset/Catalog0380__set-multiset.htm
///     #   http://code.activestate.com/recipes/259174/
///     #   Knuth, TAOCP Vol. II section 4.6.3
///
///     def __init__(self, iterable=None, /, **kwds):
///         '''Create a new, empty Counter object.  And if given, count elements
///         from an input iterable.  Or, initialize the count from another mapping
///         of elements to their counts.
///
///         >>> c = Counter()                           # a new, empty counter
///         >>> c = Counter('gallahad')                 # a new counter from an iterable
///         >>> c = Counter({'a': 4, 'b': 2})           # a new counter from a mapping
///         >>> c = Counter(a=4, b=2)                   # a new counter from keyword args
///
///         '''
///         super().__init__()
///         self.update(iterable, **kwds)
///
///     def __missing__(self, key):
///         'The count of elements not in the Counter is zero.'
///         # Needed so that self[missing_item] does not raise KeyError
///         return 0
///
///     def total(self):
///         'Sum of the counts'
///         return sum(self.values())
///
///     def most_common(self, n=None):
///         '''List the n most common elements and their counts from the most
///         common to the least.  If n is None, then list all element counts.
///
///         >>> Counter('abracadabra').most_common(3)
///         [('a', 5), ('b', 2), ('r', 2)]
///
///         '''
///         # Emulate Bag.sortedByCount from Smalltalk
///         if n is None:
///             return sorted(self.items(), key=_itemgetter(1), reverse=True)
///
///         # Lazy import to speedup Python startup time
///         import heapq
///         return heapq.nlargest(n, self.items(), key=_itemgetter(1))
///
///     def elements(self):
///         '''Iterator over elements repeating each as many times as its count.
///
///         >>> c = Counter('ABCABC')
///         >>> sorted(c.elements())
///         ['A', 'A', 'B', 'B', 'C', 'C']
///
///         # Knuth's example for prime factors of 1836:  2**2 * 3**3 * 17**1
///         >>> import math
///         >>> prime_factors = Counter({2: 2, 3: 3, 17: 1})
///         >>> math.prod(prime_factors.elements())
///         1836
///
///         Note, if an element's count has been set to zero or is a negative
///         number, elements() will ignore it.
///
///         '''
///         # Emulate Bag.do from Smalltalk and Multiset.begin from C++.
///         return _chain.from_iterable(_starmap(_repeat, self.items()))
///
///     # Override dict methods where necessary
///
///     @classmethod
///     def fromkeys(cls, iterable, v=None):
///         # There is no equivalent method for counters because the semantics
///         # would be ambiguous in cases such as Counter.fromkeys('aaabbc', v=2).
///         # Initializing counters to zero values isn't necessary because zero
///         # is already the default value for counter lookups.  Initializing
///         # to one is easily accomplished with Counter(set(iterable)).  For
///         # more exotic cases, create a dictionary first using a dictionary
///         # comprehension or dict.fromkeys().
///         raise NotImplementedError(
///             'Counter.fromkeys() is undefined.  Use Counter(iterable) instead.')
///
///     def update(self, iterable=None, /, **kwds):
///         '''Like dict.update() but add counts instead of replacing them.
///
///         Source can be an iterable, a dictionary, or another Counter instance.
///
///         >>> c = Counter('which')
///         >>> c.update('witch')           # add elements from another iterable
///         >>> d = Counter('watch')
///         >>> c.update(d)                 # add elements from another counter
///         >>> c['h']                      # four 'h' in which, witch, and watch
///         4
///
///         '''
///         # The regular dict.update() operation makes no sense here because the
///         # replace behavior results in the some of original untouched counts
///         # being mixed-in with all of the other counts for a mismash that
///         # doesn't have a straight-forward interpretation in most counting
///         # contexts.  Instead, we implement straight-addition.  Both the inputs
///         # and outputs are allowed to contain zero and negative counts.
///
///         if iterable is not None:
///             if isinstance(iterable, _collections_abc.Mapping):
///                 if self:
///                     self_get = self.get
///                     for elem, count in iterable.items():
///                         self[elem] = count + self_get(elem, 0)
///                 else:
///                     # fast path when counter is empty
///                     super().update(iterable)
///             else:
///                 _count_elements(self, iterable)
///         if kwds:
///             self.update(kwds)
///
///     def subtract(self, iterable=None, /, **kwds):
///         '''Like dict.update() but subtracts counts instead of replacing them.
///         Counts can be reduced below zero.  Both the inputs and outputs are
///         allowed to contain zero and negative counts.
///
///         Source can be an iterable, a dictionary, or another Counter instance.
///
///         >>> c = Counter('which')
///         >>> c.subtract('witch')             # subtract elements from another iterable
///         >>> c.subtract(Counter('watch'))    # subtract elements from another counter
///         >>> c['h']                          # 2 in which, minus 1 in witch, minus 1 in watch
///         0
///         >>> c['w']                          # 1 in which, minus 1 in witch, minus 1 in watch
///         -1
///
///         '''
///         if iterable is not None:
///             self_get = self.get
///             if isinstance(iterable, _collections_abc.Mapping):
///                 for elem, count in iterable.items():
///                     self[elem] = self_get(elem, 0) - count
///             else:
///                 for elem in iterable:
///                     self[elem] = self_get(elem, 0) - 1
///         if kwds:
///             self.subtract(kwds)
///
///     def copy(self):
///         'Return a shallow copy.'
///         return self.__class__(self)
///
///     def __reduce__(self):
///         return self.__class__, (dict(self),)
///
///     def __delitem__(self, elem):
///         'Like dict.__delitem__() but does not raise KeyError for missing values.'
///         if elem in self:
///             super().__delitem__(elem)
///
///     def __repr__(self):
///         if not self:
///             return f'{self.__class__.__name__}()'
///         try:
///             # dict() preserves the ordering returned by most_common()
///             d = dict(self.most_common())
///         except TypeError:
///             # handle case where values are not orderable
///             d = dict(self)
///         return f'{self.__class__.__name__}({d!r})'
///
///     # Multiset-style mathematical operations discussed in:
///     #       Knuth TAOCP Volume II section 4.6.3 exercise 19
///     #       and at http://en.wikipedia.org/wiki/Multiset
///     #
///     # Outputs guaranteed to only include positive counts.
///     #
///     # To strip negative and zero counts, add-in an empty counter:
///     #       c += Counter()
///     #
///     # Results are ordered according to when an element is first
///     # encountered in the left operand and then by the order
///     # encountered in the right operand.
///     #
///     # When the multiplicities are all zero or one, multiset operations
///     # are guaranteed to be equivalent to the corresponding operations
///     # for regular sets.
///     #     Given counter multisets such as:
///     #         cp = Counter(a=1, b=0, c=1)
///     #         cq = Counter(c=1, d=0, e=1)
///     #     The corresponding regular sets would be:
///     #         sp = {'a', 'c'}
///     #         sq = {'c', 'e'}
///     #     All of the following relations would hold:
///     #         set(cp + cq) == sp | sq
///     #         set(cp - cq) == sp - sq
///     #         set(cp | cq) == sp | sq
///     #         set(cp & cq) == sp & sq
///     #         (cp == cq) == (sp == sq)
///     #         (cp != cq) == (sp != sq)
///     #         (cp <= cq) == (sp <= sq)
///     #         (cp < cq) == (sp < sq)
///     #         (cp >= cq) == (sp >= sq)
///     #         (cp > cq) == (sp > sq)
///
///     def __eq__(self, other):
///         'True if all counts agree. Missing counts are treated as zero.'
///         if not isinstance(other, Counter):
///             return NotImplemented
///         return all(self[e] == other[e] for c in (self, other) for e in c)
///
///     def __ne__(self, other):
///         'True if any counts disagree. Missing counts are treated as zero.'
///         if not isinstance(other, Counter):
///             return NotImplemented
///         return not self == other
///
///     def __le__(self, other):
///         'True if all counts in self are a subset of those in other.'
///         if not isinstance(other, Counter):
///             return NotImplemented
///         return all(self[e] <= other[e] for c in (self, other) for e in c)
///
///     def __lt__(self, other):
///         'True if all counts in self are a proper subset of those in other.'
///         if not isinstance(other, Counter):
///             return NotImplemented
///         return self <= other and self != other
///
///     def __ge__(self, other):
///         'True if all counts in self are a superset of those in other.'
///         if not isinstance(other, Counter):
///             return NotImplemented
///         return all(self[e] >= other[e] for c in (self, other) for e in c)
///
///     def __gt__(self, other):
///         'True if all counts in self are a proper superset of those in other.'
///         if not isinstance(other, Counter):
///             return NotImplemented
///         return self >= other and self != other
///
///     def __add__(self, other):
///         '''Add counts from two counters.
///
///         >>> Counter('abbb') + Counter('bcc')
///         Counter({'b': 4, 'c': 2, 'a': 1})
///
///         '''
///         if not isinstance(other, Counter):
///             return NotImplemented
///         result = Counter()
///         for elem, count in self.items():
///             newcount = count + other[elem]
///             if newcount > 0:
///                 result[elem] = newcount
///         for elem, count in other.items():
///             if elem not in self and count > 0:
///                 result[elem] = count
///         return result
///
///     def __sub__(self, other):
///         ''' Subtract count, but keep only results with positive counts.
///
///         >>> Counter('abbbc') - Counter('bccd')
///         Counter({'b': 2, 'a': 1})
///
///         '''
///         if not isinstance(other, Counter):
///             return NotImplemented
///         result = Counter()
///         for elem, count in self.items():
///             newcount = count - other[elem]
///             if newcount > 0:
///                 result[elem] = newcount
///         for elem, count in other.items():
///             if elem not in self and count < 0:
///                 result[elem] = 0 - count
///         return result
///
///     def __or__(self, other):
///         '''Union is the maximum of value in either of the input counters.
///
///         >>> Counter('abbb') | Counter('bcc')
///         Counter({'b': 3, 'c': 2, 'a': 1})
///
///         '''
///         if not isinstance(other, Counter):
///             return NotImplemented
///         result = Counter()
///         for elem, count in self.items():
///             other_count = other[elem]
///             newcount = other_count if count < other_count else count
///             if newcount > 0:
///                 result[elem] = newcount
///         for elem, count in other.items():
///             if elem not in self and count > 0:
///                 result[elem] = count
///         return result
///
///     def __and__(self, other):
///         ''' Intersection is the minimum of corresponding counts.
///
///         >>> Counter('abbb') & Counter('bcc')
///         Counter({'b': 1})
///
///         '''
///         if not isinstance(other, Counter):
///             return NotImplemented
///         result = Counter()
///         for elem, count in self.items():
///             other_count = other[elem]
///             newcount = count if count < other_count else other_count
///             if newcount > 0:
///                 result[elem] = newcount
///         return result
///
///     def __pos__(self):
///         'Adds an empty counter, effectively stripping negative and zero counts'
///         result = Counter()
///         for elem, count in self.items():
///             if count > 0:
///                 result[elem] = count
///         return result
///
///     def __neg__(self):
///         '''Subtracts from an empty counter.  Strips positive and zero counts,
///         and flips the sign on negative counts.
///
///         '''
///         result = Counter()
///         for elem, count in self.items():
///             if count < 0:
///                 result[elem] = 0 - count
///         return result
///
///     def _keep_positive(self):
///         '''Internal method to strip elements with a negative or zero count'''
///         nonpositive = [elem for elem, count in self.items() if not count > 0]
///         for elem in nonpositive:
///             del self[elem]
///         return self
///
///     def __iadd__(self, other):
///         '''Inplace add from another counter, keeping only positive counts.
///
///         >>> c = Counter('abbb')
///         >>> c += Counter('bcc')
///         >>> c
///         Counter({'b': 4, 'c': 2, 'a': 1})
///
///         '''
///         for elem, count in other.items():
///             self[elem] += count
///         return self._keep_positive()
///
///     def __isub__(self, other):
///         '''Inplace subtract counter, but keep only results with positive counts.
///
///         >>> c = Counter('abbbc')
///         >>> c -= Counter('bccd')
///         >>> c
///         Counter({'b': 2, 'a': 1})
///
///         '''
///         for elem, count in other.items():
///             self[elem] -= count
///         return self._keep_positive()
///
///     def __ior__(self, other):
///         '''Inplace union is the maximum of value from either counter.
///
///         >>> c = Counter('abbb')
///         >>> c |= Counter('bcc')
///         >>> c
///         Counter({'b': 3, 'c': 2, 'a': 1})
///
///         '''
///         for elem, other_count in other.items():
///             count = self[elem]
///             if other_count > count:
///                 self[elem] = other_count
///         return self._keep_positive()
///
///     def __iand__(self, other):
///         '''Inplace intersection is the minimum of corresponding counts.
///
///         >>> c = Counter('abbb')
///         >>> c &= Counter('bcc')
///         >>> c
///         Counter({'b': 1})
///
///         '''
///         for elem, count in self.items():
///             other_count = other[elem]
///             if other_count < count:
///                 self[elem] = other_count
///         return self._keep_positive()
/// ```
final class Counter extends PythonClass {
  factory Counter(
    Object? iterable, {
    Map<String, Object?> kwds = const <String, Object?>{},
  }) =>
      PythonFfiDart.instance.importClass(
        "collections",
        "Counter",
        Counter.from,
        <Object?>[
          iterable,
        ],
        <String, Object?>{
          ...kwds,
        },
      );

  Counter.from(super.pythonClass) : super.from();

  /// ## copy
  ///
  /// ### python docstring
  ///
  /// Return a shallow copy.
  ///
  /// ### python source
  /// ```py
  /// def copy(self):
  ///         'Return a shallow copy.'
  ///         return self.__class__(self)
  /// ```
  Object? copy() => getFunction("copy").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## elements
  ///
  /// ### python docstring
  ///
  /// Iterator over elements repeating each as many times as its count.
  ///
  /// >>> c = Counter('ABCABC')
  /// >>> sorted(c.elements())
  /// ['A', 'A', 'B', 'B', 'C', 'C']
  ///
  /// # Knuth's example for prime factors of 1836:  2**2 * 3**3 * 17**1
  /// >>> import math
  /// >>> prime_factors = Counter({2: 2, 3: 3, 17: 1})
  /// >>> math.prod(prime_factors.elements())
  /// 1836
  ///
  /// Note, if an element's count has been set to zero or is a negative
  /// number, elements() will ignore it.
  ///
  /// ### python source
  /// ```py
  /// def elements(self):
  ///         '''Iterator over elements repeating each as many times as its count.
  ///
  ///         >>> c = Counter('ABCABC')
  ///         >>> sorted(c.elements())
  ///         ['A', 'A', 'B', 'B', 'C', 'C']
  ///
  ///         # Knuth's example for prime factors of 1836:  2**2 * 3**3 * 17**1
  ///         >>> import math
  ///         >>> prime_factors = Counter({2: 2, 3: 3, 17: 1})
  ///         >>> math.prod(prime_factors.elements())
  ///         1836
  ///
  ///         Note, if an element's count has been set to zero or is a negative
  ///         number, elements() will ignore it.
  ///
  ///         '''
  ///         # Emulate Bag.do from Smalltalk and Multiset.begin from C++.
  ///         return _chain.from_iterable(_starmap(_repeat, self.items()))
  /// ```
  Object? elements() => getFunction("elements").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## most_common
  ///
  /// ### python docstring
  ///
  /// List the n most common elements and their counts from the most
  /// common to the least.  If n is None, then list all element counts.
  ///
  /// >>> Counter('abracadabra').most_common(3)
  /// [('a', 5), ('b', 2), ('r', 2)]
  ///
  /// ### python source
  /// ```py
  /// def most_common(self, n=None):
  ///         '''List the n most common elements and their counts from the most
  ///         common to the least.  If n is None, then list all element counts.
  ///
  ///         >>> Counter('abracadabra').most_common(3)
  ///         [('a', 5), ('b', 2), ('r', 2)]
  ///
  ///         '''
  ///         # Emulate Bag.sortedByCount from Smalltalk
  ///         if n is None:
  ///             return sorted(self.items(), key=_itemgetter(1), reverse=True)
  ///
  ///         # Lazy import to speedup Python startup time
  ///         import heapq
  ///         return heapq.nlargest(n, self.items(), key=_itemgetter(1))
  /// ```
  Object? most_common({
    Object? n,
  }) =>
      getFunction("most_common").call(
        <Object?>[
          n,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## subtract
  ///
  /// ### python docstring
  ///
  /// Like dict.update() but subtracts counts instead of replacing them.
  /// Counts can be reduced below zero.  Both the inputs and outputs are
  /// allowed to contain zero and negative counts.
  ///
  /// Source can be an iterable, a dictionary, or another Counter instance.
  ///
  /// >>> c = Counter('which')
  /// >>> c.subtract('witch')             # subtract elements from another iterable
  /// >>> c.subtract(Counter('watch'))    # subtract elements from another counter
  /// >>> c['h']                          # 2 in which, minus 1 in witch, minus 1 in watch
  /// 0
  /// >>> c['w']                          # 1 in which, minus 1 in witch, minus 1 in watch
  /// -1
  ///
  /// ### python source
  /// ```py
  /// def subtract(self, iterable=None, /, **kwds):
  ///         '''Like dict.update() but subtracts counts instead of replacing them.
  ///         Counts can be reduced below zero.  Both the inputs and outputs are
  ///         allowed to contain zero and negative counts.
  ///
  ///         Source can be an iterable, a dictionary, or another Counter instance.
  ///
  ///         >>> c = Counter('which')
  ///         >>> c.subtract('witch')             # subtract elements from another iterable
  ///         >>> c.subtract(Counter('watch'))    # subtract elements from another counter
  ///         >>> c['h']                          # 2 in which, minus 1 in witch, minus 1 in watch
  ///         0
  ///         >>> c['w']                          # 1 in which, minus 1 in witch, minus 1 in watch
  ///         -1
  ///
  ///         '''
  ///         if iterable is not None:
  ///             self_get = self.get
  ///             if isinstance(iterable, _collections_abc.Mapping):
  ///                 for elem, count in iterable.items():
  ///                     self[elem] = self_get(elem, 0) - count
  ///             else:
  ///                 for elem in iterable:
  ///                     self[elem] = self_get(elem, 0) - 1
  ///         if kwds:
  ///             self.subtract(kwds)
  /// ```
  Object? subtract(
    Object? iterable, {
    Map<String, Object?> kwds = const <String, Object?>{},
  }) =>
      getFunction("subtract").call(
        <Object?>[
          iterable,
        ],
        kwargs: <String, Object?>{
          ...kwds,
        },
      );

  /// ## total
  ///
  /// ### python docstring
  ///
  /// Sum of the counts
  ///
  /// ### python source
  /// ```py
  /// def total(self):
  ///         'Sum of the counts'
  ///         return sum(self.values())
  /// ```
  Object? total() => getFunction("total").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## update
  ///
  /// ### python docstring
  ///
  /// Like dict.update() but add counts instead of replacing them.
  ///
  /// Source can be an iterable, a dictionary, or another Counter instance.
  ///
  /// >>> c = Counter('which')
  /// >>> c.update('witch')           # add elements from another iterable
  /// >>> d = Counter('watch')
  /// >>> c.update(d)                 # add elements from another counter
  /// >>> c['h']                      # four 'h' in which, witch, and watch
  /// 4
  ///
  /// ### python source
  /// ```py
  /// def update(self, iterable=None, /, **kwds):
  ///         '''Like dict.update() but add counts instead of replacing them.
  ///
  ///         Source can be an iterable, a dictionary, or another Counter instance.
  ///
  ///         >>> c = Counter('which')
  ///         >>> c.update('witch')           # add elements from another iterable
  ///         >>> d = Counter('watch')
  ///         >>> c.update(d)                 # add elements from another counter
  ///         >>> c['h']                      # four 'h' in which, witch, and watch
  ///         4
  ///
  ///         '''
  ///         # The regular dict.update() operation makes no sense here because the
  ///         # replace behavior results in the some of original untouched counts
  ///         # being mixed-in with all of the other counts for a mismash that
  ///         # doesn't have a straight-forward interpretation in most counting
  ///         # contexts.  Instead, we implement straight-addition.  Both the inputs
  ///         # and outputs are allowed to contain zero and negative counts.
  ///
  ///         if iterable is not None:
  ///             if isinstance(iterable, _collections_abc.Mapping):
  ///                 if self:
  ///                     self_get = self.get
  ///                     for elem, count in iterable.items():
  ///                         self[elem] = count + self_get(elem, 0)
  ///                 else:
  ///                     # fast path when counter is empty
  ///                     super().update(iterable)
  ///             else:
  ///                 _count_elements(self, iterable)
  ///         if kwds:
  ///             self.update(kwds)
  /// ```
  Object? update(
    Object? iterable, {
    Map<String, Object?> kwds = const <String, Object?>{},
  }) =>
      getFunction("update").call(
        <Object?>[
          iterable,
        ],
        kwargs: <String, Object?>{
          ...kwds,
        },
      );

  /// ## clear (getter)
  Object? get clear => getAttribute("clear");

  /// ## clear (setter)
  set clear(Object? clear) => setAttribute("clear", clear);

  /// ## fromkeys (getter)
  Object? get fromkeys => getAttribute("fromkeys");

  /// ## fromkeys (setter)
  set fromkeys(Object? fromkeys) => setAttribute("fromkeys", fromkeys);

  /// ## get (getter)
  Object? get $get => getAttribute("get");

  /// ## get (setter)
  set $get(Object? $get) => setAttribute("get", $get);

  /// ## items (getter)
  Object? get items => getAttribute("items");

  /// ## items (setter)
  set items(Object? items) => setAttribute("items", items);

  /// ## keys (getter)
  Object? get keys => getAttribute("keys");

  /// ## keys (setter)
  set keys(Object? keys) => setAttribute("keys", keys);

  /// ## pop (getter)
  Object? get pop => getAttribute("pop");

  /// ## pop (setter)
  set pop(Object? pop) => setAttribute("pop", pop);

  /// ## popitem (getter)
  Object? get popitem => getAttribute("popitem");

  /// ## popitem (setter)
  set popitem(Object? popitem) => setAttribute("popitem", popitem);

  /// ## setdefault (getter)
  Object? get setdefault => getAttribute("setdefault");

  /// ## setdefault (setter)
  set setdefault(Object? setdefault) => setAttribute("setdefault", setdefault);

  /// ## values (getter)
  Object? get values => getAttribute("values");

  /// ## values (setter)
  set values(Object? values) => setAttribute("values", values);
}

/// ## LR0ItemSet
///
/// ### python source
/// ```py
/// class LR0ItemSet:
///     __slots__ = ('kernel', 'closure', 'transitions', 'lookaheads')
///
///     def __init__(self, kernel, closure):
///         self.kernel = fzset(kernel)
///         self.closure = fzset(closure)
///         self.transitions = {}
///         self.lookaheads = defaultdict(set)
///
///     def __repr__(self):
///         return '{%s | %s}' % (', '.join([repr(r) for r in self.kernel]), ', '.join([repr(r) for r in self.closure]))
/// ```
final class LR0ItemSet extends PythonClass {
  factory LR0ItemSet({
    required Object? kernel,
    required Object? closure,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parsers.grammar_analysis",
        "LR0ItemSet",
        LR0ItemSet.from,
        <Object?>[
          kernel,
          closure,
        ],
        <String, Object?>{},
      );

  LR0ItemSet.from(super.pythonClass) : super.from();

  /// ## closure (getter)
  Object? get closure => getAttribute("closure");

  /// ## closure (setter)
  set closure(Object? closure) => setAttribute("closure", closure);

  /// ## kernel (getter)
  Object? get kernel => getAttribute("kernel");

  /// ## kernel (setter)
  set kernel(Object? kernel) => setAttribute("kernel", kernel);

  /// ## lookaheads (getter)
  Object? get lookaheads => getAttribute("lookaheads");

  /// ## lookaheads (setter)
  set lookaheads(Object? lookaheads) => setAttribute("lookaheads", lookaheads);

  /// ## transitions (getter)
  Object? get transitions => getAttribute("transitions");

  /// ## transitions (setter)
  set transitions(Object? transitions) =>
      setAttribute("transitions", transitions);
}

/// ## RulePtr
///
/// ### python source
/// ```py
/// class RulePtr:
///     __slots__ = ('rule', 'index')
///
///     def __init__(self, rule, index):
///         assert isinstance(rule, Rule)
///         assert index <= len(rule.expansion)
///         self.rule = rule
///         self.index = index
///
///     def __repr__(self):
///         before = [x.name for x in self.rule.expansion[:self.index]]
///         after = [x.name for x in self.rule.expansion[self.index:]]
///         return '<%s : %s * %s>' % (self.rule.origin.name, ' '.join(before), ' '.join(after))
///
///     @property
///     def next(self):
///         return self.rule.expansion[self.index]
///
///     def advance(self, sym):
///         assert self.next == sym
///         return RulePtr(self.rule, self.index+1)
///
///     @property
///     def is_satisfied(self):
///         return self.index == len(self.rule.expansion)
///
///     def __eq__(self, other):
///         return self.rule == other.rule and self.index == other.index
///     def __hash__(self):
///         return hash((self.rule, self.index))
/// ```
final class RulePtr extends PythonClass {
  factory RulePtr({
    required Object? rule,
    required Object? index,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parsers.grammar_analysis",
        "RulePtr",
        RulePtr.from,
        <Object?>[
          rule,
          index,
        ],
        <String, Object?>{},
      );

  RulePtr.from(super.pythonClass) : super.from();

  /// ## advance
  ///
  /// ### python source
  /// ```py
  /// def advance(self, sym):
  ///         assert self.next == sym
  ///         return RulePtr(self.rule, self.index+1)
  /// ```
  Object? advance({
    required Object? sym,
  }) =>
      getFunction("advance").call(
        <Object?>[
          sym,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## is_satisfied (getter)
  Object? get is_satisfied => getAttribute("is_satisfied");

  /// ## is_satisfied (setter)
  set is_satisfied(Object? is_satisfied) =>
      setAttribute("is_satisfied", is_satisfied);

  /// ## next (getter)
  Object? get next => getAttribute("next");

  /// ## next (setter)
  set next(Object? next) => setAttribute("next", next);

  /// ## index (getter)
  Object? get index => getAttribute("index");

  /// ## index (setter)
  set index(Object? index) => setAttribute("index", index);

  /// ## rule (getter)
  Object? get rule => getAttribute("rule");

  /// ## rule (setter)
  set rule(Object? rule) => setAttribute("rule", rule);
}

/// ## fzset
///
/// ### python source
/// ```py
/// class fzset(frozenset):
///     def __repr__(self):
///         return '{%s}' % ', '.join(map(repr, self))
/// ```
final class fzset extends PythonClass {
  factory fzset() => PythonFfiDart.instance.importClass(
        "lark.utils",
        "fzset",
        fzset.from,
        <Object?>[],
      );

  fzset.from(super.pythonClass) : super.from();

  /// ## copy (getter)
  Object? get copy => getAttribute("copy");

  /// ## copy (setter)
  set copy(Object? copy) => setAttribute("copy", copy);

  /// ## difference (getter)
  Object? get difference => getAttribute("difference");

  /// ## difference (setter)
  set difference(Object? difference) => setAttribute("difference", difference);

  /// ## intersection (getter)
  Object? get intersection => getAttribute("intersection");

  /// ## intersection (setter)
  set intersection(Object? intersection) =>
      setAttribute("intersection", intersection);

  /// ## isdisjoint (getter)
  Object? get isdisjoint => getAttribute("isdisjoint");

  /// ## isdisjoint (setter)
  set isdisjoint(Object? isdisjoint) => setAttribute("isdisjoint", isdisjoint);

  /// ## issubset (getter)
  Object? get issubset => getAttribute("issubset");

  /// ## issubset (setter)
  set issubset(Object? issubset) => setAttribute("issubset", issubset);

  /// ## issuperset (getter)
  Object? get issuperset => getAttribute("issuperset");

  /// ## issuperset (setter)
  set issuperset(Object? issuperset) => setAttribute("issuperset", issuperset);

  /// ## symmetric_difference (getter)
  Object? get symmetric_difference => getAttribute("symmetric_difference");

  /// ## symmetric_difference (setter)
  set symmetric_difference(Object? symmetric_difference) =>
      setAttribute("symmetric_difference", symmetric_difference);

  /// ## union (getter)
  Object? get union => getAttribute("union");

  /// ## union (setter)
  set union(Object? union) => setAttribute("union", union);
}

/// ## Action
///
/// ### python source
/// ```py
/// class Action:
///     def __init__(self, name):
///         self.name = name
///     def __str__(self):
///         return self.name
///     def __repr__(self):
///         return str(self)
/// ```
final class Action extends PythonClass {
  factory Action({
    required Object? name,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parsers.lalr_analysis",
        "Action",
        Action.from,
        <Object?>[
          name,
        ],
        <String, Object?>{},
      );

  Action.from(super.pythonClass) : super.from();

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);
}

/// ## Enumerator
///
/// ### python docstring
///
/// Safe-ish serialization interface that doesn't rely on Pickle
///
/// Attributes:
///     __serialize_fields__ (List[str]): Fields (aka attributes) to serialize.
///     __serialize_namespace__ (list): List of classes that deserialization is allowed to instantiate.
///                                     Should include all field types that aren't builtin types.
///
/// ### python source
/// ```py
/// class Enumerator(Serialize):
///     def __init__(self) -> None:
///         self.enums: Dict[Any, int] = {}
///
///     def get(self, item) -> int:
///         if item not in self.enums:
///             self.enums[item] = len(self.enums)
///         return self.enums[item]
///
///     def __len__(self):
///         return len(self.enums)
///
///     def reversed(self) -> Dict[int, Any]:
///         r = {v: k for k, v in self.enums.items()}
///         assert len(r) == len(self.enums)
///         return r
/// ```
final class Enumerator extends PythonClass {
  factory Enumerator() => PythonFfiDart.instance.importClass(
        "lark.utils",
        "Enumerator",
        Enumerator.from,
        <Object?>[],
        <String, Object?>{},
      );

  Enumerator.from(super.pythonClass) : super.from();

  /// ## get
  ///
  /// ### python source
  /// ```py
  /// def get(self, item) -> int:
  ///         if item not in self.enums:
  ///             self.enums[item] = len(self.enums)
  ///         return self.enums[item]
  /// ```
  Object? $get({
    required Object? item,
  }) =>
      getFunction("get").call(
        <Object?>[
          item,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## memo_serialize
  ///
  /// ### python source
  /// ```py
  /// def memo_serialize(self, types_to_memoize: List) -> Any:
  ///         memo = SerializeMemoizer(types_to_memoize)
  ///         return self.serialize(memo), memo.serialize()
  /// ```
  Object? memo_serialize({
    required Object? types_to_memoize,
  }) =>
      getFunction("memo_serialize").call(
        <Object?>[
          types_to_memoize,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## reversed
  ///
  /// ### python source
  /// ```py
  /// def reversed(self) -> Dict[int, Any]:
  ///         r = {v: k for k, v in self.enums.items()}
  ///         assert len(r) == len(self.enums)
  ///         return r
  /// ```
  Object? reversed() => getFunction("reversed").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## serialize
  ///
  /// ### python source
  /// ```py
  /// def serialize(self, memo = None) -> Dict[str, Any]:
  ///         if memo and memo.in_types(self):
  ///             return {'@': memo.memoized.get(self)}
  ///
  ///         fields = getattr(self, '__serialize_fields__')
  ///         res = {f: _serialize(getattr(self, f), memo) for f in fields}
  ///         res['__type__'] = type(self).__name__
  ///         if hasattr(self, '_serialize'):
  ///             self._serialize(res, memo)  # type: ignore[attr-defined]
  ///         return res
  /// ```
  Object? serialize({
    Object? memo,
  }) =>
      getFunction("serialize").call(
        <Object?>[
          memo,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## deserialize (getter)
  Object? get deserialize => getAttribute("deserialize");

  /// ## deserialize (setter)
  set deserialize(Object? deserialize) =>
      setAttribute("deserialize", deserialize);
}

/// ## IntParseTable
///
/// ### python source
/// ```py
/// class IntParseTable(ParseTable):
///
///     @classmethod
///     def from_ParseTable(cls, parse_table):
///         enum = list(parse_table.states)
///         state_to_idx = {s:i for i,s in enumerate(enum)}
///         int_states = {}
///
///         for s, la in parse_table.states.items():
///             la = {k:(v[0], state_to_idx[v[1]]) if v[0] is Shift else v
///                   for k,v in la.items()}
///             int_states[ state_to_idx[s] ] = la
///
///
///         start_states = {start:state_to_idx[s] for start, s in parse_table.start_states.items()}
///         end_states = {start:state_to_idx[s] for start, s in parse_table.end_states.items()}
///         return cls(int_states, start_states, end_states)
/// ```
final class IntParseTable extends PythonClass {
  factory IntParseTable({
    required Object? states,
    required Object? start_states,
    required Object? end_states,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parsers.lalr_analysis",
        "IntParseTable",
        IntParseTable.from,
        <Object?>[
          states,
          start_states,
          end_states,
        ],
        <String, Object?>{},
      );

  IntParseTable.from(super.pythonClass) : super.from();

  /// ## serialize
  ///
  /// ### python source
  /// ```py
  /// def serialize(self, memo):
  ///         tokens = Enumerator()
  ///
  ///         states = {
  ///             state: {tokens.get(token): ((1, arg.serialize(memo)) if action is Reduce else (0, arg))
  ///                     for token, (action, arg) in actions.items()}
  ///             for state, actions in self.states.items()
  ///         }
  ///
  ///         return {
  ///             'tokens': tokens.reversed(),
  ///             'states': states,
  ///             'start_states': self.start_states,
  ///             'end_states': self.end_states,
  ///         }
  /// ```
  Object? serialize({
    required Object? memo,
  }) =>
      getFunction("serialize").call(
        <Object?>[
          memo,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## deserialize (getter)
  Object? get deserialize => getAttribute("deserialize");

  /// ## deserialize (setter)
  set deserialize(Object? deserialize) =>
      setAttribute("deserialize", deserialize);

  /// ## from_ParseTable (getter)
  Object? get from_ParseTable => getAttribute("from_ParseTable");

  /// ## from_ParseTable (setter)
  set from_ParseTable(Object? from_ParseTable) =>
      setAttribute("from_ParseTable", from_ParseTable);

  /// ## states (getter)
  Object? get states => getAttribute("states");

  /// ## states (setter)
  set states(Object? states) => setAttribute("states", states);

  /// ## start_states (getter)
  Object? get start_states => getAttribute("start_states");

  /// ## start_states (setter)
  set start_states(Object? start_states) =>
      setAttribute("start_states", start_states);

  /// ## end_states (getter)
  Object? get end_states => getAttribute("end_states");

  /// ## end_states (setter)
  set end_states(Object? end_states) => setAttribute("end_states", end_states);
}

/// ## LALR_Analyzer
///
/// ### python source
/// ```py
/// class LALR_Analyzer(GrammarAnalyzer):
///     def __init__(self, parser_conf, debug=False):
///         GrammarAnalyzer.__init__(self, parser_conf, debug)
///         self.nonterminal_transitions = []
///         self.directly_reads = defaultdict(set)
///         self.reads = defaultdict(set)
///         self.includes = defaultdict(set)
///         self.lookback = defaultdict(set)
///
///
///     def compute_lr0_states(self):
///         self.lr0_states = set()
///         # map of kernels to LR0ItemSets
///         cache = {}
///
///         def step(state):
///             _, unsat = classify_bool(state.closure, lambda rp: rp.is_satisfied)
///
///             d = classify(unsat, lambda rp: rp.next)
///             for sym, rps in d.items():
///                 kernel = fzset({rp.advance(sym) for rp in rps})
///                 new_state = cache.get(kernel, None)
///                 if new_state is None:
///                     closure = set(kernel)
///                     for rp in kernel:
///                         if not rp.is_satisfied and not rp.next.is_term:
///                             closure |= self.expand_rule(rp.next, self.lr0_rules_by_origin)
///                     new_state = LR0ItemSet(kernel, closure)
///                     cache[kernel] = new_state
///
///                 state.transitions[sym] = new_state
///                 yield new_state
///
///             self.lr0_states.add(state)
///
///         for _ in bfs(self.lr0_start_states.values(), step):
///             pass
///
///     def compute_reads_relations(self):
///         # handle start state
///         for root in self.lr0_start_states.values():
///             assert(len(root.kernel) == 1)
///             for rp in root.kernel:
///                 assert(rp.index == 0)
///                 self.directly_reads[(root, rp.next)] = set([ Terminal('$END') ])
///
///         for state in self.lr0_states:
///             seen = set()
///             for rp in state.closure:
///                 if rp.is_satisfied:
///                     continue
///                 s = rp.next
///                 # if s is a not a nonterminal
///                 if s not in self.lr0_rules_by_origin:
///                     continue
///                 if s in seen:
///                     continue
///                 seen.add(s)
///                 nt = (state, s)
///                 self.nonterminal_transitions.append(nt)
///                 dr = self.directly_reads[nt]
///                 r = self.reads[nt]
///                 next_state = state.transitions[s]
///                 for rp2 in next_state.closure:
///                     if rp2.is_satisfied:
///                         continue
///                     s2 = rp2.next
///                     # if s2 is a terminal
///                     if s2 not in self.lr0_rules_by_origin:
///                         dr.add(s2)
///                     if s2 in self.NULLABLE:
///                         r.add((next_state, s2))
///
///     def compute_includes_lookback(self):
///         for nt in self.nonterminal_transitions:
///             state, nonterminal = nt
///             includes = []
///             lookback = self.lookback[nt]
///             for rp in state.closure:
///                 if rp.rule.origin != nonterminal:
///                     continue
///                 # traverse the states for rp(.rule)
///                 state2 = state
///                 for i in range(rp.index, len(rp.rule.expansion)):
///                     s = rp.rule.expansion[i]
///                     nt2 = (state2, s)
///                     state2 = state2.transitions[s]
///                     if nt2 not in self.reads:
///                         continue
///                     for j in range(i + 1, len(rp.rule.expansion)):
///                         if not rp.rule.expansion[j] in self.NULLABLE:
///                             break
///                     else:
///                         includes.append(nt2)
///                 # state2 is at the final state for rp.rule
///                 if rp.index == 0:
///                     for rp2 in state2.closure:
///                         if (rp2.rule == rp.rule) and rp2.is_satisfied:
///                             lookback.add((state2, rp2.rule))
///             for nt2 in includes:
///                 self.includes[nt2].add(nt)
///
///     def compute_lookaheads(self):
///         read_sets = digraph(self.nonterminal_transitions, self.reads, self.directly_reads)
///         follow_sets = digraph(self.nonterminal_transitions, self.includes, read_sets)
///
///         for nt, lookbacks in self.lookback.items():
///             for state, rule in lookbacks:
///                 for s in follow_sets[nt]:
///                     state.lookaheads[s].add(rule)
///
///     def compute_lalr1_states(self):
///         m = {}
///         reduce_reduce = []
///         for state in self.lr0_states:
///             actions = {}
///             for la, next_state in state.transitions.items():
///                 actions[la] = (Shift, next_state.closure)
///             for la, rules in state.lookaheads.items():
///                 if len(rules) > 1:
///                     # Try to resolve conflict based on priority
///                     p = [(r.options.priority or 0, r) for r in rules]
///                     p.sort(key=lambda r: r[0], reverse=True)
///                     best, second_best = p[:2]
///                     if best[0] > second_best[0]:
///                         rules = [best[1]]
///                     else:
///                         reduce_reduce.append((state, la, rules))
///                 if la in actions:
///                     if self.debug:
///                         logger.warning('Shift/Reduce conflict for terminal %s: (resolving as shift)', la.name)
///                         logger.warning(' * %s', list(rules)[0])
///                 else:
///                     actions[la] = (Reduce, list(rules)[0])
///             m[state] = { k.name: v for k, v in actions.items() }
///
///         if reduce_reduce:
///             msgs = []
///             for state, la, rules in reduce_reduce:
///                 msg = 'Reduce/Reduce collision in %s between the following rules: %s' % (la, ''.join([ '\n\t- ' + str(r) for r in rules ]))
///                 if self.debug:
///                     msg += '\n    collision occurred in state: {%s\n    }' % ''.join(['\n\t' + str(x) for x in state.closure])
///                 msgs.append(msg)
///             raise GrammarError('\n\n'.join(msgs))
///
///         states = { k.closure: v for k, v in m.items() }
///
///         # compute end states
///         end_states = {}
///         for state in states:
///             for rp in state:
///                 for start in self.lr0_start_states:
///                     if rp.rule.origin.name == ('$root_' + start) and rp.is_satisfied:
///                         assert(start not in end_states)
///                         end_states[start] = state
///
///         _parse_table = ParseTable(states, { start: state.closure for start, state in self.lr0_start_states.items() }, end_states)
///
///         if self.debug:
///             self.parse_table = _parse_table
///         else:
///             self.parse_table = IntParseTable.from_ParseTable(_parse_table)
///
///     def compute_lalr(self):
///         self.compute_lr0_states()
///         self.compute_reads_relations()
///         self.compute_includes_lookback()
///         self.compute_lookaheads()
///         self.compute_lalr1_states()
/// ```
final class LALR_Analyzer extends PythonClass {
  factory LALR_Analyzer({
    required Object? parser_conf,
    Object? debug = false,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parsers.lalr_analysis",
        "LALR_Analyzer",
        LALR_Analyzer.from,
        <Object?>[
          parser_conf,
          debug,
        ],
        <String, Object?>{},
      );

  LALR_Analyzer.from(super.pythonClass) : super.from();

  /// ## compute_includes_lookback
  ///
  /// ### python source
  /// ```py
  /// def compute_includes_lookback(self):
  ///         for nt in self.nonterminal_transitions:
  ///             state, nonterminal = nt
  ///             includes = []
  ///             lookback = self.lookback[nt]
  ///             for rp in state.closure:
  ///                 if rp.rule.origin != nonterminal:
  ///                     continue
  ///                 # traverse the states for rp(.rule)
  ///                 state2 = state
  ///                 for i in range(rp.index, len(rp.rule.expansion)):
  ///                     s = rp.rule.expansion[i]
  ///                     nt2 = (state2, s)
  ///                     state2 = state2.transitions[s]
  ///                     if nt2 not in self.reads:
  ///                         continue
  ///                     for j in range(i + 1, len(rp.rule.expansion)):
  ///                         if not rp.rule.expansion[j] in self.NULLABLE:
  ///                             break
  ///                     else:
  ///                         includes.append(nt2)
  ///                 # state2 is at the final state for rp.rule
  ///                 if rp.index == 0:
  ///                     for rp2 in state2.closure:
  ///                         if (rp2.rule == rp.rule) and rp2.is_satisfied:
  ///                             lookback.add((state2, rp2.rule))
  ///             for nt2 in includes:
  ///                 self.includes[nt2].add(nt)
  /// ```
  Object? compute_includes_lookback() =>
      getFunction("compute_includes_lookback").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## compute_lalr
  ///
  /// ### python source
  /// ```py
  /// def compute_lalr(self):
  ///         self.compute_lr0_states()
  ///         self.compute_reads_relations()
  ///         self.compute_includes_lookback()
  ///         self.compute_lookaheads()
  ///         self.compute_lalr1_states()
  /// ```
  Object? compute_lalr() => getFunction("compute_lalr").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## compute_lalr1_states
  ///
  /// ### python source
  /// ```py
  /// def compute_lalr1_states(self):
  ///         m = {}
  ///         reduce_reduce = []
  ///         for state in self.lr0_states:
  ///             actions = {}
  ///             for la, next_state in state.transitions.items():
  ///                 actions[la] = (Shift, next_state.closure)
  ///             for la, rules in state.lookaheads.items():
  ///                 if len(rules) > 1:
  ///                     # Try to resolve conflict based on priority
  ///                     p = [(r.options.priority or 0, r) for r in rules]
  ///                     p.sort(key=lambda r: r[0], reverse=True)
  ///                     best, second_best = p[:2]
  ///                     if best[0] > second_best[0]:
  ///                         rules = [best[1]]
  ///                     else:
  ///                         reduce_reduce.append((state, la, rules))
  ///                 if la in actions:
  ///                     if self.debug:
  ///                         logger.warning('Shift/Reduce conflict for terminal %s: (resolving as shift)', la.name)
  ///                         logger.warning(' * %s', list(rules)[0])
  ///                 else:
  ///                     actions[la] = (Reduce, list(rules)[0])
  ///             m[state] = { k.name: v for k, v in actions.items() }
  ///
  ///         if reduce_reduce:
  ///             msgs = []
  ///             for state, la, rules in reduce_reduce:
  ///                 msg = 'Reduce/Reduce collision in %s between the following rules: %s' % (la, ''.join([ '\n\t- ' + str(r) for r in rules ]))
  ///                 if self.debug:
  ///                     msg += '\n    collision occurred in state: {%s\n    }' % ''.join(['\n\t' + str(x) for x in state.closure])
  ///                 msgs.append(msg)
  ///             raise GrammarError('\n\n'.join(msgs))
  ///
  ///         states = { k.closure: v for k, v in m.items() }
  ///
  ///         # compute end states
  ///         end_states = {}
  ///         for state in states:
  ///             for rp in state:
  ///                 for start in self.lr0_start_states:
  ///                     if rp.rule.origin.name == ('$root_' + start) and rp.is_satisfied:
  ///                         assert(start not in end_states)
  ///                         end_states[start] = state
  ///
  ///         _parse_table = ParseTable(states, { start: state.closure for start, state in self.lr0_start_states.items() }, end_states)
  ///
  ///         if self.debug:
  ///             self.parse_table = _parse_table
  ///         else:
  ///             self.parse_table = IntParseTable.from_ParseTable(_parse_table)
  /// ```
  Object? compute_lalr1_states() => getFunction("compute_lalr1_states").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## compute_lookaheads
  ///
  /// ### python source
  /// ```py
  /// def compute_lookaheads(self):
  ///         read_sets = digraph(self.nonterminal_transitions, self.reads, self.directly_reads)
  ///         follow_sets = digraph(self.nonterminal_transitions, self.includes, read_sets)
  ///
  ///         for nt, lookbacks in self.lookback.items():
  ///             for state, rule in lookbacks:
  ///                 for s in follow_sets[nt]:
  ///                     state.lookaheads[s].add(rule)
  /// ```
  Object? compute_lookaheads() => getFunction("compute_lookaheads").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## compute_lr0_states
  ///
  /// ### python source
  /// ```py
  /// def compute_lr0_states(self):
  ///         self.lr0_states = set()
  ///         # map of kernels to LR0ItemSets
  ///         cache = {}
  ///
  ///         def step(state):
  ///             _, unsat = classify_bool(state.closure, lambda rp: rp.is_satisfied)
  ///
  ///             d = classify(unsat, lambda rp: rp.next)
  ///             for sym, rps in d.items():
  ///                 kernel = fzset({rp.advance(sym) for rp in rps})
  ///                 new_state = cache.get(kernel, None)
  ///                 if new_state is None:
  ///                     closure = set(kernel)
  ///                     for rp in kernel:
  ///                         if not rp.is_satisfied and not rp.next.is_term:
  ///                             closure |= self.expand_rule(rp.next, self.lr0_rules_by_origin)
  ///                     new_state = LR0ItemSet(kernel, closure)
  ///                     cache[kernel] = new_state
  ///
  ///                 state.transitions[sym] = new_state
  ///                 yield new_state
  ///
  ///             self.lr0_states.add(state)
  ///
  ///         for _ in bfs(self.lr0_start_states.values(), step):
  ///             pass
  /// ```
  Object? compute_lr0_states() => getFunction("compute_lr0_states").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## compute_reads_relations
  ///
  /// ### python source
  /// ```py
  /// def compute_reads_relations(self):
  ///         # handle start state
  ///         for root in self.lr0_start_states.values():
  ///             assert(len(root.kernel) == 1)
  ///             for rp in root.kernel:
  ///                 assert(rp.index == 0)
  ///                 self.directly_reads[(root, rp.next)] = set([ Terminal('$END') ])
  ///
  ///         for state in self.lr0_states:
  ///             seen = set()
  ///             for rp in state.closure:
  ///                 if rp.is_satisfied:
  ///                     continue
  ///                 s = rp.next
  ///                 # if s is a not a nonterminal
  ///                 if s not in self.lr0_rules_by_origin:
  ///                     continue
  ///                 if s in seen:
  ///                     continue
  ///                 seen.add(s)
  ///                 nt = (state, s)
  ///                 self.nonterminal_transitions.append(nt)
  ///                 dr = self.directly_reads[nt]
  ///                 r = self.reads[nt]
  ///                 next_state = state.transitions[s]
  ///                 for rp2 in next_state.closure:
  ///                     if rp2.is_satisfied:
  ///                         continue
  ///                     s2 = rp2.next
  ///                     # if s2 is a terminal
  ///                     if s2 not in self.lr0_rules_by_origin:
  ///                         dr.add(s2)
  ///                     if s2 in self.NULLABLE:
  ///                         r.add((next_state, s2))
  /// ```
  Object? compute_reads_relations() =>
      getFunction("compute_reads_relations").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## expand_rule
  ///
  /// ### python docstring
  ///
  /// Returns all init_ptrs accessible by rule (recursive)
  ///
  /// ### python source
  /// ```py
  /// def expand_rule(self, source_rule, rules_by_origin=None):
  ///         "Returns all init_ptrs accessible by rule (recursive)"
  ///
  ///         if rules_by_origin is None:
  ///             rules_by_origin = self.rules_by_origin
  ///
  ///         init_ptrs = set()
  ///         def _expand_rule(rule):
  ///             assert not rule.is_term, rule
  ///
  ///             for r in rules_by_origin[rule]:
  ///                 init_ptr = RulePtr(r, 0)
  ///                 init_ptrs.add(init_ptr)
  ///
  ///                 if r.expansion: # if not empty rule
  ///                     new_r = init_ptr.next
  ///                     if not new_r.is_term:
  ///                         yield new_r
  ///
  ///         for _ in bfs([source_rule], _expand_rule):
  ///             pass
  ///
  ///         return fzset(init_ptrs)
  /// ```
  Object? expand_rule({
    required Object? source_rule,
    Object? rules_by_origin,
  }) =>
      getFunction("expand_rule").call(
        <Object?>[
          source_rule,
          rules_by_origin,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## nonterminal_transitions (getter)
  Object? get nonterminal_transitions =>
      getAttribute("nonterminal_transitions");

  /// ## nonterminal_transitions (setter)
  set nonterminal_transitions(Object? nonterminal_transitions) =>
      setAttribute("nonterminal_transitions", nonterminal_transitions);

  /// ## directly_reads (getter)
  Object? get directly_reads => getAttribute("directly_reads");

  /// ## directly_reads (setter)
  set directly_reads(Object? directly_reads) =>
      setAttribute("directly_reads", directly_reads);

  /// ## reads (getter)
  Object? get reads => getAttribute("reads");

  /// ## reads (setter)
  set reads(Object? reads) => setAttribute("reads", reads);

  /// ## includes (getter)
  Object? get includes => getAttribute("includes");

  /// ## includes (setter)
  set includes(Object? includes) => setAttribute("includes", includes);

  /// ## lookback (getter)
  Object? get lookback => getAttribute("lookback");

  /// ## lookback (setter)
  set lookback(Object? lookback) => setAttribute("lookback", lookback);
}

/// ## ParseTable
///
/// ### python source
/// ```py
/// class ParseTable:
///     def __init__(self, states, start_states, end_states):
///         self.states = states
///         self.start_states = start_states
///         self.end_states = end_states
///
///     def serialize(self, memo):
///         tokens = Enumerator()
///
///         states = {
///             state: {tokens.get(token): ((1, arg.serialize(memo)) if action is Reduce else (0, arg))
///                     for token, (action, arg) in actions.items()}
///             for state, actions in self.states.items()
///         }
///
///         return {
///             'tokens': tokens.reversed(),
///             'states': states,
///             'start_states': self.start_states,
///             'end_states': self.end_states,
///         }
///
///     @classmethod
///     def deserialize(cls, data, memo):
///         tokens = data['tokens']
///         states = {
///             state: {tokens[token]: ((Reduce, Rule.deserialize(arg, memo)) if action==1 else (Shift, arg))
///                     for token, (action, arg) in actions.items()}
///             for state, actions in data['states'].items()
///         }
///         return cls(states, data['start_states'], data['end_states'])
/// ```
final class ParseTable extends PythonClass {
  factory ParseTable({
    required Object? states,
    required Object? start_states,
    required Object? end_states,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parsers.lalr_analysis",
        "ParseTable",
        ParseTable.from,
        <Object?>[
          states,
          start_states,
          end_states,
        ],
        <String, Object?>{},
      );

  ParseTable.from(super.pythonClass) : super.from();

  /// ## serialize
  ///
  /// ### python source
  /// ```py
  /// def serialize(self, memo):
  ///         tokens = Enumerator()
  ///
  ///         states = {
  ///             state: {tokens.get(token): ((1, arg.serialize(memo)) if action is Reduce else (0, arg))
  ///                     for token, (action, arg) in actions.items()}
  ///             for state, actions in self.states.items()
  ///         }
  ///
  ///         return {
  ///             'tokens': tokens.reversed(),
  ///             'states': states,
  ///             'start_states': self.start_states,
  ///             'end_states': self.end_states,
  ///         }
  /// ```
  Object? serialize({
    required Object? memo,
  }) =>
      getFunction("serialize").call(
        <Object?>[
          memo,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## deserialize (getter)
  Object? get deserialize => getAttribute("deserialize");

  /// ## deserialize (setter)
  set deserialize(Object? deserialize) =>
      setAttribute("deserialize", deserialize);

  /// ## states (getter)
  Object? get states => getAttribute("states");

  /// ## states (setter)
  set states(Object? states) => setAttribute("states", states);

  /// ## start_states (getter)
  Object? get start_states => getAttribute("start_states");

  /// ## start_states (setter)
  set start_states(Object? start_states) =>
      setAttribute("start_states", start_states);

  /// ## end_states (getter)
  Object? get end_states => getAttribute("end_states");

  /// ## end_states (setter)
  set end_states(Object? end_states) => setAttribute("end_states", end_states);
}

/// ## ImmutableInteractiveParser
///
/// ### python docstring
///
/// Same as ``InteractiveParser``, but operations create a new instance instead
/// of changing it in-place.
///
/// ### python source
/// ```py
/// class ImmutableInteractiveParser(InteractiveParser):
///     """Same as ``InteractiveParser``, but operations create a new instance instead
///     of changing it in-place.
///     """
///
///     result = None
///
///     def __hash__(self):
///         return hash((self.parser_state, self.lexer_thread))
///
///     def feed_token(self, token):
///         c = copy(self)
///         c.result = InteractiveParser.feed_token(c, token)
///         return c
///
///     def exhaust_lexer(self):
///         """Try to feed the rest of the lexer state into the parser.
///
///         Note that this returns a new ImmutableInteractiveParser and does not feed an '$END' Token"""
///         cursor = self.as_mutable()
///         cursor.exhaust_lexer()
///         return cursor.as_immutable()
///
///     def as_mutable(self):
///         """Convert to an ``InteractiveParser``."""
///         p = copy(self)
///         return InteractiveParser(p.parser, p.parser_state, p.lexer_thread)
/// ```
final class ImmutableInteractiveParser extends PythonClass {
  factory ImmutableInteractiveParser({
    required Object? parser,
    required Object? parser_state,
    required Object? lexer_thread,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parsers.lalr_interactive_parser",
        "ImmutableInteractiveParser",
        ImmutableInteractiveParser.from,
        <Object?>[
          parser,
          parser_state,
          lexer_thread,
        ],
        <String, Object?>{},
      );

  ImmutableInteractiveParser.from(super.pythonClass) : super.from();

  /// ## accepts
  ///
  /// ### python docstring
  ///
  /// Returns the set of possible tokens that will advance the parser into a new valid state.
  ///
  /// ### python source
  /// ```py
  /// def accepts(self):
  ///         """Returns the set of possible tokens that will advance the parser into a new valid state."""
  ///         accepts = set()
  ///         for t in self.choices():
  ///             if t.isupper(): # is terminal?
  ///                 new_cursor = copy(self)
  ///                 try:
  ///                     new_cursor.feed_token(self.lexer_thread._Token(t, ''))
  ///                 except UnexpectedToken:
  ///                     pass
  ///                 else:
  ///                     accepts.add(t)
  ///         return accepts
  /// ```
  Object? accepts() => getFunction("accepts").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## as_immutable
  ///
  /// ### python docstring
  ///
  /// Convert to an ``ImmutableInteractiveParser``.
  ///
  /// ### python source
  /// ```py
  /// def as_immutable(self):
  ///         """Convert to an ``ImmutableInteractiveParser``."""
  ///         p = copy(self)
  ///         return ImmutableInteractiveParser(p.parser, p.parser_state, p.lexer_thread)
  /// ```
  Object? as_immutable() => getFunction("as_immutable").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## as_mutable
  ///
  /// ### python docstring
  ///
  /// Convert to an ``InteractiveParser``.
  ///
  /// ### python source
  /// ```py
  /// def as_mutable(self):
  ///         """Convert to an ``InteractiveParser``."""
  ///         p = copy(self)
  ///         return InteractiveParser(p.parser, p.parser_state, p.lexer_thread)
  /// ```
  Object? as_mutable() => getFunction("as_mutable").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## choices
  ///
  /// ### python docstring
  ///
  /// Returns a dictionary of token types, matched to their action in the parser.
  ///
  /// Only returns token types that are accepted by the current state.
  ///
  /// Updated by ``feed_token()``.
  ///
  /// ### python source
  /// ```py
  /// def choices(self):
  ///         """Returns a dictionary of token types, matched to their action in the parser.
  ///
  ///         Only returns token types that are accepted by the current state.
  ///
  ///         Updated by ``feed_token()``.
  ///         """
  ///         return self.parser_state.parse_conf.parse_table.states[self.parser_state.position]
  /// ```
  Object? choices() => getFunction("choices").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## copy
  ///
  /// ### python source
  /// ```py
  /// def copy(self):
  ///         return copy(self)
  /// ```
  Object? copy() => getFunction("copy").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## exhaust_lexer
  ///
  /// ### python docstring
  ///
  /// Try to feed the rest of the lexer state into the parser.
  ///
  /// Note that this returns a new ImmutableInteractiveParser and does not feed an '$END' Token
  ///
  /// ### python source
  /// ```py
  /// def exhaust_lexer(self):
  ///         """Try to feed the rest of the lexer state into the parser.
  ///
  ///         Note that this returns a new ImmutableInteractiveParser and does not feed an '$END' Token"""
  ///         cursor = self.as_mutable()
  ///         cursor.exhaust_lexer()
  ///         return cursor.as_immutable()
  /// ```
  Object? exhaust_lexer() => getFunction("exhaust_lexer").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## feed_eof
  ///
  /// ### python docstring
  ///
  /// Feed a '$END' Token. Borrows from 'last_token' if given.
  ///
  /// ### python source
  /// ```py
  /// def feed_eof(self, last_token=None):
  ///         """Feed a '$END' Token. Borrows from 'last_token' if given."""
  ///         eof = Token.new_borrow_pos('$END', '', last_token) if last_token is not None else self.lexer_thread._Token('$END', '', 0, 1, 1)
  ///         return self.feed_token(eof)
  /// ```
  Object? feed_eof({
    Object? last_token,
  }) =>
      getFunction("feed_eof").call(
        <Object?>[
          last_token,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## feed_token
  ///
  /// ### python docstring
  ///
  /// Feed the parser with a token, and advance it to the next state, as if it received it from the lexer.
  ///
  /// Note that ``token`` has to be an instance of ``Token``.
  ///
  /// ### python source
  /// ```py
  /// def feed_token(self, token):
  ///         c = copy(self)
  ///         c.result = InteractiveParser.feed_token(c, token)
  ///         return c
  /// ```
  Object? feed_token({
    required Object? token,
  }) =>
      getFunction("feed_token").call(
        <Object?>[
          token,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## iter_parse
  ///
  /// ### python docstring
  ///
  /// Step through the different stages of the parse, by reading tokens from the lexer
  /// and feeding them to the parser, one per iteration.
  ///
  /// Returns an iterator of the tokens it encounters.
  ///
  /// When the parse is over, the resulting tree can be found in ``InteractiveParser.result``.
  ///
  /// ### python source
  /// ```py
  /// def iter_parse(self) -> Iterator[Token]:
  ///         """Step through the different stages of the parse, by reading tokens from the lexer
  ///         and feeding them to the parser, one per iteration.
  ///
  ///         Returns an iterator of the tokens it encounters.
  ///
  ///         When the parse is over, the resulting tree can be found in ``InteractiveParser.result``.
  ///         """
  ///         for token in self.lexer_thread.lex(self.parser_state):
  ///             yield token
  ///             self.result = self.feed_token(token)
  /// ```
  Object? iter_parse() => getFunction("iter_parse").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## pretty
  ///
  /// ### python docstring
  ///
  /// Print the output of ``choices()`` in a way that's easier to read.
  ///
  /// ### python source
  /// ```py
  /// def pretty(self):
  ///         """Print the output of ``choices()`` in a way that's easier to read."""
  ///         out = ["Parser choices:"]
  ///         for k, v in self.choices().items():
  ///             out.append('\t- %s -> %r' % (k, v))
  ///         out.append('stack size: %s' % len(self.parser_state.state_stack))
  ///         return '\n'.join(out)
  /// ```
  Object? pretty() => getFunction("pretty").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## resume_parse
  ///
  /// ### python docstring
  ///
  /// Resume automated parsing from the current state.
  ///
  /// ### python source
  /// ```py
  /// def resume_parse(self):
  ///         """Resume automated parsing from the current state.
  ///         """
  ///         return self.parser.parse_from_state(self.parser_state, last_token=self.lexer_state.state.last_token)
  /// ```
  Object? resume_parse() => getFunction("resume_parse").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## lexer_state (getter)
  Object? get lexer_state => getAttribute("lexer_state");

  /// ## lexer_state (setter)
  set lexer_state(Object? lexer_state) =>
      setAttribute("lexer_state", lexer_state);

  /// ## result (getter)
  Object? get result => getAttribute("result");

  /// ## result (setter)
  set result(Object? result) => setAttribute("result", result);

  /// ## parser (getter)
  Object? get parser => getAttribute("parser");

  /// ## parser (setter)
  set parser(Object? parser) => setAttribute("parser", parser);

  /// ## parser_state (getter)
  Object? get parser_state => getAttribute("parser_state");

  /// ## parser_state (setter)
  set parser_state(Object? parser_state) =>
      setAttribute("parser_state", parser_state);

  /// ## lexer_thread (getter)
  Object? get lexer_thread => getAttribute("lexer_thread");

  /// ## lexer_thread (setter)
  set lexer_thread(Object? lexer_thread) =>
      setAttribute("lexer_thread", lexer_thread);
}

/// ## InteractiveParser
///
/// ### python docstring
///
/// InteractiveParser gives you advanced control over parsing and error handling when parsing with LALR.
///
/// For a simpler interface, see the ``on_error`` argument to ``Lark.parse()``.
///
/// ### python source
/// ```py
/// class InteractiveParser:
///     """InteractiveParser gives you advanced control over parsing and error handling when parsing with LALR.
///
///     For a simpler interface, see the ``on_error`` argument to ``Lark.parse()``.
///     """
///     def __init__(self, parser, parser_state, lexer_thread: LexerThread):
///         self.parser = parser
///         self.parser_state = parser_state
///         self.lexer_thread = lexer_thread
///         self.result = None
///
///     @property
///     def lexer_state(self) -> LexerThread:
///         warnings.warn("lexer_state will be removed in subsequent releases. Use lexer_thread instead.", DeprecationWarning)
///         return self.lexer_thread
///
///     def feed_token(self, token: Token):
///         """Feed the parser with a token, and advance it to the next state, as if it received it from the lexer.
///
///         Note that ``token`` has to be an instance of ``Token``.
///         """
///         return self.parser_state.feed_token(token, token.type == '$END')
///
///     def iter_parse(self) -> Iterator[Token]:
///         """Step through the different stages of the parse, by reading tokens from the lexer
///         and feeding them to the parser, one per iteration.
///
///         Returns an iterator of the tokens it encounters.
///
///         When the parse is over, the resulting tree can be found in ``InteractiveParser.result``.
///         """
///         for token in self.lexer_thread.lex(self.parser_state):
///             yield token
///             self.result = self.feed_token(token)
///
///     def exhaust_lexer(self) -> List[Token]:
///         """Try to feed the rest of the lexer state into the interactive parser.
///
///         Note that this modifies the instance in place and does not feed an '$END' Token
///         """
///         return list(self.iter_parse())
///
///
///     def feed_eof(self, last_token=None):
///         """Feed a '$END' Token. Borrows from 'last_token' if given."""
///         eof = Token.new_borrow_pos('$END', '', last_token) if last_token is not None else self.lexer_thread._Token('$END', '', 0, 1, 1)
///         return self.feed_token(eof)
///
///
///     def __copy__(self):
///         """Create a new interactive parser with a separate state.
///
///         Calls to feed_token() won't affect the old instance, and vice-versa.
///         """
///         return type(self)(
///             self.parser,
///             copy(self.parser_state),
///             copy(self.lexer_thread),
///         )
///
///     def copy(self):
///         return copy(self)
///
///     def __eq__(self, other):
///         if not isinstance(other, InteractiveParser):
///             return False
///
///         return self.parser_state == other.parser_state and self.lexer_thread == other.lexer_thread
///
///     def as_immutable(self):
///         """Convert to an ``ImmutableInteractiveParser``."""
///         p = copy(self)
///         return ImmutableInteractiveParser(p.parser, p.parser_state, p.lexer_thread)
///
///     def pretty(self):
///         """Print the output of ``choices()`` in a way that's easier to read."""
///         out = ["Parser choices:"]
///         for k, v in self.choices().items():
///             out.append('\t- %s -> %r' % (k, v))
///         out.append('stack size: %s' % len(self.parser_state.state_stack))
///         return '\n'.join(out)
///
///     def choices(self):
///         """Returns a dictionary of token types, matched to their action in the parser.
///
///         Only returns token types that are accepted by the current state.
///
///         Updated by ``feed_token()``.
///         """
///         return self.parser_state.parse_conf.parse_table.states[self.parser_state.position]
///
///     def accepts(self):
///         """Returns the set of possible tokens that will advance the parser into a new valid state."""
///         accepts = set()
///         for t in self.choices():
///             if t.isupper(): # is terminal?
///                 new_cursor = copy(self)
///                 try:
///                     new_cursor.feed_token(self.lexer_thread._Token(t, ''))
///                 except UnexpectedToken:
///                     pass
///                 else:
///                     accepts.add(t)
///         return accepts
///
///     def resume_parse(self):
///         """Resume automated parsing from the current state.
///         """
///         return self.parser.parse_from_state(self.parser_state, last_token=self.lexer_state.state.last_token)
/// ```
final class InteractiveParser extends PythonClass {
  factory InteractiveParser({
    required Object? parser,
    required Object? parser_state,
    required Object? lexer_thread,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parsers.lalr_interactive_parser",
        "InteractiveParser",
        InteractiveParser.from,
        <Object?>[
          parser,
          parser_state,
          lexer_thread,
        ],
        <String, Object?>{},
      );

  InteractiveParser.from(super.pythonClass) : super.from();

  /// ## accepts
  ///
  /// ### python docstring
  ///
  /// Returns the set of possible tokens that will advance the parser into a new valid state.
  ///
  /// ### python source
  /// ```py
  /// def accepts(self):
  ///         """Returns the set of possible tokens that will advance the parser into a new valid state."""
  ///         accepts = set()
  ///         for t in self.choices():
  ///             if t.isupper(): # is terminal?
  ///                 new_cursor = copy(self)
  ///                 try:
  ///                     new_cursor.feed_token(self.lexer_thread._Token(t, ''))
  ///                 except UnexpectedToken:
  ///                     pass
  ///                 else:
  ///                     accepts.add(t)
  ///         return accepts
  /// ```
  Object? accepts() => getFunction("accepts").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## as_immutable
  ///
  /// ### python docstring
  ///
  /// Convert to an ``ImmutableInteractiveParser``.
  ///
  /// ### python source
  /// ```py
  /// def as_immutable(self):
  ///         """Convert to an ``ImmutableInteractiveParser``."""
  ///         p = copy(self)
  ///         return ImmutableInteractiveParser(p.parser, p.parser_state, p.lexer_thread)
  /// ```
  Object? as_immutable() => getFunction("as_immutable").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## choices
  ///
  /// ### python docstring
  ///
  /// Returns a dictionary of token types, matched to their action in the parser.
  ///
  /// Only returns token types that are accepted by the current state.
  ///
  /// Updated by ``feed_token()``.
  ///
  /// ### python source
  /// ```py
  /// def choices(self):
  ///         """Returns a dictionary of token types, matched to their action in the parser.
  ///
  ///         Only returns token types that are accepted by the current state.
  ///
  ///         Updated by ``feed_token()``.
  ///         """
  ///         return self.parser_state.parse_conf.parse_table.states[self.parser_state.position]
  /// ```
  Object? choices() => getFunction("choices").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## copy
  ///
  /// ### python source
  /// ```py
  /// def copy(self):
  ///         return copy(self)
  /// ```
  Object? copy() => getFunction("copy").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## exhaust_lexer
  ///
  /// ### python docstring
  ///
  /// Try to feed the rest of the lexer state into the interactive parser.
  ///
  /// Note that this modifies the instance in place and does not feed an '$END' Token
  ///
  /// ### python source
  /// ```py
  /// def exhaust_lexer(self) -> List[Token]:
  ///         """Try to feed the rest of the lexer state into the interactive parser.
  ///
  ///         Note that this modifies the instance in place and does not feed an '$END' Token
  ///         """
  ///         return list(self.iter_parse())
  /// ```
  Object? exhaust_lexer() => getFunction("exhaust_lexer").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## feed_eof
  ///
  /// ### python docstring
  ///
  /// Feed a '$END' Token. Borrows from 'last_token' if given.
  ///
  /// ### python source
  /// ```py
  /// def feed_eof(self, last_token=None):
  ///         """Feed a '$END' Token. Borrows from 'last_token' if given."""
  ///         eof = Token.new_borrow_pos('$END', '', last_token) if last_token is not None else self.lexer_thread._Token('$END', '', 0, 1, 1)
  ///         return self.feed_token(eof)
  /// ```
  Object? feed_eof({
    Object? last_token,
  }) =>
      getFunction("feed_eof").call(
        <Object?>[
          last_token,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## feed_token
  ///
  /// ### python docstring
  ///
  /// Feed the parser with a token, and advance it to the next state, as if it received it from the lexer.
  ///
  /// Note that ``token`` has to be an instance of ``Token``.
  ///
  /// ### python source
  /// ```py
  /// def feed_token(self, token: Token):
  ///         """Feed the parser with a token, and advance it to the next state, as if it received it from the lexer.
  ///
  ///         Note that ``token`` has to be an instance of ``Token``.
  ///         """
  ///         return self.parser_state.feed_token(token, token.type == '$END')
  /// ```
  Object? feed_token({
    required Object? token,
  }) =>
      getFunction("feed_token").call(
        <Object?>[
          token,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## iter_parse
  ///
  /// ### python docstring
  ///
  /// Step through the different stages of the parse, by reading tokens from the lexer
  /// and feeding them to the parser, one per iteration.
  ///
  /// Returns an iterator of the tokens it encounters.
  ///
  /// When the parse is over, the resulting tree can be found in ``InteractiveParser.result``.
  ///
  /// ### python source
  /// ```py
  /// def iter_parse(self) -> Iterator[Token]:
  ///         """Step through the different stages of the parse, by reading tokens from the lexer
  ///         and feeding them to the parser, one per iteration.
  ///
  ///         Returns an iterator of the tokens it encounters.
  ///
  ///         When the parse is over, the resulting tree can be found in ``InteractiveParser.result``.
  ///         """
  ///         for token in self.lexer_thread.lex(self.parser_state):
  ///             yield token
  ///             self.result = self.feed_token(token)
  /// ```
  Object? iter_parse() => getFunction("iter_parse").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## pretty
  ///
  /// ### python docstring
  ///
  /// Print the output of ``choices()`` in a way that's easier to read.
  ///
  /// ### python source
  /// ```py
  /// def pretty(self):
  ///         """Print the output of ``choices()`` in a way that's easier to read."""
  ///         out = ["Parser choices:"]
  ///         for k, v in self.choices().items():
  ///             out.append('\t- %s -> %r' % (k, v))
  ///         out.append('stack size: %s' % len(self.parser_state.state_stack))
  ///         return '\n'.join(out)
  /// ```
  Object? pretty() => getFunction("pretty").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## resume_parse
  ///
  /// ### python docstring
  ///
  /// Resume automated parsing from the current state.
  ///
  /// ### python source
  /// ```py
  /// def resume_parse(self):
  ///         """Resume automated parsing from the current state.
  ///         """
  ///         return self.parser.parse_from_state(self.parser_state, last_token=self.lexer_state.state.last_token)
  /// ```
  Object? resume_parse() => getFunction("resume_parse").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## lexer_state (getter)
  Object? get lexer_state => getAttribute("lexer_state");

  /// ## lexer_state (setter)
  set lexer_state(Object? lexer_state) =>
      setAttribute("lexer_state", lexer_state);

  /// ## parser (getter)
  Object? get parser => getAttribute("parser");

  /// ## parser (setter)
  set parser(Object? parser) => setAttribute("parser", parser);

  /// ## parser_state (getter)
  Object? get parser_state => getAttribute("parser_state");

  /// ## parser_state (setter)
  set parser_state(Object? parser_state) =>
      setAttribute("parser_state", parser_state);

  /// ## lexer_thread (getter)
  Object? get lexer_thread => getAttribute("lexer_thread");

  /// ## lexer_thread (setter)
  set lexer_thread(Object? lexer_thread) =>
      setAttribute("lexer_thread", lexer_thread);

  /// ## result (getter)
  Object? get result => getAttribute("result");

  /// ## result (setter)
  set result(Object? result) => setAttribute("result", result);
}

/// ## ParseConf
///
/// ### python source
/// ```py
/// class ParseConf:
///     __slots__ = 'parse_table', 'callbacks', 'start', 'start_state', 'end_state', 'states'
///
///     def __init__(self, parse_table, callbacks, start):
///         self.parse_table = parse_table
///
///         self.start_state = self.parse_table.start_states[start]
///         self.end_state = self.parse_table.end_states[start]
///         self.states = self.parse_table.states
///
///         self.callbacks = callbacks
///         self.start = start
/// ```
final class ParseConf extends PythonClass {
  factory ParseConf({
    required Object? parse_table,
    required Object? callbacks,
    required Object? start,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parsers.lalr_parser",
        "ParseConf",
        ParseConf.from,
        <Object?>[
          parse_table,
          callbacks,
          start,
        ],
        <String, Object?>{},
      );

  ParseConf.from(super.pythonClass) : super.from();

  /// ## callbacks (getter)
  Object? get callbacks => getAttribute("callbacks");

  /// ## callbacks (setter)
  set callbacks(Object? callbacks) => setAttribute("callbacks", callbacks);

  /// ## end_state (getter)
  Object? get end_state => getAttribute("end_state");

  /// ## end_state (setter)
  set end_state(Object? end_state) => setAttribute("end_state", end_state);

  /// ## parse_table (getter)
  Object? get parse_table => getAttribute("parse_table");

  /// ## parse_table (setter)
  set parse_table(Object? parse_table) =>
      setAttribute("parse_table", parse_table);

  /// ## start (getter)
  Object? get start => getAttribute("start");

  /// ## start (setter)
  set start(Object? start) => setAttribute("start", start);

  /// ## start_state (getter)
  Object? get start_state => getAttribute("start_state");

  /// ## start_state (setter)
  set start_state(Object? start_state) =>
      setAttribute("start_state", start_state);

  /// ## states (getter)
  Object? get states => getAttribute("states");

  /// ## states (setter)
  set states(Object? states) => setAttribute("states", states);
}

/// ## ParserState
///
/// ### python source
/// ```py
/// class ParserState:
///     __slots__ = 'parse_conf', 'lexer', 'state_stack', 'value_stack'
///
///     def __init__(self, parse_conf, lexer, state_stack=None, value_stack=None):
///         self.parse_conf = parse_conf
///         self.lexer = lexer
///         self.state_stack = state_stack or [self.parse_conf.start_state]
///         self.value_stack = value_stack or []
///
///     @property
///     def position(self):
///         return self.state_stack[-1]
///
///     # Necessary for match_examples() to work
///     def __eq__(self, other):
///         if not isinstance(other, ParserState):
///             return NotImplemented
///         return len(self.state_stack) == len(other.state_stack) and self.position == other.position
///
///     def __copy__(self):
///         return type(self)(
///             self.parse_conf,
///             self.lexer, # XXX copy
///             copy(self.state_stack),
///             deepcopy(self.value_stack),
///         )
///
///     def copy(self):
///         return copy(self)
///
///     def feed_token(self, token, is_end=False):
///         state_stack = self.state_stack
///         value_stack = self.value_stack
///         states = self.parse_conf.states
///         end_state = self.parse_conf.end_state
///         callbacks = self.parse_conf.callbacks
///
///         while True:
///             state = state_stack[-1]
///             try:
///                 action, arg = states[state][token.type]
///             except KeyError:
///                 expected = {s for s in states[state].keys() if s.isupper()}
///                 raise UnexpectedToken(token, expected, state=self, interactive_parser=None)
///
///             assert arg != end_state
///
///             if action is Shift:
///                 # shift once and return
///                 assert not is_end
///                 state_stack.append(arg)
///                 value_stack.append(token if token.type not in callbacks else callbacks[token.type](token))
///                 return
///             else:
///                 # reduce+shift as many times as necessary
///                 rule = arg
///                 size = len(rule.expansion)
///                 if size:
///                     s = value_stack[-size:]
///                     del state_stack[-size:]
///                     del value_stack[-size:]
///                 else:
///                     s = []
///
///                 value = callbacks[rule](s)
///
///                 _action, new_state = states[state_stack[-1]][rule.origin.name]
///                 assert _action is Shift
///                 state_stack.append(new_state)
///                 value_stack.append(value)
///
///                 if is_end and state_stack[-1] == end_state:
///                     return value_stack[-1]
/// ```
final class ParserState extends PythonClass {
  factory ParserState({
    required Object? parse_conf,
    required Object? lexer,
    Object? state_stack,
    Object? value_stack,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.parsers.lalr_parser",
        "ParserState",
        ParserState.from,
        <Object?>[
          parse_conf,
          lexer,
          state_stack,
          value_stack,
        ],
        <String, Object?>{},
      );

  ParserState.from(super.pythonClass) : super.from();

  /// ## copy
  ///
  /// ### python source
  /// ```py
  /// def copy(self):
  ///         return copy(self)
  /// ```
  Object? copy() => getFunction("copy").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## feed_token
  ///
  /// ### python source
  /// ```py
  /// def feed_token(self, token, is_end=False):
  ///         state_stack = self.state_stack
  ///         value_stack = self.value_stack
  ///         states = self.parse_conf.states
  ///         end_state = self.parse_conf.end_state
  ///         callbacks = self.parse_conf.callbacks
  ///
  ///         while True:
  ///             state = state_stack[-1]
  ///             try:
  ///                 action, arg = states[state][token.type]
  ///             except KeyError:
  ///                 expected = {s for s in states[state].keys() if s.isupper()}
  ///                 raise UnexpectedToken(token, expected, state=self, interactive_parser=None)
  ///
  ///             assert arg != end_state
  ///
  ///             if action is Shift:
  ///                 # shift once and return
  ///                 assert not is_end
  ///                 state_stack.append(arg)
  ///                 value_stack.append(token if token.type not in callbacks else callbacks[token.type](token))
  ///                 return
  ///             else:
  ///                 # reduce+shift as many times as necessary
  ///                 rule = arg
  ///                 size = len(rule.expansion)
  ///                 if size:
  ///                     s = value_stack[-size:]
  ///                     del state_stack[-size:]
  ///                     del value_stack[-size:]
  ///                 else:
  ///                     s = []
  ///
  ///                 value = callbacks[rule](s)
  ///
  ///                 _action, new_state = states[state_stack[-1]][rule.origin.name]
  ///                 assert _action is Shift
  ///                 state_stack.append(new_state)
  ///                 value_stack.append(value)
  ///
  ///                 if is_end and state_stack[-1] == end_state:
  ///                     return value_stack[-1]
  /// ```
  Object? feed_token({
    required Object? token,
    Object? is_end = false,
  }) =>
      getFunction("feed_token").call(
        <Object?>[
          token,
          is_end,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## position (getter)
  Object? get position => getAttribute("position");

  /// ## position (setter)
  set position(Object? position) => setAttribute("position", position);

  /// ## lexer (getter)
  Object? get lexer => getAttribute("lexer");

  /// ## lexer (setter)
  set lexer(Object? lexer) => setAttribute("lexer", lexer);

  /// ## parse_conf (getter)
  Object? get parse_conf => getAttribute("parse_conf");

  /// ## parse_conf (setter)
  set parse_conf(Object? parse_conf) => setAttribute("parse_conf", parse_conf);

  /// ## state_stack (getter)
  Object? get state_stack => getAttribute("state_stack");

  /// ## state_stack (setter)
  set state_stack(Object? state_stack) =>
      setAttribute("state_stack", state_stack);

  /// ## value_stack (getter)
  Object? get value_stack => getAttribute("value_stack");

  /// ## value_stack (setter)
  set value_stack(Object? value_stack) =>
      setAttribute("value_stack", value_stack);
}

/// ## Generic
///
/// ### python docstring
///
/// Abstract base class for generic types.
///
/// A generic type is typically declared by inheriting from
/// this class parameterized with one or more type variables.
/// For example, a generic mapping type might be defined as::
///
///   class Mapping(Generic[KT, VT]):
///       def __getitem__(self, key: KT) -> VT:
///           ...
///       # Etc.
///
/// This class can then be used as follows::
///
///   def lookup_name(mapping: Mapping[KT, VT], key: KT, default: VT) -> VT:
///       try:
///           return mapping[key]
///       except KeyError:
///           return default
///
/// ### python source
/// ```py
/// class Generic:
///     """Abstract base class for generic types.
///
///     A generic type is typically declared by inheriting from
///     this class parameterized with one or more type variables.
///     For example, a generic mapping type might be defined as::
///
///       class Mapping(Generic[KT, VT]):
///           def __getitem__(self, key: KT) -> VT:
///               ...
///           # Etc.
///
///     This class can then be used as follows::
///
///       def lookup_name(mapping: Mapping[KT, VT], key: KT, default: VT) -> VT:
///           try:
///               return mapping[key]
///           except KeyError:
///               return default
///     """
///     __slots__ = ()
///     _is_protocol = False
///
///     @_tp_cache
///     def __class_getitem__(cls, params):
///         """Parameterizes a generic class.
///
///         At least, parameterizing a generic class is the *main* thing this method
///         does. For example, for some generic class `Foo`, this is called when we
///         do `Foo[int]` - there, with `cls=Foo` and `params=int`.
///
///         However, note that this method is also called when defining generic
///         classes in the first place with `class Foo(Generic[T]): ...`.
///         """
///         if not isinstance(params, tuple):
///             params = (params,)
///
///         params = tuple(_type_convert(p) for p in params)
///         if cls in (Generic, Protocol):
///             # Generic and Protocol can only be subscripted with unique type variables.
///             if not params:
///                 raise TypeError(
///                     f"Parameter list to {cls.__qualname__}[...] cannot be empty"
///                 )
///             if not all(_is_typevar_like(p) for p in params):
///                 raise TypeError(
///                     f"Parameters to {cls.__name__}[...] must all be type variables "
///                     f"or parameter specification variables.")
///             if len(set(params)) != len(params):
///                 raise TypeError(
///                     f"Parameters to {cls.__name__}[...] must all be unique")
///         else:
///             # Subscripting a regular Generic subclass.
///             for param in cls.__parameters__:
///                 prepare = getattr(param, '__typing_prepare_subst__', None)
///                 if prepare is not None:
///                     params = prepare(cls, params)
///             _check_generic(cls, params, len(cls.__parameters__))
///
///             new_args = []
///             for param, new_arg in zip(cls.__parameters__, params):
///                 if isinstance(param, TypeVarTuple):
///                     new_args.extend(new_arg)
///                 else:
///                     new_args.append(new_arg)
///             params = tuple(new_args)
///
///         return _GenericAlias(cls, params,
///                              _paramspec_tvars=True)
///
///     def __init_subclass__(cls, *args, **kwargs):
///         super().__init_subclass__(*args, **kwargs)
///         tvars = []
///         if '__orig_bases__' in cls.__dict__:
///             error = Generic in cls.__orig_bases__
///         else:
///             error = (Generic in cls.__bases__ and
///                         cls.__name__ != 'Protocol' and
///                         type(cls) != _TypedDictMeta)
///         if error:
///             raise TypeError("Cannot inherit from plain Generic")
///         if '__orig_bases__' in cls.__dict__:
///             tvars = _collect_parameters(cls.__orig_bases__)
///             # Look for Generic[T1, ..., Tn].
///             # If found, tvars must be a subset of it.
///             # If not found, tvars is it.
///             # Also check for and reject plain Generic,
///             # and reject multiple Generic[...].
///             gvars = None
///             for base in cls.__orig_bases__:
///                 if (isinstance(base, _GenericAlias) and
///                         base.__origin__ is Generic):
///                     if gvars is not None:
///                         raise TypeError(
///                             "Cannot inherit from Generic[...] multiple types.")
///                     gvars = base.__parameters__
///             if gvars is not None:
///                 tvarset = set(tvars)
///                 gvarset = set(gvars)
///                 if not tvarset <= gvarset:
///                     s_vars = ', '.join(str(t) for t in tvars if t not in gvarset)
///                     s_args = ', '.join(str(g) for g in gvars)
///                     raise TypeError(f"Some type variables ({s_vars}) are"
///                                     f" not listed in Generic[{s_args}]")
///                 tvars = gvars
///         cls.__parameters__ = tuple(tvars)
/// ```
final class Generic extends PythonClass {
  factory Generic() => PythonFfiDart.instance.importClass(
        "typing",
        "Generic",
        Generic.from,
        <Object?>[],
      );

  Generic.from(super.pythonClass) : super.from();
}

/// ## Meta
///
/// ### python source
/// ```py
/// class Meta:
///
///     empty: bool
///     line: int
///     column: int
///     start_pos: int
///     end_line: int
///     end_column: int
///     end_pos: int
///     orig_expansion: 'List[TerminalDef]'
///     match_tree: bool
///
///     def __init__(self):
///         self.empty = True
/// ```
final class Meta extends PythonClass {
  factory Meta() => PythonFfiDart.instance.importClass(
        "lark.tree",
        "Meta",
        Meta.from,
        <Object?>[],
        <String, Object?>{},
      );

  Meta.from(super.pythonClass) : super.from();

  /// ## empty (getter)
  Object? get empty => getAttribute("empty");

  /// ## empty (setter)
  set empty(Object? empty) => setAttribute("empty", empty);
}

/// ## OrderedDict
///
/// ### python source
/// ```py
/// class OrderedDict(dict):
///     'Dictionary that remembers insertion order'
///     # An inherited dict maps keys to values.
///     # The inherited dict provides __getitem__, __len__, __contains__, and get.
///     # The remaining methods are order-aware.
///     # Big-O running times for all methods are the same as regular dictionaries.
///
///     # The internal self.__map dict maps keys to links in a doubly linked list.
///     # The circular doubly linked list starts and ends with a sentinel element.
///     # The sentinel element never gets deleted (this simplifies the algorithm).
///     # The sentinel is in self.__hardroot with a weakref proxy in self.__root.
///     # The prev links are weakref proxies (to prevent circular references).
///     # Individual links are kept alive by the hard reference in self.__map.
///     # Those hard references disappear when a key is deleted from an OrderedDict.
///
///     def __init__(self, other=(), /, **kwds):
///         '''Initialize an ordered dictionary.  The signature is the same as
///         regular dictionaries.  Keyword argument order is preserved.
///         '''
///         try:
///             self.__root
///         except AttributeError:
///             self.__hardroot = _Link()
///             self.__root = root = _proxy(self.__hardroot)
///             root.prev = root.next = root
///             self.__map = {}
///         self.__update(other, **kwds)
///
///     def __setitem__(self, key, value,
///                     dict_setitem=dict.__setitem__, proxy=_proxy, Link=_Link):
///         'od.__setitem__(i, y) <==> od[i]=y'
///         # Setting a new item creates a new link at the end of the linked list,
///         # and the inherited dictionary is updated with the new key/value pair.
///         if key not in self:
///             self.__map[key] = link = Link()
///             root = self.__root
///             last = root.prev
///             link.prev, link.next, link.key = last, root, key
///             last.next = link
///             root.prev = proxy(link)
///         dict_setitem(self, key, value)
///
///     def __delitem__(self, key, dict_delitem=dict.__delitem__):
///         'od.__delitem__(y) <==> del od[y]'
///         # Deleting an existing item uses self.__map to find the link which gets
///         # removed by updating the links in the predecessor and successor nodes.
///         dict_delitem(self, key)
///         link = self.__map.pop(key)
///         link_prev = link.prev
///         link_next = link.next
///         link_prev.next = link_next
///         link_next.prev = link_prev
///         link.prev = None
///         link.next = None
///
///     def __iter__(self):
///         'od.__iter__() <==> iter(od)'
///         # Traverse the linked list in order.
///         root = self.__root
///         curr = root.next
///         while curr is not root:
///             yield curr.key
///             curr = curr.next
///
///     def __reversed__(self):
///         'od.__reversed__() <==> reversed(od)'
///         # Traverse the linked list in reverse order.
///         root = self.__root
///         curr = root.prev
///         while curr is not root:
///             yield curr.key
///             curr = curr.prev
///
///     def clear(self):
///         'od.clear() -> None.  Remove all items from od.'
///         root = self.__root
///         root.prev = root.next = root
///         self.__map.clear()
///         dict.clear(self)
///
///     def popitem(self, last=True):
///         '''Remove and return a (key, value) pair from the dictionary.
///
///         Pairs are returned in LIFO order if last is true or FIFO order if false.
///         '''
///         if not self:
///             raise KeyError('dictionary is empty')
///         root = self.__root
///         if last:
///             link = root.prev
///             link_prev = link.prev
///             link_prev.next = root
///             root.prev = link_prev
///         else:
///             link = root.next
///             link_next = link.next
///             root.next = link_next
///             link_next.prev = root
///         key = link.key
///         del self.__map[key]
///         value = dict.pop(self, key)
///         return key, value
///
///     def move_to_end(self, key, last=True):
///         '''Move an existing element to the end (or beginning if last is false).
///
///         Raise KeyError if the element does not exist.
///         '''
///         link = self.__map[key]
///         link_prev = link.prev
///         link_next = link.next
///         soft_link = link_next.prev
///         link_prev.next = link_next
///         link_next.prev = link_prev
///         root = self.__root
///         if last:
///             last = root.prev
///             link.prev = last
///             link.next = root
///             root.prev = soft_link
///             last.next = link
///         else:
///             first = root.next
///             link.prev = root
///             link.next = first
///             first.prev = soft_link
///             root.next = link
///
///     def __sizeof__(self):
///         sizeof = _sys.getsizeof
///         n = len(self) + 1                       # number of links including root
///         size = sizeof(self.__dict__)            # instance dictionary
///         size += sizeof(self.__map) * 2          # internal dict and inherited dict
///         size += sizeof(self.__hardroot) * n     # link objects
///         size += sizeof(self.__root) * n         # proxy objects
///         return size
///
///     update = __update = _collections_abc.MutableMapping.update
///
///     def keys(self):
///         "D.keys() -> a set-like object providing a view on D's keys"
///         return _OrderedDictKeysView(self)
///
///     def items(self):
///         "D.items() -> a set-like object providing a view on D's items"
///         return _OrderedDictItemsView(self)
///
///     def values(self):
///         "D.values() -> an object providing a view on D's values"
///         return _OrderedDictValuesView(self)
///
///     __ne__ = _collections_abc.MutableMapping.__ne__
///
///     __marker = object()
///
///     def pop(self, key, default=__marker):
///         '''od.pop(k[,d]) -> v, remove specified key and return the corresponding
///         value.  If key is not found, d is returned if given, otherwise KeyError
///         is raised.
///
///         '''
///         marker = self.__marker
///         result = dict.pop(self, key, marker)
///         if result is not marker:
///             # The same as in __delitem__().
///             link = self.__map.pop(key)
///             link_prev = link.prev
///             link_next = link.next
///             link_prev.next = link_next
///             link_next.prev = link_prev
///             link.prev = None
///             link.next = None
///             return result
///         if default is marker:
///             raise KeyError(key)
///         return default
///
///     def setdefault(self, key, default=None):
///         '''Insert key with a value of default if key is not in the dictionary.
///
///         Return the value for key if key is in the dictionary, else default.
///         '''
///         if key in self:
///             return self[key]
///         self[key] = default
///         return default
///
///     @_recursive_repr()
///     def __repr__(self):
///         'od.__repr__() <==> repr(od)'
///         if not self:
///             return '%s()' % (self.__class__.__name__,)
///         return '%s(%r)' % (self.__class__.__name__, list(self.items()))
///
///     def __reduce__(self):
///         'Return state information for pickling'
///         state = self.__getstate__()
///         if state:
///             if isinstance(state, tuple):
///                 state, slots = state
///             else:
///                 slots = {}
///             state = state.copy()
///             slots = slots.copy()
///             for k in vars(OrderedDict()):
///                 state.pop(k, None)
///                 slots.pop(k, None)
///             if slots:
///                 state = state, slots
///             else:
///                 state = state or None
///         return self.__class__, (), state, None, iter(self.items())
///
///     def copy(self):
///         'od.copy() -> a shallow copy of od'
///         return self.__class__(self)
///
///     @classmethod
///     def fromkeys(cls, iterable, value=None):
///         '''Create a new ordered dictionary with keys from iterable and values set to value.
///         '''
///         self = cls()
///         for key in iterable:
///             self[key] = value
///         return self
///
///     def __eq__(self, other):
///         '''od.__eq__(y) <==> od==y.  Comparison to another OD is order-sensitive
///         while comparison to a regular mapping is order-insensitive.
///
///         '''
///         if isinstance(other, OrderedDict):
///             return dict.__eq__(self, other) and all(map(_eq, self, other))
///         return dict.__eq__(self, other)
///
///     def __ior__(self, other):
///         self.update(other)
///         return self
///
///     def __or__(self, other):
///         if not isinstance(other, dict):
///             return NotImplemented
///         new = self.__class__(self)
///         new.update(other)
///         return new
///
///     def __ror__(self, other):
///         if not isinstance(other, dict):
///             return NotImplemented
///         new = self.__class__(other)
///         new.update(self)
///         return new
/// ```
final class OrderedDict extends PythonClass {
  factory OrderedDict() => PythonFfiDart.instance.importClass(
        "collections",
        "OrderedDict",
        OrderedDict.from,
        <Object?>[],
      );

  OrderedDict.from(super.pythonClass) : super.from();

  /// ## clear (getter)
  Object? get clear => getAttribute("clear");

  /// ## clear (setter)
  set clear(Object? clear) => setAttribute("clear", clear);

  /// ## copy (getter)
  Object? get copy => getAttribute("copy");

  /// ## copy (setter)
  set copy(Object? copy) => setAttribute("copy", copy);

  /// ## get (getter)
  Object? get $get => getAttribute("get");

  /// ## get (setter)
  set $get(Object? $get) => setAttribute("get", $get);

  /// ## items (getter)
  Object? get items => getAttribute("items");

  /// ## items (setter)
  set items(Object? items) => setAttribute("items", items);

  /// ## keys (getter)
  Object? get keys => getAttribute("keys");

  /// ## keys (setter)
  set keys(Object? keys) => setAttribute("keys", keys);

  /// ## move_to_end (getter)
  Object? get move_to_end => getAttribute("move_to_end");

  /// ## move_to_end (setter)
  set move_to_end(Object? move_to_end) =>
      setAttribute("move_to_end", move_to_end);

  /// ## pop (getter)
  Object? get pop => getAttribute("pop");

  /// ## pop (setter)
  set pop(Object? pop) => setAttribute("pop", pop);

  /// ## popitem (getter)
  Object? get popitem => getAttribute("popitem");

  /// ## popitem (setter)
  set popitem(Object? popitem) => setAttribute("popitem", popitem);

  /// ## setdefault (getter)
  Object? get setdefault => getAttribute("setdefault");

  /// ## setdefault (setter)
  set setdefault(Object? setdefault) => setAttribute("setdefault", setdefault);

  /// ## update (getter)
  Object? get update => getAttribute("update");

  /// ## update (setter)
  set update(Object? update) => setAttribute("update", update);

  /// ## values (getter)
  Object? get values => getAttribute("values");

  /// ## values (setter)
  set values(Object? values) => setAttribute("values", values);
}

/// ## BufferingFormatter
///
/// ### python docstring
///
/// A formatter suitable for formatting a number of records.
///
/// ### python source
/// ```py
/// class BufferingFormatter(object):
///     """
///     A formatter suitable for formatting a number of records.
///     """
///     def __init__(self, linefmt=None):
///         """
///         Optionally specify a formatter which will be used to format each
///         individual record.
///         """
///         if linefmt:
///             self.linefmt = linefmt
///         else:
///             self.linefmt = _defaultFormatter
///
///     def formatHeader(self, records):
///         """
///         Return the header string for the specified records.
///         """
///         return ""
///
///     def formatFooter(self, records):
///         """
///         Return the footer string for the specified records.
///         """
///         return ""
///
///     def format(self, records):
///         """
///         Format the specified records and return the result as a string.
///         """
///         rv = ""
///         if len(records) > 0:
///             rv = rv + self.formatHeader(records)
///             for record in records:
///                 rv = rv + self.linefmt.format(record)
///             rv = rv + self.formatFooter(records)
///         return rv
/// ```
final class BufferingFormatter extends PythonClass {
  factory BufferingFormatter({
    Object? linefmt,
  }) =>
      PythonFfiDart.instance.importClass(
        "logging",
        "BufferingFormatter",
        BufferingFormatter.from,
        <Object?>[
          linefmt,
        ],
        <String, Object?>{},
      );

  BufferingFormatter.from(super.pythonClass) : super.from();

  /// ## format
  ///
  /// ### python docstring
  ///
  /// Format the specified records and return the result as a string.
  ///
  /// ### python source
  /// ```py
  /// def format(self, records):
  ///         """
  ///         Format the specified records and return the result as a string.
  ///         """
  ///         rv = ""
  ///         if len(records) > 0:
  ///             rv = rv + self.formatHeader(records)
  ///             for record in records:
  ///                 rv = rv + self.linefmt.format(record)
  ///             rv = rv + self.formatFooter(records)
  ///         return rv
  /// ```
  Object? format({
    required Object? records,
  }) =>
      getFunction("format").call(
        <Object?>[
          records,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## formatFooter
  ///
  /// ### python docstring
  ///
  /// Return the footer string for the specified records.
  ///
  /// ### python source
  /// ```py
  /// def formatFooter(self, records):
  ///         """
  ///         Return the footer string for the specified records.
  ///         """
  ///         return ""
  /// ```
  Object? formatFooter({
    required Object? records,
  }) =>
      getFunction("formatFooter").call(
        <Object?>[
          records,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## formatHeader
  ///
  /// ### python docstring
  ///
  /// Return the header string for the specified records.
  ///
  /// ### python source
  /// ```py
  /// def formatHeader(self, records):
  ///         """
  ///         Return the header string for the specified records.
  ///         """
  ///         return ""
  /// ```
  Object? formatHeader({
    required Object? records,
  }) =>
      getFunction("formatHeader").call(
        <Object?>[
          records,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## linefmt (getter)
  Object? get linefmt => getAttribute("linefmt");

  /// ## linefmt (setter)
  set linefmt(Object? linefmt) => setAttribute("linefmt", linefmt);
}

/// ## FileHandler
///
/// ### python docstring
///
/// A handler class which writes formatted logging records to disk files.
final class FileHandler extends PythonClass {
  factory FileHandler({
    required Object? filename,
    Object? mode = "a",
    Object? encoding,
    Object? delay = false,
    Object? errors,
  }) =>
      PythonFfiDart.instance.importClass(
        "logging",
        "FileHandler",
        FileHandler.from,
        <Object?>[
          filename,
          mode,
          encoding,
          delay,
          errors,
        ],
        <String, Object?>{},
      );

  FileHandler.from(super.pythonClass) : super.from();

  /// ## acquire
  ///
  /// ### python docstring
  ///
  /// Acquire the I/O thread lock.
  ///
  /// ### python source
  /// ```py
  /// def acquire(self):
  ///         """
  ///         Acquire the I/O thread lock.
  ///         """
  ///         if self.lock:
  ///             self.lock.acquire()
  /// ```
  Object? acquire() => getFunction("acquire").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## addFilter
  ///
  /// ### python docstring
  ///
  /// Add the specified filter to this handler.
  ///
  /// ### python source
  /// ```py
  /// def addFilter(self, filter):
  ///         """
  ///         Add the specified filter to this handler.
  ///         """
  ///         if not (filter in self.filters):
  ///             self.filters.append(filter)
  /// ```
  Object? addFilter({
    required Object? filter,
  }) =>
      getFunction("addFilter").call(
        <Object?>[
          filter,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## close
  ///
  /// ### python docstring
  ///
  /// Closes the stream.
  ///
  /// ### python source
  /// ```py
  /// def close(self):
  ///         """
  ///         Closes the stream.
  ///         """
  ///         self.acquire()
  ///         try:
  ///             try:
  ///                 if self.stream:
  ///                     try:
  ///                         self.flush()
  ///                     finally:
  ///                         stream = self.stream
  ///                         self.stream = None
  ///                         if hasattr(stream, "close"):
  ///                             stream.close()
  ///             finally:
  ///                 # Issue #19523: call unconditionally to
  ///                 # prevent a handler leak when delay is set
  ///                 # Also see Issue #42378: we also rely on
  ///                 # self._closed being set to True there
  ///                 StreamHandler.close(self)
  ///         finally:
  ///             self.release()
  /// ```
  Object? close() => getFunction("close").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## createLock
  ///
  /// ### python docstring
  ///
  /// Acquire a thread lock for serializing access to the underlying I/O.
  ///
  /// ### python source
  /// ```py
  /// def createLock(self):
  ///         """
  ///         Acquire a thread lock for serializing access to the underlying I/O.
  ///         """
  ///         self.lock = threading.RLock()
  ///         _register_at_fork_reinit_lock(self)
  /// ```
  Object? createLock() => getFunction("createLock").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## emit
  ///
  /// ### python docstring
  ///
  /// Emit a record.
  ///
  /// If the stream was not opened because 'delay' was specified in the
  /// constructor, open it before calling the superclass's emit.
  ///
  /// If stream is not open, current mode is 'w' and `_closed=True`, record
  /// will not be emitted (see Issue #42378).
  Object? emit({
    required Object? record,
  }) =>
      getFunction("emit").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## filter
  ///
  /// ### python docstring
  ///
  /// Determine if a record is loggable by consulting all the filters.
  ///
  /// The default is to allow the record to be logged; any filter can veto
  /// this and the record is then dropped. Returns a zero value if a record
  /// is to be dropped, else non-zero.
  ///
  /// .. versionchanged:: 3.2
  ///
  ///    Allow filters to be just callables.
  ///
  /// ### python source
  /// ```py
  /// def filter(self, record):
  ///         """
  ///         Determine if a record is loggable by consulting all the filters.
  ///
  ///         The default is to allow the record to be logged; any filter can veto
  ///         this and the record is then dropped. Returns a zero value if a record
  ///         is to be dropped, else non-zero.
  ///
  ///         .. versionchanged:: 3.2
  ///
  ///            Allow filters to be just callables.
  ///         """
  ///         rv = True
  ///         for f in self.filters:
  ///             if hasattr(f, 'filter'):
  ///                 result = f.filter(record)
  ///             else:
  ///                 result = f(record) # assume callable - will raise if not
  ///             if not result:
  ///                 rv = False
  ///                 break
  ///         return rv
  /// ```
  Object? filter({
    required Object? record,
  }) =>
      getFunction("filter").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## flush
  ///
  /// ### python docstring
  ///
  /// Flushes the stream.
  ///
  /// ### python source
  /// ```py
  /// def flush(self):
  ///         """
  ///         Flushes the stream.
  ///         """
  ///         self.acquire()
  ///         try:
  ///             if self.stream and hasattr(self.stream, "flush"):
  ///                 self.stream.flush()
  ///         finally:
  ///             self.release()
  /// ```
  Object? flush() => getFunction("flush").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## format
  ///
  /// ### python docstring
  ///
  /// Format the specified record.
  ///
  /// If a formatter is set, use it. Otherwise, use the default formatter
  /// for the module.
  ///
  /// ### python source
  /// ```py
  /// def format(self, record):
  ///         """
  ///         Format the specified record.
  ///
  ///         If a formatter is set, use it. Otherwise, use the default formatter
  ///         for the module.
  ///         """
  ///         if self.formatter:
  ///             fmt = self.formatter
  ///         else:
  ///             fmt = _defaultFormatter
  ///         return fmt.format(record)
  /// ```
  Object? format({
    required Object? record,
  }) =>
      getFunction("format").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## get_name
  ///
  /// ### python source
  /// ```py
  /// def get_name(self):
  ///         return self._name
  /// ```
  Object? get_name() => getFunction("get_name").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## handle
  ///
  /// ### python docstring
  ///
  /// Conditionally emit the specified logging record.
  ///
  /// Emission depends on filters which may have been added to the handler.
  /// Wrap the actual emission of the record with acquisition/release of
  /// the I/O thread lock. Returns whether the filter passed the record for
  /// emission.
  ///
  /// ### python source
  /// ```py
  /// def handle(self, record):
  ///         """
  ///         Conditionally emit the specified logging record.
  ///
  ///         Emission depends on filters which may have been added to the handler.
  ///         Wrap the actual emission of the record with acquisition/release of
  ///         the I/O thread lock. Returns whether the filter passed the record for
  ///         emission.
  ///         """
  ///         rv = self.filter(record)
  ///         if rv:
  ///             self.acquire()
  ///             try:
  ///                 self.emit(record)
  ///             finally:
  ///                 self.release()
  ///         return rv
  /// ```
  Object? handle({
    required Object? record,
  }) =>
      getFunction("handle").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## handleError
  ///
  /// ### python docstring
  ///
  /// Handle errors which occur during an emit() call.
  ///
  /// This method should be called from handlers when an exception is
  /// encountered during an emit() call. If raiseExceptions is false,
  /// exceptions get silently ignored. This is what is mostly wanted
  /// for a logging system - most users will not care about errors in
  /// the logging system, they are more interested in application errors.
  /// You could, however, replace this with a custom handler if you wish.
  /// The record which was being processed is passed in to this method.
  ///
  /// ### python source
  /// ```py
  /// def handleError(self, record):
  ///         """
  ///         Handle errors which occur during an emit() call.
  ///
  ///         This method should be called from handlers when an exception is
  ///         encountered during an emit() call. If raiseExceptions is false,
  ///         exceptions get silently ignored. This is what is mostly wanted
  ///         for a logging system - most users will not care about errors in
  ///         the logging system, they are more interested in application errors.
  ///         You could, however, replace this with a custom handler if you wish.
  ///         The record which was being processed is passed in to this method.
  ///         """
  ///         if raiseExceptions and sys.stderr:  # see issue 13807
  ///             t, v, tb = sys.exc_info()
  ///             try:
  ///                 sys.stderr.write('--- Logging error ---\n')
  ///                 traceback.print_exception(t, v, tb, None, sys.stderr)
  ///                 sys.stderr.write('Call stack:\n')
  ///                 # Walk the stack frame up until we're out of logging,
  ///                 # so as to print the calling context.
  ///                 frame = tb.tb_frame
  ///                 while (frame and os.path.dirname(frame.f_code.co_filename) ==
  ///                        __path__[0]):
  ///                     frame = frame.f_back
  ///                 if frame:
  ///                     traceback.print_stack(frame, file=sys.stderr)
  ///                 else:
  ///                     # couldn't find the right stack frame, for some reason
  ///                     sys.stderr.write('Logged from file %s, line %s\n' % (
  ///                                      record.filename, record.lineno))
  ///                 # Issue 18671: output logging message and arguments
  ///                 try:
  ///                     sys.stderr.write('Message: %r\n'
  ///                                      'Arguments: %s\n' % (record.msg,
  ///                                                           record.args))
  ///                 except RecursionError:  # See issue 36272
  ///                     raise
  ///                 except Exception:
  ///                     sys.stderr.write('Unable to print the message and arguments'
  ///                                      ' - possible formatting error.\nUse the'
  ///                                      ' traceback above to help find the error.\n'
  ///                                     )
  ///             except OSError: #pragma: no cover
  ///                 pass    # see issue 5971
  ///             finally:
  ///                 del t, v, tb
  /// ```
  Object? handleError({
    required Object? record,
  }) =>
      getFunction("handleError").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## release
  ///
  /// ### python docstring
  ///
  /// Release the I/O thread lock.
  ///
  /// ### python source
  /// ```py
  /// def release(self):
  ///         """
  ///         Release the I/O thread lock.
  ///         """
  ///         if self.lock:
  ///             self.lock.release()
  /// ```
  Object? release() => getFunction("release").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## removeFilter
  ///
  /// ### python docstring
  ///
  /// Remove the specified filter from this handler.
  ///
  /// ### python source
  /// ```py
  /// def removeFilter(self, filter):
  ///         """
  ///         Remove the specified filter from this handler.
  ///         """
  ///         if filter in self.filters:
  ///             self.filters.remove(filter)
  /// ```
  Object? removeFilter({
    required Object? filter,
  }) =>
      getFunction("removeFilter").call(
        <Object?>[
          filter,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## setFormatter
  ///
  /// ### python docstring
  ///
  /// Set the formatter for this handler.
  ///
  /// ### python source
  /// ```py
  /// def setFormatter(self, fmt):
  ///         """
  ///         Set the formatter for this handler.
  ///         """
  ///         self.formatter = fmt
  /// ```
  Object? setFormatter({
    required Object? fmt,
  }) =>
      getFunction("setFormatter").call(
        <Object?>[
          fmt,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## setLevel
  ///
  /// ### python docstring
  ///
  /// Set the logging level of this handler.  level must be an int or a str.
  ///
  /// ### python source
  /// ```py
  /// def setLevel(self, level):
  ///         """
  ///         Set the logging level of this handler.  level must be an int or a str.
  ///         """
  ///         self.level = _checkLevel(level)
  /// ```
  Object? setLevel({
    required Object? level,
  }) =>
      getFunction("setLevel").call(
        <Object?>[
          level,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## setStream
  ///
  /// ### python docstring
  ///
  /// Sets the StreamHandler's stream to the specified value,
  /// if it is different.
  ///
  /// Returns the old stream, if the stream was changed, or None
  /// if it wasn't.
  ///
  /// ### python source
  /// ```py
  /// def setStream(self, stream):
  ///         """
  ///         Sets the StreamHandler's stream to the specified value,
  ///         if it is different.
  ///
  ///         Returns the old stream, if the stream was changed, or None
  ///         if it wasn't.
  ///         """
  ///         if stream is self.stream:
  ///             result = None
  ///         else:
  ///             result = self.stream
  ///             self.acquire()
  ///             try:
  ///                 self.flush()
  ///                 self.stream = stream
  ///             finally:
  ///                 self.release()
  ///         return result
  /// ```
  Object? setStream({
    required Object? stream,
  }) =>
      getFunction("setStream").call(
        <Object?>[
          stream,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## fset
  ///
  /// ### python source
  /// ```py
  /// def set_name(self, name):
  ///         _acquireLock()
  ///         try:
  ///             if self._name in _handlers:
  ///                 del _handlers[self._name]
  ///             self._name = name
  ///             if name:
  ///                 _handlers[name] = self
  ///         finally:
  ///             _releaseLock()
  /// ```
  Object? fset({
    required Object? name,
  }) =>
      getFunction("fset").call(
        <Object?>[
          name,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);

  /// ## terminator (getter)
  Object? get terminator => getAttribute("terminator");

  /// ## terminator (setter)
  set terminator(Object? terminator) => setAttribute("terminator", terminator);

  /// ## baseFilename (getter)
  Object? get baseFilename => getAttribute("baseFilename");

  /// ## baseFilename (setter)
  set baseFilename(Object? baseFilename) =>
      setAttribute("baseFilename", baseFilename);

  /// ## mode (getter)
  Object? get mode => getAttribute("mode");

  /// ## mode (setter)
  set mode(Object? mode) => setAttribute("mode", mode);

  /// ## encoding (getter)
  Object? get encoding => getAttribute("encoding");

  /// ## encoding (setter)
  set encoding(Object? encoding) => setAttribute("encoding", encoding);

  /// ## errors (getter)
  Object? get errors => getAttribute("errors");

  /// ## errors (setter)
  set errors(Object? errors) => setAttribute("errors", errors);

  /// ## delay (getter)
  Object? get delay => getAttribute("delay");

  /// ## delay (setter)
  set delay(Object? delay) => setAttribute("delay", delay);

  /// ## stream (getter)
  Object? get stream => getAttribute("stream");

  /// ## stream (setter)
  set stream(Object? stream) => setAttribute("stream", stream);
}

/// ## Filter
///
/// ### python docstring
///
/// Filter instances are used to perform arbitrary filtering of LogRecords.
///
/// Loggers and Handlers can optionally use Filter instances to filter
/// records as desired. The base filter class only allows events which are
/// below a certain point in the logger hierarchy. For example, a filter
/// initialized with "A.B" will allow events logged by loggers "A.B",
/// "A.B.C", "A.B.C.D", "A.B.D" etc. but not "A.BB", "B.A.B" etc. If
/// initialized with the empty string, all events are passed.
///
/// ### python source
/// ```py
/// class Filter(object):
///     """
///     Filter instances are used to perform arbitrary filtering of LogRecords.
///
///     Loggers and Handlers can optionally use Filter instances to filter
///     records as desired. The base filter class only allows events which are
///     below a certain point in the logger hierarchy. For example, a filter
///     initialized with "A.B" will allow events logged by loggers "A.B",
///     "A.B.C", "A.B.C.D", "A.B.D" etc. but not "A.BB", "B.A.B" etc. If
///     initialized with the empty string, all events are passed.
///     """
///     def __init__(self, name=''):
///         """
///         Initialize a filter.
///
///         Initialize with the name of the logger which, together with its
///         children, will have its events allowed through the filter. If no
///         name is specified, allow every event.
///         """
///         self.name = name
///         self.nlen = len(name)
///
///     def filter(self, record):
///         """
///         Determine if the specified record is to be logged.
///
///         Returns True if the record should be logged, or False otherwise.
///         If deemed appropriate, the record may be modified in-place.
///         """
///         if self.nlen == 0:
///             return True
///         elif self.name == record.name:
///             return True
///         elif record.name.find(self.name, 0, self.nlen) != 0:
///             return False
///         return (record.name[self.nlen] == ".")
/// ```
final class Filter extends PythonClass {
  factory Filter({
    Object? name = "",
  }) =>
      PythonFfiDart.instance.importClass(
        "logging",
        "Filter",
        Filter.from,
        <Object?>[
          name,
        ],
        <String, Object?>{},
      );

  Filter.from(super.pythonClass) : super.from();

  /// ## filter
  ///
  /// ### python docstring
  ///
  /// Determine if the specified record is to be logged.
  ///
  /// Returns True if the record should be logged, or False otherwise.
  /// If deemed appropriate, the record may be modified in-place.
  ///
  /// ### python source
  /// ```py
  /// def filter(self, record):
  ///         """
  ///         Determine if the specified record is to be logged.
  ///
  ///         Returns True if the record should be logged, or False otherwise.
  ///         If deemed appropriate, the record may be modified in-place.
  ///         """
  ///         if self.nlen == 0:
  ///             return True
  ///         elif self.name == record.name:
  ///             return True
  ///         elif record.name.find(self.name, 0, self.nlen) != 0:
  ///             return False
  ///         return (record.name[self.nlen] == ".")
  /// ```
  Object? filter({
    required Object? record,
  }) =>
      getFunction("filter").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);

  /// ## nlen (getter)
  Object? get nlen => getAttribute("nlen");

  /// ## nlen (setter)
  set nlen(Object? nlen) => setAttribute("nlen", nlen);
}

/// ## Filterer
///
/// ### python docstring
///
/// A base class for loggers and handlers which allows them to share
/// common code.
///
/// ### python source
/// ```py
/// class Filterer(object):
///     """
///     A base class for loggers and handlers which allows them to share
///     common code.
///     """
///     def __init__(self):
///         """
///         Initialize the list of filters to be an empty list.
///         """
///         self.filters = []
///
///     def addFilter(self, filter):
///         """
///         Add the specified filter to this handler.
///         """
///         if not (filter in self.filters):
///             self.filters.append(filter)
///
///     def removeFilter(self, filter):
///         """
///         Remove the specified filter from this handler.
///         """
///         if filter in self.filters:
///             self.filters.remove(filter)
///
///     def filter(self, record):
///         """
///         Determine if a record is loggable by consulting all the filters.
///
///         The default is to allow the record to be logged; any filter can veto
///         this and the record is then dropped. Returns a zero value if a record
///         is to be dropped, else non-zero.
///
///         .. versionchanged:: 3.2
///
///            Allow filters to be just callables.
///         """
///         rv = True
///         for f in self.filters:
///             if hasattr(f, 'filter'):
///                 result = f.filter(record)
///             else:
///                 result = f(record) # assume callable - will raise if not
///             if not result:
///                 rv = False
///                 break
///         return rv
/// ```
final class Filterer extends PythonClass {
  factory Filterer() => PythonFfiDart.instance.importClass(
        "logging",
        "Filterer",
        Filterer.from,
        <Object?>[],
        <String, Object?>{},
      );

  Filterer.from(super.pythonClass) : super.from();

  /// ## addFilter
  ///
  /// ### python docstring
  ///
  /// Add the specified filter to this handler.
  ///
  /// ### python source
  /// ```py
  /// def addFilter(self, filter):
  ///         """
  ///         Add the specified filter to this handler.
  ///         """
  ///         if not (filter in self.filters):
  ///             self.filters.append(filter)
  /// ```
  Object? addFilter({
    required Object? filter,
  }) =>
      getFunction("addFilter").call(
        <Object?>[
          filter,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## filter
  ///
  /// ### python docstring
  ///
  /// Determine if a record is loggable by consulting all the filters.
  ///
  /// The default is to allow the record to be logged; any filter can veto
  /// this and the record is then dropped. Returns a zero value if a record
  /// is to be dropped, else non-zero.
  ///
  /// .. versionchanged:: 3.2
  ///
  ///    Allow filters to be just callables.
  ///
  /// ### python source
  /// ```py
  /// def filter(self, record):
  ///         """
  ///         Determine if a record is loggable by consulting all the filters.
  ///
  ///         The default is to allow the record to be logged; any filter can veto
  ///         this and the record is then dropped. Returns a zero value if a record
  ///         is to be dropped, else non-zero.
  ///
  ///         .. versionchanged:: 3.2
  ///
  ///            Allow filters to be just callables.
  ///         """
  ///         rv = True
  ///         for f in self.filters:
  ///             if hasattr(f, 'filter'):
  ///                 result = f.filter(record)
  ///             else:
  ///                 result = f(record) # assume callable - will raise if not
  ///             if not result:
  ///                 rv = False
  ///                 break
  ///         return rv
  /// ```
  Object? filter({
    required Object? record,
  }) =>
      getFunction("filter").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## removeFilter
  ///
  /// ### python docstring
  ///
  /// Remove the specified filter from this handler.
  ///
  /// ### python source
  /// ```py
  /// def removeFilter(self, filter):
  ///         """
  ///         Remove the specified filter from this handler.
  ///         """
  ///         if filter in self.filters:
  ///             self.filters.remove(filter)
  /// ```
  Object? removeFilter({
    required Object? filter,
  }) =>
      getFunction("removeFilter").call(
        <Object?>[
          filter,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## filters (getter)
  Object? get filters => getAttribute("filters");

  /// ## filters (setter)
  set filters(Object? filters) => setAttribute("filters", filters);
}

/// ## Formatter
///
/// ### python docstring
///
/// Formatter instances are used to convert a LogRecord to text.
///
/// Formatters need to know how a LogRecord is constructed. They are
/// responsible for converting a LogRecord to (usually) a string which can
/// be interpreted by either a human or an external system. The base Formatter
/// allows a formatting string to be specified. If none is supplied, the
/// style-dependent default value, "%(message)s", "{message}", or
/// "${message}", is used.
///
/// The Formatter can be initialized with a format string which makes use of
/// knowledge of the LogRecord attributes - e.g. the default value mentioned
/// above makes use of the fact that the user's message and arguments are pre-
/// formatted into a LogRecord's message attribute. Currently, the useful
/// attributes in a LogRecord are described by:
///
/// %(name)s            Name of the logger (logging channel)
/// %(levelno)s         Numeric logging level for the message (DEBUG, INFO,
///                     WARNING, ERROR, CRITICAL)
/// %(levelname)s       Text logging level for the message ("DEBUG", "INFO",
///                     "WARNING", "ERROR", "CRITICAL")
/// %(pathname)s        Full pathname of the source file where the logging
///                     call was issued (if available)
/// %(filename)s        Filename portion of pathname
/// %(module)s          Module (name portion of filename)
/// %(lineno)d          Source line number where the logging call was issued
///                     (if available)
/// %(funcName)s        Function name
/// %(created)f         Time when the LogRecord was created (time.time()
///                     return value)
/// %(asctime)s         Textual time when the LogRecord was created
/// %(msecs)d           Millisecond portion of the creation time
/// %(relativeCreated)d Time in milliseconds when the LogRecord was created,
///                     relative to the time the logging module was loaded
///                     (typically at application startup time)
/// %(thread)d          Thread ID (if available)
/// %(threadName)s      Thread name (if available)
/// %(process)d         Process ID (if available)
/// %(message)s         The result of record.getMessage(), computed just as
///                     the record is emitted
final class Formatter extends PythonClass {
  factory Formatter({
    Object? fmt,
    Object? datefmt,
    Object? style = "%",
    Object? validate = true,
    Object? defaults,
  }) =>
      PythonFfiDart.instance.importClass(
        "logging",
        "Formatter",
        Formatter.from,
        <Object?>[
          fmt,
          datefmt,
          style,
          validate,
        ],
        <String, Object?>{
          "defaults": defaults,
        },
      );

  Formatter.from(super.pythonClass) : super.from();

  /// ## format
  ///
  /// ### python docstring
  ///
  /// Format the specified record as text.
  ///
  /// The record's attribute dictionary is used as the operand to a
  /// string formatting operation which yields the returned string.
  /// Before formatting the dictionary, a couple of preparatory steps
  /// are carried out. The message attribute of the record is computed
  /// using LogRecord.getMessage(). If the formatting string uses the
  /// time (as determined by a call to usesTime(), formatTime() is
  /// called to format the event time. If there is exception information,
  /// it is formatted using formatException() and appended to the message.
  Object? format({
    required Object? record,
  }) =>
      getFunction("format").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## formatException
  ///
  /// ### python docstring
  ///
  /// Format and return the specified exception information as a string.
  ///
  /// This default implementation just uses
  /// traceback.print_exception()
  ///
  /// ### python source
  /// ```py
  /// def formatException(self, ei):
  ///         """
  ///         Format and return the specified exception information as a string.
  ///
  ///         This default implementation just uses
  ///         traceback.print_exception()
  ///         """
  ///         sio = io.StringIO()
  ///         tb = ei[2]
  ///         # See issues #9427, #1553375. Commented out for now.
  ///         #if getattr(self, 'fullstack', False):
  ///         #    traceback.print_stack(tb.tb_frame.f_back, file=sio)
  ///         traceback.print_exception(ei[0], ei[1], tb, None, sio)
  ///         s = sio.getvalue()
  ///         sio.close()
  ///         if s[-1:] == "\n":
  ///             s = s[:-1]
  ///         return s
  /// ```
  Object? formatException({
    required Object? ei,
  }) =>
      getFunction("formatException").call(
        <Object?>[
          ei,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## formatMessage
  ///
  /// ### python source
  /// ```py
  /// def formatMessage(self, record):
  ///         return self._style.format(record)
  /// ```
  Object? formatMessage({
    required Object? record,
  }) =>
      getFunction("formatMessage").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## formatStack
  ///
  /// ### python docstring
  ///
  /// This method is provided as an extension point for specialized
  /// formatting of stack information.
  ///
  /// The input data is a string as returned from a call to
  /// :func:`traceback.print_stack`, but with the last trailing newline
  /// removed.
  ///
  /// The base implementation just returns the value passed in.
  ///
  /// ### python source
  /// ```py
  /// def formatStack(self, stack_info):
  ///         """
  ///         This method is provided as an extension point for specialized
  ///         formatting of stack information.
  ///
  ///         The input data is a string as returned from a call to
  ///         :func:`traceback.print_stack`, but with the last trailing newline
  ///         removed.
  ///
  ///         The base implementation just returns the value passed in.
  ///         """
  ///         return stack_info
  /// ```
  Object? formatStack({
    required Object? stack_info,
  }) =>
      getFunction("formatStack").call(
        <Object?>[
          stack_info,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## formatTime
  ///
  /// ### python docstring
  ///
  /// Return the creation time of the specified LogRecord as formatted text.
  ///
  /// This method should be called from format() by a formatter which
  /// wants to make use of a formatted time. This method can be overridden
  /// in formatters to provide for any specific requirement, but the
  /// basic behaviour is as follows: if datefmt (a string) is specified,
  /// it is used with time.strftime() to format the creation time of the
  /// record. Otherwise, an ISO8601-like (or RFC 3339-like) format is used.
  /// The resulting string is returned. This function uses a user-configurable
  /// function to convert the creation time to a tuple. By default,
  /// time.localtime() is used; to change this for a particular formatter
  /// instance, set the 'converter' attribute to a function with the same
  /// signature as time.localtime() or time.gmtime(). To change it for all
  /// formatters, for example if you want all logging times to be shown in GMT,
  /// set the 'converter' attribute in the Formatter class.
  ///
  /// ### python source
  /// ```py
  /// def formatTime(self, record, datefmt=None):
  ///         """
  ///         Return the creation time of the specified LogRecord as formatted text.
  ///
  ///         This method should be called from format() by a formatter which
  ///         wants to make use of a formatted time. This method can be overridden
  ///         in formatters to provide for any specific requirement, but the
  ///         basic behaviour is as follows: if datefmt (a string) is specified,
  ///         it is used with time.strftime() to format the creation time of the
  ///         record. Otherwise, an ISO8601-like (or RFC 3339-like) format is used.
  ///         The resulting string is returned. This function uses a user-configurable
  ///         function to convert the creation time to a tuple. By default,
  ///         time.localtime() is used; to change this for a particular formatter
  ///         instance, set the 'converter' attribute to a function with the same
  ///         signature as time.localtime() or time.gmtime(). To change it for all
  ///         formatters, for example if you want all logging times to be shown in GMT,
  ///         set the 'converter' attribute in the Formatter class.
  ///         """
  ///         ct = self.converter(record.created)
  ///         if datefmt:
  ///             s = time.strftime(datefmt, ct)
  ///         else:
  ///             s = time.strftime(self.default_time_format, ct)
  ///             if self.default_msec_format:
  ///                 s = self.default_msec_format % (s, record.msecs)
  ///         return s
  /// ```
  Object? formatTime({
    required Object? record,
    Object? datefmt,
  }) =>
      getFunction("formatTime").call(
        <Object?>[
          record,
          datefmt,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## usesTime
  ///
  /// ### python docstring
  ///
  /// Check if the format uses the creation time of the record.
  ///
  /// ### python source
  /// ```py
  /// def usesTime(self):
  ///         """
  ///         Check if the format uses the creation time of the record.
  ///         """
  ///         return self._style.usesTime()
  /// ```
  Object? usesTime() => getFunction("usesTime").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## default_msec_format (getter)
  Object? get default_msec_format => getAttribute("default_msec_format");

  /// ## default_msec_format (setter)
  set default_msec_format(Object? default_msec_format) =>
      setAttribute("default_msec_format", default_msec_format);

  /// ## default_time_format (getter)
  Object? get default_time_format => getAttribute("default_time_format");

  /// ## default_time_format (setter)
  set default_time_format(Object? default_time_format) =>
      setAttribute("default_time_format", default_time_format);

  /// ## datefmt (getter)
  Object? get datefmt => getAttribute("datefmt");

  /// ## datefmt (setter)
  set datefmt(Object? datefmt) => setAttribute("datefmt", datefmt);
}

/// ## Handler
///
/// ### python docstring
///
/// Handler instances dispatch logging events to specific destinations.
///
/// The base handler class. Acts as a placeholder which defines the Handler
/// interface. Handlers can optionally use Formatter instances to format
/// records as desired. By default, no formatter is specified; in this case,
/// the 'raw' message as determined by record.message is logged.
///
/// ### python source
/// ```py
/// class Handler(Filterer):
///     """
///     Handler instances dispatch logging events to specific destinations.
///
///     The base handler class. Acts as a placeholder which defines the Handler
///     interface. Handlers can optionally use Formatter instances to format
///     records as desired. By default, no formatter is specified; in this case,
///     the 'raw' message as determined by record.message is logged.
///     """
///     def __init__(self, level=NOTSET):
///         """
///         Initializes the instance - basically setting the formatter to None
///         and the filter list to empty.
///         """
///         Filterer.__init__(self)
///         self._name = None
///         self.level = _checkLevel(level)
///         self.formatter = None
///         self._closed = False
///         # Add the handler to the global _handlerList (for cleanup on shutdown)
///         _addHandlerRef(self)
///         self.createLock()
///
///     def get_name(self):
///         return self._name
///
///     def set_name(self, name):
///         _acquireLock()
///         try:
///             if self._name in _handlers:
///                 del _handlers[self._name]
///             self._name = name
///             if name:
///                 _handlers[name] = self
///         finally:
///             _releaseLock()
///
///     name = property(get_name, set_name)
///
///     def createLock(self):
///         """
///         Acquire a thread lock for serializing access to the underlying I/O.
///         """
///         self.lock = threading.RLock()
///         _register_at_fork_reinit_lock(self)
///
///     def _at_fork_reinit(self):
///         self.lock._at_fork_reinit()
///
///     def acquire(self):
///         """
///         Acquire the I/O thread lock.
///         """
///         if self.lock:
///             self.lock.acquire()
///
///     def release(self):
///         """
///         Release the I/O thread lock.
///         """
///         if self.lock:
///             self.lock.release()
///
///     def setLevel(self, level):
///         """
///         Set the logging level of this handler.  level must be an int or a str.
///         """
///         self.level = _checkLevel(level)
///
///     def format(self, record):
///         """
///         Format the specified record.
///
///         If a formatter is set, use it. Otherwise, use the default formatter
///         for the module.
///         """
///         if self.formatter:
///             fmt = self.formatter
///         else:
///             fmt = _defaultFormatter
///         return fmt.format(record)
///
///     def emit(self, record):
///         """
///         Do whatever it takes to actually log the specified logging record.
///
///         This version is intended to be implemented by subclasses and so
///         raises a NotImplementedError.
///         """
///         raise NotImplementedError('emit must be implemented '
///                                   'by Handler subclasses')
///
///     def handle(self, record):
///         """
///         Conditionally emit the specified logging record.
///
///         Emission depends on filters which may have been added to the handler.
///         Wrap the actual emission of the record with acquisition/release of
///         the I/O thread lock. Returns whether the filter passed the record for
///         emission.
///         """
///         rv = self.filter(record)
///         if rv:
///             self.acquire()
///             try:
///                 self.emit(record)
///             finally:
///                 self.release()
///         return rv
///
///     def setFormatter(self, fmt):
///         """
///         Set the formatter for this handler.
///         """
///         self.formatter = fmt
///
///     def flush(self):
///         """
///         Ensure all logging output has been flushed.
///
///         This version does nothing and is intended to be implemented by
///         subclasses.
///         """
///         pass
///
///     def close(self):
///         """
///         Tidy up any resources used by the handler.
///
///         This version removes the handler from an internal map of handlers,
///         _handlers, which is used for handler lookup by name. Subclasses
///         should ensure that this gets called from overridden close()
///         methods.
///         """
///         #get the module data lock, as we're updating a shared structure.
///         _acquireLock()
///         try:    #unlikely to raise an exception, but you never know...
///             self._closed = True
///             if self._name and self._name in _handlers:
///                 del _handlers[self._name]
///         finally:
///             _releaseLock()
///
///     def handleError(self, record):
///         """
///         Handle errors which occur during an emit() call.
///
///         This method should be called from handlers when an exception is
///         encountered during an emit() call. If raiseExceptions is false,
///         exceptions get silently ignored. This is what is mostly wanted
///         for a logging system - most users will not care about errors in
///         the logging system, they are more interested in application errors.
///         You could, however, replace this with a custom handler if you wish.
///         The record which was being processed is passed in to this method.
///         """
///         if raiseExceptions and sys.stderr:  # see issue 13807
///             t, v, tb = sys.exc_info()
///             try:
///                 sys.stderr.write('--- Logging error ---\n')
///                 traceback.print_exception(t, v, tb, None, sys.stderr)
///                 sys.stderr.write('Call stack:\n')
///                 # Walk the stack frame up until we're out of logging,
///                 # so as to print the calling context.
///                 frame = tb.tb_frame
///                 while (frame and os.path.dirname(frame.f_code.co_filename) ==
///                        __path__[0]):
///                     frame = frame.f_back
///                 if frame:
///                     traceback.print_stack(frame, file=sys.stderr)
///                 else:
///                     # couldn't find the right stack frame, for some reason
///                     sys.stderr.write('Logged from file %s, line %s\n' % (
///                                      record.filename, record.lineno))
///                 # Issue 18671: output logging message and arguments
///                 try:
///                     sys.stderr.write('Message: %r\n'
///                                      'Arguments: %s\n' % (record.msg,
///                                                           record.args))
///                 except RecursionError:  # See issue 36272
///                     raise
///                 except Exception:
///                     sys.stderr.write('Unable to print the message and arguments'
///                                      ' - possible formatting error.\nUse the'
///                                      ' traceback above to help find the error.\n'
///                                     )
///             except OSError: #pragma: no cover
///                 pass    # see issue 5971
///             finally:
///                 del t, v, tb
///
///     def __repr__(self):
///         level = getLevelName(self.level)
///         return '<%s (%s)>' % (self.__class__.__name__, level)
/// ```
final class Handler extends PythonClass {
  factory Handler({
    Object? level = 0,
  }) =>
      PythonFfiDart.instance.importClass(
        "logging",
        "Handler",
        Handler.from,
        <Object?>[
          level,
        ],
        <String, Object?>{},
      );

  Handler.from(super.pythonClass) : super.from();

  /// ## acquire
  ///
  /// ### python docstring
  ///
  /// Acquire the I/O thread lock.
  ///
  /// ### python source
  /// ```py
  /// def acquire(self):
  ///         """
  ///         Acquire the I/O thread lock.
  ///         """
  ///         if self.lock:
  ///             self.lock.acquire()
  /// ```
  Object? acquire() => getFunction("acquire").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## addFilter
  ///
  /// ### python docstring
  ///
  /// Add the specified filter to this handler.
  ///
  /// ### python source
  /// ```py
  /// def addFilter(self, filter):
  ///         """
  ///         Add the specified filter to this handler.
  ///         """
  ///         if not (filter in self.filters):
  ///             self.filters.append(filter)
  /// ```
  Object? addFilter({
    required Object? filter,
  }) =>
      getFunction("addFilter").call(
        <Object?>[
          filter,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## close
  ///
  /// ### python docstring
  ///
  /// Tidy up any resources used by the handler.
  ///
  /// This version removes the handler from an internal map of handlers,
  /// _handlers, which is used for handler lookup by name. Subclasses
  /// should ensure that this gets called from overridden close()
  /// methods.
  ///
  /// ### python source
  /// ```py
  /// def close(self):
  ///         """
  ///         Tidy up any resources used by the handler.
  ///
  ///         This version removes the handler from an internal map of handlers,
  ///         _handlers, which is used for handler lookup by name. Subclasses
  ///         should ensure that this gets called from overridden close()
  ///         methods.
  ///         """
  ///         #get the module data lock, as we're updating a shared structure.
  ///         _acquireLock()
  ///         try:    #unlikely to raise an exception, but you never know...
  ///             self._closed = True
  ///             if self._name and self._name in _handlers:
  ///                 del _handlers[self._name]
  ///         finally:
  ///             _releaseLock()
  /// ```
  Object? close() => getFunction("close").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## createLock
  ///
  /// ### python docstring
  ///
  /// Acquire a thread lock for serializing access to the underlying I/O.
  ///
  /// ### python source
  /// ```py
  /// def createLock(self):
  ///         """
  ///         Acquire a thread lock for serializing access to the underlying I/O.
  ///         """
  ///         self.lock = threading.RLock()
  ///         _register_at_fork_reinit_lock(self)
  /// ```
  Object? createLock() => getFunction("createLock").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## emit
  ///
  /// ### python docstring
  ///
  /// Do whatever it takes to actually log the specified logging record.
  ///
  /// This version is intended to be implemented by subclasses and so
  /// raises a NotImplementedError.
  ///
  /// ### python source
  /// ```py
  /// def emit(self, record):
  ///         """
  ///         Do whatever it takes to actually log the specified logging record.
  ///
  ///         This version is intended to be implemented by subclasses and so
  ///         raises a NotImplementedError.
  ///         """
  ///         raise NotImplementedError('emit must be implemented '
  ///                                   'by Handler subclasses')
  /// ```
  Object? emit({
    required Object? record,
  }) =>
      getFunction("emit").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## filter
  ///
  /// ### python docstring
  ///
  /// Determine if a record is loggable by consulting all the filters.
  ///
  /// The default is to allow the record to be logged; any filter can veto
  /// this and the record is then dropped. Returns a zero value if a record
  /// is to be dropped, else non-zero.
  ///
  /// .. versionchanged:: 3.2
  ///
  ///    Allow filters to be just callables.
  ///
  /// ### python source
  /// ```py
  /// def filter(self, record):
  ///         """
  ///         Determine if a record is loggable by consulting all the filters.
  ///
  ///         The default is to allow the record to be logged; any filter can veto
  ///         this and the record is then dropped. Returns a zero value if a record
  ///         is to be dropped, else non-zero.
  ///
  ///         .. versionchanged:: 3.2
  ///
  ///            Allow filters to be just callables.
  ///         """
  ///         rv = True
  ///         for f in self.filters:
  ///             if hasattr(f, 'filter'):
  ///                 result = f.filter(record)
  ///             else:
  ///                 result = f(record) # assume callable - will raise if not
  ///             if not result:
  ///                 rv = False
  ///                 break
  ///         return rv
  /// ```
  Object? filter({
    required Object? record,
  }) =>
      getFunction("filter").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## flush
  ///
  /// ### python docstring
  ///
  /// Ensure all logging output has been flushed.
  ///
  /// This version does nothing and is intended to be implemented by
  /// subclasses.
  ///
  /// ### python source
  /// ```py
  /// def flush(self):
  ///         """
  ///         Ensure all logging output has been flushed.
  ///
  ///         This version does nothing and is intended to be implemented by
  ///         subclasses.
  ///         """
  ///         pass
  /// ```
  Object? flush() => getFunction("flush").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## format
  ///
  /// ### python docstring
  ///
  /// Format the specified record.
  ///
  /// If a formatter is set, use it. Otherwise, use the default formatter
  /// for the module.
  ///
  /// ### python source
  /// ```py
  /// def format(self, record):
  ///         """
  ///         Format the specified record.
  ///
  ///         If a formatter is set, use it. Otherwise, use the default formatter
  ///         for the module.
  ///         """
  ///         if self.formatter:
  ///             fmt = self.formatter
  ///         else:
  ///             fmt = _defaultFormatter
  ///         return fmt.format(record)
  /// ```
  Object? format({
    required Object? record,
  }) =>
      getFunction("format").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## get_name
  ///
  /// ### python source
  /// ```py
  /// def get_name(self):
  ///         return self._name
  /// ```
  Object? get_name() => getFunction("get_name").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## handle
  ///
  /// ### python docstring
  ///
  /// Conditionally emit the specified logging record.
  ///
  /// Emission depends on filters which may have been added to the handler.
  /// Wrap the actual emission of the record with acquisition/release of
  /// the I/O thread lock. Returns whether the filter passed the record for
  /// emission.
  ///
  /// ### python source
  /// ```py
  /// def handle(self, record):
  ///         """
  ///         Conditionally emit the specified logging record.
  ///
  ///         Emission depends on filters which may have been added to the handler.
  ///         Wrap the actual emission of the record with acquisition/release of
  ///         the I/O thread lock. Returns whether the filter passed the record for
  ///         emission.
  ///         """
  ///         rv = self.filter(record)
  ///         if rv:
  ///             self.acquire()
  ///             try:
  ///                 self.emit(record)
  ///             finally:
  ///                 self.release()
  ///         return rv
  /// ```
  Object? handle({
    required Object? record,
  }) =>
      getFunction("handle").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## handleError
  ///
  /// ### python docstring
  ///
  /// Handle errors which occur during an emit() call.
  ///
  /// This method should be called from handlers when an exception is
  /// encountered during an emit() call. If raiseExceptions is false,
  /// exceptions get silently ignored. This is what is mostly wanted
  /// for a logging system - most users will not care about errors in
  /// the logging system, they are more interested in application errors.
  /// You could, however, replace this with a custom handler if you wish.
  /// The record which was being processed is passed in to this method.
  ///
  /// ### python source
  /// ```py
  /// def handleError(self, record):
  ///         """
  ///         Handle errors which occur during an emit() call.
  ///
  ///         This method should be called from handlers when an exception is
  ///         encountered during an emit() call. If raiseExceptions is false,
  ///         exceptions get silently ignored. This is what is mostly wanted
  ///         for a logging system - most users will not care about errors in
  ///         the logging system, they are more interested in application errors.
  ///         You could, however, replace this with a custom handler if you wish.
  ///         The record which was being processed is passed in to this method.
  ///         """
  ///         if raiseExceptions and sys.stderr:  # see issue 13807
  ///             t, v, tb = sys.exc_info()
  ///             try:
  ///                 sys.stderr.write('--- Logging error ---\n')
  ///                 traceback.print_exception(t, v, tb, None, sys.stderr)
  ///                 sys.stderr.write('Call stack:\n')
  ///                 # Walk the stack frame up until we're out of logging,
  ///                 # so as to print the calling context.
  ///                 frame = tb.tb_frame
  ///                 while (frame and os.path.dirname(frame.f_code.co_filename) ==
  ///                        __path__[0]):
  ///                     frame = frame.f_back
  ///                 if frame:
  ///                     traceback.print_stack(frame, file=sys.stderr)
  ///                 else:
  ///                     # couldn't find the right stack frame, for some reason
  ///                     sys.stderr.write('Logged from file %s, line %s\n' % (
  ///                                      record.filename, record.lineno))
  ///                 # Issue 18671: output logging message and arguments
  ///                 try:
  ///                     sys.stderr.write('Message: %r\n'
  ///                                      'Arguments: %s\n' % (record.msg,
  ///                                                           record.args))
  ///                 except RecursionError:  # See issue 36272
  ///                     raise
  ///                 except Exception:
  ///                     sys.stderr.write('Unable to print the message and arguments'
  ///                                      ' - possible formatting error.\nUse the'
  ///                                      ' traceback above to help find the error.\n'
  ///                                     )
  ///             except OSError: #pragma: no cover
  ///                 pass    # see issue 5971
  ///             finally:
  ///                 del t, v, tb
  /// ```
  Object? handleError({
    required Object? record,
  }) =>
      getFunction("handleError").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## release
  ///
  /// ### python docstring
  ///
  /// Release the I/O thread lock.
  ///
  /// ### python source
  /// ```py
  /// def release(self):
  ///         """
  ///         Release the I/O thread lock.
  ///         """
  ///         if self.lock:
  ///             self.lock.release()
  /// ```
  Object? release() => getFunction("release").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## removeFilter
  ///
  /// ### python docstring
  ///
  /// Remove the specified filter from this handler.
  ///
  /// ### python source
  /// ```py
  /// def removeFilter(self, filter):
  ///         """
  ///         Remove the specified filter from this handler.
  ///         """
  ///         if filter in self.filters:
  ///             self.filters.remove(filter)
  /// ```
  Object? removeFilter({
    required Object? filter,
  }) =>
      getFunction("removeFilter").call(
        <Object?>[
          filter,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## setFormatter
  ///
  /// ### python docstring
  ///
  /// Set the formatter for this handler.
  ///
  /// ### python source
  /// ```py
  /// def setFormatter(self, fmt):
  ///         """
  ///         Set the formatter for this handler.
  ///         """
  ///         self.formatter = fmt
  /// ```
  Object? setFormatter({
    required Object? fmt,
  }) =>
      getFunction("setFormatter").call(
        <Object?>[
          fmt,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## setLevel
  ///
  /// ### python docstring
  ///
  /// Set the logging level of this handler.  level must be an int or a str.
  ///
  /// ### python source
  /// ```py
  /// def setLevel(self, level):
  ///         """
  ///         Set the logging level of this handler.  level must be an int or a str.
  ///         """
  ///         self.level = _checkLevel(level)
  /// ```
  Object? setLevel({
    required Object? level,
  }) =>
      getFunction("setLevel").call(
        <Object?>[
          level,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## fset
  ///
  /// ### python source
  /// ```py
  /// def set_name(self, name):
  ///         _acquireLock()
  ///         try:
  ///             if self._name in _handlers:
  ///                 del _handlers[self._name]
  ///             self._name = name
  ///             if name:
  ///                 _handlers[name] = self
  ///         finally:
  ///             _releaseLock()
  /// ```
  Object? fset({
    required Object? name,
  }) =>
      getFunction("fset").call(
        <Object?>[
          name,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);

  /// ## level (getter)
  Object? get level => getAttribute("level");

  /// ## level (setter)
  set level(Object? level) => setAttribute("level", level);

  /// ## formatter (getter)
  Object? get formatter => getAttribute("formatter");

  /// ## formatter (setter)
  set formatter(Object? formatter) => setAttribute("formatter", formatter);
}

/// ## LogRecord
///
/// ### python docstring
///
/// A LogRecord instance represents an event being logged.
///
/// LogRecord instances are created every time something is logged. They
/// contain all the information pertinent to the event being logged. The
/// main information passed in is in msg and args, which are combined
/// using str(msg) % args to create the message field of the record. The
/// record also includes information such as when the record was created,
/// the source line where the logging call was made, and any exception
/// information to be logged.
///
/// ### python source
/// ```py
/// class LogRecord(object):
///     """
///     A LogRecord instance represents an event being logged.
///
///     LogRecord instances are created every time something is logged. They
///     contain all the information pertinent to the event being logged. The
///     main information passed in is in msg and args, which are combined
///     using str(msg) % args to create the message field of the record. The
///     record also includes information such as when the record was created,
///     the source line where the logging call was made, and any exception
///     information to be logged.
///     """
///     def __init__(self, name, level, pathname, lineno,
///                  msg, args, exc_info, func=None, sinfo=None, **kwargs):
///         """
///         Initialize a logging record with interesting information.
///         """
///         ct = time.time()
///         self.name = name
///         self.msg = msg
///         #
///         # The following statement allows passing of a dictionary as a sole
///         # argument, so that you can do something like
///         #  logging.debug("a %(a)d b %(b)s", {'a':1, 'b':2})
///         # Suggested by Stefan Behnel.
///         # Note that without the test for args[0], we get a problem because
///         # during formatting, we test to see if the arg is present using
///         # 'if self.args:'. If the event being logged is e.g. 'Value is %d'
///         # and if the passed arg fails 'if self.args:' then no formatting
///         # is done. For example, logger.warning('Value is %d', 0) would log
///         # 'Value is %d' instead of 'Value is 0'.
///         # For the use case of passing a dictionary, this should not be a
///         # problem.
///         # Issue #21172: a request was made to relax the isinstance check
///         # to hasattr(args[0], '__getitem__'). However, the docs on string
///         # formatting still seem to suggest a mapping object is required.
///         # Thus, while not removing the isinstance check, it does now look
///         # for collections.abc.Mapping rather than, as before, dict.
///         if (args and len(args) == 1 and isinstance(args[0], collections.abc.Mapping)
///             and args[0]):
///             args = args[0]
///         self.args = args
///         self.levelname = getLevelName(level)
///         self.levelno = level
///         self.pathname = pathname
///         try:
///             self.filename = os.path.basename(pathname)
///             self.module = os.path.splitext(self.filename)[0]
///         except (TypeError, ValueError, AttributeError):
///             self.filename = pathname
///             self.module = "Unknown module"
///         self.exc_info = exc_info
///         self.exc_text = None      # used to cache the traceback text
///         self.stack_info = sinfo
///         self.lineno = lineno
///         self.funcName = func
///         self.created = ct
///         self.msecs = int((ct - int(ct)) * 1000) + 0.0  # see gh-89047
///         self.relativeCreated = (self.created - _startTime) * 1000
///         if logThreads:
///             self.thread = threading.get_ident()
///             self.threadName = threading.current_thread().name
///         else: # pragma: no cover
///             self.thread = None
///             self.threadName = None
///         if not logMultiprocessing: # pragma: no cover
///             self.processName = None
///         else:
///             self.processName = 'MainProcess'
///             mp = sys.modules.get('multiprocessing')
///             if mp is not None:
///                 # Errors may occur if multiprocessing has not finished loading
///                 # yet - e.g. if a custom import hook causes third-party code
///                 # to run when multiprocessing calls import. See issue 8200
///                 # for an example
///                 try:
///                     self.processName = mp.current_process().name
///                 except Exception: #pragma: no cover
///                     pass
///         if logProcesses and hasattr(os, 'getpid'):
///             self.process = os.getpid()
///         else:
///             self.process = None
///
///     def __repr__(self):
///         return '<LogRecord: %s, %s, %s, %s, "%s">'%(self.name, self.levelno,
///             self.pathname, self.lineno, self.msg)
///
///     def getMessage(self):
///         """
///         Return the message for this LogRecord.
///
///         Return the message for this LogRecord after merging any user-supplied
///         arguments with the message.
///         """
///         msg = str(self.msg)
///         if self.args:
///             msg = msg % self.args
///         return msg
/// ```
final class LogRecord extends PythonClass {
  factory LogRecord({
    required Object? name,
    required Object? level,
    required Object? pathname,
    required Object? lineno,
    required Object? msg,
    required Object? args,
    required Object? exc_info,
    Object? func,
    Object? sinfo,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      PythonFfiDart.instance.importClass(
        "logging",
        "LogRecord",
        LogRecord.from,
        <Object?>[
          name,
          level,
          pathname,
          lineno,
          msg,
          args,
          exc_info,
          func,
          sinfo,
        ],
        <String, Object?>{
          ...kwargs,
        },
      );

  LogRecord.from(super.pythonClass) : super.from();

  /// ## getMessage
  ///
  /// ### python docstring
  ///
  /// Return the message for this LogRecord.
  ///
  /// Return the message for this LogRecord after merging any user-supplied
  /// arguments with the message.
  ///
  /// ### python source
  /// ```py
  /// def getMessage(self):
  ///         """
  ///         Return the message for this LogRecord.
  ///
  ///         Return the message for this LogRecord after merging any user-supplied
  ///         arguments with the message.
  ///         """
  ///         msg = str(self.msg)
  ///         if self.args:
  ///             msg = msg % self.args
  ///         return msg
  /// ```
  Object? getMessage() => getFunction("getMessage").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);

  /// ## msg (getter)
  Object? get msg => getAttribute("msg");

  /// ## msg (setter)
  set msg(Object? msg) => setAttribute("msg", msg);

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## levelname (getter)
  Object? get levelname => getAttribute("levelname");

  /// ## levelname (setter)
  set levelname(Object? levelname) => setAttribute("levelname", levelname);

  /// ## levelno (getter)
  Object? get levelno => getAttribute("levelno");

  /// ## levelno (setter)
  set levelno(Object? levelno) => setAttribute("levelno", levelno);

  /// ## pathname (getter)
  Object? get pathname => getAttribute("pathname");

  /// ## pathname (setter)
  set pathname(Object? pathname) => setAttribute("pathname", pathname);

  /// ## filename (getter)
  Object? get filename => getAttribute("filename");

  /// ## filename (setter)
  set filename(Object? filename) => setAttribute("filename", filename);

  /// ## module (getter)
  Object? get module => getAttribute("module");

  /// ## module (setter)
  set module(Object? module) => setAttribute("module", module);

  /// ## exc_info (getter)
  Object? get exc_info => getAttribute("exc_info");

  /// ## exc_info (setter)
  set exc_info(Object? exc_info) => setAttribute("exc_info", exc_info);

  /// ## exc_text (getter)
  Object? get exc_text => getAttribute("exc_text");

  /// ## exc_text (setter)
  set exc_text(Object? exc_text) => setAttribute("exc_text", exc_text);

  /// ## stack_info (getter)
  Object? get stack_info => getAttribute("stack_info");

  /// ## stack_info (setter)
  set stack_info(Object? stack_info) => setAttribute("stack_info", stack_info);

  /// ## lineno (getter)
  Object? get lineno => getAttribute("lineno");

  /// ## lineno (setter)
  set lineno(Object? lineno) => setAttribute("lineno", lineno);

  /// ## funcName (getter)
  Object? get funcName => getAttribute("funcName");

  /// ## funcName (setter)
  set funcName(Object? funcName) => setAttribute("funcName", funcName);

  /// ## created (getter)
  Object? get created => getAttribute("created");

  /// ## created (setter)
  set created(Object? created) => setAttribute("created", created);

  /// ## msecs (getter)
  Object? get msecs => getAttribute("msecs");

  /// ## msecs (setter)
  set msecs(Object? msecs) => setAttribute("msecs", msecs);

  /// ## relativeCreated (getter)
  Object? get relativeCreated => getAttribute("relativeCreated");

  /// ## relativeCreated (setter)
  set relativeCreated(Object? relativeCreated) =>
      setAttribute("relativeCreated", relativeCreated);

  /// ## thread (getter)
  Object? get thread => getAttribute("thread");

  /// ## thread (setter)
  set thread(Object? thread) => setAttribute("thread", thread);

  /// ## threadName (getter)
  Object? get threadName => getAttribute("threadName");

  /// ## threadName (setter)
  set threadName(Object? threadName) => setAttribute("threadName", threadName);

  /// ## processName (getter)
  Object? get processName => getAttribute("processName");

  /// ## processName (setter)
  set processName(Object? processName) =>
      setAttribute("processName", processName);

  /// ## process (getter)
  Object? get process => getAttribute("process");

  /// ## process (setter)
  set process(Object? process) => setAttribute("process", process);
}

/// ## Logger
///
/// ### python docstring
///
/// Instances of the Logger class represent a single logging channel. A
/// "logging channel" indicates an area of an application. Exactly how an
/// "area" is defined is up to the application developer. Since an
/// application can have any number of areas, logging channels are identified
/// by a unique string. Application areas can be nested (e.g. an area
/// of "input processing" might include sub-areas "read CSV files", "read
/// XLS files" and "read Gnumeric files"). To cater for this natural nesting,
/// channel names are organized into a namespace hierarchy where levels are
/// separated by periods, much like the Java or Python package namespace. So
/// in the instance given above, channel names might be "input" for the upper
/// level, and "input.csv", "input.xls" and "input.gnu" for the sub-levels.
/// There is no arbitrary limit to the depth of nesting.
///
/// ### python source
/// ```py
/// class Logger(Filterer):
///     """
///     Instances of the Logger class represent a single logging channel. A
///     "logging channel" indicates an area of an application. Exactly how an
///     "area" is defined is up to the application developer. Since an
///     application can have any number of areas, logging channels are identified
///     by a unique string. Application areas can be nested (e.g. an area
///     of "input processing" might include sub-areas "read CSV files", "read
///     XLS files" and "read Gnumeric files"). To cater for this natural nesting,
///     channel names are organized into a namespace hierarchy where levels are
///     separated by periods, much like the Java or Python package namespace. So
///     in the instance given above, channel names might be "input" for the upper
///     level, and "input.csv", "input.xls" and "input.gnu" for the sub-levels.
///     There is no arbitrary limit to the depth of nesting.
///     """
///     def __init__(self, name, level=NOTSET):
///         """
///         Initialize the logger with a name and an optional level.
///         """
///         Filterer.__init__(self)
///         self.name = name
///         self.level = _checkLevel(level)
///         self.parent = None
///         self.propagate = True
///         self.handlers = []
///         self.disabled = False
///         self._cache = {}
///
///     def setLevel(self, level):
///         """
///         Set the logging level of this logger.  level must be an int or a str.
///         """
///         self.level = _checkLevel(level)
///         self.manager._clear_cache()
///
///     def debug(self, msg, *args, **kwargs):
///         """
///         Log 'msg % args' with severity 'DEBUG'.
///
///         To pass exception information, use the keyword argument exc_info with
///         a true value, e.g.
///
///         logger.debug("Houston, we have a %s", "thorny problem", exc_info=1)
///         """
///         if self.isEnabledFor(DEBUG):
///             self._log(DEBUG, msg, args, **kwargs)
///
///     def info(self, msg, *args, **kwargs):
///         """
///         Log 'msg % args' with severity 'INFO'.
///
///         To pass exception information, use the keyword argument exc_info with
///         a true value, e.g.
///
///         logger.info("Houston, we have a %s", "interesting problem", exc_info=1)
///         """
///         if self.isEnabledFor(INFO):
///             self._log(INFO, msg, args, **kwargs)
///
///     def warning(self, msg, *args, **kwargs):
///         """
///         Log 'msg % args' with severity 'WARNING'.
///
///         To pass exception information, use the keyword argument exc_info with
///         a true value, e.g.
///
///         logger.warning("Houston, we have a %s", "bit of a problem", exc_info=1)
///         """
///         if self.isEnabledFor(WARNING):
///             self._log(WARNING, msg, args, **kwargs)
///
///     def warn(self, msg, *args, **kwargs):
///         warnings.warn("The 'warn' method is deprecated, "
///             "use 'warning' instead", DeprecationWarning, 2)
///         self.warning(msg, *args, **kwargs)
///
///     def error(self, msg, *args, **kwargs):
///         """
///         Log 'msg % args' with severity 'ERROR'.
///
///         To pass exception information, use the keyword argument exc_info with
///         a true value, e.g.
///
///         logger.error("Houston, we have a %s", "major problem", exc_info=1)
///         """
///         if self.isEnabledFor(ERROR):
///             self._log(ERROR, msg, args, **kwargs)
///
///     def exception(self, msg, *args, exc_info=True, **kwargs):
///         """
///         Convenience method for logging an ERROR with exception information.
///         """
///         self.error(msg, *args, exc_info=exc_info, **kwargs)
///
///     def critical(self, msg, *args, **kwargs):
///         """
///         Log 'msg % args' with severity 'CRITICAL'.
///
///         To pass exception information, use the keyword argument exc_info with
///         a true value, e.g.
///
///         logger.critical("Houston, we have a %s", "major disaster", exc_info=1)
///         """
///         if self.isEnabledFor(CRITICAL):
///             self._log(CRITICAL, msg, args, **kwargs)
///
///     def fatal(self, msg, *args, **kwargs):
///         """
///         Don't use this method, use critical() instead.
///         """
///         self.critical(msg, *args, **kwargs)
///
///     def log(self, level, msg, *args, **kwargs):
///         """
///         Log 'msg % args' with the integer severity 'level'.
///
///         To pass exception information, use the keyword argument exc_info with
///         a true value, e.g.
///
///         logger.log(level, "We have a %s", "mysterious problem", exc_info=1)
///         """
///         if not isinstance(level, int):
///             if raiseExceptions:
///                 raise TypeError("level must be an integer")
///             else:
///                 return
///         if self.isEnabledFor(level):
///             self._log(level, msg, args, **kwargs)
///
///     def findCaller(self, stack_info=False, stacklevel=1):
///         """
///         Find the stack frame of the caller so that we can note the source
///         file name, line number and function name.
///         """
///         f = currentframe()
///         #On some versions of IronPython, currentframe() returns None if
///         #IronPython isn't run with -X:Frames.
///         if f is None:
///             return "(unknown file)", 0, "(unknown function)", None
///         while stacklevel > 0:
///             next_f = f.f_back
///             if next_f is None:
///                 ## We've got options here.
///                 ## If we want to use the last (deepest) frame:
///                 break
///                 ## If we want to mimic the warnings module:
///                 #return ("sys", 1, "(unknown function)", None)
///                 ## If we want to be pedantic:
///                 #raise ValueError("call stack is not deep enough")
///             f = next_f
///             if not _is_internal_frame(f):
///                 stacklevel -= 1
///         co = f.f_code
///         sinfo = None
///         if stack_info:
///             with io.StringIO() as sio:
///                 sio.write("Stack (most recent call last):\n")
///                 traceback.print_stack(f, file=sio)
///                 sinfo = sio.getvalue()
///                 if sinfo[-1] == '\n':
///                     sinfo = sinfo[:-1]
///         return co.co_filename, f.f_lineno, co.co_name, sinfo
///
///     def makeRecord(self, name, level, fn, lno, msg, args, exc_info,
///                    func=None, extra=None, sinfo=None):
///         """
///         A factory method which can be overridden in subclasses to create
///         specialized LogRecords.
///         """
///         rv = _logRecordFactory(name, level, fn, lno, msg, args, exc_info, func,
///                              sinfo)
///         if extra is not None:
///             for key in extra:
///                 if (key in ["message", "asctime"]) or (key in rv.__dict__):
///                     raise KeyError("Attempt to overwrite %r in LogRecord" % key)
///                 rv.__dict__[key] = extra[key]
///         return rv
///
///     def _log(self, level, msg, args, exc_info=None, extra=None, stack_info=False,
///              stacklevel=1):
///         """
///         Low-level logging routine which creates a LogRecord and then calls
///         all the handlers of this logger to handle the record.
///         """
///         sinfo = None
///         if _srcfile:
///             #IronPython doesn't track Python frames, so findCaller raises an
///             #exception on some versions of IronPython. We trap it here so that
///             #IronPython can use logging.
///             try:
///                 fn, lno, func, sinfo = self.findCaller(stack_info, stacklevel)
///             except ValueError: # pragma: no cover
///                 fn, lno, func = "(unknown file)", 0, "(unknown function)"
///         else: # pragma: no cover
///             fn, lno, func = "(unknown file)", 0, "(unknown function)"
///         if exc_info:
///             if isinstance(exc_info, BaseException):
///                 exc_info = (type(exc_info), exc_info, exc_info.__traceback__)
///             elif not isinstance(exc_info, tuple):
///                 exc_info = sys.exc_info()
///         record = self.makeRecord(self.name, level, fn, lno, msg, args,
///                                  exc_info, func, extra, sinfo)
///         self.handle(record)
///
///     def handle(self, record):
///         """
///         Call the handlers for the specified record.
///
///         This method is used for unpickled records received from a socket, as
///         well as those created locally. Logger-level filtering is applied.
///         """
///         if (not self.disabled) and self.filter(record):
///             self.callHandlers(record)
///
///     def addHandler(self, hdlr):
///         """
///         Add the specified handler to this logger.
///         """
///         _acquireLock()
///         try:
///             if not (hdlr in self.handlers):
///                 self.handlers.append(hdlr)
///         finally:
///             _releaseLock()
///
///     def removeHandler(self, hdlr):
///         """
///         Remove the specified handler from this logger.
///         """
///         _acquireLock()
///         try:
///             if hdlr in self.handlers:
///                 self.handlers.remove(hdlr)
///         finally:
///             _releaseLock()
///
///     def hasHandlers(self):
///         """
///         See if this logger has any handlers configured.
///
///         Loop through all handlers for this logger and its parents in the
///         logger hierarchy. Return True if a handler was found, else False.
///         Stop searching up the hierarchy whenever a logger with the "propagate"
///         attribute set to zero is found - that will be the last logger which
///         is checked for the existence of handlers.
///         """
///         c = self
///         rv = False
///         while c:
///             if c.handlers:
///                 rv = True
///                 break
///             if not c.propagate:
///                 break
///             else:
///                 c = c.parent
///         return rv
///
///     def callHandlers(self, record):
///         """
///         Pass a record to all relevant handlers.
///
///         Loop through all handlers for this logger and its parents in the
///         logger hierarchy. If no handler was found, output a one-off error
///         message to sys.stderr. Stop searching up the hierarchy whenever a
///         logger with the "propagate" attribute set to zero is found - that
///         will be the last logger whose handlers are called.
///         """
///         c = self
///         found = 0
///         while c:
///             for hdlr in c.handlers:
///                 found = found + 1
///                 if record.levelno >= hdlr.level:
///                     hdlr.handle(record)
///             if not c.propagate:
///                 c = None    #break out
///             else:
///                 c = c.parent
///         if (found == 0):
///             if lastResort:
///                 if record.levelno >= lastResort.level:
///                     lastResort.handle(record)
///             elif raiseExceptions and not self.manager.emittedNoHandlerWarning:
///                 sys.stderr.write("No handlers could be found for logger"
///                                  " \"%s\"\n" % self.name)
///                 self.manager.emittedNoHandlerWarning = True
///
///     def getEffectiveLevel(self):
///         """
///         Get the effective level for this logger.
///
///         Loop through this logger and its parents in the logger hierarchy,
///         looking for a non-zero logging level. Return the first one found.
///         """
///         logger = self
///         while logger:
///             if logger.level:
///                 return logger.level
///             logger = logger.parent
///         return NOTSET
///
///     def isEnabledFor(self, level):
///         """
///         Is this logger enabled for level 'level'?
///         """
///         if self.disabled:
///             return False
///
///         try:
///             return self._cache[level]
///         except KeyError:
///             _acquireLock()
///             try:
///                 if self.manager.disable >= level:
///                     is_enabled = self._cache[level] = False
///                 else:
///                     is_enabled = self._cache[level] = (
///                         level >= self.getEffectiveLevel()
///                     )
///             finally:
///                 _releaseLock()
///             return is_enabled
///
///     def getChild(self, suffix):
///         """
///         Get a logger which is a descendant to this one.
///
///         This is a convenience method, such that
///
///         logging.getLogger('abc').getChild('def.ghi')
///
///         is the same as
///
///         logging.getLogger('abc.def.ghi')
///
///         It's useful, for example, when the parent logger is named using
///         __name__ rather than a literal string.
///         """
///         if self.root is not self:
///             suffix = '.'.join((self.name, suffix))
///         return self.manager.getLogger(suffix)
///
///     def __repr__(self):
///         level = getLevelName(self.getEffectiveLevel())
///         return '<%s %s (%s)>' % (self.__class__.__name__, self.name, level)
///
///     def __reduce__(self):
///         if getLogger(self.name) is not self:
///             import pickle
///             raise pickle.PicklingError('logger cannot be pickled')
///         return getLogger, (self.name,)
/// ```
final class Logger extends PythonClass {
  factory Logger({
    required Object? name,
    Object? level = 0,
  }) =>
      PythonFfiDart.instance.importClass(
        "logging",
        "Logger",
        Logger.from,
        <Object?>[
          name,
          level,
        ],
        <String, Object?>{},
      );

  Logger.from(super.pythonClass) : super.from();

  /// ## addFilter
  ///
  /// ### python docstring
  ///
  /// Add the specified filter to this handler.
  ///
  /// ### python source
  /// ```py
  /// def addFilter(self, filter):
  ///         """
  ///         Add the specified filter to this handler.
  ///         """
  ///         if not (filter in self.filters):
  ///             self.filters.append(filter)
  /// ```
  Object? addFilter({
    required Object? filter,
  }) =>
      getFunction("addFilter").call(
        <Object?>[
          filter,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## addHandler
  ///
  /// ### python docstring
  ///
  /// Add the specified handler to this logger.
  ///
  /// ### python source
  /// ```py
  /// def addHandler(self, hdlr):
  ///         """
  ///         Add the specified handler to this logger.
  ///         """
  ///         _acquireLock()
  ///         try:
  ///             if not (hdlr in self.handlers):
  ///                 self.handlers.append(hdlr)
  ///         finally:
  ///             _releaseLock()
  /// ```
  Object? addHandler({
    required Object? hdlr,
  }) =>
      getFunction("addHandler").call(
        <Object?>[
          hdlr,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## callHandlers
  ///
  /// ### python docstring
  ///
  /// Pass a record to all relevant handlers.
  ///
  /// Loop through all handlers for this logger and its parents in the
  /// logger hierarchy. If no handler was found, output a one-off error
  /// message to sys.stderr. Stop searching up the hierarchy whenever a
  /// logger with the "propagate" attribute set to zero is found - that
  /// will be the last logger whose handlers are called.
  ///
  /// ### python source
  /// ```py
  /// def callHandlers(self, record):
  ///         """
  ///         Pass a record to all relevant handlers.
  ///
  ///         Loop through all handlers for this logger and its parents in the
  ///         logger hierarchy. If no handler was found, output a one-off error
  ///         message to sys.stderr. Stop searching up the hierarchy whenever a
  ///         logger with the "propagate" attribute set to zero is found - that
  ///         will be the last logger whose handlers are called.
  ///         """
  ///         c = self
  ///         found = 0
  ///         while c:
  ///             for hdlr in c.handlers:
  ///                 found = found + 1
  ///                 if record.levelno >= hdlr.level:
  ///                     hdlr.handle(record)
  ///             if not c.propagate:
  ///                 c = None    #break out
  ///             else:
  ///                 c = c.parent
  ///         if (found == 0):
  ///             if lastResort:
  ///                 if record.levelno >= lastResort.level:
  ///                     lastResort.handle(record)
  ///             elif raiseExceptions and not self.manager.emittedNoHandlerWarning:
  ///                 sys.stderr.write("No handlers could be found for logger"
  ///                                  " \"%s\"\n" % self.name)
  ///                 self.manager.emittedNoHandlerWarning = True
  /// ```
  Object? callHandlers({
    required Object? record,
  }) =>
      getFunction("callHandlers").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## critical
  ///
  /// ### python docstring
  ///
  /// Log 'msg % args' with severity 'CRITICAL'.
  ///
  /// To pass exception information, use the keyword argument exc_info with
  /// a true value, e.g.
  ///
  /// logger.critical("Houston, we have a %s", "major disaster", exc_info=1)
  ///
  /// ### python source
  /// ```py
  /// def critical(self, msg, *args, **kwargs):
  ///         """
  ///         Log 'msg % args' with severity 'CRITICAL'.
  ///
  ///         To pass exception information, use the keyword argument exc_info with
  ///         a true value, e.g.
  ///
  ///         logger.critical("Houston, we have a %s", "major disaster", exc_info=1)
  ///         """
  ///         if self.isEnabledFor(CRITICAL):
  ///             self._log(CRITICAL, msg, args, **kwargs)
  /// ```
  Object? critical({
    List<Object?> args = const <Object?>[],
    required Object? msg,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("critical").call(
        <Object?>[
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## debug
  ///
  /// ### python docstring
  ///
  /// Log 'msg % args' with severity 'DEBUG'.
  ///
  /// To pass exception information, use the keyword argument exc_info with
  /// a true value, e.g.
  ///
  /// logger.debug("Houston, we have a %s", "thorny problem", exc_info=1)
  ///
  /// ### python source
  /// ```py
  /// def debug(self, msg, *args, **kwargs):
  ///         """
  ///         Log 'msg % args' with severity 'DEBUG'.
  ///
  ///         To pass exception information, use the keyword argument exc_info with
  ///         a true value, e.g.
  ///
  ///         logger.debug("Houston, we have a %s", "thorny problem", exc_info=1)
  ///         """
  ///         if self.isEnabledFor(DEBUG):
  ///             self._log(DEBUG, msg, args, **kwargs)
  /// ```
  Object? debug({
    List<Object?> args = const <Object?>[],
    required Object? msg,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("debug").call(
        <Object?>[
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## error
  ///
  /// ### python docstring
  ///
  /// Log 'msg % args' with severity 'ERROR'.
  ///
  /// To pass exception information, use the keyword argument exc_info with
  /// a true value, e.g.
  ///
  /// logger.error("Houston, we have a %s", "major problem", exc_info=1)
  ///
  /// ### python source
  /// ```py
  /// def error(self, msg, *args, **kwargs):
  ///         """
  ///         Log 'msg % args' with severity 'ERROR'.
  ///
  ///         To pass exception information, use the keyword argument exc_info with
  ///         a true value, e.g.
  ///
  ///         logger.error("Houston, we have a %s", "major problem", exc_info=1)
  ///         """
  ///         if self.isEnabledFor(ERROR):
  ///             self._log(ERROR, msg, args, **kwargs)
  /// ```
  Object? error({
    List<Object?> args = const <Object?>[],
    required Object? msg,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("error").call(
        <Object?>[
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## exception
  ///
  /// ### python docstring
  ///
  /// Convenience method for logging an ERROR with exception information.
  ///
  /// ### python source
  /// ```py
  /// def exception(self, msg, *args, exc_info=True, **kwargs):
  ///         """
  ///         Convenience method for logging an ERROR with exception information.
  ///         """
  ///         self.error(msg, *args, exc_info=exc_info, **kwargs)
  /// ```
  Object? exception({
    List<Object?> args = const <Object?>[],
    required Object? msg,
    Object? exc_info = true,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("exception").call(
        <Object?>[
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          "exc_info": exc_info,
          ...kwargs,
        },
      );

  /// ## fatal
  ///
  /// ### python docstring
  ///
  /// Don't use this method, use critical() instead.
  ///
  /// ### python source
  /// ```py
  /// def fatal(self, msg, *args, **kwargs):
  ///         """
  ///         Don't use this method, use critical() instead.
  ///         """
  ///         self.critical(msg, *args, **kwargs)
  /// ```
  Object? fatal({
    List<Object?> args = const <Object?>[],
    required Object? msg,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("fatal").call(
        <Object?>[
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## filter
  ///
  /// ### python docstring
  ///
  /// Determine if a record is loggable by consulting all the filters.
  ///
  /// The default is to allow the record to be logged; any filter can veto
  /// this and the record is then dropped. Returns a zero value if a record
  /// is to be dropped, else non-zero.
  ///
  /// .. versionchanged:: 3.2
  ///
  ///    Allow filters to be just callables.
  ///
  /// ### python source
  /// ```py
  /// def filter(self, record):
  ///         """
  ///         Determine if a record is loggable by consulting all the filters.
  ///
  ///         The default is to allow the record to be logged; any filter can veto
  ///         this and the record is then dropped. Returns a zero value if a record
  ///         is to be dropped, else non-zero.
  ///
  ///         .. versionchanged:: 3.2
  ///
  ///            Allow filters to be just callables.
  ///         """
  ///         rv = True
  ///         for f in self.filters:
  ///             if hasattr(f, 'filter'):
  ///                 result = f.filter(record)
  ///             else:
  ///                 result = f(record) # assume callable - will raise if not
  ///             if not result:
  ///                 rv = False
  ///                 break
  ///         return rv
  /// ```
  Object? filter({
    required Object? record,
  }) =>
      getFunction("filter").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## findCaller
  ///
  /// ### python docstring
  ///
  /// Find the stack frame of the caller so that we can note the source
  /// file name, line number and function name.
  ///
  /// ### python source
  /// ```py
  /// def findCaller(self, stack_info=False, stacklevel=1):
  ///         """
  ///         Find the stack frame of the caller so that we can note the source
  ///         file name, line number and function name.
  ///         """
  ///         f = currentframe()
  ///         #On some versions of IronPython, currentframe() returns None if
  ///         #IronPython isn't run with -X:Frames.
  ///         if f is None:
  ///             return "(unknown file)", 0, "(unknown function)", None
  ///         while stacklevel > 0:
  ///             next_f = f.f_back
  ///             if next_f is None:
  ///                 ## We've got options here.
  ///                 ## If we want to use the last (deepest) frame:
  ///                 break
  ///                 ## If we want to mimic the warnings module:
  ///                 #return ("sys", 1, "(unknown function)", None)
  ///                 ## If we want to be pedantic:
  ///                 #raise ValueError("call stack is not deep enough")
  ///             f = next_f
  ///             if not _is_internal_frame(f):
  ///                 stacklevel -= 1
  ///         co = f.f_code
  ///         sinfo = None
  ///         if stack_info:
  ///             with io.StringIO() as sio:
  ///                 sio.write("Stack (most recent call last):\n")
  ///                 traceback.print_stack(f, file=sio)
  ///                 sinfo = sio.getvalue()
  ///                 if sinfo[-1] == '\n':
  ///                     sinfo = sinfo[:-1]
  ///         return co.co_filename, f.f_lineno, co.co_name, sinfo
  /// ```
  Object? findCaller({
    Object? stack_info = false,
    Object? stacklevel = 1,
  }) =>
      getFunction("findCaller").call(
        <Object?>[
          stack_info,
          stacklevel,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## getChild
  ///
  /// ### python docstring
  ///
  /// Get a logger which is a descendant to this one.
  ///
  /// This is a convenience method, such that
  ///
  /// logging.getLogger('abc').getChild('def.ghi')
  ///
  /// is the same as
  ///
  /// logging.getLogger('abc.def.ghi')
  ///
  /// It's useful, for example, when the parent logger is named using
  /// __name__ rather than a literal string.
  ///
  /// ### python source
  /// ```py
  /// def getChild(self, suffix):
  ///         """
  ///         Get a logger which is a descendant to this one.
  ///
  ///         This is a convenience method, such that
  ///
  ///         logging.getLogger('abc').getChild('def.ghi')
  ///
  ///         is the same as
  ///
  ///         logging.getLogger('abc.def.ghi')
  ///
  ///         It's useful, for example, when the parent logger is named using
  ///         __name__ rather than a literal string.
  ///         """
  ///         if self.root is not self:
  ///             suffix = '.'.join((self.name, suffix))
  ///         return self.manager.getLogger(suffix)
  /// ```
  Object? getChild({
    required Object? suffix,
  }) =>
      getFunction("getChild").call(
        <Object?>[
          suffix,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## getEffectiveLevel
  ///
  /// ### python docstring
  ///
  /// Get the effective level for this logger.
  ///
  /// Loop through this logger and its parents in the logger hierarchy,
  /// looking for a non-zero logging level. Return the first one found.
  ///
  /// ### python source
  /// ```py
  /// def getEffectiveLevel(self):
  ///         """
  ///         Get the effective level for this logger.
  ///
  ///         Loop through this logger and its parents in the logger hierarchy,
  ///         looking for a non-zero logging level. Return the first one found.
  ///         """
  ///         logger = self
  ///         while logger:
  ///             if logger.level:
  ///                 return logger.level
  ///             logger = logger.parent
  ///         return NOTSET
  /// ```
  Object? getEffectiveLevel() => getFunction("getEffectiveLevel").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## handle
  ///
  /// ### python docstring
  ///
  /// Call the handlers for the specified record.
  ///
  /// This method is used for unpickled records received from a socket, as
  /// well as those created locally. Logger-level filtering is applied.
  ///
  /// ### python source
  /// ```py
  /// def handle(self, record):
  ///         """
  ///         Call the handlers for the specified record.
  ///
  ///         This method is used for unpickled records received from a socket, as
  ///         well as those created locally. Logger-level filtering is applied.
  ///         """
  ///         if (not self.disabled) and self.filter(record):
  ///             self.callHandlers(record)
  /// ```
  Object? handle({
    required Object? record,
  }) =>
      getFunction("handle").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## hasHandlers
  ///
  /// ### python docstring
  ///
  /// See if this logger has any handlers configured.
  ///
  /// Loop through all handlers for this logger and its parents in the
  /// logger hierarchy. Return True if a handler was found, else False.
  /// Stop searching up the hierarchy whenever a logger with the "propagate"
  /// attribute set to zero is found - that will be the last logger which
  /// is checked for the existence of handlers.
  ///
  /// ### python source
  /// ```py
  /// def hasHandlers(self):
  ///         """
  ///         See if this logger has any handlers configured.
  ///
  ///         Loop through all handlers for this logger and its parents in the
  ///         logger hierarchy. Return True if a handler was found, else False.
  ///         Stop searching up the hierarchy whenever a logger with the "propagate"
  ///         attribute set to zero is found - that will be the last logger which
  ///         is checked for the existence of handlers.
  ///         """
  ///         c = self
  ///         rv = False
  ///         while c:
  ///             if c.handlers:
  ///                 rv = True
  ///                 break
  ///             if not c.propagate:
  ///                 break
  ///             else:
  ///                 c = c.parent
  ///         return rv
  /// ```
  Object? hasHandlers() => getFunction("hasHandlers").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## info
  ///
  /// ### python docstring
  ///
  /// Log 'msg % args' with severity 'INFO'.
  ///
  /// To pass exception information, use the keyword argument exc_info with
  /// a true value, e.g.
  ///
  /// logger.info("Houston, we have a %s", "interesting problem", exc_info=1)
  ///
  /// ### python source
  /// ```py
  /// def info(self, msg, *args, **kwargs):
  ///         """
  ///         Log 'msg % args' with severity 'INFO'.
  ///
  ///         To pass exception information, use the keyword argument exc_info with
  ///         a true value, e.g.
  ///
  ///         logger.info("Houston, we have a %s", "interesting problem", exc_info=1)
  ///         """
  ///         if self.isEnabledFor(INFO):
  ///             self._log(INFO, msg, args, **kwargs)
  /// ```
  Object? info({
    List<Object?> args = const <Object?>[],
    required Object? msg,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("info").call(
        <Object?>[
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## isEnabledFor
  ///
  /// ### python docstring
  ///
  /// Is this logger enabled for level 'level'?
  ///
  /// ### python source
  /// ```py
  /// def isEnabledFor(self, level):
  ///         """
  ///         Is this logger enabled for level 'level'?
  ///         """
  ///         if self.disabled:
  ///             return False
  ///
  ///         try:
  ///             return self._cache[level]
  ///         except KeyError:
  ///             _acquireLock()
  ///             try:
  ///                 if self.manager.disable >= level:
  ///                     is_enabled = self._cache[level] = False
  ///                 else:
  ///                     is_enabled = self._cache[level] = (
  ///                         level >= self.getEffectiveLevel()
  ///                     )
  ///             finally:
  ///                 _releaseLock()
  ///             return is_enabled
  /// ```
  Object? isEnabledFor({
    required Object? level,
  }) =>
      getFunction("isEnabledFor").call(
        <Object?>[
          level,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## log
  ///
  /// ### python docstring
  ///
  /// Log 'msg % args' with the integer severity 'level'.
  ///
  /// To pass exception information, use the keyword argument exc_info with
  /// a true value, e.g.
  ///
  /// logger.log(level, "We have a %s", "mysterious problem", exc_info=1)
  ///
  /// ### python source
  /// ```py
  /// def log(self, level, msg, *args, **kwargs):
  ///         """
  ///         Log 'msg % args' with the integer severity 'level'.
  ///
  ///         To pass exception information, use the keyword argument exc_info with
  ///         a true value, e.g.
  ///
  ///         logger.log(level, "We have a %s", "mysterious problem", exc_info=1)
  ///         """
  ///         if not isinstance(level, int):
  ///             if raiseExceptions:
  ///                 raise TypeError("level must be an integer")
  ///             else:
  ///                 return
  ///         if self.isEnabledFor(level):
  ///             self._log(level, msg, args, **kwargs)
  /// ```
  Object? log({
    List<Object?> args = const <Object?>[],
    required Object? level,
    required Object? msg,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("log").call(
        <Object?>[
          level,
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## makeRecord
  ///
  /// ### python docstring
  ///
  /// A factory method which can be overridden in subclasses to create
  /// specialized LogRecords.
  ///
  /// ### python source
  /// ```py
  /// def makeRecord(self, name, level, fn, lno, msg, args, exc_info,
  ///                    func=None, extra=None, sinfo=None):
  ///         """
  ///         A factory method which can be overridden in subclasses to create
  ///         specialized LogRecords.
  ///         """
  ///         rv = _logRecordFactory(name, level, fn, lno, msg, args, exc_info, func,
  ///                              sinfo)
  ///         if extra is not None:
  ///             for key in extra:
  ///                 if (key in ["message", "asctime"]) or (key in rv.__dict__):
  ///                     raise KeyError("Attempt to overwrite %r in LogRecord" % key)
  ///                 rv.__dict__[key] = extra[key]
  ///         return rv
  /// ```
  Object? makeRecord({
    required Object? name,
    required Object? level,
    required Object? fn,
    required Object? lno,
    required Object? msg,
    required Object? args,
    required Object? exc_info,
    Object? func,
    Object? extra,
    Object? sinfo,
  }) =>
      getFunction("makeRecord").call(
        <Object?>[
          name,
          level,
          fn,
          lno,
          msg,
          args,
          exc_info,
          func,
          extra,
          sinfo,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## removeFilter
  ///
  /// ### python docstring
  ///
  /// Remove the specified filter from this handler.
  ///
  /// ### python source
  /// ```py
  /// def removeFilter(self, filter):
  ///         """
  ///         Remove the specified filter from this handler.
  ///         """
  ///         if filter in self.filters:
  ///             self.filters.remove(filter)
  /// ```
  Object? removeFilter({
    required Object? filter,
  }) =>
      getFunction("removeFilter").call(
        <Object?>[
          filter,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## removeHandler
  ///
  /// ### python docstring
  ///
  /// Remove the specified handler from this logger.
  ///
  /// ### python source
  /// ```py
  /// def removeHandler(self, hdlr):
  ///         """
  ///         Remove the specified handler from this logger.
  ///         """
  ///         _acquireLock()
  ///         try:
  ///             if hdlr in self.handlers:
  ///                 self.handlers.remove(hdlr)
  ///         finally:
  ///             _releaseLock()
  /// ```
  Object? removeHandler({
    required Object? hdlr,
  }) =>
      getFunction("removeHandler").call(
        <Object?>[
          hdlr,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## setLevel
  ///
  /// ### python docstring
  ///
  /// Set the logging level of this logger.  level must be an int or a str.
  ///
  /// ### python source
  /// ```py
  /// def setLevel(self, level):
  ///         """
  ///         Set the logging level of this logger.  level must be an int or a str.
  ///         """
  ///         self.level = _checkLevel(level)
  ///         self.manager._clear_cache()
  /// ```
  Object? setLevel({
    required Object? level,
  }) =>
      getFunction("setLevel").call(
        <Object?>[
          level,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## warn
  ///
  /// ### python source
  /// ```py
  /// def warn(self, msg, *args, **kwargs):
  ///         warnings.warn("The 'warn' method is deprecated, "
  ///             "use 'warning' instead", DeprecationWarning, 2)
  ///         self.warning(msg, *args, **kwargs)
  /// ```
  Object? warn({
    List<Object?> args = const <Object?>[],
    required Object? msg,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("warn").call(
        <Object?>[
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## warning
  ///
  /// ### python docstring
  ///
  /// Log 'msg % args' with severity 'WARNING'.
  ///
  /// To pass exception information, use the keyword argument exc_info with
  /// a true value, e.g.
  ///
  /// logger.warning("Houston, we have a %s", "bit of a problem", exc_info=1)
  ///
  /// ### python source
  /// ```py
  /// def warning(self, msg, *args, **kwargs):
  ///         """
  ///         Log 'msg % args' with severity 'WARNING'.
  ///
  ///         To pass exception information, use the keyword argument exc_info with
  ///         a true value, e.g.
  ///
  ///         logger.warning("Houston, we have a %s", "bit of a problem", exc_info=1)
  ///         """
  ///         if self.isEnabledFor(WARNING):
  ///             self._log(WARNING, msg, args, **kwargs)
  /// ```
  Object? warning({
    List<Object?> args = const <Object?>[],
    required Object? msg,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("warning").call(
        <Object?>[
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## manager (getter)
  ///
  /// ### python docstring
  ///
  /// There is [under normal circumstances] just one Manager instance, which
  /// holds the hierarchy of loggers.
  Object? get manager => getAttribute("manager");

  /// ## manager (setter)
  ///
  /// ### python docstring
  ///
  /// There is [under normal circumstances] just one Manager instance, which
  /// holds the hierarchy of loggers.
  set manager(Object? manager) => setAttribute("manager", manager);

  /// ## root (getter)
  ///
  /// ### python docstring
  ///
  /// A root logger is not that different to any other logger, except that
  /// it must have a logging level and there is only one instance of it in
  /// the hierarchy.
  Object? get root => getAttribute("root");

  /// ## root (setter)
  ///
  /// ### python docstring
  ///
  /// A root logger is not that different to any other logger, except that
  /// it must have a logging level and there is only one instance of it in
  /// the hierarchy.
  set root(Object? root) => setAttribute("root", root);

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);

  /// ## level (getter)
  Object? get level => getAttribute("level");

  /// ## level (setter)
  set level(Object? level) => setAttribute("level", level);

  /// ## parent (getter)
  Object? get parent => getAttribute("parent");

  /// ## parent (setter)
  set parent(Object? parent) => setAttribute("parent", parent);

  /// ## propagate (getter)
  Object? get propagate => getAttribute("propagate");

  /// ## propagate (setter)
  set propagate(Object? propagate) => setAttribute("propagate", propagate);

  /// ## handlers (getter)
  Object? get handlers => getAttribute("handlers");

  /// ## handlers (setter)
  set handlers(Object? handlers) => setAttribute("handlers", handlers);

  /// ## disabled (getter)
  Object? get disabled => getAttribute("disabled");

  /// ## disabled (setter)
  set disabled(Object? disabled) => setAttribute("disabled", disabled);
}

/// ## LoggerAdapter
///
/// ### python docstring
///
/// An adapter for loggers which makes it easier to specify contextual
/// information in logging output.
///
/// ### python source
/// ```py
/// class LoggerAdapter(object):
///     """
///     An adapter for loggers which makes it easier to specify contextual
///     information in logging output.
///     """
///
///     def __init__(self, logger, extra=None):
///         """
///         Initialize the adapter with a logger and a dict-like object which
///         provides contextual information. This constructor signature allows
///         easy stacking of LoggerAdapters, if so desired.
///
///         You can effectively pass keyword arguments as shown in the
///         following example:
///
///         adapter = LoggerAdapter(someLogger, dict(p1=v1, p2="v2"))
///         """
///         self.logger = logger
///         self.extra = extra
///
///     def process(self, msg, kwargs):
///         """
///         Process the logging message and keyword arguments passed in to
///         a logging call to insert contextual information. You can either
///         manipulate the message itself, the keyword args or both. Return
///         the message and kwargs modified (or not) to suit your needs.
///
///         Normally, you'll only need to override this one method in a
///         LoggerAdapter subclass for your specific needs.
///         """
///         kwargs["extra"] = self.extra
///         return msg, kwargs
///
///     #
///     # Boilerplate convenience methods
///     #
///     def debug(self, msg, *args, **kwargs):
///         """
///         Delegate a debug call to the underlying logger.
///         """
///         self.log(DEBUG, msg, *args, **kwargs)
///
///     def info(self, msg, *args, **kwargs):
///         """
///         Delegate an info call to the underlying logger.
///         """
///         self.log(INFO, msg, *args, **kwargs)
///
///     def warning(self, msg, *args, **kwargs):
///         """
///         Delegate a warning call to the underlying logger.
///         """
///         self.log(WARNING, msg, *args, **kwargs)
///
///     def warn(self, msg, *args, **kwargs):
///         warnings.warn("The 'warn' method is deprecated, "
///             "use 'warning' instead", DeprecationWarning, 2)
///         self.warning(msg, *args, **kwargs)
///
///     def error(self, msg, *args, **kwargs):
///         """
///         Delegate an error call to the underlying logger.
///         """
///         self.log(ERROR, msg, *args, **kwargs)
///
///     def exception(self, msg, *args, exc_info=True, **kwargs):
///         """
///         Delegate an exception call to the underlying logger.
///         """
///         self.log(ERROR, msg, *args, exc_info=exc_info, **kwargs)
///
///     def critical(self, msg, *args, **kwargs):
///         """
///         Delegate a critical call to the underlying logger.
///         """
///         self.log(CRITICAL, msg, *args, **kwargs)
///
///     def log(self, level, msg, *args, **kwargs):
///         """
///         Delegate a log call to the underlying logger, after adding
///         contextual information from this adapter instance.
///         """
///         if self.isEnabledFor(level):
///             msg, kwargs = self.process(msg, kwargs)
///             self.logger.log(level, msg, *args, **kwargs)
///
///     def isEnabledFor(self, level):
///         """
///         Is this logger enabled for level 'level'?
///         """
///         return self.logger.isEnabledFor(level)
///
///     def setLevel(self, level):
///         """
///         Set the specified level on the underlying logger.
///         """
///         self.logger.setLevel(level)
///
///     def getEffectiveLevel(self):
///         """
///         Get the effective level for the underlying logger.
///         """
///         return self.logger.getEffectiveLevel()
///
///     def hasHandlers(self):
///         """
///         See if the underlying logger has any handlers.
///         """
///         return self.logger.hasHandlers()
///
///     def _log(self, level, msg, args, exc_info=None, extra=None, stack_info=False):
///         """
///         Low-level log implementation, proxied to allow nested logger adapters.
///         """
///         return self.logger._log(
///             level,
///             msg,
///             args,
///             exc_info=exc_info,
///             extra=extra,
///             stack_info=stack_info,
///         )
///
///     @property
///     def manager(self):
///         return self.logger.manager
///
///     @manager.setter
///     def manager(self, value):
///         self.logger.manager = value
///
///     @property
///     def name(self):
///         return self.logger.name
///
///     def __repr__(self):
///         logger = self.logger
///         level = getLevelName(logger.getEffectiveLevel())
///         return '<%s %s (%s)>' % (self.__class__.__name__, logger.name, level)
///
///     __class_getitem__ = classmethod(GenericAlias)
/// ```
final class LoggerAdapter extends PythonClass {
  factory LoggerAdapter({
    required Object? logger,
    Object? extra,
  }) =>
      PythonFfiDart.instance.importClass(
        "logging",
        "LoggerAdapter",
        LoggerAdapter.from,
        <Object?>[
          logger,
          extra,
        ],
        <String, Object?>{},
      );

  LoggerAdapter.from(super.pythonClass) : super.from();

  /// ## critical
  ///
  /// ### python docstring
  ///
  /// Delegate a critical call to the underlying logger.
  ///
  /// ### python source
  /// ```py
  /// def critical(self, msg, *args, **kwargs):
  ///         """
  ///         Delegate a critical call to the underlying logger.
  ///         """
  ///         self.log(CRITICAL, msg, *args, **kwargs)
  /// ```
  Object? critical({
    List<Object?> args = const <Object?>[],
    required Object? msg,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("critical").call(
        <Object?>[
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## debug
  ///
  /// ### python docstring
  ///
  /// Delegate a debug call to the underlying logger.
  ///
  /// ### python source
  /// ```py
  /// def debug(self, msg, *args, **kwargs):
  ///         """
  ///         Delegate a debug call to the underlying logger.
  ///         """
  ///         self.log(DEBUG, msg, *args, **kwargs)
  /// ```
  Object? debug({
    List<Object?> args = const <Object?>[],
    required Object? msg,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("debug").call(
        <Object?>[
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## error
  ///
  /// ### python docstring
  ///
  /// Delegate an error call to the underlying logger.
  ///
  /// ### python source
  /// ```py
  /// def error(self, msg, *args, **kwargs):
  ///         """
  ///         Delegate an error call to the underlying logger.
  ///         """
  ///         self.log(ERROR, msg, *args, **kwargs)
  /// ```
  Object? error({
    List<Object?> args = const <Object?>[],
    required Object? msg,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("error").call(
        <Object?>[
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## exception
  ///
  /// ### python docstring
  ///
  /// Delegate an exception call to the underlying logger.
  ///
  /// ### python source
  /// ```py
  /// def exception(self, msg, *args, exc_info=True, **kwargs):
  ///         """
  ///         Delegate an exception call to the underlying logger.
  ///         """
  ///         self.log(ERROR, msg, *args, exc_info=exc_info, **kwargs)
  /// ```
  Object? exception({
    List<Object?> args = const <Object?>[],
    required Object? msg,
    Object? exc_info = true,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("exception").call(
        <Object?>[
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          "exc_info": exc_info,
          ...kwargs,
        },
      );

  /// ## getEffectiveLevel
  ///
  /// ### python docstring
  ///
  /// Get the effective level for the underlying logger.
  ///
  /// ### python source
  /// ```py
  /// def getEffectiveLevel(self):
  ///         """
  ///         Get the effective level for the underlying logger.
  ///         """
  ///         return self.logger.getEffectiveLevel()
  /// ```
  Object? getEffectiveLevel() => getFunction("getEffectiveLevel").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## hasHandlers
  ///
  /// ### python docstring
  ///
  /// See if the underlying logger has any handlers.
  ///
  /// ### python source
  /// ```py
  /// def hasHandlers(self):
  ///         """
  ///         See if the underlying logger has any handlers.
  ///         """
  ///         return self.logger.hasHandlers()
  /// ```
  Object? hasHandlers() => getFunction("hasHandlers").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## info
  ///
  /// ### python docstring
  ///
  /// Delegate an info call to the underlying logger.
  ///
  /// ### python source
  /// ```py
  /// def info(self, msg, *args, **kwargs):
  ///         """
  ///         Delegate an info call to the underlying logger.
  ///         """
  ///         self.log(INFO, msg, *args, **kwargs)
  /// ```
  Object? info({
    List<Object?> args = const <Object?>[],
    required Object? msg,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("info").call(
        <Object?>[
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## isEnabledFor
  ///
  /// ### python docstring
  ///
  /// Is this logger enabled for level 'level'?
  ///
  /// ### python source
  /// ```py
  /// def isEnabledFor(self, level):
  ///         """
  ///         Is this logger enabled for level 'level'?
  ///         """
  ///         return self.logger.isEnabledFor(level)
  /// ```
  Object? isEnabledFor({
    required Object? level,
  }) =>
      getFunction("isEnabledFor").call(
        <Object?>[
          level,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## log
  ///
  /// ### python docstring
  ///
  /// Delegate a log call to the underlying logger, after adding
  /// contextual information from this adapter instance.
  ///
  /// ### python source
  /// ```py
  /// def log(self, level, msg, *args, **kwargs):
  ///         """
  ///         Delegate a log call to the underlying logger, after adding
  ///         contextual information from this adapter instance.
  ///         """
  ///         if self.isEnabledFor(level):
  ///             msg, kwargs = self.process(msg, kwargs)
  ///             self.logger.log(level, msg, *args, **kwargs)
  /// ```
  Object? log({
    List<Object?> args = const <Object?>[],
    required Object? level,
    required Object? msg,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("log").call(
        <Object?>[
          level,
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## process
  ///
  /// ### python docstring
  ///
  /// Process the logging message and keyword arguments passed in to
  /// a logging call to insert contextual information. You can either
  /// manipulate the message itself, the keyword args or both. Return
  /// the message and kwargs modified (or not) to suit your needs.
  ///
  /// Normally, you'll only need to override this one method in a
  /// LoggerAdapter subclass for your specific needs.
  ///
  /// ### python source
  /// ```py
  /// def process(self, msg, kwargs):
  ///         """
  ///         Process the logging message and keyword arguments passed in to
  ///         a logging call to insert contextual information. You can either
  ///         manipulate the message itself, the keyword args or both. Return
  ///         the message and kwargs modified (or not) to suit your needs.
  ///
  ///         Normally, you'll only need to override this one method in a
  ///         LoggerAdapter subclass for your specific needs.
  ///         """
  ///         kwargs["extra"] = self.extra
  ///         return msg, kwargs
  /// ```
  Object? process({
    required Object? msg,
    required Object? kwargs,
  }) =>
      getFunction("process").call(
        <Object?>[
          msg,
          kwargs,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## setLevel
  ///
  /// ### python docstring
  ///
  /// Set the specified level on the underlying logger.
  ///
  /// ### python source
  /// ```py
  /// def setLevel(self, level):
  ///         """
  ///         Set the specified level on the underlying logger.
  ///         """
  ///         self.logger.setLevel(level)
  /// ```
  Object? setLevel({
    required Object? level,
  }) =>
      getFunction("setLevel").call(
        <Object?>[
          level,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## warn
  ///
  /// ### python source
  /// ```py
  /// def warn(self, msg, *args, **kwargs):
  ///         warnings.warn("The 'warn' method is deprecated, "
  ///             "use 'warning' instead", DeprecationWarning, 2)
  ///         self.warning(msg, *args, **kwargs)
  /// ```
  Object? warn({
    List<Object?> args = const <Object?>[],
    required Object? msg,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("warn").call(
        <Object?>[
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## warning
  ///
  /// ### python docstring
  ///
  /// Delegate a warning call to the underlying logger.
  ///
  /// ### python source
  /// ```py
  /// def warning(self, msg, *args, **kwargs):
  ///         """
  ///         Delegate a warning call to the underlying logger.
  ///         """
  ///         self.log(WARNING, msg, *args, **kwargs)
  /// ```
  Object? warning({
    List<Object?> args = const <Object?>[],
    required Object? msg,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("warning").call(
        <Object?>[
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## manager (getter)
  Object? get manager => getAttribute("manager");

  /// ## manager (setter)
  set manager(Object? manager) => setAttribute("manager", manager);

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);

  /// ## logger (getter)
  Object? get logger => getAttribute("logger");

  /// ## logger (setter)
  set logger(Object? logger) => setAttribute("logger", logger);

  /// ## extra (getter)
  Object? get extra => getAttribute("extra");

  /// ## extra (setter)
  set extra(Object? extra) => setAttribute("extra", extra);
}

/// ## Manager
///
/// ### python docstring
///
/// There is [under normal circumstances] just one Manager instance, which
/// holds the hierarchy of loggers.
///
/// ### python source
/// ```py
/// class Manager(object):
///     """
///     There is [under normal circumstances] just one Manager instance, which
///     holds the hierarchy of loggers.
///     """
///     def __init__(self, rootnode):
///         """
///         Initialize the manager with the root node of the logger hierarchy.
///         """
///         self.root = rootnode
///         self.disable = 0
///         self.emittedNoHandlerWarning = False
///         self.loggerDict = {}
///         self.loggerClass = None
///         self.logRecordFactory = None
///
///     @property
///     def disable(self):
///         return self._disable
///
///     @disable.setter
///     def disable(self, value):
///         self._disable = _checkLevel(value)
///
///     def getLogger(self, name):
///         """
///         Get a logger with the specified name (channel name), creating it
///         if it doesn't yet exist. This name is a dot-separated hierarchical
///         name, such as "a", "a.b", "a.b.c" or similar.
///
///         If a PlaceHolder existed for the specified name [i.e. the logger
///         didn't exist but a child of it did], replace it with the created
///         logger and fix up the parent/child references which pointed to the
///         placeholder to now point to the logger.
///         """
///         rv = None
///         if not isinstance(name, str):
///             raise TypeError('A logger name must be a string')
///         _acquireLock()
///         try:
///             if name in self.loggerDict:
///                 rv = self.loggerDict[name]
///                 if isinstance(rv, PlaceHolder):
///                     ph = rv
///                     rv = (self.loggerClass or _loggerClass)(name)
///                     rv.manager = self
///                     self.loggerDict[name] = rv
///                     self._fixupChildren(ph, rv)
///                     self._fixupParents(rv)
///             else:
///                 rv = (self.loggerClass or _loggerClass)(name)
///                 rv.manager = self
///                 self.loggerDict[name] = rv
///                 self._fixupParents(rv)
///         finally:
///             _releaseLock()
///         return rv
///
///     def setLoggerClass(self, klass):
///         """
///         Set the class to be used when instantiating a logger with this Manager.
///         """
///         if klass != Logger:
///             if not issubclass(klass, Logger):
///                 raise TypeError("logger not derived from logging.Logger: "
///                                 + klass.__name__)
///         self.loggerClass = klass
///
///     def setLogRecordFactory(self, factory):
///         """
///         Set the factory to be used when instantiating a log record with this
///         Manager.
///         """
///         self.logRecordFactory = factory
///
///     def _fixupParents(self, alogger):
///         """
///         Ensure that there are either loggers or placeholders all the way
///         from the specified logger to the root of the logger hierarchy.
///         """
///         name = alogger.name
///         i = name.rfind(".")
///         rv = None
///         while (i > 0) and not rv:
///             substr = name[:i]
///             if substr not in self.loggerDict:
///                 self.loggerDict[substr] = PlaceHolder(alogger)
///             else:
///                 obj = self.loggerDict[substr]
///                 if isinstance(obj, Logger):
///                     rv = obj
///                 else:
///                     assert isinstance(obj, PlaceHolder)
///                     obj.append(alogger)
///             i = name.rfind(".", 0, i - 1)
///         if not rv:
///             rv = self.root
///         alogger.parent = rv
///
///     def _fixupChildren(self, ph, alogger):
///         """
///         Ensure that children of the placeholder ph are connected to the
///         specified logger.
///         """
///         name = alogger.name
///         namelen = len(name)
///         for c in ph.loggerMap.keys():
///             #The if means ... if not c.parent.name.startswith(nm)
///             if c.parent.name[:namelen] != name:
///                 alogger.parent = c.parent
///                 c.parent = alogger
///
///     def _clear_cache(self):
///         """
///         Clear the cache for all loggers in loggerDict
///         Called when level changes are made
///         """
///
///         _acquireLock()
///         for logger in self.loggerDict.values():
///             if isinstance(logger, Logger):
///                 logger._cache.clear()
///         self.root._cache.clear()
///         _releaseLock()
/// ```
final class Manager extends PythonClass {
  factory Manager({
    required Object? rootnode,
  }) =>
      PythonFfiDart.instance.importClass(
        "logging",
        "Manager",
        Manager.from,
        <Object?>[
          rootnode,
        ],
        <String, Object?>{},
      );

  Manager.from(super.pythonClass) : super.from();

  /// ## getLogger
  ///
  /// ### python docstring
  ///
  /// Get a logger with the specified name (channel name), creating it
  /// if it doesn't yet exist. This name is a dot-separated hierarchical
  /// name, such as "a", "a.b", "a.b.c" or similar.
  ///
  /// If a PlaceHolder existed for the specified name [i.e. the logger
  /// didn't exist but a child of it did], replace it with the created
  /// logger and fix up the parent/child references which pointed to the
  /// placeholder to now point to the logger.
  ///
  /// ### python source
  /// ```py
  /// def getLogger(self, name):
  ///         """
  ///         Get a logger with the specified name (channel name), creating it
  ///         if it doesn't yet exist. This name is a dot-separated hierarchical
  ///         name, such as "a", "a.b", "a.b.c" or similar.
  ///
  ///         If a PlaceHolder existed for the specified name [i.e. the logger
  ///         didn't exist but a child of it did], replace it with the created
  ///         logger and fix up the parent/child references which pointed to the
  ///         placeholder to now point to the logger.
  ///         """
  ///         rv = None
  ///         if not isinstance(name, str):
  ///             raise TypeError('A logger name must be a string')
  ///         _acquireLock()
  ///         try:
  ///             if name in self.loggerDict:
  ///                 rv = self.loggerDict[name]
  ///                 if isinstance(rv, PlaceHolder):
  ///                     ph = rv
  ///                     rv = (self.loggerClass or _loggerClass)(name)
  ///                     rv.manager = self
  ///                     self.loggerDict[name] = rv
  ///                     self._fixupChildren(ph, rv)
  ///                     self._fixupParents(rv)
  ///             else:
  ///                 rv = (self.loggerClass or _loggerClass)(name)
  ///                 rv.manager = self
  ///                 self.loggerDict[name] = rv
  ///                 self._fixupParents(rv)
  ///         finally:
  ///             _releaseLock()
  ///         return rv
  /// ```
  Object? getLogger({
    required Object? name,
  }) =>
      getFunction("getLogger").call(
        <Object?>[
          name,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## setLogRecordFactory
  ///
  /// ### python docstring
  ///
  /// Set the factory to be used when instantiating a log record with this
  /// Manager.
  ///
  /// ### python source
  /// ```py
  /// def setLogRecordFactory(self, factory):
  ///         """
  ///         Set the factory to be used when instantiating a log record with this
  ///         Manager.
  ///         """
  ///         self.logRecordFactory = factory
  /// ```
  Object? setLogRecordFactory({
    required Object? $factory,
  }) =>
      getFunction("setLogRecordFactory").call(
        <Object?>[
          $factory,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## setLoggerClass
  ///
  /// ### python docstring
  ///
  /// Set the class to be used when instantiating a logger with this Manager.
  ///
  /// ### python source
  /// ```py
  /// def setLoggerClass(self, klass):
  ///         """
  ///         Set the class to be used when instantiating a logger with this Manager.
  ///         """
  ///         if klass != Logger:
  ///             if not issubclass(klass, Logger):
  ///                 raise TypeError("logger not derived from logging.Logger: "
  ///                                 + klass.__name__)
  ///         self.loggerClass = klass
  /// ```
  Object? setLoggerClass({
    required Object? klass,
  }) =>
      getFunction("setLoggerClass").call(
        <Object?>[
          klass,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## disable (getter)
  Object? get disable => getAttribute("disable");

  /// ## disable (setter)
  set disable(Object? disable) => setAttribute("disable", disable);

  /// ## root (getter)
  Object? get root => getAttribute("root");

  /// ## root (setter)
  set root(Object? root) => setAttribute("root", root);

  /// ## emittedNoHandlerWarning (getter)
  Object? get emittedNoHandlerWarning =>
      getAttribute("emittedNoHandlerWarning");

  /// ## emittedNoHandlerWarning (setter)
  set emittedNoHandlerWarning(Object? emittedNoHandlerWarning) =>
      setAttribute("emittedNoHandlerWarning", emittedNoHandlerWarning);

  /// ## loggerDict (getter)
  Object? get loggerDict => getAttribute("loggerDict");

  /// ## loggerDict (setter)
  set loggerDict(Object? loggerDict) => setAttribute("loggerDict", loggerDict);

  /// ## loggerClass (getter)
  Object? get loggerClass => getAttribute("loggerClass");

  /// ## loggerClass (setter)
  set loggerClass(Object? loggerClass) =>
      setAttribute("loggerClass", loggerClass);

  /// ## logRecordFactory (getter)
  Object? get logRecordFactory => getAttribute("logRecordFactory");

  /// ## logRecordFactory (setter)
  set logRecordFactory(Object? logRecordFactory) =>
      setAttribute("logRecordFactory", logRecordFactory);
}

/// ## NullHandler
///
/// ### python docstring
///
/// This handler does nothing. It's intended to be used to avoid the
/// "No handlers could be found for logger XXX" one-off warning. This is
/// important for library code, which may contain code to log events. If a user
/// of the library does not configure logging, the one-off warning might be
/// produced; to avoid this, the library developer simply needs to instantiate
/// a NullHandler and add it to the top-level logger of the library module or
/// package.
///
/// ### python source
/// ```py
/// class NullHandler(Handler):
///     """
///     This handler does nothing. It's intended to be used to avoid the
///     "No handlers could be found for logger XXX" one-off warning. This is
///     important for library code, which may contain code to log events. If a user
///     of the library does not configure logging, the one-off warning might be
///     produced; to avoid this, the library developer simply needs to instantiate
///     a NullHandler and add it to the top-level logger of the library module or
///     package.
///     """
///     def handle(self, record):
///         """Stub."""
///
///     def emit(self, record):
///         """Stub."""
///
///     def createLock(self):
///         self.lock = None
///
///     def _at_fork_reinit(self):
///         pass
/// ```
final class NullHandler extends PythonClass {
  factory NullHandler({
    Object? level = 0,
  }) =>
      PythonFfiDart.instance.importClass(
        "logging",
        "NullHandler",
        NullHandler.from,
        <Object?>[
          level,
        ],
        <String, Object?>{},
      );

  NullHandler.from(super.pythonClass) : super.from();

  /// ## acquire
  ///
  /// ### python docstring
  ///
  /// Acquire the I/O thread lock.
  ///
  /// ### python source
  /// ```py
  /// def acquire(self):
  ///         """
  ///         Acquire the I/O thread lock.
  ///         """
  ///         if self.lock:
  ///             self.lock.acquire()
  /// ```
  Object? acquire() => getFunction("acquire").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## addFilter
  ///
  /// ### python docstring
  ///
  /// Add the specified filter to this handler.
  ///
  /// ### python source
  /// ```py
  /// def addFilter(self, filter):
  ///         """
  ///         Add the specified filter to this handler.
  ///         """
  ///         if not (filter in self.filters):
  ///             self.filters.append(filter)
  /// ```
  Object? addFilter({
    required Object? filter,
  }) =>
      getFunction("addFilter").call(
        <Object?>[
          filter,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## close
  ///
  /// ### python docstring
  ///
  /// Tidy up any resources used by the handler.
  ///
  /// This version removes the handler from an internal map of handlers,
  /// _handlers, which is used for handler lookup by name. Subclasses
  /// should ensure that this gets called from overridden close()
  /// methods.
  ///
  /// ### python source
  /// ```py
  /// def close(self):
  ///         """
  ///         Tidy up any resources used by the handler.
  ///
  ///         This version removes the handler from an internal map of handlers,
  ///         _handlers, which is used for handler lookup by name. Subclasses
  ///         should ensure that this gets called from overridden close()
  ///         methods.
  ///         """
  ///         #get the module data lock, as we're updating a shared structure.
  ///         _acquireLock()
  ///         try:    #unlikely to raise an exception, but you never know...
  ///             self._closed = True
  ///             if self._name and self._name in _handlers:
  ///                 del _handlers[self._name]
  ///         finally:
  ///             _releaseLock()
  /// ```
  Object? close() => getFunction("close").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## createLock
  ///
  /// ### python docstring
  ///
  /// Acquire a thread lock for serializing access to the underlying I/O.
  ///
  /// ### python source
  /// ```py
  /// def createLock(self):
  ///         self.lock = None
  /// ```
  Object? createLock() => getFunction("createLock").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## emit
  ///
  /// ### python docstring
  ///
  /// Stub.
  ///
  /// ### python source
  /// ```py
  /// def emit(self, record):
  ///         """Stub."""
  /// ```
  Object? emit({
    required Object? record,
  }) =>
      getFunction("emit").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## filter
  ///
  /// ### python docstring
  ///
  /// Determine if a record is loggable by consulting all the filters.
  ///
  /// The default is to allow the record to be logged; any filter can veto
  /// this and the record is then dropped. Returns a zero value if a record
  /// is to be dropped, else non-zero.
  ///
  /// .. versionchanged:: 3.2
  ///
  ///    Allow filters to be just callables.
  ///
  /// ### python source
  /// ```py
  /// def filter(self, record):
  ///         """
  ///         Determine if a record is loggable by consulting all the filters.
  ///
  ///         The default is to allow the record to be logged; any filter can veto
  ///         this and the record is then dropped. Returns a zero value if a record
  ///         is to be dropped, else non-zero.
  ///
  ///         .. versionchanged:: 3.2
  ///
  ///            Allow filters to be just callables.
  ///         """
  ///         rv = True
  ///         for f in self.filters:
  ///             if hasattr(f, 'filter'):
  ///                 result = f.filter(record)
  ///             else:
  ///                 result = f(record) # assume callable - will raise if not
  ///             if not result:
  ///                 rv = False
  ///                 break
  ///         return rv
  /// ```
  Object? filter({
    required Object? record,
  }) =>
      getFunction("filter").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## flush
  ///
  /// ### python docstring
  ///
  /// Ensure all logging output has been flushed.
  ///
  /// This version does nothing and is intended to be implemented by
  /// subclasses.
  ///
  /// ### python source
  /// ```py
  /// def flush(self):
  ///         """
  ///         Ensure all logging output has been flushed.
  ///
  ///         This version does nothing and is intended to be implemented by
  ///         subclasses.
  ///         """
  ///         pass
  /// ```
  Object? flush() => getFunction("flush").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## format
  ///
  /// ### python docstring
  ///
  /// Format the specified record.
  ///
  /// If a formatter is set, use it. Otherwise, use the default formatter
  /// for the module.
  ///
  /// ### python source
  /// ```py
  /// def format(self, record):
  ///         """
  ///         Format the specified record.
  ///
  ///         If a formatter is set, use it. Otherwise, use the default formatter
  ///         for the module.
  ///         """
  ///         if self.formatter:
  ///             fmt = self.formatter
  ///         else:
  ///             fmt = _defaultFormatter
  ///         return fmt.format(record)
  /// ```
  Object? format({
    required Object? record,
  }) =>
      getFunction("format").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## get_name
  ///
  /// ### python source
  /// ```py
  /// def get_name(self):
  ///         return self._name
  /// ```
  Object? get_name() => getFunction("get_name").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## handle
  ///
  /// ### python docstring
  ///
  /// Stub.
  ///
  /// ### python source
  /// ```py
  /// def handle(self, record):
  ///         """Stub."""
  /// ```
  Object? handle({
    required Object? record,
  }) =>
      getFunction("handle").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## handleError
  ///
  /// ### python docstring
  ///
  /// Handle errors which occur during an emit() call.
  ///
  /// This method should be called from handlers when an exception is
  /// encountered during an emit() call. If raiseExceptions is false,
  /// exceptions get silently ignored. This is what is mostly wanted
  /// for a logging system - most users will not care about errors in
  /// the logging system, they are more interested in application errors.
  /// You could, however, replace this with a custom handler if you wish.
  /// The record which was being processed is passed in to this method.
  ///
  /// ### python source
  /// ```py
  /// def handleError(self, record):
  ///         """
  ///         Handle errors which occur during an emit() call.
  ///
  ///         This method should be called from handlers when an exception is
  ///         encountered during an emit() call. If raiseExceptions is false,
  ///         exceptions get silently ignored. This is what is mostly wanted
  ///         for a logging system - most users will not care about errors in
  ///         the logging system, they are more interested in application errors.
  ///         You could, however, replace this with a custom handler if you wish.
  ///         The record which was being processed is passed in to this method.
  ///         """
  ///         if raiseExceptions and sys.stderr:  # see issue 13807
  ///             t, v, tb = sys.exc_info()
  ///             try:
  ///                 sys.stderr.write('--- Logging error ---\n')
  ///                 traceback.print_exception(t, v, tb, None, sys.stderr)
  ///                 sys.stderr.write('Call stack:\n')
  ///                 # Walk the stack frame up until we're out of logging,
  ///                 # so as to print the calling context.
  ///                 frame = tb.tb_frame
  ///                 while (frame and os.path.dirname(frame.f_code.co_filename) ==
  ///                        __path__[0]):
  ///                     frame = frame.f_back
  ///                 if frame:
  ///                     traceback.print_stack(frame, file=sys.stderr)
  ///                 else:
  ///                     # couldn't find the right stack frame, for some reason
  ///                     sys.stderr.write('Logged from file %s, line %s\n' % (
  ///                                      record.filename, record.lineno))
  ///                 # Issue 18671: output logging message and arguments
  ///                 try:
  ///                     sys.stderr.write('Message: %r\n'
  ///                                      'Arguments: %s\n' % (record.msg,
  ///                                                           record.args))
  ///                 except RecursionError:  # See issue 36272
  ///                     raise
  ///                 except Exception:
  ///                     sys.stderr.write('Unable to print the message and arguments'
  ///                                      ' - possible formatting error.\nUse the'
  ///                                      ' traceback above to help find the error.\n'
  ///                                     )
  ///             except OSError: #pragma: no cover
  ///                 pass    # see issue 5971
  ///             finally:
  ///                 del t, v, tb
  /// ```
  Object? handleError({
    required Object? record,
  }) =>
      getFunction("handleError").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## release
  ///
  /// ### python docstring
  ///
  /// Release the I/O thread lock.
  ///
  /// ### python source
  /// ```py
  /// def release(self):
  ///         """
  ///         Release the I/O thread lock.
  ///         """
  ///         if self.lock:
  ///             self.lock.release()
  /// ```
  Object? release() => getFunction("release").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## removeFilter
  ///
  /// ### python docstring
  ///
  /// Remove the specified filter from this handler.
  ///
  /// ### python source
  /// ```py
  /// def removeFilter(self, filter):
  ///         """
  ///         Remove the specified filter from this handler.
  ///         """
  ///         if filter in self.filters:
  ///             self.filters.remove(filter)
  /// ```
  Object? removeFilter({
    required Object? filter,
  }) =>
      getFunction("removeFilter").call(
        <Object?>[
          filter,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## setFormatter
  ///
  /// ### python docstring
  ///
  /// Set the formatter for this handler.
  ///
  /// ### python source
  /// ```py
  /// def setFormatter(self, fmt):
  ///         """
  ///         Set the formatter for this handler.
  ///         """
  ///         self.formatter = fmt
  /// ```
  Object? setFormatter({
    required Object? fmt,
  }) =>
      getFunction("setFormatter").call(
        <Object?>[
          fmt,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## setLevel
  ///
  /// ### python docstring
  ///
  /// Set the logging level of this handler.  level must be an int or a str.
  ///
  /// ### python source
  /// ```py
  /// def setLevel(self, level):
  ///         """
  ///         Set the logging level of this handler.  level must be an int or a str.
  ///         """
  ///         self.level = _checkLevel(level)
  /// ```
  Object? setLevel({
    required Object? level,
  }) =>
      getFunction("setLevel").call(
        <Object?>[
          level,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## fset
  ///
  /// ### python source
  /// ```py
  /// def set_name(self, name):
  ///         _acquireLock()
  ///         try:
  ///             if self._name in _handlers:
  ///                 del _handlers[self._name]
  ///             self._name = name
  ///             if name:
  ///                 _handlers[name] = self
  ///         finally:
  ///             _releaseLock()
  /// ```
  Object? fset({
    required Object? name,
  }) =>
      getFunction("fset").call(
        <Object?>[
          name,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);

  /// ## level (getter)
  Object? get level => getAttribute("level");

  /// ## level (setter)
  set level(Object? level) => setAttribute("level", level);

  /// ## formatter (getter)
  Object? get formatter => getAttribute("formatter");

  /// ## formatter (setter)
  set formatter(Object? formatter) => setAttribute("formatter", formatter);
}

/// ## PercentStyle
///
/// ### python source
/// ```py
/// class PercentStyle(object):
///
///     default_format = '%(message)s'
///     asctime_format = '%(asctime)s'
///     asctime_search = '%(asctime)'
///     validation_pattern = re.compile(r'%\(\w+\)[#0+ -]*(\*|\d+)?(\.(\*|\d+))?[diouxefgcrsa%]', re.I)
///
///     def __init__(self, fmt, *, defaults=None):
///         self._fmt = fmt or self.default_format
///         self._defaults = defaults
///
///     def usesTime(self):
///         return self._fmt.find(self.asctime_search) >= 0
///
///     def validate(self):
///         """Validate the input format, ensure it matches the correct style"""
///         if not self.validation_pattern.search(self._fmt):
///             raise ValueError("Invalid format '%s' for '%s' style" % (self._fmt, self.default_format[0]))
///
///     def _format(self, record):
///         if defaults := self._defaults:
///             values = defaults | record.__dict__
///         else:
///             values = record.__dict__
///         return self._fmt % values
///
///     def format(self, record):
///         try:
///             return self._format(record)
///         except KeyError as e:
///             raise ValueError('Formatting field not found in record: %s' % e)
/// ```
final class PercentStyle extends PythonClass {
  factory PercentStyle({
    required Object? fmt,
    Object? defaults,
  }) =>
      PythonFfiDart.instance.importClass(
        "logging",
        "PercentStyle",
        PercentStyle.from,
        <Object?>[
          fmt,
        ],
        <String, Object?>{
          "defaults": defaults,
        },
      );

  PercentStyle.from(super.pythonClass) : super.from();

  /// ## format
  ///
  /// ### python source
  /// ```py
  /// def format(self, record):
  ///         try:
  ///             return self._format(record)
  ///         except KeyError as e:
  ///             raise ValueError('Formatting field not found in record: %s' % e)
  /// ```
  Object? format({
    required Object? record,
  }) =>
      getFunction("format").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## usesTime
  ///
  /// ### python source
  /// ```py
  /// def usesTime(self):
  ///         return self._fmt.find(self.asctime_search) >= 0
  /// ```
  Object? usesTime() => getFunction("usesTime").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## validate
  ///
  /// ### python docstring
  ///
  /// Validate the input format, ensure it matches the correct style
  ///
  /// ### python source
  /// ```py
  /// def validate(self):
  ///         """Validate the input format, ensure it matches the correct style"""
  ///         if not self.validation_pattern.search(self._fmt):
  ///             raise ValueError("Invalid format '%s' for '%s' style" % (self._fmt, self.default_format[0]))
  /// ```
  Object? validate() => getFunction("validate").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## validation_pattern (getter)
  Object? get validation_pattern => getAttribute("validation_pattern");

  /// ## validation_pattern (setter)
  set validation_pattern(Object? validation_pattern) =>
      setAttribute("validation_pattern", validation_pattern);

  /// ## asctime_format (getter)
  Object? get asctime_format => getAttribute("asctime_format");

  /// ## asctime_format (setter)
  set asctime_format(Object? asctime_format) =>
      setAttribute("asctime_format", asctime_format);

  /// ## asctime_search (getter)
  Object? get asctime_search => getAttribute("asctime_search");

  /// ## asctime_search (setter)
  set asctime_search(Object? asctime_search) =>
      setAttribute("asctime_search", asctime_search);

  /// ## default_format (getter)
  Object? get default_format => getAttribute("default_format");

  /// ## default_format (setter)
  set default_format(Object? default_format) =>
      setAttribute("default_format", default_format);
}

/// ## PlaceHolder
///
/// ### python docstring
///
/// PlaceHolder instances are used in the Manager logger hierarchy to take
/// the place of nodes for which no loggers have been defined. This class is
/// intended for internal use only and not as part of the public API.
///
/// ### python source
/// ```py
/// class PlaceHolder(object):
///     """
///     PlaceHolder instances are used in the Manager logger hierarchy to take
///     the place of nodes for which no loggers have been defined. This class is
///     intended for internal use only and not as part of the public API.
///     """
///     def __init__(self, alogger):
///         """
///         Initialize with the specified logger being a child of this placeholder.
///         """
///         self.loggerMap = { alogger : None }
///
///     def append(self, alogger):
///         """
///         Add the specified logger as a child of this placeholder.
///         """
///         if alogger not in self.loggerMap:
///             self.loggerMap[alogger] = None
/// ```
final class PlaceHolder extends PythonClass {
  factory PlaceHolder({
    required Object? alogger,
  }) =>
      PythonFfiDart.instance.importClass(
        "logging",
        "PlaceHolder",
        PlaceHolder.from,
        <Object?>[
          alogger,
        ],
        <String, Object?>{},
      );

  PlaceHolder.from(super.pythonClass) : super.from();

  /// ## append
  ///
  /// ### python docstring
  ///
  /// Add the specified logger as a child of this placeholder.
  ///
  /// ### python source
  /// ```py
  /// def append(self, alogger):
  ///         """
  ///         Add the specified logger as a child of this placeholder.
  ///         """
  ///         if alogger not in self.loggerMap:
  ///             self.loggerMap[alogger] = None
  /// ```
  Object? append({
    required Object? alogger,
  }) =>
      getFunction("append").call(
        <Object?>[
          alogger,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## loggerMap (getter)
  Object? get loggerMap => getAttribute("loggerMap");

  /// ## loggerMap (setter)
  set loggerMap(Object? loggerMap) => setAttribute("loggerMap", loggerMap);
}

/// ## RootLogger
///
/// ### python docstring
///
/// A root logger is not that different to any other logger, except that
/// it must have a logging level and there is only one instance of it in
/// the hierarchy.
///
/// ### python source
/// ```py
/// class RootLogger(Logger):
///     """
///     A root logger is not that different to any other logger, except that
///     it must have a logging level and there is only one instance of it in
///     the hierarchy.
///     """
///     def __init__(self, level):
///         """
///         Initialize the logger with the name "root".
///         """
///         Logger.__init__(self, "root", level)
///
///     def __reduce__(self):
///         return getLogger, ()
/// ```
final class RootLogger extends PythonClass {
  factory RootLogger({
    required Object? level,
  }) =>
      PythonFfiDart.instance.importClass(
        "logging",
        "RootLogger",
        RootLogger.from,
        <Object?>[
          level,
        ],
        <String, Object?>{},
      );

  RootLogger.from(super.pythonClass) : super.from();

  /// ## addFilter
  ///
  /// ### python docstring
  ///
  /// Add the specified filter to this handler.
  ///
  /// ### python source
  /// ```py
  /// def addFilter(self, filter):
  ///         """
  ///         Add the specified filter to this handler.
  ///         """
  ///         if not (filter in self.filters):
  ///             self.filters.append(filter)
  /// ```
  Object? addFilter({
    required Object? filter,
  }) =>
      getFunction("addFilter").call(
        <Object?>[
          filter,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## addHandler
  ///
  /// ### python docstring
  ///
  /// Add the specified handler to this logger.
  ///
  /// ### python source
  /// ```py
  /// def addHandler(self, hdlr):
  ///         """
  ///         Add the specified handler to this logger.
  ///         """
  ///         _acquireLock()
  ///         try:
  ///             if not (hdlr in self.handlers):
  ///                 self.handlers.append(hdlr)
  ///         finally:
  ///             _releaseLock()
  /// ```
  Object? addHandler({
    required Object? hdlr,
  }) =>
      getFunction("addHandler").call(
        <Object?>[
          hdlr,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## callHandlers
  ///
  /// ### python docstring
  ///
  /// Pass a record to all relevant handlers.
  ///
  /// Loop through all handlers for this logger and its parents in the
  /// logger hierarchy. If no handler was found, output a one-off error
  /// message to sys.stderr. Stop searching up the hierarchy whenever a
  /// logger with the "propagate" attribute set to zero is found - that
  /// will be the last logger whose handlers are called.
  ///
  /// ### python source
  /// ```py
  /// def callHandlers(self, record):
  ///         """
  ///         Pass a record to all relevant handlers.
  ///
  ///         Loop through all handlers for this logger and its parents in the
  ///         logger hierarchy. If no handler was found, output a one-off error
  ///         message to sys.stderr. Stop searching up the hierarchy whenever a
  ///         logger with the "propagate" attribute set to zero is found - that
  ///         will be the last logger whose handlers are called.
  ///         """
  ///         c = self
  ///         found = 0
  ///         while c:
  ///             for hdlr in c.handlers:
  ///                 found = found + 1
  ///                 if record.levelno >= hdlr.level:
  ///                     hdlr.handle(record)
  ///             if not c.propagate:
  ///                 c = None    #break out
  ///             else:
  ///                 c = c.parent
  ///         if (found == 0):
  ///             if lastResort:
  ///                 if record.levelno >= lastResort.level:
  ///                     lastResort.handle(record)
  ///             elif raiseExceptions and not self.manager.emittedNoHandlerWarning:
  ///                 sys.stderr.write("No handlers could be found for logger"
  ///                                  " \"%s\"\n" % self.name)
  ///                 self.manager.emittedNoHandlerWarning = True
  /// ```
  Object? callHandlers({
    required Object? record,
  }) =>
      getFunction("callHandlers").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## critical
  ///
  /// ### python docstring
  ///
  /// Log 'msg % args' with severity 'CRITICAL'.
  ///
  /// To pass exception information, use the keyword argument exc_info with
  /// a true value, e.g.
  ///
  /// logger.critical("Houston, we have a %s", "major disaster", exc_info=1)
  ///
  /// ### python source
  /// ```py
  /// def critical(self, msg, *args, **kwargs):
  ///         """
  ///         Log 'msg % args' with severity 'CRITICAL'.
  ///
  ///         To pass exception information, use the keyword argument exc_info with
  ///         a true value, e.g.
  ///
  ///         logger.critical("Houston, we have a %s", "major disaster", exc_info=1)
  ///         """
  ///         if self.isEnabledFor(CRITICAL):
  ///             self._log(CRITICAL, msg, args, **kwargs)
  /// ```
  Object? critical({
    List<Object?> args = const <Object?>[],
    required Object? msg,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("critical").call(
        <Object?>[
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## debug
  ///
  /// ### python docstring
  ///
  /// Log 'msg % args' with severity 'DEBUG'.
  ///
  /// To pass exception information, use the keyword argument exc_info with
  /// a true value, e.g.
  ///
  /// logger.debug("Houston, we have a %s", "thorny problem", exc_info=1)
  ///
  /// ### python source
  /// ```py
  /// def debug(self, msg, *args, **kwargs):
  ///         """
  ///         Log 'msg % args' with severity 'DEBUG'.
  ///
  ///         To pass exception information, use the keyword argument exc_info with
  ///         a true value, e.g.
  ///
  ///         logger.debug("Houston, we have a %s", "thorny problem", exc_info=1)
  ///         """
  ///         if self.isEnabledFor(DEBUG):
  ///             self._log(DEBUG, msg, args, **kwargs)
  /// ```
  Object? debug({
    List<Object?> args = const <Object?>[],
    required Object? msg,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("debug").call(
        <Object?>[
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## error
  ///
  /// ### python docstring
  ///
  /// Log 'msg % args' with severity 'ERROR'.
  ///
  /// To pass exception information, use the keyword argument exc_info with
  /// a true value, e.g.
  ///
  /// logger.error("Houston, we have a %s", "major problem", exc_info=1)
  ///
  /// ### python source
  /// ```py
  /// def error(self, msg, *args, **kwargs):
  ///         """
  ///         Log 'msg % args' with severity 'ERROR'.
  ///
  ///         To pass exception information, use the keyword argument exc_info with
  ///         a true value, e.g.
  ///
  ///         logger.error("Houston, we have a %s", "major problem", exc_info=1)
  ///         """
  ///         if self.isEnabledFor(ERROR):
  ///             self._log(ERROR, msg, args, **kwargs)
  /// ```
  Object? error({
    List<Object?> args = const <Object?>[],
    required Object? msg,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("error").call(
        <Object?>[
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## exception
  ///
  /// ### python docstring
  ///
  /// Convenience method for logging an ERROR with exception information.
  ///
  /// ### python source
  /// ```py
  /// def exception(self, msg, *args, exc_info=True, **kwargs):
  ///         """
  ///         Convenience method for logging an ERROR with exception information.
  ///         """
  ///         self.error(msg, *args, exc_info=exc_info, **kwargs)
  /// ```
  Object? exception({
    List<Object?> args = const <Object?>[],
    required Object? msg,
    Object? exc_info = true,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("exception").call(
        <Object?>[
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          "exc_info": exc_info,
          ...kwargs,
        },
      );

  /// ## fatal
  ///
  /// ### python docstring
  ///
  /// Don't use this method, use critical() instead.
  ///
  /// ### python source
  /// ```py
  /// def fatal(self, msg, *args, **kwargs):
  ///         """
  ///         Don't use this method, use critical() instead.
  ///         """
  ///         self.critical(msg, *args, **kwargs)
  /// ```
  Object? fatal({
    List<Object?> args = const <Object?>[],
    required Object? msg,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("fatal").call(
        <Object?>[
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## filter
  ///
  /// ### python docstring
  ///
  /// Determine if a record is loggable by consulting all the filters.
  ///
  /// The default is to allow the record to be logged; any filter can veto
  /// this and the record is then dropped. Returns a zero value if a record
  /// is to be dropped, else non-zero.
  ///
  /// .. versionchanged:: 3.2
  ///
  ///    Allow filters to be just callables.
  ///
  /// ### python source
  /// ```py
  /// def filter(self, record):
  ///         """
  ///         Determine if a record is loggable by consulting all the filters.
  ///
  ///         The default is to allow the record to be logged; any filter can veto
  ///         this and the record is then dropped. Returns a zero value if a record
  ///         is to be dropped, else non-zero.
  ///
  ///         .. versionchanged:: 3.2
  ///
  ///            Allow filters to be just callables.
  ///         """
  ///         rv = True
  ///         for f in self.filters:
  ///             if hasattr(f, 'filter'):
  ///                 result = f.filter(record)
  ///             else:
  ///                 result = f(record) # assume callable - will raise if not
  ///             if not result:
  ///                 rv = False
  ///                 break
  ///         return rv
  /// ```
  Object? filter({
    required Object? record,
  }) =>
      getFunction("filter").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## findCaller
  ///
  /// ### python docstring
  ///
  /// Find the stack frame of the caller so that we can note the source
  /// file name, line number and function name.
  ///
  /// ### python source
  /// ```py
  /// def findCaller(self, stack_info=False, stacklevel=1):
  ///         """
  ///         Find the stack frame of the caller so that we can note the source
  ///         file name, line number and function name.
  ///         """
  ///         f = currentframe()
  ///         #On some versions of IronPython, currentframe() returns None if
  ///         #IronPython isn't run with -X:Frames.
  ///         if f is None:
  ///             return "(unknown file)", 0, "(unknown function)", None
  ///         while stacklevel > 0:
  ///             next_f = f.f_back
  ///             if next_f is None:
  ///                 ## We've got options here.
  ///                 ## If we want to use the last (deepest) frame:
  ///                 break
  ///                 ## If we want to mimic the warnings module:
  ///                 #return ("sys", 1, "(unknown function)", None)
  ///                 ## If we want to be pedantic:
  ///                 #raise ValueError("call stack is not deep enough")
  ///             f = next_f
  ///             if not _is_internal_frame(f):
  ///                 stacklevel -= 1
  ///         co = f.f_code
  ///         sinfo = None
  ///         if stack_info:
  ///             with io.StringIO() as sio:
  ///                 sio.write("Stack (most recent call last):\n")
  ///                 traceback.print_stack(f, file=sio)
  ///                 sinfo = sio.getvalue()
  ///                 if sinfo[-1] == '\n':
  ///                     sinfo = sinfo[:-1]
  ///         return co.co_filename, f.f_lineno, co.co_name, sinfo
  /// ```
  Object? findCaller({
    Object? stack_info = false,
    Object? stacklevel = 1,
  }) =>
      getFunction("findCaller").call(
        <Object?>[
          stack_info,
          stacklevel,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## getChild
  ///
  /// ### python docstring
  ///
  /// Get a logger which is a descendant to this one.
  ///
  /// This is a convenience method, such that
  ///
  /// logging.getLogger('abc').getChild('def.ghi')
  ///
  /// is the same as
  ///
  /// logging.getLogger('abc.def.ghi')
  ///
  /// It's useful, for example, when the parent logger is named using
  /// __name__ rather than a literal string.
  ///
  /// ### python source
  /// ```py
  /// def getChild(self, suffix):
  ///         """
  ///         Get a logger which is a descendant to this one.
  ///
  ///         This is a convenience method, such that
  ///
  ///         logging.getLogger('abc').getChild('def.ghi')
  ///
  ///         is the same as
  ///
  ///         logging.getLogger('abc.def.ghi')
  ///
  ///         It's useful, for example, when the parent logger is named using
  ///         __name__ rather than a literal string.
  ///         """
  ///         if self.root is not self:
  ///             suffix = '.'.join((self.name, suffix))
  ///         return self.manager.getLogger(suffix)
  /// ```
  Object? getChild({
    required Object? suffix,
  }) =>
      getFunction("getChild").call(
        <Object?>[
          suffix,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## getEffectiveLevel
  ///
  /// ### python docstring
  ///
  /// Get the effective level for this logger.
  ///
  /// Loop through this logger and its parents in the logger hierarchy,
  /// looking for a non-zero logging level. Return the first one found.
  ///
  /// ### python source
  /// ```py
  /// def getEffectiveLevel(self):
  ///         """
  ///         Get the effective level for this logger.
  ///
  ///         Loop through this logger and its parents in the logger hierarchy,
  ///         looking for a non-zero logging level. Return the first one found.
  ///         """
  ///         logger = self
  ///         while logger:
  ///             if logger.level:
  ///                 return logger.level
  ///             logger = logger.parent
  ///         return NOTSET
  /// ```
  Object? getEffectiveLevel() => getFunction("getEffectiveLevel").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## handle
  ///
  /// ### python docstring
  ///
  /// Call the handlers for the specified record.
  ///
  /// This method is used for unpickled records received from a socket, as
  /// well as those created locally. Logger-level filtering is applied.
  ///
  /// ### python source
  /// ```py
  /// def handle(self, record):
  ///         """
  ///         Call the handlers for the specified record.
  ///
  ///         This method is used for unpickled records received from a socket, as
  ///         well as those created locally. Logger-level filtering is applied.
  ///         """
  ///         if (not self.disabled) and self.filter(record):
  ///             self.callHandlers(record)
  /// ```
  Object? handle({
    required Object? record,
  }) =>
      getFunction("handle").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## hasHandlers
  ///
  /// ### python docstring
  ///
  /// See if this logger has any handlers configured.
  ///
  /// Loop through all handlers for this logger and its parents in the
  /// logger hierarchy. Return True if a handler was found, else False.
  /// Stop searching up the hierarchy whenever a logger with the "propagate"
  /// attribute set to zero is found - that will be the last logger which
  /// is checked for the existence of handlers.
  ///
  /// ### python source
  /// ```py
  /// def hasHandlers(self):
  ///         """
  ///         See if this logger has any handlers configured.
  ///
  ///         Loop through all handlers for this logger and its parents in the
  ///         logger hierarchy. Return True if a handler was found, else False.
  ///         Stop searching up the hierarchy whenever a logger with the "propagate"
  ///         attribute set to zero is found - that will be the last logger which
  ///         is checked for the existence of handlers.
  ///         """
  ///         c = self
  ///         rv = False
  ///         while c:
  ///             if c.handlers:
  ///                 rv = True
  ///                 break
  ///             if not c.propagate:
  ///                 break
  ///             else:
  ///                 c = c.parent
  ///         return rv
  /// ```
  Object? hasHandlers() => getFunction("hasHandlers").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## info
  ///
  /// ### python docstring
  ///
  /// Log 'msg % args' with severity 'INFO'.
  ///
  /// To pass exception information, use the keyword argument exc_info with
  /// a true value, e.g.
  ///
  /// logger.info("Houston, we have a %s", "interesting problem", exc_info=1)
  ///
  /// ### python source
  /// ```py
  /// def info(self, msg, *args, **kwargs):
  ///         """
  ///         Log 'msg % args' with severity 'INFO'.
  ///
  ///         To pass exception information, use the keyword argument exc_info with
  ///         a true value, e.g.
  ///
  ///         logger.info("Houston, we have a %s", "interesting problem", exc_info=1)
  ///         """
  ///         if self.isEnabledFor(INFO):
  ///             self._log(INFO, msg, args, **kwargs)
  /// ```
  Object? info({
    List<Object?> args = const <Object?>[],
    required Object? msg,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("info").call(
        <Object?>[
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## isEnabledFor
  ///
  /// ### python docstring
  ///
  /// Is this logger enabled for level 'level'?
  ///
  /// ### python source
  /// ```py
  /// def isEnabledFor(self, level):
  ///         """
  ///         Is this logger enabled for level 'level'?
  ///         """
  ///         if self.disabled:
  ///             return False
  ///
  ///         try:
  ///             return self._cache[level]
  ///         except KeyError:
  ///             _acquireLock()
  ///             try:
  ///                 if self.manager.disable >= level:
  ///                     is_enabled = self._cache[level] = False
  ///                 else:
  ///                     is_enabled = self._cache[level] = (
  ///                         level >= self.getEffectiveLevel()
  ///                     )
  ///             finally:
  ///                 _releaseLock()
  ///             return is_enabled
  /// ```
  Object? isEnabledFor({
    required Object? level,
  }) =>
      getFunction("isEnabledFor").call(
        <Object?>[
          level,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## log
  ///
  /// ### python docstring
  ///
  /// Log 'msg % args' with the integer severity 'level'.
  ///
  /// To pass exception information, use the keyword argument exc_info with
  /// a true value, e.g.
  ///
  /// logger.log(level, "We have a %s", "mysterious problem", exc_info=1)
  ///
  /// ### python source
  /// ```py
  /// def log(self, level, msg, *args, **kwargs):
  ///         """
  ///         Log 'msg % args' with the integer severity 'level'.
  ///
  ///         To pass exception information, use the keyword argument exc_info with
  ///         a true value, e.g.
  ///
  ///         logger.log(level, "We have a %s", "mysterious problem", exc_info=1)
  ///         """
  ///         if not isinstance(level, int):
  ///             if raiseExceptions:
  ///                 raise TypeError("level must be an integer")
  ///             else:
  ///                 return
  ///         if self.isEnabledFor(level):
  ///             self._log(level, msg, args, **kwargs)
  /// ```
  Object? log({
    List<Object?> args = const <Object?>[],
    required Object? level,
    required Object? msg,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("log").call(
        <Object?>[
          level,
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## makeRecord
  ///
  /// ### python docstring
  ///
  /// A factory method which can be overridden in subclasses to create
  /// specialized LogRecords.
  ///
  /// ### python source
  /// ```py
  /// def makeRecord(self, name, level, fn, lno, msg, args, exc_info,
  ///                    func=None, extra=None, sinfo=None):
  ///         """
  ///         A factory method which can be overridden in subclasses to create
  ///         specialized LogRecords.
  ///         """
  ///         rv = _logRecordFactory(name, level, fn, lno, msg, args, exc_info, func,
  ///                              sinfo)
  ///         if extra is not None:
  ///             for key in extra:
  ///                 if (key in ["message", "asctime"]) or (key in rv.__dict__):
  ///                     raise KeyError("Attempt to overwrite %r in LogRecord" % key)
  ///                 rv.__dict__[key] = extra[key]
  ///         return rv
  /// ```
  Object? makeRecord({
    required Object? name,
    required Object? level,
    required Object? fn,
    required Object? lno,
    required Object? msg,
    required Object? args,
    required Object? exc_info,
    Object? func,
    Object? extra,
    Object? sinfo,
  }) =>
      getFunction("makeRecord").call(
        <Object?>[
          name,
          level,
          fn,
          lno,
          msg,
          args,
          exc_info,
          func,
          extra,
          sinfo,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## removeFilter
  ///
  /// ### python docstring
  ///
  /// Remove the specified filter from this handler.
  ///
  /// ### python source
  /// ```py
  /// def removeFilter(self, filter):
  ///         """
  ///         Remove the specified filter from this handler.
  ///         """
  ///         if filter in self.filters:
  ///             self.filters.remove(filter)
  /// ```
  Object? removeFilter({
    required Object? filter,
  }) =>
      getFunction("removeFilter").call(
        <Object?>[
          filter,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## removeHandler
  ///
  /// ### python docstring
  ///
  /// Remove the specified handler from this logger.
  ///
  /// ### python source
  /// ```py
  /// def removeHandler(self, hdlr):
  ///         """
  ///         Remove the specified handler from this logger.
  ///         """
  ///         _acquireLock()
  ///         try:
  ///             if hdlr in self.handlers:
  ///                 self.handlers.remove(hdlr)
  ///         finally:
  ///             _releaseLock()
  /// ```
  Object? removeHandler({
    required Object? hdlr,
  }) =>
      getFunction("removeHandler").call(
        <Object?>[
          hdlr,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## setLevel
  ///
  /// ### python docstring
  ///
  /// Set the logging level of this logger.  level must be an int or a str.
  ///
  /// ### python source
  /// ```py
  /// def setLevel(self, level):
  ///         """
  ///         Set the logging level of this logger.  level must be an int or a str.
  ///         """
  ///         self.level = _checkLevel(level)
  ///         self.manager._clear_cache()
  /// ```
  Object? setLevel({
    required Object? level,
  }) =>
      getFunction("setLevel").call(
        <Object?>[
          level,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## warn
  ///
  /// ### python source
  /// ```py
  /// def warn(self, msg, *args, **kwargs):
  ///         warnings.warn("The 'warn' method is deprecated, "
  ///             "use 'warning' instead", DeprecationWarning, 2)
  ///         self.warning(msg, *args, **kwargs)
  /// ```
  Object? warn({
    List<Object?> args = const <Object?>[],
    required Object? msg,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("warn").call(
        <Object?>[
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## warning
  ///
  /// ### python docstring
  ///
  /// Log 'msg % args' with severity 'WARNING'.
  ///
  /// To pass exception information, use the keyword argument exc_info with
  /// a true value, e.g.
  ///
  /// logger.warning("Houston, we have a %s", "bit of a problem", exc_info=1)
  ///
  /// ### python source
  /// ```py
  /// def warning(self, msg, *args, **kwargs):
  ///         """
  ///         Log 'msg % args' with severity 'WARNING'.
  ///
  ///         To pass exception information, use the keyword argument exc_info with
  ///         a true value, e.g.
  ///
  ///         logger.warning("Houston, we have a %s", "bit of a problem", exc_info=1)
  ///         """
  ///         if self.isEnabledFor(WARNING):
  ///             self._log(WARNING, msg, args, **kwargs)
  /// ```
  Object? warning({
    List<Object?> args = const <Object?>[],
    required Object? msg,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("warning").call(
        <Object?>[
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## manager (getter)
  ///
  /// ### python docstring
  ///
  /// There is [under normal circumstances] just one Manager instance, which
  /// holds the hierarchy of loggers.
  Object? get manager => getAttribute("manager");

  /// ## manager (setter)
  ///
  /// ### python docstring
  ///
  /// There is [under normal circumstances] just one Manager instance, which
  /// holds the hierarchy of loggers.
  set manager(Object? manager) => setAttribute("manager", manager);

  /// ## root (getter)
  ///
  /// ### python docstring
  ///
  /// A root logger is not that different to any other logger, except that
  /// it must have a logging level and there is only one instance of it in
  /// the hierarchy.
  Object? get root => getAttribute("root");

  /// ## root (setter)
  ///
  /// ### python docstring
  ///
  /// A root logger is not that different to any other logger, except that
  /// it must have a logging level and there is only one instance of it in
  /// the hierarchy.
  set root(Object? root) => setAttribute("root", root);
}

/// ## StrFormatStyle
///
/// ### python source
/// ```py
/// class StrFormatStyle(PercentStyle):
///     default_format = '{message}'
///     asctime_format = '{asctime}'
///     asctime_search = '{asctime'
///
///     fmt_spec = re.compile(r'^(.?[<>=^])?[+ -]?#?0?(\d+|{\w+})?[,_]?(\.(\d+|{\w+}))?[bcdefgnosx%]?$', re.I)
///     field_spec = re.compile(r'^(\d+|\w+)(\.\w+|\[[^]]+\])*$')
///
///     def _format(self, record):
///         if defaults := self._defaults:
///             values = defaults | record.__dict__
///         else:
///             values = record.__dict__
///         return self._fmt.format(**values)
///
///     def validate(self):
///         """Validate the input format, ensure it is the correct string formatting style"""
///         fields = set()
///         try:
///             for _, fieldname, spec, conversion in _str_formatter.parse(self._fmt):
///                 if fieldname:
///                     if not self.field_spec.match(fieldname):
///                         raise ValueError('invalid field name/expression: %r' % fieldname)
///                     fields.add(fieldname)
///                 if conversion and conversion not in 'rsa':
///                     raise ValueError('invalid conversion: %r' % conversion)
///                 if spec and not self.fmt_spec.match(spec):
///                     raise ValueError('bad specifier: %r' % spec)
///         except ValueError as e:
///             raise ValueError('invalid format: %s' % e)
///         if not fields:
///             raise ValueError('invalid format: no fields')
/// ```
final class StrFormatStyle extends PythonClass {
  factory StrFormatStyle({
    required Object? fmt,
    Object? defaults,
  }) =>
      PythonFfiDart.instance.importClass(
        "logging",
        "StrFormatStyle",
        StrFormatStyle.from,
        <Object?>[
          fmt,
        ],
        <String, Object?>{
          "defaults": defaults,
        },
      );

  StrFormatStyle.from(super.pythonClass) : super.from();

  /// ## format
  ///
  /// ### python source
  /// ```py
  /// def format(self, record):
  ///         try:
  ///             return self._format(record)
  ///         except KeyError as e:
  ///             raise ValueError('Formatting field not found in record: %s' % e)
  /// ```
  Object? format({
    required Object? record,
  }) =>
      getFunction("format").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## usesTime
  ///
  /// ### python source
  /// ```py
  /// def usesTime(self):
  ///         return self._fmt.find(self.asctime_search) >= 0
  /// ```
  Object? usesTime() => getFunction("usesTime").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## validate
  ///
  /// ### python docstring
  ///
  /// Validate the input format, ensure it is the correct string formatting style
  ///
  /// ### python source
  /// ```py
  /// def validate(self):
  ///         """Validate the input format, ensure it is the correct string formatting style"""
  ///         fields = set()
  ///         try:
  ///             for _, fieldname, spec, conversion in _str_formatter.parse(self._fmt):
  ///                 if fieldname:
  ///                     if not self.field_spec.match(fieldname):
  ///                         raise ValueError('invalid field name/expression: %r' % fieldname)
  ///                     fields.add(fieldname)
  ///                 if conversion and conversion not in 'rsa':
  ///                     raise ValueError('invalid conversion: %r' % conversion)
  ///                 if spec and not self.fmt_spec.match(spec):
  ///                     raise ValueError('bad specifier: %r' % spec)
  ///         except ValueError as e:
  ///             raise ValueError('invalid format: %s' % e)
  ///         if not fields:
  ///             raise ValueError('invalid format: no fields')
  /// ```
  Object? validate() => getFunction("validate").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## field_spec (getter)
  Object? get field_spec => getAttribute("field_spec");

  /// ## field_spec (setter)
  set field_spec(Object? field_spec) => setAttribute("field_spec", field_spec);

  /// ## fmt_spec (getter)
  Object? get fmt_spec => getAttribute("fmt_spec");

  /// ## fmt_spec (setter)
  set fmt_spec(Object? fmt_spec) => setAttribute("fmt_spec", fmt_spec);

  /// ## validation_pattern (getter)
  Object? get validation_pattern => getAttribute("validation_pattern");

  /// ## validation_pattern (setter)
  set validation_pattern(Object? validation_pattern) =>
      setAttribute("validation_pattern", validation_pattern);

  /// ## asctime_format (getter)
  Object? get asctime_format => getAttribute("asctime_format");

  /// ## asctime_format (setter)
  set asctime_format(Object? asctime_format) =>
      setAttribute("asctime_format", asctime_format);

  /// ## asctime_search (getter)
  Object? get asctime_search => getAttribute("asctime_search");

  /// ## asctime_search (setter)
  set asctime_search(Object? asctime_search) =>
      setAttribute("asctime_search", asctime_search);

  /// ## default_format (getter)
  Object? get default_format => getAttribute("default_format");

  /// ## default_format (setter)
  set default_format(Object? default_format) =>
      setAttribute("default_format", default_format);
}

/// ## StreamHandler
///
/// ### python docstring
///
/// A handler class which writes logging records, appropriately formatted,
/// to a stream. Note that this class does not close the stream, as
/// sys.stdout or sys.stderr may be used.
///
/// ### python source
/// ```py
/// class StreamHandler(Handler):
///     """
///     A handler class which writes logging records, appropriately formatted,
///     to a stream. Note that this class does not close the stream, as
///     sys.stdout or sys.stderr may be used.
///     """
///
///     terminator = '\n'
///
///     def __init__(self, stream=None):
///         """
///         Initialize the handler.
///
///         If stream is not specified, sys.stderr is used.
///         """
///         Handler.__init__(self)
///         if stream is None:
///             stream = sys.stderr
///         self.stream = stream
///
///     def flush(self):
///         """
///         Flushes the stream.
///         """
///         self.acquire()
///         try:
///             if self.stream and hasattr(self.stream, "flush"):
///                 self.stream.flush()
///         finally:
///             self.release()
///
///     def emit(self, record):
///         """
///         Emit a record.
///
///         If a formatter is specified, it is used to format the record.
///         The record is then written to the stream with a trailing newline.  If
///         exception information is present, it is formatted using
///         traceback.print_exception and appended to the stream.  If the stream
///         has an 'encoding' attribute, it is used to determine how to do the
///         output to the stream.
///         """
///         try:
///             msg = self.format(record)
///             stream = self.stream
///             # issue 35046: merged two stream.writes into one.
///             stream.write(msg + self.terminator)
///             self.flush()
///         except RecursionError:  # See issue 36272
///             raise
///         except Exception:
///             self.handleError(record)
///
///     def setStream(self, stream):
///         """
///         Sets the StreamHandler's stream to the specified value,
///         if it is different.
///
///         Returns the old stream, if the stream was changed, or None
///         if it wasn't.
///         """
///         if stream is self.stream:
///             result = None
///         else:
///             result = self.stream
///             self.acquire()
///             try:
///                 self.flush()
///                 self.stream = stream
///             finally:
///                 self.release()
///         return result
///
///     def __repr__(self):
///         level = getLevelName(self.level)
///         name = getattr(self.stream, 'name', '')
///         #  bpo-36015: name can be an int
///         name = str(name)
///         if name:
///             name += ' '
///         return '<%s %s(%s)>' % (self.__class__.__name__, name, level)
///
///     __class_getitem__ = classmethod(GenericAlias)
/// ```
final class StreamHandler extends PythonClass {
  factory StreamHandler({
    Object? stream,
  }) =>
      PythonFfiDart.instance.importClass(
        "logging",
        "StreamHandler",
        StreamHandler.from,
        <Object?>[
          stream,
        ],
        <String, Object?>{},
      );

  StreamHandler.from(super.pythonClass) : super.from();

  /// ## acquire
  ///
  /// ### python docstring
  ///
  /// Acquire the I/O thread lock.
  ///
  /// ### python source
  /// ```py
  /// def acquire(self):
  ///         """
  ///         Acquire the I/O thread lock.
  ///         """
  ///         if self.lock:
  ///             self.lock.acquire()
  /// ```
  Object? acquire() => getFunction("acquire").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## addFilter
  ///
  /// ### python docstring
  ///
  /// Add the specified filter to this handler.
  ///
  /// ### python source
  /// ```py
  /// def addFilter(self, filter):
  ///         """
  ///         Add the specified filter to this handler.
  ///         """
  ///         if not (filter in self.filters):
  ///             self.filters.append(filter)
  /// ```
  Object? addFilter({
    required Object? filter,
  }) =>
      getFunction("addFilter").call(
        <Object?>[
          filter,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## close
  ///
  /// ### python docstring
  ///
  /// Tidy up any resources used by the handler.
  ///
  /// This version removes the handler from an internal map of handlers,
  /// _handlers, which is used for handler lookup by name. Subclasses
  /// should ensure that this gets called from overridden close()
  /// methods.
  ///
  /// ### python source
  /// ```py
  /// def close(self):
  ///         """
  ///         Tidy up any resources used by the handler.
  ///
  ///         This version removes the handler from an internal map of handlers,
  ///         _handlers, which is used for handler lookup by name. Subclasses
  ///         should ensure that this gets called from overridden close()
  ///         methods.
  ///         """
  ///         #get the module data lock, as we're updating a shared structure.
  ///         _acquireLock()
  ///         try:    #unlikely to raise an exception, but you never know...
  ///             self._closed = True
  ///             if self._name and self._name in _handlers:
  ///                 del _handlers[self._name]
  ///         finally:
  ///             _releaseLock()
  /// ```
  Object? close() => getFunction("close").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## createLock
  ///
  /// ### python docstring
  ///
  /// Acquire a thread lock for serializing access to the underlying I/O.
  ///
  /// ### python source
  /// ```py
  /// def createLock(self):
  ///         """
  ///         Acquire a thread lock for serializing access to the underlying I/O.
  ///         """
  ///         self.lock = threading.RLock()
  ///         _register_at_fork_reinit_lock(self)
  /// ```
  Object? createLock() => getFunction("createLock").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## emit
  ///
  /// ### python docstring
  ///
  /// Emit a record.
  ///
  /// If a formatter is specified, it is used to format the record.
  /// The record is then written to the stream with a trailing newline.  If
  /// exception information is present, it is formatted using
  /// traceback.print_exception and appended to the stream.  If the stream
  /// has an 'encoding' attribute, it is used to determine how to do the
  /// output to the stream.
  ///
  /// ### python source
  /// ```py
  /// def emit(self, record):
  ///         """
  ///         Emit a record.
  ///
  ///         If a formatter is specified, it is used to format the record.
  ///         The record is then written to the stream with a trailing newline.  If
  ///         exception information is present, it is formatted using
  ///         traceback.print_exception and appended to the stream.  If the stream
  ///         has an 'encoding' attribute, it is used to determine how to do the
  ///         output to the stream.
  ///         """
  ///         try:
  ///             msg = self.format(record)
  ///             stream = self.stream
  ///             # issue 35046: merged two stream.writes into one.
  ///             stream.write(msg + self.terminator)
  ///             self.flush()
  ///         except RecursionError:  # See issue 36272
  ///             raise
  ///         except Exception:
  ///             self.handleError(record)
  /// ```
  Object? emit({
    required Object? record,
  }) =>
      getFunction("emit").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## filter
  ///
  /// ### python docstring
  ///
  /// Determine if a record is loggable by consulting all the filters.
  ///
  /// The default is to allow the record to be logged; any filter can veto
  /// this and the record is then dropped. Returns a zero value if a record
  /// is to be dropped, else non-zero.
  ///
  /// .. versionchanged:: 3.2
  ///
  ///    Allow filters to be just callables.
  ///
  /// ### python source
  /// ```py
  /// def filter(self, record):
  ///         """
  ///         Determine if a record is loggable by consulting all the filters.
  ///
  ///         The default is to allow the record to be logged; any filter can veto
  ///         this and the record is then dropped. Returns a zero value if a record
  ///         is to be dropped, else non-zero.
  ///
  ///         .. versionchanged:: 3.2
  ///
  ///            Allow filters to be just callables.
  ///         """
  ///         rv = True
  ///         for f in self.filters:
  ///             if hasattr(f, 'filter'):
  ///                 result = f.filter(record)
  ///             else:
  ///                 result = f(record) # assume callable - will raise if not
  ///             if not result:
  ///                 rv = False
  ///                 break
  ///         return rv
  /// ```
  Object? filter({
    required Object? record,
  }) =>
      getFunction("filter").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## flush
  ///
  /// ### python docstring
  ///
  /// Flushes the stream.
  ///
  /// ### python source
  /// ```py
  /// def flush(self):
  ///         """
  ///         Flushes the stream.
  ///         """
  ///         self.acquire()
  ///         try:
  ///             if self.stream and hasattr(self.stream, "flush"):
  ///                 self.stream.flush()
  ///         finally:
  ///             self.release()
  /// ```
  Object? flush() => getFunction("flush").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## format
  ///
  /// ### python docstring
  ///
  /// Format the specified record.
  ///
  /// If a formatter is set, use it. Otherwise, use the default formatter
  /// for the module.
  ///
  /// ### python source
  /// ```py
  /// def format(self, record):
  ///         """
  ///         Format the specified record.
  ///
  ///         If a formatter is set, use it. Otherwise, use the default formatter
  ///         for the module.
  ///         """
  ///         if self.formatter:
  ///             fmt = self.formatter
  ///         else:
  ///             fmt = _defaultFormatter
  ///         return fmt.format(record)
  /// ```
  Object? format({
    required Object? record,
  }) =>
      getFunction("format").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## get_name
  ///
  /// ### python source
  /// ```py
  /// def get_name(self):
  ///         return self._name
  /// ```
  Object? get_name() => getFunction("get_name").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## handle
  ///
  /// ### python docstring
  ///
  /// Conditionally emit the specified logging record.
  ///
  /// Emission depends on filters which may have been added to the handler.
  /// Wrap the actual emission of the record with acquisition/release of
  /// the I/O thread lock. Returns whether the filter passed the record for
  /// emission.
  ///
  /// ### python source
  /// ```py
  /// def handle(self, record):
  ///         """
  ///         Conditionally emit the specified logging record.
  ///
  ///         Emission depends on filters which may have been added to the handler.
  ///         Wrap the actual emission of the record with acquisition/release of
  ///         the I/O thread lock. Returns whether the filter passed the record for
  ///         emission.
  ///         """
  ///         rv = self.filter(record)
  ///         if rv:
  ///             self.acquire()
  ///             try:
  ///                 self.emit(record)
  ///             finally:
  ///                 self.release()
  ///         return rv
  /// ```
  Object? handle({
    required Object? record,
  }) =>
      getFunction("handle").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## handleError
  ///
  /// ### python docstring
  ///
  /// Handle errors which occur during an emit() call.
  ///
  /// This method should be called from handlers when an exception is
  /// encountered during an emit() call. If raiseExceptions is false,
  /// exceptions get silently ignored. This is what is mostly wanted
  /// for a logging system - most users will not care about errors in
  /// the logging system, they are more interested in application errors.
  /// You could, however, replace this with a custom handler if you wish.
  /// The record which was being processed is passed in to this method.
  ///
  /// ### python source
  /// ```py
  /// def handleError(self, record):
  ///         """
  ///         Handle errors which occur during an emit() call.
  ///
  ///         This method should be called from handlers when an exception is
  ///         encountered during an emit() call. If raiseExceptions is false,
  ///         exceptions get silently ignored. This is what is mostly wanted
  ///         for a logging system - most users will not care about errors in
  ///         the logging system, they are more interested in application errors.
  ///         You could, however, replace this with a custom handler if you wish.
  ///         The record which was being processed is passed in to this method.
  ///         """
  ///         if raiseExceptions and sys.stderr:  # see issue 13807
  ///             t, v, tb = sys.exc_info()
  ///             try:
  ///                 sys.stderr.write('--- Logging error ---\n')
  ///                 traceback.print_exception(t, v, tb, None, sys.stderr)
  ///                 sys.stderr.write('Call stack:\n')
  ///                 # Walk the stack frame up until we're out of logging,
  ///                 # so as to print the calling context.
  ///                 frame = tb.tb_frame
  ///                 while (frame and os.path.dirname(frame.f_code.co_filename) ==
  ///                        __path__[0]):
  ///                     frame = frame.f_back
  ///                 if frame:
  ///                     traceback.print_stack(frame, file=sys.stderr)
  ///                 else:
  ///                     # couldn't find the right stack frame, for some reason
  ///                     sys.stderr.write('Logged from file %s, line %s\n' % (
  ///                                      record.filename, record.lineno))
  ///                 # Issue 18671: output logging message and arguments
  ///                 try:
  ///                     sys.stderr.write('Message: %r\n'
  ///                                      'Arguments: %s\n' % (record.msg,
  ///                                                           record.args))
  ///                 except RecursionError:  # See issue 36272
  ///                     raise
  ///                 except Exception:
  ///                     sys.stderr.write('Unable to print the message and arguments'
  ///                                      ' - possible formatting error.\nUse the'
  ///                                      ' traceback above to help find the error.\n'
  ///                                     )
  ///             except OSError: #pragma: no cover
  ///                 pass    # see issue 5971
  ///             finally:
  ///                 del t, v, tb
  /// ```
  Object? handleError({
    required Object? record,
  }) =>
      getFunction("handleError").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## release
  ///
  /// ### python docstring
  ///
  /// Release the I/O thread lock.
  ///
  /// ### python source
  /// ```py
  /// def release(self):
  ///         """
  ///         Release the I/O thread lock.
  ///         """
  ///         if self.lock:
  ///             self.lock.release()
  /// ```
  Object? release() => getFunction("release").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## removeFilter
  ///
  /// ### python docstring
  ///
  /// Remove the specified filter from this handler.
  ///
  /// ### python source
  /// ```py
  /// def removeFilter(self, filter):
  ///         """
  ///         Remove the specified filter from this handler.
  ///         """
  ///         if filter in self.filters:
  ///             self.filters.remove(filter)
  /// ```
  Object? removeFilter({
    required Object? filter,
  }) =>
      getFunction("removeFilter").call(
        <Object?>[
          filter,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## setFormatter
  ///
  /// ### python docstring
  ///
  /// Set the formatter for this handler.
  ///
  /// ### python source
  /// ```py
  /// def setFormatter(self, fmt):
  ///         """
  ///         Set the formatter for this handler.
  ///         """
  ///         self.formatter = fmt
  /// ```
  Object? setFormatter({
    required Object? fmt,
  }) =>
      getFunction("setFormatter").call(
        <Object?>[
          fmt,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## setLevel
  ///
  /// ### python docstring
  ///
  /// Set the logging level of this handler.  level must be an int or a str.
  ///
  /// ### python source
  /// ```py
  /// def setLevel(self, level):
  ///         """
  ///         Set the logging level of this handler.  level must be an int or a str.
  ///         """
  ///         self.level = _checkLevel(level)
  /// ```
  Object? setLevel({
    required Object? level,
  }) =>
      getFunction("setLevel").call(
        <Object?>[
          level,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## setStream
  ///
  /// ### python docstring
  ///
  /// Sets the StreamHandler's stream to the specified value,
  /// if it is different.
  ///
  /// Returns the old stream, if the stream was changed, or None
  /// if it wasn't.
  ///
  /// ### python source
  /// ```py
  /// def setStream(self, stream):
  ///         """
  ///         Sets the StreamHandler's stream to the specified value,
  ///         if it is different.
  ///
  ///         Returns the old stream, if the stream was changed, or None
  ///         if it wasn't.
  ///         """
  ///         if stream is self.stream:
  ///             result = None
  ///         else:
  ///             result = self.stream
  ///             self.acquire()
  ///             try:
  ///                 self.flush()
  ///                 self.stream = stream
  ///             finally:
  ///                 self.release()
  ///         return result
  /// ```
  Object? setStream({
    required Object? stream,
  }) =>
      getFunction("setStream").call(
        <Object?>[
          stream,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## fset
  ///
  /// ### python source
  /// ```py
  /// def set_name(self, name):
  ///         _acquireLock()
  ///         try:
  ///             if self._name in _handlers:
  ///                 del _handlers[self._name]
  ///             self._name = name
  ///             if name:
  ///                 _handlers[name] = self
  ///         finally:
  ///             _releaseLock()
  /// ```
  Object? fset({
    required Object? name,
  }) =>
      getFunction("fset").call(
        <Object?>[
          name,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);

  /// ## terminator (getter)
  Object? get terminator => getAttribute("terminator");

  /// ## terminator (setter)
  set terminator(Object? terminator) => setAttribute("terminator", terminator);

  /// ## stream (getter)
  Object? get stream => getAttribute("stream");

  /// ## stream (setter)
  set stream(Object? stream) => setAttribute("stream", stream);
}

/// ## StringTemplateStyle
///
/// ### python source
/// ```py
/// class StringTemplateStyle(PercentStyle):
///     default_format = '${message}'
///     asctime_format = '${asctime}'
///     asctime_search = '${asctime}'
///
///     def __init__(self, *args, **kwargs):
///         super().__init__(*args, **kwargs)
///         self._tpl = Template(self._fmt)
///
///     def usesTime(self):
///         fmt = self._fmt
///         return fmt.find('$asctime') >= 0 or fmt.find(self.asctime_search) >= 0
///
///     def validate(self):
///         pattern = Template.pattern
///         fields = set()
///         for m in pattern.finditer(self._fmt):
///             d = m.groupdict()
///             if d['named']:
///                 fields.add(d['named'])
///             elif d['braced']:
///                 fields.add(d['braced'])
///             elif m.group(0) == '$':
///                 raise ValueError('invalid format: bare \'$\' not allowed')
///         if not fields:
///             raise ValueError('invalid format: no fields')
///
///     def _format(self, record):
///         if defaults := self._defaults:
///             values = defaults | record.__dict__
///         else:
///             values = record.__dict__
///         return self._tpl.substitute(**values)
/// ```
final class StringTemplateStyle extends PythonClass {
  factory StringTemplateStyle({
    List<Object?> args = const <Object?>[],
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      PythonFfiDart.instance.importClass(
        "logging",
        "StringTemplateStyle",
        StringTemplateStyle.from,
        <Object?>[
          ...args,
        ],
        <String, Object?>{
          ...kwargs,
        },
      );

  StringTemplateStyle.from(super.pythonClass) : super.from();

  /// ## format
  ///
  /// ### python source
  /// ```py
  /// def format(self, record):
  ///         try:
  ///             return self._format(record)
  ///         except KeyError as e:
  ///             raise ValueError('Formatting field not found in record: %s' % e)
  /// ```
  Object? format({
    required Object? record,
  }) =>
      getFunction("format").call(
        <Object?>[
          record,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## usesTime
  ///
  /// ### python source
  /// ```py
  /// def usesTime(self):
  ///         fmt = self._fmt
  ///         return fmt.find('$asctime') >= 0 or fmt.find(self.asctime_search) >= 0
  /// ```
  Object? usesTime() => getFunction("usesTime").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## validate
  ///
  /// ### python docstring
  ///
  /// Validate the input format, ensure it matches the correct style
  ///
  /// ### python source
  /// ```py
  /// def validate(self):
  ///         pattern = Template.pattern
  ///         fields = set()
  ///         for m in pattern.finditer(self._fmt):
  ///             d = m.groupdict()
  ///             if d['named']:
  ///                 fields.add(d['named'])
  ///             elif d['braced']:
  ///                 fields.add(d['braced'])
  ///             elif m.group(0) == '$':
  ///                 raise ValueError('invalid format: bare \'$\' not allowed')
  ///         if not fields:
  ///             raise ValueError('invalid format: no fields')
  /// ```
  Object? validate() => getFunction("validate").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## validation_pattern (getter)
  Object? get validation_pattern => getAttribute("validation_pattern");

  /// ## validation_pattern (setter)
  set validation_pattern(Object? validation_pattern) =>
      setAttribute("validation_pattern", validation_pattern);

  /// ## asctime_format (getter)
  Object? get asctime_format => getAttribute("asctime_format");

  /// ## asctime_format (setter)
  set asctime_format(Object? asctime_format) =>
      setAttribute("asctime_format", asctime_format);

  /// ## asctime_search (getter)
  Object? get asctime_search => getAttribute("asctime_search");

  /// ## asctime_search (setter)
  set asctime_search(Object? asctime_search) =>
      setAttribute("asctime_search", asctime_search);

  /// ## default_format (getter)
  Object? get default_format => getAttribute("default_format");

  /// ## default_format (setter)
  set default_format(Object? default_format) =>
      setAttribute("default_format", default_format);
}

/// ## Template
///
/// ### python docstring
///
/// A string class for supporting $-substitutions.
///
/// ### python source
/// ```py
/// class Template:
///     """A string class for supporting $-substitutions."""
///
///     delimiter = '$'
///     # r'[a-z]' matches to non-ASCII letters when used with IGNORECASE, but
///     # without the ASCII flag.  We can't add re.ASCII to flags because of
///     # backward compatibility.  So we use the ?a local flag and [a-z] pattern.
///     # See https://bugs.python.org/issue31672
///     idpattern = r'(?a:[_a-z][_a-z0-9]*)'
///     braceidpattern = None
///     flags = _re.IGNORECASE
///
///     def __init_subclass__(cls):
///         super().__init_subclass__()
///         if 'pattern' in cls.__dict__:
///             pattern = cls.pattern
///         else:
///             delim = _re.escape(cls.delimiter)
///             id = cls.idpattern
///             bid = cls.braceidpattern or cls.idpattern
///             pattern = fr"""
///             {delim}(?:
///               (?P<escaped>{delim})  |   # Escape sequence of two delimiters
///               (?P<named>{id})       |   # delimiter and a Python identifier
///               {{(?P<braced>{bid})}} |   # delimiter and a braced identifier
///               (?P<invalid>)             # Other ill-formed delimiter exprs
///             )
///             """
///         cls.pattern = _re.compile(pattern, cls.flags | _re.VERBOSE)
///
///     def __init__(self, template):
///         self.template = template
///
///     # Search for $$, $identifier, ${identifier}, and any bare $'s
///
///     def _invalid(self, mo):
///         i = mo.start('invalid')
///         lines = self.template[:i].splitlines(keepends=True)
///         if not lines:
///             colno = 1
///             lineno = 1
///         else:
///             colno = i - len(''.join(lines[:-1]))
///             lineno = len(lines)
///         raise ValueError('Invalid placeholder in string: line %d, col %d' %
///                          (lineno, colno))
///
///     def substitute(self, mapping=_sentinel_dict, /, **kws):
///         if mapping is _sentinel_dict:
///             mapping = kws
///         elif kws:
///             mapping = _ChainMap(kws, mapping)
///         # Helper function for .sub()
///         def convert(mo):
///             # Check the most common path first.
///             named = mo.group('named') or mo.group('braced')
///             if named is not None:
///                 return str(mapping[named])
///             if mo.group('escaped') is not None:
///                 return self.delimiter
///             if mo.group('invalid') is not None:
///                 self._invalid(mo)
///             raise ValueError('Unrecognized named group in pattern',
///                              self.pattern)
///         return self.pattern.sub(convert, self.template)
///
///     def safe_substitute(self, mapping=_sentinel_dict, /, **kws):
///         if mapping is _sentinel_dict:
///             mapping = kws
///         elif kws:
///             mapping = _ChainMap(kws, mapping)
///         # Helper function for .sub()
///         def convert(mo):
///             named = mo.group('named') or mo.group('braced')
///             if named is not None:
///                 try:
///                     return str(mapping[named])
///                 except KeyError:
///                     return mo.group()
///             if mo.group('escaped') is not None:
///                 return self.delimiter
///             if mo.group('invalid') is not None:
///                 return mo.group()
///             raise ValueError('Unrecognized named group in pattern',
///                              self.pattern)
///         return self.pattern.sub(convert, self.template)
///
///     def is_valid(self):
///         for mo in self.pattern.finditer(self.template):
///             if mo.group('invalid') is not None:
///                 return False
///             if (mo.group('named') is None
///                 and mo.group('braced') is None
///                 and mo.group('escaped') is None):
///                 # If all the groups are None, there must be
///                 # another group we're not expecting
///                 raise ValueError('Unrecognized named group in pattern',
///                     self.pattern)
///         return True
///
///     def get_identifiers(self):
///         ids = []
///         for mo in self.pattern.finditer(self.template):
///             named = mo.group('named') or mo.group('braced')
///             if named is not None and named not in ids:
///                 # add a named group only the first time it appears
///                 ids.append(named)
///             elif (named is None
///                 and mo.group('invalid') is None
///                 and mo.group('escaped') is None):
///                 # If all the groups are None, there must be
///                 # another group we're not expecting
///                 raise ValueError('Unrecognized named group in pattern',
///                     self.pattern)
///         return ids
/// ```
final class Template extends PythonClass {
  factory Template({
    required Object? template,
  }) =>
      PythonFfiDart.instance.importClass(
        "string",
        "Template",
        Template.from,
        <Object?>[
          template,
        ],
        <String, Object?>{},
      );

  Template.from(super.pythonClass) : super.from();

  /// ## get_identifiers
  ///
  /// ### python source
  /// ```py
  /// def get_identifiers(self):
  ///         ids = []
  ///         for mo in self.pattern.finditer(self.template):
  ///             named = mo.group('named') or mo.group('braced')
  ///             if named is not None and named not in ids:
  ///                 # add a named group only the first time it appears
  ///                 ids.append(named)
  ///             elif (named is None
  ///                 and mo.group('invalid') is None
  ///                 and mo.group('escaped') is None):
  ///                 # If all the groups are None, there must be
  ///                 # another group we're not expecting
  ///                 raise ValueError('Unrecognized named group in pattern',
  ///                     self.pattern)
  ///         return ids
  /// ```
  Object? get_identifiers() => getFunction("get_identifiers").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## is_valid
  ///
  /// ### python source
  /// ```py
  /// def is_valid(self):
  ///         for mo in self.pattern.finditer(self.template):
  ///             if mo.group('invalid') is not None:
  ///                 return False
  ///             if (mo.group('named') is None
  ///                 and mo.group('braced') is None
  ///                 and mo.group('escaped') is None):
  ///                 # If all the groups are None, there must be
  ///                 # another group we're not expecting
  ///                 raise ValueError('Unrecognized named group in pattern',
  ///                     self.pattern)
  ///         return True
  /// ```
  Object? is_valid() => getFunction("is_valid").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## safe_substitute
  ///
  /// ### python source
  /// ```py
  /// def safe_substitute(self, mapping=_sentinel_dict, /, **kws):
  ///         if mapping is _sentinel_dict:
  ///             mapping = kws
  ///         elif kws:
  ///             mapping = _ChainMap(kws, mapping)
  ///         # Helper function for .sub()
  ///         def convert(mo):
  ///             named = mo.group('named') or mo.group('braced')
  ///             if named is not None:
  ///                 try:
  ///                     return str(mapping[named])
  ///                 except KeyError:
  ///                     return mo.group()
  ///             if mo.group('escaped') is not None:
  ///                 return self.delimiter
  ///             if mo.group('invalid') is not None:
  ///                 return mo.group()
  ///             raise ValueError('Unrecognized named group in pattern',
  ///                              self.pattern)
  ///         return self.pattern.sub(convert, self.template)
  /// ```
  Object? safe_substitute(
    Object? mapping, {
    Map<String, Object?> kws = const <String, Object?>{},
  }) =>
      getFunction("safe_substitute").call(
        <Object?>[
          mapping,
        ],
        kwargs: <String, Object?>{
          ...kws,
        },
      );

  /// ## substitute
  ///
  /// ### python source
  /// ```py
  /// def substitute(self, mapping=_sentinel_dict, /, **kws):
  ///         if mapping is _sentinel_dict:
  ///             mapping = kws
  ///         elif kws:
  ///             mapping = _ChainMap(kws, mapping)
  ///         # Helper function for .sub()
  ///         def convert(mo):
  ///             # Check the most common path first.
  ///             named = mo.group('named') or mo.group('braced')
  ///             if named is not None:
  ///                 return str(mapping[named])
  ///             if mo.group('escaped') is not None:
  ///                 return self.delimiter
  ///             if mo.group('invalid') is not None:
  ///                 self._invalid(mo)
  ///             raise ValueError('Unrecognized named group in pattern',
  ///                              self.pattern)
  ///         return self.pattern.sub(convert, self.template)
  /// ```
  Object? substitute(
    Object? mapping, {
    Map<String, Object?> kws = const <String, Object?>{},
  }) =>
      getFunction("substitute").call(
        <Object?>[
          mapping,
        ],
        kwargs: <String, Object?>{
          ...kws,
        },
      );

  /// ## pattern (getter)
  Object? get pattern => getAttribute("pattern");

  /// ## pattern (setter)
  set pattern(Object? pattern) => setAttribute("pattern", pattern);

  /// ## braceidpattern (getter)
  Object? get braceidpattern => getAttribute("braceidpattern");

  /// ## braceidpattern (setter)
  set braceidpattern(Object? braceidpattern) =>
      setAttribute("braceidpattern", braceidpattern);

  /// ## delimiter (getter)
  Object? get delimiter => getAttribute("delimiter");

  /// ## delimiter (setter)
  set delimiter(Object? delimiter) => setAttribute("delimiter", delimiter);

  /// ## flags (getter)
  Object? get flags => getAttribute("flags");

  /// ## flags (setter)
  set flags(Object? flags) => setAttribute("flags", flags);

  /// ## idpattern (getter)
  Object? get idpattern => getAttribute("idpattern");

  /// ## idpattern (setter)
  set idpattern(Object? idpattern) => setAttribute("idpattern", idpattern);

  /// ## template (getter)
  Object? get template => getAttribute("template");

  /// ## template (setter)
  set template(Object? template) => setAttribute("template", template);
}

/// ## ChainMap
///
/// ### python docstring
///
/// A ChainMap groups multiple dicts (or other mappings) together
/// to create a single, updateable view.
///
/// The underlying mappings are stored in a list.  That list is public and can
/// be accessed or updated using the *maps* attribute.  There is no other
/// state.
///
/// Lookups search the underlying mappings successively until a key is found.
/// In contrast, writes, updates, and deletions only operate on the first
/// mapping.
///
/// ### python source
/// ```py
/// class ChainMap(_collections_abc.MutableMapping):
///     ''' A ChainMap groups multiple dicts (or other mappings) together
///     to create a single, updateable view.
///
///     The underlying mappings are stored in a list.  That list is public and can
///     be accessed or updated using the *maps* attribute.  There is no other
///     state.
///
///     Lookups search the underlying mappings successively until a key is found.
///     In contrast, writes, updates, and deletions only operate on the first
///     mapping.
///
///     '''
///
///     def __init__(self, *maps):
///         '''Initialize a ChainMap by setting *maps* to the given mappings.
///         If no mappings are provided, a single empty dictionary is used.
///
///         '''
///         self.maps = list(maps) or [{}]          # always at least one map
///
///     def __missing__(self, key):
///         raise KeyError(key)
///
///     def __getitem__(self, key):
///         for mapping in self.maps:
///             try:
///                 return mapping[key]             # can't use 'key in mapping' with defaultdict
///             except KeyError:
///                 pass
///         return self.__missing__(key)            # support subclasses that define __missing__
///
///     def get(self, key, default=None):
///         return self[key] if key in self else default
///
///     def __len__(self):
///         return len(set().union(*self.maps))     # reuses stored hash values if possible
///
///     def __iter__(self):
///         d = {}
///         for mapping in reversed(self.maps):
///             d.update(dict.fromkeys(mapping))    # reuses stored hash values if possible
///         return iter(d)
///
///     def __contains__(self, key):
///         return any(key in m for m in self.maps)
///
///     def __bool__(self):
///         return any(self.maps)
///
///     @_recursive_repr()
///     def __repr__(self):
///         return f'{self.__class__.__name__}({", ".join(map(repr, self.maps))})'
///
///     @classmethod
///     def fromkeys(cls, iterable, *args):
///         'Create a ChainMap with a single dict created from the iterable.'
///         return cls(dict.fromkeys(iterable, *args))
///
///     def copy(self):
///         'New ChainMap or subclass with a new copy of maps[0] and refs to maps[1:]'
///         return self.__class__(self.maps[0].copy(), *self.maps[1:])
///
///     __copy__ = copy
///
///     def new_child(self, m=None, **kwargs):      # like Django's Context.push()
///         '''New ChainMap with a new map followed by all previous maps.
///         If no map is provided, an empty dict is used.
///         Keyword arguments update the map or new empty dict.
///         '''
///         if m is None:
///             m = kwargs
///         elif kwargs:
///             m.update(kwargs)
///         return self.__class__(m, *self.maps)
///
///     @property
///     def parents(self):                          # like Django's Context.pop()
///         'New ChainMap from maps[1:].'
///         return self.__class__(*self.maps[1:])
///
///     def __setitem__(self, key, value):
///         self.maps[0][key] = value
///
///     def __delitem__(self, key):
///         try:
///             del self.maps[0][key]
///         except KeyError:
///             raise KeyError(f'Key not found in the first mapping: {key!r}')
///
///     def popitem(self):
///         'Remove and return an item pair from maps[0]. Raise KeyError is maps[0] is empty.'
///         try:
///             return self.maps[0].popitem()
///         except KeyError:
///             raise KeyError('No keys found in the first mapping.')
///
///     def pop(self, key, *args):
///         'Remove *key* from maps[0] and return its value. Raise KeyError if *key* not in maps[0].'
///         try:
///             return self.maps[0].pop(key, *args)
///         except KeyError:
///             raise KeyError(f'Key not found in the first mapping: {key!r}')
///
///     def clear(self):
///         'Clear maps[0], leaving maps[1:] intact.'
///         self.maps[0].clear()
///
///     def __ior__(self, other):
///         self.maps[0].update(other)
///         return self
///
///     def __or__(self, other):
///         if not isinstance(other, _collections_abc.Mapping):
///             return NotImplemented
///         m = self.copy()
///         m.maps[0].update(other)
///         return m
///
///     def __ror__(self, other):
///         if not isinstance(other, _collections_abc.Mapping):
///             return NotImplemented
///         m = dict(other)
///         for child in reversed(self.maps):
///             m.update(child)
///         return self.__class__(m)
/// ```
final class ChainMap extends PythonClass {
  factory ChainMap({
    List<Object?> maps = const <Object?>[],
  }) =>
      PythonFfiDart.instance.importClass(
        "collections",
        "ChainMap",
        ChainMap.from,
        <Object?>[
          ...maps,
        ],
        <String, Object?>{},
      );

  ChainMap.from(super.pythonClass) : super.from();

  /// ## clear
  ///
  /// ### python docstring
  ///
  /// Clear maps[0], leaving maps[1:] intact.
  ///
  /// ### python source
  /// ```py
  /// def clear(self):
  ///         'Clear maps[0], leaving maps[1:] intact.'
  ///         self.maps[0].clear()
  /// ```
  Object? clear() => getFunction("clear").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## copy
  ///
  /// ### python docstring
  ///
  /// New ChainMap or subclass with a new copy of maps[0] and refs to maps[1:]
  ///
  /// ### python source
  /// ```py
  /// def copy(self):
  ///         'New ChainMap or subclass with a new copy of maps[0] and refs to maps[1:]'
  ///         return self.__class__(self.maps[0].copy(), *self.maps[1:])
  /// ```
  Object? copy() => getFunction("copy").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## get
  ///
  /// ### python docstring
  ///
  /// D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.
  ///
  /// ### python source
  /// ```py
  /// def get(self, key, default=None):
  ///         return self[key] if key in self else default
  /// ```
  Object? $get({
    required Object? key,
    Object? $default,
  }) =>
      getFunction("get").call(
        <Object?>[
          key,
          $default,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## items
  ///
  /// ### python docstring
  ///
  /// D.items() -> a set-like object providing a view on D's items
  Object? items() => getFunction("items").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## keys
  ///
  /// ### python docstring
  ///
  /// D.keys() -> a set-like object providing a view on D's keys
  Object? keys() => getFunction("keys").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## new_child
  ///
  /// ### python docstring
  ///
  /// New ChainMap with a new map followed by all previous maps.
  /// If no map is provided, an empty dict is used.
  /// Keyword arguments update the map or new empty dict.
  ///
  /// ### python source
  /// ```py
  /// def new_child(self, m=None, **kwargs):      # like Django's Context.push()
  ///         '''New ChainMap with a new map followed by all previous maps.
  ///         If no map is provided, an empty dict is used.
  ///         Keyword arguments update the map or new empty dict.
  ///         '''
  ///         if m is None:
  ///             m = kwargs
  ///         elif kwargs:
  ///             m.update(kwargs)
  ///         return self.__class__(m, *self.maps)
  /// ```
  Object? new_child({
    Object? m,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("new_child").call(
        <Object?>[
          m,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## pop
  ///
  /// ### python docstring
  ///
  /// Remove *key* from maps[0] and return its value. Raise KeyError if *key* not in maps[0].
  ///
  /// ### python source
  /// ```py
  /// def pop(self, key, *args):
  ///         'Remove *key* from maps[0] and return its value. Raise KeyError if *key* not in maps[0].'
  ///         try:
  ///             return self.maps[0].pop(key, *args)
  ///         except KeyError:
  ///             raise KeyError(f'Key not found in the first mapping: {key!r}')
  /// ```
  Object? pop({
    List<Object?> args = const <Object?>[],
    required Object? key,
  }) =>
      getFunction("pop").call(
        <Object?>[
          key,
          ...args,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## popitem
  ///
  /// ### python docstring
  ///
  /// Remove and return an item pair from maps[0]. Raise KeyError is maps[0] is empty.
  ///
  /// ### python source
  /// ```py
  /// def popitem(self):
  ///         'Remove and return an item pair from maps[0]. Raise KeyError is maps[0] is empty.'
  ///         try:
  ///             return self.maps[0].popitem()
  ///         except KeyError:
  ///             raise KeyError('No keys found in the first mapping.')
  /// ```
  Object? popitem() => getFunction("popitem").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## setdefault
  ///
  /// ### python docstring
  ///
  /// D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D
  Object? setdefault({
    required Object? key,
    Object? $default,
  }) =>
      getFunction("setdefault").call(
        <Object?>[
          key,
          $default,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## update
  ///
  /// ### python docstring
  ///
  /// D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.
  /// If E present and has a .keys() method, does:     for k in E: D[k] = E[k]
  /// If E present and lacks .keys() method, does:     for (k, v) in E: D[k] = v
  /// In either case, this is followed by: for k, v in F.items(): D[k] = v
  Object? update(
    Object? other, {
    Map<String, Object?> kwds = const <String, Object?>{},
  }) =>
      getFunction("update").call(
        <Object?>[
          other,
        ],
        kwargs: <String, Object?>{
          ...kwds,
        },
      );

  /// ## values
  ///
  /// ### python docstring
  ///
  /// D.values() -> an object providing a view on D's values
  Object? values() => getFunction("values").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## parents (getter)
  ///
  /// ### python docstring
  ///
  /// New ChainMap from maps[1:].
  Object? get parents => getAttribute("parents");

  /// ## parents (setter)
  ///
  /// ### python docstring
  ///
  /// New ChainMap from maps[1:].
  set parents(Object? parents) => setAttribute("parents", parents);

  /// ## fromkeys (getter)
  ///
  /// ### python docstring
  ///
  /// Create a ChainMap with a single dict created from the iterable.
  Object? get fromkeys => getAttribute("fromkeys");

  /// ## fromkeys (setter)
  ///
  /// ### python docstring
  ///
  /// Create a ChainMap with a single dict created from the iterable.
  set fromkeys(Object? fromkeys) => setAttribute("fromkeys", fromkeys);

  /// ## maps (getter)
  Object? get maps => getAttribute("maps");

  /// ## maps (setter)
  set maps(Object? maps) => setAttribute("maps", maps);
}

/// ## UserDict
///
/// ### python docstring
///
/// A MutableMapping is a generic container for associating
/// key/value pairs.
///
/// This class provides concrete generic implementations of all
/// methods except for __getitem__, __setitem__, __delitem__,
/// __iter__, and __len__.
///
/// ### python source
/// ```py
/// class UserDict(_collections_abc.MutableMapping):
///
///     # Start by filling-out the abstract methods
///     def __init__(self, dict=None, /, **kwargs):
///         self.data = {}
///         if dict is not None:
///             self.update(dict)
///         if kwargs:
///             self.update(kwargs)
///
///     def __len__(self):
///         return len(self.data)
///
///     def __getitem__(self, key):
///         if key in self.data:
///             return self.data[key]
///         if hasattr(self.__class__, "__missing__"):
///             return self.__class__.__missing__(self, key)
///         raise KeyError(key)
///
///     def __setitem__(self, key, item):
///         self.data[key] = item
///
///     def __delitem__(self, key):
///         del self.data[key]
///
///     def __iter__(self):
///         return iter(self.data)
///
///     # Modify __contains__ to work correctly when __missing__ is present
///     def __contains__(self, key):
///         return key in self.data
///
///     # Now, add the methods in dicts but not in MutableMapping
///     def __repr__(self):
///         return repr(self.data)
///
///     def __or__(self, other):
///         if isinstance(other, UserDict):
///             return self.__class__(self.data | other.data)
///         if isinstance(other, dict):
///             return self.__class__(self.data | other)
///         return NotImplemented
///
///     def __ror__(self, other):
///         if isinstance(other, UserDict):
///             return self.__class__(other.data | self.data)
///         if isinstance(other, dict):
///             return self.__class__(other | self.data)
///         return NotImplemented
///
///     def __ior__(self, other):
///         if isinstance(other, UserDict):
///             self.data |= other.data
///         else:
///             self.data |= other
///         return self
///
///     def __copy__(self):
///         inst = self.__class__.__new__(self.__class__)
///         inst.__dict__.update(self.__dict__)
///         # Create a copy and avoid triggering descriptors
///         inst.__dict__["data"] = self.__dict__["data"].copy()
///         return inst
///
///     def copy(self):
///         if self.__class__ is UserDict:
///             return UserDict(self.data.copy())
///         import copy
///         data = self.data
///         try:
///             self.data = {}
///             c = copy.copy(self)
///         finally:
///             self.data = data
///         c.update(self)
///         return c
///
///     @classmethod
///     def fromkeys(cls, iterable, value=None):
///         d = cls()
///         for key in iterable:
///             d[key] = value
///         return d
/// ```
final class UserDict extends PythonClass {
  factory UserDict(
    Object? dict, {
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      PythonFfiDart.instance.importClass(
        "collections",
        "UserDict",
        UserDict.from,
        <Object?>[
          dict,
        ],
        <String, Object?>{
          ...kwargs,
        },
      );

  UserDict.from(super.pythonClass) : super.from();

  /// ## clear
  ///
  /// ### python docstring
  ///
  /// D.clear() -> None.  Remove all items from D.
  Object? clear() => getFunction("clear").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## copy
  ///
  /// ### python source
  /// ```py
  /// def copy(self):
  ///         if self.__class__ is UserDict:
  ///             return UserDict(self.data.copy())
  ///         import copy
  ///         data = self.data
  ///         try:
  ///             self.data = {}
  ///             c = copy.copy(self)
  ///         finally:
  ///             self.data = data
  ///         c.update(self)
  ///         return c
  /// ```
  Object? copy() => getFunction("copy").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## get
  ///
  /// ### python docstring
  ///
  /// D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.
  Object? $get({
    required Object? key,
    Object? $default,
  }) =>
      getFunction("get").call(
        <Object?>[
          key,
          $default,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## items
  ///
  /// ### python docstring
  ///
  /// D.items() -> a set-like object providing a view on D's items
  Object? items() => getFunction("items").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## keys
  ///
  /// ### python docstring
  ///
  /// D.keys() -> a set-like object providing a view on D's keys
  Object? keys() => getFunction("keys").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## pop
  ///
  /// ### python docstring
  ///
  /// D.pop(k[,d]) -> v, remove specified key and return the corresponding value.
  /// If key is not found, d is returned if given, otherwise KeyError is raised.
  Object? pop({
    required Object? key,
    Object? $default,
  }) =>
      getFunction("pop").call(
        <Object?>[
          key,
          $default,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## popitem
  ///
  /// ### python docstring
  ///
  /// D.popitem() -> (k, v), remove and return some (key, value) pair
  /// as a 2-tuple; but raise KeyError if D is empty.
  Object? popitem() => getFunction("popitem").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## setdefault
  ///
  /// ### python docstring
  ///
  /// D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D
  Object? setdefault({
    required Object? key,
    Object? $default,
  }) =>
      getFunction("setdefault").call(
        <Object?>[
          key,
          $default,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## update
  ///
  /// ### python docstring
  ///
  /// D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.
  /// If E present and has a .keys() method, does:     for k in E: D[k] = E[k]
  /// If E present and lacks .keys() method, does:     for (k, v) in E: D[k] = v
  /// In either case, this is followed by: for k, v in F.items(): D[k] = v
  Object? update(
    Object? other, {
    Map<String, Object?> kwds = const <String, Object?>{},
  }) =>
      getFunction("update").call(
        <Object?>[
          other,
        ],
        kwargs: <String, Object?>{
          ...kwds,
        },
      );

  /// ## values
  ///
  /// ### python docstring
  ///
  /// D.values() -> an object providing a view on D's values
  Object? values() => getFunction("values").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## fromkeys (getter)
  Object? get fromkeys => getAttribute("fromkeys");

  /// ## fromkeys (setter)
  set fromkeys(Object? fromkeys) => setAttribute("fromkeys", fromkeys);

  /// ## data (getter)
  Object? get data => getAttribute("data");

  /// ## data (setter)
  set data(Object? data) => setAttribute("data", data);
}

/// ## UserList
///
/// ### python docstring
///
/// A more or less complete user-defined wrapper around list objects.
///
/// ### python source
/// ```py
/// class UserList(_collections_abc.MutableSequence):
///     """A more or less complete user-defined wrapper around list objects."""
///
///     def __init__(self, initlist=None):
///         self.data = []
///         if initlist is not None:
///             # XXX should this accept an arbitrary sequence?
///             if type(initlist) == type(self.data):
///                 self.data[:] = initlist
///             elif isinstance(initlist, UserList):
///                 self.data[:] = initlist.data[:]
///             else:
///                 self.data = list(initlist)
///
///     def __repr__(self):
///         return repr(self.data)
///
///     def __lt__(self, other):
///         return self.data < self.__cast(other)
///
///     def __le__(self, other):
///         return self.data <= self.__cast(other)
///
///     def __eq__(self, other):
///         return self.data == self.__cast(other)
///
///     def __gt__(self, other):
///         return self.data > self.__cast(other)
///
///     def __ge__(self, other):
///         return self.data >= self.__cast(other)
///
///     def __cast(self, other):
///         return other.data if isinstance(other, UserList) else other
///
///     def __contains__(self, item):
///         return item in self.data
///
///     def __len__(self):
///         return len(self.data)
///
///     def __getitem__(self, i):
///         if isinstance(i, slice):
///             return self.__class__(self.data[i])
///         else:
///             return self.data[i]
///
///     def __setitem__(self, i, item):
///         self.data[i] = item
///
///     def __delitem__(self, i):
///         del self.data[i]
///
///     def __add__(self, other):
///         if isinstance(other, UserList):
///             return self.__class__(self.data + other.data)
///         elif isinstance(other, type(self.data)):
///             return self.__class__(self.data + other)
///         return self.__class__(self.data + list(other))
///
///     def __radd__(self, other):
///         if isinstance(other, UserList):
///             return self.__class__(other.data + self.data)
///         elif isinstance(other, type(self.data)):
///             return self.__class__(other + self.data)
///         return self.__class__(list(other) + self.data)
///
///     def __iadd__(self, other):
///         if isinstance(other, UserList):
///             self.data += other.data
///         elif isinstance(other, type(self.data)):
///             self.data += other
///         else:
///             self.data += list(other)
///         return self
///
///     def __mul__(self, n):
///         return self.__class__(self.data * n)
///
///     __rmul__ = __mul__
///
///     def __imul__(self, n):
///         self.data *= n
///         return self
///
///     def __copy__(self):
///         inst = self.__class__.__new__(self.__class__)
///         inst.__dict__.update(self.__dict__)
///         # Create a copy and avoid triggering descriptors
///         inst.__dict__["data"] = self.__dict__["data"][:]
///         return inst
///
///     def append(self, item):
///         self.data.append(item)
///
///     def insert(self, i, item):
///         self.data.insert(i, item)
///
///     def pop(self, i=-1):
///         return self.data.pop(i)
///
///     def remove(self, item):
///         self.data.remove(item)
///
///     def clear(self):
///         self.data.clear()
///
///     def copy(self):
///         return self.__class__(self)
///
///     def count(self, item):
///         return self.data.count(item)
///
///     def index(self, item, *args):
///         return self.data.index(item, *args)
///
///     def reverse(self):
///         self.data.reverse()
///
///     def sort(self, /, *args, **kwds):
///         self.data.sort(*args, **kwds)
///
///     def extend(self, other):
///         if isinstance(other, UserList):
///             self.data.extend(other.data)
///         else:
///             self.data.extend(other)
/// ```
final class UserList extends PythonClass {
  factory UserList({
    Object? initlist,
  }) =>
      PythonFfiDart.instance.importClass(
        "collections",
        "UserList",
        UserList.from,
        <Object?>[
          initlist,
        ],
        <String, Object?>{},
      );

  UserList.from(super.pythonClass) : super.from();

  /// ## append
  ///
  /// ### python docstring
  ///
  /// S.append(value) -- append value to the end of the sequence
  ///
  /// ### python source
  /// ```py
  /// def append(self, item):
  ///         self.data.append(item)
  /// ```
  Object? append({
    required Object? item,
  }) =>
      getFunction("append").call(
        <Object?>[
          item,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## clear
  ///
  /// ### python docstring
  ///
  /// S.clear() -> None -- remove all items from S
  ///
  /// ### python source
  /// ```py
  /// def clear(self):
  ///         self.data.clear()
  /// ```
  Object? clear() => getFunction("clear").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## copy
  ///
  /// ### python source
  /// ```py
  /// def copy(self):
  ///         return self.__class__(self)
  /// ```
  Object? copy() => getFunction("copy").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## count
  ///
  /// ### python docstring
  ///
  /// S.count(value) -> integer -- return number of occurrences of value
  ///
  /// ### python source
  /// ```py
  /// def count(self, item):
  ///         return self.data.count(item)
  /// ```
  Object? count({
    required Object? item,
  }) =>
      getFunction("count").call(
        <Object?>[
          item,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## extend
  ///
  /// ### python docstring
  ///
  /// S.extend(iterable) -- extend sequence by appending elements from the iterable
  ///
  /// ### python source
  /// ```py
  /// def extend(self, other):
  ///         if isinstance(other, UserList):
  ///             self.data.extend(other.data)
  ///         else:
  ///             self.data.extend(other)
  /// ```
  Object? extend({
    required Object? other,
  }) =>
      getFunction("extend").call(
        <Object?>[
          other,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## index
  ///
  /// ### python docstring
  ///
  /// S.index(value, [start, [stop]]) -> integer -- return first index of value.
  /// Raises ValueError if the value is not present.
  ///
  /// Supporting start and stop arguments is optional, but
  /// recommended.
  ///
  /// ### python source
  /// ```py
  /// def index(self, item, *args):
  ///         return self.data.index(item, *args)
  /// ```
  Object? index({
    List<Object?> args = const <Object?>[],
    required Object? item,
  }) =>
      getFunction("index").call(
        <Object?>[
          item,
          ...args,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## insert
  ///
  /// ### python docstring
  ///
  /// S.insert(index, value) -- insert value before index
  ///
  /// ### python source
  /// ```py
  /// def insert(self, i, item):
  ///         self.data.insert(i, item)
  /// ```
  Object? insert({
    required Object? i,
    required Object? item,
  }) =>
      getFunction("insert").call(
        <Object?>[
          i,
          item,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## pop
  ///
  /// ### python docstring
  ///
  /// S.pop([index]) -> item -- remove and return item at index (default last).
  /// Raise IndexError if list is empty or index is out of range.
  ///
  /// ### python source
  /// ```py
  /// def pop(self, i=-1):
  ///         return self.data.pop(i)
  /// ```
  Object? pop({
    Object? i = -1,
  }) =>
      getFunction("pop").call(
        <Object?>[
          i,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## remove
  ///
  /// ### python docstring
  ///
  /// S.remove(value) -- remove first occurrence of value.
  /// Raise ValueError if the value is not present.
  ///
  /// ### python source
  /// ```py
  /// def remove(self, item):
  ///         self.data.remove(item)
  /// ```
  Object? remove({
    required Object? item,
  }) =>
      getFunction("remove").call(
        <Object?>[
          item,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## reverse
  ///
  /// ### python docstring
  ///
  /// S.reverse() -- reverse *IN PLACE*
  ///
  /// ### python source
  /// ```py
  /// def reverse(self):
  ///         self.data.reverse()
  /// ```
  Object? reverse() => getFunction("reverse").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## sort
  ///
  /// ### python source
  /// ```py
  /// def sort(self, /, *args, **kwds):
  ///         self.data.sort(*args, **kwds)
  /// ```
  Object? sort({
    List<Object?> args = const <Object?>[],
    Map<String, Object?> kwds = const <String, Object?>{},
  }) =>
      getFunction("sort").call(
        <Object?>[
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwds,
        },
      );

  /// ## data (getter)
  Object? get data => getAttribute("data");

  /// ## data (setter)
  set data(Object? data) => setAttribute("data", data);
}

/// ## UserString
///
/// ### python docstring
///
/// All the operations on a read-only sequence.
///
/// Concrete subclasses must override __new__ or __init__,
/// __getitem__, and __len__.
///
/// ### python source
/// ```py
/// class UserString(_collections_abc.Sequence):
///
///     def __init__(self, seq):
///         if isinstance(seq, str):
///             self.data = seq
///         elif isinstance(seq, UserString):
///             self.data = seq.data[:]
///         else:
///             self.data = str(seq)
///
///     def __str__(self):
///         return str(self.data)
///
///     def __repr__(self):
///         return repr(self.data)
///
///     def __int__(self):
///         return int(self.data)
///
///     def __float__(self):
///         return float(self.data)
///
///     def __complex__(self):
///         return complex(self.data)
///
///     def __hash__(self):
///         return hash(self.data)
///
///     def __getnewargs__(self):
///         return (self.data[:],)
///
///     def __eq__(self, string):
///         if isinstance(string, UserString):
///             return self.data == string.data
///         return self.data == string
///
///     def __lt__(self, string):
///         if isinstance(string, UserString):
///             return self.data < string.data
///         return self.data < string
///
///     def __le__(self, string):
///         if isinstance(string, UserString):
///             return self.data <= string.data
///         return self.data <= string
///
///     def __gt__(self, string):
///         if isinstance(string, UserString):
///             return self.data > string.data
///         return self.data > string
///
///     def __ge__(self, string):
///         if isinstance(string, UserString):
///             return self.data >= string.data
///         return self.data >= string
///
///     def __contains__(self, char):
///         if isinstance(char, UserString):
///             char = char.data
///         return char in self.data
///
///     def __len__(self):
///         return len(self.data)
///
///     def __getitem__(self, index):
///         return self.__class__(self.data[index])
///
///     def __add__(self, other):
///         if isinstance(other, UserString):
///             return self.__class__(self.data + other.data)
///         elif isinstance(other, str):
///             return self.__class__(self.data + other)
///         return self.__class__(self.data + str(other))
///
///     def __radd__(self, other):
///         if isinstance(other, str):
///             return self.__class__(other + self.data)
///         return self.__class__(str(other) + self.data)
///
///     def __mul__(self, n):
///         return self.__class__(self.data * n)
///
///     __rmul__ = __mul__
///
///     def __mod__(self, args):
///         return self.__class__(self.data % args)
///
///     def __rmod__(self, template):
///         return self.__class__(str(template) % self)
///
///     # the following methods are defined in alphabetical order:
///     def capitalize(self):
///         return self.__class__(self.data.capitalize())
///
///     def casefold(self):
///         return self.__class__(self.data.casefold())
///
///     def center(self, width, *args):
///         return self.__class__(self.data.center(width, *args))
///
///     def count(self, sub, start=0, end=_sys.maxsize):
///         if isinstance(sub, UserString):
///             sub = sub.data
///         return self.data.count(sub, start, end)
///
///     def removeprefix(self, prefix, /):
///         if isinstance(prefix, UserString):
///             prefix = prefix.data
///         return self.__class__(self.data.removeprefix(prefix))
///
///     def removesuffix(self, suffix, /):
///         if isinstance(suffix, UserString):
///             suffix = suffix.data
///         return self.__class__(self.data.removesuffix(suffix))
///
///     def encode(self, encoding='utf-8', errors='strict'):
///         encoding = 'utf-8' if encoding is None else encoding
///         errors = 'strict' if errors is None else errors
///         return self.data.encode(encoding, errors)
///
///     def endswith(self, suffix, start=0, end=_sys.maxsize):
///         return self.data.endswith(suffix, start, end)
///
///     def expandtabs(self, tabsize=8):
///         return self.__class__(self.data.expandtabs(tabsize))
///
///     def find(self, sub, start=0, end=_sys.maxsize):
///         if isinstance(sub, UserString):
///             sub = sub.data
///         return self.data.find(sub, start, end)
///
///     def format(self, /, *args, **kwds):
///         return self.data.format(*args, **kwds)
///
///     def format_map(self, mapping):
///         return self.data.format_map(mapping)
///
///     def index(self, sub, start=0, end=_sys.maxsize):
///         return self.data.index(sub, start, end)
///
///     def isalpha(self):
///         return self.data.isalpha()
///
///     def isalnum(self):
///         return self.data.isalnum()
///
///     def isascii(self):
///         return self.data.isascii()
///
///     def isdecimal(self):
///         return self.data.isdecimal()
///
///     def isdigit(self):
///         return self.data.isdigit()
///
///     def isidentifier(self):
///         return self.data.isidentifier()
///
///     def islower(self):
///         return self.data.islower()
///
///     def isnumeric(self):
///         return self.data.isnumeric()
///
///     def isprintable(self):
///         return self.data.isprintable()
///
///     def isspace(self):
///         return self.data.isspace()
///
///     def istitle(self):
///         return self.data.istitle()
///
///     def isupper(self):
///         return self.data.isupper()
///
///     def join(self, seq):
///         return self.data.join(seq)
///
///     def ljust(self, width, *args):
///         return self.__class__(self.data.ljust(width, *args))
///
///     def lower(self):
///         return self.__class__(self.data.lower())
///
///     def lstrip(self, chars=None):
///         return self.__class__(self.data.lstrip(chars))
///
///     maketrans = str.maketrans
///
///     def partition(self, sep):
///         return self.data.partition(sep)
///
///     def replace(self, old, new, maxsplit=-1):
///         if isinstance(old, UserString):
///             old = old.data
///         if isinstance(new, UserString):
///             new = new.data
///         return self.__class__(self.data.replace(old, new, maxsplit))
///
///     def rfind(self, sub, start=0, end=_sys.maxsize):
///         if isinstance(sub, UserString):
///             sub = sub.data
///         return self.data.rfind(sub, start, end)
///
///     def rindex(self, sub, start=0, end=_sys.maxsize):
///         return self.data.rindex(sub, start, end)
///
///     def rjust(self, width, *args):
///         return self.__class__(self.data.rjust(width, *args))
///
///     def rpartition(self, sep):
///         return self.data.rpartition(sep)
///
///     def rstrip(self, chars=None):
///         return self.__class__(self.data.rstrip(chars))
///
///     def split(self, sep=None, maxsplit=-1):
///         return self.data.split(sep, maxsplit)
///
///     def rsplit(self, sep=None, maxsplit=-1):
///         return self.data.rsplit(sep, maxsplit)
///
///     def splitlines(self, keepends=False):
///         return self.data.splitlines(keepends)
///
///     def startswith(self, prefix, start=0, end=_sys.maxsize):
///         return self.data.startswith(prefix, start, end)
///
///     def strip(self, chars=None):
///         return self.__class__(self.data.strip(chars))
///
///     def swapcase(self):
///         return self.__class__(self.data.swapcase())
///
///     def title(self):
///         return self.__class__(self.data.title())
///
///     def translate(self, *args):
///         return self.__class__(self.data.translate(*args))
///
///     def upper(self):
///         return self.__class__(self.data.upper())
///
///     def zfill(self, width):
///         return self.__class__(self.data.zfill(width))
/// ```
final class UserString extends PythonClass {
  factory UserString({
    required Object? seq,
  }) =>
      PythonFfiDart.instance.importClass(
        "collections",
        "UserString",
        UserString.from,
        <Object?>[
          seq,
        ],
        <String, Object?>{},
      );

  UserString.from(super.pythonClass) : super.from();

  /// ## capitalize
  ///
  /// ### python source
  /// ```py
  /// def capitalize(self):
  ///         return self.__class__(self.data.capitalize())
  /// ```
  Object? capitalize() => getFunction("capitalize").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## casefold
  ///
  /// ### python source
  /// ```py
  /// def casefold(self):
  ///         return self.__class__(self.data.casefold())
  /// ```
  Object? casefold() => getFunction("casefold").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## center
  ///
  /// ### python source
  /// ```py
  /// def center(self, width, *args):
  ///         return self.__class__(self.data.center(width, *args))
  /// ```
  Object? center({
    List<Object?> args = const <Object?>[],
    required Object? width,
  }) =>
      getFunction("center").call(
        <Object?>[
          width,
          ...args,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## count
  ///
  /// ### python docstring
  ///
  /// S.count(value) -> integer -- return number of occurrences of value
  ///
  /// ### python source
  /// ```py
  /// def count(self, sub, start=0, end=_sys.maxsize):
  ///         if isinstance(sub, UserString):
  ///             sub = sub.data
  ///         return self.data.count(sub, start, end)
  /// ```
  Object? count({
    required Object? sub,
    Object? start = 0,
    Object? end = 9223372036854775807,
  }) =>
      getFunction("count").call(
        <Object?>[
          sub,
          start,
          end,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## encode
  ///
  /// ### python source
  /// ```py
  /// def encode(self, encoding='utf-8', errors='strict'):
  ///         encoding = 'utf-8' if encoding is None else encoding
  ///         errors = 'strict' if errors is None else errors
  ///         return self.data.encode(encoding, errors)
  /// ```
  Object? encode({
    Object? encoding = "utf-8",
    Object? errors = "strict",
  }) =>
      getFunction("encode").call(
        <Object?>[
          encoding,
          errors,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## endswith
  ///
  /// ### python source
  /// ```py
  /// def endswith(self, suffix, start=0, end=_sys.maxsize):
  ///         return self.data.endswith(suffix, start, end)
  /// ```
  Object? endswith({
    required Object? suffix,
    Object? start = 0,
    Object? end = 9223372036854775807,
  }) =>
      getFunction("endswith").call(
        <Object?>[
          suffix,
          start,
          end,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## expandtabs
  ///
  /// ### python source
  /// ```py
  /// def expandtabs(self, tabsize=8):
  ///         return self.__class__(self.data.expandtabs(tabsize))
  /// ```
  Object? expandtabs({
    Object? tabsize = 8,
  }) =>
      getFunction("expandtabs").call(
        <Object?>[
          tabsize,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## find
  ///
  /// ### python source
  /// ```py
  /// def find(self, sub, start=0, end=_sys.maxsize):
  ///         if isinstance(sub, UserString):
  ///             sub = sub.data
  ///         return self.data.find(sub, start, end)
  /// ```
  Object? find({
    required Object? sub,
    Object? start = 0,
    Object? end = 9223372036854775807,
  }) =>
      getFunction("find").call(
        <Object?>[
          sub,
          start,
          end,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## format
  ///
  /// ### python source
  /// ```py
  /// def format(self, /, *args, **kwds):
  ///         return self.data.format(*args, **kwds)
  /// ```
  Object? format({
    List<Object?> args = const <Object?>[],
    Map<String, Object?> kwds = const <String, Object?>{},
  }) =>
      getFunction("format").call(
        <Object?>[
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwds,
        },
      );

  /// ## format_map
  ///
  /// ### python source
  /// ```py
  /// def format_map(self, mapping):
  ///         return self.data.format_map(mapping)
  /// ```
  Object? format_map({
    required Object? mapping,
  }) =>
      getFunction("format_map").call(
        <Object?>[
          mapping,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## index
  ///
  /// ### python docstring
  ///
  /// S.index(value, [start, [stop]]) -> integer -- return first index of value.
  /// Raises ValueError if the value is not present.
  ///
  /// Supporting start and stop arguments is optional, but
  /// recommended.
  ///
  /// ### python source
  /// ```py
  /// def index(self, sub, start=0, end=_sys.maxsize):
  ///         return self.data.index(sub, start, end)
  /// ```
  Object? index({
    required Object? sub,
    Object? start = 0,
    Object? end = 9223372036854775807,
  }) =>
      getFunction("index").call(
        <Object?>[
          sub,
          start,
          end,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## isalnum
  ///
  /// ### python source
  /// ```py
  /// def isalnum(self):
  ///         return self.data.isalnum()
  /// ```
  Object? isalnum() => getFunction("isalnum").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## isalpha
  ///
  /// ### python source
  /// ```py
  /// def isalpha(self):
  ///         return self.data.isalpha()
  /// ```
  Object? isalpha() => getFunction("isalpha").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## isascii
  ///
  /// ### python source
  /// ```py
  /// def isascii(self):
  ///         return self.data.isascii()
  /// ```
  Object? isascii() => getFunction("isascii").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## isdecimal
  ///
  /// ### python source
  /// ```py
  /// def isdecimal(self):
  ///         return self.data.isdecimal()
  /// ```
  Object? isdecimal() => getFunction("isdecimal").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## isdigit
  ///
  /// ### python source
  /// ```py
  /// def isdigit(self):
  ///         return self.data.isdigit()
  /// ```
  Object? isdigit() => getFunction("isdigit").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## isidentifier
  ///
  /// ### python source
  /// ```py
  /// def isidentifier(self):
  ///         return self.data.isidentifier()
  /// ```
  Object? isidentifier() => getFunction("isidentifier").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## islower
  ///
  /// ### python source
  /// ```py
  /// def islower(self):
  ///         return self.data.islower()
  /// ```
  Object? islower() => getFunction("islower").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## isnumeric
  ///
  /// ### python source
  /// ```py
  /// def isnumeric(self):
  ///         return self.data.isnumeric()
  /// ```
  Object? isnumeric() => getFunction("isnumeric").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## isprintable
  ///
  /// ### python source
  /// ```py
  /// def isprintable(self):
  ///         return self.data.isprintable()
  /// ```
  Object? isprintable() => getFunction("isprintable").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## isspace
  ///
  /// ### python source
  /// ```py
  /// def isspace(self):
  ///         return self.data.isspace()
  /// ```
  Object? isspace() => getFunction("isspace").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## istitle
  ///
  /// ### python source
  /// ```py
  /// def istitle(self):
  ///         return self.data.istitle()
  /// ```
  Object? istitle() => getFunction("istitle").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## isupper
  ///
  /// ### python source
  /// ```py
  /// def isupper(self):
  ///         return self.data.isupper()
  /// ```
  Object? isupper() => getFunction("isupper").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## join
  ///
  /// ### python source
  /// ```py
  /// def join(self, seq):
  ///         return self.data.join(seq)
  /// ```
  Object? join({
    required Object? seq,
  }) =>
      getFunction("join").call(
        <Object?>[
          seq,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## ljust
  ///
  /// ### python source
  /// ```py
  /// def ljust(self, width, *args):
  ///         return self.__class__(self.data.ljust(width, *args))
  /// ```
  Object? ljust({
    List<Object?> args = const <Object?>[],
    required Object? width,
  }) =>
      getFunction("ljust").call(
        <Object?>[
          width,
          ...args,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## lower
  ///
  /// ### python source
  /// ```py
  /// def lower(self):
  ///         return self.__class__(self.data.lower())
  /// ```
  Object? lower() => getFunction("lower").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## lstrip
  ///
  /// ### python source
  /// ```py
  /// def lstrip(self, chars=None):
  ///         return self.__class__(self.data.lstrip(chars))
  /// ```
  Object? lstrip({
    Object? chars,
  }) =>
      getFunction("lstrip").call(
        <Object?>[
          chars,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## partition
  ///
  /// ### python source
  /// ```py
  /// def partition(self, sep):
  ///         return self.data.partition(sep)
  /// ```
  Object? partition({
    required Object? sep,
  }) =>
      getFunction("partition").call(
        <Object?>[
          sep,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## removeprefix
  ///
  /// ### python source
  /// ```py
  /// def removeprefix(self, prefix, /):
  ///         if isinstance(prefix, UserString):
  ///             prefix = prefix.data
  ///         return self.__class__(self.data.removeprefix(prefix))
  /// ```
  Object? removeprefix(
    Object? prefix,
  ) =>
      getFunction("removeprefix").call(
        <Object?>[
          prefix,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## removesuffix
  ///
  /// ### python source
  /// ```py
  /// def removesuffix(self, suffix, /):
  ///         if isinstance(suffix, UserString):
  ///             suffix = suffix.data
  ///         return self.__class__(self.data.removesuffix(suffix))
  /// ```
  Object? removesuffix(
    Object? suffix,
  ) =>
      getFunction("removesuffix").call(
        <Object?>[
          suffix,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## replace
  ///
  /// ### python source
  /// ```py
  /// def replace(self, old, new, maxsplit=-1):
  ///         if isinstance(old, UserString):
  ///             old = old.data
  ///         if isinstance(new, UserString):
  ///             new = new.data
  ///         return self.__class__(self.data.replace(old, new, maxsplit))
  /// ```
  Object? replace({
    required Object? old,
    required Object? $new,
    Object? maxsplit = -1,
  }) =>
      getFunction("replace").call(
        <Object?>[
          old,
          $new,
          maxsplit,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## rfind
  ///
  /// ### python source
  /// ```py
  /// def rfind(self, sub, start=0, end=_sys.maxsize):
  ///         if isinstance(sub, UserString):
  ///             sub = sub.data
  ///         return self.data.rfind(sub, start, end)
  /// ```
  Object? rfind({
    required Object? sub,
    Object? start = 0,
    Object? end = 9223372036854775807,
  }) =>
      getFunction("rfind").call(
        <Object?>[
          sub,
          start,
          end,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## rindex
  ///
  /// ### python source
  /// ```py
  /// def rindex(self, sub, start=0, end=_sys.maxsize):
  ///         return self.data.rindex(sub, start, end)
  /// ```
  Object? rindex({
    required Object? sub,
    Object? start = 0,
    Object? end = 9223372036854775807,
  }) =>
      getFunction("rindex").call(
        <Object?>[
          sub,
          start,
          end,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## rjust
  ///
  /// ### python source
  /// ```py
  /// def rjust(self, width, *args):
  ///         return self.__class__(self.data.rjust(width, *args))
  /// ```
  Object? rjust({
    List<Object?> args = const <Object?>[],
    required Object? width,
  }) =>
      getFunction("rjust").call(
        <Object?>[
          width,
          ...args,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## rpartition
  ///
  /// ### python source
  /// ```py
  /// def rpartition(self, sep):
  ///         return self.data.rpartition(sep)
  /// ```
  Object? rpartition({
    required Object? sep,
  }) =>
      getFunction("rpartition").call(
        <Object?>[
          sep,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## rsplit
  ///
  /// ### python source
  /// ```py
  /// def rsplit(self, sep=None, maxsplit=-1):
  ///         return self.data.rsplit(sep, maxsplit)
  /// ```
  Object? rsplit({
    Object? sep,
    Object? maxsplit = -1,
  }) =>
      getFunction("rsplit").call(
        <Object?>[
          sep,
          maxsplit,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## rstrip
  ///
  /// ### python source
  /// ```py
  /// def rstrip(self, chars=None):
  ///         return self.__class__(self.data.rstrip(chars))
  /// ```
  Object? rstrip({
    Object? chars,
  }) =>
      getFunction("rstrip").call(
        <Object?>[
          chars,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## split
  ///
  /// ### python source
  /// ```py
  /// def split(self, sep=None, maxsplit=-1):
  ///         return self.data.split(sep, maxsplit)
  /// ```
  Object? split({
    Object? sep,
    Object? maxsplit = -1,
  }) =>
      getFunction("split").call(
        <Object?>[
          sep,
          maxsplit,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## splitlines
  ///
  /// ### python source
  /// ```py
  /// def splitlines(self, keepends=False):
  ///         return self.data.splitlines(keepends)
  /// ```
  Object? splitlines({
    Object? keepends = false,
  }) =>
      getFunction("splitlines").call(
        <Object?>[
          keepends,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## startswith
  ///
  /// ### python source
  /// ```py
  /// def startswith(self, prefix, start=0, end=_sys.maxsize):
  ///         return self.data.startswith(prefix, start, end)
  /// ```
  Object? startswith({
    required Object? prefix,
    Object? start = 0,
    Object? end = 9223372036854775807,
  }) =>
      getFunction("startswith").call(
        <Object?>[
          prefix,
          start,
          end,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## strip
  ///
  /// ### python source
  /// ```py
  /// def strip(self, chars=None):
  ///         return self.__class__(self.data.strip(chars))
  /// ```
  Object? strip({
    Object? chars,
  }) =>
      getFunction("strip").call(
        <Object?>[
          chars,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## swapcase
  ///
  /// ### python source
  /// ```py
  /// def swapcase(self):
  ///         return self.__class__(self.data.swapcase())
  /// ```
  Object? swapcase() => getFunction("swapcase").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## title
  ///
  /// ### python source
  /// ```py
  /// def title(self):
  ///         return self.__class__(self.data.title())
  /// ```
  Object? title() => getFunction("title").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## translate
  ///
  /// ### python source
  /// ```py
  /// def translate(self, *args):
  ///         return self.__class__(self.data.translate(*args))
  /// ```
  Object? translate({
    List<Object?> args = const <Object?>[],
  }) =>
      getFunction("translate").call(
        <Object?>[
          ...args,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## upper
  ///
  /// ### python source
  /// ```py
  /// def upper(self):
  ///         return self.__class__(self.data.upper())
  /// ```
  Object? upper() => getFunction("upper").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## zfill
  ///
  /// ### python source
  /// ```py
  /// def zfill(self, width):
  ///         return self.__class__(self.data.zfill(width))
  /// ```
  Object? zfill({
    required Object? width,
  }) =>
      getFunction("zfill").call(
        <Object?>[
          width,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## data (getter)
  Object? get data => getAttribute("data");

  /// ## data (setter)
  set data(Object? data) => setAttribute("data", data);
}

/// ## AsyncGenerator
final class AsyncGenerator extends PythonClass {
  factory AsyncGenerator() => PythonFfiDart.instance.importClass(
        "collections.abc",
        "AsyncGenerator",
        AsyncGenerator.from,
        <Object?>[],
      );

  AsyncGenerator.from(super.pythonClass) : super.from();

  /// ## aclose
  ///
  /// ### python docstring
  ///
  /// Raise GeneratorExit inside coroutine.
  Object? aclose() => getFunction("aclose").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## asend
  ///
  /// ### python docstring
  ///
  /// Send a value into the asynchronous generator.
  /// Return next yielded value or raise StopAsyncIteration.
  Object? asend({
    required Object? value,
  }) =>
      getFunction("asend").call(
        <Object?>[
          value,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## athrow
  ///
  /// ### python docstring
  ///
  /// Raise an exception in the asynchronous generator.
  /// Return next yielded value or raise StopAsyncIteration.
  Object? athrow({
    required Object? typ,
    Object? val,
    Object? tb,
  }) =>
      getFunction("athrow").call(
        <Object?>[
          typ,
          val,
          tb,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## AsyncIterable
final class AsyncIterable extends PythonClass {
  factory AsyncIterable() => PythonFfiDart.instance.importClass(
        "collections.abc",
        "AsyncIterable",
        AsyncIterable.from,
        <Object?>[],
      );

  AsyncIterable.from(super.pythonClass) : super.from();
}

/// ## AsyncIterator
final class AsyncIterator extends PythonClass {
  factory AsyncIterator() => PythonFfiDart.instance.importClass(
        "collections.abc",
        "AsyncIterator",
        AsyncIterator.from,
        <Object?>[],
      );

  AsyncIterator.from(super.pythonClass) : super.from();
}

/// ## Awaitable
final class Awaitable extends PythonClass {
  factory Awaitable() => PythonFfiDart.instance.importClass(
        "collections.abc",
        "Awaitable",
        Awaitable.from,
        <Object?>[],
      );

  Awaitable.from(super.pythonClass) : super.from();
}

/// ## ByteString
///
/// ### python docstring
///
/// This unifies bytes and bytearray.
///
/// XXX Should add all their methods.
final class ByteString extends PythonClass {
  factory ByteString() => PythonFfiDart.instance.importClass(
        "collections.abc",
        "ByteString",
        ByteString.from,
        <Object?>[],
      );

  ByteString.from(super.pythonClass) : super.from();

  /// ## count
  ///
  /// ### python docstring
  ///
  /// S.count(value) -> integer -- return number of occurrences of value
  Object? count({
    required Object? value,
  }) =>
      getFunction("count").call(
        <Object?>[
          value,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## index
  ///
  /// ### python docstring
  ///
  /// S.index(value, [start, [stop]]) -> integer -- return first index of value.
  /// Raises ValueError if the value is not present.
  ///
  /// Supporting start and stop arguments is optional, but
  /// recommended.
  Object? index({
    required Object? value,
    Object? start = 0,
    Object? stop,
  }) =>
      getFunction("index").call(
        <Object?>[
          value,
          start,
          stop,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## Callable
final class Callable extends PythonClass {
  factory Callable() => PythonFfiDart.instance.importClass(
        "collections.abc",
        "Callable",
        Callable.from,
        <Object?>[],
      );

  Callable.from(super.pythonClass) : super.from();
}

/// ## Collection
final class Collection extends PythonClass {
  factory Collection() => PythonFfiDart.instance.importClass(
        "collections.abc",
        "Collection",
        Collection.from,
        <Object?>[],
      );

  Collection.from(super.pythonClass) : super.from();
}

/// ## Container
final class Container extends PythonClass {
  factory Container() => PythonFfiDart.instance.importClass(
        "collections.abc",
        "Container",
        Container.from,
        <Object?>[],
      );

  Container.from(super.pythonClass) : super.from();
}

/// ## Coroutine
final class Coroutine extends PythonClass {
  factory Coroutine() => PythonFfiDart.instance.importClass(
        "collections.abc",
        "Coroutine",
        Coroutine.from,
        <Object?>[],
      );

  Coroutine.from(super.pythonClass) : super.from();

  /// ## close
  ///
  /// ### python docstring
  ///
  /// Raise GeneratorExit inside coroutine.
  Object? close() => getFunction("close").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## send
  ///
  /// ### python docstring
  ///
  /// Send a value into the coroutine.
  /// Return next yielded value or raise StopIteration.
  Object? send({
    required Object? value,
  }) =>
      getFunction("send").call(
        <Object?>[
          value,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## throw
  ///
  /// ### python docstring
  ///
  /// Raise an exception in the coroutine.
  /// Return next yielded value or raise StopIteration.
  Object? $throw({
    required Object? typ,
    Object? val,
    Object? tb,
  }) =>
      getFunction("throw").call(
        <Object?>[
          typ,
          val,
          tb,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## Generator
final class Generator extends PythonClass {
  factory Generator() => PythonFfiDart.instance.importClass(
        "collections.abc",
        "Generator",
        Generator.from,
        <Object?>[],
      );

  Generator.from(super.pythonClass) : super.from();

  /// ## close
  ///
  /// ### python docstring
  ///
  /// Raise GeneratorExit inside generator.
  Object? close() => getFunction("close").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## send
  ///
  /// ### python docstring
  ///
  /// Send a value into the generator.
  /// Return next yielded value or raise StopIteration.
  Object? send({
    required Object? value,
  }) =>
      getFunction("send").call(
        <Object?>[
          value,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## throw
  ///
  /// ### python docstring
  ///
  /// Raise an exception in the generator.
  /// Return next yielded value or raise StopIteration.
  Object? $throw({
    required Object? typ,
    Object? val,
    Object? tb,
  }) =>
      getFunction("throw").call(
        <Object?>[
          typ,
          val,
          tb,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## Hashable
final class Hashable extends PythonClass {
  factory Hashable() => PythonFfiDart.instance.importClass(
        "collections.abc",
        "Hashable",
        Hashable.from,
        <Object?>[],
      );

  Hashable.from(super.pythonClass) : super.from();
}

/// ## ItemsView
///
/// ### python docstring
///
/// A set is a finite, iterable container.
///
/// This class provides concrete generic implementations of all
/// methods except for __contains__, __iter__ and __len__.
///
/// To override the comparisons (presumably for speed, as the
/// semantics are fixed), redefine __le__ and __ge__,
/// then the other operations will automatically follow suit.
final class ItemsView extends PythonClass {
  factory ItemsView({
    required Object? mapping,
  }) =>
      PythonFfiDart.instance.importClass(
        "collections.abc",
        "ItemsView",
        ItemsView.from,
        <Object?>[
          mapping,
        ],
        <String, Object?>{},
      );

  ItemsView.from(super.pythonClass) : super.from();

  /// ## isdisjoint
  ///
  /// ### python docstring
  ///
  /// Return True if two sets have a null intersection.
  Object? isdisjoint({
    required Object? other,
  }) =>
      getFunction("isdisjoint").call(
        <Object?>[
          other,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## Iterable
final class Iterable extends PythonClass {
  factory Iterable() => PythonFfiDart.instance.importClass(
        "collections.abc",
        "Iterable",
        Iterable.from,
        <Object?>[],
      );

  Iterable.from(super.pythonClass) : super.from();
}

/// ## Iterator
final class Iterator extends PythonClass {
  factory Iterator() => PythonFfiDart.instance.importClass(
        "collections.abc",
        "Iterator",
        Iterator.from,
        <Object?>[],
      );

  Iterator.from(super.pythonClass) : super.from();
}

/// ## KeysView
///
/// ### python docstring
///
/// A set is a finite, iterable container.
///
/// This class provides concrete generic implementations of all
/// methods except for __contains__, __iter__ and __len__.
///
/// To override the comparisons (presumably for speed, as the
/// semantics are fixed), redefine __le__ and __ge__,
/// then the other operations will automatically follow suit.
final class KeysView extends PythonClass {
  factory KeysView({
    required Object? mapping,
  }) =>
      PythonFfiDart.instance.importClass(
        "collections.abc",
        "KeysView",
        KeysView.from,
        <Object?>[
          mapping,
        ],
        <String, Object?>{},
      );

  KeysView.from(super.pythonClass) : super.from();

  /// ## isdisjoint
  ///
  /// ### python docstring
  ///
  /// Return True if two sets have a null intersection.
  Object? isdisjoint({
    required Object? other,
  }) =>
      getFunction("isdisjoint").call(
        <Object?>[
          other,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## MappingView
final class MappingView extends PythonClass {
  factory MappingView({
    required Object? mapping,
  }) =>
      PythonFfiDart.instance.importClass(
        "collections.abc",
        "MappingView",
        MappingView.from,
        <Object?>[
          mapping,
        ],
        <String, Object?>{},
      );

  MappingView.from(super.pythonClass) : super.from();
}

/// ## MutableSequence
///
/// ### python docstring
///
/// All the operations on a read-write sequence.
///
/// Concrete subclasses must provide __new__ or __init__,
/// __getitem__, __setitem__, __delitem__, __len__, and insert().
final class MutableSequence extends PythonClass {
  factory MutableSequence() => PythonFfiDart.instance.importClass(
        "collections.abc",
        "MutableSequence",
        MutableSequence.from,
        <Object?>[],
      );

  MutableSequence.from(super.pythonClass) : super.from();

  /// ## append
  ///
  /// ### python docstring
  ///
  /// S.append(value) -- append value to the end of the sequence
  Object? append({
    required Object? value,
  }) =>
      getFunction("append").call(
        <Object?>[
          value,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## clear
  ///
  /// ### python docstring
  ///
  /// S.clear() -> None -- remove all items from S
  Object? clear() => getFunction("clear").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## count
  ///
  /// ### python docstring
  ///
  /// S.count(value) -> integer -- return number of occurrences of value
  Object? count({
    required Object? value,
  }) =>
      getFunction("count").call(
        <Object?>[
          value,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## extend
  ///
  /// ### python docstring
  ///
  /// S.extend(iterable) -- extend sequence by appending elements from the iterable
  Object? extend({
    required Object? values,
  }) =>
      getFunction("extend").call(
        <Object?>[
          values,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## index
  ///
  /// ### python docstring
  ///
  /// S.index(value, [start, [stop]]) -> integer -- return first index of value.
  /// Raises ValueError if the value is not present.
  ///
  /// Supporting start and stop arguments is optional, but
  /// recommended.
  Object? index({
    required Object? value,
    Object? start = 0,
    Object? stop,
  }) =>
      getFunction("index").call(
        <Object?>[
          value,
          start,
          stop,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## insert
  ///
  /// ### python docstring
  ///
  /// S.insert(index, value) -- insert value before index
  Object? insert({
    required Object? index,
    required Object? value,
  }) =>
      getFunction("insert").call(
        <Object?>[
          index,
          value,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## pop
  ///
  /// ### python docstring
  ///
  /// S.pop([index]) -> item -- remove and return item at index (default last).
  /// Raise IndexError if list is empty or index is out of range.
  Object? pop({
    Object? index = -1,
  }) =>
      getFunction("pop").call(
        <Object?>[
          index,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## remove
  ///
  /// ### python docstring
  ///
  /// S.remove(value) -- remove first occurrence of value.
  /// Raise ValueError if the value is not present.
  Object? remove({
    required Object? value,
  }) =>
      getFunction("remove").call(
        <Object?>[
          value,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## reverse
  ///
  /// ### python docstring
  ///
  /// S.reverse() -- reverse *IN PLACE*
  Object? reverse() => getFunction("reverse").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );
}

/// ## MutableSet
///
/// ### python docstring
///
/// A mutable set is a finite, iterable container.
///
/// This class provides concrete generic implementations of all
/// methods except for __contains__, __iter__, __len__,
/// add(), and discard().
///
/// To override the comparisons (presumably for speed, as the
/// semantics are fixed), all you have to do is redefine __le__ and
/// then the other operations will automatically follow suit.
final class MutableSet extends PythonClass {
  factory MutableSet() => PythonFfiDart.instance.importClass(
        "collections.abc",
        "MutableSet",
        MutableSet.from,
        <Object?>[],
      );

  MutableSet.from(super.pythonClass) : super.from();

  /// ## add
  ///
  /// ### python docstring
  ///
  /// Add an element.
  Object? add({
    required Object? value,
  }) =>
      getFunction("add").call(
        <Object?>[
          value,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## clear
  ///
  /// ### python docstring
  ///
  /// This is slow (creates N new iterators!) but effective.
  Object? clear() => getFunction("clear").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## discard
  ///
  /// ### python docstring
  ///
  /// Remove an element.  Do not raise an exception if absent.
  Object? discard({
    required Object? value,
  }) =>
      getFunction("discard").call(
        <Object?>[
          value,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## isdisjoint
  ///
  /// ### python docstring
  ///
  /// Return True if two sets have a null intersection.
  Object? isdisjoint({
    required Object? other,
  }) =>
      getFunction("isdisjoint").call(
        <Object?>[
          other,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## pop
  ///
  /// ### python docstring
  ///
  /// Return the popped value.  Raise KeyError if empty.
  Object? pop() => getFunction("pop").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## remove
  ///
  /// ### python docstring
  ///
  /// Remove an element. If not a member, raise a KeyError.
  Object? remove({
    required Object? value,
  }) =>
      getFunction("remove").call(
        <Object?>[
          value,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## Reversible
final class Reversible extends PythonClass {
  factory Reversible() => PythonFfiDart.instance.importClass(
        "collections.abc",
        "Reversible",
        Reversible.from,
        <Object?>[],
      );

  Reversible.from(super.pythonClass) : super.from();
}

/// ## Sequence
///
/// ### python docstring
///
/// All the operations on a read-only sequence.
///
/// Concrete subclasses must override __new__ or __init__,
/// __getitem__, and __len__.
final class Sequence extends PythonClass {
  factory Sequence() => PythonFfiDart.instance.importClass(
        "collections.abc",
        "Sequence",
        Sequence.from,
        <Object?>[],
      );

  Sequence.from(super.pythonClass) : super.from();

  /// ## count
  ///
  /// ### python docstring
  ///
  /// S.count(value) -> integer -- return number of occurrences of value
  Object? count({
    required Object? value,
  }) =>
      getFunction("count").call(
        <Object?>[
          value,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## index
  ///
  /// ### python docstring
  ///
  /// S.index(value, [start, [stop]]) -> integer -- return first index of value.
  /// Raises ValueError if the value is not present.
  ///
  /// Supporting start and stop arguments is optional, but
  /// recommended.
  Object? index({
    required Object? value,
    Object? start = 0,
    Object? stop,
  }) =>
      getFunction("index").call(
        <Object?>[
          value,
          start,
          stop,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## Set
///
/// ### python docstring
///
/// A set is a finite, iterable container.
///
/// This class provides concrete generic implementations of all
/// methods except for __contains__, __iter__ and __len__.
///
/// To override the comparisons (presumably for speed, as the
/// semantics are fixed), redefine __le__ and __ge__,
/// then the other operations will automatically follow suit.
final class Set extends PythonClass {
  factory Set() => PythonFfiDart.instance.importClass(
        "collections.abc",
        "Set",
        Set.from,
        <Object?>[],
      );

  Set.from(super.pythonClass) : super.from();

  /// ## isdisjoint
  ///
  /// ### python docstring
  ///
  /// Return True if two sets have a null intersection.
  Object? isdisjoint({
    required Object? other,
  }) =>
      getFunction("isdisjoint").call(
        <Object?>[
          other,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## Sized
final class Sized extends PythonClass {
  factory Sized() => PythonFfiDart.instance.importClass(
        "collections.abc",
        "Sized",
        Sized.from,
        <Object?>[],
      );

  Sized.from(super.pythonClass) : super.from();
}

/// ## ValuesView
final class ValuesView extends PythonClass {
  factory ValuesView({
    required Object? mapping,
  }) =>
      PythonFfiDart.instance.importClass(
        "collections.abc",
        "ValuesView",
        ValuesView.from,
        <Object?>[
          mapping,
        ],
        <String, Object?>{},
      );

  ValuesView.from(super.pythonClass) : super.from();
}

/// ## Barrier
///
/// ### python docstring
///
/// Implements a Barrier.
///
/// Useful for synchronizing a fixed number of threads at known synchronization
/// points.  Threads block on 'wait()' and are simultaneously awoken once they
/// have all made that call.
///
/// ### python source
/// ```py
/// class Barrier:
///     """Implements a Barrier.
///
///     Useful for synchronizing a fixed number of threads at known synchronization
///     points.  Threads block on 'wait()' and are simultaneously awoken once they
///     have all made that call.
///
///     """
///
///     def __init__(self, parties, action=None, timeout=None):
///         """Create a barrier, initialised to 'parties' threads.
///
///         'action' is a callable which, when supplied, will be called by one of
///         the threads after they have all entered the barrier and just prior to
///         releasing them all. If a 'timeout' is provided, it is used as the
///         default for all subsequent 'wait()' calls.
///
///         """
///         self._cond = Condition(Lock())
///         self._action = action
///         self._timeout = timeout
///         self._parties = parties
///         self._state = 0  # 0 filling, 1 draining, -1 resetting, -2 broken
///         self._count = 0
///
///     def __repr__(self):
///         cls = self.__class__
///         if self.broken:
///             return f"<{cls.__module__}.{cls.__qualname__} at {id(self):#x}: broken>"
///         return (f"<{cls.__module__}.{cls.__qualname__} at {id(self):#x}:"
///                 f" waiters={self.n_waiting}/{self.parties}>")
///
///     def wait(self, timeout=None):
///         """Wait for the barrier.
///
///         When the specified number of threads have started waiting, they are all
///         simultaneously awoken. If an 'action' was provided for the barrier, one
///         of the threads will have executed that callback prior to returning.
///         Returns an individual index number from 0 to 'parties-1'.
///
///         """
///         if timeout is None:
///             timeout = self._timeout
///         with self._cond:
///             self._enter() # Block while the barrier drains.
///             index = self._count
///             self._count += 1
///             try:
///                 if index + 1 == self._parties:
///                     # We release the barrier
///                     self._release()
///                 else:
///                     # We wait until someone releases us
///                     self._wait(timeout)
///                 return index
///             finally:
///                 self._count -= 1
///                 # Wake up any threads waiting for barrier to drain.
///                 self._exit()
///
///     # Block until the barrier is ready for us, or raise an exception
///     # if it is broken.
///     def _enter(self):
///         while self._state in (-1, 1):
///             # It is draining or resetting, wait until done
///             self._cond.wait()
///         #see if the barrier is in a broken state
///         if self._state < 0:
///             raise BrokenBarrierError
///         assert self._state == 0
///
///     # Optionally run the 'action' and release the threads waiting
///     # in the barrier.
///     def _release(self):
///         try:
///             if self._action:
///                 self._action()
///             # enter draining state
///             self._state = 1
///             self._cond.notify_all()
///         except:
///             #an exception during the _action handler.  Break and reraise
///             self._break()
///             raise
///
///     # Wait in the barrier until we are released.  Raise an exception
///     # if the barrier is reset or broken.
///     def _wait(self, timeout):
///         if not self._cond.wait_for(lambda : self._state != 0, timeout):
///             #timed out.  Break the barrier
///             self._break()
///             raise BrokenBarrierError
///         if self._state < 0:
///             raise BrokenBarrierError
///         assert self._state == 1
///
///     # If we are the last thread to exit the barrier, signal any threads
///     # waiting for the barrier to drain.
///     def _exit(self):
///         if self._count == 0:
///             if self._state in (-1, 1):
///                 #resetting or draining
///                 self._state = 0
///                 self._cond.notify_all()
///
///     def reset(self):
///         """Reset the barrier to the initial state.
///
///         Any threads currently waiting will get the BrokenBarrier exception
///         raised.
///
///         """
///         with self._cond:
///             if self._count > 0:
///                 if self._state == 0:
///                     #reset the barrier, waking up threads
///                     self._state = -1
///                 elif self._state == -2:
///                     #was broken, set it to reset state
///                     #which clears when the last thread exits
///                     self._state = -1
///             else:
///                 self._state = 0
///             self._cond.notify_all()
///
///     def abort(self):
///         """Place the barrier into a 'broken' state.
///
///         Useful in case of error.  Any currently waiting threads and threads
///         attempting to 'wait()' will have BrokenBarrierError raised.
///
///         """
///         with self._cond:
///             self._break()
///
///     def _break(self):
///         # An internal error was detected.  The barrier is set to
///         # a broken state all parties awakened.
///         self._state = -2
///         self._cond.notify_all()
///
///     @property
///     def parties(self):
///         """Return the number of threads required to trip the barrier."""
///         return self._parties
///
///     @property
///     def n_waiting(self):
///         """Return the number of threads currently waiting at the barrier."""
///         # We don't need synchronization here since this is an ephemeral result
///         # anyway.  It returns the correct value in the steady state.
///         if self._state == 0:
///             return self._count
///         return 0
///
///     @property
///     def broken(self):
///         """Return True if the barrier is in a broken state."""
///         return self._state == -2
/// ```
final class Barrier extends PythonClass {
  factory Barrier({
    required Object? parties,
    Object? action,
    Object? timeout,
  }) =>
      PythonFfiDart.instance.importClass(
        "threading",
        "Barrier",
        Barrier.from,
        <Object?>[
          parties,
          action,
          timeout,
        ],
        <String, Object?>{},
      );

  Barrier.from(super.pythonClass) : super.from();

  /// ## abort
  ///
  /// ### python docstring
  ///
  /// Place the barrier into a 'broken' state.
  ///
  /// Useful in case of error.  Any currently waiting threads and threads
  /// attempting to 'wait()' will have BrokenBarrierError raised.
  ///
  /// ### python source
  /// ```py
  /// def abort(self):
  ///         """Place the barrier into a 'broken' state.
  ///
  ///         Useful in case of error.  Any currently waiting threads and threads
  ///         attempting to 'wait()' will have BrokenBarrierError raised.
  ///
  ///         """
  ///         with self._cond:
  ///             self._break()
  /// ```
  Object? abort() => getFunction("abort").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## reset
  ///
  /// ### python docstring
  ///
  /// Reset the barrier to the initial state.
  ///
  /// Any threads currently waiting will get the BrokenBarrier exception
  /// raised.
  ///
  /// ### python source
  /// ```py
  /// def reset(self):
  ///         """Reset the barrier to the initial state.
  ///
  ///         Any threads currently waiting will get the BrokenBarrier exception
  ///         raised.
  ///
  ///         """
  ///         with self._cond:
  ///             if self._count > 0:
  ///                 if self._state == 0:
  ///                     #reset the barrier, waking up threads
  ///                     self._state = -1
  ///                 elif self._state == -2:
  ///                     #was broken, set it to reset state
  ///                     #which clears when the last thread exits
  ///                     self._state = -1
  ///             else:
  ///                 self._state = 0
  ///             self._cond.notify_all()
  /// ```
  Object? reset() => getFunction("reset").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## wait
  ///
  /// ### python docstring
  ///
  /// Wait for the barrier.
  ///
  /// When the specified number of threads have started waiting, they are all
  /// simultaneously awoken. If an 'action' was provided for the barrier, one
  /// of the threads will have executed that callback prior to returning.
  /// Returns an individual index number from 0 to 'parties-1'.
  ///
  /// ### python source
  /// ```py
  /// def wait(self, timeout=None):
  ///         """Wait for the barrier.
  ///
  ///         When the specified number of threads have started waiting, they are all
  ///         simultaneously awoken. If an 'action' was provided for the barrier, one
  ///         of the threads will have executed that callback prior to returning.
  ///         Returns an individual index number from 0 to 'parties-1'.
  ///
  ///         """
  ///         if timeout is None:
  ///             timeout = self._timeout
  ///         with self._cond:
  ///             self._enter() # Block while the barrier drains.
  ///             index = self._count
  ///             self._count += 1
  ///             try:
  ///                 if index + 1 == self._parties:
  ///                     # We release the barrier
  ///                     self._release()
  ///                 else:
  ///                     # We wait until someone releases us
  ///                     self._wait(timeout)
  ///                 return index
  ///             finally:
  ///                 self._count -= 1
  ///                 # Wake up any threads waiting for barrier to drain.
  ///                 self._exit()
  /// ```
  Object? wait({
    Object? timeout,
  }) =>
      getFunction("wait").call(
        <Object?>[
          timeout,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## broken (getter)
  ///
  /// ### python docstring
  ///
  /// Return True if the barrier is in a broken state.
  Object? get broken => getAttribute("broken");

  /// ## broken (setter)
  ///
  /// ### python docstring
  ///
  /// Return True if the barrier is in a broken state.
  set broken(Object? broken) => setAttribute("broken", broken);

  /// ## n_waiting (getter)
  ///
  /// ### python docstring
  ///
  /// Return the number of threads currently waiting at the barrier.
  Object? get n_waiting => getAttribute("n_waiting");

  /// ## n_waiting (setter)
  ///
  /// ### python docstring
  ///
  /// Return the number of threads currently waiting at the barrier.
  set n_waiting(Object? n_waiting) => setAttribute("n_waiting", n_waiting);

  /// ## parties (getter)
  ///
  /// ### python docstring
  ///
  /// Return the number of threads required to trip the barrier.
  Object? get parties => getAttribute("parties");

  /// ## parties (setter)
  ///
  /// ### python docstring
  ///
  /// Return the number of threads required to trip the barrier.
  set parties(Object? parties) => setAttribute("parties", parties);
}

/// ## BoundedSemaphore
///
/// ### python docstring
///
/// Implements a bounded semaphore.
///
/// A bounded semaphore checks to make sure its current value doesn't exceed its
/// initial value. If it does, ValueError is raised. In most situations
/// semaphores are used to guard resources with limited capacity.
///
/// If the semaphore is released too many times it's a sign of a bug. If not
/// given, value defaults to 1.
///
/// Like regular semaphores, bounded semaphores manage a counter representing
/// the number of release() calls minus the number of acquire() calls, plus an
/// initial value. The acquire() method blocks if necessary until it can return
/// without making the counter negative. If not given, value defaults to 1.
///
/// ### python source
/// ```py
/// class BoundedSemaphore(Semaphore):
///     """Implements a bounded semaphore.
///
///     A bounded semaphore checks to make sure its current value doesn't exceed its
///     initial value. If it does, ValueError is raised. In most situations
///     semaphores are used to guard resources with limited capacity.
///
///     If the semaphore is released too many times it's a sign of a bug. If not
///     given, value defaults to 1.
///
///     Like regular semaphores, bounded semaphores manage a counter representing
///     the number of release() calls minus the number of acquire() calls, plus an
///     initial value. The acquire() method blocks if necessary until it can return
///     without making the counter negative. If not given, value defaults to 1.
///
///     """
///
///     def __init__(self, value=1):
///         Semaphore.__init__(self, value)
///         self._initial_value = value
///
///     def __repr__(self):
///         cls = self.__class__
///         return (f"<{cls.__module__}.{cls.__qualname__} at {id(self):#x}:"
///                 f" value={self._value}/{self._initial_value}>")
///
///     def release(self, n=1):
///         """Release a semaphore, incrementing the internal counter by one or more.
///
///         When the counter is zero on entry and another thread is waiting for it
///         to become larger than zero again, wake up that thread.
///
///         If the number of releases exceeds the number of acquires,
///         raise a ValueError.
///
///         """
///         if n < 1:
///             raise ValueError('n must be one or more')
///         with self._cond:
///             if self._value + n > self._initial_value:
///                 raise ValueError("Semaphore released too many times")
///             self._value += n
///             for i in range(n):
///                 self._cond.notify()
/// ```
final class BoundedSemaphore extends PythonClass {
  factory BoundedSemaphore({
    Object? value = 1,
  }) =>
      PythonFfiDart.instance.importClass(
        "threading",
        "BoundedSemaphore",
        BoundedSemaphore.from,
        <Object?>[
          value,
        ],
        <String, Object?>{},
      );

  BoundedSemaphore.from(super.pythonClass) : super.from();

  /// ## acquire
  ///
  /// ### python docstring
  ///
  /// Acquire a semaphore, decrementing the internal counter by one.
  ///
  /// When invoked without arguments: if the internal counter is larger than
  /// zero on entry, decrement it by one and return immediately. If it is zero
  /// on entry, block, waiting until some other thread has called release() to
  /// make it larger than zero. This is done with proper interlocking so that
  /// if multiple acquire() calls are blocked, release() will wake exactly one
  /// of them up. The implementation may pick one at random, so the order in
  /// which blocked threads are awakened should not be relied on. There is no
  /// return value in this case.
  ///
  /// When invoked with blocking set to true, do the same thing as when called
  /// without arguments, and return true.
  ///
  /// When invoked with blocking set to false, do not block. If a call without
  /// an argument would block, return false immediately; otherwise, do the
  /// same thing as when called without arguments, and return true.
  ///
  /// When invoked with a timeout other than None, it will block for at
  /// most timeout seconds.  If acquire does not complete successfully in
  /// that interval, return false.  Return true otherwise.
  ///
  /// ### python source
  /// ```py
  /// def acquire(self, blocking=True, timeout=None):
  ///         """Acquire a semaphore, decrementing the internal counter by one.
  ///
  ///         When invoked without arguments: if the internal counter is larger than
  ///         zero on entry, decrement it by one and return immediately. If it is zero
  ///         on entry, block, waiting until some other thread has called release() to
  ///         make it larger than zero. This is done with proper interlocking so that
  ///         if multiple acquire() calls are blocked, release() will wake exactly one
  ///         of them up. The implementation may pick one at random, so the order in
  ///         which blocked threads are awakened should not be relied on. There is no
  ///         return value in this case.
  ///
  ///         When invoked with blocking set to true, do the same thing as when called
  ///         without arguments, and return true.
  ///
  ///         When invoked with blocking set to false, do not block. If a call without
  ///         an argument would block, return false immediately; otherwise, do the
  ///         same thing as when called without arguments, and return true.
  ///
  ///         When invoked with a timeout other than None, it will block for at
  ///         most timeout seconds.  If acquire does not complete successfully in
  ///         that interval, return false.  Return true otherwise.
  ///
  ///         """
  ///         if not blocking and timeout is not None:
  ///             raise ValueError("can't specify timeout for non-blocking acquire")
  ///         rc = False
  ///         endtime = None
  ///         with self._cond:
  ///             while self._value == 0:
  ///                 if not blocking:
  ///                     break
  ///                 if timeout is not None:
  ///                     if endtime is None:
  ///                         endtime = _time() + timeout
  ///                     else:
  ///                         timeout = endtime - _time()
  ///                         if timeout <= 0:
  ///                             break
  ///                 self._cond.wait(timeout)
  ///             else:
  ///                 self._value -= 1
  ///                 rc = True
  ///         return rc
  /// ```
  Object? acquire({
    Object? blocking = true,
    Object? timeout,
  }) =>
      getFunction("acquire").call(
        <Object?>[
          blocking,
          timeout,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## release
  ///
  /// ### python docstring
  ///
  /// Release a semaphore, incrementing the internal counter by one or more.
  ///
  /// When the counter is zero on entry and another thread is waiting for it
  /// to become larger than zero again, wake up that thread.
  ///
  /// If the number of releases exceeds the number of acquires,
  /// raise a ValueError.
  ///
  /// ### python source
  /// ```py
  /// def release(self, n=1):
  ///         """Release a semaphore, incrementing the internal counter by one or more.
  ///
  ///         When the counter is zero on entry and another thread is waiting for it
  ///         to become larger than zero again, wake up that thread.
  ///
  ///         If the number of releases exceeds the number of acquires,
  ///         raise a ValueError.
  ///
  ///         """
  ///         if n < 1:
  ///             raise ValueError('n must be one or more')
  ///         with self._cond:
  ///             if self._value + n > self._initial_value:
  ///                 raise ValueError("Semaphore released too many times")
  ///             self._value += n
  ///             for i in range(n):
  ///                 self._cond.notify()
  /// ```
  Object? release({
    Object? n = 1,
  }) =>
      getFunction("release").call(
        <Object?>[
          n,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## BrokenBarrierError
///
/// ### python source
/// ```py
/// class BrokenBarrierError(RuntimeError):
///     pass
/// ```
final class BrokenBarrierError extends PythonClass {
  factory BrokenBarrierError() => PythonFfiDart.instance.importClass(
        "threading",
        "BrokenBarrierError",
        BrokenBarrierError.from,
        <Object?>[],
      );

  BrokenBarrierError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## Condition
///
/// ### python docstring
///
/// Class that implements a condition variable.
///
/// A condition variable allows one or more threads to wait until they are
/// notified by another thread.
///
/// If the lock argument is given and not None, it must be a Lock or RLock
/// object, and it is used as the underlying lock. Otherwise, a new RLock object
/// is created and used as the underlying lock.
///
/// ### python source
/// ```py
/// class Condition:
///     """Class that implements a condition variable.
///
///     A condition variable allows one or more threads to wait until they are
///     notified by another thread.
///
///     If the lock argument is given and not None, it must be a Lock or RLock
///     object, and it is used as the underlying lock. Otherwise, a new RLock object
///     is created and used as the underlying lock.
///
///     """
///
///     def __init__(self, lock=None):
///         if lock is None:
///             lock = RLock()
///         self._lock = lock
///         # Export the lock's acquire() and release() methods
///         self.acquire = lock.acquire
///         self.release = lock.release
///         # If the lock defines _release_save() and/or _acquire_restore(),
///         # these override the default implementations (which just call
///         # release() and acquire() on the lock).  Ditto for _is_owned().
///         try:
///             self._release_save = lock._release_save
///         except AttributeError:
///             pass
///         try:
///             self._acquire_restore = lock._acquire_restore
///         except AttributeError:
///             pass
///         try:
///             self._is_owned = lock._is_owned
///         except AttributeError:
///             pass
///         self._waiters = _deque()
///
///     def _at_fork_reinit(self):
///         self._lock._at_fork_reinit()
///         self._waiters.clear()
///
///     def __enter__(self):
///         return self._lock.__enter__()
///
///     def __exit__(self, *args):
///         return self._lock.__exit__(*args)
///
///     def __repr__(self):
///         return "<Condition(%s, %d)>" % (self._lock, len(self._waiters))
///
///     def _release_save(self):
///         self._lock.release()           # No state to save
///
///     def _acquire_restore(self, x):
///         self._lock.acquire()           # Ignore saved state
///
///     def _is_owned(self):
///         # Return True if lock is owned by current_thread.
///         # This method is called only if _lock doesn't have _is_owned().
///         if self._lock.acquire(False):
///             self._lock.release()
///             return False
///         else:
///             return True
///
///     def wait(self, timeout=None):
///         """Wait until notified or until a timeout occurs.
///
///         If the calling thread has not acquired the lock when this method is
///         called, a RuntimeError is raised.
///
///         This method releases the underlying lock, and then blocks until it is
///         awakened by a notify() or notify_all() call for the same condition
///         variable in another thread, or until the optional timeout occurs. Once
///         awakened or timed out, it re-acquires the lock and returns.
///
///         When the timeout argument is present and not None, it should be a
///         floating point number specifying a timeout for the operation in seconds
///         (or fractions thereof).
///
///         When the underlying lock is an RLock, it is not released using its
///         release() method, since this may not actually unlock the lock when it
///         was acquired multiple times recursively. Instead, an internal interface
///         of the RLock class is used, which really unlocks it even when it has
///         been recursively acquired several times. Another internal interface is
///         then used to restore the recursion level when the lock is reacquired.
///
///         """
///         if not self._is_owned():
///             raise RuntimeError("cannot wait on un-acquired lock")
///         waiter = _allocate_lock()
///         waiter.acquire()
///         self._waiters.append(waiter)
///         saved_state = self._release_save()
///         gotit = False
///         try:    # restore state no matter what (e.g., KeyboardInterrupt)
///             if timeout is None:
///                 waiter.acquire()
///                 gotit = True
///             else:
///                 if timeout > 0:
///                     gotit = waiter.acquire(True, timeout)
///                 else:
///                     gotit = waiter.acquire(False)
///             return gotit
///         finally:
///             self._acquire_restore(saved_state)
///             if not gotit:
///                 try:
///                     self._waiters.remove(waiter)
///                 except ValueError:
///                     pass
///
///     def wait_for(self, predicate, timeout=None):
///         """Wait until a condition evaluates to True.
///
///         predicate should be a callable which result will be interpreted as a
///         boolean value.  A timeout may be provided giving the maximum time to
///         wait.
///
///         """
///         endtime = None
///         waittime = timeout
///         result = predicate()
///         while not result:
///             if waittime is not None:
///                 if endtime is None:
///                     endtime = _time() + waittime
///                 else:
///                     waittime = endtime - _time()
///                     if waittime <= 0:
///                         break
///             self.wait(waittime)
///             result = predicate()
///         return result
///
///     def notify(self, n=1):
///         """Wake up one or more threads waiting on this condition, if any.
///
///         If the calling thread has not acquired the lock when this method is
///         called, a RuntimeError is raised.
///
///         This method wakes up at most n of the threads waiting for the condition
///         variable; it is a no-op if no threads are waiting.
///
///         """
///         if not self._is_owned():
///             raise RuntimeError("cannot notify on un-acquired lock")
///         waiters = self._waiters
///         while waiters and n > 0:
///             waiter = waiters[0]
///             try:
///                 waiter.release()
///             except RuntimeError:
///                 # gh-92530: The previous call of notify() released the lock,
///                 # but was interrupted before removing it from the queue.
///                 # It can happen if a signal handler raises an exception,
///                 # like CTRL+C which raises KeyboardInterrupt.
///                 pass
///             else:
///                 n -= 1
///             try:
///                 waiters.remove(waiter)
///             except ValueError:
///                 pass
///
///     def notify_all(self):
///         """Wake up all threads waiting on this condition.
///
///         If the calling thread has not acquired the lock when this method
///         is called, a RuntimeError is raised.
///
///         """
///         self.notify(len(self._waiters))
///
///     def notifyAll(self):
///         """Wake up all threads waiting on this condition.
///
///         This method is deprecated, use notify_all() instead.
///
///         """
///         import warnings
///         warnings.warn('notifyAll() is deprecated, use notify_all() instead',
///                       DeprecationWarning, stacklevel=2)
///         self.notify_all()
/// ```
final class Condition extends PythonClass {
  factory Condition({
    Object? lock,
  }) =>
      PythonFfiDart.instance.importClass(
        "threading",
        "Condition",
        Condition.from,
        <Object?>[
          lock,
        ],
        <String, Object?>{},
      );

  Condition.from(super.pythonClass) : super.from();

  /// ## notify
  ///
  /// ### python docstring
  ///
  /// Wake up one or more threads waiting on this condition, if any.
  ///
  /// If the calling thread has not acquired the lock when this method is
  /// called, a RuntimeError is raised.
  ///
  /// This method wakes up at most n of the threads waiting for the condition
  /// variable; it is a no-op if no threads are waiting.
  ///
  /// ### python source
  /// ```py
  /// def notify(self, n=1):
  ///         """Wake up one or more threads waiting on this condition, if any.
  ///
  ///         If the calling thread has not acquired the lock when this method is
  ///         called, a RuntimeError is raised.
  ///
  ///         This method wakes up at most n of the threads waiting for the condition
  ///         variable; it is a no-op if no threads are waiting.
  ///
  ///         """
  ///         if not self._is_owned():
  ///             raise RuntimeError("cannot notify on un-acquired lock")
  ///         waiters = self._waiters
  ///         while waiters and n > 0:
  ///             waiter = waiters[0]
  ///             try:
  ///                 waiter.release()
  ///             except RuntimeError:
  ///                 # gh-92530: The previous call of notify() released the lock,
  ///                 # but was interrupted before removing it from the queue.
  ///                 # It can happen if a signal handler raises an exception,
  ///                 # like CTRL+C which raises KeyboardInterrupt.
  ///                 pass
  ///             else:
  ///                 n -= 1
  ///             try:
  ///                 waiters.remove(waiter)
  ///             except ValueError:
  ///                 pass
  /// ```
  Object? notify({
    Object? n = 1,
  }) =>
      getFunction("notify").call(
        <Object?>[
          n,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## notifyAll
  ///
  /// ### python docstring
  ///
  /// Wake up all threads waiting on this condition.
  ///
  /// This method is deprecated, use notify_all() instead.
  ///
  /// ### python source
  /// ```py
  /// def notifyAll(self):
  ///         """Wake up all threads waiting on this condition.
  ///
  ///         This method is deprecated, use notify_all() instead.
  ///
  ///         """
  ///         import warnings
  ///         warnings.warn('notifyAll() is deprecated, use notify_all() instead',
  ///                       DeprecationWarning, stacklevel=2)
  ///         self.notify_all()
  /// ```
  Object? notifyAll() => getFunction("notifyAll").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## notify_all
  ///
  /// ### python docstring
  ///
  /// Wake up all threads waiting on this condition.
  ///
  /// If the calling thread has not acquired the lock when this method
  /// is called, a RuntimeError is raised.
  ///
  /// ### python source
  /// ```py
  /// def notify_all(self):
  ///         """Wake up all threads waiting on this condition.
  ///
  ///         If the calling thread has not acquired the lock when this method
  ///         is called, a RuntimeError is raised.
  ///
  ///         """
  ///         self.notify(len(self._waiters))
  /// ```
  Object? notify_all() => getFunction("notify_all").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## wait
  ///
  /// ### python docstring
  ///
  /// Wait until notified or until a timeout occurs.
  ///
  /// If the calling thread has not acquired the lock when this method is
  /// called, a RuntimeError is raised.
  ///
  /// This method releases the underlying lock, and then blocks until it is
  /// awakened by a notify() or notify_all() call for the same condition
  /// variable in another thread, or until the optional timeout occurs. Once
  /// awakened or timed out, it re-acquires the lock and returns.
  ///
  /// When the timeout argument is present and not None, it should be a
  /// floating point number specifying a timeout for the operation in seconds
  /// (or fractions thereof).
  ///
  /// When the underlying lock is an RLock, it is not released using its
  /// release() method, since this may not actually unlock the lock when it
  /// was acquired multiple times recursively. Instead, an internal interface
  /// of the RLock class is used, which really unlocks it even when it has
  /// been recursively acquired several times. Another internal interface is
  /// then used to restore the recursion level when the lock is reacquired.
  ///
  /// ### python source
  /// ```py
  /// def wait(self, timeout=None):
  ///         """Wait until notified or until a timeout occurs.
  ///
  ///         If the calling thread has not acquired the lock when this method is
  ///         called, a RuntimeError is raised.
  ///
  ///         This method releases the underlying lock, and then blocks until it is
  ///         awakened by a notify() or notify_all() call for the same condition
  ///         variable in another thread, or until the optional timeout occurs. Once
  ///         awakened or timed out, it re-acquires the lock and returns.
  ///
  ///         When the timeout argument is present and not None, it should be a
  ///         floating point number specifying a timeout for the operation in seconds
  ///         (or fractions thereof).
  ///
  ///         When the underlying lock is an RLock, it is not released using its
  ///         release() method, since this may not actually unlock the lock when it
  ///         was acquired multiple times recursively. Instead, an internal interface
  ///         of the RLock class is used, which really unlocks it even when it has
  ///         been recursively acquired several times. Another internal interface is
  ///         then used to restore the recursion level when the lock is reacquired.
  ///
  ///         """
  ///         if not self._is_owned():
  ///             raise RuntimeError("cannot wait on un-acquired lock")
  ///         waiter = _allocate_lock()
  ///         waiter.acquire()
  ///         self._waiters.append(waiter)
  ///         saved_state = self._release_save()
  ///         gotit = False
  ///         try:    # restore state no matter what (e.g., KeyboardInterrupt)
  ///             if timeout is None:
  ///                 waiter.acquire()
  ///                 gotit = True
  ///             else:
  ///                 if timeout > 0:
  ///                     gotit = waiter.acquire(True, timeout)
  ///                 else:
  ///                     gotit = waiter.acquire(False)
  ///             return gotit
  ///         finally:
  ///             self._acquire_restore(saved_state)
  ///             if not gotit:
  ///                 try:
  ///                     self._waiters.remove(waiter)
  ///                 except ValueError:
  ///                     pass
  /// ```
  Object? wait({
    Object? timeout,
  }) =>
      getFunction("wait").call(
        <Object?>[
          timeout,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## wait_for
  ///
  /// ### python docstring
  ///
  /// Wait until a condition evaluates to True.
  ///
  /// predicate should be a callable which result will be interpreted as a
  /// boolean value.  A timeout may be provided giving the maximum time to
  /// wait.
  ///
  /// ### python source
  /// ```py
  /// def wait_for(self, predicate, timeout=None):
  ///         """Wait until a condition evaluates to True.
  ///
  ///         predicate should be a callable which result will be interpreted as a
  ///         boolean value.  A timeout may be provided giving the maximum time to
  ///         wait.
  ///
  ///         """
  ///         endtime = None
  ///         waittime = timeout
  ///         result = predicate()
  ///         while not result:
  ///             if waittime is not None:
  ///                 if endtime is None:
  ///                     endtime = _time() + waittime
  ///                 else:
  ///                     waittime = endtime - _time()
  ///                     if waittime <= 0:
  ///                         break
  ///             self.wait(waittime)
  ///             result = predicate()
  ///         return result
  /// ```
  Object? wait_for({
    required Object? predicate,
    Object? timeout,
  }) =>
      getFunction("wait_for").call(
        <Object?>[
          predicate,
          timeout,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## acquire (getter)
  Object? get acquire => getAttribute("acquire");

  /// ## acquire (setter)
  set acquire(Object? acquire) => setAttribute("acquire", acquire);

  /// ## release (getter)
  Object? get release => getAttribute("release");

  /// ## release (setter)
  set release(Object? release) => setAttribute("release", release);
}

/// ## Event
///
/// ### python docstring
///
/// Class implementing event objects.
///
/// Events manage a flag that can be set to true with the set() method and reset
/// to false with the clear() method. The wait() method blocks until the flag is
/// true.  The flag is initially false.
///
/// ### python source
/// ```py
/// class Event:
///     """Class implementing event objects.
///
///     Events manage a flag that can be set to true with the set() method and reset
///     to false with the clear() method. The wait() method blocks until the flag is
///     true.  The flag is initially false.
///
///     """
///
///     # After Tim Peters' event class (without is_posted())
///
///     def __init__(self):
///         self._cond = Condition(Lock())
///         self._flag = False
///
///     def __repr__(self):
///         cls = self.__class__
///         status = 'set' if self._flag else 'unset'
///         return f"<{cls.__module__}.{cls.__qualname__} at {id(self):#x}: {status}>"
///
///     def _at_fork_reinit(self):
///         # Private method called by Thread._reset_internal_locks()
///         self._cond._at_fork_reinit()
///
///     def is_set(self):
///         """Return true if and only if the internal flag is true."""
///         return self._flag
///
///     def isSet(self):
///         """Return true if and only if the internal flag is true.
///
///         This method is deprecated, use is_set() instead.
///
///         """
///         import warnings
///         warnings.warn('isSet() is deprecated, use is_set() instead',
///                       DeprecationWarning, stacklevel=2)
///         return self.is_set()
///
///     def set(self):
///         """Set the internal flag to true.
///
///         All threads waiting for it to become true are awakened. Threads
///         that call wait() once the flag is true will not block at all.
///
///         """
///         with self._cond:
///             self._flag = True
///             self._cond.notify_all()
///
///     def clear(self):
///         """Reset the internal flag to false.
///
///         Subsequently, threads calling wait() will block until set() is called to
///         set the internal flag to true again.
///
///         """
///         with self._cond:
///             self._flag = False
///
///     def wait(self, timeout=None):
///         """Block until the internal flag is true.
///
///         If the internal flag is true on entry, return immediately. Otherwise,
///         block until another thread calls set() to set the flag to true, or until
///         the optional timeout occurs.
///
///         When the timeout argument is present and not None, it should be a
///         floating point number specifying a timeout for the operation in seconds
///         (or fractions thereof).
///
///         This method returns the internal flag on exit, so it will always return
///         True except if a timeout is given and the operation times out.
///
///         """
///         with self._cond:
///             signaled = self._flag
///             if not signaled:
///                 signaled = self._cond.wait(timeout)
///             return signaled
/// ```
final class Event extends PythonClass {
  factory Event() => PythonFfiDart.instance.importClass(
        "threading",
        "Event",
        Event.from,
        <Object?>[],
        <String, Object?>{},
      );

  Event.from(super.pythonClass) : super.from();

  /// ## clear
  ///
  /// ### python docstring
  ///
  /// Reset the internal flag to false.
  ///
  /// Subsequently, threads calling wait() will block until set() is called to
  /// set the internal flag to true again.
  ///
  /// ### python source
  /// ```py
  /// def clear(self):
  ///         """Reset the internal flag to false.
  ///
  ///         Subsequently, threads calling wait() will block until set() is called to
  ///         set the internal flag to true again.
  ///
  ///         """
  ///         with self._cond:
  ///             self._flag = False
  /// ```
  Object? clear() => getFunction("clear").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## isSet
  ///
  /// ### python docstring
  ///
  /// Return true if and only if the internal flag is true.
  ///
  /// This method is deprecated, use is_set() instead.
  ///
  /// ### python source
  /// ```py
  /// def isSet(self):
  ///         """Return true if and only if the internal flag is true.
  ///
  ///         This method is deprecated, use is_set() instead.
  ///
  ///         """
  ///         import warnings
  ///         warnings.warn('isSet() is deprecated, use is_set() instead',
  ///                       DeprecationWarning, stacklevel=2)
  ///         return self.is_set()
  /// ```
  Object? isSet() => getFunction("isSet").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## is_set
  ///
  /// ### python docstring
  ///
  /// Return true if and only if the internal flag is true.
  ///
  /// ### python source
  /// ```py
  /// def is_set(self):
  ///         """Return true if and only if the internal flag is true."""
  ///         return self._flag
  /// ```
  Object? is_set() => getFunction("is_set").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## set
  ///
  /// ### python docstring
  ///
  /// Set the internal flag to true.
  ///
  /// All threads waiting for it to become true are awakened. Threads
  /// that call wait() once the flag is true will not block at all.
  ///
  /// ### python source
  /// ```py
  /// def set(self):
  ///         """Set the internal flag to true.
  ///
  ///         All threads waiting for it to become true are awakened. Threads
  ///         that call wait() once the flag is true will not block at all.
  ///
  ///         """
  ///         with self._cond:
  ///             self._flag = True
  ///             self._cond.notify_all()
  /// ```
  Object? $set() => getFunction("set").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## wait
  ///
  /// ### python docstring
  ///
  /// Block until the internal flag is true.
  ///
  /// If the internal flag is true on entry, return immediately. Otherwise,
  /// block until another thread calls set() to set the flag to true, or until
  /// the optional timeout occurs.
  ///
  /// When the timeout argument is present and not None, it should be a
  /// floating point number specifying a timeout for the operation in seconds
  /// (or fractions thereof).
  ///
  /// This method returns the internal flag on exit, so it will always return
  /// True except if a timeout is given and the operation times out.
  ///
  /// ### python source
  /// ```py
  /// def wait(self, timeout=None):
  ///         """Block until the internal flag is true.
  ///
  ///         If the internal flag is true on entry, return immediately. Otherwise,
  ///         block until another thread calls set() to set the flag to true, or until
  ///         the optional timeout occurs.
  ///
  ///         When the timeout argument is present and not None, it should be a
  ///         floating point number specifying a timeout for the operation in seconds
  ///         (or fractions thereof).
  ///
  ///         This method returns the internal flag on exit, so it will always return
  ///         True except if a timeout is given and the operation times out.
  ///
  ///         """
  ///         with self._cond:
  ///             signaled = self._flag
  ///             if not signaled:
  ///                 signaled = self._cond.wait(timeout)
  ///             return signaled
  /// ```
  Object? wait({
    Object? timeout,
  }) =>
      getFunction("wait").call(
        <Object?>[
          timeout,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## ExceptHookArgs
final class ExceptHookArgs extends PythonClass {
  factory ExceptHookArgs() => PythonFfiDart.instance.importClass(
        "_thread",
        "ExceptHookArgs",
        ExceptHookArgs.from,
        <Object?>[],
      );

  ExceptHookArgs.from(super.pythonClass) : super.from();

  /// ## exc_traceback (getter)
  ///
  /// ### python docstring
  ///
  /// Exception traceback
  Object? get exc_traceback => getAttribute("exc_traceback");

  /// ## exc_traceback (setter)
  ///
  /// ### python docstring
  ///
  /// Exception traceback
  set exc_traceback(Object? exc_traceback) =>
      setAttribute("exc_traceback", exc_traceback);

  /// ## exc_type (getter)
  ///
  /// ### python docstring
  ///
  /// Exception type
  Object? get exc_type => getAttribute("exc_type");

  /// ## exc_type (setter)
  ///
  /// ### python docstring
  ///
  /// Exception type
  set exc_type(Object? exc_type) => setAttribute("exc_type", exc_type);

  /// ## exc_value (getter)
  ///
  /// ### python docstring
  ///
  /// Exception value
  Object? get exc_value => getAttribute("exc_value");

  /// ## exc_value (setter)
  ///
  /// ### python docstring
  ///
  /// Exception value
  set exc_value(Object? exc_value) => setAttribute("exc_value", exc_value);

  /// ## thread (getter)
  ///
  /// ### python docstring
  ///
  /// Thread
  Object? get thread => getAttribute("thread");

  /// ## thread (setter)
  ///
  /// ### python docstring
  ///
  /// Thread
  set thread(Object? thread) => setAttribute("thread", thread);

  /// ## count (getter)
  Object? get count => getAttribute("count");

  /// ## count (setter)
  set count(Object? count) => setAttribute("count", count);

  /// ## index (getter)
  Object? get index => getAttribute("index");

  /// ## index (setter)
  set index(Object? index) => setAttribute("index", index);

  /// ## n_fields (getter)
  Object? get n_fields => getAttribute("n_fields");

  /// ## n_fields (setter)
  set n_fields(Object? n_fields) => setAttribute("n_fields", n_fields);

  /// ## n_sequence_fields (getter)
  Object? get n_sequence_fields => getAttribute("n_sequence_fields");

  /// ## n_sequence_fields (setter)
  set n_sequence_fields(Object? n_sequence_fields) =>
      setAttribute("n_sequence_fields", n_sequence_fields);

  /// ## n_unnamed_fields (getter)
  Object? get n_unnamed_fields => getAttribute("n_unnamed_fields");

  /// ## n_unnamed_fields (setter)
  set n_unnamed_fields(Object? n_unnamed_fields) =>
      setAttribute("n_unnamed_fields", n_unnamed_fields);
}

/// ## Semaphore
///
/// ### python docstring
///
/// This class implements semaphore objects.
///
/// Semaphores manage a counter representing the number of release() calls minus
/// the number of acquire() calls, plus an initial value. The acquire() method
/// blocks if necessary until it can return without making the counter
/// negative. If not given, value defaults to 1.
///
/// ### python source
/// ```py
/// class Semaphore:
///     """This class implements semaphore objects.
///
///     Semaphores manage a counter representing the number of release() calls minus
///     the number of acquire() calls, plus an initial value. The acquire() method
///     blocks if necessary until it can return without making the counter
///     negative. If not given, value defaults to 1.
///
///     """
///
///     # After Tim Peters' semaphore class, but not quite the same (no maximum)
///
///     def __init__(self, value=1):
///         if value < 0:
///             raise ValueError("semaphore initial value must be >= 0")
///         self._cond = Condition(Lock())
///         self._value = value
///
///     def __repr__(self):
///         cls = self.__class__
///         return (f"<{cls.__module__}.{cls.__qualname__} at {id(self):#x}:"
///                 f" value={self._value}>")
///
///     def acquire(self, blocking=True, timeout=None):
///         """Acquire a semaphore, decrementing the internal counter by one.
///
///         When invoked without arguments: if the internal counter is larger than
///         zero on entry, decrement it by one and return immediately. If it is zero
///         on entry, block, waiting until some other thread has called release() to
///         make it larger than zero. This is done with proper interlocking so that
///         if multiple acquire() calls are blocked, release() will wake exactly one
///         of them up. The implementation may pick one at random, so the order in
///         which blocked threads are awakened should not be relied on. There is no
///         return value in this case.
///
///         When invoked with blocking set to true, do the same thing as when called
///         without arguments, and return true.
///
///         When invoked with blocking set to false, do not block. If a call without
///         an argument would block, return false immediately; otherwise, do the
///         same thing as when called without arguments, and return true.
///
///         When invoked with a timeout other than None, it will block for at
///         most timeout seconds.  If acquire does not complete successfully in
///         that interval, return false.  Return true otherwise.
///
///         """
///         if not blocking and timeout is not None:
///             raise ValueError("can't specify timeout for non-blocking acquire")
///         rc = False
///         endtime = None
///         with self._cond:
///             while self._value == 0:
///                 if not blocking:
///                     break
///                 if timeout is not None:
///                     if endtime is None:
///                         endtime = _time() + timeout
///                     else:
///                         timeout = endtime - _time()
///                         if timeout <= 0:
///                             break
///                 self._cond.wait(timeout)
///             else:
///                 self._value -= 1
///                 rc = True
///         return rc
///
///     __enter__ = acquire
///
///     def release(self, n=1):
///         """Release a semaphore, incrementing the internal counter by one or more.
///
///         When the counter is zero on entry and another thread is waiting for it
///         to become larger than zero again, wake up that thread.
///
///         """
///         if n < 1:
///             raise ValueError('n must be one or more')
///         with self._cond:
///             self._value += n
///             for i in range(n):
///                 self._cond.notify()
///
///     def __exit__(self, t, v, tb):
///         self.release()
/// ```
final class Semaphore extends PythonClass {
  factory Semaphore({
    Object? value = 1,
  }) =>
      PythonFfiDart.instance.importClass(
        "threading",
        "Semaphore",
        Semaphore.from,
        <Object?>[
          value,
        ],
        <String, Object?>{},
      );

  Semaphore.from(super.pythonClass) : super.from();

  /// ## acquire
  ///
  /// ### python docstring
  ///
  /// Acquire a semaphore, decrementing the internal counter by one.
  ///
  /// When invoked without arguments: if the internal counter is larger than
  /// zero on entry, decrement it by one and return immediately. If it is zero
  /// on entry, block, waiting until some other thread has called release() to
  /// make it larger than zero. This is done with proper interlocking so that
  /// if multiple acquire() calls are blocked, release() will wake exactly one
  /// of them up. The implementation may pick one at random, so the order in
  /// which blocked threads are awakened should not be relied on. There is no
  /// return value in this case.
  ///
  /// When invoked with blocking set to true, do the same thing as when called
  /// without arguments, and return true.
  ///
  /// When invoked with blocking set to false, do not block. If a call without
  /// an argument would block, return false immediately; otherwise, do the
  /// same thing as when called without arguments, and return true.
  ///
  /// When invoked with a timeout other than None, it will block for at
  /// most timeout seconds.  If acquire does not complete successfully in
  /// that interval, return false.  Return true otherwise.
  ///
  /// ### python source
  /// ```py
  /// def acquire(self, blocking=True, timeout=None):
  ///         """Acquire a semaphore, decrementing the internal counter by one.
  ///
  ///         When invoked without arguments: if the internal counter is larger than
  ///         zero on entry, decrement it by one and return immediately. If it is zero
  ///         on entry, block, waiting until some other thread has called release() to
  ///         make it larger than zero. This is done with proper interlocking so that
  ///         if multiple acquire() calls are blocked, release() will wake exactly one
  ///         of them up. The implementation may pick one at random, so the order in
  ///         which blocked threads are awakened should not be relied on. There is no
  ///         return value in this case.
  ///
  ///         When invoked with blocking set to true, do the same thing as when called
  ///         without arguments, and return true.
  ///
  ///         When invoked with blocking set to false, do not block. If a call without
  ///         an argument would block, return false immediately; otherwise, do the
  ///         same thing as when called without arguments, and return true.
  ///
  ///         When invoked with a timeout other than None, it will block for at
  ///         most timeout seconds.  If acquire does not complete successfully in
  ///         that interval, return false.  Return true otherwise.
  ///
  ///         """
  ///         if not blocking and timeout is not None:
  ///             raise ValueError("can't specify timeout for non-blocking acquire")
  ///         rc = False
  ///         endtime = None
  ///         with self._cond:
  ///             while self._value == 0:
  ///                 if not blocking:
  ///                     break
  ///                 if timeout is not None:
  ///                     if endtime is None:
  ///                         endtime = _time() + timeout
  ///                     else:
  ///                         timeout = endtime - _time()
  ///                         if timeout <= 0:
  ///                             break
  ///                 self._cond.wait(timeout)
  ///             else:
  ///                 self._value -= 1
  ///                 rc = True
  ///         return rc
  /// ```
  Object? acquire({
    Object? blocking = true,
    Object? timeout,
  }) =>
      getFunction("acquire").call(
        <Object?>[
          blocking,
          timeout,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## release
  ///
  /// ### python docstring
  ///
  /// Release a semaphore, incrementing the internal counter by one or more.
  ///
  /// When the counter is zero on entry and another thread is waiting for it
  /// to become larger than zero again, wake up that thread.
  ///
  /// ### python source
  /// ```py
  /// def release(self, n=1):
  ///         """Release a semaphore, incrementing the internal counter by one or more.
  ///
  ///         When the counter is zero on entry and another thread is waiting for it
  ///         to become larger than zero again, wake up that thread.
  ///
  ///         """
  ///         if n < 1:
  ///             raise ValueError('n must be one or more')
  ///         with self._cond:
  ///             self._value += n
  ///             for i in range(n):
  ///                 self._cond.notify()
  /// ```
  Object? release({
    Object? n = 1,
  }) =>
      getFunction("release").call(
        <Object?>[
          n,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## Thread
///
/// ### python docstring
///
/// A class that represents a thread of control.
///
/// This class can be safely subclassed in a limited fashion. There are two ways
/// to specify the activity: by passing a callable object to the constructor, or
/// by overriding the run() method in a subclass.
///
/// ### python source
/// ```py
/// class Thread:
///     """A class that represents a thread of control.
///
///     This class can be safely subclassed in a limited fashion. There are two ways
///     to specify the activity: by passing a callable object to the constructor, or
///     by overriding the run() method in a subclass.
///
///     """
///
///     _initialized = False
///
///     def __init__(self, group=None, target=None, name=None,
///                  args=(), kwargs=None, *, daemon=None):
///         """This constructor should always be called with keyword arguments. Arguments are:
///
///         *group* should be None; reserved for future extension when a ThreadGroup
///         class is implemented.
///
///         *target* is the callable object to be invoked by the run()
///         method. Defaults to None, meaning nothing is called.
///
///         *name* is the thread name. By default, a unique name is constructed of
///         the form "Thread-N" where N is a small decimal number.
///
///         *args* is a list or tuple of arguments for the target invocation. Defaults to ().
///
///         *kwargs* is a dictionary of keyword arguments for the target
///         invocation. Defaults to {}.
///
///         If a subclass overrides the constructor, it must make sure to invoke
///         the base class constructor (Thread.__init__()) before doing anything
///         else to the thread.
///
///         """
///         assert group is None, "group argument must be None for now"
///         if kwargs is None:
///             kwargs = {}
///         if name:
///             name = str(name)
///         else:
///             name = _newname("Thread-%d")
///             if target is not None:
///                 try:
///                     target_name = target.__name__
///                     name += f" ({target_name})"
///                 except AttributeError:
///                     pass
///
///         self._target = target
///         self._name = name
///         self._args = args
///         self._kwargs = kwargs
///         if daemon is not None:
///             self._daemonic = daemon
///         else:
///             self._daemonic = current_thread().daemon
///         self._ident = None
///         if _HAVE_THREAD_NATIVE_ID:
///             self._native_id = None
///         self._tstate_lock = None
///         self._started = Event()
///         self._is_stopped = False
///         self._initialized = True
///         # Copy of sys.stderr used by self._invoke_excepthook()
///         self._stderr = _sys.stderr
///         self._invoke_excepthook = _make_invoke_excepthook()
///         # For debugging and _after_fork()
///         _dangling.add(self)
///
///     def _reset_internal_locks(self, is_alive):
///         # private!  Called by _after_fork() to reset our internal locks as
///         # they may be in an invalid state leading to a deadlock or crash.
///         self._started._at_fork_reinit()
///         if is_alive:
///             # bpo-42350: If the fork happens when the thread is already stopped
///             # (ex: after threading._shutdown() has been called), _tstate_lock
///             # is None. Do nothing in this case.
///             if self._tstate_lock is not None:
///                 self._tstate_lock._at_fork_reinit()
///                 self._tstate_lock.acquire()
///         else:
///             # The thread isn't alive after fork: it doesn't have a tstate
///             # anymore.
///             self._is_stopped = True
///             self._tstate_lock = None
///
///     def __repr__(self):
///         assert self._initialized, "Thread.__init__() was not called"
///         status = "initial"
///         if self._started.is_set():
///             status = "started"
///         self.is_alive() # easy way to get ._is_stopped set when appropriate
///         if self._is_stopped:
///             status = "stopped"
///         if self._daemonic:
///             status += " daemon"
///         if self._ident is not None:
///             status += " %s" % self._ident
///         return "<%s(%s, %s)>" % (self.__class__.__name__, self._name, status)
///
///     def start(self):
///         """Start the thread's activity.
///
///         It must be called at most once per thread object. It arranges for the
///         object's run() method to be invoked in a separate thread of control.
///
///         This method will raise a RuntimeError if called more than once on the
///         same thread object.
///
///         """
///         if not self._initialized:
///             raise RuntimeError("thread.__init__() not called")
///
///         if self._started.is_set():
///             raise RuntimeError("threads can only be started once")
///
///         with _active_limbo_lock:
///             _limbo[self] = self
///         try:
///             _start_new_thread(self._bootstrap, ())
///         except Exception:
///             with _active_limbo_lock:
///                 del _limbo[self]
///             raise
///         self._started.wait()
///
///     def run(self):
///         """Method representing the thread's activity.
///
///         You may override this method in a subclass. The standard run() method
///         invokes the callable object passed to the object's constructor as the
///         target argument, if any, with sequential and keyword arguments taken
///         from the args and kwargs arguments, respectively.
///
///         """
///         try:
///             if self._target is not None:
///                 self._target(*self._args, **self._kwargs)
///         finally:
///             # Avoid a refcycle if the thread is running a function with
///             # an argument that has a member that points to the thread.
///             del self._target, self._args, self._kwargs
///
///     def _bootstrap(self):
///         # Wrapper around the real bootstrap code that ignores
///         # exceptions during interpreter cleanup.  Those typically
///         # happen when a daemon thread wakes up at an unfortunate
///         # moment, finds the world around it destroyed, and raises some
///         # random exception *** while trying to report the exception in
///         # _bootstrap_inner() below ***.  Those random exceptions
///         # don't help anybody, and they confuse users, so we suppress
///         # them.  We suppress them only when it appears that the world
///         # indeed has already been destroyed, so that exceptions in
///         # _bootstrap_inner() during normal business hours are properly
///         # reported.  Also, we only suppress them for daemonic threads;
///         # if a non-daemonic encounters this, something else is wrong.
///         try:
///             self._bootstrap_inner()
///         except:
///             if self._daemonic and _sys is None:
///                 return
///             raise
///
///     def _set_ident(self):
///         self._ident = get_ident()
///
///     if _HAVE_THREAD_NATIVE_ID:
///         def _set_native_id(self):
///             self._native_id = get_native_id()
///
///     def _set_tstate_lock(self):
///         """
///         Set a lock object which will be released by the interpreter when
///         the underlying thread state (see pystate.h) gets deleted.
///         """
///         self._tstate_lock = _set_sentinel()
///         self._tstate_lock.acquire()
///
///         if not self.daemon:
///             with _shutdown_locks_lock:
///                 _maintain_shutdown_locks()
///                 _shutdown_locks.add(self._tstate_lock)
///
///     def _bootstrap_inner(self):
///         try:
///             self._set_ident()
///             self._set_tstate_lock()
///             if _HAVE_THREAD_NATIVE_ID:
///                 self._set_native_id()
///             self._started.set()
///             with _active_limbo_lock:
///                 _active[self._ident] = self
///                 del _limbo[self]
///
///             if _trace_hook:
///                 _sys.settrace(_trace_hook)
///             if _profile_hook:
///                 _sys.setprofile(_profile_hook)
///
///             try:
///                 self.run()
///             except:
///                 self._invoke_excepthook(self)
///         finally:
///             self._delete()
///
///     def _stop(self):
///         # After calling ._stop(), .is_alive() returns False and .join() returns
///         # immediately.  ._tstate_lock must be released before calling ._stop().
///         #
///         # Normal case:  C code at the end of the thread's life
///         # (release_sentinel in _threadmodule.c) releases ._tstate_lock, and
///         # that's detected by our ._wait_for_tstate_lock(), called by .join()
///         # and .is_alive().  Any number of threads _may_ call ._stop()
///         # simultaneously (for example, if multiple threads are blocked in
///         # .join() calls), and they're not serialized.  That's harmless -
///         # they'll just make redundant rebindings of ._is_stopped and
///         # ._tstate_lock.  Obscure:  we rebind ._tstate_lock last so that the
///         # "assert self._is_stopped" in ._wait_for_tstate_lock() always works
///         # (the assert is executed only if ._tstate_lock is None).
///         #
///         # Special case:  _main_thread releases ._tstate_lock via this
///         # module's _shutdown() function.
///         lock = self._tstate_lock
///         if lock is not None:
///             assert not lock.locked()
///         self._is_stopped = True
///         self._tstate_lock = None
///         if not self.daemon:
///             with _shutdown_locks_lock:
///                 # Remove our lock and other released locks from _shutdown_locks
///                 _maintain_shutdown_locks()
///
///     def _delete(self):
///         "Remove current thread from the dict of currently running threads."
///         with _active_limbo_lock:
///             del _active[get_ident()]
///             # There must not be any python code between the previous line
///             # and after the lock is released.  Otherwise a tracing function
///             # could try to acquire the lock again in the same thread, (in
///             # current_thread()), and would block.
///
///     def join(self, timeout=None):
///         """Wait until the thread terminates.
///
///         This blocks the calling thread until the thread whose join() method is
///         called terminates -- either normally or through an unhandled exception
///         or until the optional timeout occurs.
///
///         When the timeout argument is present and not None, it should be a
///         floating point number specifying a timeout for the operation in seconds
///         (or fractions thereof). As join() always returns None, you must call
///         is_alive() after join() to decide whether a timeout happened -- if the
///         thread is still alive, the join() call timed out.
///
///         When the timeout argument is not present or None, the operation will
///         block until the thread terminates.
///
///         A thread can be join()ed many times.
///
///         join() raises a RuntimeError if an attempt is made to join the current
///         thread as that would cause a deadlock. It is also an error to join() a
///         thread before it has been started and attempts to do so raises the same
///         exception.
///
///         """
///         if not self._initialized:
///             raise RuntimeError("Thread.__init__() not called")
///         if not self._started.is_set():
///             raise RuntimeError("cannot join thread before it is started")
///         if self is current_thread():
///             raise RuntimeError("cannot join current thread")
///
///         if timeout is None:
///             self._wait_for_tstate_lock()
///         else:
///             # the behavior of a negative timeout isn't documented, but
///             # historically .join(timeout=x) for x<0 has acted as if timeout=0
///             self._wait_for_tstate_lock(timeout=max(timeout, 0))
///
///     def _wait_for_tstate_lock(self, block=True, timeout=-1):
///         # Issue #18808: wait for the thread state to be gone.
///         # At the end of the thread's life, after all knowledge of the thread
///         # is removed from C data structures, C code releases our _tstate_lock.
///         # This method passes its arguments to _tstate_lock.acquire().
///         # If the lock is acquired, the C code is done, and self._stop() is
///         # called.  That sets ._is_stopped to True, and ._tstate_lock to None.
///         lock = self._tstate_lock
///         if lock is None:
///             # already determined that the C code is done
///             assert self._is_stopped
///             return
///
///         try:
///             if lock.acquire(block, timeout):
///                 lock.release()
///                 self._stop()
///         except:
///             if lock.locked():
///                 # bpo-45274: lock.acquire() acquired the lock, but the function
///                 # was interrupted with an exception before reaching the
///                 # lock.release(). It can happen if a signal handler raises an
///                 # exception, like CTRL+C which raises KeyboardInterrupt.
///                 lock.release()
///                 self._stop()
///             raise
///
///     @property
///     def name(self):
///         """A string used for identification purposes only.
///
///         It has no semantics. Multiple threads may be given the same name. The
///         initial name is set by the constructor.
///
///         """
///         assert self._initialized, "Thread.__init__() not called"
///         return self._name
///
///     @name.setter
///     def name(self, name):
///         assert self._initialized, "Thread.__init__() not called"
///         self._name = str(name)
///
///     @property
///     def ident(self):
///         """Thread identifier of this thread or None if it has not been started.
///
///         This is a nonzero integer. See the get_ident() function. Thread
///         identifiers may be recycled when a thread exits and another thread is
///         created. The identifier is available even after the thread has exited.
///
///         """
///         assert self._initialized, "Thread.__init__() not called"
///         return self._ident
///
///     if _HAVE_THREAD_NATIVE_ID:
///         @property
///         def native_id(self):
///             """Native integral thread ID of this thread, or None if it has not been started.
///
///             This is a non-negative integer. See the get_native_id() function.
///             This represents the Thread ID as reported by the kernel.
///
///             """
///             assert self._initialized, "Thread.__init__() not called"
///             return self._native_id
///
///     def is_alive(self):
///         """Return whether the thread is alive.
///
///         This method returns True just before the run() method starts until just
///         after the run() method terminates. See also the module function
///         enumerate().
///
///         """
///         assert self._initialized, "Thread.__init__() not called"
///         if self._is_stopped or not self._started.is_set():
///             return False
///         self._wait_for_tstate_lock(False)
///         return not self._is_stopped
///
///     @property
///     def daemon(self):
///         """A boolean value indicating whether this thread is a daemon thread.
///
///         This must be set before start() is called, otherwise RuntimeError is
///         raised. Its initial value is inherited from the creating thread; the
///         main thread is not a daemon thread and therefore all threads created in
///         the main thread default to daemon = False.
///
///         The entire Python program exits when only daemon threads are left.
///
///         """
///         assert self._initialized, "Thread.__init__() not called"
///         return self._daemonic
///
///     @daemon.setter
///     def daemon(self, daemonic):
///         if not self._initialized:
///             raise RuntimeError("Thread.__init__() not called")
///         if self._started.is_set():
///             raise RuntimeError("cannot set daemon status of active thread")
///         self._daemonic = daemonic
///
///     def isDaemon(self):
///         """Return whether this thread is a daemon.
///
///         This method is deprecated, use the daemon attribute instead.
///
///         """
///         import warnings
///         warnings.warn('isDaemon() is deprecated, get the daemon attribute instead',
///                       DeprecationWarning, stacklevel=2)
///         return self.daemon
///
///     def setDaemon(self, daemonic):
///         """Set whether this thread is a daemon.
///
///         This method is deprecated, use the .daemon property instead.
///
///         """
///         import warnings
///         warnings.warn('setDaemon() is deprecated, set the daemon attribute instead',
///                       DeprecationWarning, stacklevel=2)
///         self.daemon = daemonic
///
///     def getName(self):
///         """Return a string used for identification purposes only.
///
///         This method is deprecated, use the name attribute instead.
///
///         """
///         import warnings
///         warnings.warn('getName() is deprecated, get the name attribute instead',
///                       DeprecationWarning, stacklevel=2)
///         return self.name
///
///     def setName(self, name):
///         """Set the name string for this thread.
///
///         This method is deprecated, use the name attribute instead.
///
///         """
///         import warnings
///         warnings.warn('setName() is deprecated, set the name attribute instead',
///                       DeprecationWarning, stacklevel=2)
///         self.name = name
/// ```
final class Thread extends PythonClass {
  factory Thread({
    Object? group,
    Object? target,
    Object? name,
    Object? args = const [],
    Object? kwargs,
    Object? daemon,
  }) =>
      PythonFfiDart.instance.importClass(
        "threading",
        "Thread",
        Thread.from,
        <Object?>[
          group,
          target,
          name,
          args,
          kwargs,
        ],
        <String, Object?>{
          "daemon": daemon,
        },
      );

  Thread.from(super.pythonClass) : super.from();

  /// ## getName
  ///
  /// ### python docstring
  ///
  /// Return a string used for identification purposes only.
  ///
  /// This method is deprecated, use the name attribute instead.
  ///
  /// ### python source
  /// ```py
  /// def getName(self):
  ///         """Return a string used for identification purposes only.
  ///
  ///         This method is deprecated, use the name attribute instead.
  ///
  ///         """
  ///         import warnings
  ///         warnings.warn('getName() is deprecated, get the name attribute instead',
  ///                       DeprecationWarning, stacklevel=2)
  ///         return self.name
  /// ```
  Object? getName() => getFunction("getName").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## isDaemon
  ///
  /// ### python docstring
  ///
  /// Return whether this thread is a daemon.
  ///
  /// This method is deprecated, use the daemon attribute instead.
  ///
  /// ### python source
  /// ```py
  /// def isDaemon(self):
  ///         """Return whether this thread is a daemon.
  ///
  ///         This method is deprecated, use the daemon attribute instead.
  ///
  ///         """
  ///         import warnings
  ///         warnings.warn('isDaemon() is deprecated, get the daemon attribute instead',
  ///                       DeprecationWarning, stacklevel=2)
  ///         return self.daemon
  /// ```
  Object? isDaemon() => getFunction("isDaemon").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## is_alive
  ///
  /// ### python docstring
  ///
  /// Return whether the thread is alive.
  ///
  /// This method returns True just before the run() method starts until just
  /// after the run() method terminates. See also the module function
  /// enumerate().
  ///
  /// ### python source
  /// ```py
  /// def is_alive(self):
  ///         """Return whether the thread is alive.
  ///
  ///         This method returns True just before the run() method starts until just
  ///         after the run() method terminates. See also the module function
  ///         enumerate().
  ///
  ///         """
  ///         assert self._initialized, "Thread.__init__() not called"
  ///         if self._is_stopped or not self._started.is_set():
  ///             return False
  ///         self._wait_for_tstate_lock(False)
  ///         return not self._is_stopped
  /// ```
  Object? is_alive() => getFunction("is_alive").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## join
  ///
  /// ### python docstring
  ///
  /// Wait until the thread terminates.
  ///
  /// This blocks the calling thread until the thread whose join() method is
  /// called terminates -- either normally or through an unhandled exception
  /// or until the optional timeout occurs.
  ///
  /// When the timeout argument is present and not None, it should be a
  /// floating point number specifying a timeout for the operation in seconds
  /// (or fractions thereof). As join() always returns None, you must call
  /// is_alive() after join() to decide whether a timeout happened -- if the
  /// thread is still alive, the join() call timed out.
  ///
  /// When the timeout argument is not present or None, the operation will
  /// block until the thread terminates.
  ///
  /// A thread can be join()ed many times.
  ///
  /// join() raises a RuntimeError if an attempt is made to join the current
  /// thread as that would cause a deadlock. It is also an error to join() a
  /// thread before it has been started and attempts to do so raises the same
  /// exception.
  ///
  /// ### python source
  /// ```py
  /// def join(self, timeout=None):
  ///         """Wait until the thread terminates.
  ///
  ///         This blocks the calling thread until the thread whose join() method is
  ///         called terminates -- either normally or through an unhandled exception
  ///         or until the optional timeout occurs.
  ///
  ///         When the timeout argument is present and not None, it should be a
  ///         floating point number specifying a timeout for the operation in seconds
  ///         (or fractions thereof). As join() always returns None, you must call
  ///         is_alive() after join() to decide whether a timeout happened -- if the
  ///         thread is still alive, the join() call timed out.
  ///
  ///         When the timeout argument is not present or None, the operation will
  ///         block until the thread terminates.
  ///
  ///         A thread can be join()ed many times.
  ///
  ///         join() raises a RuntimeError if an attempt is made to join the current
  ///         thread as that would cause a deadlock. It is also an error to join() a
  ///         thread before it has been started and attempts to do so raises the same
  ///         exception.
  ///
  ///         """
  ///         if not self._initialized:
  ///             raise RuntimeError("Thread.__init__() not called")
  ///         if not self._started.is_set():
  ///             raise RuntimeError("cannot join thread before it is started")
  ///         if self is current_thread():
  ///             raise RuntimeError("cannot join current thread")
  ///
  ///         if timeout is None:
  ///             self._wait_for_tstate_lock()
  ///         else:
  ///             # the behavior of a negative timeout isn't documented, but
  ///             # historically .join(timeout=x) for x<0 has acted as if timeout=0
  ///             self._wait_for_tstate_lock(timeout=max(timeout, 0))
  /// ```
  Object? join({
    Object? timeout,
  }) =>
      getFunction("join").call(
        <Object?>[
          timeout,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## run
  ///
  /// ### python docstring
  ///
  /// Method representing the thread's activity.
  ///
  /// You may override this method in a subclass. The standard run() method
  /// invokes the callable object passed to the object's constructor as the
  /// target argument, if any, with sequential and keyword arguments taken
  /// from the args and kwargs arguments, respectively.
  ///
  /// ### python source
  /// ```py
  /// def run(self):
  ///         """Method representing the thread's activity.
  ///
  ///         You may override this method in a subclass. The standard run() method
  ///         invokes the callable object passed to the object's constructor as the
  ///         target argument, if any, with sequential and keyword arguments taken
  ///         from the args and kwargs arguments, respectively.
  ///
  ///         """
  ///         try:
  ///             if self._target is not None:
  ///                 self._target(*self._args, **self._kwargs)
  ///         finally:
  ///             # Avoid a refcycle if the thread is running a function with
  ///             # an argument that has a member that points to the thread.
  ///             del self._target, self._args, self._kwargs
  /// ```
  Object? run() => getFunction("run").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## setDaemon
  ///
  /// ### python docstring
  ///
  /// Set whether this thread is a daemon.
  ///
  /// This method is deprecated, use the .daemon property instead.
  ///
  /// ### python source
  /// ```py
  /// def setDaemon(self, daemonic):
  ///         """Set whether this thread is a daemon.
  ///
  ///         This method is deprecated, use the .daemon property instead.
  ///
  ///         """
  ///         import warnings
  ///         warnings.warn('setDaemon() is deprecated, set the daemon attribute instead',
  ///                       DeprecationWarning, stacklevel=2)
  ///         self.daemon = daemonic
  /// ```
  Object? setDaemon({
    required Object? daemonic,
  }) =>
      getFunction("setDaemon").call(
        <Object?>[
          daemonic,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## setName
  ///
  /// ### python docstring
  ///
  /// Set the name string for this thread.
  ///
  /// This method is deprecated, use the name attribute instead.
  ///
  /// ### python source
  /// ```py
  /// def setName(self, name):
  ///         """Set the name string for this thread.
  ///
  ///         This method is deprecated, use the name attribute instead.
  ///
  ///         """
  ///         import warnings
  ///         warnings.warn('setName() is deprecated, set the name attribute instead',
  ///                       DeprecationWarning, stacklevel=2)
  ///         self.name = name
  /// ```
  Object? setName({
    required Object? name,
  }) =>
      getFunction("setName").call(
        <Object?>[
          name,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## start
  ///
  /// ### python docstring
  ///
  /// Start the thread's activity.
  ///
  /// It must be called at most once per thread object. It arranges for the
  /// object's run() method to be invoked in a separate thread of control.
  ///
  /// This method will raise a RuntimeError if called more than once on the
  /// same thread object.
  ///
  /// ### python source
  /// ```py
  /// def start(self):
  ///         """Start the thread's activity.
  ///
  ///         It must be called at most once per thread object. It arranges for the
  ///         object's run() method to be invoked in a separate thread of control.
  ///
  ///         This method will raise a RuntimeError if called more than once on the
  ///         same thread object.
  ///
  ///         """
  ///         if not self._initialized:
  ///             raise RuntimeError("thread.__init__() not called")
  ///
  ///         if self._started.is_set():
  ///             raise RuntimeError("threads can only be started once")
  ///
  ///         with _active_limbo_lock:
  ///             _limbo[self] = self
  ///         try:
  ///             _start_new_thread(self._bootstrap, ())
  ///         except Exception:
  ///             with _active_limbo_lock:
  ///                 del _limbo[self]
  ///             raise
  ///         self._started.wait()
  /// ```
  Object? start() => getFunction("start").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## daemon (getter)
  ///
  /// ### python docstring
  ///
  /// A boolean value indicating whether this thread is a daemon thread.
  ///
  /// This must be set before start() is called, otherwise RuntimeError is
  /// raised. Its initial value is inherited from the creating thread; the
  /// main thread is not a daemon thread and therefore all threads created in
  /// the main thread default to daemon = False.
  ///
  /// The entire Python program exits when only daemon threads are left.
  Object? get daemon => getAttribute("daemon");

  /// ## daemon (setter)
  ///
  /// ### python docstring
  ///
  /// A boolean value indicating whether this thread is a daemon thread.
  ///
  /// This must be set before start() is called, otherwise RuntimeError is
  /// raised. Its initial value is inherited from the creating thread; the
  /// main thread is not a daemon thread and therefore all threads created in
  /// the main thread default to daemon = False.
  ///
  /// The entire Python program exits when only daemon threads are left.
  set daemon(Object? daemon) => setAttribute("daemon", daemon);

  /// ## ident (getter)
  ///
  /// ### python docstring
  ///
  /// Thread identifier of this thread or None if it has not been started.
  ///
  /// This is a nonzero integer. See the get_ident() function. Thread
  /// identifiers may be recycled when a thread exits and another thread is
  /// created. The identifier is available even after the thread has exited.
  Object? get ident => getAttribute("ident");

  /// ## ident (setter)
  ///
  /// ### python docstring
  ///
  /// Thread identifier of this thread or None if it has not been started.
  ///
  /// This is a nonzero integer. See the get_ident() function. Thread
  /// identifiers may be recycled when a thread exits and another thread is
  /// created. The identifier is available even after the thread has exited.
  set ident(Object? ident) => setAttribute("ident", ident);

  /// ## name (getter)
  ///
  /// ### python docstring
  ///
  /// A string used for identification purposes only.
  ///
  /// It has no semantics. Multiple threads may be given the same name. The
  /// initial name is set by the constructor.
  Object? get name => getAttribute("name");

  /// ## name (setter)
  ///
  /// ### python docstring
  ///
  /// A string used for identification purposes only.
  ///
  /// It has no semantics. Multiple threads may be given the same name. The
  /// initial name is set by the constructor.
  set name(Object? name) => setAttribute("name", name);

  /// ## native_id (getter)
  ///
  /// ### python docstring
  ///
  /// Native integral thread ID of this thread, or None if it has not been started.
  ///
  /// This is a non-negative integer. See the get_native_id() function.
  /// This represents the Thread ID as reported by the kernel.
  Object? get native_id => getAttribute("native_id");

  /// ## native_id (setter)
  ///
  /// ### python docstring
  ///
  /// Native integral thread ID of this thread, or None if it has not been started.
  ///
  /// This is a non-negative integer. See the get_native_id() function.
  /// This represents the Thread ID as reported by the kernel.
  set native_id(Object? native_id) => setAttribute("native_id", native_id);
}

/// ## Timer
///
/// ### python docstring
///
/// Call a function after a specified number of seconds:
///
/// t = Timer(30.0, f, args=None, kwargs=None)
/// t.start()
/// t.cancel()     # stop the timer's action if it's still waiting
///
/// ### python source
/// ```py
/// class Timer(Thread):
///     """Call a function after a specified number of seconds:
///
///             t = Timer(30.0, f, args=None, kwargs=None)
///             t.start()
///             t.cancel()     # stop the timer's action if it's still waiting
///
///     """
///
///     def __init__(self, interval, function, args=None, kwargs=None):
///         Thread.__init__(self)
///         self.interval = interval
///         self.function = function
///         self.args = args if args is not None else []
///         self.kwargs = kwargs if kwargs is not None else {}
///         self.finished = Event()
///
///     def cancel(self):
///         """Stop the timer if it hasn't finished yet."""
///         self.finished.set()
///
///     def run(self):
///         self.finished.wait(self.interval)
///         if not self.finished.is_set():
///             self.function(*self.args, **self.kwargs)
///         self.finished.set()
/// ```
final class Timer extends PythonClass {
  factory Timer({
    required Object? interval,
    required Object? function,
    Object? args,
    Object? kwargs,
  }) =>
      PythonFfiDart.instance.importClass(
        "threading",
        "Timer",
        Timer.from,
        <Object?>[
          interval,
          function,
          args,
          kwargs,
        ],
        <String, Object?>{},
      );

  Timer.from(super.pythonClass) : super.from();

  /// ## cancel
  ///
  /// ### python docstring
  ///
  /// Stop the timer if it hasn't finished yet.
  ///
  /// ### python source
  /// ```py
  /// def cancel(self):
  ///         """Stop the timer if it hasn't finished yet."""
  ///         self.finished.set()
  /// ```
  Object? cancel() => getFunction("cancel").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## getName
  ///
  /// ### python docstring
  ///
  /// Return a string used for identification purposes only.
  ///
  /// This method is deprecated, use the name attribute instead.
  ///
  /// ### python source
  /// ```py
  /// def getName(self):
  ///         """Return a string used for identification purposes only.
  ///
  ///         This method is deprecated, use the name attribute instead.
  ///
  ///         """
  ///         import warnings
  ///         warnings.warn('getName() is deprecated, get the name attribute instead',
  ///                       DeprecationWarning, stacklevel=2)
  ///         return self.name
  /// ```
  Object? getName() => getFunction("getName").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## isDaemon
  ///
  /// ### python docstring
  ///
  /// Return whether this thread is a daemon.
  ///
  /// This method is deprecated, use the daemon attribute instead.
  ///
  /// ### python source
  /// ```py
  /// def isDaemon(self):
  ///         """Return whether this thread is a daemon.
  ///
  ///         This method is deprecated, use the daemon attribute instead.
  ///
  ///         """
  ///         import warnings
  ///         warnings.warn('isDaemon() is deprecated, get the daemon attribute instead',
  ///                       DeprecationWarning, stacklevel=2)
  ///         return self.daemon
  /// ```
  Object? isDaemon() => getFunction("isDaemon").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## is_alive
  ///
  /// ### python docstring
  ///
  /// Return whether the thread is alive.
  ///
  /// This method returns True just before the run() method starts until just
  /// after the run() method terminates. See also the module function
  /// enumerate().
  ///
  /// ### python source
  /// ```py
  /// def is_alive(self):
  ///         """Return whether the thread is alive.
  ///
  ///         This method returns True just before the run() method starts until just
  ///         after the run() method terminates. See also the module function
  ///         enumerate().
  ///
  ///         """
  ///         assert self._initialized, "Thread.__init__() not called"
  ///         if self._is_stopped or not self._started.is_set():
  ///             return False
  ///         self._wait_for_tstate_lock(False)
  ///         return not self._is_stopped
  /// ```
  Object? is_alive() => getFunction("is_alive").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## join
  ///
  /// ### python docstring
  ///
  /// Wait until the thread terminates.
  ///
  /// This blocks the calling thread until the thread whose join() method is
  /// called terminates -- either normally or through an unhandled exception
  /// or until the optional timeout occurs.
  ///
  /// When the timeout argument is present and not None, it should be a
  /// floating point number specifying a timeout for the operation in seconds
  /// (or fractions thereof). As join() always returns None, you must call
  /// is_alive() after join() to decide whether a timeout happened -- if the
  /// thread is still alive, the join() call timed out.
  ///
  /// When the timeout argument is not present or None, the operation will
  /// block until the thread terminates.
  ///
  /// A thread can be join()ed many times.
  ///
  /// join() raises a RuntimeError if an attempt is made to join the current
  /// thread as that would cause a deadlock. It is also an error to join() a
  /// thread before it has been started and attempts to do so raises the same
  /// exception.
  ///
  /// ### python source
  /// ```py
  /// def join(self, timeout=None):
  ///         """Wait until the thread terminates.
  ///
  ///         This blocks the calling thread until the thread whose join() method is
  ///         called terminates -- either normally or through an unhandled exception
  ///         or until the optional timeout occurs.
  ///
  ///         When the timeout argument is present and not None, it should be a
  ///         floating point number specifying a timeout for the operation in seconds
  ///         (or fractions thereof). As join() always returns None, you must call
  ///         is_alive() after join() to decide whether a timeout happened -- if the
  ///         thread is still alive, the join() call timed out.
  ///
  ///         When the timeout argument is not present or None, the operation will
  ///         block until the thread terminates.
  ///
  ///         A thread can be join()ed many times.
  ///
  ///         join() raises a RuntimeError if an attempt is made to join the current
  ///         thread as that would cause a deadlock. It is also an error to join() a
  ///         thread before it has been started and attempts to do so raises the same
  ///         exception.
  ///
  ///         """
  ///         if not self._initialized:
  ///             raise RuntimeError("Thread.__init__() not called")
  ///         if not self._started.is_set():
  ///             raise RuntimeError("cannot join thread before it is started")
  ///         if self is current_thread():
  ///             raise RuntimeError("cannot join current thread")
  ///
  ///         if timeout is None:
  ///             self._wait_for_tstate_lock()
  ///         else:
  ///             # the behavior of a negative timeout isn't documented, but
  ///             # historically .join(timeout=x) for x<0 has acted as if timeout=0
  ///             self._wait_for_tstate_lock(timeout=max(timeout, 0))
  /// ```
  Object? join({
    Object? timeout,
  }) =>
      getFunction("join").call(
        <Object?>[
          timeout,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## run
  ///
  /// ### python docstring
  ///
  /// Method representing the thread's activity.
  ///
  /// You may override this method in a subclass. The standard run() method
  /// invokes the callable object passed to the object's constructor as the
  /// target argument, if any, with sequential and keyword arguments taken
  /// from the args and kwargs arguments, respectively.
  ///
  /// ### python source
  /// ```py
  /// def run(self):
  ///         self.finished.wait(self.interval)
  ///         if not self.finished.is_set():
  ///             self.function(*self.args, **self.kwargs)
  ///         self.finished.set()
  /// ```
  Object? run() => getFunction("run").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## setDaemon
  ///
  /// ### python docstring
  ///
  /// Set whether this thread is a daemon.
  ///
  /// This method is deprecated, use the .daemon property instead.
  ///
  /// ### python source
  /// ```py
  /// def setDaemon(self, daemonic):
  ///         """Set whether this thread is a daemon.
  ///
  ///         This method is deprecated, use the .daemon property instead.
  ///
  ///         """
  ///         import warnings
  ///         warnings.warn('setDaemon() is deprecated, set the daemon attribute instead',
  ///                       DeprecationWarning, stacklevel=2)
  ///         self.daemon = daemonic
  /// ```
  Object? setDaemon({
    required Object? daemonic,
  }) =>
      getFunction("setDaemon").call(
        <Object?>[
          daemonic,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## setName
  ///
  /// ### python docstring
  ///
  /// Set the name string for this thread.
  ///
  /// This method is deprecated, use the name attribute instead.
  ///
  /// ### python source
  /// ```py
  /// def setName(self, name):
  ///         """Set the name string for this thread.
  ///
  ///         This method is deprecated, use the name attribute instead.
  ///
  ///         """
  ///         import warnings
  ///         warnings.warn('setName() is deprecated, set the name attribute instead',
  ///                       DeprecationWarning, stacklevel=2)
  ///         self.name = name
  /// ```
  Object? setName({
    required Object? name,
  }) =>
      getFunction("setName").call(
        <Object?>[
          name,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## start
  ///
  /// ### python docstring
  ///
  /// Start the thread's activity.
  ///
  /// It must be called at most once per thread object. It arranges for the
  /// object's run() method to be invoked in a separate thread of control.
  ///
  /// This method will raise a RuntimeError if called more than once on the
  /// same thread object.
  ///
  /// ### python source
  /// ```py
  /// def start(self):
  ///         """Start the thread's activity.
  ///
  ///         It must be called at most once per thread object. It arranges for the
  ///         object's run() method to be invoked in a separate thread of control.
  ///
  ///         This method will raise a RuntimeError if called more than once on the
  ///         same thread object.
  ///
  ///         """
  ///         if not self._initialized:
  ///             raise RuntimeError("thread.__init__() not called")
  ///
  ///         if self._started.is_set():
  ///             raise RuntimeError("threads can only be started once")
  ///
  ///         with _active_limbo_lock:
  ///             _limbo[self] = self
  ///         try:
  ///             _start_new_thread(self._bootstrap, ())
  ///         except Exception:
  ///             with _active_limbo_lock:
  ///                 del _limbo[self]
  ///             raise
  ///         self._started.wait()
  /// ```
  Object? start() => getFunction("start").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## daemon (getter)
  ///
  /// ### python docstring
  ///
  /// A boolean value indicating whether this thread is a daemon thread.
  ///
  /// This must be set before start() is called, otherwise RuntimeError is
  /// raised. Its initial value is inherited from the creating thread; the
  /// main thread is not a daemon thread and therefore all threads created in
  /// the main thread default to daemon = False.
  ///
  /// The entire Python program exits when only daemon threads are left.
  Object? get daemon => getAttribute("daemon");

  /// ## daemon (setter)
  ///
  /// ### python docstring
  ///
  /// A boolean value indicating whether this thread is a daemon thread.
  ///
  /// This must be set before start() is called, otherwise RuntimeError is
  /// raised. Its initial value is inherited from the creating thread; the
  /// main thread is not a daemon thread and therefore all threads created in
  /// the main thread default to daemon = False.
  ///
  /// The entire Python program exits when only daemon threads are left.
  set daemon(Object? daemon) => setAttribute("daemon", daemon);

  /// ## ident (getter)
  ///
  /// ### python docstring
  ///
  /// Thread identifier of this thread or None if it has not been started.
  ///
  /// This is a nonzero integer. See the get_ident() function. Thread
  /// identifiers may be recycled when a thread exits and another thread is
  /// created. The identifier is available even after the thread has exited.
  Object? get ident => getAttribute("ident");

  /// ## ident (setter)
  ///
  /// ### python docstring
  ///
  /// Thread identifier of this thread or None if it has not been started.
  ///
  /// This is a nonzero integer. See the get_ident() function. Thread
  /// identifiers may be recycled when a thread exits and another thread is
  /// created. The identifier is available even after the thread has exited.
  set ident(Object? ident) => setAttribute("ident", ident);

  /// ## name (getter)
  ///
  /// ### python docstring
  ///
  /// A string used for identification purposes only.
  ///
  /// It has no semantics. Multiple threads may be given the same name. The
  /// initial name is set by the constructor.
  Object? get name => getAttribute("name");

  /// ## name (setter)
  ///
  /// ### python docstring
  ///
  /// A string used for identification purposes only.
  ///
  /// It has no semantics. Multiple threads may be given the same name. The
  /// initial name is set by the constructor.
  set name(Object? name) => setAttribute("name", name);

  /// ## native_id (getter)
  ///
  /// ### python docstring
  ///
  /// Native integral thread ID of this thread, or None if it has not been started.
  ///
  /// This is a non-negative integer. See the get_native_id() function.
  /// This represents the Thread ID as reported by the kernel.
  Object? get native_id => getAttribute("native_id");

  /// ## native_id (setter)
  ///
  /// ### python docstring
  ///
  /// Native integral thread ID of this thread, or None if it has not been started.
  ///
  /// This is a non-negative integer. See the get_native_id() function.
  /// This represents the Thread ID as reported by the kernel.
  set native_id(Object? native_id) => setAttribute("native_id", native_id);

  /// ## interval (getter)
  Object? get interval => getAttribute("interval");

  /// ## interval (setter)
  set interval(Object? interval) => setAttribute("interval", interval);

  /// ## function (getter)
  Object? get function => getAttribute("function");

  /// ## function (setter)
  set function(Object? function) => setAttribute("function", function);

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## kwargs (getter)
  Object? get kwargs => getAttribute("kwargs");

  /// ## kwargs (setter)
  set kwargs(Object? kwargs) => setAttribute("kwargs", kwargs);

  /// ## finished (getter)
  Object? get finished => getAttribute("finished");

  /// ## finished (setter)
  set finished(Object? finished) => setAttribute("finished", finished);
}

/// ## WeakSet
///
/// ### python source
/// ```py
/// class WeakSet:
///     def __init__(self, data=None):
///         self.data = set()
///         def _remove(item, selfref=ref(self)):
///             self = selfref()
///             if self is not None:
///                 if self._iterating:
///                     self._pending_removals.append(item)
///                 else:
///                     self.data.discard(item)
///         self._remove = _remove
///         # A list of keys to be removed
///         self._pending_removals = []
///         self._iterating = set()
///         if data is not None:
///             self.update(data)
///
///     def _commit_removals(self):
///         pop = self._pending_removals.pop
///         discard = self.data.discard
///         while True:
///             try:
///                 item = pop()
///             except IndexError:
///                 return
///             discard(item)
///
///     def __iter__(self):
///         with _IterationGuard(self):
///             for itemref in self.data:
///                 item = itemref()
///                 if item is not None:
///                     # Caveat: the iterator will keep a strong reference to
///                     # `item` until it is resumed or closed.
///                     yield item
///
///     def __len__(self):
///         return len(self.data) - len(self._pending_removals)
///
///     def __contains__(self, item):
///         try:
///             wr = ref(item)
///         except TypeError:
///             return False
///         return wr in self.data
///
///     def __reduce__(self):
///         return self.__class__, (list(self),), self.__getstate__()
///
///     def add(self, item):
///         if self._pending_removals:
///             self._commit_removals()
///         self.data.add(ref(item, self._remove))
///
///     def clear(self):
///         if self._pending_removals:
///             self._commit_removals()
///         self.data.clear()
///
///     def copy(self):
///         return self.__class__(self)
///
///     def pop(self):
///         if self._pending_removals:
///             self._commit_removals()
///         while True:
///             try:
///                 itemref = self.data.pop()
///             except KeyError:
///                 raise KeyError('pop from empty WeakSet') from None
///             item = itemref()
///             if item is not None:
///                 return item
///
///     def remove(self, item):
///         if self._pending_removals:
///             self._commit_removals()
///         self.data.remove(ref(item))
///
///     def discard(self, item):
///         if self._pending_removals:
///             self._commit_removals()
///         self.data.discard(ref(item))
///
///     def update(self, other):
///         if self._pending_removals:
///             self._commit_removals()
///         for element in other:
///             self.add(element)
///
///     def __ior__(self, other):
///         self.update(other)
///         return self
///
///     def difference(self, other):
///         newset = self.copy()
///         newset.difference_update(other)
///         return newset
///     __sub__ = difference
///
///     def difference_update(self, other):
///         self.__isub__(other)
///     def __isub__(self, other):
///         if self._pending_removals:
///             self._commit_removals()
///         if self is other:
///             self.data.clear()
///         else:
///             self.data.difference_update(ref(item) for item in other)
///         return self
///
///     def intersection(self, other):
///         return self.__class__(item for item in other if item in self)
///     __and__ = intersection
///
///     def intersection_update(self, other):
///         self.__iand__(other)
///     def __iand__(self, other):
///         if self._pending_removals:
///             self._commit_removals()
///         self.data.intersection_update(ref(item) for item in other)
///         return self
///
///     def issubset(self, other):
///         return self.data.issubset(ref(item) for item in other)
///     __le__ = issubset
///
///     def __lt__(self, other):
///         return self.data < set(map(ref, other))
///
///     def issuperset(self, other):
///         return self.data.issuperset(ref(item) for item in other)
///     __ge__ = issuperset
///
///     def __gt__(self, other):
///         return self.data > set(map(ref, other))
///
///     def __eq__(self, other):
///         if not isinstance(other, self.__class__):
///             return NotImplemented
///         return self.data == set(map(ref, other))
///
///     def symmetric_difference(self, other):
///         newset = self.copy()
///         newset.symmetric_difference_update(other)
///         return newset
///     __xor__ = symmetric_difference
///
///     def symmetric_difference_update(self, other):
///         self.__ixor__(other)
///     def __ixor__(self, other):
///         if self._pending_removals:
///             self._commit_removals()
///         if self is other:
///             self.data.clear()
///         else:
///             self.data.symmetric_difference_update(ref(item, self._remove) for item in other)
///         return self
///
///     def union(self, other):
///         return self.__class__(e for s in (self, other) for e in s)
///     __or__ = union
///
///     def isdisjoint(self, other):
///         return len(self.intersection(other)) == 0
///
///     def __repr__(self):
///         return repr(self.data)
///
///     __class_getitem__ = classmethod(GenericAlias)
/// ```
final class WeakSet extends PythonClass {
  factory WeakSet({
    Object? data,
  }) =>
      PythonFfiDart.instance.importClass(
        "_weakrefset",
        "WeakSet",
        WeakSet.from,
        <Object?>[
          data,
        ],
        <String, Object?>{},
      );

  WeakSet.from(super.pythonClass) : super.from();

  /// ## add
  ///
  /// ### python source
  /// ```py
  /// def add(self, item):
  ///         if self._pending_removals:
  ///             self._commit_removals()
  ///         self.data.add(ref(item, self._remove))
  /// ```
  Object? add({
    required Object? item,
  }) =>
      getFunction("add").call(
        <Object?>[
          item,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## clear
  ///
  /// ### python source
  /// ```py
  /// def clear(self):
  ///         if self._pending_removals:
  ///             self._commit_removals()
  ///         self.data.clear()
  /// ```
  Object? clear() => getFunction("clear").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## copy
  ///
  /// ### python source
  /// ```py
  /// def copy(self):
  ///         return self.__class__(self)
  /// ```
  Object? copy() => getFunction("copy").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## difference
  ///
  /// ### python source
  /// ```py
  /// def difference(self, other):
  ///         newset = self.copy()
  ///         newset.difference_update(other)
  ///         return newset
  /// ```
  Object? difference({
    required Object? other,
  }) =>
      getFunction("difference").call(
        <Object?>[
          other,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## difference_update
  ///
  /// ### python source
  /// ```py
  /// def difference_update(self, other):
  ///         self.__isub__(other)
  /// ```
  Object? difference_update({
    required Object? other,
  }) =>
      getFunction("difference_update").call(
        <Object?>[
          other,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## discard
  ///
  /// ### python source
  /// ```py
  /// def discard(self, item):
  ///         if self._pending_removals:
  ///             self._commit_removals()
  ///         self.data.discard(ref(item))
  /// ```
  Object? discard({
    required Object? item,
  }) =>
      getFunction("discard").call(
        <Object?>[
          item,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## intersection
  ///
  /// ### python source
  /// ```py
  /// def intersection(self, other):
  ///         return self.__class__(item for item in other if item in self)
  /// ```
  Object? intersection({
    required Object? other,
  }) =>
      getFunction("intersection").call(
        <Object?>[
          other,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## intersection_update
  ///
  /// ### python source
  /// ```py
  /// def intersection_update(self, other):
  ///         self.__iand__(other)
  /// ```
  Object? intersection_update({
    required Object? other,
  }) =>
      getFunction("intersection_update").call(
        <Object?>[
          other,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## isdisjoint
  ///
  /// ### python source
  /// ```py
  /// def isdisjoint(self, other):
  ///         return len(self.intersection(other)) == 0
  /// ```
  Object? isdisjoint({
    required Object? other,
  }) =>
      getFunction("isdisjoint").call(
        <Object?>[
          other,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## issubset
  ///
  /// ### python source
  /// ```py
  /// def issubset(self, other):
  ///         return self.data.issubset(ref(item) for item in other)
  /// ```
  Object? issubset({
    required Object? other,
  }) =>
      getFunction("issubset").call(
        <Object?>[
          other,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## issuperset
  ///
  /// ### python source
  /// ```py
  /// def issuperset(self, other):
  ///         return self.data.issuperset(ref(item) for item in other)
  /// ```
  Object? issuperset({
    required Object? other,
  }) =>
      getFunction("issuperset").call(
        <Object?>[
          other,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## pop
  ///
  /// ### python source
  /// ```py
  /// def pop(self):
  ///         if self._pending_removals:
  ///             self._commit_removals()
  ///         while True:
  ///             try:
  ///                 itemref = self.data.pop()
  ///             except KeyError:
  ///                 raise KeyError('pop from empty WeakSet') from None
  ///             item = itemref()
  ///             if item is not None:
  ///                 return item
  /// ```
  Object? pop() => getFunction("pop").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## remove
  ///
  /// ### python source
  /// ```py
  /// def remove(self, item):
  ///         if self._pending_removals:
  ///             self._commit_removals()
  ///         self.data.remove(ref(item))
  /// ```
  Object? remove({
    required Object? item,
  }) =>
      getFunction("remove").call(
        <Object?>[
          item,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## symmetric_difference
  ///
  /// ### python source
  /// ```py
  /// def symmetric_difference(self, other):
  ///         newset = self.copy()
  ///         newset.symmetric_difference_update(other)
  ///         return newset
  /// ```
  Object? symmetric_difference({
    required Object? other,
  }) =>
      getFunction("symmetric_difference").call(
        <Object?>[
          other,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## symmetric_difference_update
  ///
  /// ### python source
  /// ```py
  /// def symmetric_difference_update(self, other):
  ///         self.__ixor__(other)
  /// ```
  Object? symmetric_difference_update({
    required Object? other,
  }) =>
      getFunction("symmetric_difference_update").call(
        <Object?>[
          other,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## union
  ///
  /// ### python source
  /// ```py
  /// def union(self, other):
  ///         return self.__class__(e for s in (self, other) for e in s)
  /// ```
  Object? union({
    required Object? other,
  }) =>
      getFunction("union").call(
        <Object?>[
          other,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## update
  ///
  /// ### python source
  /// ```py
  /// def update(self, other):
  ///         if self._pending_removals:
  ///             self._commit_removals()
  ///         for element in other:
  ///             self.add(element)
  /// ```
  Object? update({
    required Object? other,
  }) =>
      getFunction("update").call(
        <Object?>[
          other,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## data (getter)
  Object? get data => getAttribute("data");

  /// ## data (setter)
  set data(Object? data) => setAttribute("data", data);
}

/// ## local
///
/// ### python docstring
///
/// Thread-local data
final class local extends PythonClass {
  factory local() => PythonFfiDart.instance.importClass(
        "_thread",
        "local",
        local.from,
        <Object?>[],
      );

  local.from(super.pythonClass) : super.from();
}

/// ## FrameSummary
///
/// ### python docstring
///
/// Information about a single frame from a traceback.
///
/// - :attr:`filename` The filename for the frame.
/// - :attr:`lineno` The line within filename for the frame that was
///   active when the frame was captured.
/// - :attr:`name` The name of the function or method that was executing
///   when the frame was captured.
/// - :attr:`line` The text from the linecache module for the
///   of code that was running when the frame was captured.
/// - :attr:`locals` Either None if locals were not supplied, or a dict
///   mapping the name to the repr() of the variable.
///
/// ### python source
/// ```py
/// class FrameSummary:
///     """Information about a single frame from a traceback.
///
///     - :attr:`filename` The filename for the frame.
///     - :attr:`lineno` The line within filename for the frame that was
///       active when the frame was captured.
///     - :attr:`name` The name of the function or method that was executing
///       when the frame was captured.
///     - :attr:`line` The text from the linecache module for the
///       of code that was running when the frame was captured.
///     - :attr:`locals` Either None if locals were not supplied, or a dict
///       mapping the name to the repr() of the variable.
///     """
///
///     __slots__ = ('filename', 'lineno', 'end_lineno', 'colno', 'end_colno',
///                  'name', '_line', 'locals')
///
///     def __init__(self, filename, lineno, name, *, lookup_line=True,
///             locals=None, line=None,
///             end_lineno=None, colno=None, end_colno=None):
///         """Construct a FrameSummary.
///
///         :param lookup_line: If True, `linecache` is consulted for the source
///             code line. Otherwise, the line will be looked up when first needed.
///         :param locals: If supplied the frame locals, which will be captured as
///             object representations.
///         :param line: If provided, use this instead of looking up the line in
///             the linecache.
///         """
///         self.filename = filename
///         self.lineno = lineno
///         self.name = name
///         self._line = line
///         if lookup_line:
///             self.line
///         self.locals = {k: repr(v) for k, v in locals.items()} if locals else None
///         self.end_lineno = end_lineno
///         self.colno = colno
///         self.end_colno = end_colno
///
///     def __eq__(self, other):
///         if isinstance(other, FrameSummary):
///             return (self.filename == other.filename and
///                     self.lineno == other.lineno and
///                     self.name == other.name and
///                     self.locals == other.locals)
///         if isinstance(other, tuple):
///             return (self.filename, self.lineno, self.name, self.line) == other
///         return NotImplemented
///
///     def __getitem__(self, pos):
///         return (self.filename, self.lineno, self.name, self.line)[pos]
///
///     def __iter__(self):
///         return iter([self.filename, self.lineno, self.name, self.line])
///
///     def __repr__(self):
///         return "<FrameSummary file {filename}, line {lineno} in {name}>".format(
///             filename=self.filename, lineno=self.lineno, name=self.name)
///
///     def __len__(self):
///         return 4
///
///     @property
///     def _original_line(self):
///         # Returns the line as-is from the source, without modifying whitespace.
///         self.line
///         return self._line
///
///     @property
///     def line(self):
///         if self._line is None:
///             if self.lineno is None:
///                 return None
///             self._line = linecache.getline(self.filename, self.lineno)
///         return self._line.strip()
/// ```
final class FrameSummary extends PythonClass {
  factory FrameSummary({
    required Object? filename,
    required Object? lineno,
    required Object? name,
    Object? lookup_line = true,
    Object? locals,
    Object? line,
    Object? end_lineno,
    Object? colno,
    Object? end_colno,
  }) =>
      PythonFfiDart.instance.importClass(
        "traceback",
        "FrameSummary",
        FrameSummary.from,
        <Object?>[
          filename,
          lineno,
          name,
        ],
        <String, Object?>{
          "lookup_line": lookup_line,
          "locals": locals,
          "line": line,
          "end_lineno": end_lineno,
          "colno": colno,
          "end_colno": end_colno,
        },
      );

  FrameSummary.from(super.pythonClass) : super.from();

  /// ## line (getter)
  Object? get line => getAttribute("line");

  /// ## line (setter)
  set line(Object? line) => setAttribute("line", line);

  /// ## colno (getter)
  Object? get colno => getAttribute("colno");

  /// ## colno (setter)
  set colno(Object? colno) => setAttribute("colno", colno);

  /// ## end_colno (getter)
  Object? get end_colno => getAttribute("end_colno");

  /// ## end_colno (setter)
  set end_colno(Object? end_colno) => setAttribute("end_colno", end_colno);

  /// ## end_lineno (getter)
  Object? get end_lineno => getAttribute("end_lineno");

  /// ## end_lineno (setter)
  set end_lineno(Object? end_lineno) => setAttribute("end_lineno", end_lineno);

  /// ## filename (getter)
  Object? get filename => getAttribute("filename");

  /// ## filename (setter)
  set filename(Object? filename) => setAttribute("filename", filename);

  /// ## lineno (getter)
  Object? get lineno => getAttribute("lineno");

  /// ## lineno (setter)
  set lineno(Object? lineno) => setAttribute("lineno", lineno);

  /// ## locals (getter)
  Object? get locals => getAttribute("locals");

  /// ## locals (setter)
  set locals(Object? locals) => setAttribute("locals", locals);

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);
}

/// ## StackSummary
///
/// ### python docstring
///
/// A list of FrameSummary objects, representing a stack of frames.
///
/// ### python source
/// ```py
/// class StackSummary(list):
///     """A list of FrameSummary objects, representing a stack of frames."""
///
///     @classmethod
///     def extract(klass, frame_gen, *, limit=None, lookup_lines=True,
///             capture_locals=False):
///         """Create a StackSummary from a traceback or stack object.
///
///         :param frame_gen: A generator that yields (frame, lineno) tuples
///             whose summaries are to be included in the stack.
///         :param limit: None to include all frames or the number of frames to
///             include.
///         :param lookup_lines: If True, lookup lines for each frame immediately,
///             otherwise lookup is deferred until the frame is rendered.
///         :param capture_locals: If True, the local variables from each frame will
///             be captured as object representations into the FrameSummary.
///         """
///         def extended_frame_gen():
///             for f, lineno in frame_gen:
///                 yield f, (lineno, None, None, None)
///
///         return klass._extract_from_extended_frame_gen(
///             extended_frame_gen(), limit=limit, lookup_lines=lookup_lines,
///             capture_locals=capture_locals)
///
///     @classmethod
///     def _extract_from_extended_frame_gen(klass, frame_gen, *, limit=None,
///             lookup_lines=True, capture_locals=False):
///         # Same as extract but operates on a frame generator that yields
///         # (frame, (lineno, end_lineno, colno, end_colno)) in the stack.
///         # Only lineno is required, the remaining fields can be None if the
///         # information is not available.
///         if limit is None:
///             limit = getattr(sys, 'tracebacklimit', None)
///             if limit is not None and limit < 0:
///                 limit = 0
///         if limit is not None:
///             if limit >= 0:
///                 frame_gen = itertools.islice(frame_gen, limit)
///             else:
///                 frame_gen = collections.deque(frame_gen, maxlen=-limit)
///
///         result = klass()
///         fnames = set()
///         for f, (lineno, end_lineno, colno, end_colno) in frame_gen:
///             co = f.f_code
///             filename = co.co_filename
///             name = co.co_name
///
///             fnames.add(filename)
///             linecache.lazycache(filename, f.f_globals)
///             # Must defer line lookups until we have called checkcache.
///             if capture_locals:
///                 f_locals = f.f_locals
///             else:
///                 f_locals = None
///             result.append(FrameSummary(
///                 filename, lineno, name, lookup_line=False, locals=f_locals,
///                 end_lineno=end_lineno, colno=colno, end_colno=end_colno))
///         for filename in fnames:
///             linecache.checkcache(filename)
///         # If immediate lookup was desired, trigger lookups now.
///         if lookup_lines:
///             for f in result:
///                 f.line
///         return result
///
///     @classmethod
///     def from_list(klass, a_list):
///         """
///         Create a StackSummary object from a supplied list of
///         FrameSummary objects or old-style list of tuples.
///         """
///         # While doing a fast-path check for isinstance(a_list, StackSummary) is
///         # appealing, idlelib.run.cleanup_traceback and other similar code may
///         # break this by making arbitrary frames plain tuples, so we need to
///         # check on a frame by frame basis.
///         result = StackSummary()
///         for frame in a_list:
///             if isinstance(frame, FrameSummary):
///                 result.append(frame)
///             else:
///                 filename, lineno, name, line = frame
///                 result.append(FrameSummary(filename, lineno, name, line=line))
///         return result
///
///     def format_frame_summary(self, frame_summary):
///         """Format the lines for a single FrameSummary.
///
///         Returns a string representing one frame involved in the stack. This
///         gets called for every frame to be printed in the stack summary.
///         """
///         row = []
///         row.append('  File "{}", line {}, in {}\n'.format(
///             frame_summary.filename, frame_summary.lineno, frame_summary.name))
///         if frame_summary.line:
///             stripped_line = frame_summary.line.strip()
///             row.append('    {}\n'.format(stripped_line))
///
///             orig_line_len = len(frame_summary._original_line)
///             frame_line_len = len(frame_summary.line.lstrip())
///             stripped_characters = orig_line_len - frame_line_len
///             if (
///                 frame_summary.colno is not None
///                 and frame_summary.end_colno is not None
///             ):
///                 start_offset = _byte_offset_to_character_offset(
///                     frame_summary._original_line, frame_summary.colno) + 1
///                 end_offset = _byte_offset_to_character_offset(
///                     frame_summary._original_line, frame_summary.end_colno) + 1
///
///                 anchors = None
///                 if frame_summary.lineno == frame_summary.end_lineno:
///                     with suppress(Exception):
///                         anchors = _extract_caret_anchors_from_line_segment(
///                             frame_summary._original_line[start_offset - 1:end_offset - 1]
///                         )
///                 else:
///                     end_offset = stripped_characters + len(stripped_line)
///
///                 # show indicators if primary char doesn't span the frame line
///                 if end_offset - start_offset < len(stripped_line) or (
///                         anchors and anchors.right_start_offset - anchors.left_end_offset > 0):
///                     row.append('    ')
///                     row.append(' ' * (start_offset - stripped_characters))
///
///                     if anchors:
///                         row.append(anchors.primary_char * (anchors.left_end_offset))
///                         row.append(anchors.secondary_char * (anchors.right_start_offset - anchors.left_end_offset))
///                         row.append(anchors.primary_char * (end_offset - start_offset - anchors.right_start_offset))
///                     else:
///                         row.append('^' * (end_offset - start_offset))
///
///                     row.append('\n')
///
///         if frame_summary.locals:
///             for name, value in sorted(frame_summary.locals.items()):
///                 row.append('    {name} = {value}\n'.format(name=name, value=value))
///
///         return ''.join(row)
///
///     def format(self):
///         """Format the stack ready for printing.
///
///         Returns a list of strings ready for printing.  Each string in the
///         resulting list corresponds to a single frame from the stack.
///         Each string ends in a newline; the strings may contain internal
///         newlines as well, for those items with source text lines.
///
///         For long sequences of the same frame and line, the first few
///         repetitions are shown, followed by a summary line stating the exact
///         number of further repetitions.
///         """
///         result = []
///         last_file = None
///         last_line = None
///         last_name = None
///         count = 0
///         for frame_summary in self:
///             formatted_frame = self.format_frame_summary(frame_summary)
///             if formatted_frame is None:
///                 continue
///             if (last_file is None or last_file != frame_summary.filename or
///                 last_line is None or last_line != frame_summary.lineno or
///                 last_name is None or last_name != frame_summary.name):
///                 if count > _RECURSIVE_CUTOFF:
///                     count -= _RECURSIVE_CUTOFF
///                     result.append(
///                         f'  [Previous line repeated {count} more '
///                         f'time{"s" if count > 1 else ""}]\n'
///                     )
///                 last_file = frame_summary.filename
///                 last_line = frame_summary.lineno
///                 last_name = frame_summary.name
///                 count = 0
///             count += 1
///             if count > _RECURSIVE_CUTOFF:
///                 continue
///             result.append(formatted_frame)
///
///         if count > _RECURSIVE_CUTOFF:
///             count -= _RECURSIVE_CUTOFF
///             result.append(
///                 f'  [Previous line repeated {count} more '
///                 f'time{"s" if count > 1 else ""}]\n'
///             )
///         return result
/// ```
final class StackSummary extends PythonClass {
  factory StackSummary() => PythonFfiDart.instance.importClass(
        "traceback",
        "StackSummary",
        StackSummary.from,
        <Object?>[],
      );

  StackSummary.from(super.pythonClass) : super.from();

  /// ## format
  ///
  /// ### python docstring
  ///
  /// Format the stack ready for printing.
  ///
  /// Returns a list of strings ready for printing.  Each string in the
  /// resulting list corresponds to a single frame from the stack.
  /// Each string ends in a newline; the strings may contain internal
  /// newlines as well, for those items with source text lines.
  ///
  /// For long sequences of the same frame and line, the first few
  /// repetitions are shown, followed by a summary line stating the exact
  /// number of further repetitions.
  ///
  /// ### python source
  /// ```py
  /// def format(self):
  ///         """Format the stack ready for printing.
  ///
  ///         Returns a list of strings ready for printing.  Each string in the
  ///         resulting list corresponds to a single frame from the stack.
  ///         Each string ends in a newline; the strings may contain internal
  ///         newlines as well, for those items with source text lines.
  ///
  ///         For long sequences of the same frame and line, the first few
  ///         repetitions are shown, followed by a summary line stating the exact
  ///         number of further repetitions.
  ///         """
  ///         result = []
  ///         last_file = None
  ///         last_line = None
  ///         last_name = None
  ///         count = 0
  ///         for frame_summary in self:
  ///             formatted_frame = self.format_frame_summary(frame_summary)
  ///             if formatted_frame is None:
  ///                 continue
  ///             if (last_file is None or last_file != frame_summary.filename or
  ///                 last_line is None or last_line != frame_summary.lineno or
  ///                 last_name is None or last_name != frame_summary.name):
  ///                 if count > _RECURSIVE_CUTOFF:
  ///                     count -= _RECURSIVE_CUTOFF
  ///                     result.append(
  ///                         f'  [Previous line repeated {count} more '
  ///                         f'time{"s" if count > 1 else ""}]\n'
  ///                     )
  ///                 last_file = frame_summary.filename
  ///                 last_line = frame_summary.lineno
  ///                 last_name = frame_summary.name
  ///                 count = 0
  ///             count += 1
  ///             if count > _RECURSIVE_CUTOFF:
  ///                 continue
  ///             result.append(formatted_frame)
  ///
  ///         if count > _RECURSIVE_CUTOFF:
  ///             count -= _RECURSIVE_CUTOFF
  ///             result.append(
  ///                 f'  [Previous line repeated {count} more '
  ///                 f'time{"s" if count > 1 else ""}]\n'
  ///             )
  ///         return result
  /// ```
  Object? format() => getFunction("format").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## format_frame_summary
  ///
  /// ### python docstring
  ///
  /// Format the lines for a single FrameSummary.
  ///
  /// Returns a string representing one frame involved in the stack. This
  /// gets called for every frame to be printed in the stack summary.
  ///
  /// ### python source
  /// ```py
  /// def format_frame_summary(self, frame_summary):
  ///         """Format the lines for a single FrameSummary.
  ///
  ///         Returns a string representing one frame involved in the stack. This
  ///         gets called for every frame to be printed in the stack summary.
  ///         """
  ///         row = []
  ///         row.append('  File "{}", line {}, in {}\n'.format(
  ///             frame_summary.filename, frame_summary.lineno, frame_summary.name))
  ///         if frame_summary.line:
  ///             stripped_line = frame_summary.line.strip()
  ///             row.append('    {}\n'.format(stripped_line))
  ///
  ///             orig_line_len = len(frame_summary._original_line)
  ///             frame_line_len = len(frame_summary.line.lstrip())
  ///             stripped_characters = orig_line_len - frame_line_len
  ///             if (
  ///                 frame_summary.colno is not None
  ///                 and frame_summary.end_colno is not None
  ///             ):
  ///                 start_offset = _byte_offset_to_character_offset(
  ///                     frame_summary._original_line, frame_summary.colno) + 1
  ///                 end_offset = _byte_offset_to_character_offset(
  ///                     frame_summary._original_line, frame_summary.end_colno) + 1
  ///
  ///                 anchors = None
  ///                 if frame_summary.lineno == frame_summary.end_lineno:
  ///                     with suppress(Exception):
  ///                         anchors = _extract_caret_anchors_from_line_segment(
  ///                             frame_summary._original_line[start_offset - 1:end_offset - 1]
  ///                         )
  ///                 else:
  ///                     end_offset = stripped_characters + len(stripped_line)
  ///
  ///                 # show indicators if primary char doesn't span the frame line
  ///                 if end_offset - start_offset < len(stripped_line) or (
  ///                         anchors and anchors.right_start_offset - anchors.left_end_offset > 0):
  ///                     row.append('    ')
  ///                     row.append(' ' * (start_offset - stripped_characters))
  ///
  ///                     if anchors:
  ///                         row.append(anchors.primary_char * (anchors.left_end_offset))
  ///                         row.append(anchors.secondary_char * (anchors.right_start_offset - anchors.left_end_offset))
  ///                         row.append(anchors.primary_char * (end_offset - start_offset - anchors.right_start_offset))
  ///                     else:
  ///                         row.append('^' * (end_offset - start_offset))
  ///
  ///                     row.append('\n')
  ///
  ///         if frame_summary.locals:
  ///             for name, value in sorted(frame_summary.locals.items()):
  ///                 row.append('    {name} = {value}\n'.format(name=name, value=value))
  ///
  ///         return ''.join(row)
  /// ```
  Object? format_frame_summary({
    required Object? frame_summary,
  }) =>
      getFunction("format_frame_summary").call(
        <Object?>[
          frame_summary,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## append (getter)
  Object? get append => getAttribute("append");

  /// ## append (setter)
  set append(Object? append) => setAttribute("append", append);

  /// ## clear (getter)
  Object? get clear => getAttribute("clear");

  /// ## clear (setter)
  set clear(Object? clear) => setAttribute("clear", clear);

  /// ## copy (getter)
  Object? get copy => getAttribute("copy");

  /// ## copy (setter)
  set copy(Object? copy) => setAttribute("copy", copy);

  /// ## count (getter)
  Object? get count => getAttribute("count");

  /// ## count (setter)
  set count(Object? count) => setAttribute("count", count);

  /// ## extend (getter)
  Object? get extend => getAttribute("extend");

  /// ## extend (setter)
  set extend(Object? extend) => setAttribute("extend", extend);

  /// ## extract (getter)
  ///
  /// ### python docstring
  ///
  /// Create a StackSummary from a traceback or stack object.
  ///
  /// :param frame_gen: A generator that yields (frame, lineno) tuples
  ///     whose summaries are to be included in the stack.
  /// :param limit: None to include all frames or the number of frames to
  ///     include.
  /// :param lookup_lines: If True, lookup lines for each frame immediately,
  ///     otherwise lookup is deferred until the frame is rendered.
  /// :param capture_locals: If True, the local variables from each frame will
  ///     be captured as object representations into the FrameSummary.
  Object? get extract => getAttribute("extract");

  /// ## extract (setter)
  ///
  /// ### python docstring
  ///
  /// Create a StackSummary from a traceback or stack object.
  ///
  /// :param frame_gen: A generator that yields (frame, lineno) tuples
  ///     whose summaries are to be included in the stack.
  /// :param limit: None to include all frames or the number of frames to
  ///     include.
  /// :param lookup_lines: If True, lookup lines for each frame immediately,
  ///     otherwise lookup is deferred until the frame is rendered.
  /// :param capture_locals: If True, the local variables from each frame will
  ///     be captured as object representations into the FrameSummary.
  set extract(Object? extract) => setAttribute("extract", extract);

  /// ## from_list (getter)
  ///
  /// ### python docstring
  ///
  /// Create a StackSummary object from a supplied list of
  /// FrameSummary objects or old-style list of tuples.
  Object? get from_list => getAttribute("from_list");

  /// ## from_list (setter)
  ///
  /// ### python docstring
  ///
  /// Create a StackSummary object from a supplied list of
  /// FrameSummary objects or old-style list of tuples.
  set from_list(Object? from_list) => setAttribute("from_list", from_list);

  /// ## index (getter)
  Object? get index => getAttribute("index");

  /// ## index (setter)
  set index(Object? index) => setAttribute("index", index);

  /// ## insert (getter)
  Object? get insert => getAttribute("insert");

  /// ## insert (setter)
  set insert(Object? insert) => setAttribute("insert", insert);

  /// ## pop (getter)
  Object? get pop => getAttribute("pop");

  /// ## pop (setter)
  set pop(Object? pop) => setAttribute("pop", pop);

  /// ## remove (getter)
  Object? get remove => getAttribute("remove");

  /// ## remove (setter)
  set remove(Object? remove) => setAttribute("remove", remove);

  /// ## reverse (getter)
  Object? get reverse => getAttribute("reverse");

  /// ## reverse (setter)
  set reverse(Object? reverse) => setAttribute("reverse", reverse);

  /// ## sort (getter)
  Object? get sort => getAttribute("sort");

  /// ## sort (setter)
  set sort(Object? sort) => setAttribute("sort", sort);
}

/// ## TracebackException
///
/// ### python docstring
///
/// An exception ready for rendering.
///
/// The traceback module captures enough attributes from the original exception
/// to this intermediary form to ensure that no references are held, while
/// still being able to fully print or format it.
///
/// max_group_width and max_group_depth control the formatting of exception
/// groups. The depth refers to the nesting level of the group, and the width
/// refers to the size of a single exception group's exceptions array. The
/// formatted output is truncated when either limit is exceeded.
///
/// Use `from_exception` to create TracebackException instances from exception
/// objects, or the constructor to create TracebackException instances from
/// individual components.
///
/// - :attr:`__cause__` A TracebackException of the original *__cause__*.
/// - :attr:`__context__` A TracebackException of the original *__context__*.
/// - :attr:`__suppress_context__` The *__suppress_context__* value from the
///   original exception.
/// - :attr:`stack` A `StackSummary` representing the traceback.
/// - :attr:`exc_type` The class of the original traceback.
/// - :attr:`filename` For syntax errors - the filename where the error
///   occurred.
/// - :attr:`lineno` For syntax errors - the linenumber where the error
///   occurred.
/// - :attr:`end_lineno` For syntax errors - the end linenumber where the error
///   occurred. Can be `None` if not present.
/// - :attr:`text` For syntax errors - the text where the error
///   occurred.
/// - :attr:`offset` For syntax errors - the offset into the text where the
///   error occurred.
/// - :attr:`end_offset` For syntax errors - the offset into the text where the
///   error occurred. Can be `None` if not present.
/// - :attr:`msg` For syntax errors - the compiler error message.
///
/// ### python source
/// ```py
/// class TracebackException:
///     """An exception ready for rendering.
///
///     The traceback module captures enough attributes from the original exception
///     to this intermediary form to ensure that no references are held, while
///     still being able to fully print or format it.
///
///     max_group_width and max_group_depth control the formatting of exception
///     groups. The depth refers to the nesting level of the group, and the width
///     refers to the size of a single exception group's exceptions array. The
///     formatted output is truncated when either limit is exceeded.
///
///     Use `from_exception` to create TracebackException instances from exception
///     objects, or the constructor to create TracebackException instances from
///     individual components.
///
///     - :attr:`__cause__` A TracebackException of the original *__cause__*.
///     - :attr:`__context__` A TracebackException of the original *__context__*.
///     - :attr:`__suppress_context__` The *__suppress_context__* value from the
///       original exception.
///     - :attr:`stack` A `StackSummary` representing the traceback.
///     - :attr:`exc_type` The class of the original traceback.
///     - :attr:`filename` For syntax errors - the filename where the error
///       occurred.
///     - :attr:`lineno` For syntax errors - the linenumber where the error
///       occurred.
///     - :attr:`end_lineno` For syntax errors - the end linenumber where the error
///       occurred. Can be `None` if not present.
///     - :attr:`text` For syntax errors - the text where the error
///       occurred.
///     - :attr:`offset` For syntax errors - the offset into the text where the
///       error occurred.
///     - :attr:`end_offset` For syntax errors - the offset into the text where the
///       error occurred. Can be `None` if not present.
///     - :attr:`msg` For syntax errors - the compiler error message.
///     """
///
///     def __init__(self, exc_type, exc_value, exc_traceback, *, limit=None,
///             lookup_lines=True, capture_locals=False, compact=False,
///             max_group_width=15, max_group_depth=10, _seen=None):
///         # NB: we need to accept exc_traceback, exc_value, exc_traceback to
///         # permit backwards compat with the existing API, otherwise we
///         # need stub thunk objects just to glue it together.
///         # Handle loops in __cause__ or __context__.
///         is_recursive_call = _seen is not None
///         if _seen is None:
///             _seen = set()
///         _seen.add(id(exc_value))
///
///         self.max_group_width = max_group_width
///         self.max_group_depth = max_group_depth
///
///         self.stack = StackSummary._extract_from_extended_frame_gen(
///             _walk_tb_with_full_positions(exc_traceback),
///             limit=limit, lookup_lines=lookup_lines,
///             capture_locals=capture_locals)
///         self.exc_type = exc_type
///         # Capture now to permit freeing resources: only complication is in the
///         # unofficial API _format_final_exc_line
///         self._str = _safe_string(exc_value, 'exception')
///         self.__notes__ = getattr(exc_value, '__notes__', None)
///
///         if exc_type and issubclass(exc_type, SyntaxError):
///             # Handle SyntaxError's specially
///             self.filename = exc_value.filename
///             lno = exc_value.lineno
///             self.lineno = str(lno) if lno is not None else None
///             end_lno = exc_value.end_lineno
///             self.end_lineno = str(end_lno) if end_lno is not None else None
///             self.text = exc_value.text
///             self.offset = exc_value.offset
///             self.end_offset = exc_value.end_offset
///             self.msg = exc_value.msg
///         if lookup_lines:
///             self._load_lines()
///         self.__suppress_context__ = \
///             exc_value.__suppress_context__ if exc_value is not None else False
///
///         # Convert __cause__ and __context__ to `TracebackExceptions`s, use a
///         # queue to avoid recursion (only the top-level call gets _seen == None)
///         if not is_recursive_call:
///             queue = [(self, exc_value)]
///             while queue:
///                 te, e = queue.pop()
///                 if (e and e.__cause__ is not None
///                     and id(e.__cause__) not in _seen):
///                     cause = TracebackException(
///                         type(e.__cause__),
///                         e.__cause__,
///                         e.__cause__.__traceback__,
///                         limit=limit,
///                         lookup_lines=lookup_lines,
///                         capture_locals=capture_locals,
///                         max_group_width=max_group_width,
///                         max_group_depth=max_group_depth,
///                         _seen=_seen)
///                 else:
///                     cause = None
///
///                 if compact:
///                     need_context = (cause is None and
///                                     e is not None and
///                                     not e.__suppress_context__)
///                 else:
///                     need_context = True
///                 if (e and e.__context__ is not None
///                     and need_context and id(e.__context__) not in _seen):
///                     context = TracebackException(
///                         type(e.__context__),
///                         e.__context__,
///                         e.__context__.__traceback__,
///                         limit=limit,
///                         lookup_lines=lookup_lines,
///                         capture_locals=capture_locals,
///                         max_group_width=max_group_width,
///                         max_group_depth=max_group_depth,
///                         _seen=_seen)
///                 else:
///                     context = None
///
///                 if e and isinstance(e, BaseExceptionGroup):
///                     exceptions = []
///                     for exc in e.exceptions:
///                         texc = TracebackException(
///                             type(exc),
///                             exc,
///                             exc.__traceback__,
///                             limit=limit,
///                             lookup_lines=lookup_lines,
///                             capture_locals=capture_locals,
///                             max_group_width=max_group_width,
///                             max_group_depth=max_group_depth,
///                             _seen=_seen)
///                         exceptions.append(texc)
///                 else:
///                     exceptions = None
///
///                 te.__cause__ = cause
///                 te.__context__ = context
///                 te.exceptions = exceptions
///                 if cause:
///                     queue.append((te.__cause__, e.__cause__))
///                 if context:
///                     queue.append((te.__context__, e.__context__))
///                 if exceptions:
///                     queue.extend(zip(te.exceptions, e.exceptions))
///
///     @classmethod
///     def from_exception(cls, exc, *args, **kwargs):
///         """Create a TracebackException from an exception."""
///         return cls(type(exc), exc, exc.__traceback__, *args, **kwargs)
///
///     def _load_lines(self):
///         """Private API. force all lines in the stack to be loaded."""
///         for frame in self.stack:
///             frame.line
///
///     def __eq__(self, other):
///         if isinstance(other, TracebackException):
///             return self.__dict__ == other.__dict__
///         return NotImplemented
///
///     def __str__(self):
///         return self._str
///
///     def format_exception_only(self):
///         """Format the exception part of the traceback.
///
///         The return value is a generator of strings, each ending in a newline.
///
///         Normally, the generator emits a single string; however, for
///         SyntaxError exceptions, it emits several lines that (when
///         printed) display detailed information about where the syntax
///         error occurred.
///
///         The message indicating which exception occurred is always the last
///         string in the output.
///         """
///         if self.exc_type is None:
///             yield _format_final_exc_line(None, self._str)
///             return
///
///         stype = self.exc_type.__qualname__
///         smod = self.exc_type.__module__
///         if smod not in ("__main__", "builtins"):
///             if not isinstance(smod, str):
///                 smod = "<unknown>"
///             stype = smod + '.' + stype
///
///         if not issubclass(self.exc_type, SyntaxError):
///             yield _format_final_exc_line(stype, self._str)
///         else:
///             yield from self._format_syntax_error(stype)
///         if isinstance(self.__notes__, collections.abc.Sequence):
///             for note in self.__notes__:
///                 note = _safe_string(note, 'note')
///                 yield from [l + '\n' for l in note.split('\n')]
///         elif self.__notes__ is not None:
///             yield _safe_string(self.__notes__, '__notes__', func=repr)
///
///     def _format_syntax_error(self, stype):
///         """Format SyntaxError exceptions (internal helper)."""
///         # Show exactly where the problem was found.
///         filename_suffix = ''
///         if self.lineno is not None:
///             yield '  File "{}", line {}\n'.format(
///                 self.filename or "<string>", self.lineno)
///         elif self.filename is not None:
///             filename_suffix = ' ({})'.format(self.filename)
///
///         text = self.text
///         if text is not None:
///             # text  = "   foo\n"
///             # rtext = "   foo"
///             # ltext =    "foo"
///             rtext = text.rstrip('\n')
///             ltext = rtext.lstrip(' \n\f')
///             spaces = len(rtext) - len(ltext)
///             yield '    {}\n'.format(ltext)
///
///             if self.offset is not None:
///                 offset = self.offset
///                 end_offset = self.end_offset if self.end_offset not in {None, 0} else offset
///                 if offset == end_offset or end_offset == -1:
///                     end_offset = offset + 1
///
///                 # Convert 1-based column offset to 0-based index into stripped text
///                 colno = offset - 1 - spaces
///                 end_colno = end_offset - 1 - spaces
///                 if colno >= 0:
///                     # non-space whitespace (likes tabs) must be kept for alignment
///                     caretspace = ((c if c.isspace() else ' ') for c in ltext[:colno])
///                     yield '    {}{}'.format("".join(caretspace), ('^' * (end_colno - colno) + "\n"))
///         msg = self.msg or "<no detail available>"
///         yield "{}: {}{}\n".format(stype, msg, filename_suffix)
///
///     def format(self, *, chain=True, _ctx=None):
///         """Format the exception.
///
///         If chain is not *True*, *__cause__* and *__context__* will not be formatted.
///
///         The return value is a generator of strings, each ending in a newline and
///         some containing internal newlines. `print_exception` is a wrapper around
///         this method which just prints the lines to a file.
///
///         The message indicating which exception occurred is always the last
///         string in the output.
///         """
///
///         if _ctx is None:
///             _ctx = _ExceptionPrintContext()
///
///         output = []
///         exc = self
///         if chain:
///             while exc:
///                 if exc.__cause__ is not None:
///                     chained_msg = _cause_message
///                     chained_exc = exc.__cause__
///                 elif (exc.__context__  is not None and
///                       not exc.__suppress_context__):
///                     chained_msg = _context_message
///                     chained_exc = exc.__context__
///                 else:
///                     chained_msg = None
///                     chained_exc = None
///
///                 output.append((chained_msg, exc))
///                 exc = chained_exc
///         else:
///             output.append((None, exc))
///
///         for msg, exc in reversed(output):
///             if msg is not None:
///                 yield from _ctx.emit(msg)
///             if exc.exceptions is None:
///                 if exc.stack:
///                     yield from _ctx.emit('Traceback (most recent call last):\n')
///                     yield from _ctx.emit(exc.stack.format())
///                 yield from _ctx.emit(exc.format_exception_only())
///             elif _ctx.exception_group_depth > self.max_group_depth:
///                 # exception group, but depth exceeds limit
///                 yield from _ctx.emit(
///                     f"... (max_group_depth is {self.max_group_depth})\n")
///             else:
///                 # format exception group
///                 is_toplevel = (_ctx.exception_group_depth == 0)
///                 if is_toplevel:
///                     _ctx.exception_group_depth += 1
///
///                 if exc.stack:
///                     yield from _ctx.emit(
///                         'Exception Group Traceback (most recent call last):\n',
///                         margin_char = '+' if is_toplevel else None)
///                     yield from _ctx.emit(exc.stack.format())
///
///                 yield from _ctx.emit(exc.format_exception_only())
///                 num_excs = len(exc.exceptions)
///                 if num_excs <= self.max_group_width:
///                     n = num_excs
///                 else:
///                     n = self.max_group_width + 1
///                 _ctx.need_close = False
///                 for i in range(n):
///                     last_exc = (i == n-1)
///                     if last_exc:
///                         # The closing frame may be added by a recursive call
///                         _ctx.need_close = True
///
///                     if self.max_group_width is not None:
///                         truncated = (i >= self.max_group_width)
///                     else:
///                         truncated = False
///                     title = f'{i+1}' if not truncated else '...'
///                     yield (_ctx.indent() +
///                            ('+-' if i==0 else '  ') +
///                            f'+---------------- {title} ----------------\n')
///                     _ctx.exception_group_depth += 1
///                     if not truncated:
///                         yield from exc.exceptions[i].format(chain=chain, _ctx=_ctx)
///                     else:
///                         remaining = num_excs - self.max_group_width
///                         plural = 's' if remaining > 1 else ''
///                         yield from _ctx.emit(
///                             f"and {remaining} more exception{plural}\n")
///
///                     if last_exc and _ctx.need_close:
///                         yield (_ctx.indent() +
///                                "+------------------------------------\n")
///                         _ctx.need_close = False
///                     _ctx.exception_group_depth -= 1
///
///                 if is_toplevel:
///                     assert _ctx.exception_group_depth == 1
///                     _ctx.exception_group_depth = 0
///
///
///     def print(self, *, file=None, chain=True):
///         """Print the result of self.format(chain=chain) to 'file'."""
///         if file is None:
///             file = sys.stderr
///         for line in self.format(chain=chain):
///             print(line, file=file, end="")
/// ```
final class TracebackException extends PythonClass {
  factory TracebackException({
    required Object? exc_type,
    required Object? exc_value,
    required Object? exc_traceback,
    Object? limit,
    Object? lookup_lines = true,
    Object? capture_locals = false,
    Object? compact = false,
    Object? max_group_width = 15,
    Object? max_group_depth = 10,
    Object? $_seen,
  }) =>
      PythonFfiDart.instance.importClass(
        "traceback",
        "TracebackException",
        TracebackException.from,
        <Object?>[
          exc_type,
          exc_value,
          exc_traceback,
        ],
        <String, Object?>{
          "limit": limit,
          "lookup_lines": lookup_lines,
          "capture_locals": capture_locals,
          "compact": compact,
          "max_group_width": max_group_width,
          "max_group_depth": max_group_depth,
          "_seen": $_seen,
        },
      );

  TracebackException.from(super.pythonClass) : super.from();

  /// ## format
  ///
  /// ### python docstring
  ///
  /// Format the exception.
  ///
  /// If chain is not *True*, *__cause__* and *__context__* will not be formatted.
  ///
  /// The return value is a generator of strings, each ending in a newline and
  /// some containing internal newlines. `print_exception` is a wrapper around
  /// this method which just prints the lines to a file.
  ///
  /// The message indicating which exception occurred is always the last
  /// string in the output.
  ///
  /// ### python source
  /// ```py
  /// def format(self, *, chain=True, _ctx=None):
  ///         """Format the exception.
  ///
  ///         If chain is not *True*, *__cause__* and *__context__* will not be formatted.
  ///
  ///         The return value is a generator of strings, each ending in a newline and
  ///         some containing internal newlines. `print_exception` is a wrapper around
  ///         this method which just prints the lines to a file.
  ///
  ///         The message indicating which exception occurred is always the last
  ///         string in the output.
  ///         """
  ///
  ///         if _ctx is None:
  ///             _ctx = _ExceptionPrintContext()
  ///
  ///         output = []
  ///         exc = self
  ///         if chain:
  ///             while exc:
  ///                 if exc.__cause__ is not None:
  ///                     chained_msg = _cause_message
  ///                     chained_exc = exc.__cause__
  ///                 elif (exc.__context__  is not None and
  ///                       not exc.__suppress_context__):
  ///                     chained_msg = _context_message
  ///                     chained_exc = exc.__context__
  ///                 else:
  ///                     chained_msg = None
  ///                     chained_exc = None
  ///
  ///                 output.append((chained_msg, exc))
  ///                 exc = chained_exc
  ///         else:
  ///             output.append((None, exc))
  ///
  ///         for msg, exc in reversed(output):
  ///             if msg is not None:
  ///                 yield from _ctx.emit(msg)
  ///             if exc.exceptions is None:
  ///                 if exc.stack:
  ///                     yield from _ctx.emit('Traceback (most recent call last):\n')
  ///                     yield from _ctx.emit(exc.stack.format())
  ///                 yield from _ctx.emit(exc.format_exception_only())
  ///             elif _ctx.exception_group_depth > self.max_group_depth:
  ///                 # exception group, but depth exceeds limit
  ///                 yield from _ctx.emit(
  ///                     f"... (max_group_depth is {self.max_group_depth})\n")
  ///             else:
  ///                 # format exception group
  ///                 is_toplevel = (_ctx.exception_group_depth == 0)
  ///                 if is_toplevel:
  ///                     _ctx.exception_group_depth += 1
  ///
  ///                 if exc.stack:
  ///                     yield from _ctx.emit(
  ///                         'Exception Group Traceback (most recent call last):\n',
  ///                         margin_char = '+' if is_toplevel else None)
  ///                     yield from _ctx.emit(exc.stack.format())
  ///
  ///                 yield from _ctx.emit(exc.format_exception_only())
  ///                 num_excs = len(exc.exceptions)
  ///                 if num_excs <= self.max_group_width:
  ///                     n = num_excs
  ///                 else:
  ///                     n = self.max_group_width + 1
  ///                 _ctx.need_close = False
  ///                 for i in range(n):
  ///                     last_exc = (i == n-1)
  ///                     if last_exc:
  ///                         # The closing frame may be added by a recursive call
  ///                         _ctx.need_close = True
  ///
  ///                     if self.max_group_width is not None:
  ///                         truncated = (i >= self.max_group_width)
  ///                     else:
  ///                         truncated = False
  ///                     title = f'{i+1}' if not truncated else '...'
  ///                     yield (_ctx.indent() +
  ///                            ('+-' if i==0 else '  ') +
  ///                            f'+---------------- {title} ----------------\n')
  ///                     _ctx.exception_group_depth += 1
  ///                     if not truncated:
  ///                         yield from exc.exceptions[i].format(chain=chain, _ctx=_ctx)
  ///                     else:
  ///                         remaining = num_excs - self.max_group_width
  ///                         plural = 's' if remaining > 1 else ''
  ///                         yield from _ctx.emit(
  ///                             f"and {remaining} more exception{plural}\n")
  ///
  ///                     if last_exc and _ctx.need_close:
  ///                         yield (_ctx.indent() +
  ///                                "+------------------------------------\n")
  ///                         _ctx.need_close = False
  ///                     _ctx.exception_group_depth -= 1
  ///
  ///                 if is_toplevel:
  ///                     assert _ctx.exception_group_depth == 1
  ///                     _ctx.exception_group_depth = 0
  /// ```
  Object? format({
    Object? chain = true,
    Object? $_ctx,
  }) =>
      getFunction("format").call(
        <Object?>[],
        kwargs: <String, Object?>{
          "chain": chain,
          "_ctx": $_ctx,
        },
      );

  /// ## format_exception_only
  ///
  /// ### python docstring
  ///
  /// Format the exception part of the traceback.
  ///
  /// The return value is a generator of strings, each ending in a newline.
  ///
  /// Normally, the generator emits a single string; however, for
  /// SyntaxError exceptions, it emits several lines that (when
  /// printed) display detailed information about where the syntax
  /// error occurred.
  ///
  /// The message indicating which exception occurred is always the last
  /// string in the output.
  ///
  /// ### python source
  /// ```py
  /// def format_exception_only(self):
  ///         """Format the exception part of the traceback.
  ///
  ///         The return value is a generator of strings, each ending in a newline.
  ///
  ///         Normally, the generator emits a single string; however, for
  ///         SyntaxError exceptions, it emits several lines that (when
  ///         printed) display detailed information about where the syntax
  ///         error occurred.
  ///
  ///         The message indicating which exception occurred is always the last
  ///         string in the output.
  ///         """
  ///         if self.exc_type is None:
  ///             yield _format_final_exc_line(None, self._str)
  ///             return
  ///
  ///         stype = self.exc_type.__qualname__
  ///         smod = self.exc_type.__module__
  ///         if smod not in ("__main__", "builtins"):
  ///             if not isinstance(smod, str):
  ///                 smod = "<unknown>"
  ///             stype = smod + '.' + stype
  ///
  ///         if not issubclass(self.exc_type, SyntaxError):
  ///             yield _format_final_exc_line(stype, self._str)
  ///         else:
  ///             yield from self._format_syntax_error(stype)
  ///         if isinstance(self.__notes__, collections.abc.Sequence):
  ///             for note in self.__notes__:
  ///                 note = _safe_string(note, 'note')
  ///                 yield from [l + '\n' for l in note.split('\n')]
  ///         elif self.__notes__ is not None:
  ///             yield _safe_string(self.__notes__, '__notes__', func=repr)
  /// ```
  Object? format_exception_only() => getFunction("format_exception_only").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## print
  ///
  /// ### python docstring
  ///
  /// Print the result of self.format(chain=chain) to 'file'.
  ///
  /// ### python source
  /// ```py
  /// def print(self, *, file=None, chain=True):
  ///         """Print the result of self.format(chain=chain) to 'file'."""
  ///         if file is None:
  ///             file = sys.stderr
  ///         for line in self.format(chain=chain):
  ///             print(line, file=file, end="")
  /// ```
  Object? print({
    Object? file,
    Object? chain = true,
  }) =>
      getFunction("print").call(
        <Object?>[],
        kwargs: <String, Object?>{
          "file": file,
          "chain": chain,
        },
      );

  /// ## from_exception (getter)
  ///
  /// ### python docstring
  ///
  /// Create a TracebackException from an exception.
  Object? get from_exception => getAttribute("from_exception");

  /// ## from_exception (setter)
  ///
  /// ### python docstring
  ///
  /// Create a TracebackException from an exception.
  set from_exception(Object? from_exception) =>
      setAttribute("from_exception", from_exception);

  /// ## max_group_width (getter)
  Object? get max_group_width => getAttribute("max_group_width");

  /// ## max_group_width (setter)
  set max_group_width(Object? max_group_width) =>
      setAttribute("max_group_width", max_group_width);

  /// ## max_group_depth (getter)
  Object? get max_group_depth => getAttribute("max_group_depth");

  /// ## max_group_depth (setter)
  set max_group_depth(Object? max_group_depth) =>
      setAttribute("max_group_depth", max_group_depth);

  /// ## stack (getter)
  Object? get stack => getAttribute("stack");

  /// ## stack (setter)
  set stack(Object? stack) => setAttribute("stack", stack);

  /// ## exc_type (getter)
  Object? get exc_type => getAttribute("exc_type");

  /// ## exc_type (setter)
  set exc_type(Object? exc_type) => setAttribute("exc_type", exc_type);

  /// ## filename (getter)
  Object? get filename => getAttribute("filename");

  /// ## filename (setter)
  set filename(Object? filename) => setAttribute("filename", filename);

  /// ## lineno (getter)
  Object? get lineno => getAttribute("lineno");

  /// ## lineno (setter)
  set lineno(Object? lineno) => setAttribute("lineno", lineno);

  /// ## end_lineno (getter)
  Object? get end_lineno => getAttribute("end_lineno");

  /// ## end_lineno (setter)
  set end_lineno(Object? end_lineno) => setAttribute("end_lineno", end_lineno);

  /// ## text (getter)
  Object? get text => getAttribute("text");

  /// ## text (setter)
  set text(Object? text) => setAttribute("text", text);

  /// ## offset (getter)
  Object? get offset => getAttribute("offset");

  /// ## offset (setter)
  set offset(Object? offset) => setAttribute("offset", offset);

  /// ## end_offset (getter)
  Object? get end_offset => getAttribute("end_offset");

  /// ## end_offset (setter)
  set end_offset(Object? end_offset) => setAttribute("end_offset", end_offset);

  /// ## msg (getter)
  Object? get msg => getAttribute("msg");

  /// ## msg (setter)
  set msg(Object? msg) => setAttribute("msg", msg);
}

/// ## StopTokenizing
///
/// ### python source
/// ```py
/// class StopTokenizing(Exception): pass
/// ```
final class StopTokenizing extends PythonClass {
  factory StopTokenizing() => PythonFfiDart.instance.importClass(
        "tokenize",
        "StopTokenizing",
        StopTokenizing.from,
        <Object?>[],
      );

  StopTokenizing.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## TokenError
///
/// ### python source
/// ```py
/// class TokenError(Exception): pass
/// ```
final class TokenError extends PythonClass {
  factory TokenError() => PythonFfiDart.instance.importClass(
        "tokenize",
        "TokenError",
        TokenError.from,
        <Object?>[],
      );

  TokenError.from(super.pythonClass) : super.from();

  /// ## args (getter)
  Object? get args => getAttribute("args");

  /// ## args (setter)
  set args(Object? args) => setAttribute("args", args);

  /// ## add_note (getter)
  Object? get add_note => getAttribute("add_note");

  /// ## add_note (setter)
  set add_note(Object? add_note) => setAttribute("add_note", add_note);

  /// ## with_traceback (getter)
  Object? get with_traceback => getAttribute("with_traceback");

  /// ## with_traceback (setter)
  set with_traceback(Object? with_traceback) =>
      setAttribute("with_traceback", with_traceback);
}

/// ## TokenInfo
///
/// ### python docstring
///
/// TokenInfo(type, string, start, end, line)
///
/// ### python source
/// ```py
/// class TokenInfo(collections.namedtuple('TokenInfo', 'type string start end line')):
///     def __repr__(self):
///         annotated_type = '%d (%s)' % (self.type, tok_name[self.type])
///         return ('TokenInfo(type=%s, string=%r, start=%r, end=%r, line=%r)' %
///                 self._replace(type=annotated_type))
///
///     @property
///     def exact_type(self):
///         if self.type == OP and self.string in EXACT_TOKEN_TYPES:
///             return EXACT_TOKEN_TYPES[self.string]
///         else:
///             return self.type
/// ```
final class TokenInfo extends PythonClass {
  factory TokenInfo() => PythonFfiDart.instance.importClass(
        "tokenize",
        "TokenInfo",
        TokenInfo.from,
        <Object?>[],
      );

  TokenInfo.from(super.pythonClass) : super.from();

  /// ## end (getter)
  ///
  /// ### python docstring
  ///
  /// Alias for field number 3
  Object? get end => getAttribute("end");

  /// ## end (setter)
  ///
  /// ### python docstring
  ///
  /// Alias for field number 3
  set end(Object? end) => setAttribute("end", end);

  /// ## exact_type (getter)
  Object? get exact_type => getAttribute("exact_type");

  /// ## exact_type (setter)
  set exact_type(Object? exact_type) => setAttribute("exact_type", exact_type);

  /// ## line (getter)
  ///
  /// ### python docstring
  ///
  /// Alias for field number 4
  Object? get line => getAttribute("line");

  /// ## line (setter)
  ///
  /// ### python docstring
  ///
  /// Alias for field number 4
  set line(Object? line) => setAttribute("line", line);

  /// ## start (getter)
  ///
  /// ### python docstring
  ///
  /// Alias for field number 2
  Object? get start => getAttribute("start");

  /// ## start (setter)
  ///
  /// ### python docstring
  ///
  /// Alias for field number 2
  set start(Object? start) => setAttribute("start", start);

  /// ## string (getter)
  ///
  /// ### python docstring
  ///
  /// Alias for field number 1
  Object? get string => getAttribute("string");

  /// ## string (setter)
  ///
  /// ### python docstring
  ///
  /// Alias for field number 1
  set string(Object? string) => setAttribute("string", string);

  /// ## type (getter)
  ///
  /// ### python docstring
  ///
  /// Alias for field number 0
  Object? get type => getAttribute("type");

  /// ## type (setter)
  ///
  /// ### python docstring
  ///
  /// Alias for field number 0
  set type(Object? type) => setAttribute("type", type);

  /// ## count (getter)
  Object? get count => getAttribute("count");

  /// ## count (setter)
  set count(Object? count) => setAttribute("count", count);

  /// ## index (getter)
  Object? get index => getAttribute("index");

  /// ## index (setter)
  set index(Object? index) => setAttribute("index", index);
}

/// ## Untokenizer
///
/// ### python source
/// ```py
/// class Untokenizer:
///
///     def __init__(self):
///         self.tokens = []
///         self.prev_row = 1
///         self.prev_col = 0
///         self.encoding = None
///
///     def add_whitespace(self, start):
///         row, col = start
///         if row < self.prev_row or row == self.prev_row and col < self.prev_col:
///             raise ValueError("start ({},{}) precedes previous end ({},{})"
///                              .format(row, col, self.prev_row, self.prev_col))
///         row_offset = row - self.prev_row
///         if row_offset:
///             self.tokens.append("\\\n" * row_offset)
///             self.prev_col = 0
///         col_offset = col - self.prev_col
///         if col_offset:
///             self.tokens.append(" " * col_offset)
///
///     def untokenize(self, iterable):
///         it = iter(iterable)
///         indents = []
///         startline = False
///         for t in it:
///             if len(t) == 2:
///                 self.compat(t, it)
///                 break
///             tok_type, token, start, end, line = t
///             if tok_type == ENCODING:
///                 self.encoding = token
///                 continue
///             if tok_type == ENDMARKER:
///                 break
///             if tok_type == INDENT:
///                 indents.append(token)
///                 continue
///             elif tok_type == DEDENT:
///                 indents.pop()
///                 self.prev_row, self.prev_col = end
///                 continue
///             elif tok_type in (NEWLINE, NL):
///                 startline = True
///             elif startline and indents:
///                 indent = indents[-1]
///                 if start[1] >= len(indent):
///                     self.tokens.append(indent)
///                     self.prev_col = len(indent)
///                 startline = False
///             self.add_whitespace(start)
///             self.tokens.append(token)
///             self.prev_row, self.prev_col = end
///             if tok_type in (NEWLINE, NL):
///                 self.prev_row += 1
///                 self.prev_col = 0
///         return "".join(self.tokens)
///
///     def compat(self, token, iterable):
///         indents = []
///         toks_append = self.tokens.append
///         startline = token[0] in (NEWLINE, NL)
///         prevstring = False
///
///         for tok in _itertools.chain([token], iterable):
///             toknum, tokval = tok[:2]
///             if toknum == ENCODING:
///                 self.encoding = tokval
///                 continue
///
///             if toknum in (NAME, NUMBER):
///                 tokval += ' '
///
///             # Insert a space between two consecutive strings
///             if toknum == STRING:
///                 if prevstring:
///                     tokval = ' ' + tokval
///                 prevstring = True
///             else:
///                 prevstring = False
///
///             if toknum == INDENT:
///                 indents.append(tokval)
///                 continue
///             elif toknum == DEDENT:
///                 indents.pop()
///                 continue
///             elif toknum in (NEWLINE, NL):
///                 startline = True
///             elif startline and indents:
///                 toks_append(indents[-1])
///                 startline = False
///             toks_append(tokval)
/// ```
final class Untokenizer extends PythonClass {
  factory Untokenizer() => PythonFfiDart.instance.importClass(
        "tokenize",
        "Untokenizer",
        Untokenizer.from,
        <Object?>[],
        <String, Object?>{},
      );

  Untokenizer.from(super.pythonClass) : super.from();

  /// ## add_whitespace
  ///
  /// ### python source
  /// ```py
  /// def add_whitespace(self, start):
  ///         row, col = start
  ///         if row < self.prev_row or row == self.prev_row and col < self.prev_col:
  ///             raise ValueError("start ({},{}) precedes previous end ({},{})"
  ///                              .format(row, col, self.prev_row, self.prev_col))
  ///         row_offset = row - self.prev_row
  ///         if row_offset:
  ///             self.tokens.append("\\\n" * row_offset)
  ///             self.prev_col = 0
  ///         col_offset = col - self.prev_col
  ///         if col_offset:
  ///             self.tokens.append(" " * col_offset)
  /// ```
  Object? add_whitespace({
    required Object? start,
  }) =>
      getFunction("add_whitespace").call(
        <Object?>[
          start,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## compat
  ///
  /// ### python source
  /// ```py
  /// def compat(self, token, iterable):
  ///         indents = []
  ///         toks_append = self.tokens.append
  ///         startline = token[0] in (NEWLINE, NL)
  ///         prevstring = False
  ///
  ///         for tok in _itertools.chain([token], iterable):
  ///             toknum, tokval = tok[:2]
  ///             if toknum == ENCODING:
  ///                 self.encoding = tokval
  ///                 continue
  ///
  ///             if toknum in (NAME, NUMBER):
  ///                 tokval += ' '
  ///
  ///             # Insert a space between two consecutive strings
  ///             if toknum == STRING:
  ///                 if prevstring:
  ///                     tokval = ' ' + tokval
  ///                 prevstring = True
  ///             else:
  ///                 prevstring = False
  ///
  ///             if toknum == INDENT:
  ///                 indents.append(tokval)
  ///                 continue
  ///             elif toknum == DEDENT:
  ///                 indents.pop()
  ///                 continue
  ///             elif toknum in (NEWLINE, NL):
  ///                 startline = True
  ///             elif startline and indents:
  ///                 toks_append(indents[-1])
  ///                 startline = False
  ///             toks_append(tokval)
  /// ```
  Object? compat({
    required Object? token,
    required Object? iterable,
  }) =>
      getFunction("compat").call(
        <Object?>[
          token,
          iterable,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## untokenize
  ///
  /// ### python source
  /// ```py
  /// def untokenize(self, iterable):
  ///         it = iter(iterable)
  ///         indents = []
  ///         startline = False
  ///         for t in it:
  ///             if len(t) == 2:
  ///                 self.compat(t, it)
  ///                 break
  ///             tok_type, token, start, end, line = t
  ///             if tok_type == ENCODING:
  ///                 self.encoding = token
  ///                 continue
  ///             if tok_type == ENDMARKER:
  ///                 break
  ///             if tok_type == INDENT:
  ///                 indents.append(token)
  ///                 continue
  ///             elif tok_type == DEDENT:
  ///                 indents.pop()
  ///                 self.prev_row, self.prev_col = end
  ///                 continue
  ///             elif tok_type in (NEWLINE, NL):
  ///                 startline = True
  ///             elif startline and indents:
  ///                 indent = indents[-1]
  ///                 if start[1] >= len(indent):
  ///                     self.tokens.append(indent)
  ///                     self.prev_col = len(indent)
  ///                 startline = False
  ///             self.add_whitespace(start)
  ///             self.tokens.append(token)
  ///             self.prev_row, self.prev_col = end
  ///             if tok_type in (NEWLINE, NL):
  ///                 self.prev_row += 1
  ///                 self.prev_col = 0
  ///         return "".join(self.tokens)
  /// ```
  Object? untokenize({
    required Object? iterable,
  }) =>
      getFunction("untokenize").call(
        <Object?>[
          iterable,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## tokens (getter)
  Object? get tokens => getAttribute("tokens");

  /// ## tokens (setter)
  set tokens(Object? tokens) => setAttribute("tokens", tokens);

  /// ## prev_row (getter)
  Object? get prev_row => getAttribute("prev_row");

  /// ## prev_row (setter)
  set prev_row(Object? prev_row) => setAttribute("prev_row", prev_row);

  /// ## prev_col (getter)
  Object? get prev_col => getAttribute("prev_col");

  /// ## prev_col (setter)
  set prev_col(Object? prev_col) => setAttribute("prev_col", prev_col);

  /// ## encoding (getter)
  Object? get encoding => getAttribute("encoding");

  /// ## encoding (setter)
  set encoding(Object? encoding) => setAttribute("encoding", encoding);
}

/// ## TextWrapper
///
/// ### python docstring
///
/// Object for wrapping/filling text.  The public interface consists of
/// the wrap() and fill() methods; the other methods are just there for
/// subclasses to override in order to tweak the default behaviour.
/// If you want to completely replace the main wrapping algorithm,
/// you'll probably have to override _wrap_chunks().
///
/// Several instance attributes control various aspects of wrapping:
///   width (default: 70)
///     the maximum width of wrapped lines (unless break_long_words
///     is false)
///   initial_indent (default: "")
///     string that will be prepended to the first line of wrapped
///     output.  Counts towards the line's width.
///   subsequent_indent (default: "")
///     string that will be prepended to all lines save the first
///     of wrapped output; also counts towards each line's width.
///   expand_tabs (default: true)
///     Expand tabs in input text to spaces before further processing.
///     Each tab will become 0 .. 'tabsize' spaces, depending on its position
///     in its line.  If false, each tab is treated as a single character.
///   tabsize (default: 8)
///     Expand tabs in input text to 0 .. 'tabsize' spaces, unless
///     'expand_tabs' is false.
///   replace_whitespace (default: true)
///     Replace all whitespace characters in the input text by spaces
///     after tab expansion.  Note that if expand_tabs is false and
///     replace_whitespace is true, every tab will be converted to a
///     single space!
///   fix_sentence_endings (default: false)
///     Ensure that sentence-ending punctuation is always followed
///     by two spaces.  Off by default because the algorithm is
///     (unavoidably) imperfect.
///   break_long_words (default: true)
///     Break words longer than 'width'.  If false, those words will not
///     be broken, and some lines might be longer than 'width'.
///   break_on_hyphens (default: true)
///     Allow breaking hyphenated words. If true, wrapping will occur
///     preferably on whitespaces and right after hyphens part of
///     compound words.
///   drop_whitespace (default: true)
///     Drop leading and trailing whitespace from lines.
///   max_lines (default: None)
///     Truncate wrapped lines.
///   placeholder (default: ' [...]')
///     Append to the last line of truncated text.
///
/// ### python source
/// ```py
/// class TextWrapper:
///     """
///     Object for wrapping/filling text.  The public interface consists of
///     the wrap() and fill() methods; the other methods are just there for
///     subclasses to override in order to tweak the default behaviour.
///     If you want to completely replace the main wrapping algorithm,
///     you'll probably have to override _wrap_chunks().
///
///     Several instance attributes control various aspects of wrapping:
///       width (default: 70)
///         the maximum width of wrapped lines (unless break_long_words
///         is false)
///       initial_indent (default: "")
///         string that will be prepended to the first line of wrapped
///         output.  Counts towards the line's width.
///       subsequent_indent (default: "")
///         string that will be prepended to all lines save the first
///         of wrapped output; also counts towards each line's width.
///       expand_tabs (default: true)
///         Expand tabs in input text to spaces before further processing.
///         Each tab will become 0 .. 'tabsize' spaces, depending on its position
///         in its line.  If false, each tab is treated as a single character.
///       tabsize (default: 8)
///         Expand tabs in input text to 0 .. 'tabsize' spaces, unless
///         'expand_tabs' is false.
///       replace_whitespace (default: true)
///         Replace all whitespace characters in the input text by spaces
///         after tab expansion.  Note that if expand_tabs is false and
///         replace_whitespace is true, every tab will be converted to a
///         single space!
///       fix_sentence_endings (default: false)
///         Ensure that sentence-ending punctuation is always followed
///         by two spaces.  Off by default because the algorithm is
///         (unavoidably) imperfect.
///       break_long_words (default: true)
///         Break words longer than 'width'.  If false, those words will not
///         be broken, and some lines might be longer than 'width'.
///       break_on_hyphens (default: true)
///         Allow breaking hyphenated words. If true, wrapping will occur
///         preferably on whitespaces and right after hyphens part of
///         compound words.
///       drop_whitespace (default: true)
///         Drop leading and trailing whitespace from lines.
///       max_lines (default: None)
///         Truncate wrapped lines.
///       placeholder (default: ' [...]')
///         Append to the last line of truncated text.
///     """
///
///     unicode_whitespace_trans = dict.fromkeys(map(ord, _whitespace), ord(' '))
///
///     # This funky little regex is just the trick for splitting
///     # text up into word-wrappable chunks.  E.g.
///     #   "Hello there -- you goof-ball, use the -b option!"
///     # splits into
///     #   Hello/ /there/ /--/ /you/ /goof-/ball,/ /use/ /the/ /-b/ /option!
///     # (after stripping out empty strings).
///     word_punct = r'[\w!"\'&.,?]'
///     letter = r'[^\d\W]'
///     whitespace = r'[%s]' % re.escape(_whitespace)
///     nowhitespace = '[^' + whitespace[1:]
///     wordsep_re = re.compile(r'''
///         ( # any whitespace
///           %(ws)s+
///         | # em-dash between words
///           (?<=%(wp)s) -{2,} (?=\w)
///         | # word, possibly hyphenated
///           %(nws)s+? (?:
///             # hyphenated word
///               -(?: (?<=%(lt)s{2}-) | (?<=%(lt)s-%(lt)s-))
///               (?= %(lt)s -? %(lt)s)
///             | # end of word
///               (?=%(ws)s|\Z)
///             | # em-dash
///               (?<=%(wp)s) (?=-{2,}\w)
///             )
///         )''' % {'wp': word_punct, 'lt': letter,
///                 'ws': whitespace, 'nws': nowhitespace},
///         re.VERBOSE)
///     del word_punct, letter, nowhitespace
///
///     # This less funky little regex just split on recognized spaces. E.g.
///     #   "Hello there -- you goof-ball, use the -b option!"
///     # splits into
///     #   Hello/ /there/ /--/ /you/ /goof-ball,/ /use/ /the/ /-b/ /option!/
///     wordsep_simple_re = re.compile(r'(%s+)' % whitespace)
///     del whitespace
///
///     # XXX this is not locale- or charset-aware -- string.lowercase
///     # is US-ASCII only (and therefore English-only)
///     sentence_end_re = re.compile(r'[a-z]'             # lowercase letter
///                                  r'[\.\!\?]'          # sentence-ending punct.
///                                  r'[\"\']?'           # optional end-of-quote
///                                  r'\Z')               # end of chunk
///
///     def __init__(self,
///                  width=70,
///                  initial_indent="",
///                  subsequent_indent="",
///                  expand_tabs=True,
///                  replace_whitespace=True,
///                  fix_sentence_endings=False,
///                  break_long_words=True,
///                  drop_whitespace=True,
///                  break_on_hyphens=True,
///                  tabsize=8,
///                  *,
///                  max_lines=None,
///                  placeholder=' [...]'):
///         self.width = width
///         self.initial_indent = initial_indent
///         self.subsequent_indent = subsequent_indent
///         self.expand_tabs = expand_tabs
///         self.replace_whitespace = replace_whitespace
///         self.fix_sentence_endings = fix_sentence_endings
///         self.break_long_words = break_long_words
///         self.drop_whitespace = drop_whitespace
///         self.break_on_hyphens = break_on_hyphens
///         self.tabsize = tabsize
///         self.max_lines = max_lines
///         self.placeholder = placeholder
///
///
///     # -- Private methods -----------------------------------------------
///     # (possibly useful for subclasses to override)
///
///     def _munge_whitespace(self, text):
///         """_munge_whitespace(text : string) -> string
///
///         Munge whitespace in text: expand tabs and convert all other
///         whitespace characters to spaces.  Eg. " foo\\tbar\\n\\nbaz"
///         becomes " foo    bar  baz".
///         """
///         if self.expand_tabs:
///             text = text.expandtabs(self.tabsize)
///         if self.replace_whitespace:
///             text = text.translate(self.unicode_whitespace_trans)
///         return text
///
///
///     def _split(self, text):
///         """_split(text : string) -> [string]
///
///         Split the text to wrap into indivisible chunks.  Chunks are
///         not quite the same as words; see _wrap_chunks() for full
///         details.  As an example, the text
///           Look, goof-ball -- use the -b option!
///         breaks into the following chunks:
///           'Look,', ' ', 'goof-', 'ball', ' ', '--', ' ',
///           'use', ' ', 'the', ' ', '-b', ' ', 'option!'
///         if break_on_hyphens is True, or in:
///           'Look,', ' ', 'goof-ball', ' ', '--', ' ',
///           'use', ' ', 'the', ' ', '-b', ' ', option!'
///         otherwise.
///         """
///         if self.break_on_hyphens is True:
///             chunks = self.wordsep_re.split(text)
///         else:
///             chunks = self.wordsep_simple_re.split(text)
///         chunks = [c for c in chunks if c]
///         return chunks
///
///     def _fix_sentence_endings(self, chunks):
///         """_fix_sentence_endings(chunks : [string])
///
///         Correct for sentence endings buried in 'chunks'.  Eg. when the
///         original text contains "... foo.\\nBar ...", munge_whitespace()
///         and split() will convert that to [..., "foo.", " ", "Bar", ...]
///         which has one too few spaces; this method simply changes the one
///         space to two.
///         """
///         i = 0
///         patsearch = self.sentence_end_re.search
///         while i < len(chunks)-1:
///             if chunks[i+1] == " " and patsearch(chunks[i]):
///                 chunks[i+1] = "  "
///                 i += 2
///             else:
///                 i += 1
///
///     def _handle_long_word(self, reversed_chunks, cur_line, cur_len, width):
///         """_handle_long_word(chunks : [string],
///                              cur_line : [string],
///                              cur_len : int, width : int)
///
///         Handle a chunk of text (most likely a word, not whitespace) that
///         is too long to fit in any line.
///         """
///         # Figure out when indent is larger than the specified width, and make
///         # sure at least one character is stripped off on every pass
///         if width < 1:
///             space_left = 1
///         else:
///             space_left = width - cur_len
///
///         # If we're allowed to break long words, then do so: put as much
///         # of the next chunk onto the current line as will fit.
///         if self.break_long_words:
///             end = space_left
///             chunk = reversed_chunks[-1]
///             if self.break_on_hyphens and len(chunk) > space_left:
///                 # break after last hyphen, but only if there are
///                 # non-hyphens before it
///                 hyphen = chunk.rfind('-', 0, space_left)
///                 if hyphen > 0 and any(c != '-' for c in chunk[:hyphen]):
///                     end = hyphen + 1
///             cur_line.append(chunk[:end])
///             reversed_chunks[-1] = chunk[end:]
///
///         # Otherwise, we have to preserve the long word intact.  Only add
///         # it to the current line if there's nothing already there --
///         # that minimizes how much we violate the width constraint.
///         elif not cur_line:
///             cur_line.append(reversed_chunks.pop())
///
///         # If we're not allowed to break long words, and there's already
///         # text on the current line, do nothing.  Next time through the
///         # main loop of _wrap_chunks(), we'll wind up here again, but
///         # cur_len will be zero, so the next line will be entirely
///         # devoted to the long word that we can't handle right now.
///
///     def _wrap_chunks(self, chunks):
///         """_wrap_chunks(chunks : [string]) -> [string]
///
///         Wrap a sequence of text chunks and return a list of lines of
///         length 'self.width' or less.  (If 'break_long_words' is false,
///         some lines may be longer than this.)  Chunks correspond roughly
///         to words and the whitespace between them: each chunk is
///         indivisible (modulo 'break_long_words'), but a line break can
///         come between any two chunks.  Chunks should not have internal
///         whitespace; ie. a chunk is either all whitespace or a "word".
///         Whitespace chunks will be removed from the beginning and end of
///         lines, but apart from that whitespace is preserved.
///         """
///         lines = []
///         if self.width <= 0:
///             raise ValueError("invalid width %r (must be > 0)" % self.width)
///         if self.max_lines is not None:
///             if self.max_lines > 1:
///                 indent = self.subsequent_indent
///             else:
///                 indent = self.initial_indent
///             if len(indent) + len(self.placeholder.lstrip()) > self.width:
///                 raise ValueError("placeholder too large for max width")
///
///         # Arrange in reverse order so items can be efficiently popped
///         # from a stack of chucks.
///         chunks.reverse()
///
///         while chunks:
///
///             # Start the list of chunks that will make up the current line.
///             # cur_len is just the length of all the chunks in cur_line.
///             cur_line = []
///             cur_len = 0
///
///             # Figure out which static string will prefix this line.
///             if lines:
///                 indent = self.subsequent_indent
///             else:
///                 indent = self.initial_indent
///
///             # Maximum width for this line.
///             width = self.width - len(indent)
///
///             # First chunk on line is whitespace -- drop it, unless this
///             # is the very beginning of the text (ie. no lines started yet).
///             if self.drop_whitespace and chunks[-1].strip() == '' and lines:
///                 del chunks[-1]
///
///             while chunks:
///                 l = len(chunks[-1])
///
///                 # Can at least squeeze this chunk onto the current line.
///                 if cur_len + l <= width:
///                     cur_line.append(chunks.pop())
///                     cur_len += l
///
///                 # Nope, this line is full.
///                 else:
///                     break
///
///             # The current line is full, and the next chunk is too big to
///             # fit on *any* line (not just this one).
///             if chunks and len(chunks[-1]) > width:
///                 self._handle_long_word(chunks, cur_line, cur_len, width)
///                 cur_len = sum(map(len, cur_line))
///
///             # If the last chunk on this line is all whitespace, drop it.
///             if self.drop_whitespace and cur_line and cur_line[-1].strip() == '':
///                 cur_len -= len(cur_line[-1])
///                 del cur_line[-1]
///
///             if cur_line:
///                 if (self.max_lines is None or
///                     len(lines) + 1 < self.max_lines or
///                     (not chunks or
///                      self.drop_whitespace and
///                      len(chunks) == 1 and
///                      not chunks[0].strip()) and cur_len <= width):
///                     # Convert current line back to a string and store it in
///                     # list of all lines (return value).
///                     lines.append(indent + ''.join(cur_line))
///                 else:
///                     while cur_line:
///                         if (cur_line[-1].strip() and
///                             cur_len + len(self.placeholder) <= width):
///                             cur_line.append(self.placeholder)
///                             lines.append(indent + ''.join(cur_line))
///                             break
///                         cur_len -= len(cur_line[-1])
///                         del cur_line[-1]
///                     else:
///                         if lines:
///                             prev_line = lines[-1].rstrip()
///                             if (len(prev_line) + len(self.placeholder) <=
///                                     self.width):
///                                 lines[-1] = prev_line + self.placeholder
///                                 break
///                         lines.append(indent + self.placeholder.lstrip())
///                     break
///
///         return lines
///
///     def _split_chunks(self, text):
///         text = self._munge_whitespace(text)
///         return self._split(text)
///
///     # -- Public interface ----------------------------------------------
///
///     def wrap(self, text):
///         """wrap(text : string) -> [string]
///
///         Reformat the single paragraph in 'text' so it fits in lines of
///         no more than 'self.width' columns, and return a list of wrapped
///         lines.  Tabs in 'text' are expanded with string.expandtabs(),
///         and all other whitespace characters (including newline) are
///         converted to space.
///         """
///         chunks = self._split_chunks(text)
///         if self.fix_sentence_endings:
///             self._fix_sentence_endings(chunks)
///         return self._wrap_chunks(chunks)
///
///     def fill(self, text):
///         """fill(text : string) -> string
///
///         Reformat the single paragraph in 'text' to fit in lines of no
///         more than 'self.width' columns, and return a new string
///         containing the entire wrapped paragraph.
///         """
///         return "\n".join(self.wrap(text))
/// ```
final class TextWrapper extends PythonClass {
  factory TextWrapper({
    Object? width = 70,
    Object? initial_indent = "",
    Object? subsequent_indent = "",
    Object? expand_tabs = true,
    Object? replace_whitespace = true,
    Object? fix_sentence_endings = false,
    Object? break_long_words = true,
    Object? drop_whitespace = true,
    Object? break_on_hyphens = true,
    Object? tabsize = 8,
    Object? max_lines,
    Object? placeholder = " [...]",
  }) =>
      PythonFfiDart.instance.importClass(
        "textwrap",
        "TextWrapper",
        TextWrapper.from,
        <Object?>[
          width,
          initial_indent,
          subsequent_indent,
          expand_tabs,
          replace_whitespace,
          fix_sentence_endings,
          break_long_words,
          drop_whitespace,
          break_on_hyphens,
          tabsize,
        ],
        <String, Object?>{
          "max_lines": max_lines,
          "placeholder": placeholder,
        },
      );

  TextWrapper.from(super.pythonClass) : super.from();

  /// ## fill
  ///
  /// ### python docstring
  ///
  /// fill(text : string) -> string
  ///
  /// Reformat the single paragraph in 'text' to fit in lines of no
  /// more than 'self.width' columns, and return a new string
  /// containing the entire wrapped paragraph.
  ///
  /// ### python source
  /// ```py
  /// def fill(self, text):
  ///         """fill(text : string) -> string
  ///
  ///         Reformat the single paragraph in 'text' to fit in lines of no
  ///         more than 'self.width' columns, and return a new string
  ///         containing the entire wrapped paragraph.
  ///         """
  ///         return "\n".join(self.wrap(text))
  /// ```
  Object? fill({
    required Object? text,
  }) =>
      getFunction("fill").call(
        <Object?>[
          text,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## wrap
  ///
  /// ### python docstring
  ///
  /// wrap(text : string) -> [string]
  ///
  /// Reformat the single paragraph in 'text' so it fits in lines of
  /// no more than 'self.width' columns, and return a list of wrapped
  /// lines.  Tabs in 'text' are expanded with string.expandtabs(),
  /// and all other whitespace characters (including newline) are
  /// converted to space.
  ///
  /// ### python source
  /// ```py
  /// def wrap(self, text):
  ///         """wrap(text : string) -> [string]
  ///
  ///         Reformat the single paragraph in 'text' so it fits in lines of
  ///         no more than 'self.width' columns, and return a list of wrapped
  ///         lines.  Tabs in 'text' are expanded with string.expandtabs(),
  ///         and all other whitespace characters (including newline) are
  ///         converted to space.
  ///         """
  ///         chunks = self._split_chunks(text)
  ///         if self.fix_sentence_endings:
  ///             self._fix_sentence_endings(chunks)
  ///         return self._wrap_chunks(chunks)
  /// ```
  Object? wrap({
    required Object? text,
  }) =>
      getFunction("wrap").call(
        <Object?>[
          text,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## sentence_end_re (getter)
  Object? get sentence_end_re => getAttribute("sentence_end_re");

  /// ## sentence_end_re (setter)
  set sentence_end_re(Object? sentence_end_re) =>
      setAttribute("sentence_end_re", sentence_end_re);

  /// ## wordsep_re (getter)
  Object? get wordsep_re => getAttribute("wordsep_re");

  /// ## wordsep_re (setter)
  set wordsep_re(Object? wordsep_re) => setAttribute("wordsep_re", wordsep_re);

  /// ## wordsep_simple_re (getter)
  Object? get wordsep_simple_re => getAttribute("wordsep_simple_re");

  /// ## wordsep_simple_re (setter)
  set wordsep_simple_re(Object? wordsep_simple_re) =>
      setAttribute("wordsep_simple_re", wordsep_simple_re);

  /// ## unicode_whitespace_trans (getter)
  Object? get unicode_whitespace_trans =>
      getAttribute("unicode_whitespace_trans");

  /// ## unicode_whitespace_trans (setter)
  set unicode_whitespace_trans(Object? unicode_whitespace_trans) =>
      setAttribute("unicode_whitespace_trans", unicode_whitespace_trans);

  /// ## width (getter)
  Object? get width => getAttribute("width");

  /// ## width (setter)
  set width(Object? width) => setAttribute("width", width);

  /// ## initial_indent (getter)
  Object? get initial_indent => getAttribute("initial_indent");

  /// ## initial_indent (setter)
  set initial_indent(Object? initial_indent) =>
      setAttribute("initial_indent", initial_indent);

  /// ## subsequent_indent (getter)
  Object? get subsequent_indent => getAttribute("subsequent_indent");

  /// ## subsequent_indent (setter)
  set subsequent_indent(Object? subsequent_indent) =>
      setAttribute("subsequent_indent", subsequent_indent);

  /// ## expand_tabs (getter)
  Object? get expand_tabs => getAttribute("expand_tabs");

  /// ## expand_tabs (setter)
  set expand_tabs(Object? expand_tabs) =>
      setAttribute("expand_tabs", expand_tabs);

  /// ## replace_whitespace (getter)
  Object? get replace_whitespace => getAttribute("replace_whitespace");

  /// ## replace_whitespace (setter)
  set replace_whitespace(Object? replace_whitespace) =>
      setAttribute("replace_whitespace", replace_whitespace);

  /// ## fix_sentence_endings (getter)
  Object? get fix_sentence_endings => getAttribute("fix_sentence_endings");

  /// ## fix_sentence_endings (setter)
  set fix_sentence_endings(Object? fix_sentence_endings) =>
      setAttribute("fix_sentence_endings", fix_sentence_endings);

  /// ## break_long_words (getter)
  Object? get break_long_words => getAttribute("break_long_words");

  /// ## break_long_words (setter)
  set break_long_words(Object? break_long_words) =>
      setAttribute("break_long_words", break_long_words);

  /// ## drop_whitespace (getter)
  Object? get drop_whitespace => getAttribute("drop_whitespace");

  /// ## drop_whitespace (setter)
  set drop_whitespace(Object? drop_whitespace) =>
      setAttribute("drop_whitespace", drop_whitespace);

  /// ## break_on_hyphens (getter)
  Object? get break_on_hyphens => getAttribute("break_on_hyphens");

  /// ## break_on_hyphens (setter)
  set break_on_hyphens(Object? break_on_hyphens) =>
      setAttribute("break_on_hyphens", break_on_hyphens);

  /// ## tabsize (getter)
  Object? get tabsize => getAttribute("tabsize");

  /// ## tabsize (setter)
  set tabsize(Object? tabsize) => setAttribute("tabsize", tabsize);

  /// ## max_lines (getter)
  Object? get max_lines => getAttribute("max_lines");

  /// ## max_lines (setter)
  set max_lines(Object? max_lines) => setAttribute("max_lines", max_lines);

  /// ## placeholder (getter)
  Object? get placeholder => getAttribute("placeholder");

  /// ## placeholder (setter)
  set placeholder(Object? placeholder) =>
      setAttribute("placeholder", placeholder);
}

/// ## CallableProxyType
final class CallableProxyType extends PythonClass {
  factory CallableProxyType() => PythonFfiDart.instance.importClass(
        "weakref",
        "CallableProxyType",
        CallableProxyType.from,
        <Object?>[],
      );

  CallableProxyType.from(super.pythonClass) : super.from();
}

/// ## KeyedRef
///
/// ### python docstring
///
/// Specialized reference that includes a key corresponding to the value.
///
/// This is used in the WeakValueDictionary to avoid having to create
/// a function object for each key stored in the mapping.  A shared
/// callback object can use the 'key' attribute of a KeyedRef instead
/// of getting a reference to the key from an enclosing scope.
///
/// ### python source
/// ```py
/// class KeyedRef(ref):
///     """Specialized reference that includes a key corresponding to the value.
///
///     This is used in the WeakValueDictionary to avoid having to create
///     a function object for each key stored in the mapping.  A shared
///     callback object can use the 'key' attribute of a KeyedRef instead
///     of getting a reference to the key from an enclosing scope.
///
///     """
///
///     __slots__ = "key",
///
///     def __new__(type, ob, callback, key):
///         self = ref.__new__(type, ob, callback)
///         self.key = key
///         return self
///
///     def __init__(self, ob, callback, key):
///         super().__init__(ob, callback)
/// ```
final class KeyedRef extends PythonClass {
  factory KeyedRef({
    required Object? ob,
    required Object? callback,
    required Object? key,
  }) =>
      PythonFfiDart.instance.importClass(
        "weakref",
        "KeyedRef",
        KeyedRef.from,
        <Object?>[
          ob,
          callback,
          key,
        ],
        <String, Object?>{},
      );

  KeyedRef.from(super.pythonClass) : super.from();

  /// ## key (getter)
  Object? get key => getAttribute("key");

  /// ## key (setter)
  set key(Object? key) => setAttribute("key", key);
}

/// ## ProxyType
final class ProxyType extends PythonClass {
  factory ProxyType() => PythonFfiDart.instance.importClass(
        "weakref",
        "ProxyType",
        ProxyType.from,
        <Object?>[],
      );

  ProxyType.from(super.pythonClass) : super.from();
}

/// ## ReferenceType
final class ReferenceType extends PythonClass {
  factory ReferenceType() => PythonFfiDart.instance.importClass(
        "weakref",
        "ReferenceType",
        ReferenceType.from,
        <Object?>[],
      );

  ReferenceType.from(super.pythonClass) : super.from();
}

/// ## WeakKeyDictionary
///
/// ### python docstring
///
/// Mapping class that references keys weakly.
///
/// Entries in the dictionary will be discarded when there is no
/// longer a strong reference to the key. This can be used to
/// associate additional data with an object owned by other parts of
/// an application without adding attributes to those objects. This
/// can be especially useful with objects that override attribute
/// accesses.
///
/// ### python source
/// ```py
/// class WeakKeyDictionary(_collections_abc.MutableMapping):
///     """ Mapping class that references keys weakly.
///
///     Entries in the dictionary will be discarded when there is no
///     longer a strong reference to the key. This can be used to
///     associate additional data with an object owned by other parts of
///     an application without adding attributes to those objects. This
///     can be especially useful with objects that override attribute
///     accesses.
///     """
///
///     def __init__(self, dict=None):
///         self.data = {}
///         def remove(k, selfref=ref(self)):
///             self = selfref()
///             if self is not None:
///                 if self._iterating:
///                     self._pending_removals.append(k)
///                 else:
///                     try:
///                         del self.data[k]
///                     except KeyError:
///                         pass
///         self._remove = remove
///         # A list of dead weakrefs (keys to be removed)
///         self._pending_removals = []
///         self._iterating = set()
///         self._dirty_len = False
///         if dict is not None:
///             self.update(dict)
///
///     def _commit_removals(self):
///         # NOTE: We don't need to call this method before mutating the dict,
///         # because a dead weakref never compares equal to a live weakref,
///         # even if they happened to refer to equal objects.
///         # However, it means keys may already have been removed.
///         pop = self._pending_removals.pop
///         d = self.data
///         while True:
///             try:
///                 key = pop()
///             except IndexError:
///                 return
///
///             try:
///                 del d[key]
///             except KeyError:
///                 pass
///
///     def _scrub_removals(self):
///         d = self.data
///         self._pending_removals = [k for k in self._pending_removals if k in d]
///         self._dirty_len = False
///
///     def __delitem__(self, key):
///         self._dirty_len = True
///         del self.data[ref(key)]
///
///     def __getitem__(self, key):
///         return self.data[ref(key)]
///
///     def __len__(self):
///         if self._dirty_len and self._pending_removals:
///             # self._pending_removals may still contain keys which were
///             # explicitly removed, we have to scrub them (see issue #21173).
///             self._scrub_removals()
///         return len(self.data) - len(self._pending_removals)
///
///     def __repr__(self):
///         return "<%s at %#x>" % (self.__class__.__name__, id(self))
///
///     def __setitem__(self, key, value):
///         self.data[ref(key, self._remove)] = value
///
///     def copy(self):
///         new = WeakKeyDictionary()
///         with _IterationGuard(self):
///             for key, value in self.data.items():
///                 o = key()
///                 if o is not None:
///                     new[o] = value
///         return new
///
///     __copy__ = copy
///
///     def __deepcopy__(self, memo):
///         from copy import deepcopy
///         new = self.__class__()
///         with _IterationGuard(self):
///             for key, value in self.data.items():
///                 o = key()
///                 if o is not None:
///                     new[o] = deepcopy(value, memo)
///         return new
///
///     def get(self, key, default=None):
///         return self.data.get(ref(key),default)
///
///     def __contains__(self, key):
///         try:
///             wr = ref(key)
///         except TypeError:
///             return False
///         return wr in self.data
///
///     def items(self):
///         with _IterationGuard(self):
///             for wr, value in self.data.items():
///                 key = wr()
///                 if key is not None:
///                     yield key, value
///
///     def keys(self):
///         with _IterationGuard(self):
///             for wr in self.data:
///                 obj = wr()
///                 if obj is not None:
///                     yield obj
///
///     __iter__ = keys
///
///     def values(self):
///         with _IterationGuard(self):
///             for wr, value in self.data.items():
///                 if wr() is not None:
///                     yield value
///
///     def keyrefs(self):
///         """Return a list of weak references to the keys.
///
///         The references are not guaranteed to be 'live' at the time
///         they are used, so the result of calling the references needs
///         to be checked before being used.  This can be used to avoid
///         creating references that will cause the garbage collector to
///         keep the keys around longer than needed.
///
///         """
///         return list(self.data)
///
///     def popitem(self):
///         self._dirty_len = True
///         while True:
///             key, value = self.data.popitem()
///             o = key()
///             if o is not None:
///                 return o, value
///
///     def pop(self, key, *args):
///         self._dirty_len = True
///         return self.data.pop(ref(key), *args)
///
///     def setdefault(self, key, default=None):
///         return self.data.setdefault(ref(key, self._remove),default)
///
///     def update(self, dict=None, /, **kwargs):
///         d = self.data
///         if dict is not None:
///             if not hasattr(dict, "items"):
///                 dict = type({})(dict)
///             for key, value in dict.items():
///                 d[ref(key, self._remove)] = value
///         if len(kwargs):
///             self.update(kwargs)
///
///     def __ior__(self, other):
///         self.update(other)
///         return self
///
///     def __or__(self, other):
///         if isinstance(other, _collections_abc.Mapping):
///             c = self.copy()
///             c.update(other)
///             return c
///         return NotImplemented
///
///     def __ror__(self, other):
///         if isinstance(other, _collections_abc.Mapping):
///             c = self.__class__()
///             c.update(other)
///             c.update(self)
///             return c
///         return NotImplemented
/// ```
final class WeakKeyDictionary extends PythonClass {
  factory WeakKeyDictionary({
    Object? dict,
  }) =>
      PythonFfiDart.instance.importClass(
        "weakref",
        "WeakKeyDictionary",
        WeakKeyDictionary.from,
        <Object?>[
          dict,
        ],
        <String, Object?>{},
      );

  WeakKeyDictionary.from(super.pythonClass) : super.from();

  /// ## clear
  ///
  /// ### python docstring
  ///
  /// D.clear() -> None.  Remove all items from D.
  Object? clear() => getFunction("clear").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## copy
  ///
  /// ### python source
  /// ```py
  /// def copy(self):
  ///         new = WeakKeyDictionary()
  ///         with _IterationGuard(self):
  ///             for key, value in self.data.items():
  ///                 o = key()
  ///                 if o is not None:
  ///                     new[o] = value
  ///         return new
  /// ```
  Object? copy() => getFunction("copy").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## get
  ///
  /// ### python docstring
  ///
  /// D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.
  ///
  /// ### python source
  /// ```py
  /// def get(self, key, default=None):
  ///         return self.data.get(ref(key),default)
  /// ```
  Object? $get({
    required Object? key,
    Object? $default,
  }) =>
      getFunction("get").call(
        <Object?>[
          key,
          $default,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## items
  ///
  /// ### python docstring
  ///
  /// D.items() -> a set-like object providing a view on D's items
  ///
  /// ### python source
  /// ```py
  /// def items(self):
  ///         with _IterationGuard(self):
  ///             for wr, value in self.data.items():
  ///                 key = wr()
  ///                 if key is not None:
  ///                     yield key, value
  /// ```
  Object? items() => getFunction("items").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## keyrefs
  ///
  /// ### python docstring
  ///
  /// Return a list of weak references to the keys.
  ///
  /// The references are not guaranteed to be 'live' at the time
  /// they are used, so the result of calling the references needs
  /// to be checked before being used.  This can be used to avoid
  /// creating references that will cause the garbage collector to
  /// keep the keys around longer than needed.
  ///
  /// ### python source
  /// ```py
  /// def keyrefs(self):
  ///         """Return a list of weak references to the keys.
  ///
  ///         The references are not guaranteed to be 'live' at the time
  ///         they are used, so the result of calling the references needs
  ///         to be checked before being used.  This can be used to avoid
  ///         creating references that will cause the garbage collector to
  ///         keep the keys around longer than needed.
  ///
  ///         """
  ///         return list(self.data)
  /// ```
  Object? keyrefs() => getFunction("keyrefs").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## keys
  ///
  /// ### python docstring
  ///
  /// D.keys() -> a set-like object providing a view on D's keys
  ///
  /// ### python source
  /// ```py
  /// def keys(self):
  ///         with _IterationGuard(self):
  ///             for wr in self.data:
  ///                 obj = wr()
  ///                 if obj is not None:
  ///                     yield obj
  /// ```
  Object? keys() => getFunction("keys").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## pop
  ///
  /// ### python docstring
  ///
  /// D.pop(k[,d]) -> v, remove specified key and return the corresponding value.
  /// If key is not found, d is returned if given, otherwise KeyError is raised.
  ///
  /// ### python source
  /// ```py
  /// def pop(self, key, *args):
  ///         self._dirty_len = True
  ///         return self.data.pop(ref(key), *args)
  /// ```
  Object? pop({
    List<Object?> args = const <Object?>[],
    required Object? key,
  }) =>
      getFunction("pop").call(
        <Object?>[
          key,
          ...args,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## popitem
  ///
  /// ### python docstring
  ///
  /// D.popitem() -> (k, v), remove and return some (key, value) pair
  /// as a 2-tuple; but raise KeyError if D is empty.
  ///
  /// ### python source
  /// ```py
  /// def popitem(self):
  ///         self._dirty_len = True
  ///         while True:
  ///             key, value = self.data.popitem()
  ///             o = key()
  ///             if o is not None:
  ///                 return o, value
  /// ```
  Object? popitem() => getFunction("popitem").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## setdefault
  ///
  /// ### python docstring
  ///
  /// D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D
  ///
  /// ### python source
  /// ```py
  /// def setdefault(self, key, default=None):
  ///         return self.data.setdefault(ref(key, self._remove),default)
  /// ```
  Object? setdefault({
    required Object? key,
    Object? $default,
  }) =>
      getFunction("setdefault").call(
        <Object?>[
          key,
          $default,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## update
  ///
  /// ### python docstring
  ///
  /// D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.
  /// If E present and has a .keys() method, does:     for k in E: D[k] = E[k]
  /// If E present and lacks .keys() method, does:     for (k, v) in E: D[k] = v
  /// In either case, this is followed by: for k, v in F.items(): D[k] = v
  ///
  /// ### python source
  /// ```py
  /// def update(self, dict=None, /, **kwargs):
  ///         d = self.data
  ///         if dict is not None:
  ///             if not hasattr(dict, "items"):
  ///                 dict = type({})(dict)
  ///             for key, value in dict.items():
  ///                 d[ref(key, self._remove)] = value
  ///         if len(kwargs):
  ///             self.update(kwargs)
  /// ```
  Object? update(
    Object? dict, {
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("update").call(
        <Object?>[
          dict,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## values
  ///
  /// ### python docstring
  ///
  /// D.values() -> an object providing a view on D's values
  ///
  /// ### python source
  /// ```py
  /// def values(self):
  ///         with _IterationGuard(self):
  ///             for wr, value in self.data.items():
  ///                 if wr() is not None:
  ///                     yield value
  /// ```
  Object? values() => getFunction("values").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## data (getter)
  Object? get data => getAttribute("data");

  /// ## data (setter)
  set data(Object? data) => setAttribute("data", data);
}

/// ## WeakMethod
///
/// ### python docstring
///
/// A custom `weakref.ref` subclass which simulates a weak reference to
/// a bound method, working around the lifetime problem of bound methods.
///
/// ### python source
/// ```py
/// class WeakMethod(ref):
///     """
///     A custom `weakref.ref` subclass which simulates a weak reference to
///     a bound method, working around the lifetime problem of bound methods.
///     """
///
///     __slots__ = "_func_ref", "_meth_type", "_alive", "__weakref__"
///
///     def __new__(cls, meth, callback=None):
///         try:
///             obj = meth.__self__
///             func = meth.__func__
///         except AttributeError:
///             raise TypeError("argument should be a bound method, not {}"
///                             .format(type(meth))) from None
///         def _cb(arg):
///             # The self-weakref trick is needed to avoid creating a reference
///             # cycle.
///             self = self_wr()
///             if self._alive:
///                 self._alive = False
///                 if callback is not None:
///                     callback(self)
///         self = ref.__new__(cls, obj, _cb)
///         self._func_ref = ref(func, _cb)
///         self._meth_type = type(meth)
///         self._alive = True
///         self_wr = ref(self)
///         return self
///
///     def __call__(self):
///         obj = super().__call__()
///         func = self._func_ref()
///         if obj is None or func is None:
///             return None
///         return self._meth_type(func, obj)
///
///     def __eq__(self, other):
///         if isinstance(other, WeakMethod):
///             if not self._alive or not other._alive:
///                 return self is other
///             return ref.__eq__(self, other) and self._func_ref == other._func_ref
///         return NotImplemented
///
///     def __ne__(self, other):
///         if isinstance(other, WeakMethod):
///             if not self._alive or not other._alive:
///                 return self is not other
///             return ref.__ne__(self, other) or self._func_ref != other._func_ref
///         return NotImplemented
///
///     __hash__ = ref.__hash__
/// ```
final class WeakMethod extends PythonClass {
  factory WeakMethod() => PythonFfiDart.instance.importClass(
        "weakref",
        "WeakMethod",
        WeakMethod.from,
        <Object?>[],
      );

  WeakMethod.from(super.pythonClass) : super.from();
}

/// ## WeakValueDictionary
///
/// ### python docstring
///
/// Mapping class that references values weakly.
///
/// Entries in the dictionary will be discarded when no strong
/// reference to the value exists anymore
///
/// ### python source
/// ```py
/// class WeakValueDictionary(_collections_abc.MutableMapping):
///     """Mapping class that references values weakly.
///
///     Entries in the dictionary will be discarded when no strong
///     reference to the value exists anymore
///     """
///     # We inherit the constructor without worrying about the input
///     # dictionary; since it uses our .update() method, we get the right
///     # checks (if the other dictionary is a WeakValueDictionary,
///     # objects are unwrapped on the way out, and we always wrap on the
///     # way in).
///
///     def __init__(self, other=(), /, **kw):
///         def remove(wr, selfref=ref(self), _atomic_removal=_remove_dead_weakref):
///             self = selfref()
///             if self is not None:
///                 if self._iterating:
///                     self._pending_removals.append(wr.key)
///                 else:
///                     # Atomic removal is necessary since this function
///                     # can be called asynchronously by the GC
///                     _atomic_removal(self.data, wr.key)
///         self._remove = remove
///         # A list of keys to be removed
///         self._pending_removals = []
///         self._iterating = set()
///         self.data = {}
///         self.update(other, **kw)
///
///     def _commit_removals(self, _atomic_removal=_remove_dead_weakref):
///         pop = self._pending_removals.pop
///         d = self.data
///         # We shouldn't encounter any KeyError, because this method should
///         # always be called *before* mutating the dict.
///         while True:
///             try:
///                 key = pop()
///             except IndexError:
///                 return
///             _atomic_removal(d, key)
///
///     def __getitem__(self, key):
///         if self._pending_removals:
///             self._commit_removals()
///         o = self.data[key]()
///         if o is None:
///             raise KeyError(key)
///         else:
///             return o
///
///     def __delitem__(self, key):
///         if self._pending_removals:
///             self._commit_removals()
///         del self.data[key]
///
///     def __len__(self):
///         if self._pending_removals:
///             self._commit_removals()
///         return len(self.data)
///
///     def __contains__(self, key):
///         if self._pending_removals:
///             self._commit_removals()
///         try:
///             o = self.data[key]()
///         except KeyError:
///             return False
///         return o is not None
///
///     def __repr__(self):
///         return "<%s at %#x>" % (self.__class__.__name__, id(self))
///
///     def __setitem__(self, key, value):
///         if self._pending_removals:
///             self._commit_removals()
///         self.data[key] = KeyedRef(value, self._remove, key)
///
///     def copy(self):
///         if self._pending_removals:
///             self._commit_removals()
///         new = WeakValueDictionary()
///         with _IterationGuard(self):
///             for key, wr in self.data.items():
///                 o = wr()
///                 if o is not None:
///                     new[key] = o
///         return new
///
///     __copy__ = copy
///
///     def __deepcopy__(self, memo):
///         from copy import deepcopy
///         if self._pending_removals:
///             self._commit_removals()
///         new = self.__class__()
///         with _IterationGuard(self):
///             for key, wr in self.data.items():
///                 o = wr()
///                 if o is not None:
///                     new[deepcopy(key, memo)] = o
///         return new
///
///     def get(self, key, default=None):
///         if self._pending_removals:
///             self._commit_removals()
///         try:
///             wr = self.data[key]
///         except KeyError:
///             return default
///         else:
///             o = wr()
///             if o is None:
///                 # This should only happen
///                 return default
///             else:
///                 return o
///
///     def items(self):
///         if self._pending_removals:
///             self._commit_removals()
///         with _IterationGuard(self):
///             for k, wr in self.data.items():
///                 v = wr()
///                 if v is not None:
///                     yield k, v
///
///     def keys(self):
///         if self._pending_removals:
///             self._commit_removals()
///         with _IterationGuard(self):
///             for k, wr in self.data.items():
///                 if wr() is not None:
///                     yield k
///
///     __iter__ = keys
///
///     def itervaluerefs(self):
///         """Return an iterator that yields the weak references to the values.
///
///         The references are not guaranteed to be 'live' at the time
///         they are used, so the result of calling the references needs
///         to be checked before being used.  This can be used to avoid
///         creating references that will cause the garbage collector to
///         keep the values around longer than needed.
///
///         """
///         if self._pending_removals:
///             self._commit_removals()
///         with _IterationGuard(self):
///             yield from self.data.values()
///
///     def values(self):
///         if self._pending_removals:
///             self._commit_removals()
///         with _IterationGuard(self):
///             for wr in self.data.values():
///                 obj = wr()
///                 if obj is not None:
///                     yield obj
///
///     def popitem(self):
///         if self._pending_removals:
///             self._commit_removals()
///         while True:
///             key, wr = self.data.popitem()
///             o = wr()
///             if o is not None:
///                 return key, o
///
///     def pop(self, key, *args):
///         if self._pending_removals:
///             self._commit_removals()
///         try:
///             o = self.data.pop(key)()
///         except KeyError:
///             o = None
///         if o is None:
///             if args:
///                 return args[0]
///             else:
///                 raise KeyError(key)
///         else:
///             return o
///
///     def setdefault(self, key, default=None):
///         try:
///             o = self.data[key]()
///         except KeyError:
///             o = None
///         if o is None:
///             if self._pending_removals:
///                 self._commit_removals()
///             self.data[key] = KeyedRef(default, self._remove, key)
///             return default
///         else:
///             return o
///
///     def update(self, other=None, /, **kwargs):
///         if self._pending_removals:
///             self._commit_removals()
///         d = self.data
///         if other is not None:
///             if not hasattr(other, "items"):
///                 other = dict(other)
///             for key, o in other.items():
///                 d[key] = KeyedRef(o, self._remove, key)
///         for key, o in kwargs.items():
///             d[key] = KeyedRef(o, self._remove, key)
///
///     def valuerefs(self):
///         """Return a list of weak references to the values.
///
///         The references are not guaranteed to be 'live' at the time
///         they are used, so the result of calling the references needs
///         to be checked before being used.  This can be used to avoid
///         creating references that will cause the garbage collector to
///         keep the values around longer than needed.
///
///         """
///         if self._pending_removals:
///             self._commit_removals()
///         return list(self.data.values())
///
///     def __ior__(self, other):
///         self.update(other)
///         return self
///
///     def __or__(self, other):
///         if isinstance(other, _collections_abc.Mapping):
///             c = self.copy()
///             c.update(other)
///             return c
///         return NotImplemented
///
///     def __ror__(self, other):
///         if isinstance(other, _collections_abc.Mapping):
///             c = self.__class__()
///             c.update(other)
///             c.update(self)
///             return c
///         return NotImplemented
/// ```
final class WeakValueDictionary extends PythonClass {
  factory WeakValueDictionary(
    Object? other, {
    Map<String, Object?> kw = const <String, Object?>{},
  }) =>
      PythonFfiDart.instance.importClass(
        "weakref",
        "WeakValueDictionary",
        WeakValueDictionary.from,
        <Object?>[
          other,
        ],
        <String, Object?>{
          ...kw,
        },
      );

  WeakValueDictionary.from(super.pythonClass) : super.from();

  /// ## clear
  ///
  /// ### python docstring
  ///
  /// D.clear() -> None.  Remove all items from D.
  Object? clear() => getFunction("clear").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## copy
  ///
  /// ### python source
  /// ```py
  /// def copy(self):
  ///         if self._pending_removals:
  ///             self._commit_removals()
  ///         new = WeakValueDictionary()
  ///         with _IterationGuard(self):
  ///             for key, wr in self.data.items():
  ///                 o = wr()
  ///                 if o is not None:
  ///                     new[key] = o
  ///         return new
  /// ```
  Object? copy() => getFunction("copy").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## get
  ///
  /// ### python docstring
  ///
  /// D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.
  ///
  /// ### python source
  /// ```py
  /// def get(self, key, default=None):
  ///         if self._pending_removals:
  ///             self._commit_removals()
  ///         try:
  ///             wr = self.data[key]
  ///         except KeyError:
  ///             return default
  ///         else:
  ///             o = wr()
  ///             if o is None:
  ///                 # This should only happen
  ///                 return default
  ///             else:
  ///                 return o
  /// ```
  Object? $get({
    required Object? key,
    Object? $default,
  }) =>
      getFunction("get").call(
        <Object?>[
          key,
          $default,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## items
  ///
  /// ### python docstring
  ///
  /// D.items() -> a set-like object providing a view on D's items
  ///
  /// ### python source
  /// ```py
  /// def items(self):
  ///         if self._pending_removals:
  ///             self._commit_removals()
  ///         with _IterationGuard(self):
  ///             for k, wr in self.data.items():
  ///                 v = wr()
  ///                 if v is not None:
  ///                     yield k, v
  /// ```
  Object? items() => getFunction("items").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## itervaluerefs
  ///
  /// ### python docstring
  ///
  /// Return an iterator that yields the weak references to the values.
  ///
  /// The references are not guaranteed to be 'live' at the time
  /// they are used, so the result of calling the references needs
  /// to be checked before being used.  This can be used to avoid
  /// creating references that will cause the garbage collector to
  /// keep the values around longer than needed.
  ///
  /// ### python source
  /// ```py
  /// def itervaluerefs(self):
  ///         """Return an iterator that yields the weak references to the values.
  ///
  ///         The references are not guaranteed to be 'live' at the time
  ///         they are used, so the result of calling the references needs
  ///         to be checked before being used.  This can be used to avoid
  ///         creating references that will cause the garbage collector to
  ///         keep the values around longer than needed.
  ///
  ///         """
  ///         if self._pending_removals:
  ///             self._commit_removals()
  ///         with _IterationGuard(self):
  ///             yield from self.data.values()
  /// ```
  Object? itervaluerefs() => getFunction("itervaluerefs").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## keys
  ///
  /// ### python docstring
  ///
  /// D.keys() -> a set-like object providing a view on D's keys
  ///
  /// ### python source
  /// ```py
  /// def keys(self):
  ///         if self._pending_removals:
  ///             self._commit_removals()
  ///         with _IterationGuard(self):
  ///             for k, wr in self.data.items():
  ///                 if wr() is not None:
  ///                     yield k
  /// ```
  Object? keys() => getFunction("keys").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## pop
  ///
  /// ### python docstring
  ///
  /// D.pop(k[,d]) -> v, remove specified key and return the corresponding value.
  /// If key is not found, d is returned if given, otherwise KeyError is raised.
  ///
  /// ### python source
  /// ```py
  /// def pop(self, key, *args):
  ///         if self._pending_removals:
  ///             self._commit_removals()
  ///         try:
  ///             o = self.data.pop(key)()
  ///         except KeyError:
  ///             o = None
  ///         if o is None:
  ///             if args:
  ///                 return args[0]
  ///             else:
  ///                 raise KeyError(key)
  ///         else:
  ///             return o
  /// ```
  Object? pop({
    List<Object?> args = const <Object?>[],
    required Object? key,
  }) =>
      getFunction("pop").call(
        <Object?>[
          key,
          ...args,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## popitem
  ///
  /// ### python docstring
  ///
  /// D.popitem() -> (k, v), remove and return some (key, value) pair
  /// as a 2-tuple; but raise KeyError if D is empty.
  ///
  /// ### python source
  /// ```py
  /// def popitem(self):
  ///         if self._pending_removals:
  ///             self._commit_removals()
  ///         while True:
  ///             key, wr = self.data.popitem()
  ///             o = wr()
  ///             if o is not None:
  ///                 return key, o
  /// ```
  Object? popitem() => getFunction("popitem").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## setdefault
  ///
  /// ### python docstring
  ///
  /// D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D
  ///
  /// ### python source
  /// ```py
  /// def setdefault(self, key, default=None):
  ///         try:
  ///             o = self.data[key]()
  ///         except KeyError:
  ///             o = None
  ///         if o is None:
  ///             if self._pending_removals:
  ///                 self._commit_removals()
  ///             self.data[key] = KeyedRef(default, self._remove, key)
  ///             return default
  ///         else:
  ///             return o
  /// ```
  Object? setdefault({
    required Object? key,
    Object? $default,
  }) =>
      getFunction("setdefault").call(
        <Object?>[
          key,
          $default,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## update
  ///
  /// ### python docstring
  ///
  /// D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.
  /// If E present and has a .keys() method, does:     for k in E: D[k] = E[k]
  /// If E present and lacks .keys() method, does:     for (k, v) in E: D[k] = v
  /// In either case, this is followed by: for k, v in F.items(): D[k] = v
  ///
  /// ### python source
  /// ```py
  /// def update(self, other=None, /, **kwargs):
  ///         if self._pending_removals:
  ///             self._commit_removals()
  ///         d = self.data
  ///         if other is not None:
  ///             if not hasattr(other, "items"):
  ///                 other = dict(other)
  ///             for key, o in other.items():
  ///                 d[key] = KeyedRef(o, self._remove, key)
  ///         for key, o in kwargs.items():
  ///             d[key] = KeyedRef(o, self._remove, key)
  /// ```
  Object? update(
    Object? other, {
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("update").call(
        <Object?>[
          other,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## valuerefs
  ///
  /// ### python docstring
  ///
  /// Return a list of weak references to the values.
  ///
  /// The references are not guaranteed to be 'live' at the time
  /// they are used, so the result of calling the references needs
  /// to be checked before being used.  This can be used to avoid
  /// creating references that will cause the garbage collector to
  /// keep the values around longer than needed.
  ///
  /// ### python source
  /// ```py
  /// def valuerefs(self):
  ///         """Return a list of weak references to the values.
  ///
  ///         The references are not guaranteed to be 'live' at the time
  ///         they are used, so the result of calling the references needs
  ///         to be checked before being used.  This can be used to avoid
  ///         creating references that will cause the garbage collector to
  ///         keep the values around longer than needed.
  ///
  ///         """
  ///         if self._pending_removals:
  ///             self._commit_removals()
  ///         return list(self.data.values())
  /// ```
  Object? valuerefs() => getFunction("valuerefs").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## values
  ///
  /// ### python docstring
  ///
  /// D.values() -> an object providing a view on D's values
  ///
  /// ### python source
  /// ```py
  /// def values(self):
  ///         if self._pending_removals:
  ///             self._commit_removals()
  ///         with _IterationGuard(self):
  ///             for wr in self.data.values():
  ///                 obj = wr()
  ///                 if obj is not None:
  ///                     yield obj
  /// ```
  Object? values() => getFunction("values").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## data (getter)
  Object? get data => getAttribute("data");

  /// ## data (setter)
  set data(Object? data) => setAttribute("data", data);
}

/// ## finalize
///
/// ### python docstring
///
/// Class for finalization of weakrefable objects
///
/// finalize(obj, func, *args, **kwargs) returns a callable finalizer
/// object which will be called when obj is garbage collected. The
/// first time the finalizer is called it evaluates func(*arg, **kwargs)
/// and returns the result. After this the finalizer is dead, and
/// calling it just returns None.
///
/// When the program exits any remaining finalizers for which the
/// atexit attribute is true will be run in reverse order of creation.
/// By default atexit is true.
///
/// ### python source
/// ```py
/// class finalize:
///     """Class for finalization of weakrefable objects
///
///     finalize(obj, func, *args, **kwargs) returns a callable finalizer
///     object which will be called when obj is garbage collected. The
///     first time the finalizer is called it evaluates func(*arg, **kwargs)
///     and returns the result. After this the finalizer is dead, and
///     calling it just returns None.
///
///     When the program exits any remaining finalizers for which the
///     atexit attribute is true will be run in reverse order of creation.
///     By default atexit is true.
///     """
///
///     # Finalizer objects don't have any state of their own.  They are
///     # just used as keys to lookup _Info objects in the registry.  This
///     # ensures that they cannot be part of a ref-cycle.
///
///     __slots__ = ()
///     _registry = {}
///     _shutdown = False
///     _index_iter = itertools.count()
///     _dirty = False
///     _registered_with_atexit = False
///
///     class _Info:
///         __slots__ = ("weakref", "func", "args", "kwargs", "atexit", "index")
///
///     def __init__(self, obj, func, /, *args, **kwargs):
///         if not self._registered_with_atexit:
///             # We may register the exit function more than once because
///             # of a thread race, but that is harmless
///             import atexit
///             atexit.register(self._exitfunc)
///             finalize._registered_with_atexit = True
///         info = self._Info()
///         info.weakref = ref(obj, self)
///         info.func = func
///         info.args = args
///         info.kwargs = kwargs or None
///         info.atexit = True
///         info.index = next(self._index_iter)
///         self._registry[self] = info
///         finalize._dirty = True
///
///     def __call__(self, _=None):
///         """If alive then mark as dead and return func(*args, **kwargs);
///         otherwise return None"""
///         info = self._registry.pop(self, None)
///         if info and not self._shutdown:
///             return info.func(*info.args, **(info.kwargs or {}))
///
///     def detach(self):
///         """If alive then mark as dead and return (obj, func, args, kwargs);
///         otherwise return None"""
///         info = self._registry.get(self)
///         obj = info and info.weakref()
///         if obj is not None and self._registry.pop(self, None):
///             return (obj, info.func, info.args, info.kwargs or {})
///
///     def peek(self):
///         """If alive then return (obj, func, args, kwargs);
///         otherwise return None"""
///         info = self._registry.get(self)
///         obj = info and info.weakref()
///         if obj is not None:
///             return (obj, info.func, info.args, info.kwargs or {})
///
///     @property
///     def alive(self):
///         """Whether finalizer is alive"""
///         return self in self._registry
///
///     @property
///     def atexit(self):
///         """Whether finalizer should be called at exit"""
///         info = self._registry.get(self)
///         return bool(info) and info.atexit
///
///     @atexit.setter
///     def atexit(self, value):
///         info = self._registry.get(self)
///         if info:
///             info.atexit = bool(value)
///
///     def __repr__(self):
///         info = self._registry.get(self)
///         obj = info and info.weakref()
///         if obj is None:
///             return '<%s object at %#x; dead>' % (type(self).__name__, id(self))
///         else:
///             return '<%s object at %#x; for %r at %#x>' % \
///                 (type(self).__name__, id(self), type(obj).__name__, id(obj))
///
///     @classmethod
///     def _select_for_exit(cls):
///         # Return live finalizers marked for exit, oldest first
///         L = [(f,i) for (f,i) in cls._registry.items() if i.atexit]
///         L.sort(key=lambda item:item[1].index)
///         return [f for (f,i) in L]
///
///     @classmethod
///     def _exitfunc(cls):
///         # At shutdown invoke finalizers for which atexit is true.
///         # This is called once all other non-daemonic threads have been
///         # joined.
///         reenable_gc = False
///         try:
///             if cls._registry:
///                 import gc
///                 if gc.isenabled():
///                     reenable_gc = True
///                     gc.disable()
///                 pending = None
///                 while True:
///                     if pending is None or finalize._dirty:
///                         pending = cls._select_for_exit()
///                         finalize._dirty = False
///                     if not pending:
///                         break
///                     f = pending.pop()
///                     try:
///                         # gc is disabled, so (assuming no daemonic
///                         # threads) the following is the only line in
///                         # this function which might trigger creation
///                         # of a new finalizer
///                         f()
///                     except Exception:
///                         sys.excepthook(*sys.exc_info())
///                     assert f not in cls._registry
///         finally:
///             # prevent any more finalizers from executing during shutdown
///             finalize._shutdown = True
///             if reenable_gc:
///                 gc.enable()
/// ```
final class finalize extends PythonClass {
  factory finalize(
    Object? obj,
    Object? func, {
    List<Object?> args = const <Object?>[],
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      PythonFfiDart.instance.importClass(
        "weakref",
        "finalize",
        finalize.from,
        <Object?>[
          obj,
          func,
          ...args,
        ],
        <String, Object?>{
          ...kwargs,
        },
      );

  finalize.from(super.pythonClass) : super.from();

  /// ## detach
  ///
  /// ### python docstring
  ///
  /// If alive then mark as dead and return (obj, func, args, kwargs);
  /// otherwise return None
  ///
  /// ### python source
  /// ```py
  /// def detach(self):
  ///         """If alive then mark as dead and return (obj, func, args, kwargs);
  ///         otherwise return None"""
  ///         info = self._registry.get(self)
  ///         obj = info and info.weakref()
  ///         if obj is not None and self._registry.pop(self, None):
  ///             return (obj, info.func, info.args, info.kwargs or {})
  /// ```
  Object? detach() => getFunction("detach").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## peek
  ///
  /// ### python docstring
  ///
  /// If alive then return (obj, func, args, kwargs);
  /// otherwise return None
  ///
  /// ### python source
  /// ```py
  /// def peek(self):
  ///         """If alive then return (obj, func, args, kwargs);
  ///         otherwise return None"""
  ///         info = self._registry.get(self)
  ///         obj = info and info.weakref()
  ///         if obj is not None:
  ///             return (obj, info.func, info.args, info.kwargs or {})
  /// ```
  Object? peek() => getFunction("peek").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## alive (getter)
  ///
  /// ### python docstring
  ///
  /// Whether finalizer is alive
  Object? get alive => getAttribute("alive");

  /// ## alive (setter)
  ///
  /// ### python docstring
  ///
  /// Whether finalizer is alive
  set alive(Object? alive) => setAttribute("alive", alive);

  /// ## atexit (getter)
  ///
  /// ### python docstring
  ///
  /// Whether finalizer should be called at exit
  Object? get atexit => getAttribute("atexit");

  /// ## atexit (setter)
  ///
  /// ### python docstring
  ///
  /// Whether finalizer should be called at exit
  set atexit(Object? atexit) => setAttribute("atexit", atexit);
}

/// ## State
///
/// ### python source
/// ```py
/// class State:
///     # keeps track of state for parsing
///     def __init__(self):
///         self.flags = 0
///         self.groupdict = {}
///         self.groupwidths = [None]  # group 0
///         self.lookbehindgroups = None
///         self.grouprefpos = {}
///     @property
///     def groups(self):
///         return len(self.groupwidths)
///     def opengroup(self, name=None):
///         gid = self.groups
///         self.groupwidths.append(None)
///         if self.groups > MAXGROUPS:
///             raise error("too many groups")
///         if name is not None:
///             ogid = self.groupdict.get(name, None)
///             if ogid is not None:
///                 raise error("redefinition of group name %r as group %d; "
///                             "was group %d" % (name, gid,  ogid))
///             self.groupdict[name] = gid
///         return gid
///     def closegroup(self, gid, p):
///         self.groupwidths[gid] = p.getwidth()
///     def checkgroup(self, gid):
///         return gid < self.groups and self.groupwidths[gid] is not None
///
///     def checklookbehindgroup(self, gid, source):
///         if self.lookbehindgroups is not None:
///             if not self.checkgroup(gid):
///                 raise source.error('cannot refer to an open group')
///             if gid >= self.lookbehindgroups:
///                 raise source.error('cannot refer to group defined in the same '
///                                    'lookbehind subpattern')
/// ```
final class State extends PythonClass {
  factory State() => PythonFfiDart.instance.importClass(
        "re._parser",
        "State",
        State.from,
        <Object?>[],
        <String, Object?>{},
      );

  State.from(super.pythonClass) : super.from();

  /// ## checkgroup
  ///
  /// ### python source
  /// ```py
  /// def checkgroup(self, gid):
  ///         return gid < self.groups and self.groupwidths[gid] is not None
  /// ```
  Object? checkgroup({
    required Object? gid,
  }) =>
      getFunction("checkgroup").call(
        <Object?>[
          gid,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## checklookbehindgroup
  ///
  /// ### python source
  /// ```py
  /// def checklookbehindgroup(self, gid, source):
  ///         if self.lookbehindgroups is not None:
  ///             if not self.checkgroup(gid):
  ///                 raise source.error('cannot refer to an open group')
  ///             if gid >= self.lookbehindgroups:
  ///                 raise source.error('cannot refer to group defined in the same '
  ///                                    'lookbehind subpattern')
  /// ```
  Object? checklookbehindgroup({
    required Object? gid,
    required Object? source,
  }) =>
      getFunction("checklookbehindgroup").call(
        <Object?>[
          gid,
          source,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## closegroup
  ///
  /// ### python source
  /// ```py
  /// def closegroup(self, gid, p):
  ///         self.groupwidths[gid] = p.getwidth()
  /// ```
  Object? closegroup({
    required Object? gid,
    required Object? p,
  }) =>
      getFunction("closegroup").call(
        <Object?>[
          gid,
          p,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## opengroup
  ///
  /// ### python source
  /// ```py
  /// def opengroup(self, name=None):
  ///         gid = self.groups
  ///         self.groupwidths.append(None)
  ///         if self.groups > MAXGROUPS:
  ///             raise error("too many groups")
  ///         if name is not None:
  ///             ogid = self.groupdict.get(name, None)
  ///             if ogid is not None:
  ///                 raise error("redefinition of group name %r as group %d; "
  ///                             "was group %d" % (name, gid,  ogid))
  ///             self.groupdict[name] = gid
  ///         return gid
  /// ```
  Object? opengroup({
    Object? name,
  }) =>
      getFunction("opengroup").call(
        <Object?>[
          name,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## groups (getter)
  Object? get groups => getAttribute("groups");

  /// ## groups (setter)
  set groups(Object? groups) => setAttribute("groups", groups);

  /// ## flags (getter)
  Object? get flags => getAttribute("flags");

  /// ## flags (setter)
  set flags(Object? flags) => setAttribute("flags", flags);

  /// ## groupdict (getter)
  Object? get groupdict => getAttribute("groupdict");

  /// ## groupdict (setter)
  set groupdict(Object? groupdict) => setAttribute("groupdict", groupdict);

  /// ## groupwidths (getter)
  Object? get groupwidths => getAttribute("groupwidths");

  /// ## groupwidths (setter)
  set groupwidths(Object? groupwidths) =>
      setAttribute("groupwidths", groupwidths);

  /// ## lookbehindgroups (getter)
  Object? get lookbehindgroups => getAttribute("lookbehindgroups");

  /// ## lookbehindgroups (setter)
  set lookbehindgroups(Object? lookbehindgroups) =>
      setAttribute("lookbehindgroups", lookbehindgroups);

  /// ## grouprefpos (getter)
  Object? get grouprefpos => getAttribute("grouprefpos");

  /// ## grouprefpos (setter)
  set grouprefpos(Object? grouprefpos) =>
      setAttribute("grouprefpos", grouprefpos);
}

/// ## SubPattern
///
/// ### python source
/// ```py
/// class SubPattern:
///     # a subpattern, in intermediate form
///     def __init__(self, state, data=None):
///         self.state = state
///         if data is None:
///             data = []
///         self.data = data
///         self.width = None
///
///     def dump(self, level=0):
///         nl = True
///         seqtypes = (tuple, list)
///         for op, av in self.data:
///             print(level*"  " + str(op), end='')
///             if op is IN:
///                 # member sublanguage
///                 print()
///                 for op, a in av:
///                     print((level+1)*"  " + str(op), a)
///             elif op is BRANCH:
///                 print()
///                 for i, a in enumerate(av[1]):
///                     if i:
///                         print(level*"  " + "OR")
///                     a.dump(level+1)
///             elif op is GROUPREF_EXISTS:
///                 condgroup, item_yes, item_no = av
///                 print('', condgroup)
///                 item_yes.dump(level+1)
///                 if item_no:
///                     print(level*"  " + "ELSE")
///                     item_no.dump(level+1)
///             elif isinstance(av, seqtypes):
///                 nl = False
///                 for a in av:
///                     if isinstance(a, SubPattern):
///                         if not nl:
///                             print()
///                         a.dump(level+1)
///                         nl = True
///                     else:
///                         if not nl:
///                             print(' ', end='')
///                         print(a, end='')
///                         nl = False
///                 if not nl:
///                     print()
///             else:
///                 print('', av)
///     def __repr__(self):
///         return repr(self.data)
///     def __len__(self):
///         return len(self.data)
///     def __delitem__(self, index):
///         del self.data[index]
///     def __getitem__(self, index):
///         if isinstance(index, slice):
///             return SubPattern(self.state, self.data[index])
///         return self.data[index]
///     def __setitem__(self, index, code):
///         self.data[index] = code
///     def insert(self, index, code):
///         self.data.insert(index, code)
///     def append(self, code):
///         self.data.append(code)
///     def getwidth(self):
///         # determine the width (min, max) for this subpattern
///         if self.width is not None:
///             return self.width
///         lo = hi = 0
///         for op, av in self.data:
///             if op is BRANCH:
///                 i = MAXREPEAT - 1
///                 j = 0
///                 for av in av[1]:
///                     l, h = av.getwidth()
///                     i = min(i, l)
///                     j = max(j, h)
///                 lo = lo + i
///                 hi = hi + j
///             elif op is ATOMIC_GROUP:
///                 i, j = av.getwidth()
///                 lo = lo + i
///                 hi = hi + j
///             elif op is SUBPATTERN:
///                 i, j = av[-1].getwidth()
///                 lo = lo + i
///                 hi = hi + j
///             elif op in _REPEATCODES:
///                 i, j = av[2].getwidth()
///                 lo = lo + i * av[0]
///                 hi = hi + j * av[1]
///             elif op in _UNITCODES:
///                 lo = lo + 1
///                 hi = hi + 1
///             elif op is GROUPREF:
///                 i, j = self.state.groupwidths[av]
///                 lo = lo + i
///                 hi = hi + j
///             elif op is GROUPREF_EXISTS:
///                 i, j = av[1].getwidth()
///                 if av[2] is not None:
///                     l, h = av[2].getwidth()
///                     i = min(i, l)
///                     j = max(j, h)
///                 else:
///                     i = 0
///                 lo = lo + i
///                 hi = hi + j
///             elif op is SUCCESS:
///                 break
///         self.width = min(lo, MAXREPEAT - 1), min(hi, MAXREPEAT)
///         return self.width
/// ```
final class SubPattern extends PythonClass {
  factory SubPattern({
    required Object? state,
    Object? data,
  }) =>
      PythonFfiDart.instance.importClass(
        "re._parser",
        "SubPattern",
        SubPattern.from,
        <Object?>[
          state,
          data,
        ],
        <String, Object?>{},
      );

  SubPattern.from(super.pythonClass) : super.from();

  /// ## append
  ///
  /// ### python source
  /// ```py
  /// def append(self, code):
  ///         self.data.append(code)
  /// ```
  Object? append({
    required Object? code,
  }) =>
      getFunction("append").call(
        <Object?>[
          code,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## dump
  ///
  /// ### python source
  /// ```py
  /// def dump(self, level=0):
  ///         nl = True
  ///         seqtypes = (tuple, list)
  ///         for op, av in self.data:
  ///             print(level*"  " + str(op), end='')
  ///             if op is IN:
  ///                 # member sublanguage
  ///                 print()
  ///                 for op, a in av:
  ///                     print((level+1)*"  " + str(op), a)
  ///             elif op is BRANCH:
  ///                 print()
  ///                 for i, a in enumerate(av[1]):
  ///                     if i:
  ///                         print(level*"  " + "OR")
  ///                     a.dump(level+1)
  ///             elif op is GROUPREF_EXISTS:
  ///                 condgroup, item_yes, item_no = av
  ///                 print('', condgroup)
  ///                 item_yes.dump(level+1)
  ///                 if item_no:
  ///                     print(level*"  " + "ELSE")
  ///                     item_no.dump(level+1)
  ///             elif isinstance(av, seqtypes):
  ///                 nl = False
  ///                 for a in av:
  ///                     if isinstance(a, SubPattern):
  ///                         if not nl:
  ///                             print()
  ///                         a.dump(level+1)
  ///                         nl = True
  ///                     else:
  ///                         if not nl:
  ///                             print(' ', end='')
  ///                         print(a, end='')
  ///                         nl = False
  ///                 if not nl:
  ///                     print()
  ///             else:
  ///                 print('', av)
  /// ```
  Object? dump({
    Object? level = 0,
  }) =>
      getFunction("dump").call(
        <Object?>[
          level,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## getwidth
  ///
  /// ### python source
  /// ```py
  /// def getwidth(self):
  ///         # determine the width (min, max) for this subpattern
  ///         if self.width is not None:
  ///             return self.width
  ///         lo = hi = 0
  ///         for op, av in self.data:
  ///             if op is BRANCH:
  ///                 i = MAXREPEAT - 1
  ///                 j = 0
  ///                 for av in av[1]:
  ///                     l, h = av.getwidth()
  ///                     i = min(i, l)
  ///                     j = max(j, h)
  ///                 lo = lo + i
  ///                 hi = hi + j
  ///             elif op is ATOMIC_GROUP:
  ///                 i, j = av.getwidth()
  ///                 lo = lo + i
  ///                 hi = hi + j
  ///             elif op is SUBPATTERN:
  ///                 i, j = av[-1].getwidth()
  ///                 lo = lo + i
  ///                 hi = hi + j
  ///             elif op in _REPEATCODES:
  ///                 i, j = av[2].getwidth()
  ///                 lo = lo + i * av[0]
  ///                 hi = hi + j * av[1]
  ///             elif op in _UNITCODES:
  ///                 lo = lo + 1
  ///                 hi = hi + 1
  ///             elif op is GROUPREF:
  ///                 i, j = self.state.groupwidths[av]
  ///                 lo = lo + i
  ///                 hi = hi + j
  ///             elif op is GROUPREF_EXISTS:
  ///                 i, j = av[1].getwidth()
  ///                 if av[2] is not None:
  ///                     l, h = av[2].getwidth()
  ///                     i = min(i, l)
  ///                     j = max(j, h)
  ///                 else:
  ///                     i = 0
  ///                 lo = lo + i
  ///                 hi = hi + j
  ///             elif op is SUCCESS:
  ///                 break
  ///         self.width = min(lo, MAXREPEAT - 1), min(hi, MAXREPEAT)
  ///         return self.width
  /// ```
  Object? getwidth() => getFunction("getwidth").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## insert
  ///
  /// ### python source
  /// ```py
  /// def insert(self, index, code):
  ///         self.data.insert(index, code)
  /// ```
  Object? insert({
    required Object? index,
    required Object? code,
  }) =>
      getFunction("insert").call(
        <Object?>[
          index,
          code,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## state (getter)
  Object? get state => getAttribute("state");

  /// ## state (setter)
  set state(Object? state) => setAttribute("state", state);

  /// ## data (getter)
  Object? get data => getAttribute("data");

  /// ## data (setter)
  set data(Object? data) => setAttribute("data", data);

  /// ## width (getter)
  Object? get width => getAttribute("width");

  /// ## width (setter)
  set width(Object? width) => setAttribute("width", width);
}

/// ## Tokenizer
///
/// ### python source
/// ```py
/// class Tokenizer:
///     def __init__(self, string):
///         self.istext = isinstance(string, str)
///         self.string = string
///         if not self.istext:
///             string = str(string, 'latin1')
///         self.decoded_string = string
///         self.index = 0
///         self.next = None
///         self.__next()
///     def __next(self):
///         index = self.index
///         try:
///             char = self.decoded_string[index]
///         except IndexError:
///             self.next = None
///             return
///         if char == "\\":
///             index += 1
///             try:
///                 char += self.decoded_string[index]
///             except IndexError:
///                 raise error("bad escape (end of pattern)",
///                             self.string, len(self.string) - 1) from None
///         self.index = index + 1
///         self.next = char
///     def match(self, char):
///         if char == self.next:
///             self.__next()
///             return True
///         return False
///     def get(self):
///         this = self.next
///         self.__next()
///         return this
///     def getwhile(self, n, charset):
///         result = ''
///         for _ in range(n):
///             c = self.next
///             if c not in charset:
///                 break
///             result += c
///             self.__next()
///         return result
///     def getuntil(self, terminator, name):
///         result = ''
///         while True:
///             c = self.next
///             self.__next()
///             if c is None:
///                 if not result:
///                     raise self.error("missing " + name)
///                 raise self.error("missing %s, unterminated name" % terminator,
///                                  len(result))
///             if c == terminator:
///                 if not result:
///                     raise self.error("missing " + name, 1)
///                 break
///             result += c
///         return result
///     @property
///     def pos(self):
///         return self.index - len(self.next or '')
///     def tell(self):
///         return self.index - len(self.next or '')
///     def seek(self, index):
///         self.index = index
///         self.__next()
///
///     def error(self, msg, offset=0):
///         if not self.istext:
///             msg = msg.encode('ascii', 'backslashreplace').decode('ascii')
///         return error(msg, self.string, self.tell() - offset)
///
///     def checkgroupname(self, name, offset, nested):
///         if not name.isidentifier():
///             msg = "bad character in group name %r" % name
///             raise self.error(msg, len(name) + offset)
///         if not (self.istext or name.isascii()):
///             import warnings
///             warnings.warn(
///                 "bad character in group name %a at position %d" %
///                 (name, self.tell() - len(name) - offset),
///                 DeprecationWarning, stacklevel=nested + 7
///             )
/// ```
final class Tokenizer extends PythonClass {
  factory Tokenizer({
    required Object? string,
  }) =>
      PythonFfiDart.instance.importClass(
        "re._parser",
        "Tokenizer",
        Tokenizer.from,
        <Object?>[
          string,
        ],
        <String, Object?>{},
      );

  Tokenizer.from(super.pythonClass) : super.from();

  /// ## checkgroupname
  ///
  /// ### python source
  /// ```py
  /// def checkgroupname(self, name, offset, nested):
  ///         if not name.isidentifier():
  ///             msg = "bad character in group name %r" % name
  ///             raise self.error(msg, len(name) + offset)
  ///         if not (self.istext or name.isascii()):
  ///             import warnings
  ///             warnings.warn(
  ///                 "bad character in group name %a at position %d" %
  ///                 (name, self.tell() - len(name) - offset),
  ///                 DeprecationWarning, stacklevel=nested + 7
  ///             )
  /// ```
  Object? checkgroupname({
    required Object? name,
    required Object? offset,
    required Object? nested,
  }) =>
      getFunction("checkgroupname").call(
        <Object?>[
          name,
          offset,
          nested,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## error
  ///
  /// ### python source
  /// ```py
  /// def error(self, msg, offset=0):
  ///         if not self.istext:
  ///             msg = msg.encode('ascii', 'backslashreplace').decode('ascii')
  ///         return error(msg, self.string, self.tell() - offset)
  /// ```
  Object? error({
    required Object? msg,
    Object? offset = 0,
  }) =>
      getFunction("error").call(
        <Object?>[
          msg,
          offset,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## get
  ///
  /// ### python source
  /// ```py
  /// def get(self):
  ///         this = self.next
  ///         self.__next()
  ///         return this
  /// ```
  Object? $get() => getFunction("get").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## getuntil
  ///
  /// ### python source
  /// ```py
  /// def getuntil(self, terminator, name):
  ///         result = ''
  ///         while True:
  ///             c = self.next
  ///             self.__next()
  ///             if c is None:
  ///                 if not result:
  ///                     raise self.error("missing " + name)
  ///                 raise self.error("missing %s, unterminated name" % terminator,
  ///                                  len(result))
  ///             if c == terminator:
  ///                 if not result:
  ///                     raise self.error("missing " + name, 1)
  ///                 break
  ///             result += c
  ///         return result
  /// ```
  Object? getuntil({
    required Object? terminator,
    required Object? name,
  }) =>
      getFunction("getuntil").call(
        <Object?>[
          terminator,
          name,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## getwhile
  ///
  /// ### python source
  /// ```py
  /// def getwhile(self, n, charset):
  ///         result = ''
  ///         for _ in range(n):
  ///             c = self.next
  ///             if c not in charset:
  ///                 break
  ///             result += c
  ///             self.__next()
  ///         return result
  /// ```
  Object? getwhile({
    required Object? n,
    required Object? charset,
  }) =>
      getFunction("getwhile").call(
        <Object?>[
          n,
          charset,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## match
  ///
  /// ### python source
  /// ```py
  /// def match(self, char):
  ///         if char == self.next:
  ///             self.__next()
  ///             return True
  ///         return False
  /// ```
  Object? match({
    required Object? char,
  }) =>
      getFunction("match").call(
        <Object?>[
          char,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## seek
  ///
  /// ### python source
  /// ```py
  /// def seek(self, index):
  ///         self.index = index
  ///         self.__next()
  /// ```
  Object? seek({
    required Object? index,
  }) =>
      getFunction("seek").call(
        <Object?>[
          index,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## tell
  ///
  /// ### python source
  /// ```py
  /// def tell(self):
  ///         return self.index - len(self.next or '')
  /// ```
  Object? tell() => getFunction("tell").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## pos (getter)
  Object? get pos => getAttribute("pos");

  /// ## pos (setter)
  set pos(Object? pos) => setAttribute("pos", pos);

  /// ## istext (getter)
  Object? get istext => getAttribute("istext");

  /// ## istext (setter)
  set istext(Object? istext) => setAttribute("istext", istext);

  /// ## string (getter)
  Object? get string => getAttribute("string");

  /// ## string (setter)
  set string(Object? string) => setAttribute("string", string);

  /// ## decoded_string (getter)
  Object? get decoded_string => getAttribute("decoded_string");

  /// ## decoded_string (setter)
  set decoded_string(Object? decoded_string) =>
      setAttribute("decoded_string", decoded_string);

  /// ## index (getter)
  Object? get index => getAttribute("index");

  /// ## index (setter)
  set index(Object? index) => setAttribute("index", index);

  /// ## next (getter)
  Object? get next => getAttribute("next");

  /// ## next (setter)
  set next(Object? next) => setAttribute("next", next);
}

/// ## UCD
final class UCD extends PythonClass {
  factory UCD() => PythonFfiDart.instance.importClass(
        "unicodedata",
        "UCD",
        UCD.from,
        <Object?>[],
      );

  UCD.from(super.pythonClass) : super.from();

  /// ## unidata_version (getter)
  Object? get unidata_version => getAttribute("unidata_version");

  /// ## unidata_version (setter)
  set unidata_version(Object? unidata_version) =>
      setAttribute("unidata_version", unidata_version);

  /// ## bidirectional (getter)
  Object? get bidirectional => getAttribute("bidirectional");

  /// ## bidirectional (setter)
  set bidirectional(Object? bidirectional) =>
      setAttribute("bidirectional", bidirectional);

  /// ## category (getter)
  Object? get category => getAttribute("category");

  /// ## category (setter)
  set category(Object? category) => setAttribute("category", category);

  /// ## combining (getter)
  Object? get combining => getAttribute("combining");

  /// ## combining (setter)
  set combining(Object? combining) => setAttribute("combining", combining);

  /// ## decimal (getter)
  Object? get decimal => getAttribute("decimal");

  /// ## decimal (setter)
  set decimal(Object? decimal) => setAttribute("decimal", decimal);

  /// ## decomposition (getter)
  Object? get decomposition => getAttribute("decomposition");

  /// ## decomposition (setter)
  set decomposition(Object? decomposition) =>
      setAttribute("decomposition", decomposition);

  /// ## digit (getter)
  Object? get digit => getAttribute("digit");

  /// ## digit (setter)
  set digit(Object? digit) => setAttribute("digit", digit);

  /// ## east_asian_width (getter)
  Object? get east_asian_width => getAttribute("east_asian_width");

  /// ## east_asian_width (setter)
  set east_asian_width(Object? east_asian_width) =>
      setAttribute("east_asian_width", east_asian_width);

  /// ## is_normalized (getter)
  Object? get is_normalized => getAttribute("is_normalized");

  /// ## is_normalized (setter)
  set is_normalized(Object? is_normalized) =>
      setAttribute("is_normalized", is_normalized);

  /// ## lookup (getter)
  Object? get lookup => getAttribute("lookup");

  /// ## lookup (setter)
  set lookup(Object? lookup) => setAttribute("lookup", lookup);

  /// ## mirrored (getter)
  Object? get mirrored => getAttribute("mirrored");

  /// ## mirrored (setter)
  set mirrored(Object? mirrored) => setAttribute("mirrored", mirrored);

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);

  /// ## normalize (getter)
  Object? get normalize => getAttribute("normalize");

  /// ## normalize (setter)
  set normalize(Object? normalize) => setAttribute("normalize", normalize);

  /// ## numeric (getter)
  Object? get numeric => getAttribute("numeric");

  /// ## numeric (setter)
  set numeric(Object? numeric) => setAttribute("numeric", numeric);
}

/// ## CollapseAmbiguities
///
/// ### python docstring
///
/// Transforms a tree that contains any number of _ambig nodes into a list of trees,
/// each one containing an unambiguous tree.
///
/// The length of the resulting list is the product of the length of all _ambig nodes.
///
/// Warning: This may quickly explode for highly ambiguous trees.
///
/// ### python source
/// ```py
/// class CollapseAmbiguities(Transformer):
///     """
///     Transforms a tree that contains any number of _ambig nodes into a list of trees,
///     each one containing an unambiguous tree.
///
///     The length of the resulting list is the product of the length of all _ambig nodes.
///
///     Warning: This may quickly explode for highly ambiguous trees.
///
///     """
///     def _ambig(self, options):
///         return sum(options, [])
///
///     def __default__(self, data, children_lists, meta):
///         return [Tree(data, children, meta) for children in combine_alternatives(children_lists)]
///
///     def __default_token__(self, t):
///         return [t]
/// ```
final class CollapseAmbiguities extends PythonClass {
  factory CollapseAmbiguities({
    Object? visit_tokens = true,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.visitors",
        "CollapseAmbiguities",
        CollapseAmbiguities.from,
        <Object?>[
          visit_tokens,
        ],
        <String, Object?>{},
      );

  CollapseAmbiguities.from(super.pythonClass) : super.from();

  /// ## transform
  ///
  /// ### python docstring
  ///
  /// Transform the given tree, and return the final result
  ///
  /// ### python source
  /// ```py
  /// def transform(self, tree: Tree[_Leaf_T]) -> _Return_T:
  ///         "Transform the given tree, and return the final result"
  ///         return self._transform_tree(tree)
  /// ```
  Object? transform({
    required Object? tree,
  }) =>
      getFunction("transform").call(
        <Object?>[
          tree,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## InlineTransformer
///
/// ### python docstring
///
/// Transformers work bottom-up (or depth-first), starting with visiting the leaves and working
/// their way up until ending at the root of the tree.
///
/// For each node visited, the transformer will call the appropriate method (callbacks), according to the
/// node's ``data``, and use the returned value to replace the node, thereby creating a new tree structure.
///
/// Transformers can be used to implement map & reduce patterns. Because nodes are reduced from leaf to root,
/// at any point the callbacks may assume the children have already been transformed (if applicable).
///
/// If the transformer cannot find a method with the right name, it will instead call ``__default__``, which by
/// default creates a copy of the node.
///
/// To discard a node, return Discard (``lark.visitors.Discard``).
///
/// ``Transformer`` can do anything ``Visitor`` can do, but because it reconstructs the tree,
/// it is slightly less efficient.
///
/// A transformer without methods essentially performs a non-memoized partial deepcopy.
///
/// All these classes implement the transformer interface:
///
/// - ``Transformer`` - Recursively transforms the tree. This is the one you probably want.
/// - ``Transformer_InPlace`` - Non-recursive. Changes the tree in-place instead of returning new instances
/// - ``Transformer_InPlaceRecursive`` - Recursive. Changes the tree in-place instead of returning new instances
///
/// Parameters:
///     visit_tokens (bool, optional): Should the transformer visit tokens in addition to rules.
///                                    Setting this to ``False`` is slightly faster. Defaults to ``True``.
///                                    (For processing ignored tokens, use the ``lexer_callbacks`` options)
///
/// ### python source
/// ```py
/// class InlineTransformer(Transformer):   # XXX Deprecated
///     def _call_userfunc(self, tree, new_children=None):
///         # Assumes tree is already transformed
///         children = new_children if new_children is not None else tree.children
///         try:
///             f = getattr(self, tree.data)
///         except AttributeError:
///             return self.__default__(tree.data, children, tree.meta)
///         else:
///             return f(*children)
/// ```
final class InlineTransformer extends PythonClass {
  factory InlineTransformer({
    Object? visit_tokens = true,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.visitors",
        "InlineTransformer",
        InlineTransformer.from,
        <Object?>[
          visit_tokens,
        ],
        <String, Object?>{},
      );

  InlineTransformer.from(super.pythonClass) : super.from();

  /// ## transform
  ///
  /// ### python docstring
  ///
  /// Transform the given tree, and return the final result
  ///
  /// ### python source
  /// ```py
  /// def transform(self, tree: Tree[_Leaf_T]) -> _Return_T:
  ///         "Transform the given tree, and return the final result"
  ///         return self._transform_tree(tree)
  /// ```
  Object? transform({
    required Object? tree,
  }) =>
      getFunction("transform").call(
        <Object?>[
          tree,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## Interpreter
///
/// ### python docstring
///
/// Interpreter walks the tree starting at the root.
///
/// Visits the tree, starting with the root and finally the leaves (top-down)
///
/// For each tree node, it calls its methods (provided by user via inheritance) according to ``tree.data``.
///
/// Unlike ``Transformer`` and ``Visitor``, the Interpreter doesn't automatically visit its sub-branches.
/// The user has to explicitly call ``visit``, ``visit_children``, or use the ``@visit_children_decor``.
/// This allows the user to implement branching and loops.
///
/// ### python source
/// ```py
/// class Interpreter(_Decoratable, ABC, Generic[_Leaf_T, _Return_T]):
///     """Interpreter walks the tree starting at the root.
///
///     Visits the tree, starting with the root and finally the leaves (top-down)
///
///     For each tree node, it calls its methods (provided by user via inheritance) according to ``tree.data``.
///
///     Unlike ``Transformer`` and ``Visitor``, the Interpreter doesn't automatically visit its sub-branches.
///     The user has to explicitly call ``visit``, ``visit_children``, or use the ``@visit_children_decor``.
///     This allows the user to implement branching and loops.
///     """
///
///     def visit(self, tree: Tree[_Leaf_T]) -> _Return_T:
///         # There are no guarantees on the type of the value produced by calling a user func for a
///         # child will produce. So only annotate the public method and use an internal method when
///         # visiting child trees.
///         return self._visit_tree(tree)
///
///     def _visit_tree(self, tree: Tree[_Leaf_T]):
///         f = getattr(self, tree.data)
///         wrapper = getattr(f, 'visit_wrapper', None)
///         if wrapper is not None:
///             return f.visit_wrapper(f, tree.data, tree.children, tree.meta)
///         else:
///             return f(tree)
///
///     def visit_children(self, tree: Tree[_Leaf_T]) -> List:
///         return [self._visit_tree(child) if isinstance(child, Tree) else child
///                 for child in tree.children]
///
///     def __getattr__(self, name):
///         return self.__default__
///
///     def __default__(self, tree):
///         return self.visit_children(tree)
/// ```
final class Interpreter extends PythonClass {
  factory Interpreter() => PythonFfiDart.instance.importClass(
        "lark.visitors",
        "Interpreter",
        Interpreter.from,
        <Object?>[],
      );

  Interpreter.from(super.pythonClass) : super.from();

  /// ## visit
  ///
  /// ### python source
  /// ```py
  /// def visit(self, tree: Tree[_Leaf_T]) -> _Return_T:
  ///         # There are no guarantees on the type of the value produced by calling a user func for a
  ///         # child will produce. So only annotate the public method and use an internal method when
  ///         # visiting child trees.
  ///         return self._visit_tree(tree)
  /// ```
  Object? visit({
    required Object? tree,
  }) =>
      getFunction("visit").call(
        <Object?>[
          tree,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_children
  ///
  /// ### python source
  /// ```py
  /// def visit_children(self, tree: Tree[_Leaf_T]) -> List:
  ///         return [self._visit_tree(child) if isinstance(child, Tree) else child
  ///                 for child in tree.children]
  /// ```
  Object? visit_children({
    required Object? tree,
  }) =>
      getFunction("visit_children").call(
        <Object?>[
          tree,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## TransformerChain
///
/// ### python docstring
///
/// Abstract base class for generic types.
///
/// A generic type is typically declared by inheriting from
/// this class parameterized with one or more type variables.
/// For example, a generic mapping type might be defined as::
///
///   class Mapping(Generic[KT, VT]):
///       def __getitem__(self, key: KT) -> VT:
///           ...
///       # Etc.
///
/// This class can then be used as follows::
///
///   def lookup_name(mapping: Mapping[KT, VT], key: KT, default: VT) -> VT:
///       try:
///           return mapping[key]
///       except KeyError:
///           return default
///
/// ### python source
/// ```py
/// class TransformerChain(Generic[_Leaf_T, _Return_T]):
///
///     transformers: 'Tuple[Union[Transformer, TransformerChain], ...]'
///
///     def __init__(self, *transformers: 'Union[Transformer, TransformerChain]') -> None:
///         self.transformers = transformers
///
///     def transform(self, tree: Tree[_Leaf_T]) -> _Return_T:
///         for t in self.transformers:
///             tree = t.transform(tree)
///         return cast(_Return_T, tree)
///
///     def __mul__(
///             self: 'TransformerChain[_Leaf_T, Tree[_Leaf_U]]',
///             other: 'Union[Transformer[_Leaf_U, _Return_V], TransformerChain[_Leaf_U, _Return_V]]'
///     ) -> 'TransformerChain[_Leaf_T, _Return_V]':
///         return TransformerChain(*self.transformers + (other,))
/// ```
final class TransformerChain extends PythonClass {
  factory TransformerChain({
    List<Object?> transformers = const <Object?>[],
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.visitors",
        "TransformerChain",
        TransformerChain.from,
        <Object?>[
          ...transformers,
        ],
        <String, Object?>{},
      );

  TransformerChain.from(super.pythonClass) : super.from();

  /// ## transform
  ///
  /// ### python source
  /// ```py
  /// def transform(self, tree: Tree[_Leaf_T]) -> _Return_T:
  ///         for t in self.transformers:
  ///             tree = t.transform(tree)
  ///         return cast(_Return_T, tree)
  /// ```
  Object? transform({
    required Object? tree,
  }) =>
      getFunction("transform").call(
        <Object?>[
          tree,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## transformers (getter)
  Object? get transformers => getAttribute("transformers");

  /// ## transformers (setter)
  set transformers(Object? transformers) =>
      setAttribute("transformers", transformers);
}

/// ## Transformer_InPlaceRecursive
///
/// ### python docstring
///
/// Same as Transformer, recursive, but changes the tree in-place instead of returning new instances
///
/// ### python source
/// ```py
/// class Transformer_InPlaceRecursive(Transformer):
///     "Same as Transformer, recursive, but changes the tree in-place instead of returning new instances"
///     def _transform_tree(self, tree):
///         tree.children = list(self._transform_children(tree.children))
///         return self._call_userfunc(tree)
/// ```
final class Transformer_InPlaceRecursive extends PythonClass {
  factory Transformer_InPlaceRecursive({
    Object? visit_tokens = true,
  }) =>
      PythonFfiDart.instance.importClass(
        "lark.visitors",
        "Transformer_InPlaceRecursive",
        Transformer_InPlaceRecursive.from,
        <Object?>[
          visit_tokens,
        ],
        <String, Object?>{},
      );

  Transformer_InPlaceRecursive.from(super.pythonClass) : super.from();

  /// ## transform
  ///
  /// ### python docstring
  ///
  /// Transform the given tree, and return the final result
  ///
  /// ### python source
  /// ```py
  /// def transform(self, tree: Tree[_Leaf_T]) -> _Return_T:
  ///         "Transform the given tree, and return the final result"
  ///         return self._transform_tree(tree)
  /// ```
  Object? transform({
    required Object? tree,
  }) =>
      getFunction("transform").call(
        <Object?>[
          tree,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## VisitorBase
///
/// ### python source
/// ```py
/// class VisitorBase:
///     def _call_userfunc(self, tree):
///         return getattr(self, tree.data, self.__default__)(tree)
///
///     def __default__(self, tree):
///         """Default function that is called if there is no attribute matching ``tree.data``
///
///         Can be overridden. Defaults to doing nothing.
///         """
///         return tree
///
///     def __class_getitem__(cls, _):
///         return cls
/// ```
final class VisitorBase extends PythonClass {
  factory VisitorBase() => PythonFfiDart.instance.importClass(
        "lark.visitors",
        "VisitorBase",
        VisitorBase.from,
        <Object?>[],
      );

  VisitorBase.from(super.pythonClass) : super.from();
}

/// ## Visitor_Recursive
///
/// ### python docstring
///
/// Bottom-up visitor, recursive.
///
/// Visiting a node calls its methods (provided by the user via inheritance) according to ``tree.data``
///
/// Slightly faster than the non-recursive version.
///
/// ### python source
/// ```py
/// class Visitor_Recursive(VisitorBase, Generic[_Leaf_T]):
///     """Bottom-up visitor, recursive.
///
///     Visiting a node calls its methods (provided by the user via inheritance) according to ``tree.data``
///
///     Slightly faster than the non-recursive version.
///     """
///
///     def visit(self, tree: Tree[_Leaf_T]) -> Tree[_Leaf_T]:
///         "Visits the tree, starting with the leaves and finally the root (bottom-up)"
///         for child in tree.children:
///             if isinstance(child, Tree):
///                 self.visit(child)
///
///         self._call_userfunc(tree)
///         return tree
///
///     def visit_topdown(self,tree: Tree[_Leaf_T]) -> Tree[_Leaf_T]:
///         "Visit the tree, starting at the root, and ending at the leaves (top-down)"
///         self._call_userfunc(tree)
///
///         for child in tree.children:
///             if isinstance(child, Tree):
///                 self.visit_topdown(child)
///
///         return tree
/// ```
final class Visitor_Recursive extends PythonClass {
  factory Visitor_Recursive() => PythonFfiDart.instance.importClass(
        "lark.visitors",
        "Visitor_Recursive",
        Visitor_Recursive.from,
        <Object?>[],
      );

  Visitor_Recursive.from(super.pythonClass) : super.from();

  /// ## visit
  ///
  /// ### python docstring
  ///
  /// Visits the tree, starting with the leaves and finally the root (bottom-up)
  ///
  /// ### python source
  /// ```py
  /// def visit(self, tree: Tree[_Leaf_T]) -> Tree[_Leaf_T]:
  ///         "Visits the tree, starting with the leaves and finally the root (bottom-up)"
  ///         for child in tree.children:
  ///             if isinstance(child, Tree):
  ///                 self.visit(child)
  ///
  ///         self._call_userfunc(tree)
  ///         return tree
  /// ```
  Object? visit({
    required Object? tree,
  }) =>
      getFunction("visit").call(
        <Object?>[
          tree,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_topdown
  ///
  /// ### python docstring
  ///
  /// Visit the tree, starting at the root, and ending at the leaves (top-down)
  ///
  /// ### python source
  /// ```py
  /// def visit_topdown(self,tree: Tree[_Leaf_T]) -> Tree[_Leaf_T]:
  ///         "Visit the tree, starting at the root, and ending at the leaves (top-down)"
  ///         self._call_userfunc(tree)
  ///
  ///         for child in tree.children:
  ///             if isinstance(child, Tree):
  ///                 self.visit_topdown(child)
  ///
  ///         return tree
  /// ```
  Object? visit_topdown({
    required Object? tree,
  }) =>
      getFunction("visit_topdown").call(
        <Object?>[
          tree,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## lark
///
/// ### python source
/// ```py
/// from .exceptions import (
///     GrammarError,
///     LarkError,
///     LexError,
///     ParseError,
///     UnexpectedCharacters,
///     UnexpectedEOF,
///     UnexpectedInput,
///     UnexpectedToken,
/// )
/// from .lark import Lark
/// from .lexer import Token
/// from .tree import ParseTree, Tree
/// from .utils import logger
/// from .visitors import Discard, Transformer, Transformer_NonRecursive, Visitor, v_args
///
/// __version__: str = "1.1.5"
///
/// __all__ = (
///     "GrammarError",
///     "LarkError",
///     "LexError",
///     "ParseError",
///     "UnexpectedCharacters",
///     "UnexpectedEOF",
///     "UnexpectedInput",
///     "UnexpectedToken",
///     "Lark",
///     "Token",
///     "ParseTree",
///     "Tree",
///     "logger",
///     "Discard",
///     "Transformer",
///     "Transformer_NonRecursive",
///     "Visitor",
///     "v_args",
/// )
/// ```
final class lark extends PythonModule {
  lark.from(super.pythonModule) : super.from();

  static lark import() => PythonFfiDart.instance.importModule(
        "lark",
        lark.from,
      );
}

/// ## common
///
/// ### python source
/// ```py
/// from copy import deepcopy
/// import sys
/// from types import ModuleType
/// from typing import Callable, Collection, Dict, Optional, TYPE_CHECKING
///
/// if TYPE_CHECKING:
///     from .lark import PostLex
///     from .lexer import Lexer
///     from typing import Union, Type
///     if sys.version_info >= (3, 8):
///         from typing import Literal
///     else:
///         from typing_extensions import Literal
///     if sys.version_info >= (3, 10):
///         from typing import TypeAlias
///     else:
///         from typing_extensions import TypeAlias
///
/// from .utils import Serialize
/// from .lexer import TerminalDef, Token
///
/// ###{standalone
///
/// _ParserArgType: 'TypeAlias' = 'Literal["earley", "lalr", "cyk", "auto"]'
/// _LexerArgType: 'TypeAlias' = 'Union[Literal["auto", "basic", "contextual", "dynamic", "dynamic_complete"], Type[Lexer]]'
/// _Callback = Callable[[Token], Token]
///
/// class LexerConf(Serialize):
///     __serialize_fields__ = 'terminals', 'ignore', 'g_regex_flags', 'use_bytes', 'lexer_type'
///     __serialize_namespace__ = TerminalDef,
///
///     terminals: Collection[TerminalDef]
///     re_module: ModuleType
///     ignore: Collection[str]
///     postlex: 'Optional[PostLex]'
///     callbacks: Dict[str, _Callback]
///     g_regex_flags: int
///     skip_validation: bool
///     use_bytes: bool
///     lexer_type: Optional[_LexerArgType]
///
///     def __init__(self, terminals: Collection[TerminalDef], re_module: ModuleType, ignore: Collection[str]=(), postlex: 'Optional[PostLex]'=None, callbacks: Optional[Dict[str, _Callback]]=None, g_regex_flags: int=0, skip_validation: bool=False, use_bytes: bool=False):
///         self.terminals = terminals
///         self.terminals_by_name = {t.name: t for t in self.terminals}
///         assert len(self.terminals) == len(self.terminals_by_name)
///         self.ignore = ignore
///         self.postlex = postlex
///         self.callbacks = callbacks or {}
///         self.g_regex_flags = g_regex_flags
///         self.re_module = re_module
///         self.skip_validation = skip_validation
///         self.use_bytes = use_bytes
///         self.lexer_type = None
///
///     def _deserialize(self):
///         self.terminals_by_name = {t.name: t for t in self.terminals}
///
///     def __deepcopy__(self, memo=None):
///         return type(self)(
///             deepcopy(self.terminals, memo),
///             self.re_module,
///             deepcopy(self.ignore, memo),
///             deepcopy(self.postlex, memo),
///             deepcopy(self.callbacks, memo),
///             deepcopy(self.g_regex_flags, memo),
///             deepcopy(self.skip_validation, memo),
///             deepcopy(self.use_bytes, memo),
///         )
///
///
/// class ParserConf(Serialize):
///     __serialize_fields__ = 'rules', 'start', 'parser_type'
///
///     def __init__(self, rules, callbacks, start):
///         assert isinstance(start, list)
///         self.rules = rules
///         self.callbacks = callbacks
///         self.start = start
///
///         self.parser_type = None
///
/// ###}
/// ```
final class common extends PythonModule {
  common.from(super.pythonModule) : super.from();

  static common import() => PythonFfiDart.instance.importModule(
        "lark.common",
        common.from,
      );

  /// ## TYPE_CHECKING (getter)
  Object? get TYPE_CHECKING => getAttribute("TYPE_CHECKING");

  /// ## TYPE_CHECKING (setter)
  set TYPE_CHECKING(Object? TYPE_CHECKING) =>
      setAttribute("TYPE_CHECKING", TYPE_CHECKING);
}

/// ## sys
final class sys extends PythonModule {
  sys.from(super.pythonModule) : super.from();

  static sys import() => PythonFfiDart.instance.importModule(
        "sys",
        sys.from,
      );

  /// ## abiflags (getter)
  Object? get abiflags => getAttribute("abiflags");

  /// ## abiflags (setter)
  set abiflags(Object? abiflags) => setAttribute("abiflags", abiflags);

  /// ## api_version (getter)
  Object? get api_version => getAttribute("api_version");

  /// ## api_version (setter)
  set api_version(Object? api_version) =>
      setAttribute("api_version", api_version);

  /// ## argv (getter)
  Object? get argv => getAttribute("argv");

  /// ## argv (setter)
  set argv(Object? argv) => setAttribute("argv", argv);

  /// ## base_exec_prefix (getter)
  Object? get base_exec_prefix => getAttribute("base_exec_prefix");

  /// ## base_exec_prefix (setter)
  set base_exec_prefix(Object? base_exec_prefix) =>
      setAttribute("base_exec_prefix", base_exec_prefix);

  /// ## base_prefix (getter)
  Object? get base_prefix => getAttribute("base_prefix");

  /// ## base_prefix (setter)
  set base_prefix(Object? base_prefix) =>
      setAttribute("base_prefix", base_prefix);

  /// ## builtin_module_names (getter)
  Object? get builtin_module_names => getAttribute("builtin_module_names");

  /// ## builtin_module_names (setter)
  set builtin_module_names(Object? builtin_module_names) =>
      setAttribute("builtin_module_names", builtin_module_names);

  /// ## byteorder (getter)
  Object? get byteorder => getAttribute("byteorder");

  /// ## byteorder (setter)
  set byteorder(Object? byteorder) => setAttribute("byteorder", byteorder);

  /// ## copyright (getter)
  Object? get copyright => getAttribute("copyright");

  /// ## copyright (setter)
  set copyright(Object? copyright) => setAttribute("copyright", copyright);

  /// ## dont_write_bytecode (getter)
  Object? get dont_write_bytecode => getAttribute("dont_write_bytecode");

  /// ## dont_write_bytecode (setter)
  set dont_write_bytecode(Object? dont_write_bytecode) =>
      setAttribute("dont_write_bytecode", dont_write_bytecode);

  /// ## exec_prefix (getter)
  Object? get exec_prefix => getAttribute("exec_prefix");

  /// ## exec_prefix (setter)
  set exec_prefix(Object? exec_prefix) =>
      setAttribute("exec_prefix", exec_prefix);

  /// ## executable (getter)
  Object? get executable => getAttribute("executable");

  /// ## executable (setter)
  set executable(Object? executable) => setAttribute("executable", executable);

  /// ## flags (getter)
  Object? get flags => getAttribute("flags");

  /// ## flags (setter)
  set flags(Object? flags) => setAttribute("flags", flags);

  /// ## float_info (getter)
  Object? get float_info => getAttribute("float_info");

  /// ## float_info (setter)
  set float_info(Object? float_info) => setAttribute("float_info", float_info);

  /// ## float_repr_style (getter)
  Object? get float_repr_style => getAttribute("float_repr_style");

  /// ## float_repr_style (setter)
  set float_repr_style(Object? float_repr_style) =>
      setAttribute("float_repr_style", float_repr_style);

  /// ## hash_info (getter)
  Object? get hash_info => getAttribute("hash_info");

  /// ## hash_info (setter)
  set hash_info(Object? hash_info) => setAttribute("hash_info", hash_info);

  /// ## hexversion (getter)
  Object? get hexversion => getAttribute("hexversion");

  /// ## hexversion (setter)
  set hexversion(Object? hexversion) => setAttribute("hexversion", hexversion);

  /// ## int_info (getter)
  Object? get int_info => getAttribute("int_info");

  /// ## int_info (setter)
  set int_info(Object? int_info) => setAttribute("int_info", int_info);

  /// ## maxsize (getter)
  Object? get maxsize => getAttribute("maxsize");

  /// ## maxsize (setter)
  set maxsize(Object? maxsize) => setAttribute("maxsize", maxsize);

  /// ## maxunicode (getter)
  Object? get maxunicode => getAttribute("maxunicode");

  /// ## maxunicode (setter)
  set maxunicode(Object? maxunicode) => setAttribute("maxunicode", maxunicode);

  /// ## meta_path (getter)
  Object? get meta_path => getAttribute("meta_path");

  /// ## meta_path (setter)
  set meta_path(Object? meta_path) => setAttribute("meta_path", meta_path);

  /// ## modules (getter)
  Object? get modules => getAttribute("modules");

  /// ## modules (setter)
  set modules(Object? modules) => setAttribute("modules", modules);

  /// ## orig_argv (getter)
  Object? get orig_argv => getAttribute("orig_argv");

  /// ## orig_argv (setter)
  set orig_argv(Object? orig_argv) => setAttribute("orig_argv", orig_argv);

  /// ## path (getter)
  Object? get path => getAttribute("path");

  /// ## path (setter)
  set path(Object? path) => setAttribute("path", path);

  /// ## path_hooks (getter)
  Object? get path_hooks => getAttribute("path_hooks");

  /// ## path_hooks (setter)
  set path_hooks(Object? path_hooks) => setAttribute("path_hooks", path_hooks);

  /// ## path_importer_cache (getter)
  Object? get path_importer_cache => getAttribute("path_importer_cache");

  /// ## path_importer_cache (setter)
  set path_importer_cache(Object? path_importer_cache) =>
      setAttribute("path_importer_cache", path_importer_cache);

  /// ## platform (getter)
  Object? get $platform => getAttribute("platform");

  /// ## platform (setter)
  set $platform(Object? $platform) => setAttribute("platform", $platform);

  /// ## platlibdir (getter)
  Object? get platlibdir => getAttribute("platlibdir");

  /// ## platlibdir (setter)
  set platlibdir(Object? platlibdir) => setAttribute("platlibdir", platlibdir);

  /// ## prefix (getter)
  Object? get prefix => getAttribute("prefix");

  /// ## prefix (setter)
  set prefix(Object? prefix) => setAttribute("prefix", prefix);

  /// ## pycache_prefix (getter)
  Object? get pycache_prefix => getAttribute("pycache_prefix");

  /// ## pycache_prefix (setter)
  set pycache_prefix(Object? pycache_prefix) =>
      setAttribute("pycache_prefix", pycache_prefix);

  /// ## thread_info (getter)
  Object? get thread_info => getAttribute("thread_info");

  /// ## thread_info (setter)
  set thread_info(Object? thread_info) =>
      setAttribute("thread_info", thread_info);

  /// ## version (getter)
  Object? get version => getAttribute("version");

  /// ## version (setter)
  set version(Object? version) => setAttribute("version", version);

  /// ## version_info (getter)
  Object? get version_info => getAttribute("version_info");

  /// ## version_info (setter)
  set version_info(Object? version_info) =>
      setAttribute("version_info", version_info);

  /// ## warnoptions (getter)
  Object? get warnoptions => getAttribute("warnoptions");

  /// ## warnoptions (setter)
  set warnoptions(Object? warnoptions) =>
      setAttribute("warnoptions", warnoptions);
}

/// ## exceptions
///
/// ### python source
/// ```py
/// from .utils import logger, NO_VALUE
/// from typing import Mapping, Iterable, Callable, Union, TypeVar, Tuple, Any, List, Set, Optional, Collection, TYPE_CHECKING
///
/// if TYPE_CHECKING:
///     from .lexer import Token
///     from .parsers.lalr_interactive_parser import InteractiveParser
///     from .tree import Tree
///
/// ###{standalone
///
/// class LarkError(Exception):
///     pass
///
///
/// class ConfigurationError(LarkError, ValueError):
///     pass
///
///
/// def assert_config(value, options: Collection, msg='Got %r, expected one of %s'):
///     if value not in options:
///         raise ConfigurationError(msg % (value, options))
///
///
/// class GrammarError(LarkError):
///     pass
///
///
/// class ParseError(LarkError):
///     pass
///
///
/// class LexError(LarkError):
///     pass
///
/// T = TypeVar('T')
///
/// class UnexpectedInput(LarkError):
///     """UnexpectedInput Error.
///
///     Used as a base class for the following exceptions:
///
///     - ``UnexpectedCharacters``: The lexer encountered an unexpected string
///     - ``UnexpectedToken``: The parser received an unexpected token
///     - ``UnexpectedEOF``: The parser expected a token, but the input ended
///
///     After catching one of these exceptions, you may call the following helper methods to create a nicer error message.
///     """
///     line: int
///     column: int
///     pos_in_stream = None
///     state: Any
///     _terminals_by_name = None
///
///     def get_context(self, text: str, span: int=40) -> str:
///         """Returns a pretty string pinpointing the error in the text,
///         with span amount of context characters around it.
///
///         Note:
///             The parser doesn't hold a copy of the text it has to parse,
///             so you have to provide it again
///         """
///         assert self.pos_in_stream is not None, self
///         pos = self.pos_in_stream
///         start = max(pos - span, 0)
///         end = pos + span
///         if not isinstance(text, bytes):
///             before = text[start:pos].rsplit('\n', 1)[-1]
///             after = text[pos:end].split('\n', 1)[0]
///             return before + after + '\n' + ' ' * len(before.expandtabs()) + '^\n'
///         else:
///             before = text[start:pos].rsplit(b'\n', 1)[-1]
///             after = text[pos:end].split(b'\n', 1)[0]
///             return (before + after + b'\n' + b' ' * len(before.expandtabs()) + b'^\n').decode("ascii", "backslashreplace")
///
///     def match_examples(self, parse_fn: 'Callable[[str], Tree]',
///                              examples: Union[Mapping[T, Iterable[str]], Iterable[Tuple[T, Iterable[str]]]],
///                              token_type_match_fallback: bool=False,
///                              use_accepts: bool=True
///                          ) -> Optional[T]:
///         """Allows you to detect what's wrong in the input text by matching
///         against example errors.
///
///         Given a parser instance and a dictionary mapping some label with
///         some malformed syntax examples, it'll return the label for the
///         example that bests matches the current error. The function will
///         iterate the dictionary until it finds a matching error, and
///         return the corresponding value.
///
///         For an example usage, see `examples/error_reporting_lalr.py`
///
///         Parameters:
///             parse_fn: parse function (usually ``lark_instance.parse``)
///             examples: dictionary of ``{'example_string': value}``.
///             use_accepts: Recommended to keep this as ``use_accepts=True``.
///         """
///         assert self.state is not None, "Not supported for this exception"
///
///         if isinstance(examples, Mapping):
///             examples = examples.items()
///
///         candidate = (None, False)
///         for i, (label, example) in enumerate(examples):
///             assert not isinstance(example, str), "Expecting a list"
///
///             for j, malformed in enumerate(example):
///                 try:
///                     parse_fn(malformed)
///                 except UnexpectedInput as ut:
///                     if ut.state == self.state:
///                         if (
///                             use_accepts
///                             and isinstance(self, UnexpectedToken)
///                             and isinstance(ut, UnexpectedToken)
///                             and ut.accepts != self.accepts
///                         ):
///                             logger.debug("Different accepts with same state[%d]: %s != %s at example [%s][%s]" %
///                                          (self.state, self.accepts, ut.accepts, i, j))
///                             continue
///                         if (
///                             isinstance(self, (UnexpectedToken, UnexpectedEOF))
///                             and isinstance(ut, (UnexpectedToken, UnexpectedEOF))
///                         ):
///                             if ut.token == self.token:  # Try exact match first
///                                 logger.debug("Exact Match at example [%s][%s]" % (i, j))
///                                 return label
///
///                             if token_type_match_fallback:
///                                 # Fallback to token types match
///                                 if (ut.token.type == self.token.type) and not candidate[-1]:
///                                     logger.debug("Token Type Fallback at example [%s][%s]" % (i, j))
///                                     candidate = label, True
///
///                         if candidate[0] is None:
///                             logger.debug("Same State match at example [%s][%s]" % (i, j))
///                             candidate = label, False
///
///         return candidate[0]
///
///     def _format_expected(self, expected):
///         if self._terminals_by_name:
///             d = self._terminals_by_name
///             expected = [d[t_name].user_repr() if t_name in d else t_name for t_name in expected]
///         return "Expected one of: \n\t* %s\n" % '\n\t* '.join(expected)
///
///
/// class UnexpectedEOF(ParseError, UnexpectedInput):
///     """An exception that is raised by the parser, when the input ends while it still expects a token.
///     """
///     expected: 'List[Token]'
///
///     def __init__(self, expected, state=None, terminals_by_name=None):
///         super(UnexpectedEOF, self).__init__()
///
///         self.expected = expected
///         self.state = state
///         from .lexer import Token
///         self.token = Token("<EOF>", "")  # , line=-1, column=-1, pos_in_stream=-1)
///         self.pos_in_stream = -1
///         self.line = -1
///         self.column = -1
///         self._terminals_by_name = terminals_by_name
///
///
///     def __str__(self):
///         message = "Unexpected end-of-input. "
///         message += self._format_expected(self.expected)
///         return message
///
///
/// class UnexpectedCharacters(LexError, UnexpectedInput):
///     """An exception that is raised by the lexer, when it cannot match the next
///     string of characters to any of its terminals.
///     """
///
///     allowed: Set[str]
///     considered_tokens: Set[Any]
///
///     def __init__(self, seq, lex_pos, line, column, allowed=None, considered_tokens=None, state=None, token_history=None,
///                  terminals_by_name=None, considered_rules=None):
///         super(UnexpectedCharacters, self).__init__()
///
///         # TODO considered_tokens and allowed can be figured out using state
///         self.line = line
///         self.column = column
///         self.pos_in_stream = lex_pos
///         self.state = state
///         self._terminals_by_name = terminals_by_name
///
///         self.allowed = allowed
///         self.considered_tokens = considered_tokens
///         self.considered_rules = considered_rules
///         self.token_history = token_history
///
///         if isinstance(seq, bytes):
///             self.char = seq[lex_pos:lex_pos + 1].decode("ascii", "backslashreplace")
///         else:
///             self.char = seq[lex_pos]
///         self._context = self.get_context(seq)
///
///
///     def __str__(self):
///         message = "No terminal matches '%s' in the current parser context, at line %d col %d" % (self.char, self.line, self.column)
///         message += '\n\n' + self._context
///         if self.allowed:
///             message += self._format_expected(self.allowed)
///         if self.token_history:
///             message += '\nPrevious tokens: %s\n' % ', '.join(repr(t) for t in self.token_history)
///         return message
///
///
/// class UnexpectedToken(ParseError, UnexpectedInput):
///     """An exception that is raised by the parser, when the token it received
///     doesn't match any valid step forward.
///
///     Parameters:
///         token: The mismatched token
///         expected: The set of expected tokens
///         considered_rules: Which rules were considered, to deduce the expected tokens
///         state: A value representing the parser state. Do not rely on its value or type.
///         interactive_parser: An instance of ``InteractiveParser``, that is initialized to the point of failture,
///                             and can be used for debugging and error handling.
///
///     Note: These parameters are available as attributes of the instance.
///     """
///
///     expected: Set[str]
///     considered_rules: Set[str]
///     interactive_parser: 'InteractiveParser'
///
///     def __init__(self, token, expected, considered_rules=None, state=None, interactive_parser=None, terminals_by_name=None, token_history=None):
///         super(UnexpectedToken, self).__init__()
///
///         # TODO considered_rules and expected can be figured out using state
///         self.line = getattr(token, 'line', '?')
///         self.column = getattr(token, 'column', '?')
///         self.pos_in_stream = getattr(token, 'start_pos', None)
///         self.state = state
///
///         self.token = token
///         self.expected = expected  # XXX deprecate? `accepts` is better
///         self._accepts = NO_VALUE
///         self.considered_rules = considered_rules
///         self.interactive_parser = interactive_parser
///         self._terminals_by_name = terminals_by_name
///         self.token_history = token_history
///
///
///     @property
///     def accepts(self) -> Set[str]:
///         if self._accepts is NO_VALUE:
///             self._accepts = self.interactive_parser and self.interactive_parser.accepts()
///         return self._accepts
///
///     def __str__(self):
///         message = ("Unexpected token %r at line %s, column %s.\n%s"
///                    % (self.token, self.line, self.column, self._format_expected(self.accepts or self.expected)))
///         if self.token_history:
///             message += "Previous tokens: %r\n" % self.token_history
///
///         return message
///
///
///
/// class VisitError(LarkError):
///     """VisitError is raised when visitors are interrupted by an exception
///
///     It provides the following attributes for inspection:
///
///     Parameters:
///         rule: the name of the visit rule that failed
///         obj: the tree-node or token that was being processed
///         orig_exc: the exception that cause it to fail
///
///     Note: These parameters are available as attributes
///     """
///
///     obj: 'Union[Tree, Token]'
///     orig_exc: Exception
///
///     def __init__(self, rule, obj, orig_exc):
///         message = 'Error trying to process rule "%s":\n\n%s' % (rule, orig_exc)
///         super(VisitError, self).__init__(message)
///
///         self.rule = rule
///         self.obj = obj
///         self.orig_exc = orig_exc
///
///
/// class MissingVariableError(LarkError):
///     pass
///
/// ###}
/// ```
final class exceptions extends PythonModule {
  exceptions.from(super.pythonModule) : super.from();

  static exceptions import() => PythonFfiDart.instance.importModule(
        "lark.exceptions",
        exceptions.from,
      );

  /// ## assert_config
  ///
  /// ### python source
  /// ```py
  /// def assert_config(value, options: Collection, msg='Got %r, expected one of %s'):
  ///     if value not in options:
  ///         raise ConfigurationError(msg % (value, options))
  /// ```
  Object? assert_config({
    required Object? value,
    required Object? options,
    Object? msg = "Got %r, expected one of %s",
  }) =>
      getFunction("assert_config").call(
        <Object?>[
          value,
          options,
          msg,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## T (getter)
  ///
  /// ### python docstring
  ///
  /// Type variable.
  ///
  /// Usage::
  ///
  ///   T = TypeVar('T')  # Can be anything
  ///   A = TypeVar('A', str, bytes)  # Must be str or bytes
  ///
  /// Type variables exist primarily for the benefit of static type
  /// checkers.  They serve as the parameters for generic types as well
  /// as for generic function definitions.  See class Generic for more
  /// information on generic types.  Generic functions work as follows:
  ///
  ///   def repeat(x: T, n: int) -> List[T]:
  ///       '''Return a list containing n references to x.'''
  ///       return [x]*n
  ///
  ///   def longest(x: A, y: A) -> A:
  ///       '''Return the longest of two strings.'''
  ///       return x if len(x) >= len(y) else y
  ///
  /// The latter example's signature is essentially the overloading
  /// of (str, str) -> str and (bytes, bytes) -> bytes.  Also note
  /// that if the arguments are instances of some subclass of str,
  /// the return type is still plain str.
  ///
  /// At runtime, isinstance(x, T) and issubclass(C, T) will raise TypeError.
  ///
  /// Type variables defined with covariant=True or contravariant=True
  /// can be used to declare covariant or contravariant generic types.
  /// See PEP 484 for more details. By default generic types are invariant
  /// in all type variables.
  ///
  /// Type variables can be introspected. e.g.:
  ///
  ///   T.__name__ == 'T'
  ///   T.__constraints__ == ()
  ///   T.__covariant__ == False
  ///   T.__contravariant__ = False
  ///   A.__constraints__ == (str, bytes)
  ///
  /// Note that only type variables defined in global scope can be pickled.
  Object? get T => getAttribute("T");

  /// ## T (setter)
  ///
  /// ### python docstring
  ///
  /// Type variable.
  ///
  /// Usage::
  ///
  ///   T = TypeVar('T')  # Can be anything
  ///   A = TypeVar('A', str, bytes)  # Must be str or bytes
  ///
  /// Type variables exist primarily for the benefit of static type
  /// checkers.  They serve as the parameters for generic types as well
  /// as for generic function definitions.  See class Generic for more
  /// information on generic types.  Generic functions work as follows:
  ///
  ///   def repeat(x: T, n: int) -> List[T]:
  ///       '''Return a list containing n references to x.'''
  ///       return [x]*n
  ///
  ///   def longest(x: A, y: A) -> A:
  ///       '''Return the longest of two strings.'''
  ///       return x if len(x) >= len(y) else y
  ///
  /// The latter example's signature is essentially the overloading
  /// of (str, str) -> str and (bytes, bytes) -> bytes.  Also note
  /// that if the arguments are instances of some subclass of str,
  /// the return type is still plain str.
  ///
  /// At runtime, isinstance(x, T) and issubclass(C, T) will raise TypeError.
  ///
  /// Type variables defined with covariant=True or contravariant=True
  /// can be used to declare covariant or contravariant generic types.
  /// See PEP 484 for more details. By default generic types are invariant
  /// in all type variables.
  ///
  /// Type variables can be introspected. e.g.:
  ///
  ///   T.__name__ == 'T'
  ///   T.__constraints__ == ()
  ///   T.__covariant__ == False
  ///   T.__contravariant__ = False
  ///   A.__constraints__ == (str, bytes)
  ///
  /// Note that only type variables defined in global scope can be pickled.
  set T(Object? T) => setAttribute("T", T);

  /// ## TYPE_CHECKING (getter)
  Object? get TYPE_CHECKING => getAttribute("TYPE_CHECKING");

  /// ## TYPE_CHECKING (setter)
  set TYPE_CHECKING(Object? TYPE_CHECKING) =>
      setAttribute("TYPE_CHECKING", TYPE_CHECKING);
}

/// ## grammar
///
/// ### python source
/// ```py
/// from typing import Optional, Tuple, ClassVar
///
/// from .utils import Serialize
///
/// ###{standalone
/// TOKEN_DEFAULT_PRIORITY = 0
///
///
/// class Symbol(Serialize):
///     __slots__ = ('name',)
///
///     name: str
///     is_term: ClassVar[bool] = NotImplemented
///
///     def __init__(self, name: str) -> None:
///         self.name = name
///
///     def __eq__(self, other):
///         assert isinstance(other, Symbol), other
///         return self.is_term == other.is_term and self.name == other.name
///
///     def __ne__(self, other):
///         return not (self == other)
///
///     def __hash__(self):
///         return hash(self.name)
///
///     def __repr__(self):
///         return '%s(%r)' % (type(self).__name__, self.name)
///
///     fullrepr = property(__repr__)
///
///     def renamed(self, f):
///         return type(self)(f(self.name))
///
///
/// class Terminal(Symbol):
///     __serialize_fields__ = 'name', 'filter_out'
///
///     is_term: ClassVar[bool] = True
///
///     def __init__(self, name, filter_out=False):
///         self.name = name
///         self.filter_out = filter_out
///
///     @property
///     def fullrepr(self):
///         return '%s(%r, %r)' % (type(self).__name__, self.name, self.filter_out)
///
///     def renamed(self, f):
///         return type(self)(f(self.name), self.filter_out)
///
///
/// class NonTerminal(Symbol):
///     __serialize_fields__ = 'name',
///
///     is_term: ClassVar[bool] = False
///
///
/// class RuleOptions(Serialize):
///     __serialize_fields__ = 'keep_all_tokens', 'expand1', 'priority', 'template_source', 'empty_indices'
///
///     keep_all_tokens: bool
///     expand1: bool
///     priority: Optional[int]
///     template_source: Optional[str]
///     empty_indices: Tuple[bool, ...]
///
///     def __init__(self, keep_all_tokens: bool=False, expand1: bool=False, priority: Optional[int]=None, template_source: Optional[str]=None, empty_indices: Tuple[bool, ...]=()) -> None:
///         self.keep_all_tokens = keep_all_tokens
///         self.expand1 = expand1
///         self.priority = priority
///         self.template_source = template_source
///         self.empty_indices = empty_indices
///
///     def __repr__(self):
///         return 'RuleOptions(%r, %r, %r, %r)' % (
///             self.keep_all_tokens,
///             self.expand1,
///             self.priority,
///             self.template_source
///         )
///
///
/// class Rule(Serialize):
///     """
///         origin : a symbol
///         expansion : a list of symbols
///         order : index of this expansion amongst all rules of the same name
///     """
///     __slots__ = ('origin', 'expansion', 'alias', 'options', 'order', '_hash')
///
///     __serialize_fields__ = 'origin', 'expansion', 'order', 'alias', 'options'
///     __serialize_namespace__ = Terminal, NonTerminal, RuleOptions
///
///     def __init__(self, origin, expansion, order=0, alias=None, options=None):
///         self.origin = origin
///         self.expansion = expansion
///         self.alias = alias
///         self.order = order
///         self.options = options or RuleOptions()
///         self._hash = hash((self.origin, tuple(self.expansion)))
///
///     def _deserialize(self):
///         self._hash = hash((self.origin, tuple(self.expansion)))
///
///     def __str__(self):
///         return '<%s : %s>' % (self.origin.name, ' '.join(x.name for x in self.expansion))
///
///     def __repr__(self):
///         return 'Rule(%r, %r, %r, %r)' % (self.origin, self.expansion, self.alias, self.options)
///
///     def __hash__(self):
///         return self._hash
///
///     def __eq__(self, other):
///         if not isinstance(other, Rule):
///             return False
///         return self.origin == other.origin and self.expansion == other.expansion
///
///
/// ###}
/// ```
final class grammar extends PythonModule {
  grammar.from(super.pythonModule) : super.from();

  static grammar import() => PythonFfiDart.instance.importModule(
        "lark.grammar",
        grammar.from,
      );

  /// ## TOKEN_DEFAULT_PRIORITY (getter)
  Object? get TOKEN_DEFAULT_PRIORITY => getAttribute("TOKEN_DEFAULT_PRIORITY");

  /// ## TOKEN_DEFAULT_PRIORITY (setter)
  set TOKEN_DEFAULT_PRIORITY(Object? TOKEN_DEFAULT_PRIORITY) =>
      setAttribute("TOKEN_DEFAULT_PRIORITY", TOKEN_DEFAULT_PRIORITY);
}

/// ## getpass
///
/// ### python docstring
///
/// Utilities to get a password and/or the current user name.
///
/// getpass(prompt[, stream]) - Prompt for a password, with echo turned off.
/// getuser() - Get the user name from the environment or password database.
///
/// GetPassWarning - This UserWarning is issued when getpass() cannot prevent
///                  echoing of the password contents while reading.
///
/// On Windows, the msvcrt module will be used.
///
/// ### python source
/// ```py
/// """Utilities to get a password and/or the current user name.
///
/// getpass(prompt[, stream]) - Prompt for a password, with echo turned off.
/// getuser() - Get the user name from the environment or password database.
///
/// GetPassWarning - This UserWarning is issued when getpass() cannot prevent
///                  echoing of the password contents while reading.
///
/// On Windows, the msvcrt module will be used.
///
/// """
///
/// # Authors: Piers Lauder (original)
/// #          Guido van Rossum (Windows support and cleanup)
/// #          Gregory P. Smith (tty support & GetPassWarning)
///
/// import contextlib
/// import io
/// import os
/// import sys
/// import warnings
///
/// __all__ = ["getpass","getuser","GetPassWarning"]
///
///
/// class GetPassWarning(UserWarning): pass
///
///
/// def unix_getpass(prompt='Password: ', stream=None):
///     """Prompt for a password, with echo turned off.
///
///     Args:
///       prompt: Written on stream to ask for the input.  Default: 'Password: '
///       stream: A writable file object to display the prompt.  Defaults to
///               the tty.  If no tty is available defaults to sys.stderr.
///     Returns:
///       The seKr3t input.
///     Raises:
///       EOFError: If our input tty or stdin was closed.
///       GetPassWarning: When we were unable to turn echo off on the input.
///
///     Always restores terminal settings before returning.
///     """
///     passwd = None
///     with contextlib.ExitStack() as stack:
///         try:
///             # Always try reading and writing directly on the tty first.
///             fd = os.open('/dev/tty', os.O_RDWR|os.O_NOCTTY)
///             tty = io.FileIO(fd, 'w+')
///             stack.enter_context(tty)
///             input = io.TextIOWrapper(tty)
///             stack.enter_context(input)
///             if not stream:
///                 stream = input
///         except OSError:
///             # If that fails, see if stdin can be controlled.
///             stack.close()
///             try:
///                 fd = sys.stdin.fileno()
///             except (AttributeError, ValueError):
///                 fd = None
///                 passwd = fallback_getpass(prompt, stream)
///             input = sys.stdin
///             if not stream:
///                 stream = sys.stderr
///
///         if fd is not None:
///             try:
///                 old = termios.tcgetattr(fd)     # a copy to save
///                 new = old[:]
///                 new[3] &= ~termios.ECHO  # 3 == 'lflags'
///                 tcsetattr_flags = termios.TCSAFLUSH
///                 if hasattr(termios, 'TCSASOFT'):
///                     tcsetattr_flags |= termios.TCSASOFT
///                 try:
///                     termios.tcsetattr(fd, tcsetattr_flags, new)
///                     passwd = _raw_input(prompt, stream, input=input)
///                 finally:
///                     termios.tcsetattr(fd, tcsetattr_flags, old)
///                     stream.flush()  # issue7208
///             except termios.error:
///                 if passwd is not None:
///                     # _raw_input succeeded.  The final tcsetattr failed.  Reraise
///                     # instead of leaving the terminal in an unknown state.
///                     raise
///                 # We can't control the tty or stdin.  Give up and use normal IO.
///                 # fallback_getpass() raises an appropriate warning.
///                 if stream is not input:
///                     # clean up unused file objects before blocking
///                     stack.close()
///                 passwd = fallback_getpass(prompt, stream)
///
///         stream.write('\n')
///         return passwd
///
///
/// def win_getpass(prompt='Password: ', stream=None):
///     """Prompt for password with echo off, using Windows getwch()."""
///     if sys.stdin is not sys.__stdin__:
///         return fallback_getpass(prompt, stream)
///
///     for c in prompt:
///         msvcrt.putwch(c)
///     pw = ""
///     while 1:
///         c = msvcrt.getwch()
///         if c == '\r' or c == '\n':
///             break
///         if c == '\003':
///             raise KeyboardInterrupt
///         if c == '\b':
///             pw = pw[:-1]
///         else:
///             pw = pw + c
///     msvcrt.putwch('\r')
///     msvcrt.putwch('\n')
///     return pw
///
///
/// def fallback_getpass(prompt='Password: ', stream=None):
///     warnings.warn("Can not control echo on the terminal.", GetPassWarning,
///                   stacklevel=2)
///     if not stream:
///         stream = sys.stderr
///     print("Warning: Password input may be echoed.", file=stream)
///     return _raw_input(prompt, stream)
///
///
/// def _raw_input(prompt="", stream=None, input=None):
///     # This doesn't save the string in the GNU readline history.
///     if not stream:
///         stream = sys.stderr
///     if not input:
///         input = sys.stdin
///     prompt = str(prompt)
///     if prompt:
///         try:
///             stream.write(prompt)
///         except UnicodeEncodeError:
///             # Use replace error handler to get as much as possible printed.
///             prompt = prompt.encode(stream.encoding, 'replace')
///             prompt = prompt.decode(stream.encoding)
///             stream.write(prompt)
///         stream.flush()
///     # NOTE: The Python C API calls flockfile() (and unlock) during readline.
///     line = input.readline()
///     if not line:
///         raise EOFError
///     if line[-1] == '\n':
///         line = line[:-1]
///     return line
///
///
/// def getuser():
///     """Get the username from the environment or password database.
///
///     First try various environment variables, then the password
///     database.  This works on Windows as long as USERNAME is set.
///
///     """
///
///     for name in ('LOGNAME', 'USER', 'LNAME', 'USERNAME'):
///         user = os.environ.get(name)
///         if user:
///             return user
///
///     # If this fails, the exception will "explain" why
///     import pwd
///     return pwd.getpwuid(os.getuid())[0]
///
/// # Bind the name getpass to the appropriate function
/// try:
///     import termios
///     # it's possible there is an incompatible termios from the
///     # McMillan Installer, make sure we have a UNIX-compatible termios
///     termios.tcgetattr, termios.tcsetattr
/// except (ImportError, AttributeError):
///     try:
///         import msvcrt
///     except ImportError:
///         getpass = fallback_getpass
///     else:
///         getpass = win_getpass
/// else:
///     getpass = unix_getpass
/// ```
final class getpass extends PythonModule {
  getpass.from(super.pythonModule) : super.from();

  static getpass import() => PythonFfiDart.instance.importModule(
        "getpass",
        getpass.from,
      );

  /// ## fallback_getpass
  ///
  /// ### python source
  /// ```py
  /// def fallback_getpass(prompt='Password: ', stream=None):
  ///     warnings.warn("Can not control echo on the terminal.", GetPassWarning,
  ///                   stacklevel=2)
  ///     if not stream:
  ///         stream = sys.stderr
  ///     print("Warning: Password input may be echoed.", file=stream)
  ///     return _raw_input(prompt, stream)
  /// ```
  Object? fallback_getpass({
    Object? prompt = "Password: ",
    Object? stream,
  }) =>
      getFunction("fallback_getpass").call(
        <Object?>[
          prompt,
          stream,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## getuser
  ///
  /// ### python docstring
  ///
  /// Get the username from the environment or password database.
  ///
  /// First try various environment variables, then the password
  /// database.  This works on Windows as long as USERNAME is set.
  ///
  /// ### python source
  /// ```py
  /// def getuser():
  ///     """Get the username from the environment or password database.
  ///
  ///     First try various environment variables, then the password
  ///     database.  This works on Windows as long as USERNAME is set.
  ///
  ///     """
  ///
  ///     for name in ('LOGNAME', 'USER', 'LNAME', 'USERNAME'):
  ///         user = os.environ.get(name)
  ///         if user:
  ///             return user
  ///
  ///     # If this fails, the exception will "explain" why
  ///     import pwd
  ///     return pwd.getpwuid(os.getuid())[0]
  /// ```
  Object? getuser() => getFunction("getuser").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## win_getpass
  ///
  /// ### python docstring
  ///
  /// Prompt for password with echo off, using Windows getwch().
  ///
  /// ### python source
  /// ```py
  /// def win_getpass(prompt='Password: ', stream=None):
  ///     """Prompt for password with echo off, using Windows getwch()."""
  ///     if sys.stdin is not sys.__stdin__:
  ///         return fallback_getpass(prompt, stream)
  ///
  ///     for c in prompt:
  ///         msvcrt.putwch(c)
  ///     pw = ""
  ///     while 1:
  ///         c = msvcrt.getwch()
  ///         if c == '\r' or c == '\n':
  ///             break
  ///         if c == '\003':
  ///             raise KeyboardInterrupt
  ///         if c == '\b':
  ///             pw = pw[:-1]
  ///         else:
  ///             pw = pw + c
  ///     msvcrt.putwch('\r')
  ///     msvcrt.putwch('\n')
  ///     return pw
  /// ```
  Object? win_getpass({
    Object? prompt = "Password: ",
    Object? stream,
  }) =>
      getFunction("win_getpass").call(
        <Object?>[
          prompt,
          stream,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## contextlib
///
/// ### python docstring
///
/// Utilities for with-statement contexts.  See PEP 343.
///
/// ### python source
/// ```py
/// """Utilities for with-statement contexts.  See PEP 343."""
/// import abc
/// import os
/// import sys
/// import _collections_abc
/// from collections import deque
/// from functools import wraps
/// from types import MethodType, GenericAlias
///
/// __all__ = ["asynccontextmanager", "contextmanager", "closing", "nullcontext",
///            "AbstractContextManager", "AbstractAsyncContextManager",
///            "AsyncExitStack", "ContextDecorator", "ExitStack",
///            "redirect_stdout", "redirect_stderr", "suppress", "aclosing",
///            "chdir"]
///
///
/// class AbstractContextManager(abc.ABC):
///
///     """An abstract base class for context managers."""
///
///     __class_getitem__ = classmethod(GenericAlias)
///
///     def __enter__(self):
///         """Return `self` upon entering the runtime context."""
///         return self
///
///     @abc.abstractmethod
///     def __exit__(self, exc_type, exc_value, traceback):
///         """Raise any exception triggered within the runtime context."""
///         return None
///
///     @classmethod
///     def __subclasshook__(cls, C):
///         if cls is AbstractContextManager:
///             return _collections_abc._check_methods(C, "__enter__", "__exit__")
///         return NotImplemented
///
///
/// class AbstractAsyncContextManager(abc.ABC):
///
///     """An abstract base class for asynchronous context managers."""
///
///     __class_getitem__ = classmethod(GenericAlias)
///
///     async def __aenter__(self):
///         """Return `self` upon entering the runtime context."""
///         return self
///
///     @abc.abstractmethod
///     async def __aexit__(self, exc_type, exc_value, traceback):
///         """Raise any exception triggered within the runtime context."""
///         return None
///
///     @classmethod
///     def __subclasshook__(cls, C):
///         if cls is AbstractAsyncContextManager:
///             return _collections_abc._check_methods(C, "__aenter__",
///                                                    "__aexit__")
///         return NotImplemented
///
///
/// class ContextDecorator(object):
///     "A base class or mixin that enables context managers to work as decorators."
///
///     def _recreate_cm(self):
///         """Return a recreated instance of self.
///
///         Allows an otherwise one-shot context manager like
///         _GeneratorContextManager to support use as
///         a decorator via implicit recreation.
///
///         This is a private interface just for _GeneratorContextManager.
///         See issue #11647 for details.
///         """
///         return self
///
///     def __call__(self, func):
///         @wraps(func)
///         def inner(*args, **kwds):
///             with self._recreate_cm():
///                 return func(*args, **kwds)
///         return inner
///
///
/// class AsyncContextDecorator(object):
///     "A base class or mixin that enables async context managers to work as decorators."
///
///     def _recreate_cm(self):
///         """Return a recreated instance of self.
///         """
///         return self
///
///     def __call__(self, func):
///         @wraps(func)
///         async def inner(*args, **kwds):
///             async with self._recreate_cm():
///                 return await func(*args, **kwds)
///         return inner
///
///
/// class _GeneratorContextManagerBase:
///     """Shared functionality for @contextmanager and @asynccontextmanager."""
///
///     def __init__(self, func, args, kwds):
///         self.gen = func(*args, **kwds)
///         self.func, self.args, self.kwds = func, args, kwds
///         # Issue 19330: ensure context manager instances have good docstrings
///         doc = getattr(func, "__doc__", None)
///         if doc is None:
///             doc = type(self).__doc__
///         self.__doc__ = doc
///         # Unfortunately, this still doesn't provide good help output when
///         # inspecting the created context manager instances, since pydoc
///         # currently bypasses the instance docstring and shows the docstring
///         # for the class instead.
///         # See http://bugs.python.org/issue19404 for more details.
///
///     def _recreate_cm(self):
///         # _GCMB instances are one-shot context managers, so the
///         # CM must be recreated each time a decorated function is
///         # called
///         return self.__class__(self.func, self.args, self.kwds)
///
///
/// class _GeneratorContextManager(
///     _GeneratorContextManagerBase,
///     AbstractContextManager,
///     ContextDecorator,
/// ):
///     """Helper for @contextmanager decorator."""
///
///     def __enter__(self):
///         # do not keep args and kwds alive unnecessarily
///         # they are only needed for recreation, which is not possible anymore
///         del self.args, self.kwds, self.func
///         try:
///             return next(self.gen)
///         except StopIteration:
///             raise RuntimeError("generator didn't yield") from None
///
///     def __exit__(self, typ, value, traceback):
///         if typ is None:
///             try:
///                 next(self.gen)
///             except StopIteration:
///                 return False
///             else:
///                 raise RuntimeError("generator didn't stop")
///         else:
///             if value is None:
///                 # Need to force instantiation so we can reliably
///                 # tell if we get the same exception back
///                 value = typ()
///             try:
///                 self.gen.throw(typ, value, traceback)
///             except StopIteration as exc:
///                 # Suppress StopIteration *unless* it's the same exception that
///                 # was passed to throw().  This prevents a StopIteration
///                 # raised inside the "with" statement from being suppressed.
///                 return exc is not value
///             except RuntimeError as exc:
///                 # Don't re-raise the passed in exception. (issue27122)
///                 if exc is value:
///                     exc.__traceback__ = traceback
///                     return False
///                 # Avoid suppressing if a StopIteration exception
///                 # was passed to throw() and later wrapped into a RuntimeError
///                 # (see PEP 479 for sync generators; async generators also
///                 # have this behavior). But do this only if the exception wrapped
///                 # by the RuntimeError is actually Stop(Async)Iteration (see
///                 # issue29692).
///                 if (
///                     isinstance(value, StopIteration)
///                     and exc.__cause__ is value
///                 ):
///                     value.__traceback__ = traceback
///                     return False
///                 raise
///             except BaseException as exc:
///                 # only re-raise if it's *not* the exception that was
///                 # passed to throw(), because __exit__() must not raise
///                 # an exception unless __exit__() itself failed.  But throw()
///                 # has to raise the exception to signal propagation, so this
///                 # fixes the impedance mismatch between the throw() protocol
///                 # and the __exit__() protocol.
///                 if exc is not value:
///                     raise
///                 exc.__traceback__ = traceback
///                 return False
///             raise RuntimeError("generator didn't stop after throw()")
///
/// class _AsyncGeneratorContextManager(
///     _GeneratorContextManagerBase,
///     AbstractAsyncContextManager,
///     AsyncContextDecorator,
/// ):
///     """Helper for @asynccontextmanager decorator."""
///
///     async def __aenter__(self):
///         # do not keep args and kwds alive unnecessarily
///         # they are only needed for recreation, which is not possible anymore
///         del self.args, self.kwds, self.func
///         try:
///             return await anext(self.gen)
///         except StopAsyncIteration:
///             raise RuntimeError("generator didn't yield") from None
///
///     async def __aexit__(self, typ, value, traceback):
///         if typ is None:
///             try:
///                 await anext(self.gen)
///             except StopAsyncIteration:
///                 return False
///             else:
///                 raise RuntimeError("generator didn't stop")
///         else:
///             if value is None:
///                 # Need to force instantiation so we can reliably
///                 # tell if we get the same exception back
///                 value = typ()
///             try:
///                 await self.gen.athrow(typ, value, traceback)
///             except StopAsyncIteration as exc:
///                 # Suppress StopIteration *unless* it's the same exception that
///                 # was passed to throw().  This prevents a StopIteration
///                 # raised inside the "with" statement from being suppressed.
///                 return exc is not value
///             except RuntimeError as exc:
///                 # Don't re-raise the passed in exception. (issue27122)
///                 if exc is value:
///                     exc.__traceback__ = traceback
///                     return False
///                 # Avoid suppressing if a Stop(Async)Iteration exception
///                 # was passed to athrow() and later wrapped into a RuntimeError
///                 # (see PEP 479 for sync generators; async generators also
///                 # have this behavior). But do this only if the exception wrapped
///                 # by the RuntimeError is actually Stop(Async)Iteration (see
///                 # issue29692).
///                 if (
///                     isinstance(value, (StopIteration, StopAsyncIteration))
///                     and exc.__cause__ is value
///                 ):
///                     value.__traceback__ = traceback
///                     return False
///                 raise
///             except BaseException as exc:
///                 # only re-raise if it's *not* the exception that was
///                 # passed to throw(), because __exit__() must not raise
///                 # an exception unless __exit__() itself failed.  But throw()
///                 # has to raise the exception to signal propagation, so this
///                 # fixes the impedance mismatch between the throw() protocol
///                 # and the __exit__() protocol.
///                 if exc is not value:
///                     raise
///                 exc.__traceback__ = traceback
///                 return False
///             raise RuntimeError("generator didn't stop after athrow()")
///
///
/// def contextmanager(func):
///     """@contextmanager decorator.
///
///     Typical usage:
///
///         @contextmanager
///         def some_generator(<arguments>):
///             <setup>
///             try:
///                 yield <value>
///             finally:
///                 <cleanup>
///
///     This makes this:
///
///         with some_generator(<arguments>) as <variable>:
///             <body>
///
///     equivalent to this:
///
///         <setup>
///         try:
///             <variable> = <value>
///             <body>
///         finally:
///             <cleanup>
///     """
///     @wraps(func)
///     def helper(*args, **kwds):
///         return _GeneratorContextManager(func, args, kwds)
///     return helper
///
///
/// def asynccontextmanager(func):
///     """@asynccontextmanager decorator.
///
///     Typical usage:
///
///         @asynccontextmanager
///         async def some_async_generator(<arguments>):
///             <setup>
///             try:
///                 yield <value>
///             finally:
///                 <cleanup>
///
///     This makes this:
///
///         async with some_async_generator(<arguments>) as <variable>:
///             <body>
///
///     equivalent to this:
///
///         <setup>
///         try:
///             <variable> = <value>
///             <body>
///         finally:
///             <cleanup>
///     """
///     @wraps(func)
///     def helper(*args, **kwds):
///         return _AsyncGeneratorContextManager(func, args, kwds)
///     return helper
///
///
/// class closing(AbstractContextManager):
///     """Context to automatically close something at the end of a block.
///
///     Code like this:
///
///         with closing(<module>.open(<arguments>)) as f:
///             <block>
///
///     is equivalent to this:
///
///         f = <module>.open(<arguments>)
///         try:
///             <block>
///         finally:
///             f.close()
///
///     """
///     def __init__(self, thing):
///         self.thing = thing
///     def __enter__(self):
///         return self.thing
///     def __exit__(self, *exc_info):
///         self.thing.close()
///
///
/// class aclosing(AbstractAsyncContextManager):
///     """Async context manager for safely finalizing an asynchronously cleaned-up
///     resource such as an async generator, calling its ``aclose()`` method.
///
///     Code like this:
///
///         async with aclosing(<module>.fetch(<arguments>)) as agen:
///             <block>
///
///     is equivalent to this:
///
///         agen = <module>.fetch(<arguments>)
///         try:
///             <block>
///         finally:
///             await agen.aclose()
///
///     """
///     def __init__(self, thing):
///         self.thing = thing
///     async def __aenter__(self):
///         return self.thing
///     async def __aexit__(self, *exc_info):
///         await self.thing.aclose()
///
///
/// class _RedirectStream(AbstractContextManager):
///
///     _stream = None
///
///     def __init__(self, new_target):
///         self._new_target = new_target
///         # We use a list of old targets to make this CM re-entrant
///         self._old_targets = []
///
///     def __enter__(self):
///         self._old_targets.append(getattr(sys, self._stream))
///         setattr(sys, self._stream, self._new_target)
///         return self._new_target
///
///     def __exit__(self, exctype, excinst, exctb):
///         setattr(sys, self._stream, self._old_targets.pop())
///
///
/// class redirect_stdout(_RedirectStream):
///     """Context manager for temporarily redirecting stdout to another file.
///
///         # How to send help() to stderr
///         with redirect_stdout(sys.stderr):
///             help(dir)
///
///         # How to write help() to a file
///         with open('help.txt', 'w') as f:
///             with redirect_stdout(f):
///                 help(pow)
///     """
///
///     _stream = "stdout"
///
///
/// class redirect_stderr(_RedirectStream):
///     """Context manager for temporarily redirecting stderr to another file."""
///
///     _stream = "stderr"
///
///
/// class suppress(AbstractContextManager):
///     """Context manager to suppress specified exceptions
///
///     After the exception is suppressed, execution proceeds with the next
///     statement following the with statement.
///
///          with suppress(FileNotFoundError):
///              os.remove(somefile)
///          # Execution still resumes here if the file was already removed
///     """
///
///     def __init__(self, *exceptions):
///         self._exceptions = exceptions
///
///     def __enter__(self):
///         pass
///
///     def __exit__(self, exctype, excinst, exctb):
///         # Unlike isinstance and issubclass, CPython exception handling
///         # currently only looks at the concrete type hierarchy (ignoring
///         # the instance and subclass checking hooks). While Guido considers
///         # that a bug rather than a feature, it's a fairly hard one to fix
///         # due to various internal implementation details. suppress provides
///         # the simpler issubclass based semantics, rather than trying to
///         # exactly reproduce the limitations of the CPython interpreter.
///         #
///         # See http://bugs.python.org/issue12029 for more details
///         return exctype is not None and issubclass(exctype, self._exceptions)
///
///
/// class _BaseExitStack:
///     """A base class for ExitStack and AsyncExitStack."""
///
///     @staticmethod
///     def _create_exit_wrapper(cm, cm_exit):
///         return MethodType(cm_exit, cm)
///
///     @staticmethod
///     def _create_cb_wrapper(callback, /, *args, **kwds):
///         def _exit_wrapper(exc_type, exc, tb):
///             callback(*args, **kwds)
///         return _exit_wrapper
///
///     def __init__(self):
///         self._exit_callbacks = deque()
///
///     def pop_all(self):
///         """Preserve the context stack by transferring it to a new instance."""
///         new_stack = type(self)()
///         new_stack._exit_callbacks = self._exit_callbacks
///         self._exit_callbacks = deque()
///         return new_stack
///
///     def push(self, exit):
///         """Registers a callback with the standard __exit__ method signature.
///
///         Can suppress exceptions the same way __exit__ method can.
///         Also accepts any object with an __exit__ method (registering a call
///         to the method instead of the object itself).
///         """
///         # We use an unbound method rather than a bound method to follow
///         # the standard lookup behaviour for special methods.
///         _cb_type = type(exit)
///
///         try:
///             exit_method = _cb_type.__exit__
///         except AttributeError:
///             # Not a context manager, so assume it's a callable.
///             self._push_exit_callback(exit)
///         else:
///             self._push_cm_exit(exit, exit_method)
///         return exit  # Allow use as a decorator.
///
///     def enter_context(self, cm):
///         """Enters the supplied context manager.
///
///         If successful, also pushes its __exit__ method as a callback and
///         returns the result of the __enter__ method.
///         """
///         # We look up the special methods on the type to match the with
///         # statement.
///         cls = type(cm)
///         try:
///             _enter = cls.__enter__
///             _exit = cls.__exit__
///         except AttributeError:
///             raise TypeError(f"'{cls.__module__}.{cls.__qualname__}' object does "
///                             f"not support the context manager protocol") from None
///         result = _enter(cm)
///         self._push_cm_exit(cm, _exit)
///         return result
///
///     def callback(self, callback, /, *args, **kwds):
///         """Registers an arbitrary callback and arguments.
///
///         Cannot suppress exceptions.
///         """
///         _exit_wrapper = self._create_cb_wrapper(callback, *args, **kwds)
///
///         # We changed the signature, so using @wraps is not appropriate, but
///         # setting __wrapped__ may still help with introspection.
///         _exit_wrapper.__wrapped__ = callback
///         self._push_exit_callback(_exit_wrapper)
///         return callback  # Allow use as a decorator
///
///     def _push_cm_exit(self, cm, cm_exit):
///         """Helper to correctly register callbacks to __exit__ methods."""
///         _exit_wrapper = self._create_exit_wrapper(cm, cm_exit)
///         self._push_exit_callback(_exit_wrapper, True)
///
///     def _push_exit_callback(self, callback, is_sync=True):
///         self._exit_callbacks.append((is_sync, callback))
///
///
/// # Inspired by discussions on http://bugs.python.org/issue13585
/// class ExitStack(_BaseExitStack, AbstractContextManager):
///     """Context manager for dynamic management of a stack of exit callbacks.
///
///     For example:
///         with ExitStack() as stack:
///             files = [stack.enter_context(open(fname)) for fname in filenames]
///             # All opened files will automatically be closed at the end of
///             # the with statement, even if attempts to open files later
///             # in the list raise an exception.
///     """
///
///     def __enter__(self):
///         return self
///
///     def __exit__(self, *exc_details):
///         received_exc = exc_details[0] is not None
///
///         # We manipulate the exception state so it behaves as though
///         # we were actually nesting multiple with statements
///         frame_exc = sys.exc_info()[1]
///         def _fix_exception_context(new_exc, old_exc):
///             # Context may not be correct, so find the end of the chain
///             while 1:
///                 exc_context = new_exc.__context__
///                 if exc_context is None or exc_context is old_exc:
///                     # Context is already set correctly (see issue 20317)
///                     return
///                 if exc_context is frame_exc:
///                     break
///                 new_exc = exc_context
///             # Change the end of the chain to point to the exception
///             # we expect it to reference
///             new_exc.__context__ = old_exc
///
///         # Callbacks are invoked in LIFO order to match the behaviour of
///         # nested context managers
///         suppressed_exc = False
///         pending_raise = False
///         while self._exit_callbacks:
///             is_sync, cb = self._exit_callbacks.pop()
///             assert is_sync
///             try:
///                 if cb(*exc_details):
///                     suppressed_exc = True
///                     pending_raise = False
///                     exc_details = (None, None, None)
///             except:
///                 new_exc_details = sys.exc_info()
///                 # simulate the stack of exceptions by setting the context
///                 _fix_exception_context(new_exc_details[1], exc_details[1])
///                 pending_raise = True
///                 exc_details = new_exc_details
///         if pending_raise:
///             try:
///                 # bare "raise exc_details[1]" replaces our carefully
///                 # set-up context
///                 fixed_ctx = exc_details[1].__context__
///                 raise exc_details[1]
///             except BaseException:
///                 exc_details[1].__context__ = fixed_ctx
///                 raise
///         return received_exc and suppressed_exc
///
///     def close(self):
///         """Immediately unwind the context stack."""
///         self.__exit__(None, None, None)
///
///
/// # Inspired by discussions on https://bugs.python.org/issue29302
/// class AsyncExitStack(_BaseExitStack, AbstractAsyncContextManager):
///     """Async context manager for dynamic management of a stack of exit
///     callbacks.
///
///     For example:
///         async with AsyncExitStack() as stack:
///             connections = [await stack.enter_async_context(get_connection())
///                 for i in range(5)]
///             # All opened connections will automatically be released at the
///             # end of the async with statement, even if attempts to open a
///             # connection later in the list raise an exception.
///     """
///
///     @staticmethod
///     def _create_async_exit_wrapper(cm, cm_exit):
///         return MethodType(cm_exit, cm)
///
///     @staticmethod
///     def _create_async_cb_wrapper(callback, /, *args, **kwds):
///         async def _exit_wrapper(exc_type, exc, tb):
///             await callback(*args, **kwds)
///         return _exit_wrapper
///
///     async def enter_async_context(self, cm):
///         """Enters the supplied async context manager.
///
///         If successful, also pushes its __aexit__ method as a callback and
///         returns the result of the __aenter__ method.
///         """
///         cls = type(cm)
///         try:
///             _enter = cls.__aenter__
///             _exit = cls.__aexit__
///         except AttributeError:
///             raise TypeError(f"'{cls.__module__}.{cls.__qualname__}' object does "
///                             f"not support the asynchronous context manager protocol"
///                            ) from None
///         result = await _enter(cm)
///         self._push_async_cm_exit(cm, _exit)
///         return result
///
///     def push_async_exit(self, exit):
///         """Registers a coroutine function with the standard __aexit__ method
///         signature.
///
///         Can suppress exceptions the same way __aexit__ method can.
///         Also accepts any object with an __aexit__ method (registering a call
///         to the method instead of the object itself).
///         """
///         _cb_type = type(exit)
///         try:
///             exit_method = _cb_type.__aexit__
///         except AttributeError:
///             # Not an async context manager, so assume it's a coroutine function
///             self._push_exit_callback(exit, False)
///         else:
///             self._push_async_cm_exit(exit, exit_method)
///         return exit  # Allow use as a decorator
///
///     def push_async_callback(self, callback, /, *args, **kwds):
///         """Registers an arbitrary coroutine function and arguments.
///
///         Cannot suppress exceptions.
///         """
///         _exit_wrapper = self._create_async_cb_wrapper(callback, *args, **kwds)
///
///         # We changed the signature, so using @wraps is not appropriate, but
///         # setting __wrapped__ may still help with introspection.
///         _exit_wrapper.__wrapped__ = callback
///         self._push_exit_callback(_exit_wrapper, False)
///         return callback  # Allow use as a decorator
///
///     async def aclose(self):
///         """Immediately unwind the context stack."""
///         await self.__aexit__(None, None, None)
///
///     def _push_async_cm_exit(self, cm, cm_exit):
///         """Helper to correctly register coroutine function to __aexit__
///         method."""
///         _exit_wrapper = self._create_async_exit_wrapper(cm, cm_exit)
///         self._push_exit_callback(_exit_wrapper, False)
///
///     async def __aenter__(self):
///         return self
///
///     async def __aexit__(self, *exc_details):
///         received_exc = exc_details[0] is not None
///
///         # We manipulate the exception state so it behaves as though
///         # we were actually nesting multiple with statements
///         frame_exc = sys.exc_info()[1]
///         def _fix_exception_context(new_exc, old_exc):
///             # Context may not be correct, so find the end of the chain
///             while 1:
///                 exc_context = new_exc.__context__
///                 if exc_context is None or exc_context is old_exc:
///                     # Context is already set correctly (see issue 20317)
///                     return
///                 if exc_context is frame_exc:
///                     break
///                 new_exc = exc_context
///             # Change the end of the chain to point to the exception
///             # we expect it to reference
///             new_exc.__context__ = old_exc
///
///         # Callbacks are invoked in LIFO order to match the behaviour of
///         # nested context managers
///         suppressed_exc = False
///         pending_raise = False
///         while self._exit_callbacks:
///             is_sync, cb = self._exit_callbacks.pop()
///             try:
///                 if is_sync:
///                     cb_suppress = cb(*exc_details)
///                 else:
///                     cb_suppress = await cb(*exc_details)
///
///                 if cb_suppress:
///                     suppressed_exc = True
///                     pending_raise = False
///                     exc_details = (None, None, None)
///             except:
///                 new_exc_details = sys.exc_info()
///                 # simulate the stack of exceptions by setting the context
///                 _fix_exception_context(new_exc_details[1], exc_details[1])
///                 pending_raise = True
///                 exc_details = new_exc_details
///         if pending_raise:
///             try:
///                 # bare "raise exc_details[1]" replaces our carefully
///                 # set-up context
///                 fixed_ctx = exc_details[1].__context__
///                 raise exc_details[1]
///             except BaseException:
///                 exc_details[1].__context__ = fixed_ctx
///                 raise
///         return received_exc and suppressed_exc
///
///
/// class nullcontext(AbstractContextManager, AbstractAsyncContextManager):
///     """Context manager that does no additional processing.
///
///     Used as a stand-in for a normal context manager, when a particular
///     block of code is only sometimes used with a normal context manager:
///
///     cm = optional_cm if condition else nullcontext()
///     with cm:
///         # Perform operation, using optional_cm if condition is True
///     """
///
///     def __init__(self, enter_result=None):
///         self.enter_result = enter_result
///
///     def __enter__(self):
///         return self.enter_result
///
///     def __exit__(self, *excinfo):
///         pass
///
///     async def __aenter__(self):
///         return self.enter_result
///
///     async def __aexit__(self, *excinfo):
///         pass
///
///
/// class chdir(AbstractContextManager):
///     """Non thread-safe context manager to change the current working directory."""
///
///     def __init__(self, path):
///         self.path = path
///         self._old_cwd = []
///
///     def __enter__(self):
///         self._old_cwd.append(os.getcwd())
///         os.chdir(self.path)
///
///     def __exit__(self, *excinfo):
///         os.chdir(self._old_cwd.pop())
/// ```
final class contextlib extends PythonModule {
  contextlib.from(super.pythonModule) : super.from();

  static contextlib import() => PythonFfiDart.instance.importModule(
        "contextlib",
        contextlib.from,
      );

  /// ## asynccontextmanager
  ///
  /// ### python docstring
  ///
  /// @asynccontextmanager decorator.
  ///
  /// Typical usage:
  ///
  ///     @asynccontextmanager
  ///     async def some_async_generator(<arguments>):
  ///         <setup>
  ///         try:
  ///             yield <value>
  ///         finally:
  ///             <cleanup>
  ///
  /// This makes this:
  ///
  ///     async with some_async_generator(<arguments>) as <variable>:
  ///         <body>
  ///
  /// equivalent to this:
  ///
  ///     <setup>
  ///     try:
  ///         <variable> = <value>
  ///         <body>
  ///     finally:
  ///         <cleanup>
  ///
  /// ### python source
  /// ```py
  /// def asynccontextmanager(func):
  ///     """@asynccontextmanager decorator.
  ///
  ///     Typical usage:
  ///
  ///         @asynccontextmanager
  ///         async def some_async_generator(<arguments>):
  ///             <setup>
  ///             try:
  ///                 yield <value>
  ///             finally:
  ///                 <cleanup>
  ///
  ///     This makes this:
  ///
  ///         async with some_async_generator(<arguments>) as <variable>:
  ///             <body>
  ///
  ///     equivalent to this:
  ///
  ///         <setup>
  ///         try:
  ///             <variable> = <value>
  ///             <body>
  ///         finally:
  ///             <cleanup>
  ///     """
  ///     @wraps(func)
  ///     def helper(*args, **kwds):
  ///         return _AsyncGeneratorContextManager(func, args, kwds)
  ///     return helper
  /// ```
  Object? asynccontextmanager({
    required Object? func,
  }) =>
      getFunction("asynccontextmanager").call(
        <Object?>[
          func,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## contextmanager
  ///
  /// ### python docstring
  ///
  /// @contextmanager decorator.
  ///
  /// Typical usage:
  ///
  ///     @contextmanager
  ///     def some_generator(<arguments>):
  ///         <setup>
  ///         try:
  ///             yield <value>
  ///         finally:
  ///             <cleanup>
  ///
  /// This makes this:
  ///
  ///     with some_generator(<arguments>) as <variable>:
  ///         <body>
  ///
  /// equivalent to this:
  ///
  ///     <setup>
  ///     try:
  ///         <variable> = <value>
  ///         <body>
  ///     finally:
  ///         <cleanup>
  ///
  /// ### python source
  /// ```py
  /// def contextmanager(func):
  ///     """@contextmanager decorator.
  ///
  ///     Typical usage:
  ///
  ///         @contextmanager
  ///         def some_generator(<arguments>):
  ///             <setup>
  ///             try:
  ///                 yield <value>
  ///             finally:
  ///                 <cleanup>
  ///
  ///     This makes this:
  ///
  ///         with some_generator(<arguments>) as <variable>:
  ///             <body>
  ///
  ///     equivalent to this:
  ///
  ///         <setup>
  ///         try:
  ///             <variable> = <value>
  ///             <body>
  ///         finally:
  ///             <cleanup>
  ///     """
  ///     @wraps(func)
  ///     def helper(*args, **kwds):
  ///         return _GeneratorContextManager(func, args, kwds)
  ///     return helper
  /// ```
  Object? contextmanager({
    required Object? func,
  }) =>
      getFunction("contextmanager").call(
        <Object?>[
          func,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## abc
///
/// ### python docstring
///
/// Abstract Base Classes (ABCs) according to PEP 3119.
///
/// ### python source
/// ```py
/// # Copyright 2007 Google, Inc. All Rights Reserved.
/// # Licensed to PSF under a Contributor Agreement.
///
/// """Abstract Base Classes (ABCs) according to PEP 3119."""
///
///
/// def abstractmethod(funcobj):
///     """A decorator indicating abstract methods.
///
///     Requires that the metaclass is ABCMeta or derived from it.  A
///     class that has a metaclass derived from ABCMeta cannot be
///     instantiated unless all of its abstract methods are overridden.
///     The abstract methods can be called using any of the normal
///     'super' call mechanisms.  abstractmethod() may be used to declare
///     abstract methods for properties and descriptors.
///
///     Usage:
///
///         class C(metaclass=ABCMeta):
///             @abstractmethod
///             def my_abstract_method(self, ...):
///                 ...
///     """
///     funcobj.__isabstractmethod__ = True
///     return funcobj
///
///
/// class abstractclassmethod(classmethod):
///     """A decorator indicating abstract classmethods.
///
///     Deprecated, use 'classmethod' with 'abstractmethod' instead:
///
///         class C(ABC):
///             @classmethod
///             @abstractmethod
///             def my_abstract_classmethod(cls, ...):
///                 ...
///
///     """
///
///     __isabstractmethod__ = True
///
///     def __init__(self, callable):
///         callable.__isabstractmethod__ = True
///         super().__init__(callable)
///
///
/// class abstractstaticmethod(staticmethod):
///     """A decorator indicating abstract staticmethods.
///
///     Deprecated, use 'staticmethod' with 'abstractmethod' instead:
///
///         class C(ABC):
///             @staticmethod
///             @abstractmethod
///             def my_abstract_staticmethod(...):
///                 ...
///
///     """
///
///     __isabstractmethod__ = True
///
///     def __init__(self, callable):
///         callable.__isabstractmethod__ = True
///         super().__init__(callable)
///
///
/// class abstractproperty(property):
///     """A decorator indicating abstract properties.
///
///     Deprecated, use 'property' with 'abstractmethod' instead:
///
///         class C(ABC):
///             @property
///             @abstractmethod
///             def my_abstract_property(self):
///                 ...
///
///     """
///
///     __isabstractmethod__ = True
///
///
/// try:
///     from _abc import (get_cache_token, _abc_init, _abc_register,
///                       _abc_instancecheck, _abc_subclasscheck, _get_dump,
///                       _reset_registry, _reset_caches)
/// except ImportError:
///     from _py_abc import ABCMeta, get_cache_token
///     ABCMeta.__module__ = 'abc'
/// else:
///     class ABCMeta(type):
///         """Metaclass for defining Abstract Base Classes (ABCs).
///
///         Use this metaclass to create an ABC.  An ABC can be subclassed
///         directly, and then acts as a mix-in class.  You can also register
///         unrelated concrete classes (even built-in classes) and unrelated
///         ABCs as 'virtual subclasses' -- these and their descendants will
///         be considered subclasses of the registering ABC by the built-in
///         issubclass() function, but the registering ABC won't show up in
///         their MRO (Method Resolution Order) nor will method
///         implementations defined by the registering ABC be callable (not
///         even via super()).
///         """
///         def __new__(mcls, name, bases, namespace, /, **kwargs):
///             cls = super().__new__(mcls, name, bases, namespace, **kwargs)
///             _abc_init(cls)
///             return cls
///
///         def register(cls, subclass):
///             """Register a virtual subclass of an ABC.
///
///             Returns the subclass, to allow usage as a class decorator.
///             """
///             return _abc_register(cls, subclass)
///
///         def __instancecheck__(cls, instance):
///             """Override for isinstance(instance, cls)."""
///             return _abc_instancecheck(cls, instance)
///
///         def __subclasscheck__(cls, subclass):
///             """Override for issubclass(subclass, cls)."""
///             return _abc_subclasscheck(cls, subclass)
///
///         def _dump_registry(cls, file=None):
///             """Debug helper to print the ABC registry."""
///             print(f"Class: {cls.__module__}.{cls.__qualname__}", file=file)
///             print(f"Inv. counter: {get_cache_token()}", file=file)
///             (_abc_registry, _abc_cache, _abc_negative_cache,
///              _abc_negative_cache_version) = _get_dump(cls)
///             print(f"_abc_registry: {_abc_registry!r}", file=file)
///             print(f"_abc_cache: {_abc_cache!r}", file=file)
///             print(f"_abc_negative_cache: {_abc_negative_cache!r}", file=file)
///             print(f"_abc_negative_cache_version: {_abc_negative_cache_version!r}",
///                   file=file)
///
///         def _abc_registry_clear(cls):
///             """Clear the registry (for debugging or testing)."""
///             _reset_registry(cls)
///
///         def _abc_caches_clear(cls):
///             """Clear the caches (for debugging or testing)."""
///             _reset_caches(cls)
///
///
/// def update_abstractmethods(cls):
///     """Recalculate the set of abstract methods of an abstract class.
///
///     If a class has had one of its abstract methods implemented after the
///     class was created, the method will not be considered implemented until
///     this function is called. Alternatively, if a new abstract method has been
///     added to the class, it will only be considered an abstract method of the
///     class after this function is called.
///
///     This function should be called before any use is made of the class,
///     usually in class decorators that add methods to the subject class.
///
///     Returns cls, to allow usage as a class decorator.
///
///     If cls is not an instance of ABCMeta, does nothing.
///     """
///     if not hasattr(cls, '__abstractmethods__'):
///         # We check for __abstractmethods__ here because cls might by a C
///         # implementation or a python implementation (especially during
///         # testing), and we want to handle both cases.
///         return cls
///
///     abstracts = set()
///     # Check the existing abstract methods of the parents, keep only the ones
///     # that are not implemented.
///     for scls in cls.__bases__:
///         for name in getattr(scls, '__abstractmethods__', ()):
///             value = getattr(cls, name, None)
///             if getattr(value, "__isabstractmethod__", False):
///                 abstracts.add(name)
///     # Also add any other newly added abstract methods.
///     for name, value in cls.__dict__.items():
///         if getattr(value, "__isabstractmethod__", False):
///             abstracts.add(name)
///     cls.__abstractmethods__ = frozenset(abstracts)
///     return cls
///
///
/// class ABC(metaclass=ABCMeta):
///     """Helper class that provides a standard way to create an ABC using
///     inheritance.
///     """
///     __slots__ = ()
/// ```
final class abc extends PythonModule {
  abc.from(super.pythonModule) : super.from();

  static abc import() => PythonFfiDart.instance.importModule(
        "abc",
        abc.from,
      );

  /// ## abstractmethod
  ///
  /// ### python docstring
  ///
  /// A decorator indicating abstract methods.
  ///
  /// Requires that the metaclass is ABCMeta or derived from it.  A
  /// class that has a metaclass derived from ABCMeta cannot be
  /// instantiated unless all of its abstract methods are overridden.
  /// The abstract methods can be called using any of the normal
  /// 'super' call mechanisms.  abstractmethod() may be used to declare
  /// abstract methods for properties and descriptors.
  ///
  /// Usage:
  ///
  ///     class C(metaclass=ABCMeta):
  ///         @abstractmethod
  ///         def my_abstract_method(self, ...):
  ///             ...
  Object? abstractmethod({
    required Object? funcobj,
  }) =>
      getFunction("abstractmethod").call(
        <Object?>[
          funcobj,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## update_abstractmethods
  ///
  /// ### python docstring
  ///
  /// Recalculate the set of abstract methods of an abstract class.
  ///
  /// If a class has had one of its abstract methods implemented after the
  /// class was created, the method will not be considered implemented until
  /// this function is called. Alternatively, if a new abstract method has been
  /// added to the class, it will only be considered an abstract method of the
  /// class after this function is called.
  ///
  /// This function should be called before any use is made of the class,
  /// usually in class decorators that add methods to the subject class.
  ///
  /// Returns cls, to allow usage as a class decorator.
  ///
  /// If cls is not an instance of ABCMeta, does nothing.
  Object? update_abstractmethods({
    required Object? cls,
  }) =>
      getFunction("update_abstractmethods").call(
        <Object?>[
          cls,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## os
///
/// ### python docstring
///
/// OS routines for NT or Posix depending on what system we're on.
///
/// This exports:
///   - all functions from posix or nt, e.g. unlink, stat, etc.
///   - os.path is either posixpath or ntpath
///   - os.name is either 'posix' or 'nt'
///   - os.curdir is a string representing the current directory (always '.')
///   - os.pardir is a string representing the parent directory (always '..')
///   - os.sep is the (or a most common) pathname separator ('/' or '\\')
///   - os.extsep is the extension separator (always '.')
///   - os.altsep is the alternate pathname separator (None or '/')
///   - os.pathsep is the component separator used in $PATH etc
///   - os.linesep is the line separator in text files ('\r' or '\n' or '\r\n')
///   - os.defpath is the default search path for executables
///   - os.devnull is the file path of the null device ('/dev/null', etc.)
///
/// Programs that import and use 'os' stand a better chance of being
/// portable between different platforms.  Of course, they must then
/// only use functions that are defined by all platforms (e.g., unlink
/// and opendir), and leave all pathname manipulation to os.path
/// (e.g., split and join).
///
/// ### python source
/// ```py
/// r"""OS routines for NT or Posix depending on what system we're on.
///
/// This exports:
///   - all functions from posix or nt, e.g. unlink, stat, etc.
///   - os.path is either posixpath or ntpath
///   - os.name is either 'posix' or 'nt'
///   - os.curdir is a string representing the current directory (always '.')
///   - os.pardir is a string representing the parent directory (always '..')
///   - os.sep is the (or a most common) pathname separator ('/' or '\\')
///   - os.extsep is the extension separator (always '.')
///   - os.altsep is the alternate pathname separator (None or '/')
///   - os.pathsep is the component separator used in $PATH etc
///   - os.linesep is the line separator in text files ('\r' or '\n' or '\r\n')
///   - os.defpath is the default search path for executables
///   - os.devnull is the file path of the null device ('/dev/null', etc.)
///
/// Programs that import and use 'os' stand a better chance of being
/// portable between different platforms.  Of course, they must then
/// only use functions that are defined by all platforms (e.g., unlink
/// and opendir), and leave all pathname manipulation to os.path
/// (e.g., split and join).
/// """
///
/// #'
/// import abc
/// import sys
/// import stat as st
///
/// from _collections_abc import _check_methods
///
/// GenericAlias = type(list[int])
///
/// _names = sys.builtin_module_names
///
/// # Note:  more names are added to __all__ later.
/// __all__ = ["altsep", "curdir", "pardir", "sep", "pathsep", "linesep",
///            "defpath", "name", "path", "devnull", "SEEK_SET", "SEEK_CUR",
///            "SEEK_END", "fsencode", "fsdecode", "get_exec_path", "fdopen",
///            "extsep"]
///
/// def _exists(name):
///     return name in globals()
///
/// def _get_exports_list(module):
///     try:
///         return list(module.__all__)
///     except AttributeError:
///         return [n for n in dir(module) if n[0] != '_']
///
/// # Any new dependencies of the os module and/or changes in path separator
/// # requires updating importlib as well.
/// if 'posix' in _names:
///     name = 'posix'
///     linesep = '\n'
///     from posix import *
///     try:
///         from posix import _exit
///         __all__.append('_exit')
///     except ImportError:
///         pass
///     import posixpath as path
///
///     try:
///         from posix import _have_functions
///     except ImportError:
///         pass
///
///     import posix
///     __all__.extend(_get_exports_list(posix))
///     del posix
///
/// elif 'nt' in _names:
///     name = 'nt'
///     linesep = '\r\n'
///     from nt import *
///     try:
///         from nt import _exit
///         __all__.append('_exit')
///     except ImportError:
///         pass
///     import ntpath as path
///
///     import nt
///     __all__.extend(_get_exports_list(nt))
///     del nt
///
///     try:
///         from nt import _have_functions
///     except ImportError:
///         pass
///
/// else:
///     raise ImportError('no os specific module found')
///
/// sys.modules['os.path'] = path
/// from os.path import (curdir, pardir, sep, pathsep, defpath, extsep, altsep,
///     devnull)
///
/// del _names
///
///
/// if _exists("_have_functions"):
///     _globals = globals()
///     def _add(str, fn):
///         if (fn in _globals) and (str in _have_functions):
///             _set.add(_globals[fn])
///
///     _set = set()
///     _add("HAVE_FACCESSAT",  "access")
///     _add("HAVE_FCHMODAT",   "chmod")
///     _add("HAVE_FCHOWNAT",   "chown")
///     _add("HAVE_FSTATAT",    "stat")
///     _add("HAVE_FUTIMESAT",  "utime")
///     _add("HAVE_LINKAT",     "link")
///     _add("HAVE_MKDIRAT",    "mkdir")
///     _add("HAVE_MKFIFOAT",   "mkfifo")
///     _add("HAVE_MKNODAT",    "mknod")
///     _add("HAVE_OPENAT",     "open")
///     _add("HAVE_READLINKAT", "readlink")
///     _add("HAVE_RENAMEAT",   "rename")
///     _add("HAVE_SYMLINKAT",  "symlink")
///     _add("HAVE_UNLINKAT",   "unlink")
///     _add("HAVE_UNLINKAT",   "rmdir")
///     _add("HAVE_UTIMENSAT",  "utime")
///     supports_dir_fd = _set
///
///     _set = set()
///     _add("HAVE_FACCESSAT",  "access")
///     supports_effective_ids = _set
///
///     _set = set()
///     _add("HAVE_FCHDIR",     "chdir")
///     _add("HAVE_FCHMOD",     "chmod")
///     _add("HAVE_FCHOWN",     "chown")
///     _add("HAVE_FDOPENDIR",  "listdir")
///     _add("HAVE_FDOPENDIR",  "scandir")
///     _add("HAVE_FEXECVE",    "execve")
///     _set.add(stat) # fstat always works
///     _add("HAVE_FTRUNCATE",  "truncate")
///     _add("HAVE_FUTIMENS",   "utime")
///     _add("HAVE_FUTIMES",    "utime")
///     _add("HAVE_FPATHCONF",  "pathconf")
///     if _exists("statvfs") and _exists("fstatvfs"): # mac os x10.3
///         _add("HAVE_FSTATVFS", "statvfs")
///     supports_fd = _set
///
///     _set = set()
///     _add("HAVE_FACCESSAT",  "access")
///     # Some platforms don't support lchmod().  Often the function exists
///     # anyway, as a stub that always returns ENOSUP or perhaps EOPNOTSUPP.
///     # (No, I don't know why that's a good design.)  ./configure will detect
///     # this and reject it--so HAVE_LCHMOD still won't be defined on such
///     # platforms.  This is Very Helpful.
///     #
///     # However, sometimes platforms without a working lchmod() *do* have
///     # fchmodat().  (Examples: Linux kernel 3.2 with glibc 2.15,
///     # OpenIndiana 3.x.)  And fchmodat() has a flag that theoretically makes
///     # it behave like lchmod().  So in theory it would be a suitable
///     # replacement for lchmod().  But when lchmod() doesn't work, fchmodat()'s
///     # flag doesn't work *either*.  Sadly ./configure isn't sophisticated
///     # enough to detect this condition--it only determines whether or not
///     # fchmodat() minimally works.
///     #
///     # Therefore we simply ignore fchmodat() when deciding whether or not
///     # os.chmod supports follow_symlinks.  Just checking lchmod() is
///     # sufficient.  After all--if you have a working fchmodat(), your
///     # lchmod() almost certainly works too.
///     #
///     # _add("HAVE_FCHMODAT",   "chmod")
///     _add("HAVE_FCHOWNAT",   "chown")
///     _add("HAVE_FSTATAT",    "stat")
///     _add("HAVE_LCHFLAGS",   "chflags")
///     _add("HAVE_LCHMOD",     "chmod")
///     if _exists("lchown"): # mac os x10.3
///         _add("HAVE_LCHOWN", "chown")
///     _add("HAVE_LINKAT",     "link")
///     _add("HAVE_LUTIMES",    "utime")
///     _add("HAVE_LSTAT",      "stat")
///     _add("HAVE_FSTATAT",    "stat")
///     _add("HAVE_UTIMENSAT",  "utime")
///     _add("MS_WINDOWS",      "stat")
///     supports_follow_symlinks = _set
///
///     del _set
///     del _have_functions
///     del _globals
///     del _add
///
///
/// # Python uses fixed values for the SEEK_ constants; they are mapped
/// # to native constants if necessary in posixmodule.c
/// # Other possible SEEK values are directly imported from posixmodule.c
/// SEEK_SET = 0
/// SEEK_CUR = 1
/// SEEK_END = 2
///
/// # Super directory utilities.
/// # (Inspired by Eric Raymond; the doc strings are mostly his)
///
/// def makedirs(name, mode=0o777, exist_ok=False):
///     """makedirs(name [, mode=0o777][, exist_ok=False])
///
///     Super-mkdir; create a leaf directory and all intermediate ones.  Works like
///     mkdir, except that any intermediate path segment (not just the rightmost)
///     will be created if it does not exist. If the target directory already
///     exists, raise an OSError if exist_ok is False. Otherwise no exception is
///     raised.  This is recursive.
///
///     """
///     head, tail = path.split(name)
///     if not tail:
///         head, tail = path.split(head)
///     if head and tail and not path.exists(head):
///         try:
///             makedirs(head, exist_ok=exist_ok)
///         except FileExistsError:
///             # Defeats race condition when another thread created the path
///             pass
///         cdir = curdir
///         if isinstance(tail, bytes):
///             cdir = bytes(curdir, 'ASCII')
///         if tail == cdir:           # xxx/newdir/. exists if xxx/newdir exists
///             return
///     try:
///         mkdir(name, mode)
///     except OSError:
///         # Cannot rely on checking for EEXIST, since the operating system
///         # could give priority to other errors like EACCES or EROFS
///         if not exist_ok or not path.isdir(name):
///             raise
///
/// def removedirs(name):
///     """removedirs(name)
///
///     Super-rmdir; remove a leaf directory and all empty intermediate
///     ones.  Works like rmdir except that, if the leaf directory is
///     successfully removed, directories corresponding to rightmost path
///     segments will be pruned away until either the whole path is
///     consumed or an error occurs.  Errors during this latter phase are
///     ignored -- they generally mean that a directory was not empty.
///
///     """
///     rmdir(name)
///     head, tail = path.split(name)
///     if not tail:
///         head, tail = path.split(head)
///     while head and tail:
///         try:
///             rmdir(head)
///         except OSError:
///             break
///         head, tail = path.split(head)
///
/// def renames(old, new):
///     """renames(old, new)
///
///     Super-rename; create directories as necessary and delete any left
///     empty.  Works like rename, except creation of any intermediate
///     directories needed to make the new pathname good is attempted
///     first.  After the rename, directories corresponding to rightmost
///     path segments of the old name will be pruned until either the
///     whole path is consumed or a nonempty directory is found.
///
///     Note: this function can fail with the new directory structure made
///     if you lack permissions needed to unlink the leaf directory or
///     file.
///
///     """
///     head, tail = path.split(new)
///     if head and tail and not path.exists(head):
///         makedirs(head)
///     rename(old, new)
///     head, tail = path.split(old)
///     if head and tail:
///         try:
///             removedirs(head)
///         except OSError:
///             pass
///
/// __all__.extend(["makedirs", "removedirs", "renames"])
///
/// def walk(top, topdown=True, onerror=None, followlinks=False):
///     """Directory tree generator.
///
///     For each directory in the directory tree rooted at top (including top
///     itself, but excluding '.' and '..'), yields a 3-tuple
///
///         dirpath, dirnames, filenames
///
///     dirpath is a string, the path to the directory.  dirnames is a list of
///     the names of the subdirectories in dirpath (including symlinks to directories,
///     and excluding '.' and '..').
///     filenames is a list of the names of the non-directory files in dirpath.
///     Note that the names in the lists are just names, with no path components.
///     To get a full path (which begins with top) to a file or directory in
///     dirpath, do os.path.join(dirpath, name).
///
///     If optional arg 'topdown' is true or not specified, the triple for a
///     directory is generated before the triples for any of its subdirectories
///     (directories are generated top down).  If topdown is false, the triple
///     for a directory is generated after the triples for all of its
///     subdirectories (directories are generated bottom up).
///
///     When topdown is true, the caller can modify the dirnames list in-place
///     (e.g., via del or slice assignment), and walk will only recurse into the
///     subdirectories whose names remain in dirnames; this can be used to prune the
///     search, or to impose a specific order of visiting.  Modifying dirnames when
///     topdown is false has no effect on the behavior of os.walk(), since the
///     directories in dirnames have already been generated by the time dirnames
///     itself is generated. No matter the value of topdown, the list of
///     subdirectories is retrieved before the tuples for the directory and its
///     subdirectories are generated.
///
///     By default errors from the os.scandir() call are ignored.  If
///     optional arg 'onerror' is specified, it should be a function; it
///     will be called with one argument, an OSError instance.  It can
///     report the error to continue with the walk, or raise the exception
///     to abort the walk.  Note that the filename is available as the
///     filename attribute of the exception object.
///
///     By default, os.walk does not follow symbolic links to subdirectories on
///     systems that support them.  In order to get this functionality, set the
///     optional argument 'followlinks' to true.
///
///     Caution:  if you pass a relative pathname for top, don't change the
///     current working directory between resumptions of walk.  walk never
///     changes the current directory, and assumes that the client doesn't
///     either.
///
///     Example:
///
///     import os
///     from os.path import join, getsize
///     for root, dirs, files in os.walk('python/Lib/email'):
///         print(root, "consumes ")
///         print(sum(getsize(join(root, name)) for name in files), end=" ")
///         print("bytes in", len(files), "non-directory files")
///         if 'CVS' in dirs:
///             dirs.remove('CVS')  # don't visit CVS directories
///
///     """
///     sys.audit("os.walk", top, topdown, onerror, followlinks)
///     return _walk(fspath(top), topdown, onerror, followlinks)
///
/// def _walk(top, topdown, onerror, followlinks):
///     dirs = []
///     nondirs = []
///     walk_dirs = []
///
///     # We may not have read permission for top, in which case we can't
///     # get a list of the files the directory contains.  os.walk
///     # always suppressed the exception then, rather than blow up for a
///     # minor reason when (say) a thousand readable directories are still
///     # left to visit.  That logic is copied here.
///     try:
///         # Note that scandir is global in this module due
///         # to earlier import-*.
///         scandir_it = scandir(top)
///     except OSError as error:
///         if onerror is not None:
///             onerror(error)
///         return
///
///     with scandir_it:
///         while True:
///             try:
///                 try:
///                     entry = next(scandir_it)
///                 except StopIteration:
///                     break
///             except OSError as error:
///                 if onerror is not None:
///                     onerror(error)
///                 return
///
///             try:
///                 is_dir = entry.is_dir()
///             except OSError:
///                 # If is_dir() raises an OSError, consider that the entry is not
///                 # a directory, same behaviour than os.path.isdir().
///                 is_dir = False
///
///             if is_dir:
///                 dirs.append(entry.name)
///             else:
///                 nondirs.append(entry.name)
///
///             if not topdown and is_dir:
///                 # Bottom-up: recurse into sub-directory, but exclude symlinks to
///                 # directories if followlinks is False
///                 if followlinks:
///                     walk_into = True
///                 else:
///                     try:
///                         is_symlink = entry.is_symlink()
///                     except OSError:
///                         # If is_symlink() raises an OSError, consider that the
///                         # entry is not a symbolic link, same behaviour than
///                         # os.path.islink().
///                         is_symlink = False
///                     walk_into = not is_symlink
///
///                 if walk_into:
///                     walk_dirs.append(entry.path)
///
///     # Yield before recursion if going top down
///     if topdown:
///         yield top, dirs, nondirs
///
///         # Recurse into sub-directories
///         islink, join = path.islink, path.join
///         for dirname in dirs:
///             new_path = join(top, dirname)
///             # Issue #23605: os.path.islink() is used instead of caching
///             # entry.is_symlink() result during the loop on os.scandir() because
///             # the caller can replace the directory entry during the "yield"
///             # above.
///             if followlinks or not islink(new_path):
///                 yield from _walk(new_path, topdown, onerror, followlinks)
///     else:
///         # Recurse into sub-directories
///         for new_path in walk_dirs:
///             yield from _walk(new_path, topdown, onerror, followlinks)
///         # Yield after recursion if going bottom up
///         yield top, dirs, nondirs
///
/// __all__.append("walk")
///
/// if {open, stat} <= supports_dir_fd and {scandir, stat} <= supports_fd:
///
///     def fwalk(top=".", topdown=True, onerror=None, *, follow_symlinks=False, dir_fd=None):
///         """Directory tree generator.
///
///         This behaves exactly like walk(), except that it yields a 4-tuple
///
///             dirpath, dirnames, filenames, dirfd
///
///         `dirpath`, `dirnames` and `filenames` are identical to walk() output,
///         and `dirfd` is a file descriptor referring to the directory `dirpath`.
///
///         The advantage of fwalk() over walk() is that it's safe against symlink
///         races (when follow_symlinks is False).
///
///         If dir_fd is not None, it should be a file descriptor open to a directory,
///           and top should be relative; top will then be relative to that directory.
///           (dir_fd is always supported for fwalk.)
///
///         Caution:
///         Since fwalk() yields file descriptors, those are only valid until the
///         next iteration step, so you should dup() them if you want to keep them
///         for a longer period.
///
///         Example:
///
///         import os
///         for root, dirs, files, rootfd in os.fwalk('python/Lib/email'):
///             print(root, "consumes", end="")
///             print(sum(os.stat(name, dir_fd=rootfd).st_size for name in files),
///                   end="")
///             print("bytes in", len(files), "non-directory files")
///             if 'CVS' in dirs:
///                 dirs.remove('CVS')  # don't visit CVS directories
///         """
///         sys.audit("os.fwalk", top, topdown, onerror, follow_symlinks, dir_fd)
///         top = fspath(top)
///         # Note: To guard against symlink races, we use the standard
///         # lstat()/open()/fstat() trick.
///         if not follow_symlinks:
///             orig_st = stat(top, follow_symlinks=False, dir_fd=dir_fd)
///         topfd = open(top, O_RDONLY, dir_fd=dir_fd)
///         try:
///             if (follow_symlinks or (st.S_ISDIR(orig_st.st_mode) and
///                                     path.samestat(orig_st, stat(topfd)))):
///                 yield from _fwalk(topfd, top, isinstance(top, bytes),
///                                   topdown, onerror, follow_symlinks)
///         finally:
///             close(topfd)
///
///     def _fwalk(topfd, toppath, isbytes, topdown, onerror, follow_symlinks):
///         # Note: This uses O(depth of the directory tree) file descriptors: if
///         # necessary, it can be adapted to only require O(1) FDs, see issue
///         # #13734.
///
///         scandir_it = scandir(topfd)
///         dirs = []
///         nondirs = []
///         entries = None if topdown or follow_symlinks else []
///         for entry in scandir_it:
///             name = entry.name
///             if isbytes:
///                 name = fsencode(name)
///             try:
///                 if entry.is_dir():
///                     dirs.append(name)
///                     if entries is not None:
///                         entries.append(entry)
///                 else:
///                     nondirs.append(name)
///             except OSError:
///                 try:
///                     # Add dangling symlinks, ignore disappeared files
///                     if entry.is_symlink():
///                         nondirs.append(name)
///                 except OSError:
///                     pass
///
///         if topdown:
///             yield toppath, dirs, nondirs, topfd
///
///         for name in dirs if entries is None else zip(dirs, entries):
///             try:
///                 if not follow_symlinks:
///                     if topdown:
///                         orig_st = stat(name, dir_fd=topfd, follow_symlinks=False)
///                     else:
///                         assert entries is not None
///                         name, entry = name
///                         orig_st = entry.stat(follow_symlinks=False)
///                 dirfd = open(name, O_RDONLY, dir_fd=topfd)
///             except OSError as err:
///                 if onerror is not None:
///                     onerror(err)
///                 continue
///             try:
///                 if follow_symlinks or path.samestat(orig_st, stat(dirfd)):
///                     dirpath = path.join(toppath, name)
///                     yield from _fwalk(dirfd, dirpath, isbytes,
///                                       topdown, onerror, follow_symlinks)
///             finally:
///                 close(dirfd)
///
///         if not topdown:
///             yield toppath, dirs, nondirs, topfd
///
///     __all__.append("fwalk")
///
/// def execl(file, *args):
///     """execl(file, *args)
///
///     Execute the executable file with argument list args, replacing the
///     current process. """
///     execv(file, args)
///
/// def execle(file, *args):
///     """execle(file, *args, env)
///
///     Execute the executable file with argument list args and
///     environment env, replacing the current process. """
///     env = args[-1]
///     execve(file, args[:-1], env)
///
/// def execlp(file, *args):
///     """execlp(file, *args)
///
///     Execute the executable file (which is searched for along $PATH)
///     with argument list args, replacing the current process. """
///     execvp(file, args)
///
/// def execlpe(file, *args):
///     """execlpe(file, *args, env)
///
///     Execute the executable file (which is searched for along $PATH)
///     with argument list args and environment env, replacing the current
///     process. """
///     env = args[-1]
///     execvpe(file, args[:-1], env)
///
/// def execvp(file, args):
///     """execvp(file, args)
///
///     Execute the executable file (which is searched for along $PATH)
///     with argument list args, replacing the current process.
///     args may be a list or tuple of strings. """
///     _execvpe(file, args)
///
/// def execvpe(file, args, env):
///     """execvpe(file, args, env)
///
///     Execute the executable file (which is searched for along $PATH)
///     with argument list args and environment env, replacing the
///     current process.
///     args may be a list or tuple of strings. """
///     _execvpe(file, args, env)
///
/// __all__.extend(["execl","execle","execlp","execlpe","execvp","execvpe"])
///
/// def _execvpe(file, args, env=None):
///     if env is not None:
///         exec_func = execve
///         argrest = (args, env)
///     else:
///         exec_func = execv
///         argrest = (args,)
///         env = environ
///
///     if path.dirname(file):
///         exec_func(file, *argrest)
///         return
///     saved_exc = None
///     path_list = get_exec_path(env)
///     if name != 'nt':
///         file = fsencode(file)
///         path_list = map(fsencode, path_list)
///     for dir in path_list:
///         fullname = path.join(dir, file)
///         try:
///             exec_func(fullname, *argrest)
///         except (FileNotFoundError, NotADirectoryError) as e:
///             last_exc = e
///         except OSError as e:
///             last_exc = e
///             if saved_exc is None:
///                 saved_exc = e
///     if saved_exc is not None:
///         raise saved_exc
///     raise last_exc
///
///
/// def get_exec_path(env=None):
///     """Returns the sequence of directories that will be searched for the
///     named executable (similar to a shell) when launching a process.
///
///     *env* must be an environment variable dict or None.  If *env* is None,
///     os.environ will be used.
///     """
///     # Use a local import instead of a global import to limit the number of
///     # modules loaded at startup: the os module is always loaded at startup by
///     # Python. It may also avoid a bootstrap issue.
///     import warnings
///
///     if env is None:
///         env = environ
///
///     # {b'PATH': ...}.get('PATH') and {'PATH': ...}.get(b'PATH') emit a
///     # BytesWarning when using python -b or python -bb: ignore the warning
///     with warnings.catch_warnings():
///         warnings.simplefilter("ignore", BytesWarning)
///
///         try:
///             path_list = env.get('PATH')
///         except TypeError:
///             path_list = None
///
///         if supports_bytes_environ:
///             try:
///                 path_listb = env[b'PATH']
///             except (KeyError, TypeError):
///                 pass
///             else:
///                 if path_list is not None:
///                     raise ValueError(
///                         "env cannot contain 'PATH' and b'PATH' keys")
///                 path_list = path_listb
///
///             if path_list is not None and isinstance(path_list, bytes):
///                 path_list = fsdecode(path_list)
///
///     if path_list is None:
///         path_list = defpath
///     return path_list.split(pathsep)
///
///
/// # Change environ to automatically call putenv() and unsetenv()
/// from _collections_abc import MutableMapping, Mapping
///
/// class _Environ(MutableMapping):
///     def __init__(self, data, encodekey, decodekey, encodevalue, decodevalue):
///         self.encodekey = encodekey
///         self.decodekey = decodekey
///         self.encodevalue = encodevalue
///         self.decodevalue = decodevalue
///         self._data = data
///
///     def __getitem__(self, key):
///         try:
///             value = self._data[self.encodekey(key)]
///         except KeyError:
///             # raise KeyError with the original key value
///             raise KeyError(key) from None
///         return self.decodevalue(value)
///
///     def __setitem__(self, key, value):
///         key = self.encodekey(key)
///         value = self.encodevalue(value)
///         putenv(key, value)
///         self._data[key] = value
///
///     def __delitem__(self, key):
///         encodedkey = self.encodekey(key)
///         unsetenv(encodedkey)
///         try:
///             del self._data[encodedkey]
///         except KeyError:
///             # raise KeyError with the original key value
///             raise KeyError(key) from None
///
///     def __iter__(self):
///         # list() from dict object is an atomic operation
///         keys = list(self._data)
///         for key in keys:
///             yield self.decodekey(key)
///
///     def __len__(self):
///         return len(self._data)
///
///     def __repr__(self):
///         formatted_items = ", ".join(
///             f"{self.decodekey(key)!r}: {self.decodevalue(value)!r}"
///             for key, value in self._data.items()
///         )
///         return f"environ({{{formatted_items}}})"
///
///     def copy(self):
///         return dict(self)
///
///     def setdefault(self, key, value):
///         if key not in self:
///             self[key] = value
///         return self[key]
///
///     def __ior__(self, other):
///         self.update(other)
///         return self
///
///     def __or__(self, other):
///         if not isinstance(other, Mapping):
///             return NotImplemented
///         new = dict(self)
///         new.update(other)
///         return new
///
///     def __ror__(self, other):
///         if not isinstance(other, Mapping):
///             return NotImplemented
///         new = dict(other)
///         new.update(self)
///         return new
///
/// def _createenviron():
///     if name == 'nt':
///         # Where Env Var Names Must Be UPPERCASE
///         def check_str(value):
///             if not isinstance(value, str):
///                 raise TypeError("str expected, not %s" % type(value).__name__)
///             return value
///         encode = check_str
///         decode = str
///         def encodekey(key):
///             return encode(key).upper()
///         data = {}
///         for key, value in environ.items():
///             data[encodekey(key)] = value
///     else:
///         # Where Env Var Names Can Be Mixed Case
///         encoding = sys.getfilesystemencoding()
///         def encode(value):
///             if not isinstance(value, str):
///                 raise TypeError("str expected, not %s" % type(value).__name__)
///             return value.encode(encoding, 'surrogateescape')
///         def decode(value):
///             return value.decode(encoding, 'surrogateescape')
///         encodekey = encode
///         data = environ
///     return _Environ(data,
///         encodekey, decode,
///         encode, decode)
///
/// # unicode environ
/// environ = _createenviron()
/// del _createenviron
///
///
/// def getenv(key, default=None):
///     """Get an environment variable, return None if it doesn't exist.
///     The optional second argument can specify an alternate default.
///     key, default and the result are str."""
///     return environ.get(key, default)
///
/// supports_bytes_environ = (name != 'nt')
/// __all__.extend(("getenv", "supports_bytes_environ"))
///
/// if supports_bytes_environ:
///     def _check_bytes(value):
///         if not isinstance(value, bytes):
///             raise TypeError("bytes expected, not %s" % type(value).__name__)
///         return value
///
///     # bytes environ
///     environb = _Environ(environ._data,
///         _check_bytes, bytes,
///         _check_bytes, bytes)
///     del _check_bytes
///
///     def getenvb(key, default=None):
///         """Get an environment variable, return None if it doesn't exist.
///         The optional second argument can specify an alternate default.
///         key, default and the result are bytes."""
///         return environb.get(key, default)
///
///     __all__.extend(("environb", "getenvb"))
///
/// def _fscodec():
///     encoding = sys.getfilesystemencoding()
///     errors = sys.getfilesystemencodeerrors()
///
///     def fsencode(filename):
///         """Encode filename (an os.PathLike, bytes, or str) to the filesystem
///         encoding with 'surrogateescape' error handler, return bytes unchanged.
///         On Windows, use 'strict' error handler if the file system encoding is
///         'mbcs' (which is the default encoding).
///         """
///         filename = fspath(filename)  # Does type-checking of `filename`.
///         if isinstance(filename, str):
///             return filename.encode(encoding, errors)
///         else:
///             return filename
///
///     def fsdecode(filename):
///         """Decode filename (an os.PathLike, bytes, or str) from the filesystem
///         encoding with 'surrogateescape' error handler, return str unchanged. On
///         Windows, use 'strict' error handler if the file system encoding is
///         'mbcs' (which is the default encoding).
///         """
///         filename = fspath(filename)  # Does type-checking of `filename`.
///         if isinstance(filename, bytes):
///             return filename.decode(encoding, errors)
///         else:
///             return filename
///
///     return fsencode, fsdecode
///
/// fsencode, fsdecode = _fscodec()
/// del _fscodec
///
/// # Supply spawn*() (probably only for Unix)
/// if _exists("fork") and not _exists("spawnv") and _exists("execv"):
///
///     P_WAIT = 0
///     P_NOWAIT = P_NOWAITO = 1
///
///     __all__.extend(["P_WAIT", "P_NOWAIT", "P_NOWAITO"])
///
///     # XXX Should we support P_DETACH?  I suppose it could fork()**2
///     # and close the std I/O streams.  Also, P_OVERLAY is the same
///     # as execv*()?
///
///     def _spawnvef(mode, file, args, env, func):
///         # Internal helper; func is the exec*() function to use
///         if not isinstance(args, (tuple, list)):
///             raise TypeError('argv must be a tuple or a list')
///         if not args or not args[0]:
///             raise ValueError('argv first element cannot be empty')
///         pid = fork()
///         if not pid:
///             # Child
///             try:
///                 if env is None:
///                     func(file, args)
///                 else:
///                     func(file, args, env)
///             except:
///                 _exit(127)
///         else:
///             # Parent
///             if mode == P_NOWAIT:
///                 return pid # Caller is responsible for waiting!
///             while 1:
///                 wpid, sts = waitpid(pid, 0)
///                 if WIFSTOPPED(sts):
///                     continue
///
///                 return waitstatus_to_exitcode(sts)
///
///     def spawnv(mode, file, args):
///         """spawnv(mode, file, args) -> integer
///
/// Execute file with arguments from args in a subprocess.
/// If mode == P_NOWAIT return the pid of the process.
/// If mode == P_WAIT return the process's exit code if it exits normally;
/// otherwise return -SIG, where SIG is the signal that killed it. """
///         return _spawnvef(mode, file, args, None, execv)
///
///     def spawnve(mode, file, args, env):
///         """spawnve(mode, file, args, env) -> integer
///
/// Execute file with arguments from args in a subprocess with the
/// specified environment.
/// If mode == P_NOWAIT return the pid of the process.
/// If mode == P_WAIT return the process's exit code if it exits normally;
/// otherwise return -SIG, where SIG is the signal that killed it. """
///         return _spawnvef(mode, file, args, env, execve)
///
///     # Note: spawnvp[e] isn't currently supported on Windows
///
///     def spawnvp(mode, file, args):
///         """spawnvp(mode, file, args) -> integer
///
/// Execute file (which is looked for along $PATH) with arguments from
/// args in a subprocess.
/// If mode == P_NOWAIT return the pid of the process.
/// If mode == P_WAIT return the process's exit code if it exits normally;
/// otherwise return -SIG, where SIG is the signal that killed it. """
///         return _spawnvef(mode, file, args, None, execvp)
///
///     def spawnvpe(mode, file, args, env):
///         """spawnvpe(mode, file, args, env) -> integer
///
/// Execute file (which is looked for along $PATH) with arguments from
/// args in a subprocess with the supplied environment.
/// If mode == P_NOWAIT return the pid of the process.
/// If mode == P_WAIT return the process's exit code if it exits normally;
/// otherwise return -SIG, where SIG is the signal that killed it. """
///         return _spawnvef(mode, file, args, env, execvpe)
///
///
///     __all__.extend(["spawnv", "spawnve", "spawnvp", "spawnvpe"])
///
///
/// if _exists("spawnv"):
///     # These aren't supplied by the basic Windows code
///     # but can be easily implemented in Python
///
///     def spawnl(mode, file, *args):
///         """spawnl(mode, file, *args) -> integer
///
/// Execute file with arguments from args in a subprocess.
/// If mode == P_NOWAIT return the pid of the process.
/// If mode == P_WAIT return the process's exit code if it exits normally;
/// otherwise return -SIG, where SIG is the signal that killed it. """
///         return spawnv(mode, file, args)
///
///     def spawnle(mode, file, *args):
///         """spawnle(mode, file, *args, env) -> integer
///
/// Execute file with arguments from args in a subprocess with the
/// supplied environment.
/// If mode == P_NOWAIT return the pid of the process.
/// If mode == P_WAIT return the process's exit code if it exits normally;
/// otherwise return -SIG, where SIG is the signal that killed it. """
///         env = args[-1]
///         return spawnve(mode, file, args[:-1], env)
///
///
///     __all__.extend(["spawnl", "spawnle"])
///
///
/// if _exists("spawnvp"):
///     # At the moment, Windows doesn't implement spawnvp[e],
///     # so it won't have spawnlp[e] either.
///     def spawnlp(mode, file, *args):
///         """spawnlp(mode, file, *args) -> integer
///
/// Execute file (which is looked for along $PATH) with arguments from
/// args in a subprocess with the supplied environment.
/// If mode == P_NOWAIT return the pid of the process.
/// If mode == P_WAIT return the process's exit code if it exits normally;
/// otherwise return -SIG, where SIG is the signal that killed it. """
///         return spawnvp(mode, file, args)
///
///     def spawnlpe(mode, file, *args):
///         """spawnlpe(mode, file, *args, env) -> integer
///
/// Execute file (which is looked for along $PATH) with arguments from
/// args in a subprocess with the supplied environment.
/// If mode == P_NOWAIT return the pid of the process.
/// If mode == P_WAIT return the process's exit code if it exits normally;
/// otherwise return -SIG, where SIG is the signal that killed it. """
///         env = args[-1]
///         return spawnvpe(mode, file, args[:-1], env)
///
///
///     __all__.extend(["spawnlp", "spawnlpe"])
///
/// # VxWorks has no user space shell provided. As a result, running
/// # command in a shell can't be supported.
/// if sys.platform != 'vxworks':
///     # Supply os.popen()
///     def popen(cmd, mode="r", buffering=-1):
///         if not isinstance(cmd, str):
///             raise TypeError("invalid cmd type (%s, expected string)" % type(cmd))
///         if mode not in ("r", "w"):
///             raise ValueError("invalid mode %r" % mode)
///         if buffering == 0 or buffering is None:
///             raise ValueError("popen() does not support unbuffered streams")
///         import subprocess
///         if mode == "r":
///             proc = subprocess.Popen(cmd,
///                                     shell=True, text=True,
///                                     stdout=subprocess.PIPE,
///                                     bufsize=buffering)
///             return _wrap_close(proc.stdout, proc)
///         else:
///             proc = subprocess.Popen(cmd,
///                                     shell=True, text=True,
///                                     stdin=subprocess.PIPE,
///                                     bufsize=buffering)
///             return _wrap_close(proc.stdin, proc)
///
///     # Helper for popen() -- a proxy for a file whose close waits for the process
///     class _wrap_close:
///         def __init__(self, stream, proc):
///             self._stream = stream
///             self._proc = proc
///         def close(self):
///             self._stream.close()
///             returncode = self._proc.wait()
///             if returncode == 0:
///                 return None
///             if name == 'nt':
///                 return returncode
///             else:
///                 return returncode << 8  # Shift left to match old behavior
///         def __enter__(self):
///             return self
///         def __exit__(self, *args):
///             self.close()
///         def __getattr__(self, name):
///             return getattr(self._stream, name)
///         def __iter__(self):
///             return iter(self._stream)
///
///     __all__.append("popen")
///
/// # Supply os.fdopen()
/// def fdopen(fd, mode="r", buffering=-1, encoding=None, *args, **kwargs):
///     if not isinstance(fd, int):
///         raise TypeError("invalid fd type (%s, expected integer)" % type(fd))
///     import io
///     if "b" not in mode:
///         encoding = io.text_encoding(encoding)
///     return io.open(fd, mode, buffering, encoding, *args, **kwargs)
///
///
/// # For testing purposes, make sure the function is available when the C
/// # implementation exists.
/// def _fspath(path):
///     """Return the path representation of a path-like object.
///
///     If str or bytes is passed in, it is returned unchanged. Otherwise the
///     os.PathLike interface is used to get the path representation. If the
///     path representation is not str or bytes, TypeError is raised. If the
///     provided path is not str, bytes, or os.PathLike, TypeError is raised.
///     """
///     if isinstance(path, (str, bytes)):
///         return path
///
///     # Work from the object's type to match method resolution of other magic
///     # methods.
///     path_type = type(path)
///     try:
///         path_repr = path_type.__fspath__(path)
///     except AttributeError:
///         if hasattr(path_type, '__fspath__'):
///             raise
///         else:
///             raise TypeError("expected str, bytes or os.PathLike object, "
///                             "not " + path_type.__name__)
///     if isinstance(path_repr, (str, bytes)):
///         return path_repr
///     else:
///         raise TypeError("expected {}.__fspath__() to return str or bytes, "
///                         "not {}".format(path_type.__name__,
///                                         type(path_repr).__name__))
///
/// # If there is no C implementation, make the pure Python version the
/// # implementation as transparently as possible.
/// if not _exists('fspath'):
///     fspath = _fspath
///     fspath.__name__ = "fspath"
///
///
/// class PathLike(abc.ABC):
///
///     """Abstract base class for implementing the file system path protocol."""
///
///     @abc.abstractmethod
///     def __fspath__(self):
///         """Return the file system path representation of the object."""
///         raise NotImplementedError
///
///     @classmethod
///     def __subclasshook__(cls, subclass):
///         if cls is PathLike:
///             return _check_methods(subclass, '__fspath__')
///         return NotImplemented
///
///     __class_getitem__ = classmethod(GenericAlias)
///
///
/// if name == 'nt':
///     class _AddedDllDirectory:
///         def __init__(self, path, cookie, remove_dll_directory):
///             self.path = path
///             self._cookie = cookie
///             self._remove_dll_directory = remove_dll_directory
///         def close(self):
///             self._remove_dll_directory(self._cookie)
///             self.path = None
///         def __enter__(self):
///             return self
///         def __exit__(self, *args):
///             self.close()
///         def __repr__(self):
///             if self.path:
///                 return "<AddedDllDirectory({!r})>".format(self.path)
///             return "<AddedDllDirectory()>"
///
///     def add_dll_directory(path):
///         """Add a path to the DLL search path.
///
///         This search path is used when resolving dependencies for imported
///         extension modules (the module itself is resolved through sys.path),
///         and also by ctypes.
///
///         Remove the directory by calling close() on the returned object or
///         using it in a with statement.
///         """
///         import nt
///         cookie = nt._add_dll_directory(path)
///         return _AddedDllDirectory(
///             path,
///             cookie,
///             nt._remove_dll_directory
///         )
/// ```
final class os extends PythonModule {
  os.from(super.pythonModule) : super.from();

  static os import() => PythonFfiDart.instance.importModule(
        "os",
        os.from,
      );

  /// ## execl
  ///
  /// ### python docstring
  ///
  /// execl(file, *args)
  ///
  /// Execute the executable file with argument list args, replacing the
  /// current process.
  Object? execl({
    List<Object?> args = const <Object?>[],
    required Object? file,
  }) =>
      getFunction("execl").call(
        <Object?>[
          file,
          ...args,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## execle
  ///
  /// ### python docstring
  ///
  /// execle(file, *args, env)
  ///
  /// Execute the executable file with argument list args and
  /// environment env, replacing the current process.
  Object? execle({
    List<Object?> args = const <Object?>[],
    required Object? file,
  }) =>
      getFunction("execle").call(
        <Object?>[
          file,
          ...args,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## execlp
  ///
  /// ### python docstring
  ///
  /// execlp(file, *args)
  ///
  /// Execute the executable file (which is searched for along $PATH)
  /// with argument list args, replacing the current process.
  Object? execlp({
    List<Object?> args = const <Object?>[],
    required Object? file,
  }) =>
      getFunction("execlp").call(
        <Object?>[
          file,
          ...args,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## execlpe
  ///
  /// ### python docstring
  ///
  /// execlpe(file, *args, env)
  ///
  /// Execute the executable file (which is searched for along $PATH)
  /// with argument list args and environment env, replacing the current
  /// process.
  Object? execlpe({
    List<Object?> args = const <Object?>[],
    required Object? file,
  }) =>
      getFunction("execlpe").call(
        <Object?>[
          file,
          ...args,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## execvp
  ///
  /// ### python docstring
  ///
  /// execvp(file, args)
  ///
  /// Execute the executable file (which is searched for along $PATH)
  /// with argument list args, replacing the current process.
  /// args may be a list or tuple of strings.
  Object? execvp({
    required Object? file,
    required Object? args,
  }) =>
      getFunction("execvp").call(
        <Object?>[
          file,
          args,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## execvpe
  ///
  /// ### python docstring
  ///
  /// execvpe(file, args, env)
  ///
  /// Execute the executable file (which is searched for along $PATH)
  /// with argument list args and environment env, replacing the
  /// current process.
  /// args may be a list or tuple of strings.
  Object? execvpe({
    required Object? file,
    required Object? args,
    required Object? env,
  }) =>
      getFunction("execvpe").call(
        <Object?>[
          file,
          args,
          env,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## fdopen
  Object? fdopen({
    List<Object?> args = const <Object?>[],
    required Object? fd,
    Object? mode = "r",
    Object? buffering = -1,
    Object? encoding,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("fdopen").call(
        <Object?>[
          fd,
          mode,
          buffering,
          encoding,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## fsdecode
  ///
  /// ### python docstring
  ///
  /// Decode filename (an os.PathLike, bytes, or str) from the filesystem
  /// encoding with 'surrogateescape' error handler, return str unchanged. On
  /// Windows, use 'strict' error handler if the file system encoding is
  /// 'mbcs' (which is the default encoding).
  Object? fsdecode({
    required Object? filename,
  }) =>
      getFunction("fsdecode").call(
        <Object?>[
          filename,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## fsencode
  ///
  /// ### python docstring
  ///
  /// Encode filename (an os.PathLike, bytes, or str) to the filesystem
  /// encoding with 'surrogateescape' error handler, return bytes unchanged.
  /// On Windows, use 'strict' error handler if the file system encoding is
  /// 'mbcs' (which is the default encoding).
  Object? fsencode({
    required Object? filename,
  }) =>
      getFunction("fsencode").call(
        <Object?>[
          filename,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## fwalk
  ///
  /// ### python docstring
  ///
  /// Directory tree generator.
  ///
  /// This behaves exactly like walk(), except that it yields a 4-tuple
  ///
  ///     dirpath, dirnames, filenames, dirfd
  ///
  /// `dirpath`, `dirnames` and `filenames` are identical to walk() output,
  /// and `dirfd` is a file descriptor referring to the directory `dirpath`.
  ///
  /// The advantage of fwalk() over walk() is that it's safe against symlink
  /// races (when follow_symlinks is False).
  ///
  /// If dir_fd is not None, it should be a file descriptor open to a directory,
  ///   and top should be relative; top will then be relative to that directory.
  ///   (dir_fd is always supported for fwalk.)
  ///
  /// Caution:
  /// Since fwalk() yields file descriptors, those are only valid until the
  /// next iteration step, so you should dup() them if you want to keep them
  /// for a longer period.
  ///
  /// Example:
  ///
  /// import os
  /// for root, dirs, files, rootfd in os.fwalk('python/Lib/email'):
  ///     print(root, "consumes", end="")
  ///     print(sum(os.stat(name, dir_fd=rootfd).st_size for name in files),
  ///           end="")
  ///     print("bytes in", len(files), "non-directory files")
  ///     if 'CVS' in dirs:
  ///         dirs.remove('CVS')  # don't visit CVS directories
  Object? fwalk({
    Object? top = ".",
    Object? topdown = true,
    Object? onerror,
    Object? follow_symlinks = false,
    Object? dir_fd,
  }) =>
      getFunction("fwalk").call(
        <Object?>[
          top,
          topdown,
          onerror,
        ],
        kwargs: <String, Object?>{
          "follow_symlinks": follow_symlinks,
          "dir_fd": dir_fd,
        },
      );

  /// ## get_exec_path
  ///
  /// ### python docstring
  ///
  /// Returns the sequence of directories that will be searched for the
  /// named executable (similar to a shell) when launching a process.
  ///
  /// *env* must be an environment variable dict or None.  If *env* is None,
  /// os.environ will be used.
  Object? get_exec_path({
    Object? env,
  }) =>
      getFunction("get_exec_path").call(
        <Object?>[
          env,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## getenv
  ///
  /// ### python docstring
  ///
  /// Get an environment variable, return None if it doesn't exist.
  /// The optional second argument can specify an alternate default.
  /// key, default and the result are str.
  Object? getenv({
    required Object? key,
    Object? $default,
  }) =>
      getFunction("getenv").call(
        <Object?>[
          key,
          $default,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## getenvb
  ///
  /// ### python docstring
  ///
  /// Get an environment variable, return None if it doesn't exist.
  /// The optional second argument can specify an alternate default.
  /// key, default and the result are bytes.
  Object? getenvb({
    required Object? key,
    Object? $default,
  }) =>
      getFunction("getenvb").call(
        <Object?>[
          key,
          $default,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## makedirs
  ///
  /// ### python docstring
  ///
  /// makedirs(name [, mode=0o777][, exist_ok=False])
  ///
  /// Super-mkdir; create a leaf directory and all intermediate ones.  Works like
  /// mkdir, except that any intermediate path segment (not just the rightmost)
  /// will be created if it does not exist. If the target directory already
  /// exists, raise an OSError if exist_ok is False. Otherwise no exception is
  /// raised.  This is recursive.
  Object? makedirs({
    required Object? name,
    Object? mode = 511,
    Object? exist_ok = false,
  }) =>
      getFunction("makedirs").call(
        <Object?>[
          name,
          mode,
          exist_ok,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## popen
  Object? popen({
    required Object? cmd,
    Object? mode = "r",
    Object? buffering = -1,
  }) =>
      getFunction("popen").call(
        <Object?>[
          cmd,
          mode,
          buffering,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## removedirs
  ///
  /// ### python docstring
  ///
  /// removedirs(name)
  ///
  /// Super-rmdir; remove a leaf directory and all empty intermediate
  /// ones.  Works like rmdir except that, if the leaf directory is
  /// successfully removed, directories corresponding to rightmost path
  /// segments will be pruned away until either the whole path is
  /// consumed or an error occurs.  Errors during this latter phase are
  /// ignored -- they generally mean that a directory was not empty.
  Object? removedirs({
    required Object? name,
  }) =>
      getFunction("removedirs").call(
        <Object?>[
          name,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## renames
  ///
  /// ### python docstring
  ///
  /// renames(old, new)
  ///
  /// Super-rename; create directories as necessary and delete any left
  /// empty.  Works like rename, except creation of any intermediate
  /// directories needed to make the new pathname good is attempted
  /// first.  After the rename, directories corresponding to rightmost
  /// path segments of the old name will be pruned until either the
  /// whole path is consumed or a nonempty directory is found.
  ///
  /// Note: this function can fail with the new directory structure made
  /// if you lack permissions needed to unlink the leaf directory or
  /// file.
  Object? renames({
    required Object? old,
    required Object? $new,
  }) =>
      getFunction("renames").call(
        <Object?>[
          old,
          $new,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## spawnl
  ///
  /// ### python docstring
  ///
  /// spawnl(mode, file, *args) -> integer
  ///
  /// Execute file with arguments from args in a subprocess.
  /// If mode == P_NOWAIT return the pid of the process.
  /// If mode == P_WAIT return the process's exit code if it exits normally;
  /// otherwise return -SIG, where SIG is the signal that killed it.
  Object? spawnl({
    List<Object?> args = const <Object?>[],
    required Object? mode,
    required Object? file,
  }) =>
      getFunction("spawnl").call(
        <Object?>[
          mode,
          file,
          ...args,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## spawnle
  ///
  /// ### python docstring
  ///
  /// spawnle(mode, file, *args, env) -> integer
  ///
  /// Execute file with arguments from args in a subprocess with the
  /// supplied environment.
  /// If mode == P_NOWAIT return the pid of the process.
  /// If mode == P_WAIT return the process's exit code if it exits normally;
  /// otherwise return -SIG, where SIG is the signal that killed it.
  Object? spawnle({
    List<Object?> args = const <Object?>[],
    required Object? mode,
    required Object? file,
  }) =>
      getFunction("spawnle").call(
        <Object?>[
          mode,
          file,
          ...args,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## spawnlp
  ///
  /// ### python docstring
  ///
  /// spawnlp(mode, file, *args) -> integer
  ///
  /// Execute file (which is looked for along $PATH) with arguments from
  /// args in a subprocess with the supplied environment.
  /// If mode == P_NOWAIT return the pid of the process.
  /// If mode == P_WAIT return the process's exit code if it exits normally;
  /// otherwise return -SIG, where SIG is the signal that killed it.
  Object? spawnlp({
    List<Object?> args = const <Object?>[],
    required Object? mode,
    required Object? file,
  }) =>
      getFunction("spawnlp").call(
        <Object?>[
          mode,
          file,
          ...args,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## spawnlpe
  ///
  /// ### python docstring
  ///
  /// spawnlpe(mode, file, *args, env) -> integer
  ///
  /// Execute file (which is looked for along $PATH) with arguments from
  /// args in a subprocess with the supplied environment.
  /// If mode == P_NOWAIT return the pid of the process.
  /// If mode == P_WAIT return the process's exit code if it exits normally;
  /// otherwise return -SIG, where SIG is the signal that killed it.
  Object? spawnlpe({
    List<Object?> args = const <Object?>[],
    required Object? mode,
    required Object? file,
  }) =>
      getFunction("spawnlpe").call(
        <Object?>[
          mode,
          file,
          ...args,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## spawnv
  ///
  /// ### python docstring
  ///
  /// spawnv(mode, file, args) -> integer
  ///
  /// Execute file with arguments from args in a subprocess.
  /// If mode == P_NOWAIT return the pid of the process.
  /// If mode == P_WAIT return the process's exit code if it exits normally;
  /// otherwise return -SIG, where SIG is the signal that killed it.
  Object? spawnv({
    required Object? mode,
    required Object? file,
    required Object? args,
  }) =>
      getFunction("spawnv").call(
        <Object?>[
          mode,
          file,
          args,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## spawnve
  ///
  /// ### python docstring
  ///
  /// spawnve(mode, file, args, env) -> integer
  ///
  /// Execute file with arguments from args in a subprocess with the
  /// specified environment.
  /// If mode == P_NOWAIT return the pid of the process.
  /// If mode == P_WAIT return the process's exit code if it exits normally;
  /// otherwise return -SIG, where SIG is the signal that killed it.
  Object? spawnve({
    required Object? mode,
    required Object? file,
    required Object? args,
    required Object? env,
  }) =>
      getFunction("spawnve").call(
        <Object?>[
          mode,
          file,
          args,
          env,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## spawnvp
  ///
  /// ### python docstring
  ///
  /// spawnvp(mode, file, args) -> integer
  ///
  /// Execute file (which is looked for along $PATH) with arguments from
  /// args in a subprocess.
  /// If mode == P_NOWAIT return the pid of the process.
  /// If mode == P_WAIT return the process's exit code if it exits normally;
  /// otherwise return -SIG, where SIG is the signal that killed it.
  Object? spawnvp({
    required Object? mode,
    required Object? file,
    required Object? args,
  }) =>
      getFunction("spawnvp").call(
        <Object?>[
          mode,
          file,
          args,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## spawnvpe
  ///
  /// ### python docstring
  ///
  /// spawnvpe(mode, file, args, env) -> integer
  ///
  /// Execute file (which is looked for along $PATH) with arguments from
  /// args in a subprocess with the supplied environment.
  /// If mode == P_NOWAIT return the pid of the process.
  /// If mode == P_WAIT return the process's exit code if it exits normally;
  /// otherwise return -SIG, where SIG is the signal that killed it.
  Object? spawnvpe({
    required Object? mode,
    required Object? file,
    required Object? args,
    required Object? env,
  }) =>
      getFunction("spawnvpe").call(
        <Object?>[
          mode,
          file,
          args,
          env,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## walk
  ///
  /// ### python docstring
  ///
  /// Directory tree generator.
  ///
  /// For each directory in the directory tree rooted at top (including top
  /// itself, but excluding '.' and '..'), yields a 3-tuple
  ///
  ///     dirpath, dirnames, filenames
  ///
  /// dirpath is a string, the path to the directory.  dirnames is a list of
  /// the names of the subdirectories in dirpath (including symlinks to directories,
  /// and excluding '.' and '..').
  /// filenames is a list of the names of the non-directory files in dirpath.
  /// Note that the names in the lists are just names, with no path components.
  /// To get a full path (which begins with top) to a file or directory in
  /// dirpath, do os.path.join(dirpath, name).
  ///
  /// If optional arg 'topdown' is true or not specified, the triple for a
  /// directory is generated before the triples for any of its subdirectories
  /// (directories are generated top down).  If topdown is false, the triple
  /// for a directory is generated after the triples for all of its
  /// subdirectories (directories are generated bottom up).
  ///
  /// When topdown is true, the caller can modify the dirnames list in-place
  /// (e.g., via del or slice assignment), and walk will only recurse into the
  /// subdirectories whose names remain in dirnames; this can be used to prune the
  /// search, or to impose a specific order of visiting.  Modifying dirnames when
  /// topdown is false has no effect on the behavior of os.walk(), since the
  /// directories in dirnames have already been generated by the time dirnames
  /// itself is generated. No matter the value of topdown, the list of
  /// subdirectories is retrieved before the tuples for the directory and its
  /// subdirectories are generated.
  ///
  /// By default errors from the os.scandir() call are ignored.  If
  /// optional arg 'onerror' is specified, it should be a function; it
  /// will be called with one argument, an OSError instance.  It can
  /// report the error to continue with the walk, or raise the exception
  /// to abort the walk.  Note that the filename is available as the
  /// filename attribute of the exception object.
  ///
  /// By default, os.walk does not follow symbolic links to subdirectories on
  /// systems that support them.  In order to get this functionality, set the
  /// optional argument 'followlinks' to true.
  ///
  /// Caution:  if you pass a relative pathname for top, don't change the
  /// current working directory between resumptions of walk.  walk never
  /// changes the current directory, and assumes that the client doesn't
  /// either.
  ///
  /// Example:
  ///
  /// import os
  /// from os.path import join, getsize
  /// for root, dirs, files in os.walk('python/Lib/email'):
  ///     print(root, "consumes ")
  ///     print(sum(getsize(join(root, name)) for name in files), end=" ")
  ///     print("bytes in", len(files), "non-directory files")
  ///     if 'CVS' in dirs:
  ///         dirs.remove('CVS')  # don't visit CVS directories
  Object? walk({
    required Object? top,
    Object? topdown = true,
    Object? onerror,
    Object? followlinks = false,
  }) =>
      getFunction("walk").call(
        <Object?>[
          top,
          topdown,
          onerror,
          followlinks,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## CLD_CONTINUED (getter)
  Object? get CLD_CONTINUED => getAttribute("CLD_CONTINUED");

  /// ## CLD_CONTINUED (setter)
  set CLD_CONTINUED(Object? CLD_CONTINUED) =>
      setAttribute("CLD_CONTINUED", CLD_CONTINUED);

  /// ## CLD_DUMPED (getter)
  Object? get CLD_DUMPED => getAttribute("CLD_DUMPED");

  /// ## CLD_DUMPED (setter)
  set CLD_DUMPED(Object? CLD_DUMPED) => setAttribute("CLD_DUMPED", CLD_DUMPED);

  /// ## CLD_EXITED (getter)
  Object? get CLD_EXITED => getAttribute("CLD_EXITED");

  /// ## CLD_EXITED (setter)
  set CLD_EXITED(Object? CLD_EXITED) => setAttribute("CLD_EXITED", CLD_EXITED);

  /// ## CLD_KILLED (getter)
  Object? get CLD_KILLED => getAttribute("CLD_KILLED");

  /// ## CLD_KILLED (setter)
  set CLD_KILLED(Object? CLD_KILLED) => setAttribute("CLD_KILLED", CLD_KILLED);

  /// ## CLD_STOPPED (getter)
  Object? get CLD_STOPPED => getAttribute("CLD_STOPPED");

  /// ## CLD_STOPPED (setter)
  set CLD_STOPPED(Object? CLD_STOPPED) =>
      setAttribute("CLD_STOPPED", CLD_STOPPED);

  /// ## CLD_TRAPPED (getter)
  Object? get CLD_TRAPPED => getAttribute("CLD_TRAPPED");

  /// ## CLD_TRAPPED (setter)
  set CLD_TRAPPED(Object? CLD_TRAPPED) =>
      setAttribute("CLD_TRAPPED", CLD_TRAPPED);

  /// ## EX_CANTCREAT (getter)
  Object? get EX_CANTCREAT => getAttribute("EX_CANTCREAT");

  /// ## EX_CANTCREAT (setter)
  set EX_CANTCREAT(Object? EX_CANTCREAT) =>
      setAttribute("EX_CANTCREAT", EX_CANTCREAT);

  /// ## EX_CONFIG (getter)
  Object? get EX_CONFIG => getAttribute("EX_CONFIG");

  /// ## EX_CONFIG (setter)
  set EX_CONFIG(Object? EX_CONFIG) => setAttribute("EX_CONFIG", EX_CONFIG);

  /// ## EX_DATAERR (getter)
  Object? get EX_DATAERR => getAttribute("EX_DATAERR");

  /// ## EX_DATAERR (setter)
  set EX_DATAERR(Object? EX_DATAERR) => setAttribute("EX_DATAERR", EX_DATAERR);

  /// ## EX_IOERR (getter)
  Object? get EX_IOERR => getAttribute("EX_IOERR");

  /// ## EX_IOERR (setter)
  set EX_IOERR(Object? EX_IOERR) => setAttribute("EX_IOERR", EX_IOERR);

  /// ## EX_NOHOST (getter)
  Object? get EX_NOHOST => getAttribute("EX_NOHOST");

  /// ## EX_NOHOST (setter)
  set EX_NOHOST(Object? EX_NOHOST) => setAttribute("EX_NOHOST", EX_NOHOST);

  /// ## EX_NOINPUT (getter)
  Object? get EX_NOINPUT => getAttribute("EX_NOINPUT");

  /// ## EX_NOINPUT (setter)
  set EX_NOINPUT(Object? EX_NOINPUT) => setAttribute("EX_NOINPUT", EX_NOINPUT);

  /// ## EX_NOPERM (getter)
  Object? get EX_NOPERM => getAttribute("EX_NOPERM");

  /// ## EX_NOPERM (setter)
  set EX_NOPERM(Object? EX_NOPERM) => setAttribute("EX_NOPERM", EX_NOPERM);

  /// ## EX_NOUSER (getter)
  Object? get EX_NOUSER => getAttribute("EX_NOUSER");

  /// ## EX_NOUSER (setter)
  set EX_NOUSER(Object? EX_NOUSER) => setAttribute("EX_NOUSER", EX_NOUSER);

  /// ## EX_OK (getter)
  Object? get EX_OK => getAttribute("EX_OK");

  /// ## EX_OK (setter)
  set EX_OK(Object? EX_OK) => setAttribute("EX_OK", EX_OK);

  /// ## EX_OSERR (getter)
  Object? get EX_OSERR => getAttribute("EX_OSERR");

  /// ## EX_OSERR (setter)
  set EX_OSERR(Object? EX_OSERR) => setAttribute("EX_OSERR", EX_OSERR);

  /// ## EX_OSFILE (getter)
  Object? get EX_OSFILE => getAttribute("EX_OSFILE");

  /// ## EX_OSFILE (setter)
  set EX_OSFILE(Object? EX_OSFILE) => setAttribute("EX_OSFILE", EX_OSFILE);

  /// ## EX_PROTOCOL (getter)
  Object? get EX_PROTOCOL => getAttribute("EX_PROTOCOL");

  /// ## EX_PROTOCOL (setter)
  set EX_PROTOCOL(Object? EX_PROTOCOL) =>
      setAttribute("EX_PROTOCOL", EX_PROTOCOL);

  /// ## EX_SOFTWARE (getter)
  Object? get EX_SOFTWARE => getAttribute("EX_SOFTWARE");

  /// ## EX_SOFTWARE (setter)
  set EX_SOFTWARE(Object? EX_SOFTWARE) =>
      setAttribute("EX_SOFTWARE", EX_SOFTWARE);

  /// ## EX_TEMPFAIL (getter)
  Object? get EX_TEMPFAIL => getAttribute("EX_TEMPFAIL");

  /// ## EX_TEMPFAIL (setter)
  set EX_TEMPFAIL(Object? EX_TEMPFAIL) =>
      setAttribute("EX_TEMPFAIL", EX_TEMPFAIL);

  /// ## EX_UNAVAILABLE (getter)
  Object? get EX_UNAVAILABLE => getAttribute("EX_UNAVAILABLE");

  /// ## EX_UNAVAILABLE (setter)
  set EX_UNAVAILABLE(Object? EX_UNAVAILABLE) =>
      setAttribute("EX_UNAVAILABLE", EX_UNAVAILABLE);

  /// ## EX_USAGE (getter)
  Object? get EX_USAGE => getAttribute("EX_USAGE");

  /// ## EX_USAGE (setter)
  set EX_USAGE(Object? EX_USAGE) => setAttribute("EX_USAGE", EX_USAGE);

  /// ## F_LOCK (getter)
  Object? get F_LOCK => getAttribute("F_LOCK");

  /// ## F_LOCK (setter)
  set F_LOCK(Object? F_LOCK) => setAttribute("F_LOCK", F_LOCK);

  /// ## F_OK (getter)
  Object? get F_OK => getAttribute("F_OK");

  /// ## F_OK (setter)
  set F_OK(Object? F_OK) => setAttribute("F_OK", F_OK);

  /// ## F_TEST (getter)
  Object? get F_TEST => getAttribute("F_TEST");

  /// ## F_TEST (setter)
  set F_TEST(Object? F_TEST) => setAttribute("F_TEST", F_TEST);

  /// ## F_TLOCK (getter)
  Object? get F_TLOCK => getAttribute("F_TLOCK");

  /// ## F_TLOCK (setter)
  set F_TLOCK(Object? F_TLOCK) => setAttribute("F_TLOCK", F_TLOCK);

  /// ## F_ULOCK (getter)
  Object? get F_ULOCK => getAttribute("F_ULOCK");

  /// ## F_ULOCK (setter)
  set F_ULOCK(Object? F_ULOCK) => setAttribute("F_ULOCK", F_ULOCK);

  /// ## NGROUPS_MAX (getter)
  Object? get NGROUPS_MAX => getAttribute("NGROUPS_MAX");

  /// ## NGROUPS_MAX (setter)
  set NGROUPS_MAX(Object? NGROUPS_MAX) =>
      setAttribute("NGROUPS_MAX", NGROUPS_MAX);

  /// ## O_ACCMODE (getter)
  Object? get O_ACCMODE => getAttribute("O_ACCMODE");

  /// ## O_ACCMODE (setter)
  set O_ACCMODE(Object? O_ACCMODE) => setAttribute("O_ACCMODE", O_ACCMODE);

  /// ## O_APPEND (getter)
  Object? get O_APPEND => getAttribute("O_APPEND");

  /// ## O_APPEND (setter)
  set O_APPEND(Object? O_APPEND) => setAttribute("O_APPEND", O_APPEND);

  /// ## O_ASYNC (getter)
  Object? get O_ASYNC => getAttribute("O_ASYNC");

  /// ## O_ASYNC (setter)
  set O_ASYNC(Object? O_ASYNC) => setAttribute("O_ASYNC", O_ASYNC);

  /// ## O_CLOEXEC (getter)
  Object? get O_CLOEXEC => getAttribute("O_CLOEXEC");

  /// ## O_CLOEXEC (setter)
  set O_CLOEXEC(Object? O_CLOEXEC) => setAttribute("O_CLOEXEC", O_CLOEXEC);

  /// ## O_CREAT (getter)
  Object? get O_CREAT => getAttribute("O_CREAT");

  /// ## O_CREAT (setter)
  set O_CREAT(Object? O_CREAT) => setAttribute("O_CREAT", O_CREAT);

  /// ## O_DIRECTORY (getter)
  Object? get O_DIRECTORY => getAttribute("O_DIRECTORY");

  /// ## O_DIRECTORY (setter)
  set O_DIRECTORY(Object? O_DIRECTORY) =>
      setAttribute("O_DIRECTORY", O_DIRECTORY);

  /// ## O_DSYNC (getter)
  Object? get O_DSYNC => getAttribute("O_DSYNC");

  /// ## O_DSYNC (setter)
  set O_DSYNC(Object? O_DSYNC) => setAttribute("O_DSYNC", O_DSYNC);

  /// ## O_EVTONLY (getter)
  Object? get O_EVTONLY => getAttribute("O_EVTONLY");

  /// ## O_EVTONLY (setter)
  set O_EVTONLY(Object? O_EVTONLY) => setAttribute("O_EVTONLY", O_EVTONLY);

  /// ## O_EXCL (getter)
  Object? get O_EXCL => getAttribute("O_EXCL");

  /// ## O_EXCL (setter)
  set O_EXCL(Object? O_EXCL) => setAttribute("O_EXCL", O_EXCL);

  /// ## O_EXEC (getter)
  Object? get O_EXEC => getAttribute("O_EXEC");

  /// ## O_EXEC (setter)
  set O_EXEC(Object? O_EXEC) => setAttribute("O_EXEC", O_EXEC);

  /// ## O_EXLOCK (getter)
  Object? get O_EXLOCK => getAttribute("O_EXLOCK");

  /// ## O_EXLOCK (setter)
  set O_EXLOCK(Object? O_EXLOCK) => setAttribute("O_EXLOCK", O_EXLOCK);

  /// ## O_FSYNC (getter)
  Object? get O_FSYNC => getAttribute("O_FSYNC");

  /// ## O_FSYNC (setter)
  set O_FSYNC(Object? O_FSYNC) => setAttribute("O_FSYNC", O_FSYNC);

  /// ## O_NDELAY (getter)
  Object? get O_NDELAY => getAttribute("O_NDELAY");

  /// ## O_NDELAY (setter)
  set O_NDELAY(Object? O_NDELAY) => setAttribute("O_NDELAY", O_NDELAY);

  /// ## O_NOCTTY (getter)
  Object? get O_NOCTTY => getAttribute("O_NOCTTY");

  /// ## O_NOCTTY (setter)
  set O_NOCTTY(Object? O_NOCTTY) => setAttribute("O_NOCTTY", O_NOCTTY);

  /// ## O_NOFOLLOW (getter)
  Object? get O_NOFOLLOW => getAttribute("O_NOFOLLOW");

  /// ## O_NOFOLLOW (setter)
  set O_NOFOLLOW(Object? O_NOFOLLOW) => setAttribute("O_NOFOLLOW", O_NOFOLLOW);

  /// ## O_NOFOLLOW_ANY (getter)
  Object? get O_NOFOLLOW_ANY => getAttribute("O_NOFOLLOW_ANY");

  /// ## O_NOFOLLOW_ANY (setter)
  set O_NOFOLLOW_ANY(Object? O_NOFOLLOW_ANY) =>
      setAttribute("O_NOFOLLOW_ANY", O_NOFOLLOW_ANY);

  /// ## O_NONBLOCK (getter)
  Object? get O_NONBLOCK => getAttribute("O_NONBLOCK");

  /// ## O_NONBLOCK (setter)
  set O_NONBLOCK(Object? O_NONBLOCK) => setAttribute("O_NONBLOCK", O_NONBLOCK);

  /// ## O_RDONLY (getter)
  Object? get O_RDONLY => getAttribute("O_RDONLY");

  /// ## O_RDONLY (setter)
  set O_RDONLY(Object? O_RDONLY) => setAttribute("O_RDONLY", O_RDONLY);

  /// ## O_RDWR (getter)
  Object? get O_RDWR => getAttribute("O_RDWR");

  /// ## O_RDWR (setter)
  set O_RDWR(Object? O_RDWR) => setAttribute("O_RDWR", O_RDWR);

  /// ## O_SEARCH (getter)
  Object? get O_SEARCH => getAttribute("O_SEARCH");

  /// ## O_SEARCH (setter)
  set O_SEARCH(Object? O_SEARCH) => setAttribute("O_SEARCH", O_SEARCH);

  /// ## O_SHLOCK (getter)
  Object? get O_SHLOCK => getAttribute("O_SHLOCK");

  /// ## O_SHLOCK (setter)
  set O_SHLOCK(Object? O_SHLOCK) => setAttribute("O_SHLOCK", O_SHLOCK);

  /// ## O_SYMLINK (getter)
  Object? get O_SYMLINK => getAttribute("O_SYMLINK");

  /// ## O_SYMLINK (setter)
  set O_SYMLINK(Object? O_SYMLINK) => setAttribute("O_SYMLINK", O_SYMLINK);

  /// ## O_SYNC (getter)
  Object? get O_SYNC => getAttribute("O_SYNC");

  /// ## O_SYNC (setter)
  set O_SYNC(Object? O_SYNC) => setAttribute("O_SYNC", O_SYNC);

  /// ## O_TRUNC (getter)
  Object? get O_TRUNC => getAttribute("O_TRUNC");

  /// ## O_TRUNC (setter)
  set O_TRUNC(Object? O_TRUNC) => setAttribute("O_TRUNC", O_TRUNC);

  /// ## O_WRONLY (getter)
  Object? get O_WRONLY => getAttribute("O_WRONLY");

  /// ## O_WRONLY (setter)
  set O_WRONLY(Object? O_WRONLY) => setAttribute("O_WRONLY", O_WRONLY);

  /// ## POSIX_SPAWN_CLOSE (getter)
  Object? get POSIX_SPAWN_CLOSE => getAttribute("POSIX_SPAWN_CLOSE");

  /// ## POSIX_SPAWN_CLOSE (setter)
  set POSIX_SPAWN_CLOSE(Object? POSIX_SPAWN_CLOSE) =>
      setAttribute("POSIX_SPAWN_CLOSE", POSIX_SPAWN_CLOSE);

  /// ## POSIX_SPAWN_DUP2 (getter)
  Object? get POSIX_SPAWN_DUP2 => getAttribute("POSIX_SPAWN_DUP2");

  /// ## POSIX_SPAWN_DUP2 (setter)
  set POSIX_SPAWN_DUP2(Object? POSIX_SPAWN_DUP2) =>
      setAttribute("POSIX_SPAWN_DUP2", POSIX_SPAWN_DUP2);

  /// ## POSIX_SPAWN_OPEN (getter)
  Object? get POSIX_SPAWN_OPEN => getAttribute("POSIX_SPAWN_OPEN");

  /// ## POSIX_SPAWN_OPEN (setter)
  set POSIX_SPAWN_OPEN(Object? POSIX_SPAWN_OPEN) =>
      setAttribute("POSIX_SPAWN_OPEN", POSIX_SPAWN_OPEN);

  /// ## PRIO_PGRP (getter)
  Object? get PRIO_PGRP => getAttribute("PRIO_PGRP");

  /// ## PRIO_PGRP (setter)
  set PRIO_PGRP(Object? PRIO_PGRP) => setAttribute("PRIO_PGRP", PRIO_PGRP);

  /// ## PRIO_PROCESS (getter)
  Object? get PRIO_PROCESS => getAttribute("PRIO_PROCESS");

  /// ## PRIO_PROCESS (setter)
  set PRIO_PROCESS(Object? PRIO_PROCESS) =>
      setAttribute("PRIO_PROCESS", PRIO_PROCESS);

  /// ## PRIO_USER (getter)
  Object? get PRIO_USER => getAttribute("PRIO_USER");

  /// ## PRIO_USER (setter)
  set PRIO_USER(Object? PRIO_USER) => setAttribute("PRIO_USER", PRIO_USER);

  /// ## P_ALL (getter)
  Object? get P_ALL => getAttribute("P_ALL");

  /// ## P_ALL (setter)
  set P_ALL(Object? P_ALL) => setAttribute("P_ALL", P_ALL);

  /// ## P_NOWAIT (getter)
  Object? get P_NOWAIT => getAttribute("P_NOWAIT");

  /// ## P_NOWAIT (setter)
  set P_NOWAIT(Object? P_NOWAIT) => setAttribute("P_NOWAIT", P_NOWAIT);

  /// ## P_NOWAITO (getter)
  Object? get P_NOWAITO => getAttribute("P_NOWAITO");

  /// ## P_NOWAITO (setter)
  set P_NOWAITO(Object? P_NOWAITO) => setAttribute("P_NOWAITO", P_NOWAITO);

  /// ## P_PGID (getter)
  Object? get P_PGID => getAttribute("P_PGID");

  /// ## P_PGID (setter)
  set P_PGID(Object? P_PGID) => setAttribute("P_PGID", P_PGID);

  /// ## P_PID (getter)
  Object? get P_PID => getAttribute("P_PID");

  /// ## P_PID (setter)
  set P_PID(Object? P_PID) => setAttribute("P_PID", P_PID);

  /// ## P_WAIT (getter)
  Object? get P_WAIT => getAttribute("P_WAIT");

  /// ## P_WAIT (setter)
  set P_WAIT(Object? P_WAIT) => setAttribute("P_WAIT", P_WAIT);

  /// ## RTLD_GLOBAL (getter)
  Object? get RTLD_GLOBAL => getAttribute("RTLD_GLOBAL");

  /// ## RTLD_GLOBAL (setter)
  set RTLD_GLOBAL(Object? RTLD_GLOBAL) =>
      setAttribute("RTLD_GLOBAL", RTLD_GLOBAL);

  /// ## RTLD_LAZY (getter)
  Object? get RTLD_LAZY => getAttribute("RTLD_LAZY");

  /// ## RTLD_LAZY (setter)
  set RTLD_LAZY(Object? RTLD_LAZY) => setAttribute("RTLD_LAZY", RTLD_LAZY);

  /// ## RTLD_LOCAL (getter)
  Object? get RTLD_LOCAL => getAttribute("RTLD_LOCAL");

  /// ## RTLD_LOCAL (setter)
  set RTLD_LOCAL(Object? RTLD_LOCAL) => setAttribute("RTLD_LOCAL", RTLD_LOCAL);

  /// ## RTLD_NODELETE (getter)
  Object? get RTLD_NODELETE => getAttribute("RTLD_NODELETE");

  /// ## RTLD_NODELETE (setter)
  set RTLD_NODELETE(Object? RTLD_NODELETE) =>
      setAttribute("RTLD_NODELETE", RTLD_NODELETE);

  /// ## RTLD_NOLOAD (getter)
  Object? get RTLD_NOLOAD => getAttribute("RTLD_NOLOAD");

  /// ## RTLD_NOLOAD (setter)
  set RTLD_NOLOAD(Object? RTLD_NOLOAD) =>
      setAttribute("RTLD_NOLOAD", RTLD_NOLOAD);

  /// ## RTLD_NOW (getter)
  Object? get RTLD_NOW => getAttribute("RTLD_NOW");

  /// ## RTLD_NOW (setter)
  set RTLD_NOW(Object? RTLD_NOW) => setAttribute("RTLD_NOW", RTLD_NOW);

  /// ## R_OK (getter)
  Object? get R_OK => getAttribute("R_OK");

  /// ## R_OK (setter)
  set R_OK(Object? R_OK) => setAttribute("R_OK", R_OK);

  /// ## SCHED_FIFO (getter)
  Object? get SCHED_FIFO => getAttribute("SCHED_FIFO");

  /// ## SCHED_FIFO (setter)
  set SCHED_FIFO(Object? SCHED_FIFO) => setAttribute("SCHED_FIFO", SCHED_FIFO);

  /// ## SCHED_OTHER (getter)
  Object? get SCHED_OTHER => getAttribute("SCHED_OTHER");

  /// ## SCHED_OTHER (setter)
  set SCHED_OTHER(Object? SCHED_OTHER) =>
      setAttribute("SCHED_OTHER", SCHED_OTHER);

  /// ## SCHED_RR (getter)
  Object? get SCHED_RR => getAttribute("SCHED_RR");

  /// ## SCHED_RR (setter)
  set SCHED_RR(Object? SCHED_RR) => setAttribute("SCHED_RR", SCHED_RR);

  /// ## SEEK_CUR (getter)
  Object? get SEEK_CUR => getAttribute("SEEK_CUR");

  /// ## SEEK_CUR (setter)
  set SEEK_CUR(Object? SEEK_CUR) => setAttribute("SEEK_CUR", SEEK_CUR);

  /// ## SEEK_DATA (getter)
  Object? get SEEK_DATA => getAttribute("SEEK_DATA");

  /// ## SEEK_DATA (setter)
  set SEEK_DATA(Object? SEEK_DATA) => setAttribute("SEEK_DATA", SEEK_DATA);

  /// ## SEEK_END (getter)
  Object? get SEEK_END => getAttribute("SEEK_END");

  /// ## SEEK_END (setter)
  set SEEK_END(Object? SEEK_END) => setAttribute("SEEK_END", SEEK_END);

  /// ## SEEK_HOLE (getter)
  Object? get SEEK_HOLE => getAttribute("SEEK_HOLE");

  /// ## SEEK_HOLE (setter)
  set SEEK_HOLE(Object? SEEK_HOLE) => setAttribute("SEEK_HOLE", SEEK_HOLE);

  /// ## SEEK_SET (getter)
  Object? get SEEK_SET => getAttribute("SEEK_SET");

  /// ## SEEK_SET (setter)
  set SEEK_SET(Object? SEEK_SET) => setAttribute("SEEK_SET", SEEK_SET);

  /// ## ST_NOSUID (getter)
  Object? get ST_NOSUID => getAttribute("ST_NOSUID");

  /// ## ST_NOSUID (setter)
  set ST_NOSUID(Object? ST_NOSUID) => setAttribute("ST_NOSUID", ST_NOSUID);

  /// ## ST_RDONLY (getter)
  Object? get ST_RDONLY => getAttribute("ST_RDONLY");

  /// ## ST_RDONLY (setter)
  set ST_RDONLY(Object? ST_RDONLY) => setAttribute("ST_RDONLY", ST_RDONLY);

  /// ## TMP_MAX (getter)
  Object? get TMP_MAX => getAttribute("TMP_MAX");

  /// ## TMP_MAX (setter)
  set TMP_MAX(Object? TMP_MAX) => setAttribute("TMP_MAX", TMP_MAX);

  /// ## WCONTINUED (getter)
  Object? get WCONTINUED => getAttribute("WCONTINUED");

  /// ## WCONTINUED (setter)
  set WCONTINUED(Object? WCONTINUED) => setAttribute("WCONTINUED", WCONTINUED);

  /// ## WEXITED (getter)
  Object? get WEXITED => getAttribute("WEXITED");

  /// ## WEXITED (setter)
  set WEXITED(Object? WEXITED) => setAttribute("WEXITED", WEXITED);

  /// ## WNOHANG (getter)
  Object? get WNOHANG => getAttribute("WNOHANG");

  /// ## WNOHANG (setter)
  set WNOHANG(Object? WNOHANG) => setAttribute("WNOHANG", WNOHANG);

  /// ## WNOWAIT (getter)
  Object? get WNOWAIT => getAttribute("WNOWAIT");

  /// ## WNOWAIT (setter)
  set WNOWAIT(Object? WNOWAIT) => setAttribute("WNOWAIT", WNOWAIT);

  /// ## WSTOPPED (getter)
  Object? get WSTOPPED => getAttribute("WSTOPPED");

  /// ## WSTOPPED (setter)
  set WSTOPPED(Object? WSTOPPED) => setAttribute("WSTOPPED", WSTOPPED);

  /// ## WUNTRACED (getter)
  Object? get WUNTRACED => getAttribute("WUNTRACED");

  /// ## WUNTRACED (setter)
  set WUNTRACED(Object? WUNTRACED) => setAttribute("WUNTRACED", WUNTRACED);

  /// ## W_OK (getter)
  Object? get W_OK => getAttribute("W_OK");

  /// ## W_OK (setter)
  set W_OK(Object? W_OK) => setAttribute("W_OK", W_OK);

  /// ## X_OK (getter)
  Object? get X_OK => getAttribute("X_OK");

  /// ## X_OK (setter)
  set X_OK(Object? X_OK) => setAttribute("X_OK", X_OK);

  /// ## altsep (getter)
  Object? get altsep => getAttribute("altsep");

  /// ## altsep (setter)
  set altsep(Object? altsep) => setAttribute("altsep", altsep);

  /// ## confstr_names (getter)
  Object? get confstr_names => getAttribute("confstr_names");

  /// ## confstr_names (setter)
  set confstr_names(Object? confstr_names) =>
      setAttribute("confstr_names", confstr_names);

  /// ## curdir (getter)
  Object? get curdir => getAttribute("curdir");

  /// ## curdir (setter)
  set curdir(Object? curdir) => setAttribute("curdir", curdir);

  /// ## defpath (getter)
  Object? get defpath => getAttribute("defpath");

  /// ## defpath (setter)
  set defpath(Object? defpath) => setAttribute("defpath", defpath);

  /// ## devnull (getter)
  Object? get devnull => getAttribute("devnull");

  /// ## devnull (setter)
  set devnull(Object? devnull) => setAttribute("devnull", devnull);

  /// ## extsep (getter)
  Object? get extsep => getAttribute("extsep");

  /// ## extsep (setter)
  set extsep(Object? extsep) => setAttribute("extsep", extsep);

  /// ## linesep (getter)
  Object? get linesep => getAttribute("linesep");

  /// ## linesep (setter)
  set linesep(Object? linesep) => setAttribute("linesep", linesep);

  /// ## name (getter)
  Object? get name => getAttribute("name");

  /// ## name (setter)
  set name(Object? name) => setAttribute("name", name);

  /// ## pardir (getter)
  Object? get pardir => getAttribute("pardir");

  /// ## pardir (setter)
  set pardir(Object? pardir) => setAttribute("pardir", pardir);

  /// ## pathconf_names (getter)
  Object? get pathconf_names => getAttribute("pathconf_names");

  /// ## pathconf_names (setter)
  set pathconf_names(Object? pathconf_names) =>
      setAttribute("pathconf_names", pathconf_names);

  /// ## pathsep (getter)
  Object? get pathsep => getAttribute("pathsep");

  /// ## pathsep (setter)
  set pathsep(Object? pathsep) => setAttribute("pathsep", pathsep);

  /// ## sep (getter)
  Object? get sep => getAttribute("sep");

  /// ## sep (setter)
  set sep(Object? sep) => setAttribute("sep", sep);

  /// ## supports_bytes_environ (getter)
  Object? get supports_bytes_environ => getAttribute("supports_bytes_environ");

  /// ## supports_bytes_environ (setter)
  set supports_bytes_environ(Object? supports_bytes_environ) =>
      setAttribute("supports_bytes_environ", supports_bytes_environ);

  /// ## supports_dir_fd (getter)
  Object? get supports_dir_fd => getAttribute("supports_dir_fd");

  /// ## supports_dir_fd (setter)
  set supports_dir_fd(Object? supports_dir_fd) =>
      setAttribute("supports_dir_fd", supports_dir_fd);

  /// ## supports_effective_ids (getter)
  Object? get supports_effective_ids => getAttribute("supports_effective_ids");

  /// ## supports_effective_ids (setter)
  set supports_effective_ids(Object? supports_effective_ids) =>
      setAttribute("supports_effective_ids", supports_effective_ids);

  /// ## supports_fd (getter)
  Object? get supports_fd => getAttribute("supports_fd");

  /// ## supports_fd (setter)
  set supports_fd(Object? supports_fd) =>
      setAttribute("supports_fd", supports_fd);

  /// ## supports_follow_symlinks (getter)
  Object? get supports_follow_symlinks =>
      getAttribute("supports_follow_symlinks");

  /// ## supports_follow_symlinks (setter)
  set supports_follow_symlinks(Object? supports_follow_symlinks) =>
      setAttribute("supports_follow_symlinks", supports_follow_symlinks);

  /// ## sysconf_names (getter)
  Object? get sysconf_names => getAttribute("sysconf_names");

  /// ## sysconf_names (setter)
  set sysconf_names(Object? sysconf_names) =>
      setAttribute("sysconf_names", sysconf_names);
}

/// ## path
///
/// ### python docstring
///
/// Common operations on Posix pathnames.
///
/// Instead of importing this module directly, import os and refer to
/// this module as os.path.  The "os.path" name is an alias for this
/// module on Posix systems; on other systems (e.g. Windows),
/// os.path provides the same operations in a manner specific to that
/// platform, and is an alias to another module (e.g. ntpath).
///
/// Some of this can actually be useful on non-Posix systems too, e.g.
/// for manipulation of the pathname component of URLs.
///
/// ### python source
/// ```py
/// """Common operations on Posix pathnames.
///
/// Instead of importing this module directly, import os and refer to
/// this module as os.path.  The "os.path" name is an alias for this
/// module on Posix systems; on other systems (e.g. Windows),
/// os.path provides the same operations in a manner specific to that
/// platform, and is an alias to another module (e.g. ntpath).
///
/// Some of this can actually be useful on non-Posix systems too, e.g.
/// for manipulation of the pathname component of URLs.
/// """
///
/// # Strings representing various path-related bits and pieces.
/// # These are primarily for export; internally, they are hardcoded.
/// # Should be set before imports for resolving cyclic dependency.
/// curdir = '.'
/// pardir = '..'
/// extsep = '.'
/// sep = '/'
/// pathsep = ':'
/// defpath = '/bin:/usr/bin'
/// altsep = None
/// devnull = '/dev/null'
///
/// import os
/// import sys
/// import stat
/// import genericpath
/// from genericpath import *
///
/// __all__ = ["normcase","isabs","join","splitdrive","split","splitext",
///            "basename","dirname","commonprefix","getsize","getmtime",
///            "getatime","getctime","islink","exists","lexists","isdir","isfile",
///            "ismount", "expanduser","expandvars","normpath","abspath",
///            "samefile","sameopenfile","samestat",
///            "curdir","pardir","sep","pathsep","defpath","altsep","extsep",
///            "devnull","realpath","supports_unicode_filenames","relpath",
///            "commonpath"]
///
///
/// def _get_sep(path):
///     if isinstance(path, bytes):
///         return b'/'
///     else:
///         return '/'
///
/// # Normalize the case of a pathname.  Trivial in Posix, string.lower on Mac.
/// # On MS-DOS this may also turn slashes into backslashes; however, other
/// # normalizations (such as optimizing '../' away) are not allowed
/// # (another function should be defined to do that).
///
/// def normcase(s):
///     """Normalize case of pathname.  Has no effect under Posix"""
///     return os.fspath(s)
///
///
/// # Return whether a path is absolute.
/// # Trivial in Posix, harder on the Mac or MS-DOS.
///
/// def isabs(s):
///     """Test whether a path is absolute"""
///     s = os.fspath(s)
///     sep = _get_sep(s)
///     return s.startswith(sep)
///
///
/// # Join pathnames.
/// # Ignore the previous parts if a part is absolute.
/// # Insert a '/' unless the first part is empty or already ends in '/'.
///
/// def join(a, *p):
///     """Join two or more pathname components, inserting '/' as needed.
///     If any component is an absolute path, all previous path components
///     will be discarded.  An empty last part will result in a path that
///     ends with a separator."""
///     a = os.fspath(a)
///     sep = _get_sep(a)
///     path = a
///     try:
///         if not p:
///             path[:0] + sep  #23780: Ensure compatible data type even if p is null.
///         for b in map(os.fspath, p):
///             if b.startswith(sep):
///                 path = b
///             elif not path or path.endswith(sep):
///                 path += b
///             else:
///                 path += sep + b
///     except (TypeError, AttributeError, BytesWarning):
///         genericpath._check_arg_types('join', a, *p)
///         raise
///     return path
///
///
/// # Split a path in head (everything up to the last '/') and tail (the
/// # rest).  If the path ends in '/', tail will be empty.  If there is no
/// # '/' in the path, head  will be empty.
/// # Trailing '/'es are stripped from head unless it is the root.
///
/// def split(p):
///     """Split a pathname.  Returns tuple "(head, tail)" where "tail" is
///     everything after the final slash.  Either part may be empty."""
///     p = os.fspath(p)
///     sep = _get_sep(p)
///     i = p.rfind(sep) + 1
///     head, tail = p[:i], p[i:]
///     if head and head != sep*len(head):
///         head = head.rstrip(sep)
///     return head, tail
///
///
/// # Split a path in root and extension.
/// # The extension is everything starting at the last dot in the last
/// # pathname component; the root is everything before that.
/// # It is always true that root + ext == p.
///
/// def splitext(p):
///     p = os.fspath(p)
///     if isinstance(p, bytes):
///         sep = b'/'
///         extsep = b'.'
///     else:
///         sep = '/'
///         extsep = '.'
///     return genericpath._splitext(p, sep, None, extsep)
/// splitext.__doc__ = genericpath._splitext.__doc__
///
/// # Split a pathname into a drive specification and the rest of the
/// # path.  Useful on DOS/Windows/NT; on Unix, the drive is always empty.
///
/// def splitdrive(p):
///     """Split a pathname into drive and path. On Posix, drive is always
///     empty."""
///     p = os.fspath(p)
///     return p[:0], p
///
///
/// # Return the tail (basename) part of a path, same as split(path)[1].
///
/// def basename(p):
///     """Returns the final component of a pathname"""
///     p = os.fspath(p)
///     sep = _get_sep(p)
///     i = p.rfind(sep) + 1
///     return p[i:]
///
///
/// # Return the head (dirname) part of a path, same as split(path)[0].
///
/// def dirname(p):
///     """Returns the directory component of a pathname"""
///     p = os.fspath(p)
///     sep = _get_sep(p)
///     i = p.rfind(sep) + 1
///     head = p[:i]
///     if head and head != sep*len(head):
///         head = head.rstrip(sep)
///     return head
///
///
/// # Is a path a symbolic link?
/// # This will always return false on systems where os.lstat doesn't exist.
///
/// def islink(path):
///     """Test whether a path is a symbolic link"""
///     try:
///         st = os.lstat(path)
///     except (OSError, ValueError, AttributeError):
///         return False
///     return stat.S_ISLNK(st.st_mode)
///
/// # Being true for dangling symbolic links is also useful.
///
/// def lexists(path):
///     """Test whether a path exists.  Returns True for broken symbolic links"""
///     try:
///         os.lstat(path)
///     except (OSError, ValueError):
///         return False
///     return True
///
///
/// # Is a path a mount point?
/// # (Does this work for all UNIXes?  Is it even guaranteed to work by Posix?)
///
/// def ismount(path):
///     """Test whether a path is a mount point"""
///     try:
///         s1 = os.lstat(path)
///     except (OSError, ValueError):
///         # It doesn't exist -- so not a mount point. :-)
///         return False
///     else:
///         # A symlink can never be a mount point
///         if stat.S_ISLNK(s1.st_mode):
///             return False
///
///     path = os.fspath(path)
///     if isinstance(path, bytes):
///         parent = join(path, b'..')
///     else:
///         parent = join(path, '..')
///     parent = realpath(parent)
///     try:
///         s2 = os.lstat(parent)
///     except (OSError, ValueError):
///         return False
///
///     dev1 = s1.st_dev
///     dev2 = s2.st_dev
///     if dev1 != dev2:
///         return True     # path/.. on a different device as path
///     ino1 = s1.st_ino
///     ino2 = s2.st_ino
///     if ino1 == ino2:
///         return True     # path/.. is the same i-node as path
///     return False
///
///
/// # Expand paths beginning with '~' or '~user'.
/// # '~' means $HOME; '~user' means that user's home directory.
/// # If the path doesn't begin with '~', or if the user or $HOME is unknown,
/// # the path is returned unchanged (leaving error reporting to whatever
/// # function is called with the expanded path as argument).
/// # See also module 'glob' for expansion of *, ? and [...] in pathnames.
/// # (A function should also be defined to do full *sh-style environment
/// # variable expansion.)
///
/// def expanduser(path):
///     """Expand ~ and ~user constructions.  If user or $HOME is unknown,
///     do nothing."""
///     path = os.fspath(path)
///     if isinstance(path, bytes):
///         tilde = b'~'
///     else:
///         tilde = '~'
///     if not path.startswith(tilde):
///         return path
///     sep = _get_sep(path)
///     i = path.find(sep, 1)
///     if i < 0:
///         i = len(path)
///     if i == 1:
///         if 'HOME' not in os.environ:
///             try:
///                 import pwd
///             except ImportError:
///                 # pwd module unavailable, return path unchanged
///                 return path
///             try:
///                 userhome = pwd.getpwuid(os.getuid()).pw_dir
///             except KeyError:
///                 # bpo-10496: if the current user identifier doesn't exist in the
///                 # password database, return the path unchanged
///                 return path
///         else:
///             userhome = os.environ['HOME']
///     else:
///         try:
///             import pwd
///         except ImportError:
///             # pwd module unavailable, return path unchanged
///             return path
///         name = path[1:i]
///         if isinstance(name, bytes):
///             name = str(name, 'ASCII')
///         try:
///             pwent = pwd.getpwnam(name)
///         except KeyError:
///             # bpo-10496: if the user name from the path doesn't exist in the
///             # password database, return the path unchanged
///             return path
///         userhome = pwent.pw_dir
///     # if no user home, return the path unchanged on VxWorks
///     if userhome is None and sys.platform == "vxworks":
///         return path
///     if isinstance(path, bytes):
///         userhome = os.fsencode(userhome)
///         root = b'/'
///     else:
///         root = '/'
///     userhome = userhome.rstrip(root)
///     return (userhome + path[i:]) or root
///
///
/// # Expand paths containing shell variable substitutions.
/// # This expands the forms $variable and ${variable} only.
/// # Non-existent variables are left unchanged.
///
/// _varprog = None
/// _varprogb = None
///
/// def expandvars(path):
///     """Expand shell variables of form $var and ${var}.  Unknown variables
///     are left unchanged."""
///     path = os.fspath(path)
///     global _varprog, _varprogb
///     if isinstance(path, bytes):
///         if b'$' not in path:
///             return path
///         if not _varprogb:
///             import re
///             _varprogb = re.compile(br'\$(\w+|\{[^}]*\})', re.ASCII)
///         search = _varprogb.search
///         start = b'{'
///         end = b'}'
///         environ = getattr(os, 'environb', None)
///     else:
///         if '$' not in path:
///             return path
///         if not _varprog:
///             import re
///             _varprog = re.compile(r'\$(\w+|\{[^}]*\})', re.ASCII)
///         search = _varprog.search
///         start = '{'
///         end = '}'
///         environ = os.environ
///     i = 0
///     while True:
///         m = search(path, i)
///         if not m:
///             break
///         i, j = m.span(0)
///         name = m.group(1)
///         if name.startswith(start) and name.endswith(end):
///             name = name[1:-1]
///         try:
///             if environ is None:
///                 value = os.fsencode(os.environ[os.fsdecode(name)])
///             else:
///                 value = environ[name]
///         except KeyError:
///             i = j
///         else:
///             tail = path[j:]
///             path = path[:i] + value
///             i = len(path)
///             path += tail
///     return path
///
///
/// # Normalize a path, e.g. A//B, A/./B and A/foo/../B all become A/B.
/// # It should be understood that this may change the meaning of the path
/// # if it contains symbolic links!
///
/// try:
///     from posix import _path_normpath
///
/// except ImportError:
///     def normpath(path):
///         """Normalize path, eliminating double slashes, etc."""
///         path = os.fspath(path)
///         if isinstance(path, bytes):
///             sep = b'/'
///             empty = b''
///             dot = b'.'
///             dotdot = b'..'
///         else:
///             sep = '/'
///             empty = ''
///             dot = '.'
///             dotdot = '..'
///         if path == empty:
///             return dot
///         initial_slashes = path.startswith(sep)
///         # POSIX allows one or two initial slashes, but treats three or more
///         # as single slash.
///         # (see https://pubs.opengroup.org/onlinepubs/9699919799/basedefs/V1_chap04.html#tag_04_13)
///         if (initial_slashes and
///             path.startswith(sep*2) and not path.startswith(sep*3)):
///             initial_slashes = 2
///         comps = path.split(sep)
///         new_comps = []
///         for comp in comps:
///             if comp in (empty, dot):
///                 continue
///             if (comp != dotdot or (not initial_slashes and not new_comps) or
///                  (new_comps and new_comps[-1] == dotdot)):
///                 new_comps.append(comp)
///             elif new_comps:
///                 new_comps.pop()
///         comps = new_comps
///         path = sep.join(comps)
///         if initial_slashes:
///             path = sep*initial_slashes + path
///         return path or dot
///
/// else:
///     def normpath(path):
///         """Normalize path, eliminating double slashes, etc."""
///         path = os.fspath(path)
///         if isinstance(path, bytes):
///             return os.fsencode(_path_normpath(os.fsdecode(path))) or b"."
///         return _path_normpath(path) or "."
///
///
/// def abspath(path):
///     """Return an absolute path."""
///     path = os.fspath(path)
///     if not isabs(path):
///         if isinstance(path, bytes):
///             cwd = os.getcwdb()
///         else:
///             cwd = os.getcwd()
///         path = join(cwd, path)
///     return normpath(path)
///
///
/// # Return a canonical path (i.e. the absolute location of a file on the
/// # filesystem).
///
/// def realpath(filename, *, strict=False):
///     """Return the canonical path of the specified filename, eliminating any
/// symbolic links encountered in the path."""
///     filename = os.fspath(filename)
///     path, ok = _joinrealpath(filename[:0], filename, strict, {})
///     return abspath(path)
///
/// # Join two paths, normalizing and eliminating any symbolic links
/// # encountered in the second path.
/// def _joinrealpath(path, rest, strict, seen):
///     if isinstance(path, bytes):
///         sep = b'/'
///         curdir = b'.'
///         pardir = b'..'
///     else:
///         sep = '/'
///         curdir = '.'
///         pardir = '..'
///
///     if isabs(rest):
///         rest = rest[1:]
///         path = sep
///
///     while rest:
///         name, _, rest = rest.partition(sep)
///         if not name or name == curdir:
///             # current dir
///             continue
///         if name == pardir:
///             # parent dir
///             if path:
///                 path, name = split(path)
///                 if name == pardir:
///                     path = join(path, pardir, pardir)
///             else:
///                 path = pardir
///             continue
///         newpath = join(path, name)
///         try:
///             st = os.lstat(newpath)
///         except OSError:
///             if strict:
///                 raise
///             is_link = False
///         else:
///             is_link = stat.S_ISLNK(st.st_mode)
///         if not is_link:
///             path = newpath
///             continue
///         # Resolve the symbolic link
///         if newpath in seen:
///             # Already seen this path
///             path = seen[newpath]
///             if path is not None:
///                 # use cached value
///                 continue
///             # The symlink is not resolved, so we must have a symlink loop.
///             if strict:
///                 # Raise OSError(errno.ELOOP)
///                 os.stat(newpath)
///             else:
///                 # Return already resolved part + rest of the path unchanged.
///                 return join(newpath, rest), False
///         seen[newpath] = None # not resolved symlink
///         path, ok = _joinrealpath(path, os.readlink(newpath), strict, seen)
///         if not ok:
///             return join(path, rest), False
///         seen[newpath] = path # resolved symlink
///
///     return path, True
///
///
/// supports_unicode_filenames = (sys.platform == 'darwin')
///
/// def relpath(path, start=None):
///     """Return a relative version of a path"""
///
///     if not path:
///         raise ValueError("no path specified")
///
///     path = os.fspath(path)
///     if isinstance(path, bytes):
///         curdir = b'.'
///         sep = b'/'
///         pardir = b'..'
///     else:
///         curdir = '.'
///         sep = '/'
///         pardir = '..'
///
///     if start is None:
///         start = curdir
///     else:
///         start = os.fspath(start)
///
///     try:
///         start_list = [x for x in abspath(start).split(sep) if x]
///         path_list = [x for x in abspath(path).split(sep) if x]
///         # Work out how much of the filepath is shared by start and path.
///         i = len(commonprefix([start_list, path_list]))
///
///         rel_list = [pardir] * (len(start_list)-i) + path_list[i:]
///         if not rel_list:
///             return curdir
///         return join(*rel_list)
///     except (TypeError, AttributeError, BytesWarning, DeprecationWarning):
///         genericpath._check_arg_types('relpath', path, start)
///         raise
///
///
/// # Return the longest common sub-path of the sequence of paths given as input.
/// # The paths are not normalized before comparing them (this is the
/// # responsibility of the caller). Any trailing separator is stripped from the
/// # returned path.
///
/// def commonpath(paths):
///     """Given a sequence of path names, returns the longest common sub-path."""
///
///     if not paths:
///         raise ValueError('commonpath() arg is an empty sequence')
///
///     paths = tuple(map(os.fspath, paths))
///     if isinstance(paths[0], bytes):
///         sep = b'/'
///         curdir = b'.'
///     else:
///         sep = '/'
///         curdir = '.'
///
///     try:
///         split_paths = [path.split(sep) for path in paths]
///
///         try:
///             isabs, = set(p[:1] == sep for p in paths)
///         except ValueError:
///             raise ValueError("Can't mix absolute and relative paths") from None
///
///         split_paths = [[c for c in s if c and c != curdir] for s in split_paths]
///         s1 = min(split_paths)
///         s2 = max(split_paths)
///         common = s1
///         for i, c in enumerate(s1):
///             if c != s2[i]:
///                 common = s1[:i]
///                 break
///
///         prefix = sep if isabs else sep[:0]
///         return prefix + sep.join(common)
///     except (TypeError, AttributeError):
///         genericpath._check_arg_types('commonpath', *paths)
///         raise
/// ```
final class path extends PythonModule {
  path.from(super.pythonModule) : super.from();

  static path import() => PythonFfiDart.instance.importModule(
        "posixpath",
        path.from,
      );

  /// ## abspath
  ///
  /// ### python docstring
  ///
  /// Return an absolute path.
  Object? abspath({
    required Object? path,
  }) =>
      getFunction("abspath").call(
        <Object?>[
          path,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## basename
  ///
  /// ### python docstring
  ///
  /// Returns the final component of a pathname
  Object? basename({
    required Object? p,
  }) =>
      getFunction("basename").call(
        <Object?>[
          p,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## commonpath
  ///
  /// ### python docstring
  ///
  /// Given a sequence of path names, returns the longest common sub-path.
  Object? commonpath({
    required Object? paths,
  }) =>
      getFunction("commonpath").call(
        <Object?>[
          paths,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## dirname
  ///
  /// ### python docstring
  ///
  /// Returns the directory component of a pathname
  Object? dirname({
    required Object? p,
  }) =>
      getFunction("dirname").call(
        <Object?>[
          p,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## expanduser
  ///
  /// ### python docstring
  ///
  /// Expand ~ and ~user constructions.  If user or $HOME is unknown,
  /// do nothing.
  Object? expanduser({
    required Object? path,
  }) =>
      getFunction("expanduser").call(
        <Object?>[
          path,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## expandvars
  ///
  /// ### python docstring
  ///
  /// Expand shell variables of form $var and ${var}.  Unknown variables
  /// are left unchanged.
  Object? expandvars({
    required Object? path,
  }) =>
      getFunction("expandvars").call(
        <Object?>[
          path,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## isabs
  ///
  /// ### python docstring
  ///
  /// Test whether a path is absolute
  Object? isabs({
    required Object? s,
  }) =>
      getFunction("isabs").call(
        <Object?>[
          s,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## islink
  ///
  /// ### python docstring
  ///
  /// Test whether a path is a symbolic link
  Object? islink({
    required Object? path,
  }) =>
      getFunction("islink").call(
        <Object?>[
          path,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## ismount
  ///
  /// ### python docstring
  ///
  /// Test whether a path is a mount point
  Object? ismount({
    required Object? path,
  }) =>
      getFunction("ismount").call(
        <Object?>[
          path,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## join
  ///
  /// ### python docstring
  ///
  /// Join two or more pathname components, inserting '/' as needed.
  /// If any component is an absolute path, all previous path components
  /// will be discarded.  An empty last part will result in a path that
  /// ends with a separator.
  Object? join({
    List<Object?> p = const <Object?>[],
    required Object? a,
  }) =>
      getFunction("join").call(
        <Object?>[
          a,
          ...p,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## lexists
  ///
  /// ### python docstring
  ///
  /// Test whether a path exists.  Returns True for broken symbolic links
  Object? lexists({
    required Object? path,
  }) =>
      getFunction("lexists").call(
        <Object?>[
          path,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## normcase
  ///
  /// ### python docstring
  ///
  /// Normalize case of pathname.  Has no effect under Posix
  Object? normcase({
    required Object? s,
  }) =>
      getFunction("normcase").call(
        <Object?>[
          s,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## normpath
  ///
  /// ### python docstring
  ///
  /// Normalize path, eliminating double slashes, etc.
  Object? normpath({
    required Object? path,
  }) =>
      getFunction("normpath").call(
        <Object?>[
          path,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## realpath
  ///
  /// ### python docstring
  ///
  /// Return the canonical path of the specified filename, eliminating any
  /// symbolic links encountered in the path.
  Object? realpath({
    required Object? filename,
    Object? strict = false,
  }) =>
      getFunction("realpath").call(
        <Object?>[
          filename,
        ],
        kwargs: <String, Object?>{
          "strict": strict,
        },
      );

  /// ## relpath
  ///
  /// ### python docstring
  ///
  /// Return a relative version of a path
  Object? relpath({
    required Object? path,
    Object? start,
  }) =>
      getFunction("relpath").call(
        <Object?>[
          path,
          start,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## split
  ///
  /// ### python docstring
  ///
  /// Split a pathname.  Returns tuple "(head, tail)" where "tail" is
  /// everything after the final slash.  Either part may be empty.
  Object? split({
    required Object? p,
  }) =>
      getFunction("split").call(
        <Object?>[
          p,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## splitdrive
  ///
  /// ### python docstring
  ///
  /// Split a pathname into drive and path. On Posix, drive is always
  /// empty.
  Object? splitdrive({
    required Object? p,
  }) =>
      getFunction("splitdrive").call(
        <Object?>[
          p,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## splitext
  ///
  /// ### python docstring
  ///
  /// Split the extension from a pathname.
  ///
  /// Extension is everything from the last dot to the end, ignoring
  /// leading dots.  Returns "(root, ext)"; ext may be empty.
  Object? splitext({
    required Object? p,
  }) =>
      getFunction("splitext").call(
        <Object?>[
          p,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## altsep (getter)
  Object? get altsep => getAttribute("altsep");

  /// ## altsep (setter)
  set altsep(Object? altsep) => setAttribute("altsep", altsep);

  /// ## curdir (getter)
  Object? get curdir => getAttribute("curdir");

  /// ## curdir (setter)
  set curdir(Object? curdir) => setAttribute("curdir", curdir);

  /// ## defpath (getter)
  Object? get defpath => getAttribute("defpath");

  /// ## defpath (setter)
  set defpath(Object? defpath) => setAttribute("defpath", defpath);

  /// ## devnull (getter)
  Object? get devnull => getAttribute("devnull");

  /// ## devnull (setter)
  set devnull(Object? devnull) => setAttribute("devnull", devnull);

  /// ## extsep (getter)
  Object? get extsep => getAttribute("extsep");

  /// ## extsep (setter)
  set extsep(Object? extsep) => setAttribute("extsep", extsep);

  /// ## pardir (getter)
  Object? get pardir => getAttribute("pardir");

  /// ## pardir (setter)
  set pardir(Object? pardir) => setAttribute("pardir", pardir);

  /// ## pathsep (getter)
  Object? get pathsep => getAttribute("pathsep");

  /// ## pathsep (setter)
  set pathsep(Object? pathsep) => setAttribute("pathsep", pathsep);

  /// ## sep (getter)
  Object? get sep => getAttribute("sep");

  /// ## sep (setter)
  set sep(Object? sep) => setAttribute("sep", sep);

  /// ## supports_unicode_filenames (getter)
  Object? get supports_unicode_filenames =>
      getAttribute("supports_unicode_filenames");

  /// ## supports_unicode_filenames (setter)
  set supports_unicode_filenames(Object? supports_unicode_filenames) =>
      setAttribute("supports_unicode_filenames", supports_unicode_filenames);
}

/// ## genericpath
///
/// ### python docstring
///
/// Path operations common to more than one OS
/// Do not use directly.  The OS specific modules import the appropriate
/// functions from this module themselves.
///
/// ### python source
/// ```py
/// """
/// Path operations common to more than one OS
/// Do not use directly.  The OS specific modules import the appropriate
/// functions from this module themselves.
/// """
/// import os
/// import stat
///
/// __all__ = ['commonprefix', 'exists', 'getatime', 'getctime', 'getmtime',
///            'getsize', 'isdir', 'isfile', 'samefile', 'sameopenfile',
///            'samestat']
///
///
/// # Does a path exist?
/// # This is false for dangling symbolic links on systems that support them.
/// def exists(path):
///     """Test whether a path exists.  Returns False for broken symbolic links"""
///     try:
///         os.stat(path)
///     except (OSError, ValueError):
///         return False
///     return True
///
///
/// # This follows symbolic links, so both islink() and isdir() can be true
/// # for the same path on systems that support symlinks
/// def isfile(path):
///     """Test whether a path is a regular file"""
///     try:
///         st = os.stat(path)
///     except (OSError, ValueError):
///         return False
///     return stat.S_ISREG(st.st_mode)
///
///
/// # Is a path a directory?
/// # This follows symbolic links, so both islink() and isdir()
/// # can be true for the same path on systems that support symlinks
/// def isdir(s):
///     """Return true if the pathname refers to an existing directory."""
///     try:
///         st = os.stat(s)
///     except (OSError, ValueError):
///         return False
///     return stat.S_ISDIR(st.st_mode)
///
///
/// def getsize(filename):
///     """Return the size of a file, reported by os.stat()."""
///     return os.stat(filename).st_size
///
///
/// def getmtime(filename):
///     """Return the last modification time of a file, reported by os.stat()."""
///     return os.stat(filename).st_mtime
///
///
/// def getatime(filename):
///     """Return the last access time of a file, reported by os.stat()."""
///     return os.stat(filename).st_atime
///
///
/// def getctime(filename):
///     """Return the metadata change time of a file, reported by os.stat()."""
///     return os.stat(filename).st_ctime
///
///
/// # Return the longest prefix of all list elements.
/// def commonprefix(m):
///     "Given a list of pathnames, returns the longest common leading component"
///     if not m: return ''
///     # Some people pass in a list of pathname parts to operate in an OS-agnostic
///     # fashion; don't try to translate in that case as that's an abuse of the
///     # API and they are already doing what they need to be OS-agnostic and so
///     # they most likely won't be using an os.PathLike object in the sublists.
///     if not isinstance(m[0], (list, tuple)):
///         m = tuple(map(os.fspath, m))
///     s1 = min(m)
///     s2 = max(m)
///     for i, c in enumerate(s1):
///         if c != s2[i]:
///             return s1[:i]
///     return s1
///
/// # Are two stat buffers (obtained from stat, fstat or lstat)
/// # describing the same file?
/// def samestat(s1, s2):
///     """Test whether two stat buffers reference the same file"""
///     return (s1.st_ino == s2.st_ino and
///             s1.st_dev == s2.st_dev)
///
///
/// # Are two filenames really pointing to the same file?
/// def samefile(f1, f2):
///     """Test whether two pathnames reference the same actual file or directory
///
///     This is determined by the device number and i-node number and
///     raises an exception if an os.stat() call on either pathname fails.
///     """
///     s1 = os.stat(f1)
///     s2 = os.stat(f2)
///     return samestat(s1, s2)
///
///
/// # Are two open files really referencing the same file?
/// # (Not necessarily the same file descriptor!)
/// def sameopenfile(fp1, fp2):
///     """Test whether two open file objects reference the same file"""
///     s1 = os.fstat(fp1)
///     s2 = os.fstat(fp2)
///     return samestat(s1, s2)
///
///
/// # Split a path in root and extension.
/// # The extension is everything starting at the last dot in the last
/// # pathname component; the root is everything before that.
/// # It is always true that root + ext == p.
///
/// # Generic implementation of splitext, to be parametrized with
/// # the separators
/// def _splitext(p, sep, altsep, extsep):
///     """Split the extension from a pathname.
///
///     Extension is everything from the last dot to the end, ignoring
///     leading dots.  Returns "(root, ext)"; ext may be empty."""
///     # NOTE: This code must work for text and bytes strings.
///
///     sepIndex = p.rfind(sep)
///     if altsep:
///         altsepIndex = p.rfind(altsep)
///         sepIndex = max(sepIndex, altsepIndex)
///
///     dotIndex = p.rfind(extsep)
///     if dotIndex > sepIndex:
///         # skip all leading dots
///         filenameIndex = sepIndex + 1
///         while filenameIndex < dotIndex:
///             if p[filenameIndex:filenameIndex+1] != extsep:
///                 return p[:dotIndex], p[dotIndex:]
///             filenameIndex += 1
///
///     return p, p[:0]
///
/// def _check_arg_types(funcname, *args):
///     hasstr = hasbytes = False
///     for s in args:
///         if isinstance(s, str):
///             hasstr = True
///         elif isinstance(s, bytes):
///             hasbytes = True
///         else:
///             raise TypeError(f'{funcname}() argument must be str, bytes, or '
///                             f'os.PathLike object, not {s.__class__.__name__!r}') from None
///     if hasstr and hasbytes:
///         raise TypeError("Can't mix strings and bytes in path components") from None
/// ```
final class genericpath extends PythonModule {
  genericpath.from(super.pythonModule) : super.from();

  static genericpath import() => PythonFfiDart.instance.importModule(
        "genericpath",
        genericpath.from,
      );

  /// ## commonprefix
  ///
  /// ### python docstring
  ///
  /// Given a list of pathnames, returns the longest common leading component
  Object? commonprefix({
    required Object? m,
  }) =>
      getFunction("commonprefix").call(
        <Object?>[
          m,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## exists
  ///
  /// ### python docstring
  ///
  /// Test whether a path exists.  Returns False for broken symbolic links
  Object? exists({
    required Object? path,
  }) =>
      getFunction("exists").call(
        <Object?>[
          path,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## getatime
  ///
  /// ### python docstring
  ///
  /// Return the last access time of a file, reported by os.stat().
  Object? getatime({
    required Object? filename,
  }) =>
      getFunction("getatime").call(
        <Object?>[
          filename,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## getctime
  ///
  /// ### python docstring
  ///
  /// Return the metadata change time of a file, reported by os.stat().
  Object? getctime({
    required Object? filename,
  }) =>
      getFunction("getctime").call(
        <Object?>[
          filename,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## getmtime
  ///
  /// ### python docstring
  ///
  /// Return the last modification time of a file, reported by os.stat().
  Object? getmtime({
    required Object? filename,
  }) =>
      getFunction("getmtime").call(
        <Object?>[
          filename,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## getsize
  ///
  /// ### python docstring
  ///
  /// Return the size of a file, reported by os.stat().
  Object? getsize({
    required Object? filename,
  }) =>
      getFunction("getsize").call(
        <Object?>[
          filename,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## isdir
  ///
  /// ### python docstring
  ///
  /// Return true if the pathname refers to an existing directory.
  Object? isdir({
    required Object? s,
  }) =>
      getFunction("isdir").call(
        <Object?>[
          s,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## isfile
  ///
  /// ### python docstring
  ///
  /// Test whether a path is a regular file
  Object? isfile({
    required Object? path,
  }) =>
      getFunction("isfile").call(
        <Object?>[
          path,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## samefile
  ///
  /// ### python docstring
  ///
  /// Test whether two pathnames reference the same actual file or directory
  ///
  /// This is determined by the device number and i-node number and
  /// raises an exception if an os.stat() call on either pathname fails.
  Object? samefile({
    required Object? f1,
    required Object? f2,
  }) =>
      getFunction("samefile").call(
        <Object?>[
          f1,
          f2,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## sameopenfile
  ///
  /// ### python docstring
  ///
  /// Test whether two open file objects reference the same file
  Object? sameopenfile({
    required Object? fp1,
    required Object? fp2,
  }) =>
      getFunction("sameopenfile").call(
        <Object?>[
          fp1,
          fp2,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## samestat
  ///
  /// ### python docstring
  ///
  /// Test whether two stat buffers reference the same file
  Object? samestat({
    required Object? s1,
    required Object? s2,
  }) =>
      getFunction("samestat").call(
        <Object?>[
          s1,
          s2,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## stat
///
/// ### python docstring
///
/// Constants/functions for interpreting results of os.stat() and os.lstat().
///
/// Suggested usage: from stat import *
///
/// ### python source
/// ```py
/// """Constants/functions for interpreting results of os.stat() and os.lstat().
///
/// Suggested usage: from stat import *
/// """
///
/// # Indices for stat struct members in the tuple returned by os.stat()
///
/// ST_MODE  = 0
/// ST_INO   = 1
/// ST_DEV   = 2
/// ST_NLINK = 3
/// ST_UID   = 4
/// ST_GID   = 5
/// ST_SIZE  = 6
/// ST_ATIME = 7
/// ST_MTIME = 8
/// ST_CTIME = 9
///
/// # Extract bits from the mode
///
/// def S_IMODE(mode):
///     """Return the portion of the file's mode that can be set by
///     os.chmod().
///     """
///     return mode & 0o7777
///
/// def S_IFMT(mode):
///     """Return the portion of the file's mode that describes the
///     file type.
///     """
///     return mode & 0o170000
///
/// # Constants used as S_IFMT() for various file types
/// # (not all are implemented on all systems)
///
/// S_IFDIR  = 0o040000  # directory
/// S_IFCHR  = 0o020000  # character device
/// S_IFBLK  = 0o060000  # block device
/// S_IFREG  = 0o100000  # regular file
/// S_IFIFO  = 0o010000  # fifo (named pipe)
/// S_IFLNK  = 0o120000  # symbolic link
/// S_IFSOCK = 0o140000  # socket file
/// # Fallbacks for uncommon platform-specific constants
/// S_IFDOOR = 0
/// S_IFPORT = 0
/// S_IFWHT = 0
///
/// # Functions to test for each file type
///
/// def S_ISDIR(mode):
///     """Return True if mode is from a directory."""
///     return S_IFMT(mode) == S_IFDIR
///
/// def S_ISCHR(mode):
///     """Return True if mode is from a character special device file."""
///     return S_IFMT(mode) == S_IFCHR
///
/// def S_ISBLK(mode):
///     """Return True if mode is from a block special device file."""
///     return S_IFMT(mode) == S_IFBLK
///
/// def S_ISREG(mode):
///     """Return True if mode is from a regular file."""
///     return S_IFMT(mode) == S_IFREG
///
/// def S_ISFIFO(mode):
///     """Return True if mode is from a FIFO (named pipe)."""
///     return S_IFMT(mode) == S_IFIFO
///
/// def S_ISLNK(mode):
///     """Return True if mode is from a symbolic link."""
///     return S_IFMT(mode) == S_IFLNK
///
/// def S_ISSOCK(mode):
///     """Return True if mode is from a socket."""
///     return S_IFMT(mode) == S_IFSOCK
///
/// def S_ISDOOR(mode):
///     """Return True if mode is from a door."""
///     return False
///
/// def S_ISPORT(mode):
///     """Return True if mode is from an event port."""
///     return False
///
/// def S_ISWHT(mode):
///     """Return True if mode is from a whiteout."""
///     return False
///
/// # Names for permission bits
///
/// S_ISUID = 0o4000  # set UID bit
/// S_ISGID = 0o2000  # set GID bit
/// S_ENFMT = S_ISGID # file locking enforcement
/// S_ISVTX = 0o1000  # sticky bit
/// S_IREAD = 0o0400  # Unix V7 synonym for S_IRUSR
/// S_IWRITE = 0o0200 # Unix V7 synonym for S_IWUSR
/// S_IEXEC = 0o0100  # Unix V7 synonym for S_IXUSR
/// S_IRWXU = 0o0700  # mask for owner permissions
/// S_IRUSR = 0o0400  # read by owner
/// S_IWUSR = 0o0200  # write by owner
/// S_IXUSR = 0o0100  # execute by owner
/// S_IRWXG = 0o0070  # mask for group permissions
/// S_IRGRP = 0o0040  # read by group
/// S_IWGRP = 0o0020  # write by group
/// S_IXGRP = 0o0010  # execute by group
/// S_IRWXO = 0o0007  # mask for others (not in group) permissions
/// S_IROTH = 0o0004  # read by others
/// S_IWOTH = 0o0002  # write by others
/// S_IXOTH = 0o0001  # execute by others
///
/// # Names for file flags
///
/// UF_NODUMP    = 0x00000001  # do not dump file
/// UF_IMMUTABLE = 0x00000002  # file may not be changed
/// UF_APPEND    = 0x00000004  # file may only be appended to
/// UF_OPAQUE    = 0x00000008  # directory is opaque when viewed through a union stack
/// UF_NOUNLINK  = 0x00000010  # file may not be renamed or deleted
/// UF_COMPRESSED = 0x00000020 # OS X: file is hfs-compressed
/// UF_HIDDEN    = 0x00008000  # OS X: file should not be displayed
/// SF_ARCHIVED  = 0x00010000  # file may be archived
/// SF_IMMUTABLE = 0x00020000  # file may not be changed
/// SF_APPEND    = 0x00040000  # file may only be appended to
/// SF_NOUNLINK  = 0x00100000  # file may not be renamed or deleted
/// SF_SNAPSHOT  = 0x00200000  # file is a snapshot file
///
///
/// _filemode_table = (
///     ((S_IFLNK,         "l"),
///      (S_IFSOCK,        "s"),  # Must appear before IFREG and IFDIR as IFSOCK == IFREG | IFDIR
///      (S_IFREG,         "-"),
///      (S_IFBLK,         "b"),
///      (S_IFDIR,         "d"),
///      (S_IFCHR,         "c"),
///      (S_IFIFO,         "p")),
///
///     ((S_IRUSR,         "r"),),
///     ((S_IWUSR,         "w"),),
///     ((S_IXUSR|S_ISUID, "s"),
///      (S_ISUID,         "S"),
///      (S_IXUSR,         "x")),
///
///     ((S_IRGRP,         "r"),),
///     ((S_IWGRP,         "w"),),
///     ((S_IXGRP|S_ISGID, "s"),
///      (S_ISGID,         "S"),
///      (S_IXGRP,         "x")),
///
///     ((S_IROTH,         "r"),),
///     ((S_IWOTH,         "w"),),
///     ((S_IXOTH|S_ISVTX, "t"),
///      (S_ISVTX,         "T"),
///      (S_IXOTH,         "x"))
/// )
///
/// def filemode(mode):
///     """Convert a file's mode to a string of the form '-rwxrwxrwx'."""
///     perm = []
///     for table in _filemode_table:
///         for bit, char in table:
///             if mode & bit == bit:
///                 perm.append(char)
///                 break
///         else:
///             perm.append("-")
///     return "".join(perm)
///
///
/// # Windows FILE_ATTRIBUTE constants for interpreting os.stat()'s
/// # "st_file_attributes" member
///
/// FILE_ATTRIBUTE_ARCHIVE = 32
/// FILE_ATTRIBUTE_COMPRESSED = 2048
/// FILE_ATTRIBUTE_DEVICE = 64
/// FILE_ATTRIBUTE_DIRECTORY = 16
/// FILE_ATTRIBUTE_ENCRYPTED = 16384
/// FILE_ATTRIBUTE_HIDDEN = 2
/// FILE_ATTRIBUTE_INTEGRITY_STREAM = 32768
/// FILE_ATTRIBUTE_NORMAL = 128
/// FILE_ATTRIBUTE_NOT_CONTENT_INDEXED = 8192
/// FILE_ATTRIBUTE_NO_SCRUB_DATA = 131072
/// FILE_ATTRIBUTE_OFFLINE = 4096
/// FILE_ATTRIBUTE_READONLY = 1
/// FILE_ATTRIBUTE_REPARSE_POINT = 1024
/// FILE_ATTRIBUTE_SPARSE_FILE = 512
/// FILE_ATTRIBUTE_SYSTEM = 4
/// FILE_ATTRIBUTE_TEMPORARY = 256
/// FILE_ATTRIBUTE_VIRTUAL = 65536
///
///
/// # If available, use C implementation
/// try:
///     from _stat import *
/// except ImportError:
///     pass
/// ```
final class stat extends PythonModule {
  stat.from(super.pythonModule) : super.from();

  static stat import() => PythonFfiDart.instance.importModule(
        "stat",
        stat.from,
      );

  /// ## FILE_ATTRIBUTE_ARCHIVE (getter)
  Object? get FILE_ATTRIBUTE_ARCHIVE => getAttribute("FILE_ATTRIBUTE_ARCHIVE");

  /// ## FILE_ATTRIBUTE_ARCHIVE (setter)
  set FILE_ATTRIBUTE_ARCHIVE(Object? FILE_ATTRIBUTE_ARCHIVE) =>
      setAttribute("FILE_ATTRIBUTE_ARCHIVE", FILE_ATTRIBUTE_ARCHIVE);

  /// ## FILE_ATTRIBUTE_COMPRESSED (getter)
  Object? get FILE_ATTRIBUTE_COMPRESSED =>
      getAttribute("FILE_ATTRIBUTE_COMPRESSED");

  /// ## FILE_ATTRIBUTE_COMPRESSED (setter)
  set FILE_ATTRIBUTE_COMPRESSED(Object? FILE_ATTRIBUTE_COMPRESSED) =>
      setAttribute("FILE_ATTRIBUTE_COMPRESSED", FILE_ATTRIBUTE_COMPRESSED);

  /// ## FILE_ATTRIBUTE_DEVICE (getter)
  Object? get FILE_ATTRIBUTE_DEVICE => getAttribute("FILE_ATTRIBUTE_DEVICE");

  /// ## FILE_ATTRIBUTE_DEVICE (setter)
  set FILE_ATTRIBUTE_DEVICE(Object? FILE_ATTRIBUTE_DEVICE) =>
      setAttribute("FILE_ATTRIBUTE_DEVICE", FILE_ATTRIBUTE_DEVICE);

  /// ## FILE_ATTRIBUTE_DIRECTORY (getter)
  Object? get FILE_ATTRIBUTE_DIRECTORY =>
      getAttribute("FILE_ATTRIBUTE_DIRECTORY");

  /// ## FILE_ATTRIBUTE_DIRECTORY (setter)
  set FILE_ATTRIBUTE_DIRECTORY(Object? FILE_ATTRIBUTE_DIRECTORY) =>
      setAttribute("FILE_ATTRIBUTE_DIRECTORY", FILE_ATTRIBUTE_DIRECTORY);

  /// ## FILE_ATTRIBUTE_ENCRYPTED (getter)
  Object? get FILE_ATTRIBUTE_ENCRYPTED =>
      getAttribute("FILE_ATTRIBUTE_ENCRYPTED");

  /// ## FILE_ATTRIBUTE_ENCRYPTED (setter)
  set FILE_ATTRIBUTE_ENCRYPTED(Object? FILE_ATTRIBUTE_ENCRYPTED) =>
      setAttribute("FILE_ATTRIBUTE_ENCRYPTED", FILE_ATTRIBUTE_ENCRYPTED);

  /// ## FILE_ATTRIBUTE_HIDDEN (getter)
  Object? get FILE_ATTRIBUTE_HIDDEN => getAttribute("FILE_ATTRIBUTE_HIDDEN");

  /// ## FILE_ATTRIBUTE_HIDDEN (setter)
  set FILE_ATTRIBUTE_HIDDEN(Object? FILE_ATTRIBUTE_HIDDEN) =>
      setAttribute("FILE_ATTRIBUTE_HIDDEN", FILE_ATTRIBUTE_HIDDEN);

  /// ## FILE_ATTRIBUTE_INTEGRITY_STREAM (getter)
  Object? get FILE_ATTRIBUTE_INTEGRITY_STREAM =>
      getAttribute("FILE_ATTRIBUTE_INTEGRITY_STREAM");

  /// ## FILE_ATTRIBUTE_INTEGRITY_STREAM (setter)
  set FILE_ATTRIBUTE_INTEGRITY_STREAM(
          Object? FILE_ATTRIBUTE_INTEGRITY_STREAM) =>
      setAttribute(
          "FILE_ATTRIBUTE_INTEGRITY_STREAM", FILE_ATTRIBUTE_INTEGRITY_STREAM);

  /// ## FILE_ATTRIBUTE_NORMAL (getter)
  Object? get FILE_ATTRIBUTE_NORMAL => getAttribute("FILE_ATTRIBUTE_NORMAL");

  /// ## FILE_ATTRIBUTE_NORMAL (setter)
  set FILE_ATTRIBUTE_NORMAL(Object? FILE_ATTRIBUTE_NORMAL) =>
      setAttribute("FILE_ATTRIBUTE_NORMAL", FILE_ATTRIBUTE_NORMAL);

  /// ## FILE_ATTRIBUTE_NOT_CONTENT_INDEXED (getter)
  Object? get FILE_ATTRIBUTE_NOT_CONTENT_INDEXED =>
      getAttribute("FILE_ATTRIBUTE_NOT_CONTENT_INDEXED");

  /// ## FILE_ATTRIBUTE_NOT_CONTENT_INDEXED (setter)
  set FILE_ATTRIBUTE_NOT_CONTENT_INDEXED(
          Object? FILE_ATTRIBUTE_NOT_CONTENT_INDEXED) =>
      setAttribute("FILE_ATTRIBUTE_NOT_CONTENT_INDEXED",
          FILE_ATTRIBUTE_NOT_CONTENT_INDEXED);

  /// ## FILE_ATTRIBUTE_NO_SCRUB_DATA (getter)
  Object? get FILE_ATTRIBUTE_NO_SCRUB_DATA =>
      getAttribute("FILE_ATTRIBUTE_NO_SCRUB_DATA");

  /// ## FILE_ATTRIBUTE_NO_SCRUB_DATA (setter)
  set FILE_ATTRIBUTE_NO_SCRUB_DATA(Object? FILE_ATTRIBUTE_NO_SCRUB_DATA) =>
      setAttribute(
          "FILE_ATTRIBUTE_NO_SCRUB_DATA", FILE_ATTRIBUTE_NO_SCRUB_DATA);

  /// ## FILE_ATTRIBUTE_OFFLINE (getter)
  Object? get FILE_ATTRIBUTE_OFFLINE => getAttribute("FILE_ATTRIBUTE_OFFLINE");

  /// ## FILE_ATTRIBUTE_OFFLINE (setter)
  set FILE_ATTRIBUTE_OFFLINE(Object? FILE_ATTRIBUTE_OFFLINE) =>
      setAttribute("FILE_ATTRIBUTE_OFFLINE", FILE_ATTRIBUTE_OFFLINE);

  /// ## FILE_ATTRIBUTE_READONLY (getter)
  Object? get FILE_ATTRIBUTE_READONLY =>
      getAttribute("FILE_ATTRIBUTE_READONLY");

  /// ## FILE_ATTRIBUTE_READONLY (setter)
  set FILE_ATTRIBUTE_READONLY(Object? FILE_ATTRIBUTE_READONLY) =>
      setAttribute("FILE_ATTRIBUTE_READONLY", FILE_ATTRIBUTE_READONLY);

  /// ## FILE_ATTRIBUTE_REPARSE_POINT (getter)
  Object? get FILE_ATTRIBUTE_REPARSE_POINT =>
      getAttribute("FILE_ATTRIBUTE_REPARSE_POINT");

  /// ## FILE_ATTRIBUTE_REPARSE_POINT (setter)
  set FILE_ATTRIBUTE_REPARSE_POINT(Object? FILE_ATTRIBUTE_REPARSE_POINT) =>
      setAttribute(
          "FILE_ATTRIBUTE_REPARSE_POINT", FILE_ATTRIBUTE_REPARSE_POINT);

  /// ## FILE_ATTRIBUTE_SPARSE_FILE (getter)
  Object? get FILE_ATTRIBUTE_SPARSE_FILE =>
      getAttribute("FILE_ATTRIBUTE_SPARSE_FILE");

  /// ## FILE_ATTRIBUTE_SPARSE_FILE (setter)
  set FILE_ATTRIBUTE_SPARSE_FILE(Object? FILE_ATTRIBUTE_SPARSE_FILE) =>
      setAttribute("FILE_ATTRIBUTE_SPARSE_FILE", FILE_ATTRIBUTE_SPARSE_FILE);

  /// ## FILE_ATTRIBUTE_SYSTEM (getter)
  Object? get FILE_ATTRIBUTE_SYSTEM => getAttribute("FILE_ATTRIBUTE_SYSTEM");

  /// ## FILE_ATTRIBUTE_SYSTEM (setter)
  set FILE_ATTRIBUTE_SYSTEM(Object? FILE_ATTRIBUTE_SYSTEM) =>
      setAttribute("FILE_ATTRIBUTE_SYSTEM", FILE_ATTRIBUTE_SYSTEM);

  /// ## FILE_ATTRIBUTE_TEMPORARY (getter)
  Object? get FILE_ATTRIBUTE_TEMPORARY =>
      getAttribute("FILE_ATTRIBUTE_TEMPORARY");

  /// ## FILE_ATTRIBUTE_TEMPORARY (setter)
  set FILE_ATTRIBUTE_TEMPORARY(Object? FILE_ATTRIBUTE_TEMPORARY) =>
      setAttribute("FILE_ATTRIBUTE_TEMPORARY", FILE_ATTRIBUTE_TEMPORARY);

  /// ## FILE_ATTRIBUTE_VIRTUAL (getter)
  Object? get FILE_ATTRIBUTE_VIRTUAL => getAttribute("FILE_ATTRIBUTE_VIRTUAL");

  /// ## FILE_ATTRIBUTE_VIRTUAL (setter)
  set FILE_ATTRIBUTE_VIRTUAL(Object? FILE_ATTRIBUTE_VIRTUAL) =>
      setAttribute("FILE_ATTRIBUTE_VIRTUAL", FILE_ATTRIBUTE_VIRTUAL);

  /// ## SF_APPEND (getter)
  Object? get SF_APPEND => getAttribute("SF_APPEND");

  /// ## SF_APPEND (setter)
  set SF_APPEND(Object? SF_APPEND) => setAttribute("SF_APPEND", SF_APPEND);

  /// ## SF_ARCHIVED (getter)
  Object? get SF_ARCHIVED => getAttribute("SF_ARCHIVED");

  /// ## SF_ARCHIVED (setter)
  set SF_ARCHIVED(Object? SF_ARCHIVED) =>
      setAttribute("SF_ARCHIVED", SF_ARCHIVED);

  /// ## SF_IMMUTABLE (getter)
  Object? get SF_IMMUTABLE => getAttribute("SF_IMMUTABLE");

  /// ## SF_IMMUTABLE (setter)
  set SF_IMMUTABLE(Object? SF_IMMUTABLE) =>
      setAttribute("SF_IMMUTABLE", SF_IMMUTABLE);

  /// ## SF_NOUNLINK (getter)
  Object? get SF_NOUNLINK => getAttribute("SF_NOUNLINK");

  /// ## SF_NOUNLINK (setter)
  set SF_NOUNLINK(Object? SF_NOUNLINK) =>
      setAttribute("SF_NOUNLINK", SF_NOUNLINK);

  /// ## SF_SNAPSHOT (getter)
  Object? get SF_SNAPSHOT => getAttribute("SF_SNAPSHOT");

  /// ## SF_SNAPSHOT (setter)
  set SF_SNAPSHOT(Object? SF_SNAPSHOT) =>
      setAttribute("SF_SNAPSHOT", SF_SNAPSHOT);

  /// ## ST_ATIME (getter)
  Object? get ST_ATIME => getAttribute("ST_ATIME");

  /// ## ST_ATIME (setter)
  set ST_ATIME(Object? ST_ATIME) => setAttribute("ST_ATIME", ST_ATIME);

  /// ## ST_CTIME (getter)
  Object? get ST_CTIME => getAttribute("ST_CTIME");

  /// ## ST_CTIME (setter)
  set ST_CTIME(Object? ST_CTIME) => setAttribute("ST_CTIME", ST_CTIME);

  /// ## ST_DEV (getter)
  Object? get ST_DEV => getAttribute("ST_DEV");

  /// ## ST_DEV (setter)
  set ST_DEV(Object? ST_DEV) => setAttribute("ST_DEV", ST_DEV);

  /// ## ST_GID (getter)
  Object? get ST_GID => getAttribute("ST_GID");

  /// ## ST_GID (setter)
  set ST_GID(Object? ST_GID) => setAttribute("ST_GID", ST_GID);

  /// ## ST_INO (getter)
  Object? get ST_INO => getAttribute("ST_INO");

  /// ## ST_INO (setter)
  set ST_INO(Object? ST_INO) => setAttribute("ST_INO", ST_INO);

  /// ## ST_MODE (getter)
  Object? get ST_MODE => getAttribute("ST_MODE");

  /// ## ST_MODE (setter)
  set ST_MODE(Object? ST_MODE) => setAttribute("ST_MODE", ST_MODE);

  /// ## ST_MTIME (getter)
  Object? get ST_MTIME => getAttribute("ST_MTIME");

  /// ## ST_MTIME (setter)
  set ST_MTIME(Object? ST_MTIME) => setAttribute("ST_MTIME", ST_MTIME);

  /// ## ST_NLINK (getter)
  Object? get ST_NLINK => getAttribute("ST_NLINK");

  /// ## ST_NLINK (setter)
  set ST_NLINK(Object? ST_NLINK) => setAttribute("ST_NLINK", ST_NLINK);

  /// ## ST_SIZE (getter)
  Object? get ST_SIZE => getAttribute("ST_SIZE");

  /// ## ST_SIZE (setter)
  set ST_SIZE(Object? ST_SIZE) => setAttribute("ST_SIZE", ST_SIZE);

  /// ## ST_UID (getter)
  Object? get ST_UID => getAttribute("ST_UID");

  /// ## ST_UID (setter)
  set ST_UID(Object? ST_UID) => setAttribute("ST_UID", ST_UID);

  /// ## S_ENFMT (getter)
  Object? get S_ENFMT => getAttribute("S_ENFMT");

  /// ## S_ENFMT (setter)
  set S_ENFMT(Object? S_ENFMT) => setAttribute("S_ENFMT", S_ENFMT);

  /// ## S_IEXEC (getter)
  Object? get S_IEXEC => getAttribute("S_IEXEC");

  /// ## S_IEXEC (setter)
  set S_IEXEC(Object? S_IEXEC) => setAttribute("S_IEXEC", S_IEXEC);

  /// ## S_IFBLK (getter)
  Object? get S_IFBLK => getAttribute("S_IFBLK");

  /// ## S_IFBLK (setter)
  set S_IFBLK(Object? S_IFBLK) => setAttribute("S_IFBLK", S_IFBLK);

  /// ## S_IFCHR (getter)
  Object? get S_IFCHR => getAttribute("S_IFCHR");

  /// ## S_IFCHR (setter)
  set S_IFCHR(Object? S_IFCHR) => setAttribute("S_IFCHR", S_IFCHR);

  /// ## S_IFDIR (getter)
  Object? get S_IFDIR => getAttribute("S_IFDIR");

  /// ## S_IFDIR (setter)
  set S_IFDIR(Object? S_IFDIR) => setAttribute("S_IFDIR", S_IFDIR);

  /// ## S_IFDOOR (getter)
  Object? get S_IFDOOR => getAttribute("S_IFDOOR");

  /// ## S_IFDOOR (setter)
  set S_IFDOOR(Object? S_IFDOOR) => setAttribute("S_IFDOOR", S_IFDOOR);

  /// ## S_IFIFO (getter)
  Object? get S_IFIFO => getAttribute("S_IFIFO");

  /// ## S_IFIFO (setter)
  set S_IFIFO(Object? S_IFIFO) => setAttribute("S_IFIFO", S_IFIFO);

  /// ## S_IFLNK (getter)
  Object? get S_IFLNK => getAttribute("S_IFLNK");

  /// ## S_IFLNK (setter)
  set S_IFLNK(Object? S_IFLNK) => setAttribute("S_IFLNK", S_IFLNK);

  /// ## S_IFPORT (getter)
  Object? get S_IFPORT => getAttribute("S_IFPORT");

  /// ## S_IFPORT (setter)
  set S_IFPORT(Object? S_IFPORT) => setAttribute("S_IFPORT", S_IFPORT);

  /// ## S_IFREG (getter)
  Object? get S_IFREG => getAttribute("S_IFREG");

  /// ## S_IFREG (setter)
  set S_IFREG(Object? S_IFREG) => setAttribute("S_IFREG", S_IFREG);

  /// ## S_IFSOCK (getter)
  Object? get S_IFSOCK => getAttribute("S_IFSOCK");

  /// ## S_IFSOCK (setter)
  set S_IFSOCK(Object? S_IFSOCK) => setAttribute("S_IFSOCK", S_IFSOCK);

  /// ## S_IFWHT (getter)
  Object? get S_IFWHT => getAttribute("S_IFWHT");

  /// ## S_IFWHT (setter)
  set S_IFWHT(Object? S_IFWHT) => setAttribute("S_IFWHT", S_IFWHT);

  /// ## S_IREAD (getter)
  Object? get S_IREAD => getAttribute("S_IREAD");

  /// ## S_IREAD (setter)
  set S_IREAD(Object? S_IREAD) => setAttribute("S_IREAD", S_IREAD);

  /// ## S_IRGRP (getter)
  Object? get S_IRGRP => getAttribute("S_IRGRP");

  /// ## S_IRGRP (setter)
  set S_IRGRP(Object? S_IRGRP) => setAttribute("S_IRGRP", S_IRGRP);

  /// ## S_IROTH (getter)
  Object? get S_IROTH => getAttribute("S_IROTH");

  /// ## S_IROTH (setter)
  set S_IROTH(Object? S_IROTH) => setAttribute("S_IROTH", S_IROTH);

  /// ## S_IRUSR (getter)
  Object? get S_IRUSR => getAttribute("S_IRUSR");

  /// ## S_IRUSR (setter)
  set S_IRUSR(Object? S_IRUSR) => setAttribute("S_IRUSR", S_IRUSR);

  /// ## S_IRWXG (getter)
  Object? get S_IRWXG => getAttribute("S_IRWXG");

  /// ## S_IRWXG (setter)
  set S_IRWXG(Object? S_IRWXG) => setAttribute("S_IRWXG", S_IRWXG);

  /// ## S_IRWXO (getter)
  Object? get S_IRWXO => getAttribute("S_IRWXO");

  /// ## S_IRWXO (setter)
  set S_IRWXO(Object? S_IRWXO) => setAttribute("S_IRWXO", S_IRWXO);

  /// ## S_IRWXU (getter)
  Object? get S_IRWXU => getAttribute("S_IRWXU");

  /// ## S_IRWXU (setter)
  set S_IRWXU(Object? S_IRWXU) => setAttribute("S_IRWXU", S_IRWXU);

  /// ## S_ISGID (getter)
  Object? get S_ISGID => getAttribute("S_ISGID");

  /// ## S_ISGID (setter)
  set S_ISGID(Object? S_ISGID) => setAttribute("S_ISGID", S_ISGID);

  /// ## S_ISUID (getter)
  Object? get S_ISUID => getAttribute("S_ISUID");

  /// ## S_ISUID (setter)
  set S_ISUID(Object? S_ISUID) => setAttribute("S_ISUID", S_ISUID);

  /// ## S_ISVTX (getter)
  Object? get S_ISVTX => getAttribute("S_ISVTX");

  /// ## S_ISVTX (setter)
  set S_ISVTX(Object? S_ISVTX) => setAttribute("S_ISVTX", S_ISVTX);

  /// ## S_IWGRP (getter)
  Object? get S_IWGRP => getAttribute("S_IWGRP");

  /// ## S_IWGRP (setter)
  set S_IWGRP(Object? S_IWGRP) => setAttribute("S_IWGRP", S_IWGRP);

  /// ## S_IWOTH (getter)
  Object? get S_IWOTH => getAttribute("S_IWOTH");

  /// ## S_IWOTH (setter)
  set S_IWOTH(Object? S_IWOTH) => setAttribute("S_IWOTH", S_IWOTH);

  /// ## S_IWRITE (getter)
  Object? get S_IWRITE => getAttribute("S_IWRITE");

  /// ## S_IWRITE (setter)
  set S_IWRITE(Object? S_IWRITE) => setAttribute("S_IWRITE", S_IWRITE);

  /// ## S_IWUSR (getter)
  Object? get S_IWUSR => getAttribute("S_IWUSR");

  /// ## S_IWUSR (setter)
  set S_IWUSR(Object? S_IWUSR) => setAttribute("S_IWUSR", S_IWUSR);

  /// ## S_IXGRP (getter)
  Object? get S_IXGRP => getAttribute("S_IXGRP");

  /// ## S_IXGRP (setter)
  set S_IXGRP(Object? S_IXGRP) => setAttribute("S_IXGRP", S_IXGRP);

  /// ## S_IXOTH (getter)
  Object? get S_IXOTH => getAttribute("S_IXOTH");

  /// ## S_IXOTH (setter)
  set S_IXOTH(Object? S_IXOTH) => setAttribute("S_IXOTH", S_IXOTH);

  /// ## S_IXUSR (getter)
  Object? get S_IXUSR => getAttribute("S_IXUSR");

  /// ## S_IXUSR (setter)
  set S_IXUSR(Object? S_IXUSR) => setAttribute("S_IXUSR", S_IXUSR);

  /// ## UF_APPEND (getter)
  Object? get UF_APPEND => getAttribute("UF_APPEND");

  /// ## UF_APPEND (setter)
  set UF_APPEND(Object? UF_APPEND) => setAttribute("UF_APPEND", UF_APPEND);

  /// ## UF_COMPRESSED (getter)
  Object? get UF_COMPRESSED => getAttribute("UF_COMPRESSED");

  /// ## UF_COMPRESSED (setter)
  set UF_COMPRESSED(Object? UF_COMPRESSED) =>
      setAttribute("UF_COMPRESSED", UF_COMPRESSED);

  /// ## UF_HIDDEN (getter)
  Object? get UF_HIDDEN => getAttribute("UF_HIDDEN");

  /// ## UF_HIDDEN (setter)
  set UF_HIDDEN(Object? UF_HIDDEN) => setAttribute("UF_HIDDEN", UF_HIDDEN);

  /// ## UF_IMMUTABLE (getter)
  Object? get UF_IMMUTABLE => getAttribute("UF_IMMUTABLE");

  /// ## UF_IMMUTABLE (setter)
  set UF_IMMUTABLE(Object? UF_IMMUTABLE) =>
      setAttribute("UF_IMMUTABLE", UF_IMMUTABLE);

  /// ## UF_NODUMP (getter)
  Object? get UF_NODUMP => getAttribute("UF_NODUMP");

  /// ## UF_NODUMP (setter)
  set UF_NODUMP(Object? UF_NODUMP) => setAttribute("UF_NODUMP", UF_NODUMP);

  /// ## UF_NOUNLINK (getter)
  Object? get UF_NOUNLINK => getAttribute("UF_NOUNLINK");

  /// ## UF_NOUNLINK (setter)
  set UF_NOUNLINK(Object? UF_NOUNLINK) =>
      setAttribute("UF_NOUNLINK", UF_NOUNLINK);

  /// ## UF_OPAQUE (getter)
  Object? get UF_OPAQUE => getAttribute("UF_OPAQUE");

  /// ## UF_OPAQUE (setter)
  set UF_OPAQUE(Object? UF_OPAQUE) => setAttribute("UF_OPAQUE", UF_OPAQUE);
}

/// ## io
///
/// ### python docstring
///
/// The io module provides the Python interfaces to stream handling. The
/// builtin open function is defined in this module.
///
/// At the top of the I/O hierarchy is the abstract base class IOBase. It
/// defines the basic interface to a stream. Note, however, that there is no
/// separation between reading and writing to streams; implementations are
/// allowed to raise an OSError if they do not support a given operation.
///
/// Extending IOBase is RawIOBase which deals simply with the reading and
/// writing of raw bytes to a stream. FileIO subclasses RawIOBase to provide
/// an interface to OS files.
///
/// BufferedIOBase deals with buffering on a raw byte stream (RawIOBase). Its
/// subclasses, BufferedWriter, BufferedReader, and BufferedRWPair buffer
/// streams that are readable, writable, and both respectively.
/// BufferedRandom provides a buffered interface to random access
/// streams. BytesIO is a simple stream of in-memory bytes.
///
/// Another IOBase subclass, TextIOBase, deals with the encoding and decoding
/// of streams into text. TextIOWrapper, which extends it, is a buffered text
/// interface to a buffered raw stream (`BufferedIOBase`). Finally, StringIO
/// is an in-memory stream for text.
///
/// Argument names are not part of the specification, and only the arguments
/// of open() are intended to be used as keyword arguments.
///
/// data:
///
/// DEFAULT_BUFFER_SIZE
///
///    An int containing the default buffer size used by the module's buffered
///    I/O classes. open() uses the file's blksize (as obtained by os.stat) if
///    possible.
///
/// ### python source
/// ```py
/// """The io module provides the Python interfaces to stream handling. The
/// builtin open function is defined in this module.
///
/// At the top of the I/O hierarchy is the abstract base class IOBase. It
/// defines the basic interface to a stream. Note, however, that there is no
/// separation between reading and writing to streams; implementations are
/// allowed to raise an OSError if they do not support a given operation.
///
/// Extending IOBase is RawIOBase which deals simply with the reading and
/// writing of raw bytes to a stream. FileIO subclasses RawIOBase to provide
/// an interface to OS files.
///
/// BufferedIOBase deals with buffering on a raw byte stream (RawIOBase). Its
/// subclasses, BufferedWriter, BufferedReader, and BufferedRWPair buffer
/// streams that are readable, writable, and both respectively.
/// BufferedRandom provides a buffered interface to random access
/// streams. BytesIO is a simple stream of in-memory bytes.
///
/// Another IOBase subclass, TextIOBase, deals with the encoding and decoding
/// of streams into text. TextIOWrapper, which extends it, is a buffered text
/// interface to a buffered raw stream (`BufferedIOBase`). Finally, StringIO
/// is an in-memory stream for text.
///
/// Argument names are not part of the specification, and only the arguments
/// of open() are intended to be used as keyword arguments.
///
/// data:
///
/// DEFAULT_BUFFER_SIZE
///
///    An int containing the default buffer size used by the module's buffered
///    I/O classes. open() uses the file's blksize (as obtained by os.stat) if
///    possible.
/// """
/// # New I/O library conforming to PEP 3116.
///
/// __author__ = ("Guido van Rossum <guido@python.org>, "
///               "Mike Verdone <mike.verdone@gmail.com>, "
///               "Mark Russell <mark.russell@zen.co.uk>, "
///               "Antoine Pitrou <solipsis@pitrou.net>, "
///               "Amaury Forgeot d'Arc <amauryfa@gmail.com>, "
///               "Benjamin Peterson <benjamin@python.org>")
///
/// __all__ = ["BlockingIOError", "open", "open_code", "IOBase", "RawIOBase",
///            "FileIO", "BytesIO", "StringIO", "BufferedIOBase",
///            "BufferedReader", "BufferedWriter", "BufferedRWPair",
///            "BufferedRandom", "TextIOBase", "TextIOWrapper",
///            "UnsupportedOperation", "SEEK_SET", "SEEK_CUR", "SEEK_END"]
///
///
/// import _io
/// import abc
///
/// from _io import (DEFAULT_BUFFER_SIZE, BlockingIOError, UnsupportedOperation,
///                  open, open_code, FileIO, BytesIO, StringIO, BufferedReader,
///                  BufferedWriter, BufferedRWPair, BufferedRandom,
///                  IncrementalNewlineDecoder, text_encoding, TextIOWrapper)
///
///
/// def __getattr__(name):
///     if name == "OpenWrapper":
///         # bpo-43680: Until Python 3.9, _pyio.open was not a static method and
///         # builtins.open was set to OpenWrapper to not become a bound method
///         # when set to a class variable. _io.open is a built-in function whereas
///         # _pyio.open is a Python function. In Python 3.10, _pyio.open() is now
///         # a static method, and builtins.open() is now io.open().
///         import warnings
///         warnings.warn('OpenWrapper is deprecated, use open instead',
///                       DeprecationWarning, stacklevel=2)
///         global OpenWrapper
///         OpenWrapper = open
///         return OpenWrapper
///     raise AttributeError(f"module {__name__!r} has no attribute {name!r}")
///
///
/// # Pretend this exception was created here.
/// UnsupportedOperation.__module__ = "io"
///
/// # for seek()
/// SEEK_SET = 0
/// SEEK_CUR = 1
/// SEEK_END = 2
///
/// # Declaring ABCs in C is tricky so we do it here.
/// # Method descriptions and default implementations are inherited from the C
/// # version however.
/// class IOBase(_io._IOBase, metaclass=abc.ABCMeta):
///     __doc__ = _io._IOBase.__doc__
///
/// class RawIOBase(_io._RawIOBase, IOBase):
///     __doc__ = _io._RawIOBase.__doc__
///
/// class BufferedIOBase(_io._BufferedIOBase, IOBase):
///     __doc__ = _io._BufferedIOBase.__doc__
///
/// class TextIOBase(_io._TextIOBase, IOBase):
///     __doc__ = _io._TextIOBase.__doc__
///
/// RawIOBase.register(FileIO)
///
/// for klass in (BytesIO, BufferedReader, BufferedWriter, BufferedRandom,
///               BufferedRWPair):
///     BufferedIOBase.register(klass)
///
/// for klass in (StringIO, TextIOWrapper):
///     TextIOBase.register(klass)
/// del klass
///
/// try:
///     from _io import _WindowsConsoleIO
/// except ImportError:
///     pass
/// else:
///     RawIOBase.register(_WindowsConsoleIO)
/// ```
final class io extends PythonModule {
  io.from(super.pythonModule) : super.from();

  static io import() => PythonFfiDart.instance.importModule(
        "io",
        io.from,
      );

  /// ## DEFAULT_BUFFER_SIZE (getter)
  Object? get DEFAULT_BUFFER_SIZE => getAttribute("DEFAULT_BUFFER_SIZE");

  /// ## DEFAULT_BUFFER_SIZE (setter)
  set DEFAULT_BUFFER_SIZE(Object? DEFAULT_BUFFER_SIZE) =>
      setAttribute("DEFAULT_BUFFER_SIZE", DEFAULT_BUFFER_SIZE);

  /// ## SEEK_CUR (getter)
  Object? get SEEK_CUR => getAttribute("SEEK_CUR");

  /// ## SEEK_CUR (setter)
  set SEEK_CUR(Object? SEEK_CUR) => setAttribute("SEEK_CUR", SEEK_CUR);

  /// ## SEEK_END (getter)
  Object? get SEEK_END => getAttribute("SEEK_END");

  /// ## SEEK_END (setter)
  set SEEK_END(Object? SEEK_END) => setAttribute("SEEK_END", SEEK_END);

  /// ## SEEK_SET (getter)
  Object? get SEEK_SET => getAttribute("SEEK_SET");

  /// ## SEEK_SET (setter)
  set SEEK_SET(Object? SEEK_SET) => setAttribute("SEEK_SET", SEEK_SET);
}

/// ## termios
final class termios extends PythonModule {
  termios.from(super.pythonModule) : super.from();

  static termios import() => PythonFfiDart.instance.importModule(
        "termios",
        termios.from,
      );

  /// ## B0 (getter)
  Object? get B0 => getAttribute("B0");

  /// ## B0 (setter)
  set B0(Object? B0) => setAttribute("B0", B0);

  /// ## B110 (getter)
  Object? get B110 => getAttribute("B110");

  /// ## B110 (setter)
  set B110(Object? B110) => setAttribute("B110", B110);

  /// ## B115200 (getter)
  Object? get B115200 => getAttribute("B115200");

  /// ## B115200 (setter)
  set B115200(Object? B115200) => setAttribute("B115200", B115200);

  /// ## B1200 (getter)
  Object? get B1200 => getAttribute("B1200");

  /// ## B1200 (setter)
  set B1200(Object? B1200) => setAttribute("B1200", B1200);

  /// ## B134 (getter)
  Object? get B134 => getAttribute("B134");

  /// ## B134 (setter)
  set B134(Object? B134) => setAttribute("B134", B134);

  /// ## B150 (getter)
  Object? get B150 => getAttribute("B150");

  /// ## B150 (setter)
  set B150(Object? B150) => setAttribute("B150", B150);

  /// ## B1800 (getter)
  Object? get B1800 => getAttribute("B1800");

  /// ## B1800 (setter)
  set B1800(Object? B1800) => setAttribute("B1800", B1800);

  /// ## B19200 (getter)
  Object? get B19200 => getAttribute("B19200");

  /// ## B19200 (setter)
  set B19200(Object? B19200) => setAttribute("B19200", B19200);

  /// ## B200 (getter)
  Object? get B200 => getAttribute("B200");

  /// ## B200 (setter)
  set B200(Object? B200) => setAttribute("B200", B200);

  /// ## B230400 (getter)
  Object? get B230400 => getAttribute("B230400");

  /// ## B230400 (setter)
  set B230400(Object? B230400) => setAttribute("B230400", B230400);

  /// ## B2400 (getter)
  Object? get B2400 => getAttribute("B2400");

  /// ## B2400 (setter)
  set B2400(Object? B2400) => setAttribute("B2400", B2400);

  /// ## B300 (getter)
  Object? get B300 => getAttribute("B300");

  /// ## B300 (setter)
  set B300(Object? B300) => setAttribute("B300", B300);

  /// ## B38400 (getter)
  Object? get B38400 => getAttribute("B38400");

  /// ## B38400 (setter)
  set B38400(Object? B38400) => setAttribute("B38400", B38400);

  /// ## B4800 (getter)
  Object? get B4800 => getAttribute("B4800");

  /// ## B4800 (setter)
  set B4800(Object? B4800) => setAttribute("B4800", B4800);

  /// ## B50 (getter)
  Object? get B50 => getAttribute("B50");

  /// ## B50 (setter)
  set B50(Object? B50) => setAttribute("B50", B50);

  /// ## B57600 (getter)
  Object? get B57600 => getAttribute("B57600");

  /// ## B57600 (setter)
  set B57600(Object? B57600) => setAttribute("B57600", B57600);

  /// ## B600 (getter)
  Object? get B600 => getAttribute("B600");

  /// ## B600 (setter)
  set B600(Object? B600) => setAttribute("B600", B600);

  /// ## B75 (getter)
  Object? get B75 => getAttribute("B75");

  /// ## B75 (setter)
  set B75(Object? B75) => setAttribute("B75", B75);

  /// ## B9600 (getter)
  Object? get B9600 => getAttribute("B9600");

  /// ## B9600 (setter)
  set B9600(Object? B9600) => setAttribute("B9600", B9600);

  /// ## BRKINT (getter)
  Object? get BRKINT => getAttribute("BRKINT");

  /// ## BRKINT (setter)
  set BRKINT(Object? BRKINT) => setAttribute("BRKINT", BRKINT);

  /// ## BS0 (getter)
  Object? get BS0 => getAttribute("BS0");

  /// ## BS0 (setter)
  set BS0(Object? BS0) => setAttribute("BS0", BS0);

  /// ## BS1 (getter)
  Object? get BS1 => getAttribute("BS1");

  /// ## BS1 (setter)
  set BS1(Object? BS1) => setAttribute("BS1", BS1);

  /// ## BSDLY (getter)
  Object? get BSDLY => getAttribute("BSDLY");

  /// ## BSDLY (setter)
  set BSDLY(Object? BSDLY) => setAttribute("BSDLY", BSDLY);

  /// ## CDSUSP (getter)
  Object? get CDSUSP => getAttribute("CDSUSP");

  /// ## CDSUSP (setter)
  set CDSUSP(Object? CDSUSP) => setAttribute("CDSUSP", CDSUSP);

  /// ## CEOF (getter)
  Object? get CEOF => getAttribute("CEOF");

  /// ## CEOF (setter)
  set CEOF(Object? CEOF) => setAttribute("CEOF", CEOF);

  /// ## CEOL (getter)
  Object? get CEOL => getAttribute("CEOL");

  /// ## CEOL (setter)
  set CEOL(Object? CEOL) => setAttribute("CEOL", CEOL);

  /// ## CEOT (getter)
  Object? get CEOT => getAttribute("CEOT");

  /// ## CEOT (setter)
  set CEOT(Object? CEOT) => setAttribute("CEOT", CEOT);

  /// ## CERASE (getter)
  Object? get CERASE => getAttribute("CERASE");

  /// ## CERASE (setter)
  set CERASE(Object? CERASE) => setAttribute("CERASE", CERASE);

  /// ## CFLUSH (getter)
  Object? get CFLUSH => getAttribute("CFLUSH");

  /// ## CFLUSH (setter)
  set CFLUSH(Object? CFLUSH) => setAttribute("CFLUSH", CFLUSH);

  /// ## CINTR (getter)
  Object? get CINTR => getAttribute("CINTR");

  /// ## CINTR (setter)
  set CINTR(Object? CINTR) => setAttribute("CINTR", CINTR);

  /// ## CKILL (getter)
  Object? get CKILL => getAttribute("CKILL");

  /// ## CKILL (setter)
  set CKILL(Object? CKILL) => setAttribute("CKILL", CKILL);

  /// ## CLNEXT (getter)
  Object? get CLNEXT => getAttribute("CLNEXT");

  /// ## CLNEXT (setter)
  set CLNEXT(Object? CLNEXT) => setAttribute("CLNEXT", CLNEXT);

  /// ## CLOCAL (getter)
  Object? get CLOCAL => getAttribute("CLOCAL");

  /// ## CLOCAL (setter)
  set CLOCAL(Object? CLOCAL) => setAttribute("CLOCAL", CLOCAL);

  /// ## CQUIT (getter)
  Object? get CQUIT => getAttribute("CQUIT");

  /// ## CQUIT (setter)
  set CQUIT(Object? CQUIT) => setAttribute("CQUIT", CQUIT);

  /// ## CR0 (getter)
  Object? get CR0 => getAttribute("CR0");

  /// ## CR0 (setter)
  set CR0(Object? CR0) => setAttribute("CR0", CR0);

  /// ## CR1 (getter)
  Object? get CR1 => getAttribute("CR1");

  /// ## CR1 (setter)
  set CR1(Object? CR1) => setAttribute("CR1", CR1);

  /// ## CR2 (getter)
  Object? get CR2 => getAttribute("CR2");

  /// ## CR2 (setter)
  set CR2(Object? CR2) => setAttribute("CR2", CR2);

  /// ## CR3 (getter)
  Object? get CR3 => getAttribute("CR3");

  /// ## CR3 (setter)
  set CR3(Object? CR3) => setAttribute("CR3", CR3);

  /// ## CRDLY (getter)
  Object? get CRDLY => getAttribute("CRDLY");

  /// ## CRDLY (setter)
  set CRDLY(Object? CRDLY) => setAttribute("CRDLY", CRDLY);

  /// ## CREAD (getter)
  Object? get CREAD => getAttribute("CREAD");

  /// ## CREAD (setter)
  set CREAD(Object? CREAD) => setAttribute("CREAD", CREAD);

  /// ## CRPRNT (getter)
  Object? get CRPRNT => getAttribute("CRPRNT");

  /// ## CRPRNT (setter)
  set CRPRNT(Object? CRPRNT) => setAttribute("CRPRNT", CRPRNT);

  /// ## CRTSCTS (getter)
  Object? get CRTSCTS => getAttribute("CRTSCTS");

  /// ## CRTSCTS (setter)
  set CRTSCTS(Object? CRTSCTS) => setAttribute("CRTSCTS", CRTSCTS);

  /// ## CS5 (getter)
  Object? get CS5 => getAttribute("CS5");

  /// ## CS5 (setter)
  set CS5(Object? CS5) => setAttribute("CS5", CS5);

  /// ## CS6 (getter)
  Object? get CS6 => getAttribute("CS6");

  /// ## CS6 (setter)
  set CS6(Object? CS6) => setAttribute("CS6", CS6);

  /// ## CS7 (getter)
  Object? get CS7 => getAttribute("CS7");

  /// ## CS7 (setter)
  set CS7(Object? CS7) => setAttribute("CS7", CS7);

  /// ## CS8 (getter)
  Object? get CS8 => getAttribute("CS8");

  /// ## CS8 (setter)
  set CS8(Object? CS8) => setAttribute("CS8", CS8);

  /// ## CSIZE (getter)
  Object? get CSIZE => getAttribute("CSIZE");

  /// ## CSIZE (setter)
  set CSIZE(Object? CSIZE) => setAttribute("CSIZE", CSIZE);

  /// ## CSTART (getter)
  Object? get CSTART => getAttribute("CSTART");

  /// ## CSTART (setter)
  set CSTART(Object? CSTART) => setAttribute("CSTART", CSTART);

  /// ## CSTOP (getter)
  Object? get CSTOP => getAttribute("CSTOP");

  /// ## CSTOP (setter)
  set CSTOP(Object? CSTOP) => setAttribute("CSTOP", CSTOP);

  /// ## CSTOPB (getter)
  Object? get CSTOPB => getAttribute("CSTOPB");

  /// ## CSTOPB (setter)
  set CSTOPB(Object? CSTOPB) => setAttribute("CSTOPB", CSTOPB);

  /// ## CSUSP (getter)
  Object? get CSUSP => getAttribute("CSUSP");

  /// ## CSUSP (setter)
  set CSUSP(Object? CSUSP) => setAttribute("CSUSP", CSUSP);

  /// ## CWERASE (getter)
  Object? get CWERASE => getAttribute("CWERASE");

  /// ## CWERASE (setter)
  set CWERASE(Object? CWERASE) => setAttribute("CWERASE", CWERASE);

  /// ## ECHO (getter)
  Object? get ECHO => getAttribute("ECHO");

  /// ## ECHO (setter)
  set ECHO(Object? ECHO) => setAttribute("ECHO", ECHO);

  /// ## ECHOCTL (getter)
  Object? get ECHOCTL => getAttribute("ECHOCTL");

  /// ## ECHOCTL (setter)
  set ECHOCTL(Object? ECHOCTL) => setAttribute("ECHOCTL", ECHOCTL);

  /// ## ECHOE (getter)
  Object? get ECHOE => getAttribute("ECHOE");

  /// ## ECHOE (setter)
  set ECHOE(Object? ECHOE) => setAttribute("ECHOE", ECHOE);

  /// ## ECHOK (getter)
  Object? get ECHOK => getAttribute("ECHOK");

  /// ## ECHOK (setter)
  set ECHOK(Object? ECHOK) => setAttribute("ECHOK", ECHOK);

  /// ## ECHOKE (getter)
  Object? get ECHOKE => getAttribute("ECHOKE");

  /// ## ECHOKE (setter)
  set ECHOKE(Object? ECHOKE) => setAttribute("ECHOKE", ECHOKE);

  /// ## ECHONL (getter)
  Object? get ECHONL => getAttribute("ECHONL");

  /// ## ECHONL (setter)
  set ECHONL(Object? ECHONL) => setAttribute("ECHONL", ECHONL);

  /// ## ECHOPRT (getter)
  Object? get ECHOPRT => getAttribute("ECHOPRT");

  /// ## ECHOPRT (setter)
  set ECHOPRT(Object? ECHOPRT) => setAttribute("ECHOPRT", ECHOPRT);

  /// ## EXTA (getter)
  Object? get EXTA => getAttribute("EXTA");

  /// ## EXTA (setter)
  set EXTA(Object? EXTA) => setAttribute("EXTA", EXTA);

  /// ## EXTB (getter)
  Object? get EXTB => getAttribute("EXTB");

  /// ## EXTB (setter)
  set EXTB(Object? EXTB) => setAttribute("EXTB", EXTB);

  /// ## FF0 (getter)
  Object? get FF0 => getAttribute("FF0");

  /// ## FF0 (setter)
  set FF0(Object? FF0) => setAttribute("FF0", FF0);

  /// ## FF1 (getter)
  Object? get FF1 => getAttribute("FF1");

  /// ## FF1 (setter)
  set FF1(Object? FF1) => setAttribute("FF1", FF1);

  /// ## FFDLY (getter)
  Object? get FFDLY => getAttribute("FFDLY");

  /// ## FFDLY (setter)
  set FFDLY(Object? FFDLY) => setAttribute("FFDLY", FFDLY);

  /// ## FIOASYNC (getter)
  Object? get FIOASYNC => getAttribute("FIOASYNC");

  /// ## FIOASYNC (setter)
  set FIOASYNC(Object? FIOASYNC) => setAttribute("FIOASYNC", FIOASYNC);

  /// ## FIOCLEX (getter)
  Object? get FIOCLEX => getAttribute("FIOCLEX");

  /// ## FIOCLEX (setter)
  set FIOCLEX(Object? FIOCLEX) => setAttribute("FIOCLEX", FIOCLEX);

  /// ## FIONBIO (getter)
  Object? get FIONBIO => getAttribute("FIONBIO");

  /// ## FIONBIO (setter)
  set FIONBIO(Object? FIONBIO) => setAttribute("FIONBIO", FIONBIO);

  /// ## FIONCLEX (getter)
  Object? get FIONCLEX => getAttribute("FIONCLEX");

  /// ## FIONCLEX (setter)
  set FIONCLEX(Object? FIONCLEX) => setAttribute("FIONCLEX", FIONCLEX);

  /// ## FIONREAD (getter)
  Object? get FIONREAD => getAttribute("FIONREAD");

  /// ## FIONREAD (setter)
  set FIONREAD(Object? FIONREAD) => setAttribute("FIONREAD", FIONREAD);

  /// ## FLUSHO (getter)
  Object? get FLUSHO => getAttribute("FLUSHO");

  /// ## FLUSHO (setter)
  set FLUSHO(Object? FLUSHO) => setAttribute("FLUSHO", FLUSHO);

  /// ## HUPCL (getter)
  Object? get HUPCL => getAttribute("HUPCL");

  /// ## HUPCL (setter)
  set HUPCL(Object? HUPCL) => setAttribute("HUPCL", HUPCL);

  /// ## ICANON (getter)
  Object? get ICANON => getAttribute("ICANON");

  /// ## ICANON (setter)
  set ICANON(Object? ICANON) => setAttribute("ICANON", ICANON);

  /// ## ICRNL (getter)
  Object? get ICRNL => getAttribute("ICRNL");

  /// ## ICRNL (setter)
  set ICRNL(Object? ICRNL) => setAttribute("ICRNL", ICRNL);

  /// ## IEXTEN (getter)
  Object? get IEXTEN => getAttribute("IEXTEN");

  /// ## IEXTEN (setter)
  set IEXTEN(Object? IEXTEN) => setAttribute("IEXTEN", IEXTEN);

  /// ## IGNBRK (getter)
  Object? get IGNBRK => getAttribute("IGNBRK");

  /// ## IGNBRK (setter)
  set IGNBRK(Object? IGNBRK) => setAttribute("IGNBRK", IGNBRK);

  /// ## IGNCR (getter)
  Object? get IGNCR => getAttribute("IGNCR");

  /// ## IGNCR (setter)
  set IGNCR(Object? IGNCR) => setAttribute("IGNCR", IGNCR);

  /// ## IGNPAR (getter)
  Object? get IGNPAR => getAttribute("IGNPAR");

  /// ## IGNPAR (setter)
  set IGNPAR(Object? IGNPAR) => setAttribute("IGNPAR", IGNPAR);

  /// ## IMAXBEL (getter)
  Object? get IMAXBEL => getAttribute("IMAXBEL");

  /// ## IMAXBEL (setter)
  set IMAXBEL(Object? IMAXBEL) => setAttribute("IMAXBEL", IMAXBEL);

  /// ## INLCR (getter)
  Object? get INLCR => getAttribute("INLCR");

  /// ## INLCR (setter)
  set INLCR(Object? INLCR) => setAttribute("INLCR", INLCR);

  /// ## INPCK (getter)
  Object? get INPCK => getAttribute("INPCK");

  /// ## INPCK (setter)
  set INPCK(Object? INPCK) => setAttribute("INPCK", INPCK);

  /// ## ISIG (getter)
  Object? get ISIG => getAttribute("ISIG");

  /// ## ISIG (setter)
  set ISIG(Object? ISIG) => setAttribute("ISIG", ISIG);

  /// ## ISTRIP (getter)
  Object? get ISTRIP => getAttribute("ISTRIP");

  /// ## ISTRIP (setter)
  set ISTRIP(Object? ISTRIP) => setAttribute("ISTRIP", ISTRIP);

  /// ## IXANY (getter)
  Object? get IXANY => getAttribute("IXANY");

  /// ## IXANY (setter)
  set IXANY(Object? IXANY) => setAttribute("IXANY", IXANY);

  /// ## IXOFF (getter)
  Object? get IXOFF => getAttribute("IXOFF");

  /// ## IXOFF (setter)
  set IXOFF(Object? IXOFF) => setAttribute("IXOFF", IXOFF);

  /// ## IXON (getter)
  Object? get IXON => getAttribute("IXON");

  /// ## IXON (setter)
  set IXON(Object? IXON) => setAttribute("IXON", IXON);

  /// ## NCCS (getter)
  Object? get NCCS => getAttribute("NCCS");

  /// ## NCCS (setter)
  set NCCS(Object? NCCS) => setAttribute("NCCS", NCCS);

  /// ## NL0 (getter)
  Object? get NL0 => getAttribute("NL0");

  /// ## NL0 (setter)
  set NL0(Object? NL0) => setAttribute("NL0", NL0);

  /// ## NL1 (getter)
  Object? get NL1 => getAttribute("NL1");

  /// ## NL1 (setter)
  set NL1(Object? NL1) => setAttribute("NL1", NL1);

  /// ## NLDLY (getter)
  Object? get NLDLY => getAttribute("NLDLY");

  /// ## NLDLY (setter)
  set NLDLY(Object? NLDLY) => setAttribute("NLDLY", NLDLY);

  /// ## NOFLSH (getter)
  Object? get NOFLSH => getAttribute("NOFLSH");

  /// ## NOFLSH (setter)
  set NOFLSH(Object? NOFLSH) => setAttribute("NOFLSH", NOFLSH);

  /// ## OCRNL (getter)
  Object? get OCRNL => getAttribute("OCRNL");

  /// ## OCRNL (setter)
  set OCRNL(Object? OCRNL) => setAttribute("OCRNL", OCRNL);

  /// ## OFDEL (getter)
  Object? get OFDEL => getAttribute("OFDEL");

  /// ## OFDEL (setter)
  set OFDEL(Object? OFDEL) => setAttribute("OFDEL", OFDEL);

  /// ## OFILL (getter)
  Object? get OFILL => getAttribute("OFILL");

  /// ## OFILL (setter)
  set OFILL(Object? OFILL) => setAttribute("OFILL", OFILL);

  /// ## ONLCR (getter)
  Object? get ONLCR => getAttribute("ONLCR");

  /// ## ONLCR (setter)
  set ONLCR(Object? ONLCR) => setAttribute("ONLCR", ONLCR);

  /// ## ONLRET (getter)
  Object? get ONLRET => getAttribute("ONLRET");

  /// ## ONLRET (setter)
  set ONLRET(Object? ONLRET) => setAttribute("ONLRET", ONLRET);

  /// ## ONOCR (getter)
  Object? get ONOCR => getAttribute("ONOCR");

  /// ## ONOCR (setter)
  set ONOCR(Object? ONOCR) => setAttribute("ONOCR", ONOCR);

  /// ## OPOST (getter)
  Object? get OPOST => getAttribute("OPOST");

  /// ## OPOST (setter)
  set OPOST(Object? OPOST) => setAttribute("OPOST", OPOST);

  /// ## PARENB (getter)
  Object? get PARENB => getAttribute("PARENB");

  /// ## PARENB (setter)
  set PARENB(Object? PARENB) => setAttribute("PARENB", PARENB);

  /// ## PARMRK (getter)
  Object? get PARMRK => getAttribute("PARMRK");

  /// ## PARMRK (setter)
  set PARMRK(Object? PARMRK) => setAttribute("PARMRK", PARMRK);

  /// ## PARODD (getter)
  Object? get PARODD => getAttribute("PARODD");

  /// ## PARODD (setter)
  set PARODD(Object? PARODD) => setAttribute("PARODD", PARODD);

  /// ## PENDIN (getter)
  Object? get PENDIN => getAttribute("PENDIN");

  /// ## PENDIN (setter)
  set PENDIN(Object? PENDIN) => setAttribute("PENDIN", PENDIN);

  /// ## TAB0 (getter)
  Object? get TAB0 => getAttribute("TAB0");

  /// ## TAB0 (setter)
  set TAB0(Object? TAB0) => setAttribute("TAB0", TAB0);

  /// ## TAB1 (getter)
  Object? get TAB1 => getAttribute("TAB1");

  /// ## TAB1 (setter)
  set TAB1(Object? TAB1) => setAttribute("TAB1", TAB1);

  /// ## TAB2 (getter)
  Object? get TAB2 => getAttribute("TAB2");

  /// ## TAB2 (setter)
  set TAB2(Object? TAB2) => setAttribute("TAB2", TAB2);

  /// ## TAB3 (getter)
  Object? get TAB3 => getAttribute("TAB3");

  /// ## TAB3 (setter)
  set TAB3(Object? TAB3) => setAttribute("TAB3", TAB3);

  /// ## TABDLY (getter)
  Object? get TABDLY => getAttribute("TABDLY");

  /// ## TABDLY (setter)
  set TABDLY(Object? TABDLY) => setAttribute("TABDLY", TABDLY);

  /// ## TCIFLUSH (getter)
  Object? get TCIFLUSH => getAttribute("TCIFLUSH");

  /// ## TCIFLUSH (setter)
  set TCIFLUSH(Object? TCIFLUSH) => setAttribute("TCIFLUSH", TCIFLUSH);

  /// ## TCIOFF (getter)
  Object? get TCIOFF => getAttribute("TCIOFF");

  /// ## TCIOFF (setter)
  set TCIOFF(Object? TCIOFF) => setAttribute("TCIOFF", TCIOFF);

  /// ## TCIOFLUSH (getter)
  Object? get TCIOFLUSH => getAttribute("TCIOFLUSH");

  /// ## TCIOFLUSH (setter)
  set TCIOFLUSH(Object? TCIOFLUSH) => setAttribute("TCIOFLUSH", TCIOFLUSH);

  /// ## TCION (getter)
  Object? get TCION => getAttribute("TCION");

  /// ## TCION (setter)
  set TCION(Object? TCION) => setAttribute("TCION", TCION);

  /// ## TCOFLUSH (getter)
  Object? get TCOFLUSH => getAttribute("TCOFLUSH");

  /// ## TCOFLUSH (setter)
  set TCOFLUSH(Object? TCOFLUSH) => setAttribute("TCOFLUSH", TCOFLUSH);

  /// ## TCOOFF (getter)
  Object? get TCOOFF => getAttribute("TCOOFF");

  /// ## TCOOFF (setter)
  set TCOOFF(Object? TCOOFF) => setAttribute("TCOOFF", TCOOFF);

  /// ## TCOON (getter)
  Object? get TCOON => getAttribute("TCOON");

  /// ## TCOON (setter)
  set TCOON(Object? TCOON) => setAttribute("TCOON", TCOON);

  /// ## TCSADRAIN (getter)
  Object? get TCSADRAIN => getAttribute("TCSADRAIN");

  /// ## TCSADRAIN (setter)
  set TCSADRAIN(Object? TCSADRAIN) => setAttribute("TCSADRAIN", TCSADRAIN);

  /// ## TCSAFLUSH (getter)
  Object? get TCSAFLUSH => getAttribute("TCSAFLUSH");

  /// ## TCSAFLUSH (setter)
  set TCSAFLUSH(Object? TCSAFLUSH) => setAttribute("TCSAFLUSH", TCSAFLUSH);

  /// ## TCSANOW (getter)
  Object? get TCSANOW => getAttribute("TCSANOW");

  /// ## TCSANOW (setter)
  set TCSANOW(Object? TCSANOW) => setAttribute("TCSANOW", TCSANOW);

  /// ## TCSASOFT (getter)
  Object? get TCSASOFT => getAttribute("TCSASOFT");

  /// ## TCSASOFT (setter)
  set TCSASOFT(Object? TCSASOFT) => setAttribute("TCSASOFT", TCSASOFT);

  /// ## TIOCCONS (getter)
  Object? get TIOCCONS => getAttribute("TIOCCONS");

  /// ## TIOCCONS (setter)
  set TIOCCONS(Object? TIOCCONS) => setAttribute("TIOCCONS", TIOCCONS);

  /// ## TIOCEXCL (getter)
  Object? get TIOCEXCL => getAttribute("TIOCEXCL");

  /// ## TIOCEXCL (setter)
  set TIOCEXCL(Object? TIOCEXCL) => setAttribute("TIOCEXCL", TIOCEXCL);

  /// ## TIOCGETD (getter)
  Object? get TIOCGETD => getAttribute("TIOCGETD");

  /// ## TIOCGETD (setter)
  set TIOCGETD(Object? TIOCGETD) => setAttribute("TIOCGETD", TIOCGETD);

  /// ## TIOCGPGRP (getter)
  Object? get TIOCGPGRP => getAttribute("TIOCGPGRP");

  /// ## TIOCGPGRP (setter)
  set TIOCGPGRP(Object? TIOCGPGRP) => setAttribute("TIOCGPGRP", TIOCGPGRP);

  /// ## TIOCGSIZE (getter)
  Object? get TIOCGSIZE => getAttribute("TIOCGSIZE");

  /// ## TIOCGSIZE (setter)
  set TIOCGSIZE(Object? TIOCGSIZE) => setAttribute("TIOCGSIZE", TIOCGSIZE);

  /// ## TIOCGWINSZ (getter)
  Object? get TIOCGWINSZ => getAttribute("TIOCGWINSZ");

  /// ## TIOCGWINSZ (setter)
  set TIOCGWINSZ(Object? TIOCGWINSZ) => setAttribute("TIOCGWINSZ", TIOCGWINSZ);

  /// ## TIOCMBIC (getter)
  Object? get TIOCMBIC => getAttribute("TIOCMBIC");

  /// ## TIOCMBIC (setter)
  set TIOCMBIC(Object? TIOCMBIC) => setAttribute("TIOCMBIC", TIOCMBIC);

  /// ## TIOCMBIS (getter)
  Object? get TIOCMBIS => getAttribute("TIOCMBIS");

  /// ## TIOCMBIS (setter)
  set TIOCMBIS(Object? TIOCMBIS) => setAttribute("TIOCMBIS", TIOCMBIS);

  /// ## TIOCMGET (getter)
  Object? get TIOCMGET => getAttribute("TIOCMGET");

  /// ## TIOCMGET (setter)
  set TIOCMGET(Object? TIOCMGET) => setAttribute("TIOCMGET", TIOCMGET);

  /// ## TIOCMSET (getter)
  Object? get TIOCMSET => getAttribute("TIOCMSET");

  /// ## TIOCMSET (setter)
  set TIOCMSET(Object? TIOCMSET) => setAttribute("TIOCMSET", TIOCMSET);

  /// ## TIOCM_CAR (getter)
  Object? get TIOCM_CAR => getAttribute("TIOCM_CAR");

  /// ## TIOCM_CAR (setter)
  set TIOCM_CAR(Object? TIOCM_CAR) => setAttribute("TIOCM_CAR", TIOCM_CAR);

  /// ## TIOCM_CD (getter)
  Object? get TIOCM_CD => getAttribute("TIOCM_CD");

  /// ## TIOCM_CD (setter)
  set TIOCM_CD(Object? TIOCM_CD) => setAttribute("TIOCM_CD", TIOCM_CD);

  /// ## TIOCM_CTS (getter)
  Object? get TIOCM_CTS => getAttribute("TIOCM_CTS");

  /// ## TIOCM_CTS (setter)
  set TIOCM_CTS(Object? TIOCM_CTS) => setAttribute("TIOCM_CTS", TIOCM_CTS);

  /// ## TIOCM_DSR (getter)
  Object? get TIOCM_DSR => getAttribute("TIOCM_DSR");

  /// ## TIOCM_DSR (setter)
  set TIOCM_DSR(Object? TIOCM_DSR) => setAttribute("TIOCM_DSR", TIOCM_DSR);

  /// ## TIOCM_DTR (getter)
  Object? get TIOCM_DTR => getAttribute("TIOCM_DTR");

  /// ## TIOCM_DTR (setter)
  set TIOCM_DTR(Object? TIOCM_DTR) => setAttribute("TIOCM_DTR", TIOCM_DTR);

  /// ## TIOCM_LE (getter)
  Object? get TIOCM_LE => getAttribute("TIOCM_LE");

  /// ## TIOCM_LE (setter)
  set TIOCM_LE(Object? TIOCM_LE) => setAttribute("TIOCM_LE", TIOCM_LE);

  /// ## TIOCM_RI (getter)
  Object? get TIOCM_RI => getAttribute("TIOCM_RI");

  /// ## TIOCM_RI (setter)
  set TIOCM_RI(Object? TIOCM_RI) => setAttribute("TIOCM_RI", TIOCM_RI);

  /// ## TIOCM_RNG (getter)
  Object? get TIOCM_RNG => getAttribute("TIOCM_RNG");

  /// ## TIOCM_RNG (setter)
  set TIOCM_RNG(Object? TIOCM_RNG) => setAttribute("TIOCM_RNG", TIOCM_RNG);

  /// ## TIOCM_RTS (getter)
  Object? get TIOCM_RTS => getAttribute("TIOCM_RTS");

  /// ## TIOCM_RTS (setter)
  set TIOCM_RTS(Object? TIOCM_RTS) => setAttribute("TIOCM_RTS", TIOCM_RTS);

  /// ## TIOCM_SR (getter)
  Object? get TIOCM_SR => getAttribute("TIOCM_SR");

  /// ## TIOCM_SR (setter)
  set TIOCM_SR(Object? TIOCM_SR) => setAttribute("TIOCM_SR", TIOCM_SR);

  /// ## TIOCM_ST (getter)
  Object? get TIOCM_ST => getAttribute("TIOCM_ST");

  /// ## TIOCM_ST (setter)
  set TIOCM_ST(Object? TIOCM_ST) => setAttribute("TIOCM_ST", TIOCM_ST);

  /// ## TIOCNOTTY (getter)
  Object? get TIOCNOTTY => getAttribute("TIOCNOTTY");

  /// ## TIOCNOTTY (setter)
  set TIOCNOTTY(Object? TIOCNOTTY) => setAttribute("TIOCNOTTY", TIOCNOTTY);

  /// ## TIOCNXCL (getter)
  Object? get TIOCNXCL => getAttribute("TIOCNXCL");

  /// ## TIOCNXCL (setter)
  set TIOCNXCL(Object? TIOCNXCL) => setAttribute("TIOCNXCL", TIOCNXCL);

  /// ## TIOCOUTQ (getter)
  Object? get TIOCOUTQ => getAttribute("TIOCOUTQ");

  /// ## TIOCOUTQ (setter)
  set TIOCOUTQ(Object? TIOCOUTQ) => setAttribute("TIOCOUTQ", TIOCOUTQ);

  /// ## TIOCPKT (getter)
  Object? get TIOCPKT => getAttribute("TIOCPKT");

  /// ## TIOCPKT (setter)
  set TIOCPKT(Object? TIOCPKT) => setAttribute("TIOCPKT", TIOCPKT);

  /// ## TIOCPKT_DATA (getter)
  Object? get TIOCPKT_DATA => getAttribute("TIOCPKT_DATA");

  /// ## TIOCPKT_DATA (setter)
  set TIOCPKT_DATA(Object? TIOCPKT_DATA) =>
      setAttribute("TIOCPKT_DATA", TIOCPKT_DATA);

  /// ## TIOCPKT_DOSTOP (getter)
  Object? get TIOCPKT_DOSTOP => getAttribute("TIOCPKT_DOSTOP");

  /// ## TIOCPKT_DOSTOP (setter)
  set TIOCPKT_DOSTOP(Object? TIOCPKT_DOSTOP) =>
      setAttribute("TIOCPKT_DOSTOP", TIOCPKT_DOSTOP);

  /// ## TIOCPKT_FLUSHREAD (getter)
  Object? get TIOCPKT_FLUSHREAD => getAttribute("TIOCPKT_FLUSHREAD");

  /// ## TIOCPKT_FLUSHREAD (setter)
  set TIOCPKT_FLUSHREAD(Object? TIOCPKT_FLUSHREAD) =>
      setAttribute("TIOCPKT_FLUSHREAD", TIOCPKT_FLUSHREAD);

  /// ## TIOCPKT_FLUSHWRITE (getter)
  Object? get TIOCPKT_FLUSHWRITE => getAttribute("TIOCPKT_FLUSHWRITE");

  /// ## TIOCPKT_FLUSHWRITE (setter)
  set TIOCPKT_FLUSHWRITE(Object? TIOCPKT_FLUSHWRITE) =>
      setAttribute("TIOCPKT_FLUSHWRITE", TIOCPKT_FLUSHWRITE);

  /// ## TIOCPKT_NOSTOP (getter)
  Object? get TIOCPKT_NOSTOP => getAttribute("TIOCPKT_NOSTOP");

  /// ## TIOCPKT_NOSTOP (setter)
  set TIOCPKT_NOSTOP(Object? TIOCPKT_NOSTOP) =>
      setAttribute("TIOCPKT_NOSTOP", TIOCPKT_NOSTOP);

  /// ## TIOCPKT_START (getter)
  Object? get TIOCPKT_START => getAttribute("TIOCPKT_START");

  /// ## TIOCPKT_START (setter)
  set TIOCPKT_START(Object? TIOCPKT_START) =>
      setAttribute("TIOCPKT_START", TIOCPKT_START);

  /// ## TIOCPKT_STOP (getter)
  Object? get TIOCPKT_STOP => getAttribute("TIOCPKT_STOP");

  /// ## TIOCPKT_STOP (setter)
  set TIOCPKT_STOP(Object? TIOCPKT_STOP) =>
      setAttribute("TIOCPKT_STOP", TIOCPKT_STOP);

  /// ## TIOCSCTTY (getter)
  Object? get TIOCSCTTY => getAttribute("TIOCSCTTY");

  /// ## TIOCSCTTY (setter)
  set TIOCSCTTY(Object? TIOCSCTTY) => setAttribute("TIOCSCTTY", TIOCSCTTY);

  /// ## TIOCSETD (getter)
  Object? get TIOCSETD => getAttribute("TIOCSETD");

  /// ## TIOCSETD (setter)
  set TIOCSETD(Object? TIOCSETD) => setAttribute("TIOCSETD", TIOCSETD);

  /// ## TIOCSPGRP (getter)
  Object? get TIOCSPGRP => getAttribute("TIOCSPGRP");

  /// ## TIOCSPGRP (setter)
  set TIOCSPGRP(Object? TIOCSPGRP) => setAttribute("TIOCSPGRP", TIOCSPGRP);

  /// ## TIOCSSIZE (getter)
  Object? get TIOCSSIZE => getAttribute("TIOCSSIZE");

  /// ## TIOCSSIZE (setter)
  set TIOCSSIZE(Object? TIOCSSIZE) => setAttribute("TIOCSSIZE", TIOCSSIZE);

  /// ## TIOCSTI (getter)
  Object? get TIOCSTI => getAttribute("TIOCSTI");

  /// ## TIOCSTI (setter)
  set TIOCSTI(Object? TIOCSTI) => setAttribute("TIOCSTI", TIOCSTI);

  /// ## TIOCSWINSZ (getter)
  Object? get TIOCSWINSZ => getAttribute("TIOCSWINSZ");

  /// ## TIOCSWINSZ (setter)
  set TIOCSWINSZ(Object? TIOCSWINSZ) => setAttribute("TIOCSWINSZ", TIOCSWINSZ);

  /// ## TOSTOP (getter)
  Object? get TOSTOP => getAttribute("TOSTOP");

  /// ## TOSTOP (setter)
  set TOSTOP(Object? TOSTOP) => setAttribute("TOSTOP", TOSTOP);

  /// ## VDISCARD (getter)
  Object? get VDISCARD => getAttribute("VDISCARD");

  /// ## VDISCARD (setter)
  set VDISCARD(Object? VDISCARD) => setAttribute("VDISCARD", VDISCARD);

  /// ## VEOF (getter)
  Object? get VEOF => getAttribute("VEOF");

  /// ## VEOF (setter)
  set VEOF(Object? VEOF) => setAttribute("VEOF", VEOF);

  /// ## VEOL (getter)
  Object? get VEOL => getAttribute("VEOL");

  /// ## VEOL (setter)
  set VEOL(Object? VEOL) => setAttribute("VEOL", VEOL);

  /// ## VEOL2 (getter)
  Object? get VEOL2 => getAttribute("VEOL2");

  /// ## VEOL2 (setter)
  set VEOL2(Object? VEOL2) => setAttribute("VEOL2", VEOL2);

  /// ## VERASE (getter)
  Object? get VERASE => getAttribute("VERASE");

  /// ## VERASE (setter)
  set VERASE(Object? VERASE) => setAttribute("VERASE", VERASE);

  /// ## VINTR (getter)
  Object? get VINTR => getAttribute("VINTR");

  /// ## VINTR (setter)
  set VINTR(Object? VINTR) => setAttribute("VINTR", VINTR);

  /// ## VKILL (getter)
  Object? get VKILL => getAttribute("VKILL");

  /// ## VKILL (setter)
  set VKILL(Object? VKILL) => setAttribute("VKILL", VKILL);

  /// ## VLNEXT (getter)
  Object? get VLNEXT => getAttribute("VLNEXT");

  /// ## VLNEXT (setter)
  set VLNEXT(Object? VLNEXT) => setAttribute("VLNEXT", VLNEXT);

  /// ## VMIN (getter)
  Object? get VMIN => getAttribute("VMIN");

  /// ## VMIN (setter)
  set VMIN(Object? VMIN) => setAttribute("VMIN", VMIN);

  /// ## VQUIT (getter)
  Object? get VQUIT => getAttribute("VQUIT");

  /// ## VQUIT (setter)
  set VQUIT(Object? VQUIT) => setAttribute("VQUIT", VQUIT);

  /// ## VREPRINT (getter)
  Object? get VREPRINT => getAttribute("VREPRINT");

  /// ## VREPRINT (setter)
  set VREPRINT(Object? VREPRINT) => setAttribute("VREPRINT", VREPRINT);

  /// ## VSTART (getter)
  Object? get VSTART => getAttribute("VSTART");

  /// ## VSTART (setter)
  set VSTART(Object? VSTART) => setAttribute("VSTART", VSTART);

  /// ## VSTOP (getter)
  Object? get VSTOP => getAttribute("VSTOP");

  /// ## VSTOP (setter)
  set VSTOP(Object? VSTOP) => setAttribute("VSTOP", VSTOP);

  /// ## VSUSP (getter)
  Object? get VSUSP => getAttribute("VSUSP");

  /// ## VSUSP (setter)
  set VSUSP(Object? VSUSP) => setAttribute("VSUSP", VSUSP);

  /// ## VT0 (getter)
  Object? get VT0 => getAttribute("VT0");

  /// ## VT0 (setter)
  set VT0(Object? VT0) => setAttribute("VT0", VT0);

  /// ## VT1 (getter)
  Object? get VT1 => getAttribute("VT1");

  /// ## VT1 (setter)
  set VT1(Object? VT1) => setAttribute("VT1", VT1);

  /// ## VTDLY (getter)
  Object? get VTDLY => getAttribute("VTDLY");

  /// ## VTDLY (setter)
  set VTDLY(Object? VTDLY) => setAttribute("VTDLY", VTDLY);

  /// ## VTIME (getter)
  Object? get VTIME => getAttribute("VTIME");

  /// ## VTIME (setter)
  set VTIME(Object? VTIME) => setAttribute("VTIME", VTIME);

  /// ## VWERASE (getter)
  Object? get VWERASE => getAttribute("VWERASE");

  /// ## VWERASE (setter)
  set VWERASE(Object? VWERASE) => setAttribute("VWERASE", VWERASE);
}

/// ## warnings
///
/// ### python docstring
///
/// Python part of the warnings subsystem.
///
/// ### python source
/// ```py
/// """Python part of the warnings subsystem."""
///
/// import sys
///
///
/// __all__ = ["warn", "warn_explicit", "showwarning",
///            "formatwarning", "filterwarnings", "simplefilter",
///            "resetwarnings", "catch_warnings"]
///
/// def showwarning(message, category, filename, lineno, file=None, line=None):
///     """Hook to write a warning to a file; replace if you like."""
///     msg = WarningMessage(message, category, filename, lineno, file, line)
///     _showwarnmsg_impl(msg)
///
/// def formatwarning(message, category, filename, lineno, line=None):
///     """Function to format a warning the standard way."""
///     msg = WarningMessage(message, category, filename, lineno, None, line)
///     return _formatwarnmsg_impl(msg)
///
/// def _showwarnmsg_impl(msg):
///     file = msg.file
///     if file is None:
///         file = sys.stderr
///         if file is None:
///             # sys.stderr is None when run with pythonw.exe:
///             # warnings get lost
///             return
///     text = _formatwarnmsg(msg)
///     try:
///         file.write(text)
///     except OSError:
///         # the file (probably stderr) is invalid - this warning gets lost.
///         pass
///
/// def _formatwarnmsg_impl(msg):
///     category = msg.category.__name__
///     s =  f"{msg.filename}:{msg.lineno}: {category}: {msg.message}\n"
///
///     if msg.line is None:
///         try:
///             import linecache
///             line = linecache.getline(msg.filename, msg.lineno)
///         except Exception:
///             # When a warning is logged during Python shutdown, linecache
///             # and the import machinery don't work anymore
///             line = None
///             linecache = None
///     else:
///         line = msg.line
///     if line:
///         line = line.strip()
///         s += "  %s\n" % line
///
///     if msg.source is not None:
///         try:
///             import tracemalloc
///         # Logging a warning should not raise a new exception:
///         # catch Exception, not only ImportError and RecursionError.
///         except Exception:
///             # don't suggest to enable tracemalloc if it's not available
///             tracing = True
///             tb = None
///         else:
///             tracing = tracemalloc.is_tracing()
///             try:
///                 tb = tracemalloc.get_object_traceback(msg.source)
///             except Exception:
///                 # When a warning is logged during Python shutdown, tracemalloc
///                 # and the import machinery don't work anymore
///                 tb = None
///
///         if tb is not None:
///             s += 'Object allocated at (most recent call last):\n'
///             for frame in tb:
///                 s += ('  File "%s", lineno %s\n'
///                       % (frame.filename, frame.lineno))
///
///                 try:
///                     if linecache is not None:
///                         line = linecache.getline(frame.filename, frame.lineno)
///                     else:
///                         line = None
///                 except Exception:
///                     line = None
///                 if line:
///                     line = line.strip()
///                     s += '    %s\n' % line
///         elif not tracing:
///             s += (f'{category}: Enable tracemalloc to get the object '
///                   f'allocation traceback\n')
///     return s
///
/// # Keep a reference to check if the function was replaced
/// _showwarning_orig = showwarning
///
/// def _showwarnmsg(msg):
///     """Hook to write a warning to a file; replace if you like."""
///     try:
///         sw = showwarning
///     except NameError:
///         pass
///     else:
///         if sw is not _showwarning_orig:
///             # warnings.showwarning() was replaced
///             if not callable(sw):
///                 raise TypeError("warnings.showwarning() must be set to a "
///                                 "function or method")
///
///             sw(msg.message, msg.category, msg.filename, msg.lineno,
///                msg.file, msg.line)
///             return
///     _showwarnmsg_impl(msg)
///
/// # Keep a reference to check if the function was replaced
/// _formatwarning_orig = formatwarning
///
/// def _formatwarnmsg(msg):
///     """Function to format a warning the standard way."""
///     try:
///         fw = formatwarning
///     except NameError:
///         pass
///     else:
///         if fw is not _formatwarning_orig:
///             # warnings.formatwarning() was replaced
///             return fw(msg.message, msg.category,
///                       msg.filename, msg.lineno, msg.line)
///     return _formatwarnmsg_impl(msg)
///
/// def filterwarnings(action, message="", category=Warning, module="", lineno=0,
///                    append=False):
///     """Insert an entry into the list of warnings filters (at the front).
///
///     'action' -- one of "error", "ignore", "always", "default", "module",
///                 or "once"
///     'message' -- a regex that the warning message must match
///     'category' -- a class that the warning must be a subclass of
///     'module' -- a regex that the module name must match
///     'lineno' -- an integer line number, 0 matches all warnings
///     'append' -- if true, append to the list of filters
///     """
///     assert action in ("error", "ignore", "always", "default", "module",
///                       "once"), "invalid action: %r" % (action,)
///     assert isinstance(message, str), "message must be a string"
///     assert isinstance(category, type), "category must be a class"
///     assert issubclass(category, Warning), "category must be a Warning subclass"
///     assert isinstance(module, str), "module must be a string"
///     assert isinstance(lineno, int) and lineno >= 0, \
///            "lineno must be an int >= 0"
///
///     if message or module:
///         import re
///
///     if message:
///         message = re.compile(message, re.I)
///     else:
///         message = None
///     if module:
///         module = re.compile(module)
///     else:
///         module = None
///
///     _add_filter(action, message, category, module, lineno, append=append)
///
/// def simplefilter(action, category=Warning, lineno=0, append=False):
///     """Insert a simple entry into the list of warnings filters (at the front).
///
///     A simple filter matches all modules and messages.
///     'action' -- one of "error", "ignore", "always", "default", "module",
///                 or "once"
///     'category' -- a class that the warning must be a subclass of
///     'lineno' -- an integer line number, 0 matches all warnings
///     'append' -- if true, append to the list of filters
///     """
///     assert action in ("error", "ignore", "always", "default", "module",
///                       "once"), "invalid action: %r" % (action,)
///     assert isinstance(lineno, int) and lineno >= 0, \
///            "lineno must be an int >= 0"
///     _add_filter(action, None, category, None, lineno, append=append)
///
/// def _add_filter(*item, append):
///     # Remove possible duplicate filters, so new one will be placed
///     # in correct place. If append=True and duplicate exists, do nothing.
///     if not append:
///         try:
///             filters.remove(item)
///         except ValueError:
///             pass
///         filters.insert(0, item)
///     else:
///         if item not in filters:
///             filters.append(item)
///     _filters_mutated()
///
/// def resetwarnings():
///     """Clear the list of warning filters, so that no filters are active."""
///     filters[:] = []
///     _filters_mutated()
///
/// class _OptionError(Exception):
///     """Exception used by option processing helpers."""
///     pass
///
/// # Helper to process -W options passed via sys.warnoptions
/// def _processoptions(args):
///     for arg in args:
///         try:
///             _setoption(arg)
///         except _OptionError as msg:
///             print("Invalid -W option ignored:", msg, file=sys.stderr)
///
/// # Helper for _processoptions()
/// def _setoption(arg):
///     parts = arg.split(':')
///     if len(parts) > 5:
///         raise _OptionError("too many fields (max 5): %r" % (arg,))
///     while len(parts) < 5:
///         parts.append('')
///     action, message, category, module, lineno = [s.strip()
///                                                  for s in parts]
///     action = _getaction(action)
///     category = _getcategory(category)
///     if message or module:
///         import re
///     if message:
///         message = re.escape(message)
///     if module:
///         module = re.escape(module) + r'\Z'
///     if lineno:
///         try:
///             lineno = int(lineno)
///             if lineno < 0:
///                 raise ValueError
///         except (ValueError, OverflowError):
///             raise _OptionError("invalid lineno %r" % (lineno,)) from None
///     else:
///         lineno = 0
///     filterwarnings(action, message, category, module, lineno)
///
/// # Helper for _setoption()
/// def _getaction(action):
///     if not action:
///         return "default"
///     if action == "all": return "always" # Alias
///     for a in ('default', 'always', 'ignore', 'module', 'once', 'error'):
///         if a.startswith(action):
///             return a
///     raise _OptionError("invalid action: %r" % (action,))
///
/// # Helper for _setoption()
/// def _getcategory(category):
///     if not category:
///         return Warning
///     if '.' not in category:
///         import builtins as m
///         klass = category
///     else:
///         module, _, klass = category.rpartition('.')
///         try:
///             m = __import__(module, None, None, [klass])
///         except ImportError:
///             raise _OptionError("invalid module name: %r" % (module,)) from None
///     try:
///         cat = getattr(m, klass)
///     except AttributeError:
///         raise _OptionError("unknown warning category: %r" % (category,)) from None
///     if not issubclass(cat, Warning):
///         raise _OptionError("invalid warning category: %r" % (category,))
///     return cat
///
///
/// def _is_internal_frame(frame):
///     """Signal whether the frame is an internal CPython implementation detail."""
///     filename = frame.f_code.co_filename
///     return 'importlib' in filename and '_bootstrap' in filename
///
///
/// def _next_external_frame(frame):
///     """Find the next frame that doesn't involve CPython internals."""
///     frame = frame.f_back
///     while frame is not None and _is_internal_frame(frame):
///         frame = frame.f_back
///     return frame
///
///
/// # Code typically replaced by _warnings
/// def warn(message, category=None, stacklevel=1, source=None):
///     """Issue a warning, or maybe ignore it or raise an exception."""
///     # Check if message is already a Warning object
///     if isinstance(message, Warning):
///         category = message.__class__
///     # Check category argument
///     if category is None:
///         category = UserWarning
///     if not (isinstance(category, type) and issubclass(category, Warning)):
///         raise TypeError("category must be a Warning subclass, "
///                         "not '{:s}'".format(type(category).__name__))
///     # Get context information
///     try:
///         if stacklevel <= 1 or _is_internal_frame(sys._getframe(1)):
///             # If frame is too small to care or if the warning originated in
///             # internal code, then do not try to hide any frames.
///             frame = sys._getframe(stacklevel)
///         else:
///             frame = sys._getframe(1)
///             # Look for one frame less since the above line starts us off.
///             for x in range(stacklevel-1):
///                 frame = _next_external_frame(frame)
///                 if frame is None:
///                     raise ValueError
///     except ValueError:
///         globals = sys.__dict__
///         filename = "sys"
///         lineno = 1
///     else:
///         globals = frame.f_globals
///         filename = frame.f_code.co_filename
///         lineno = frame.f_lineno
///     if '__name__' in globals:
///         module = globals['__name__']
///     else:
///         module = "<string>"
///     registry = globals.setdefault("__warningregistry__", {})
///     warn_explicit(message, category, filename, lineno, module, registry,
///                   globals, source)
///
/// def warn_explicit(message, category, filename, lineno,
///                   module=None, registry=None, module_globals=None,
///                   source=None):
///     lineno = int(lineno)
///     if module is None:
///         module = filename or "<unknown>"
///         if module[-3:].lower() == ".py":
///             module = module[:-3] # XXX What about leading pathname?
///     if registry is None:
///         registry = {}
///     if registry.get('version', 0) != _filters_version:
///         registry.clear()
///         registry['version'] = _filters_version
///     if isinstance(message, Warning):
///         text = str(message)
///         category = message.__class__
///     else:
///         text = message
///         message = category(message)
///     key = (text, category, lineno)
///     # Quick test for common case
///     if registry.get(key):
///         return
///     # Search the filters
///     for item in filters:
///         action, msg, cat, mod, ln = item
///         if ((msg is None or msg.match(text)) and
///             issubclass(category, cat) and
///             (mod is None or mod.match(module)) and
///             (ln == 0 or lineno == ln)):
///             break
///     else:
///         action = defaultaction
///     # Early exit actions
///     if action == "ignore":
///         return
///
///     # Prime the linecache for formatting, in case the
///     # "file" is actually in a zipfile or something.
///     import linecache
///     linecache.getlines(filename, module_globals)
///
///     if action == "error":
///         raise message
///     # Other actions
///     if action == "once":
///         registry[key] = 1
///         oncekey = (text, category)
///         if onceregistry.get(oncekey):
///             return
///         onceregistry[oncekey] = 1
///     elif action == "always":
///         pass
///     elif action == "module":
///         registry[key] = 1
///         altkey = (text, category, 0)
///         if registry.get(altkey):
///             return
///         registry[altkey] = 1
///     elif action == "default":
///         registry[key] = 1
///     else:
///         # Unrecognized actions are errors
///         raise RuntimeError(
///               "Unrecognized action (%r) in warnings.filters:\n %s" %
///               (action, item))
///     # Print message and context
///     msg = WarningMessage(message, category, filename, lineno, source)
///     _showwarnmsg(msg)
///
///
/// class WarningMessage(object):
///
///     _WARNING_DETAILS = ("message", "category", "filename", "lineno", "file",
///                         "line", "source")
///
///     def __init__(self, message, category, filename, lineno, file=None,
///                  line=None, source=None):
///         self.message = message
///         self.category = category
///         self.filename = filename
///         self.lineno = lineno
///         self.file = file
///         self.line = line
///         self.source = source
///         self._category_name = category.__name__ if category else None
///
///     def __str__(self):
///         return ("{message : %r, category : %r, filename : %r, lineno : %s, "
///                     "line : %r}" % (self.message, self._category_name,
///                                     self.filename, self.lineno, self.line))
///
///
/// class catch_warnings(object):
///
///     """A context manager that copies and restores the warnings filter upon
///     exiting the context.
///
///     The 'record' argument specifies whether warnings should be captured by a
///     custom implementation of warnings.showwarning() and be appended to a list
///     returned by the context manager. Otherwise None is returned by the context
///     manager. The objects appended to the list are arguments whose attributes
///     mirror the arguments to showwarning().
///
///     The 'module' argument is to specify an alternative module to the module
///     named 'warnings' and imported under that name. This argument is only useful
///     when testing the warnings module itself.
///
///     If the 'action' argument is not None, the remaining arguments are passed
///     to warnings.simplefilter() as if it were called immediately on entering the
///     context.
///     """
///
///     def __init__(self, *, record=False, module=None,
///                  action=None, category=Warning, lineno=0, append=False):
///         """Specify whether to record warnings and if an alternative module
///         should be used other than sys.modules['warnings'].
///
///         For compatibility with Python 3.0, please consider all arguments to be
///         keyword-only.
///
///         """
///         self._record = record
///         self._module = sys.modules['warnings'] if module is None else module
///         self._entered = False
///         if action is None:
///             self._filter = None
///         else:
///             self._filter = (action, category, lineno, append)
///
///     def __repr__(self):
///         args = []
///         if self._record:
///             args.append("record=True")
///         if self._module is not sys.modules['warnings']:
///             args.append("module=%r" % self._module)
///         name = type(self).__name__
///         return "%s(%s)" % (name, ", ".join(args))
///
///     def __enter__(self):
///         if self._entered:
///             raise RuntimeError("Cannot enter %r twice" % self)
///         self._entered = True
///         self._filters = self._module.filters
///         self._module.filters = self._filters[:]
///         self._module._filters_mutated()
///         self._showwarning = self._module.showwarning
///         self._showwarnmsg_impl = self._module._showwarnmsg_impl
///         if self._filter is not None:
///             simplefilter(*self._filter)
///         if self._record:
///             log = []
///             self._module._showwarnmsg_impl = log.append
///             # Reset showwarning() to the default implementation to make sure
///             # that _showwarnmsg() calls _showwarnmsg_impl()
///             self._module.showwarning = self._module._showwarning_orig
///             return log
///         else:
///             return None
///
///     def __exit__(self, *exc_info):
///         if not self._entered:
///             raise RuntimeError("Cannot exit %r without entering first" % self)
///         self._module.filters = self._filters
///         self._module._filters_mutated()
///         self._module.showwarning = self._showwarning
///         self._module._showwarnmsg_impl = self._showwarnmsg_impl
///
///
/// _DEPRECATED_MSG = "{name!r} is deprecated and slated for removal in Python {remove}"
///
/// def _deprecated(name, message=_DEPRECATED_MSG, *, remove, _version=sys.version_info):
///     """Warn that *name* is deprecated or should be removed.
///
///     RuntimeError is raised if *remove* specifies a major/minor tuple older than
///     the current Python version or the same version but past the alpha.
///
///     The *message* argument is formatted with *name* and *remove* as a Python
///     version (e.g. "3.11").
///
///     """
///     remove_formatted = f"{remove[0]}.{remove[1]}"
///     if (_version[:2] > remove) or (_version[:2] == remove and _version[3] != "alpha"):
///         msg = f"{name!r} was slated for removal after Python {remove_formatted} alpha"
///         raise RuntimeError(msg)
///     else:
///         msg = message.format(name=name, remove=remove_formatted)
///         warn(msg, DeprecationWarning, stacklevel=3)
///
///
/// # Private utility function called by _PyErr_WarnUnawaitedCoroutine
/// def _warn_unawaited_coroutine(coro):
///     msg_lines = [
///         f"coroutine '{coro.__qualname__}' was never awaited\n"
///     ]
///     if coro.cr_origin is not None:
///         import linecache, traceback
///         def extract():
///             for filename, lineno, funcname in reversed(coro.cr_origin):
///                 line = linecache.getline(filename, lineno)
///                 yield (filename, lineno, funcname, line)
///         msg_lines.append("Coroutine created at (most recent call last)\n")
///         msg_lines += traceback.format_list(list(extract()))
///     msg = "".join(msg_lines).rstrip("\n")
///     # Passing source= here means that if the user happens to have tracemalloc
///     # enabled and tracking where the coroutine was created, the warning will
///     # contain that traceback. This does mean that if they have *both*
///     # coroutine origin tracking *and* tracemalloc enabled, they'll get two
///     # partially-redundant tracebacks. If we wanted to be clever we could
///     # probably detect this case and avoid it, but for now we don't bother.
///     warn(msg, category=RuntimeWarning, stacklevel=2, source=coro)
///
///
/// # filters contains a sequence of filter 5-tuples
/// # The components of the 5-tuple are:
/// # - an action: error, ignore, always, default, module, or once
/// # - a compiled regex that must match the warning message
/// # - a class representing the warning category
/// # - a compiled regex that must match the module that is being warned
/// # - a line number for the line being warning, or 0 to mean any line
/// # If either if the compiled regexs are None, match anything.
/// try:
///     from _warnings import (filters, _defaultaction, _onceregistry,
///                            warn, warn_explicit, _filters_mutated)
///     defaultaction = _defaultaction
///     onceregistry = _onceregistry
///     _warnings_defaults = True
/// except ImportError:
///     filters = []
///     defaultaction = "default"
///     onceregistry = {}
///
///     _filters_version = 1
///
///     def _filters_mutated():
///         global _filters_version
///         _filters_version += 1
///
///     _warnings_defaults = False
///
///
/// # Module initialization
/// _processoptions(sys.warnoptions)
/// if not _warnings_defaults:
///     # Several warning categories are ignored by default in regular builds
///     if not hasattr(sys, 'gettotalrefcount'):
///         filterwarnings("default", category=DeprecationWarning,
///                        module="__main__", append=1)
///         simplefilter("ignore", category=DeprecationWarning, append=1)
///         simplefilter("ignore", category=PendingDeprecationWarning, append=1)
///         simplefilter("ignore", category=ImportWarning, append=1)
///         simplefilter("ignore", category=ResourceWarning, append=1)
///
/// del _warnings_defaults
/// ```
final class warnings extends PythonModule {
  warnings.from(super.pythonModule) : super.from();

  static warnings import() => PythonFfiDart.instance.importModule(
        "warnings",
        warnings.from,
      );

  /// ## filterwarnings
  ///
  /// ### python docstring
  ///
  /// Insert an entry into the list of warnings filters (at the front).
  ///
  /// 'action' -- one of "error", "ignore", "always", "default", "module",
  ///             or "once"
  /// 'message' -- a regex that the warning message must match
  /// 'category' -- a class that the warning must be a subclass of
  /// 'module' -- a regex that the module name must match
  /// 'lineno' -- an integer line number, 0 matches all warnings
  /// 'append' -- if true, append to the list of filters
  ///
  /// ### python source
  /// ```py
  /// def filterwarnings(action, message="", category=Warning, module="", lineno=0,
  ///                    append=False):
  ///     """Insert an entry into the list of warnings filters (at the front).
  ///
  ///     'action' -- one of "error", "ignore", "always", "default", "module",
  ///                 or "once"
  ///     'message' -- a regex that the warning message must match
  ///     'category' -- a class that the warning must be a subclass of
  ///     'module' -- a regex that the module name must match
  ///     'lineno' -- an integer line number, 0 matches all warnings
  ///     'append' -- if true, append to the list of filters
  ///     """
  ///     assert action in ("error", "ignore", "always", "default", "module",
  ///                       "once"), "invalid action: %r" % (action,)
  ///     assert isinstance(message, str), "message must be a string"
  ///     assert isinstance(category, type), "category must be a class"
  ///     assert issubclass(category, Warning), "category must be a Warning subclass"
  ///     assert isinstance(module, str), "module must be a string"
  ///     assert isinstance(lineno, int) and lineno >= 0, \
  ///            "lineno must be an int >= 0"
  ///
  ///     if message or module:
  ///         import re
  ///
  ///     if message:
  ///         message = re.compile(message, re.I)
  ///     else:
  ///         message = None
  ///     if module:
  ///         module = re.compile(module)
  ///     else:
  ///         module = None
  ///
  ///     _add_filter(action, message, category, module, lineno, append=append)
  /// ```
  Object? filterwarnings({
    required Object? action,
    Object? message = "",
    Object? category,
    Object? module = "",
    Object? lineno = 0,
    Object? append = false,
  }) =>
      getFunction("filterwarnings").call(
        <Object?>[
          action,
          message,
          category,
          module,
          lineno,
          append,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## formatwarning
  ///
  /// ### python docstring
  ///
  /// Function to format a warning the standard way.
  ///
  /// ### python source
  /// ```py
  /// def formatwarning(message, category, filename, lineno, line=None):
  ///     """Function to format a warning the standard way."""
  ///     msg = WarningMessage(message, category, filename, lineno, None, line)
  ///     return _formatwarnmsg_impl(msg)
  /// ```
  Object? formatwarning({
    required Object? message,
    required Object? category,
    required Object? filename,
    required Object? lineno,
    Object? line,
  }) =>
      getFunction("formatwarning").call(
        <Object?>[
          message,
          category,
          filename,
          lineno,
          line,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## resetwarnings
  ///
  /// ### python docstring
  ///
  /// Clear the list of warning filters, so that no filters are active.
  ///
  /// ### python source
  /// ```py
  /// def resetwarnings():
  ///     """Clear the list of warning filters, so that no filters are active."""
  ///     filters[:] = []
  ///     _filters_mutated()
  /// ```
  Object? resetwarnings() => getFunction("resetwarnings").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## showwarning
  ///
  /// ### python docstring
  ///
  /// Hook to write a warning to a file; replace if you like.
  ///
  /// ### python source
  /// ```py
  /// def showwarning(message, category, filename, lineno, file=None, line=None):
  ///     """Hook to write a warning to a file; replace if you like."""
  ///     msg = WarningMessage(message, category, filename, lineno, file, line)
  ///     _showwarnmsg_impl(msg)
  /// ```
  Object? showwarning({
    required Object? message,
    required Object? category,
    required Object? filename,
    required Object? lineno,
    Object? file,
    Object? line,
  }) =>
      getFunction("showwarning").call(
        <Object?>[
          message,
          category,
          filename,
          lineno,
          file,
          line,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## simplefilter
  ///
  /// ### python docstring
  ///
  /// Insert a simple entry into the list of warnings filters (at the front).
  ///
  /// A simple filter matches all modules and messages.
  /// 'action' -- one of "error", "ignore", "always", "default", "module",
  ///             or "once"
  /// 'category' -- a class that the warning must be a subclass of
  /// 'lineno' -- an integer line number, 0 matches all warnings
  /// 'append' -- if true, append to the list of filters
  ///
  /// ### python source
  /// ```py
  /// def simplefilter(action, category=Warning, lineno=0, append=False):
  ///     """Insert a simple entry into the list of warnings filters (at the front).
  ///
  ///     A simple filter matches all modules and messages.
  ///     'action' -- one of "error", "ignore", "always", "default", "module",
  ///                 or "once"
  ///     'category' -- a class that the warning must be a subclass of
  ///     'lineno' -- an integer line number, 0 matches all warnings
  ///     'append' -- if true, append to the list of filters
  ///     """
  ///     assert action in ("error", "ignore", "always", "default", "module",
  ///                       "once"), "invalid action: %r" % (action,)
  ///     assert isinstance(lineno, int) and lineno >= 0, \
  ///            "lineno must be an int >= 0"
  ///     _add_filter(action, None, category, None, lineno, append=append)
  /// ```
  Object? simplefilter({
    required Object? action,
    Object? category,
    Object? lineno = 0,
    Object? append = false,
  }) =>
      getFunction("simplefilter").call(
        <Object?>[
          action,
          category,
          lineno,
          append,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## defaultaction (getter)
  Object? get defaultaction => getAttribute("defaultaction");

  /// ## defaultaction (setter)
  set defaultaction(Object? defaultaction) =>
      setAttribute("defaultaction", defaultaction);

  /// ## filters (getter)
  Object? get filters => getAttribute("filters");

  /// ## filters (setter)
  set filters(Object? filters) => setAttribute("filters", filters);

  /// ## onceregistry (getter)
  Object? get onceregistry => getAttribute("onceregistry");

  /// ## onceregistry (setter)
  set onceregistry(Object? onceregistry) =>
      setAttribute("onceregistry", onceregistry);
}

/// ## pickle
///
/// ### python docstring
///
/// Create portable serialized representations of Python objects.
///
/// See module copyreg for a mechanism for registering custom picklers.
/// See module pickletools source for extensive comments.
///
/// Classes:
///
///     Pickler
///     Unpickler
///
/// Functions:
///
///     dump(object, file)
///     dumps(object) -> string
///     load(file) -> object
///     loads(bytes) -> object
///
/// Misc variables:
///
///     __version__
///     format_version
///     compatible_formats
///
/// ### python source
/// ```py
/// """Create portable serialized representations of Python objects.
///
/// See module copyreg for a mechanism for registering custom picklers.
/// See module pickletools source for extensive comments.
///
/// Classes:
///
///     Pickler
///     Unpickler
///
/// Functions:
///
///     dump(object, file)
///     dumps(object) -> string
///     load(file) -> object
///     loads(bytes) -> object
///
/// Misc variables:
///
///     __version__
///     format_version
///     compatible_formats
///
/// """
///
/// from types import FunctionType
/// from copyreg import dispatch_table
/// from copyreg import _extension_registry, _inverted_registry, _extension_cache
/// from itertools import islice
/// from functools import partial
/// import sys
/// from sys import maxsize
/// from struct import pack, unpack
/// import re
/// import io
/// import codecs
/// import _compat_pickle
///
/// __all__ = ["PickleError", "PicklingError", "UnpicklingError", "Pickler",
///            "Unpickler", "dump", "dumps", "load", "loads"]
///
/// try:
///     from _pickle import PickleBuffer
///     __all__.append("PickleBuffer")
///     _HAVE_PICKLE_BUFFER = True
/// except ImportError:
///     _HAVE_PICKLE_BUFFER = False
///
///
/// # Shortcut for use in isinstance testing
/// bytes_types = (bytes, bytearray)
///
/// # These are purely informational; no code uses these.
/// format_version = "4.0"                  # File format version we write
/// compatible_formats = ["1.0",            # Original protocol 0
///                       "1.1",            # Protocol 0 with INST added
///                       "1.2",            # Original protocol 1
///                       "1.3",            # Protocol 1 with BINFLOAT added
///                       "2.0",            # Protocol 2
///                       "3.0",            # Protocol 3
///                       "4.0",            # Protocol 4
///                       "5.0",            # Protocol 5
///                       ]                 # Old format versions we can read
///
/// # This is the highest protocol number we know how to read.
/// HIGHEST_PROTOCOL = 5
///
/// # The protocol we write by default.  May be less than HIGHEST_PROTOCOL.
/// # Only bump this if the oldest still supported version of Python already
/// # includes it.
/// DEFAULT_PROTOCOL = 4
///
/// class PickleError(Exception):
///     """A common base class for the other pickling exceptions."""
///     pass
///
/// class PicklingError(PickleError):
///     """This exception is raised when an unpicklable object is passed to the
///     dump() method.
///
///     """
///     pass
///
/// class UnpicklingError(PickleError):
///     """This exception is raised when there is a problem unpickling an object,
///     such as a security violation.
///
///     Note that other exceptions may also be raised during unpickling, including
///     (but not necessarily limited to) AttributeError, EOFError, ImportError,
///     and IndexError.
///
///     """
///     pass
///
/// # An instance of _Stop is raised by Unpickler.load_stop() in response to
/// # the STOP opcode, passing the object that is the result of unpickling.
/// class _Stop(Exception):
///     def __init__(self, value):
///         self.value = value
///
/// # Jython has PyStringMap; it's a dict subclass with string keys
/// try:
///     from org.python.core import PyStringMap
/// except ImportError:
///     PyStringMap = None
///
/// # Pickle opcodes.  See pickletools.py for extensive docs.  The listing
/// # here is in kind-of alphabetical order of 1-character pickle code.
/// # pickletools groups them by purpose.
///
/// MARK           = b'('   # push special markobject on stack
/// STOP           = b'.'   # every pickle ends with STOP
/// POP            = b'0'   # discard topmost stack item
/// POP_MARK       = b'1'   # discard stack top through topmost markobject
/// DUP            = b'2'   # duplicate top stack item
/// FLOAT          = b'F'   # push float object; decimal string argument
/// INT            = b'I'   # push integer or bool; decimal string argument
/// BININT         = b'J'   # push four-byte signed int
/// BININT1        = b'K'   # push 1-byte unsigned int
/// LONG           = b'L'   # push long; decimal string argument
/// BININT2        = b'M'   # push 2-byte unsigned int
/// NONE           = b'N'   # push None
/// PERSID         = b'P'   # push persistent object; id is taken from string arg
/// BINPERSID      = b'Q'   #  "       "         "  ;  "  "   "     "  stack
/// REDUCE         = b'R'   # apply callable to argtuple, both on stack
/// STRING         = b'S'   # push string; NL-terminated string argument
/// BINSTRING      = b'T'   # push string; counted binary string argument
/// SHORT_BINSTRING= b'U'   #  "     "   ;    "      "       "      " < 256 bytes
/// UNICODE        = b'V'   # push Unicode string; raw-unicode-escaped'd argument
/// BINUNICODE     = b'X'   #   "     "       "  ; counted UTF-8 string argument
/// APPEND         = b'a'   # append stack top to list below it
/// BUILD          = b'b'   # call __setstate__ or __dict__.update()
/// GLOBAL         = b'c'   # push self.find_class(modname, name); 2 string args
/// DICT           = b'd'   # build a dict from stack items
/// EMPTY_DICT     = b'}'   # push empty dict
/// APPENDS        = b'e'   # extend list on stack by topmost stack slice
/// GET            = b'g'   # push item from memo on stack; index is string arg
/// BINGET         = b'h'   #   "    "    "    "   "   "  ;   "    " 1-byte arg
/// INST           = b'i'   # build & push class instance
/// LONG_BINGET    = b'j'   # push item from memo on stack; index is 4-byte arg
/// LIST           = b'l'   # build list from topmost stack items
/// EMPTY_LIST     = b']'   # push empty list
/// OBJ            = b'o'   # build & push class instance
/// PUT            = b'p'   # store stack top in memo; index is string arg
/// BINPUT         = b'q'   #   "     "    "   "   " ;   "    " 1-byte arg
/// LONG_BINPUT    = b'r'   #   "     "    "   "   " ;   "    " 4-byte arg
/// SETITEM        = b's'   # add key+value pair to dict
/// TUPLE          = b't'   # build tuple from topmost stack items
/// EMPTY_TUPLE    = b')'   # push empty tuple
/// SETITEMS       = b'u'   # modify dict by adding topmost key+value pairs
/// BINFLOAT       = b'G'   # push float; arg is 8-byte float encoding
///
/// TRUE           = b'I01\n'  # not an opcode; see INT docs in pickletools.py
/// FALSE          = b'I00\n'  # not an opcode; see INT docs in pickletools.py
///
/// # Protocol 2
///
/// PROTO          = b'\x80'  # identify pickle protocol
/// NEWOBJ         = b'\x81'  # build object by applying cls.__new__ to argtuple
/// EXT1           = b'\x82'  # push object from extension registry; 1-byte index
/// EXT2           = b'\x83'  # ditto, but 2-byte index
/// EXT4           = b'\x84'  # ditto, but 4-byte index
/// TUPLE1         = b'\x85'  # build 1-tuple from stack top
/// TUPLE2         = b'\x86'  # build 2-tuple from two topmost stack items
/// TUPLE3         = b'\x87'  # build 3-tuple from three topmost stack items
/// NEWTRUE        = b'\x88'  # push True
/// NEWFALSE       = b'\x89'  # push False
/// LONG1          = b'\x8a'  # push long from < 256 bytes
/// LONG4          = b'\x8b'  # push really big long
///
/// _tuplesize2code = [EMPTY_TUPLE, TUPLE1, TUPLE2, TUPLE3]
///
/// # Protocol 3 (Python 3.x)
///
/// BINBYTES       = b'B'   # push bytes; counted binary string argument
/// SHORT_BINBYTES = b'C'   #  "     "   ;    "      "       "      " < 256 bytes
///
/// # Protocol 4
///
/// SHORT_BINUNICODE = b'\x8c'  # push short string; UTF-8 length < 256 bytes
/// BINUNICODE8      = b'\x8d'  # push very long string
/// BINBYTES8        = b'\x8e'  # push very long bytes string
/// EMPTY_SET        = b'\x8f'  # push empty set on the stack
/// ADDITEMS         = b'\x90'  # modify set by adding topmost stack items
/// FROZENSET        = b'\x91'  # build frozenset from topmost stack items
/// NEWOBJ_EX        = b'\x92'  # like NEWOBJ but work with keyword only arguments
/// STACK_GLOBAL     = b'\x93'  # same as GLOBAL but using names on the stacks
/// MEMOIZE          = b'\x94'  # store top of the stack in memo
/// FRAME            = b'\x95'  # indicate the beginning of a new frame
///
/// # Protocol 5
///
/// BYTEARRAY8       = b'\x96'  # push bytearray
/// NEXT_BUFFER      = b'\x97'  # push next out-of-band buffer
/// READONLY_BUFFER  = b'\x98'  # make top of stack readonly
///
/// __all__.extend([x for x in dir() if re.match("[A-Z][A-Z0-9_]+$", x)])
///
///
/// class _Framer:
///
///     _FRAME_SIZE_MIN = 4
///     _FRAME_SIZE_TARGET = 64 * 1024
///
///     def __init__(self, file_write):
///         self.file_write = file_write
///         self.current_frame = None
///
///     def start_framing(self):
///         self.current_frame = io.BytesIO()
///
///     def end_framing(self):
///         if self.current_frame and self.current_frame.tell() > 0:
///             self.commit_frame(force=True)
///             self.current_frame = None
///
///     def commit_frame(self, force=False):
///         if self.current_frame:
///             f = self.current_frame
///             if f.tell() >= self._FRAME_SIZE_TARGET or force:
///                 data = f.getbuffer()
///                 write = self.file_write
///                 if len(data) >= self._FRAME_SIZE_MIN:
///                     # Issue a single call to the write method of the underlying
///                     # file object for the frame opcode with the size of the
///                     # frame. The concatenation is expected to be less expensive
///                     # than issuing an additional call to write.
///                     write(FRAME + pack("<Q", len(data)))
///
///                 # Issue a separate call to write to append the frame
///                 # contents without concatenation to the above to avoid a
///                 # memory copy.
///                 write(data)
///
///                 # Start the new frame with a new io.BytesIO instance so that
///                 # the file object can have delayed access to the previous frame
///                 # contents via an unreleased memoryview of the previous
///                 # io.BytesIO instance.
///                 self.current_frame = io.BytesIO()
///
///     def write(self, data):
///         if self.current_frame:
///             return self.current_frame.write(data)
///         else:
///             return self.file_write(data)
///
///     def write_large_bytes(self, header, payload):
///         write = self.file_write
///         if self.current_frame:
///             # Terminate the current frame and flush it to the file.
///             self.commit_frame(force=True)
///
///         # Perform direct write of the header and payload of the large binary
///         # object. Be careful not to concatenate the header and the payload
///         # prior to calling 'write' as we do not want to allocate a large
///         # temporary bytes object.
///         # We intentionally do not insert a protocol 4 frame opcode to make
///         # it possible to optimize file.read calls in the loader.
///         write(header)
///         write(payload)
///
///
/// class _Unframer:
///
///     def __init__(self, file_read, file_readline, file_tell=None):
///         self.file_read = file_read
///         self.file_readline = file_readline
///         self.current_frame = None
///
///     def readinto(self, buf):
///         if self.current_frame:
///             n = self.current_frame.readinto(buf)
///             if n == 0 and len(buf) != 0:
///                 self.current_frame = None
///                 n = len(buf)
///                 buf[:] = self.file_read(n)
///                 return n
///             if n < len(buf):
///                 raise UnpicklingError(
///                     "pickle exhausted before end of frame")
///             return n
///         else:
///             n = len(buf)
///             buf[:] = self.file_read(n)
///             return n
///
///     def read(self, n):
///         if self.current_frame:
///             data = self.current_frame.read(n)
///             if not data and n != 0:
///                 self.current_frame = None
///                 return self.file_read(n)
///             if len(data) < n:
///                 raise UnpicklingError(
///                     "pickle exhausted before end of frame")
///             return data
///         else:
///             return self.file_read(n)
///
///     def readline(self):
///         if self.current_frame:
///             data = self.current_frame.readline()
///             if not data:
///                 self.current_frame = None
///                 return self.file_readline()
///             if data[-1] != b'\n'[0]:
///                 raise UnpicklingError(
///                     "pickle exhausted before end of frame")
///             return data
///         else:
///             return self.file_readline()
///
///     def load_frame(self, frame_size):
///         if self.current_frame and self.current_frame.read() != b'':
///             raise UnpicklingError(
///                 "beginning of a new frame before end of current frame")
///         self.current_frame = io.BytesIO(self.file_read(frame_size))
///
///
/// # Tools used for pickling.
///
/// def _getattribute(obj, name):
///     for subpath in name.split('.'):
///         if subpath == '<locals>':
///             raise AttributeError("Can't get local attribute {!r} on {!r}"
///                                  .format(name, obj))
///         try:
///             parent = obj
///             obj = getattr(obj, subpath)
///         except AttributeError:
///             raise AttributeError("Can't get attribute {!r} on {!r}"
///                                  .format(name, obj)) from None
///     return obj, parent
///
/// def whichmodule(obj, name):
///     """Find the module an object belong to."""
///     module_name = getattr(obj, '__module__', None)
///     if module_name is not None:
///         return module_name
///     # Protect the iteration by using a list copy of sys.modules against dynamic
///     # modules that trigger imports of other modules upon calls to getattr.
///     for module_name, module in sys.modules.copy().items():
///         if (module_name == '__main__'
///             or module_name == '__mp_main__'  # bpo-42406
///             or module is None):
///             continue
///         try:
///             if _getattribute(module, name)[0] is obj:
///                 return module_name
///         except AttributeError:
///             pass
///     return '__main__'
///
/// def encode_long(x):
///     r"""Encode a long to a two's complement little-endian binary string.
///     Note that 0 is a special case, returning an empty string, to save a
///     byte in the LONG1 pickling context.
///
///     >>> encode_long(0)
///     b''
///     >>> encode_long(255)
///     b'\xff\x00'
///     >>> encode_long(32767)
///     b'\xff\x7f'
///     >>> encode_long(-256)
///     b'\x00\xff'
///     >>> encode_long(-32768)
///     b'\x00\x80'
///     >>> encode_long(-128)
///     b'\x80'
///     >>> encode_long(127)
///     b'\x7f'
///     >>>
///     """
///     if x == 0:
///         return b''
///     nbytes = (x.bit_length() >> 3) + 1
///     result = x.to_bytes(nbytes, byteorder='little', signed=True)
///     if x < 0 and nbytes > 1:
///         if result[-1] == 0xff and (result[-2] & 0x80) != 0:
///             result = result[:-1]
///     return result
///
/// def decode_long(data):
///     r"""Decode a long from a two's complement little-endian binary string.
///
///     >>> decode_long(b'')
///     0
///     >>> decode_long(b"\xff\x00")
///     255
///     >>> decode_long(b"\xff\x7f")
///     32767
///     >>> decode_long(b"\x00\xff")
///     -256
///     >>> decode_long(b"\x00\x80")
///     -32768
///     >>> decode_long(b"\x80")
///     -128
///     >>> decode_long(b"\x7f")
///     127
///     """
///     return int.from_bytes(data, byteorder='little', signed=True)
///
///
/// # Pickling machinery
///
/// class _Pickler:
///
///     def __init__(self, file, protocol=None, *, fix_imports=True,
///                  buffer_callback=None):
///         """This takes a binary file for writing a pickle data stream.
///
///         The optional *protocol* argument tells the pickler to use the
///         given protocol; supported protocols are 0, 1, 2, 3, 4 and 5.
///         The default protocol is 4. It was introduced in Python 3.4, and
///         is incompatible with previous versions.
///
///         Specifying a negative protocol version selects the highest
///         protocol version supported.  The higher the protocol used, the
///         more recent the version of Python needed to read the pickle
///         produced.
///
///         The *file* argument must have a write() method that accepts a
///         single bytes argument. It can thus be a file object opened for
///         binary writing, an io.BytesIO instance, or any other custom
///         object that meets this interface.
///
///         If *fix_imports* is True and *protocol* is less than 3, pickle
///         will try to map the new Python 3 names to the old module names
///         used in Python 2, so that the pickle data stream is readable
///         with Python 2.
///
///         If *buffer_callback* is None (the default), buffer views are
///         serialized into *file* as part of the pickle stream.
///
///         If *buffer_callback* is not None, then it can be called any number
///         of times with a buffer view.  If the callback returns a false value
///         (such as None), the given buffer is out-of-band; otherwise the
///         buffer is serialized in-band, i.e. inside the pickle stream.
///
///         It is an error if *buffer_callback* is not None and *protocol*
///         is None or smaller than 5.
///         """
///         if protocol is None:
///             protocol = DEFAULT_PROTOCOL
///         if protocol < 0:
///             protocol = HIGHEST_PROTOCOL
///         elif not 0 <= protocol <= HIGHEST_PROTOCOL:
///             raise ValueError("pickle protocol must be <= %d" % HIGHEST_PROTOCOL)
///         if buffer_callback is not None and protocol < 5:
///             raise ValueError("buffer_callback needs protocol >= 5")
///         self._buffer_callback = buffer_callback
///         try:
///             self._file_write = file.write
///         except AttributeError:
///             raise TypeError("file must have a 'write' attribute")
///         self.framer = _Framer(self._file_write)
///         self.write = self.framer.write
///         self._write_large_bytes = self.framer.write_large_bytes
///         self.memo = {}
///         self.proto = int(protocol)
///         self.bin = protocol >= 1
///         self.fast = 0
///         self.fix_imports = fix_imports and protocol < 3
///
///     def clear_memo(self):
///         """Clears the pickler's "memo".
///
///         The memo is the data structure that remembers which objects the
///         pickler has already seen, so that shared or recursive objects
///         are pickled by reference and not by value.  This method is
///         useful when re-using picklers.
///         """
///         self.memo.clear()
///
///     def dump(self, obj):
///         """Write a pickled representation of obj to the open file."""
///         # Check whether Pickler was initialized correctly. This is
///         # only needed to mimic the behavior of _pickle.Pickler.dump().
///         if not hasattr(self, "_file_write"):
///             raise PicklingError("Pickler.__init__() was not called by "
///                                 "%s.__init__()" % (self.__class__.__name__,))
///         if self.proto >= 2:
///             self.write(PROTO + pack("<B", self.proto))
///         if self.proto >= 4:
///             self.framer.start_framing()
///         self.save(obj)
///         self.write(STOP)
///         self.framer.end_framing()
///
///     def memoize(self, obj):
///         """Store an object in the memo."""
///
///         # The Pickler memo is a dictionary mapping object ids to 2-tuples
///         # that contain the Unpickler memo key and the object being memoized.
///         # The memo key is written to the pickle and will become
///         # the key in the Unpickler's memo.  The object is stored in the
///         # Pickler memo so that transient objects are kept alive during
///         # pickling.
///
///         # The use of the Unpickler memo length as the memo key is just a
///         # convention.  The only requirement is that the memo values be unique.
///         # But there appears no advantage to any other scheme, and this
///         # scheme allows the Unpickler memo to be implemented as a plain (but
///         # growable) array, indexed by memo key.
///         if self.fast:
///             return
///         assert id(obj) not in self.memo
///         idx = len(self.memo)
///         self.write(self.put(idx))
///         self.memo[id(obj)] = idx, obj
///
///     # Return a PUT (BINPUT, LONG_BINPUT) opcode string, with argument i.
///     def put(self, idx):
///         if self.proto >= 4:
///             return MEMOIZE
///         elif self.bin:
///             if idx < 256:
///                 return BINPUT + pack("<B", idx)
///             else:
///                 return LONG_BINPUT + pack("<I", idx)
///         else:
///             return PUT + repr(idx).encode("ascii") + b'\n'
///
///     # Return a GET (BINGET, LONG_BINGET) opcode string, with argument i.
///     def get(self, i):
///         if self.bin:
///             if i < 256:
///                 return BINGET + pack("<B", i)
///             else:
///                 return LONG_BINGET + pack("<I", i)
///
///         return GET + repr(i).encode("ascii") + b'\n'
///
///     def save(self, obj, save_persistent_id=True):
///         self.framer.commit_frame()
///
///         # Check for persistent id (defined by a subclass)
///         pid = self.persistent_id(obj)
///         if pid is not None and save_persistent_id:
///             self.save_pers(pid)
///             return
///
///         # Check the memo
///         x = self.memo.get(id(obj))
///         if x is not None:
///             self.write(self.get(x[0]))
///             return
///
///         rv = NotImplemented
///         reduce = getattr(self, "reducer_override", None)
///         if reduce is not None:
///             rv = reduce(obj)
///
///         if rv is NotImplemented:
///             # Check the type dispatch table
///             t = type(obj)
///             f = self.dispatch.get(t)
///             if f is not None:
///                 f(self, obj)  # Call unbound method with explicit self
///                 return
///
///             # Check private dispatch table if any, or else
///             # copyreg.dispatch_table
///             reduce = getattr(self, 'dispatch_table', dispatch_table).get(t)
///             if reduce is not None:
///                 rv = reduce(obj)
///             else:
///                 # Check for a class with a custom metaclass; treat as regular
///                 # class
///                 if issubclass(t, type):
///                     self.save_global(obj)
///                     return
///
///                 # Check for a __reduce_ex__ method, fall back to __reduce__
///                 reduce = getattr(obj, "__reduce_ex__", None)
///                 if reduce is not None:
///                     rv = reduce(self.proto)
///                 else:
///                     reduce = getattr(obj, "__reduce__", None)
///                     if reduce is not None:
///                         rv = reduce()
///                     else:
///                         raise PicklingError("Can't pickle %r object: %r" %
///                                             (t.__name__, obj))
///
///         # Check for string returned by reduce(), meaning "save as global"
///         if isinstance(rv, str):
///             self.save_global(obj, rv)
///             return
///
///         # Assert that reduce() returned a tuple
///         if not isinstance(rv, tuple):
///             raise PicklingError("%s must return string or tuple" % reduce)
///
///         # Assert that it returned an appropriately sized tuple
///         l = len(rv)
///         if not (2 <= l <= 6):
///             raise PicklingError("Tuple returned by %s must have "
///                                 "two to six elements" % reduce)
///
///         # Save the reduce() output and finally memoize the object
///         self.save_reduce(obj=obj, *rv)
///
///     def persistent_id(self, obj):
///         # This exists so a subclass can override it
///         return None
///
///     def save_pers(self, pid):
///         # Save a persistent id reference
///         if self.bin:
///             self.save(pid, save_persistent_id=False)
///             self.write(BINPERSID)
///         else:
///             try:
///                 self.write(PERSID + str(pid).encode("ascii") + b'\n')
///             except UnicodeEncodeError:
///                 raise PicklingError(
///                     "persistent IDs in protocol 0 must be ASCII strings")
///
///     def save_reduce(self, func, args, state=None, listitems=None,
///                     dictitems=None, state_setter=None, *, obj=None):
///         # This API is called by some subclasses
///
///         if not isinstance(args, tuple):
///             raise PicklingError("args from save_reduce() must be a tuple")
///         if not callable(func):
///             raise PicklingError("func from save_reduce() must be callable")
///
///         save = self.save
///         write = self.write
///
///         func_name = getattr(func, "__name__", "")
///         if self.proto >= 2 and func_name == "__newobj_ex__":
///             cls, args, kwargs = args
///             if not hasattr(cls, "__new__"):
///                 raise PicklingError("args[0] from {} args has no __new__"
///                                     .format(func_name))
///             if obj is not None and cls is not obj.__class__:
///                 raise PicklingError("args[0] from {} args has the wrong class"
///                                     .format(func_name))
///             if self.proto >= 4:
///                 save(cls)
///                 save(args)
///                 save(kwargs)
///                 write(NEWOBJ_EX)
///             else:
///                 func = partial(cls.__new__, cls, *args, **kwargs)
///                 save(func)
///                 save(())
///                 write(REDUCE)
///         elif self.proto >= 2 and func_name == "__newobj__":
///             # A __reduce__ implementation can direct protocol 2 or newer to
///             # use the more efficient NEWOBJ opcode, while still
///             # allowing protocol 0 and 1 to work normally.  For this to
///             # work, the function returned by __reduce__ should be
///             # called __newobj__, and its first argument should be a
///             # class.  The implementation for __newobj__
///             # should be as follows, although pickle has no way to
///             # verify this:
///             #
///             # def __newobj__(cls, *args):
///             #     return cls.__new__(cls, *args)
///             #
///             # Protocols 0 and 1 will pickle a reference to __newobj__,
///             # while protocol 2 (and above) will pickle a reference to
///             # cls, the remaining args tuple, and the NEWOBJ code,
///             # which calls cls.__new__(cls, *args) at unpickling time
///             # (see load_newobj below).  If __reduce__ returns a
///             # three-tuple, the state from the third tuple item will be
///             # pickled regardless of the protocol, calling __setstate__
///             # at unpickling time (see load_build below).
///             #
///             # Note that no standard __newobj__ implementation exists;
///             # you have to provide your own.  This is to enforce
///             # compatibility with Python 2.2 (pickles written using
///             # protocol 0 or 1 in Python 2.3 should be unpicklable by
///             # Python 2.2).
///             cls = args[0]
///             if not hasattr(cls, "__new__"):
///                 raise PicklingError(
///                     "args[0] from __newobj__ args has no __new__")
///             if obj is not None and cls is not obj.__class__:
///                 raise PicklingError(
///                     "args[0] from __newobj__ args has the wrong class")
///             args = args[1:]
///             save(cls)
///             save(args)
///             write(NEWOBJ)
///         else:
///             save(func)
///             save(args)
///             write(REDUCE)
///
///         if obj is not None:
///             # If the object is already in the memo, this means it is
///             # recursive. In this case, throw away everything we put on the
///             # stack, and fetch the object back from the memo.
///             if id(obj) in self.memo:
///                 write(POP + self.get(self.memo[id(obj)][0]))
///             else:
///                 self.memoize(obj)
///
///         # More new special cases (that work with older protocols as
///         # well): when __reduce__ returns a tuple with 4 or 5 items,
///         # the 4th and 5th item should be iterators that provide list
///         # items and dict items (as (key, value) tuples), or None.
///
///         if listitems is not None:
///             self._batch_appends(listitems)
///
///         if dictitems is not None:
///             self._batch_setitems(dictitems)
///
///         if state is not None:
///             if state_setter is None:
///                 save(state)
///                 write(BUILD)
///             else:
///                 # If a state_setter is specified, call it instead of load_build
///                 # to update obj's with its previous state.
///                 # First, push state_setter and its tuple of expected arguments
///                 # (obj, state) onto the stack.
///                 save(state_setter)
///                 save(obj)  # simple BINGET opcode as obj is already memoized.
///                 save(state)
///                 write(TUPLE2)
///                 # Trigger a state_setter(obj, state) function call.
///                 write(REDUCE)
///                 # The purpose of state_setter is to carry-out an
///                 # inplace modification of obj. We do not care about what the
///                 # method might return, so its output is eventually removed from
///                 # the stack.
///                 write(POP)
///
///     # Methods below this point are dispatched through the dispatch table
///
///     dispatch = {}
///
///     def save_none(self, obj):
///         self.write(NONE)
///     dispatch[type(None)] = save_none
///
///     def save_bool(self, obj):
///         if self.proto >= 2:
///             self.write(NEWTRUE if obj else NEWFALSE)
///         else:
///             self.write(TRUE if obj else FALSE)
///     dispatch[bool] = save_bool
///
///     def save_long(self, obj):
///         if self.bin:
///             # If the int is small enough to fit in a signed 4-byte 2's-comp
///             # format, we can store it more efficiently than the general
///             # case.
///             # First one- and two-byte unsigned ints:
///             if obj >= 0:
///                 if obj <= 0xff:
///                     self.write(BININT1 + pack("<B", obj))
///                     return
///                 if obj <= 0xffff:
///                     self.write(BININT2 + pack("<H", obj))
///                     return
///             # Next check for 4-byte signed ints:
///             if -0x80000000 <= obj <= 0x7fffffff:
///                 self.write(BININT + pack("<i", obj))
///                 return
///         if self.proto >= 2:
///             encoded = encode_long(obj)
///             n = len(encoded)
///             if n < 256:
///                 self.write(LONG1 + pack("<B", n) + encoded)
///             else:
///                 self.write(LONG4 + pack("<i", n) + encoded)
///             return
///         if -0x80000000 <= obj <= 0x7fffffff:
///             self.write(INT + repr(obj).encode("ascii") + b'\n')
///         else:
///             self.write(LONG + repr(obj).encode("ascii") + b'L\n')
///     dispatch[int] = save_long
///
///     def save_float(self, obj):
///         if self.bin:
///             self.write(BINFLOAT + pack('>d', obj))
///         else:
///             self.write(FLOAT + repr(obj).encode("ascii") + b'\n')
///     dispatch[float] = save_float
///
///     def save_bytes(self, obj):
///         if self.proto < 3:
///             if not obj: # bytes object is empty
///                 self.save_reduce(bytes, (), obj=obj)
///             else:
///                 self.save_reduce(codecs.encode,
///                                  (str(obj, 'latin1'), 'latin1'), obj=obj)
///             return
///         n = len(obj)
///         if n <= 0xff:
///             self.write(SHORT_BINBYTES + pack("<B", n) + obj)
///         elif n > 0xffffffff and self.proto >= 4:
///             self._write_large_bytes(BINBYTES8 + pack("<Q", n), obj)
///         elif n >= self.framer._FRAME_SIZE_TARGET:
///             self._write_large_bytes(BINBYTES + pack("<I", n), obj)
///         else:
///             self.write(BINBYTES + pack("<I", n) + obj)
///         self.memoize(obj)
///     dispatch[bytes] = save_bytes
///
///     def save_bytearray(self, obj):
///         if self.proto < 5:
///             if not obj:  # bytearray is empty
///                 self.save_reduce(bytearray, (), obj=obj)
///             else:
///                 self.save_reduce(bytearray, (bytes(obj),), obj=obj)
///             return
///         n = len(obj)
///         if n >= self.framer._FRAME_SIZE_TARGET:
///             self._write_large_bytes(BYTEARRAY8 + pack("<Q", n), obj)
///         else:
///             self.write(BYTEARRAY8 + pack("<Q", n) + obj)
///         self.memoize(obj)
///     dispatch[bytearray] = save_bytearray
///
///     if _HAVE_PICKLE_BUFFER:
///         def save_picklebuffer(self, obj):
///             if self.proto < 5:
///                 raise PicklingError("PickleBuffer can only pickled with "
///                                     "protocol >= 5")
///             with obj.raw() as m:
///                 if not m.contiguous:
///                     raise PicklingError("PickleBuffer can not be pickled when "
///                                         "pointing to a non-contiguous buffer")
///                 in_band = True
///                 if self._buffer_callback is not None:
///                     in_band = bool(self._buffer_callback(obj))
///                 if in_band:
///                     # Write data in-band
///                     # XXX The C implementation avoids a copy here
///                     if m.readonly:
///                         self.save_bytes(m.tobytes())
///                     else:
///                         self.save_bytearray(m.tobytes())
///                 else:
///                     # Write data out-of-band
///                     self.write(NEXT_BUFFER)
///                     if m.readonly:
///                         self.write(READONLY_BUFFER)
///
///         dispatch[PickleBuffer] = save_picklebuffer
///
///     def save_str(self, obj):
///         if self.bin:
///             encoded = obj.encode('utf-8', 'surrogatepass')
///             n = len(encoded)
///             if n <= 0xff and self.proto >= 4:
///                 self.write(SHORT_BINUNICODE + pack("<B", n) + encoded)
///             elif n > 0xffffffff and self.proto >= 4:
///                 self._write_large_bytes(BINUNICODE8 + pack("<Q", n), encoded)
///             elif n >= self.framer._FRAME_SIZE_TARGET:
///                 self._write_large_bytes(BINUNICODE + pack("<I", n), encoded)
///             else:
///                 self.write(BINUNICODE + pack("<I", n) + encoded)
///         else:
///             obj = obj.replace("\\", "\\u005c")
///             obj = obj.replace("\0", "\\u0000")
///             obj = obj.replace("\n", "\\u000a")
///             obj = obj.replace("\r", "\\u000d")
///             obj = obj.replace("\x1a", "\\u001a")  # EOF on DOS
///             self.write(UNICODE + obj.encode('raw-unicode-escape') +
///                        b'\n')
///         self.memoize(obj)
///     dispatch[str] = save_str
///
///     def save_tuple(self, obj):
///         if not obj: # tuple is empty
///             if self.bin:
///                 self.write(EMPTY_TUPLE)
///             else:
///                 self.write(MARK + TUPLE)
///             return
///
///         n = len(obj)
///         save = self.save
///         memo = self.memo
///         if n <= 3 and self.proto >= 2:
///             for element in obj:
///                 save(element)
///             # Subtle.  Same as in the big comment below.
///             if id(obj) in memo:
///                 get = self.get(memo[id(obj)][0])
///                 self.write(POP * n + get)
///             else:
///                 self.write(_tuplesize2code[n])
///                 self.memoize(obj)
///             return
///
///         # proto 0 or proto 1 and tuple isn't empty, or proto > 1 and tuple
///         # has more than 3 elements.
///         write = self.write
///         write(MARK)
///         for element in obj:
///             save(element)
///
///         if id(obj) in memo:
///             # Subtle.  d was not in memo when we entered save_tuple(), so
///             # the process of saving the tuple's elements must have saved
///             # the tuple itself:  the tuple is recursive.  The proper action
///             # now is to throw away everything we put on the stack, and
///             # simply GET the tuple (it's already constructed).  This check
///             # could have been done in the "for element" loop instead, but
///             # recursive tuples are a rare thing.
///             get = self.get(memo[id(obj)][0])
///             if self.bin:
///                 write(POP_MARK + get)
///             else:   # proto 0 -- POP_MARK not available
///                 write(POP * (n+1) + get)
///             return
///
///         # No recursion.
///         write(TUPLE)
///         self.memoize(obj)
///
///     dispatch[tuple] = save_tuple
///
///     def save_list(self, obj):
///         if self.bin:
///             self.write(EMPTY_LIST)
///         else:   # proto 0 -- can't use EMPTY_LIST
///             self.write(MARK + LIST)
///
///         self.memoize(obj)
///         self._batch_appends(obj)
///
///     dispatch[list] = save_list
///
///     _BATCHSIZE = 1000
///
///     def _batch_appends(self, items):
///         # Helper to batch up APPENDS sequences
///         save = self.save
///         write = self.write
///
///         if not self.bin:
///             for x in items:
///                 save(x)
///                 write(APPEND)
///             return
///
///         it = iter(items)
///         while True:
///             tmp = list(islice(it, self._BATCHSIZE))
///             n = len(tmp)
///             if n > 1:
///                 write(MARK)
///                 for x in tmp:
///                     save(x)
///                 write(APPENDS)
///             elif n:
///                 save(tmp[0])
///                 write(APPEND)
///             # else tmp is empty, and we're done
///             if n < self._BATCHSIZE:
///                 return
///
///     def save_dict(self, obj):
///         if self.bin:
///             self.write(EMPTY_DICT)
///         else:   # proto 0 -- can't use EMPTY_DICT
///             self.write(MARK + DICT)
///
///         self.memoize(obj)
///         self._batch_setitems(obj.items())
///
///     dispatch[dict] = save_dict
///     if PyStringMap is not None:
///         dispatch[PyStringMap] = save_dict
///
///     def _batch_setitems(self, items):
///         # Helper to batch up SETITEMS sequences; proto >= 1 only
///         save = self.save
///         write = self.write
///
///         if not self.bin:
///             for k, v in items:
///                 save(k)
///                 save(v)
///                 write(SETITEM)
///             return
///
///         it = iter(items)
///         while True:
///             tmp = list(islice(it, self._BATCHSIZE))
///             n = len(tmp)
///             if n > 1:
///                 write(MARK)
///                 for k, v in tmp:
///                     save(k)
///                     save(v)
///                 write(SETITEMS)
///             elif n:
///                 k, v = tmp[0]
///                 save(k)
///                 save(v)
///                 write(SETITEM)
///             # else tmp is empty, and we're done
///             if n < self._BATCHSIZE:
///                 return
///
///     def save_set(self, obj):
///         save = self.save
///         write = self.write
///
///         if self.proto < 4:
///             self.save_reduce(set, (list(obj),), obj=obj)
///             return
///
///         write(EMPTY_SET)
///         self.memoize(obj)
///
///         it = iter(obj)
///         while True:
///             batch = list(islice(it, self._BATCHSIZE))
///             n = len(batch)
///             if n > 0:
///                 write(MARK)
///                 for item in batch:
///                     save(item)
///                 write(ADDITEMS)
///             if n < self._BATCHSIZE:
///                 return
///     dispatch[set] = save_set
///
///     def save_frozenset(self, obj):
///         save = self.save
///         write = self.write
///
///         if self.proto < 4:
///             self.save_reduce(frozenset, (list(obj),), obj=obj)
///             return
///
///         write(MARK)
///         for item in obj:
///             save(item)
///
///         if id(obj) in self.memo:
///             # If the object is already in the memo, this means it is
///             # recursive. In this case, throw away everything we put on the
///             # stack, and fetch the object back from the memo.
///             write(POP_MARK + self.get(self.memo[id(obj)][0]))
///             return
///
///         write(FROZENSET)
///         self.memoize(obj)
///     dispatch[frozenset] = save_frozenset
///
///     def save_global(self, obj, name=None):
///         write = self.write
///         memo = self.memo
///
///         if name is None:
///             name = getattr(obj, '__qualname__', None)
///         if name is None:
///             name = obj.__name__
///
///         module_name = whichmodule(obj, name)
///         try:
///             __import__(module_name, level=0)
///             module = sys.modules[module_name]
///             obj2, parent = _getattribute(module, name)
///         except (ImportError, KeyError, AttributeError):
///             raise PicklingError(
///                 "Can't pickle %r: it's not found as %s.%s" %
///                 (obj, module_name, name)) from None
///         else:
///             if obj2 is not obj:
///                 raise PicklingError(
///                     "Can't pickle %r: it's not the same object as %s.%s" %
///                     (obj, module_name, name))
///
///         if self.proto >= 2:
///             code = _extension_registry.get((module_name, name))
///             if code:
///                 assert code > 0
///                 if code <= 0xff:
///                     write(EXT1 + pack("<B", code))
///                 elif code <= 0xffff:
///                     write(EXT2 + pack("<H", code))
///                 else:
///                     write(EXT4 + pack("<i", code))
///                 return
///         lastname = name.rpartition('.')[2]
///         if parent is module:
///             name = lastname
///         # Non-ASCII identifiers are supported only with protocols >= 3.
///         if self.proto >= 4:
///             self.save(module_name)
///             self.save(name)
///             write(STACK_GLOBAL)
///         elif parent is not module:
///             self.save_reduce(getattr, (parent, lastname))
///         elif self.proto >= 3:
///             write(GLOBAL + bytes(module_name, "utf-8") + b'\n' +
///                   bytes(name, "utf-8") + b'\n')
///         else:
///             if self.fix_imports:
///                 r_name_mapping = _compat_pickle.REVERSE_NAME_MAPPING
///                 r_import_mapping = _compat_pickle.REVERSE_IMPORT_MAPPING
///                 if (module_name, name) in r_name_mapping:
///                     module_name, name = r_name_mapping[(module_name, name)]
///                 elif module_name in r_import_mapping:
///                     module_name = r_import_mapping[module_name]
///             try:
///                 write(GLOBAL + bytes(module_name, "ascii") + b'\n' +
///                       bytes(name, "ascii") + b'\n')
///             except UnicodeEncodeError:
///                 raise PicklingError(
///                     "can't pickle global identifier '%s.%s' using "
///                     "pickle protocol %i" % (module, name, self.proto)) from None
///
///         self.memoize(obj)
///
///     def save_type(self, obj):
///         if obj is type(None):
///             return self.save_reduce(type, (None,), obj=obj)
///         elif obj is type(NotImplemented):
///             return self.save_reduce(type, (NotImplemented,), obj=obj)
///         elif obj is type(...):
///             return self.save_reduce(type, (...,), obj=obj)
///         return self.save_global(obj)
///
///     dispatch[FunctionType] = save_global
///     dispatch[type] = save_type
///
///
/// # Unpickling machinery
///
/// class _Unpickler:
///
///     def __init__(self, file, *, fix_imports=True,
///                  encoding="ASCII", errors="strict", buffers=None):
///         """This takes a binary file for reading a pickle data stream.
///
///         The protocol version of the pickle is detected automatically, so
///         no proto argument is needed.
///
///         The argument *file* must have two methods, a read() method that
///         takes an integer argument, and a readline() method that requires
///         no arguments.  Both methods should return bytes.  Thus *file*
///         can be a binary file object opened for reading, an io.BytesIO
///         object, or any other custom object that meets this interface.
///
///         The file-like object must have two methods, a read() method
///         that takes an integer argument, and a readline() method that
///         requires no arguments.  Both methods should return bytes.
///         Thus file-like object can be a binary file object opened for
///         reading, a BytesIO object, or any other custom object that
///         meets this interface.
///
///         If *buffers* is not None, it should be an iterable of buffer-enabled
///         objects that is consumed each time the pickle stream references
///         an out-of-band buffer view.  Such buffers have been given in order
///         to the *buffer_callback* of a Pickler object.
///
///         If *buffers* is None (the default), then the buffers are taken
///         from the pickle stream, assuming they are serialized there.
///         It is an error for *buffers* to be None if the pickle stream
///         was produced with a non-None *buffer_callback*.
///
///         Other optional arguments are *fix_imports*, *encoding* and
///         *errors*, which are used to control compatibility support for
///         pickle stream generated by Python 2.  If *fix_imports* is True,
///         pickle will try to map the old Python 2 names to the new names
///         used in Python 3.  The *encoding* and *errors* tell pickle how
///         to decode 8-bit string instances pickled by Python 2; these
///         default to 'ASCII' and 'strict', respectively. *encoding* can be
///         'bytes' to read these 8-bit string instances as bytes objects.
///         """
///         self._buffers = iter(buffers) if buffers is not None else None
///         self._file_readline = file.readline
///         self._file_read = file.read
///         self.memo = {}
///         self.encoding = encoding
///         self.errors = errors
///         self.proto = 0
///         self.fix_imports = fix_imports
///
///     def load(self):
///         """Read a pickled object representation from the open file.
///
///         Return the reconstituted object hierarchy specified in the file.
///         """
///         # Check whether Unpickler was initialized correctly. This is
///         # only needed to mimic the behavior of _pickle.Unpickler.dump().
///         if not hasattr(self, "_file_read"):
///             raise UnpicklingError("Unpickler.__init__() was not called by "
///                                   "%s.__init__()" % (self.__class__.__name__,))
///         self._unframer = _Unframer(self._file_read, self._file_readline)
///         self.read = self._unframer.read
///         self.readinto = self._unframer.readinto
///         self.readline = self._unframer.readline
///         self.metastack = []
///         self.stack = []
///         self.append = self.stack.append
///         self.proto = 0
///         read = self.read
///         dispatch = self.dispatch
///         try:
///             while True:
///                 key = read(1)
///                 if not key:
///                     raise EOFError
///                 assert isinstance(key, bytes_types)
///                 dispatch[key[0]](self)
///         except _Stop as stopinst:
///             return stopinst.value
///
///     # Return a list of items pushed in the stack after last MARK instruction.
///     def pop_mark(self):
///         items = self.stack
///         self.stack = self.metastack.pop()
///         self.append = self.stack.append
///         return items
///
///     def persistent_load(self, pid):
///         raise UnpicklingError("unsupported persistent id encountered")
///
///     dispatch = {}
///
///     def load_proto(self):
///         proto = self.read(1)[0]
///         if not 0 <= proto <= HIGHEST_PROTOCOL:
///             raise ValueError("unsupported pickle protocol: %d" % proto)
///         self.proto = proto
///     dispatch[PROTO[0]] = load_proto
///
///     def load_frame(self):
///         frame_size, = unpack('<Q', self.read(8))
///         if frame_size > sys.maxsize:
///             raise ValueError("frame size > sys.maxsize: %d" % frame_size)
///         self._unframer.load_frame(frame_size)
///     dispatch[FRAME[0]] = load_frame
///
///     def load_persid(self):
///         try:
///             pid = self.readline()[:-1].decode("ascii")
///         except UnicodeDecodeError:
///             raise UnpicklingError(
///                 "persistent IDs in protocol 0 must be ASCII strings")
///         self.append(self.persistent_load(pid))
///     dispatch[PERSID[0]] = load_persid
///
///     def load_binpersid(self):
///         pid = self.stack.pop()
///         self.append(self.persistent_load(pid))
///     dispatch[BINPERSID[0]] = load_binpersid
///
///     def load_none(self):
///         self.append(None)
///     dispatch[NONE[0]] = load_none
///
///     def load_false(self):
///         self.append(False)
///     dispatch[NEWFALSE[0]] = load_false
///
///     def load_true(self):
///         self.append(True)
///     dispatch[NEWTRUE[0]] = load_true
///
///     def load_int(self):
///         data = self.readline()
///         if data == FALSE[1:]:
///             val = False
///         elif data == TRUE[1:]:
///             val = True
///         else:
///             val = int(data, 0)
///         self.append(val)
///     dispatch[INT[0]] = load_int
///
///     def load_binint(self):
///         self.append(unpack('<i', self.read(4))[0])
///     dispatch[BININT[0]] = load_binint
///
///     def load_binint1(self):
///         self.append(self.read(1)[0])
///     dispatch[BININT1[0]] = load_binint1
///
///     def load_binint2(self):
///         self.append(unpack('<H', self.read(2))[0])
///     dispatch[BININT2[0]] = load_binint2
///
///     def load_long(self):
///         val = self.readline()[:-1]
///         if val and val[-1] == b'L'[0]:
///             val = val[:-1]
///         self.append(int(val, 0))
///     dispatch[LONG[0]] = load_long
///
///     def load_long1(self):
///         n = self.read(1)[0]
///         data = self.read(n)
///         self.append(decode_long(data))
///     dispatch[LONG1[0]] = load_long1
///
///     def load_long4(self):
///         n, = unpack('<i', self.read(4))
///         if n < 0:
///             # Corrupt or hostile pickle -- we never write one like this
///             raise UnpicklingError("LONG pickle has negative byte count")
///         data = self.read(n)
///         self.append(decode_long(data))
///     dispatch[LONG4[0]] = load_long4
///
///     def load_float(self):
///         self.append(float(self.readline()[:-1]))
///     dispatch[FLOAT[0]] = load_float
///
///     def load_binfloat(self):
///         self.append(unpack('>d', self.read(8))[0])
///     dispatch[BINFLOAT[0]] = load_binfloat
///
///     def _decode_string(self, value):
///         # Used to allow strings from Python 2 to be decoded either as
///         # bytes or Unicode strings.  This should be used only with the
///         # STRING, BINSTRING and SHORT_BINSTRING opcodes.
///         if self.encoding == "bytes":
///             return value
///         else:
///             return value.decode(self.encoding, self.errors)
///
///     def load_string(self):
///         data = self.readline()[:-1]
///         # Strip outermost quotes
///         if len(data) >= 2 and data[0] == data[-1] and data[0] in b'"\'':
///             data = data[1:-1]
///         else:
///             raise UnpicklingError("the STRING opcode argument must be quoted")
///         self.append(self._decode_string(codecs.escape_decode(data)[0]))
///     dispatch[STRING[0]] = load_string
///
///     def load_binstring(self):
///         # Deprecated BINSTRING uses signed 32-bit length
///         len, = unpack('<i', self.read(4))
///         if len < 0:
///             raise UnpicklingError("BINSTRING pickle has negative byte count")
///         data = self.read(len)
///         self.append(self._decode_string(data))
///     dispatch[BINSTRING[0]] = load_binstring
///
///     def load_binbytes(self):
///         len, = unpack('<I', self.read(4))
///         if len > maxsize:
///             raise UnpicklingError("BINBYTES exceeds system's maximum size "
///                                   "of %d bytes" % maxsize)
///         self.append(self.read(len))
///     dispatch[BINBYTES[0]] = load_binbytes
///
///     def load_unicode(self):
///         self.append(str(self.readline()[:-1], 'raw-unicode-escape'))
///     dispatch[UNICODE[0]] = load_unicode
///
///     def load_binunicode(self):
///         len, = unpack('<I', self.read(4))
///         if len > maxsize:
///             raise UnpicklingError("BINUNICODE exceeds system's maximum size "
///                                   "of %d bytes" % maxsize)
///         self.append(str(self.read(len), 'utf-8', 'surrogatepass'))
///     dispatch[BINUNICODE[0]] = load_binunicode
///
///     def load_binunicode8(self):
///         len, = unpack('<Q', self.read(8))
///         if len > maxsize:
///             raise UnpicklingError("BINUNICODE8 exceeds system's maximum size "
///                                   "of %d bytes" % maxsize)
///         self.append(str(self.read(len), 'utf-8', 'surrogatepass'))
///     dispatch[BINUNICODE8[0]] = load_binunicode8
///
///     def load_binbytes8(self):
///         len, = unpack('<Q', self.read(8))
///         if len > maxsize:
///             raise UnpicklingError("BINBYTES8 exceeds system's maximum size "
///                                   "of %d bytes" % maxsize)
///         self.append(self.read(len))
///     dispatch[BINBYTES8[0]] = load_binbytes8
///
///     def load_bytearray8(self):
///         len, = unpack('<Q', self.read(8))
///         if len > maxsize:
///             raise UnpicklingError("BYTEARRAY8 exceeds system's maximum size "
///                                   "of %d bytes" % maxsize)
///         b = bytearray(len)
///         self.readinto(b)
///         self.append(b)
///     dispatch[BYTEARRAY8[0]] = load_bytearray8
///
///     def load_next_buffer(self):
///         if self._buffers is None:
///             raise UnpicklingError("pickle stream refers to out-of-band data "
///                                   "but no *buffers* argument was given")
///         try:
///             buf = next(self._buffers)
///         except StopIteration:
///             raise UnpicklingError("not enough out-of-band buffers")
///         self.append(buf)
///     dispatch[NEXT_BUFFER[0]] = load_next_buffer
///
///     def load_readonly_buffer(self):
///         buf = self.stack[-1]
///         with memoryview(buf) as m:
///             if not m.readonly:
///                 self.stack[-1] = m.toreadonly()
///     dispatch[READONLY_BUFFER[0]] = load_readonly_buffer
///
///     def load_short_binstring(self):
///         len = self.read(1)[0]
///         data = self.read(len)
///         self.append(self._decode_string(data))
///     dispatch[SHORT_BINSTRING[0]] = load_short_binstring
///
///     def load_short_binbytes(self):
///         len = self.read(1)[0]
///         self.append(self.read(len))
///     dispatch[SHORT_BINBYTES[0]] = load_short_binbytes
///
///     def load_short_binunicode(self):
///         len = self.read(1)[0]
///         self.append(str(self.read(len), 'utf-8', 'surrogatepass'))
///     dispatch[SHORT_BINUNICODE[0]] = load_short_binunicode
///
///     def load_tuple(self):
///         items = self.pop_mark()
///         self.append(tuple(items))
///     dispatch[TUPLE[0]] = load_tuple
///
///     def load_empty_tuple(self):
///         self.append(())
///     dispatch[EMPTY_TUPLE[0]] = load_empty_tuple
///
///     def load_tuple1(self):
///         self.stack[-1] = (self.stack[-1],)
///     dispatch[TUPLE1[0]] = load_tuple1
///
///     def load_tuple2(self):
///         self.stack[-2:] = [(self.stack[-2], self.stack[-1])]
///     dispatch[TUPLE2[0]] = load_tuple2
///
///     def load_tuple3(self):
///         self.stack[-3:] = [(self.stack[-3], self.stack[-2], self.stack[-1])]
///     dispatch[TUPLE3[0]] = load_tuple3
///
///     def load_empty_list(self):
///         self.append([])
///     dispatch[EMPTY_LIST[0]] = load_empty_list
///
///     def load_empty_dictionary(self):
///         self.append({})
///     dispatch[EMPTY_DICT[0]] = load_empty_dictionary
///
///     def load_empty_set(self):
///         self.append(set())
///     dispatch[EMPTY_SET[0]] = load_empty_set
///
///     def load_frozenset(self):
///         items = self.pop_mark()
///         self.append(frozenset(items))
///     dispatch[FROZENSET[0]] = load_frozenset
///
///     def load_list(self):
///         items = self.pop_mark()
///         self.append(items)
///     dispatch[LIST[0]] = load_list
///
///     def load_dict(self):
///         items = self.pop_mark()
///         d = {items[i]: items[i+1]
///              for i in range(0, len(items), 2)}
///         self.append(d)
///     dispatch[DICT[0]] = load_dict
///
///     # INST and OBJ differ only in how they get a class object.  It's not
///     # only sensible to do the rest in a common routine, the two routines
///     # previously diverged and grew different bugs.
///     # klass is the class to instantiate, and k points to the topmost mark
///     # object, following which are the arguments for klass.__init__.
///     def _instantiate(self, klass, args):
///         if (args or not isinstance(klass, type) or
///             hasattr(klass, "__getinitargs__")):
///             try:
///                 value = klass(*args)
///             except TypeError as err:
///                 raise TypeError("in constructor for %s: %s" %
///                                 (klass.__name__, str(err)), sys.exc_info()[2])
///         else:
///             value = klass.__new__(klass)
///         self.append(value)
///
///     def load_inst(self):
///         module = self.readline()[:-1].decode("ascii")
///         name = self.readline()[:-1].decode("ascii")
///         klass = self.find_class(module, name)
///         self._instantiate(klass, self.pop_mark())
///     dispatch[INST[0]] = load_inst
///
///     def load_obj(self):
///         # Stack is ... markobject classobject arg1 arg2 ...
///         args = self.pop_mark()
///         cls = args.pop(0)
///         self._instantiate(cls, args)
///     dispatch[OBJ[0]] = load_obj
///
///     def load_newobj(self):
///         args = self.stack.pop()
///         cls = self.stack.pop()
///         obj = cls.__new__(cls, *args)
///         self.append(obj)
///     dispatch[NEWOBJ[0]] = load_newobj
///
///     def load_newobj_ex(self):
///         kwargs = self.stack.pop()
///         args = self.stack.pop()
///         cls = self.stack.pop()
///         obj = cls.__new__(cls, *args, **kwargs)
///         self.append(obj)
///     dispatch[NEWOBJ_EX[0]] = load_newobj_ex
///
///     def load_global(self):
///         module = self.readline()[:-1].decode("utf-8")
///         name = self.readline()[:-1].decode("utf-8")
///         klass = self.find_class(module, name)
///         self.append(klass)
///     dispatch[GLOBAL[0]] = load_global
///
///     def load_stack_global(self):
///         name = self.stack.pop()
///         module = self.stack.pop()
///         if type(name) is not str or type(module) is not str:
///             raise UnpicklingError("STACK_GLOBAL requires str")
///         self.append(self.find_class(module, name))
///     dispatch[STACK_GLOBAL[0]] = load_stack_global
///
///     def load_ext1(self):
///         code = self.read(1)[0]
///         self.get_extension(code)
///     dispatch[EXT1[0]] = load_ext1
///
///     def load_ext2(self):
///         code, = unpack('<H', self.read(2))
///         self.get_extension(code)
///     dispatch[EXT2[0]] = load_ext2
///
///     def load_ext4(self):
///         code, = unpack('<i', self.read(4))
///         self.get_extension(code)
///     dispatch[EXT4[0]] = load_ext4
///
///     def get_extension(self, code):
///         nil = []
///         obj = _extension_cache.get(code, nil)
///         if obj is not nil:
///             self.append(obj)
///             return
///         key = _inverted_registry.get(code)
///         if not key:
///             if code <= 0: # note that 0 is forbidden
///                 # Corrupt or hostile pickle.
///                 raise UnpicklingError("EXT specifies code <= 0")
///             raise ValueError("unregistered extension code %d" % code)
///         obj = self.find_class(*key)
///         _extension_cache[code] = obj
///         self.append(obj)
///
///     def find_class(self, module, name):
///         # Subclasses may override this.
///         sys.audit('pickle.find_class', module, name)
///         if self.proto < 3 and self.fix_imports:
///             if (module, name) in _compat_pickle.NAME_MAPPING:
///                 module, name = _compat_pickle.NAME_MAPPING[(module, name)]
///             elif module in _compat_pickle.IMPORT_MAPPING:
///                 module = _compat_pickle.IMPORT_MAPPING[module]
///         __import__(module, level=0)
///         if self.proto >= 4:
///             return _getattribute(sys.modules[module], name)[0]
///         else:
///             return getattr(sys.modules[module], name)
///
///     def load_reduce(self):
///         stack = self.stack
///         args = stack.pop()
///         func = stack[-1]
///         stack[-1] = func(*args)
///     dispatch[REDUCE[0]] = load_reduce
///
///     def load_pop(self):
///         if self.stack:
///             del self.stack[-1]
///         else:
///             self.pop_mark()
///     dispatch[POP[0]] = load_pop
///
///     def load_pop_mark(self):
///         self.pop_mark()
///     dispatch[POP_MARK[0]] = load_pop_mark
///
///     def load_dup(self):
///         self.append(self.stack[-1])
///     dispatch[DUP[0]] = load_dup
///
///     def load_get(self):
///         i = int(self.readline()[:-1])
///         try:
///             self.append(self.memo[i])
///         except KeyError:
///             msg = f'Memo value not found at index {i}'
///             raise UnpicklingError(msg) from None
///     dispatch[GET[0]] = load_get
///
///     def load_binget(self):
///         i = self.read(1)[0]
///         try:
///             self.append(self.memo[i])
///         except KeyError as exc:
///             msg = f'Memo value not found at index {i}'
///             raise UnpicklingError(msg) from None
///     dispatch[BINGET[0]] = load_binget
///
///     def load_long_binget(self):
///         i, = unpack('<I', self.read(4))
///         try:
///             self.append(self.memo[i])
///         except KeyError as exc:
///             msg = f'Memo value not found at index {i}'
///             raise UnpicklingError(msg) from None
///     dispatch[LONG_BINGET[0]] = load_long_binget
///
///     def load_put(self):
///         i = int(self.readline()[:-1])
///         if i < 0:
///             raise ValueError("negative PUT argument")
///         self.memo[i] = self.stack[-1]
///     dispatch[PUT[0]] = load_put
///
///     def load_binput(self):
///         i = self.read(1)[0]
///         if i < 0:
///             raise ValueError("negative BINPUT argument")
///         self.memo[i] = self.stack[-1]
///     dispatch[BINPUT[0]] = load_binput
///
///     def load_long_binput(self):
///         i, = unpack('<I', self.read(4))
///         if i > maxsize:
///             raise ValueError("negative LONG_BINPUT argument")
///         self.memo[i] = self.stack[-1]
///     dispatch[LONG_BINPUT[0]] = load_long_binput
///
///     def load_memoize(self):
///         memo = self.memo
///         memo[len(memo)] = self.stack[-1]
///     dispatch[MEMOIZE[0]] = load_memoize
///
///     def load_append(self):
///         stack = self.stack
///         value = stack.pop()
///         list = stack[-1]
///         list.append(value)
///     dispatch[APPEND[0]] = load_append
///
///     def load_appends(self):
///         items = self.pop_mark()
///         list_obj = self.stack[-1]
///         try:
///             extend = list_obj.extend
///         except AttributeError:
///             pass
///         else:
///             extend(items)
///             return
///         # Even if the PEP 307 requires extend() and append() methods,
///         # fall back on append() if the object has no extend() method
///         # for backward compatibility.
///         append = list_obj.append
///         for item in items:
///             append(item)
///     dispatch[APPENDS[0]] = load_appends
///
///     def load_setitem(self):
///         stack = self.stack
///         value = stack.pop()
///         key = stack.pop()
///         dict = stack[-1]
///         dict[key] = value
///     dispatch[SETITEM[0]] = load_setitem
///
///     def load_setitems(self):
///         items = self.pop_mark()
///         dict = self.stack[-1]
///         for i in range(0, len(items), 2):
///             dict[items[i]] = items[i + 1]
///     dispatch[SETITEMS[0]] = load_setitems
///
///     def load_additems(self):
///         items = self.pop_mark()
///         set_obj = self.stack[-1]
///         if isinstance(set_obj, set):
///             set_obj.update(items)
///         else:
///             add = set_obj.add
///             for item in items:
///                 add(item)
///     dispatch[ADDITEMS[0]] = load_additems
///
///     def load_build(self):
///         stack = self.stack
///         state = stack.pop()
///         inst = stack[-1]
///         setstate = getattr(inst, "__setstate__", None)
///         if setstate is not None:
///             setstate(state)
///             return
///         slotstate = None
///         if isinstance(state, tuple) and len(state) == 2:
///             state, slotstate = state
///         if state:
///             inst_dict = inst.__dict__
///             intern = sys.intern
///             for k, v in state.items():
///                 if type(k) is str:
///                     inst_dict[intern(k)] = v
///                 else:
///                     inst_dict[k] = v
///         if slotstate:
///             for k, v in slotstate.items():
///                 setattr(inst, k, v)
///     dispatch[BUILD[0]] = load_build
///
///     def load_mark(self):
///         self.metastack.append(self.stack)
///         self.stack = []
///         self.append = self.stack.append
///     dispatch[MARK[0]] = load_mark
///
///     def load_stop(self):
///         value = self.stack.pop()
///         raise _Stop(value)
///     dispatch[STOP[0]] = load_stop
///
///
/// # Shorthands
///
/// def _dump(obj, file, protocol=None, *, fix_imports=True, buffer_callback=None):
///     _Pickler(file, protocol, fix_imports=fix_imports,
///              buffer_callback=buffer_callback).dump(obj)
///
/// def _dumps(obj, protocol=None, *, fix_imports=True, buffer_callback=None):
///     f = io.BytesIO()
///     _Pickler(f, protocol, fix_imports=fix_imports,
///              buffer_callback=buffer_callback).dump(obj)
///     res = f.getvalue()
///     assert isinstance(res, bytes_types)
///     return res
///
/// def _load(file, *, fix_imports=True, encoding="ASCII", errors="strict",
///           buffers=None):
///     return _Unpickler(file, fix_imports=fix_imports, buffers=buffers,
///                      encoding=encoding, errors=errors).load()
///
/// def _loads(s, /, *, fix_imports=True, encoding="ASCII", errors="strict",
///            buffers=None):
///     if isinstance(s, str):
///         raise TypeError("Can't load pickle from unicode string")
///     file = io.BytesIO(s)
///     return _Unpickler(file, fix_imports=fix_imports, buffers=buffers,
///                       encoding=encoding, errors=errors).load()
///
/// # Use the faster _pickle if possible
/// try:
///     from _pickle import (
///         PickleError,
///         PicklingError,
///         UnpicklingError,
///         Pickler,
///         Unpickler,
///         dump,
///         dumps,
///         load,
///         loads
///     )
/// except ImportError:
///     Pickler, Unpickler = _Pickler, _Unpickler
///     dump, dumps, load, loads = _dump, _dumps, _load, _loads
///
/// # Doctest
/// def _test():
///     import doctest
///     return doctest.testmod()
///
/// if __name__ == "__main__":
///     import argparse
///     parser = argparse.ArgumentParser(
///         description='display contents of the pickle files')
///     parser.add_argument(
///         'pickle_file', type=argparse.FileType('br'),
///         nargs='*', help='the pickle file')
///     parser.add_argument(
///         '-t', '--test', action='store_true',
///         help='run self-test suite')
///     parser.add_argument(
///         '-v', action='store_true',
///         help='run verbosely; only affects self-test run')
///     args = parser.parse_args()
///     if args.test:
///         _test()
///     else:
///         if not args.pickle_file:
///             parser.print_help()
///         else:
///             import pprint
///             for f in args.pickle_file:
///                 obj = load(f)
///                 pprint.pprint(obj)
/// ```
final class pickle extends PythonModule {
  pickle.from(super.pythonModule) : super.from();

  static pickle import() => PythonFfiDart.instance.importModule(
        "pickle",
        pickle.from,
      );

  /// ## decode_long
  ///
  /// ### python docstring
  ///
  /// Decode a long from a two's complement little-endian binary string.
  ///
  /// >>> decode_long(b'')
  /// 0
  /// >>> decode_long(b"\xff\x00")
  /// 255
  /// >>> decode_long(b"\xff\x7f")
  /// 32767
  /// >>> decode_long(b"\x00\xff")
  /// -256
  /// >>> decode_long(b"\x00\x80")
  /// -32768
  /// >>> decode_long(b"\x80")
  /// -128
  /// >>> decode_long(b"\x7f")
  /// 127
  ///
  /// ### python source
  /// ```py
  /// def decode_long(data):
  ///     r"""Decode a long from a two's complement little-endian binary string.
  ///
  ///     >>> decode_long(b'')
  ///     0
  ///     >>> decode_long(b"\xff\x00")
  ///     255
  ///     >>> decode_long(b"\xff\x7f")
  ///     32767
  ///     >>> decode_long(b"\x00\xff")
  ///     -256
  ///     >>> decode_long(b"\x00\x80")
  ///     -32768
  ///     >>> decode_long(b"\x80")
  ///     -128
  ///     >>> decode_long(b"\x7f")
  ///     127
  ///     """
  ///     return int.from_bytes(data, byteorder='little', signed=True)
  /// ```
  Object? decode_long({
    required Object? data,
  }) =>
      getFunction("decode_long").call(
        <Object?>[
          data,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## encode_long
  ///
  /// ### python docstring
  ///
  /// Encode a long to a two's complement little-endian binary string.
  /// Note that 0 is a special case, returning an empty string, to save a
  /// byte in the LONG1 pickling context.
  ///
  /// >>> encode_long(0)
  /// b''
  /// >>> encode_long(255)
  /// b'\xff\x00'
  /// >>> encode_long(32767)
  /// b'\xff\x7f'
  /// >>> encode_long(-256)
  /// b'\x00\xff'
  /// >>> encode_long(-32768)
  /// b'\x00\x80'
  /// >>> encode_long(-128)
  /// b'\x80'
  /// >>> encode_long(127)
  /// b'\x7f'
  /// >>>
  ///
  /// ### python source
  /// ```py
  /// def encode_long(x):
  ///     r"""Encode a long to a two's complement little-endian binary string.
  ///     Note that 0 is a special case, returning an empty string, to save a
  ///     byte in the LONG1 pickling context.
  ///
  ///     >>> encode_long(0)
  ///     b''
  ///     >>> encode_long(255)
  ///     b'\xff\x00'
  ///     >>> encode_long(32767)
  ///     b'\xff\x7f'
  ///     >>> encode_long(-256)
  ///     b'\x00\xff'
  ///     >>> encode_long(-32768)
  ///     b'\x00\x80'
  ///     >>> encode_long(-128)
  ///     b'\x80'
  ///     >>> encode_long(127)
  ///     b'\x7f'
  ///     >>>
  ///     """
  ///     if x == 0:
  ///         return b''
  ///     nbytes = (x.bit_length() >> 3) + 1
  ///     result = x.to_bytes(nbytes, byteorder='little', signed=True)
  ///     if x < 0 and nbytes > 1:
  ///         if result[-1] == 0xff and (result[-2] & 0x80) != 0:
  ///             result = result[:-1]
  ///     return result
  /// ```
  Object? encode_long({
    required Object? x,
  }) =>
      getFunction("encode_long").call(
        <Object?>[
          x,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## whichmodule
  ///
  /// ### python docstring
  ///
  /// Find the module an object belong to.
  ///
  /// ### python source
  /// ```py
  /// def whichmodule(obj, name):
  ///     """Find the module an object belong to."""
  ///     module_name = getattr(obj, '__module__', None)
  ///     if module_name is not None:
  ///         return module_name
  ///     # Protect the iteration by using a list copy of sys.modules against dynamic
  ///     # modules that trigger imports of other modules upon calls to getattr.
  ///     for module_name, module in sys.modules.copy().items():
  ///         if (module_name == '__main__'
  ///             or module_name == '__mp_main__'  # bpo-42406
  ///             or module is None):
  ///             continue
  ///         try:
  ///             if _getattribute(module, name)[0] is obj:
  ///                 return module_name
  ///         except AttributeError:
  ///             pass
  ///     return '__main__'
  /// ```
  Object? whichmodule({
    required Object? obj,
    required Object? name,
  }) =>
      getFunction("whichmodule").call(
        <Object?>[
          obj,
          name,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## ADDITEMS (getter)
  Object? get ADDITEMS => getAttribute("ADDITEMS");

  /// ## ADDITEMS (setter)
  set ADDITEMS(Object? ADDITEMS) => setAttribute("ADDITEMS", ADDITEMS);

  /// ## APPEND (getter)
  Object? get APPEND => getAttribute("APPEND");

  /// ## APPEND (setter)
  set APPEND(Object? APPEND) => setAttribute("APPEND", APPEND);

  /// ## APPENDS (getter)
  Object? get APPENDS => getAttribute("APPENDS");

  /// ## APPENDS (setter)
  set APPENDS(Object? APPENDS) => setAttribute("APPENDS", APPENDS);

  /// ## BINBYTES (getter)
  Object? get BINBYTES => getAttribute("BINBYTES");

  /// ## BINBYTES (setter)
  set BINBYTES(Object? BINBYTES) => setAttribute("BINBYTES", BINBYTES);

  /// ## BINBYTES8 (getter)
  Object? get BINBYTES8 => getAttribute("BINBYTES8");

  /// ## BINBYTES8 (setter)
  set BINBYTES8(Object? BINBYTES8) => setAttribute("BINBYTES8", BINBYTES8);

  /// ## BINFLOAT (getter)
  Object? get BINFLOAT => getAttribute("BINFLOAT");

  /// ## BINFLOAT (setter)
  set BINFLOAT(Object? BINFLOAT) => setAttribute("BINFLOAT", BINFLOAT);

  /// ## BINGET (getter)
  Object? get BINGET => getAttribute("BINGET");

  /// ## BINGET (setter)
  set BINGET(Object? BINGET) => setAttribute("BINGET", BINGET);

  /// ## BININT (getter)
  Object? get BININT => getAttribute("BININT");

  /// ## BININT (setter)
  set BININT(Object? BININT) => setAttribute("BININT", BININT);

  /// ## BININT1 (getter)
  Object? get BININT1 => getAttribute("BININT1");

  /// ## BININT1 (setter)
  set BININT1(Object? BININT1) => setAttribute("BININT1", BININT1);

  /// ## BININT2 (getter)
  Object? get BININT2 => getAttribute("BININT2");

  /// ## BININT2 (setter)
  set BININT2(Object? BININT2) => setAttribute("BININT2", BININT2);

  /// ## BINPERSID (getter)
  Object? get BINPERSID => getAttribute("BINPERSID");

  /// ## BINPERSID (setter)
  set BINPERSID(Object? BINPERSID) => setAttribute("BINPERSID", BINPERSID);

  /// ## BINPUT (getter)
  Object? get BINPUT => getAttribute("BINPUT");

  /// ## BINPUT (setter)
  set BINPUT(Object? BINPUT) => setAttribute("BINPUT", BINPUT);

  /// ## BINSTRING (getter)
  Object? get BINSTRING => getAttribute("BINSTRING");

  /// ## BINSTRING (setter)
  set BINSTRING(Object? BINSTRING) => setAttribute("BINSTRING", BINSTRING);

  /// ## BINUNICODE (getter)
  Object? get BINUNICODE => getAttribute("BINUNICODE");

  /// ## BINUNICODE (setter)
  set BINUNICODE(Object? BINUNICODE) => setAttribute("BINUNICODE", BINUNICODE);

  /// ## BINUNICODE8 (getter)
  Object? get BINUNICODE8 => getAttribute("BINUNICODE8");

  /// ## BINUNICODE8 (setter)
  set BINUNICODE8(Object? BINUNICODE8) =>
      setAttribute("BINUNICODE8", BINUNICODE8);

  /// ## BUILD (getter)
  Object? get BUILD => getAttribute("BUILD");

  /// ## BUILD (setter)
  set BUILD(Object? BUILD) => setAttribute("BUILD", BUILD);

  /// ## BYTEARRAY8 (getter)
  Object? get BYTEARRAY8 => getAttribute("BYTEARRAY8");

  /// ## BYTEARRAY8 (setter)
  set BYTEARRAY8(Object? BYTEARRAY8) => setAttribute("BYTEARRAY8", BYTEARRAY8);

  /// ## DEFAULT_PROTOCOL (getter)
  Object? get DEFAULT_PROTOCOL => getAttribute("DEFAULT_PROTOCOL");

  /// ## DEFAULT_PROTOCOL (setter)
  set DEFAULT_PROTOCOL(Object? DEFAULT_PROTOCOL) =>
      setAttribute("DEFAULT_PROTOCOL", DEFAULT_PROTOCOL);

  /// ## DICT (getter)
  Object? get DICT => getAttribute("DICT");

  /// ## DICT (setter)
  set DICT(Object? DICT) => setAttribute("DICT", DICT);

  /// ## DUP (getter)
  Object? get DUP => getAttribute("DUP");

  /// ## DUP (setter)
  set DUP(Object? DUP) => setAttribute("DUP", DUP);

  /// ## EMPTY_DICT (getter)
  Object? get EMPTY_DICT => getAttribute("EMPTY_DICT");

  /// ## EMPTY_DICT (setter)
  set EMPTY_DICT(Object? EMPTY_DICT) => setAttribute("EMPTY_DICT", EMPTY_DICT);

  /// ## EMPTY_LIST (getter)
  Object? get EMPTY_LIST => getAttribute("EMPTY_LIST");

  /// ## EMPTY_LIST (setter)
  set EMPTY_LIST(Object? EMPTY_LIST) => setAttribute("EMPTY_LIST", EMPTY_LIST);

  /// ## EMPTY_SET (getter)
  Object? get EMPTY_SET => getAttribute("EMPTY_SET");

  /// ## EMPTY_SET (setter)
  set EMPTY_SET(Object? EMPTY_SET) => setAttribute("EMPTY_SET", EMPTY_SET);

  /// ## EMPTY_TUPLE (getter)
  Object? get EMPTY_TUPLE => getAttribute("EMPTY_TUPLE");

  /// ## EMPTY_TUPLE (setter)
  set EMPTY_TUPLE(Object? EMPTY_TUPLE) =>
      setAttribute("EMPTY_TUPLE", EMPTY_TUPLE);

  /// ## EXT1 (getter)
  Object? get EXT1 => getAttribute("EXT1");

  /// ## EXT1 (setter)
  set EXT1(Object? EXT1) => setAttribute("EXT1", EXT1);

  /// ## EXT2 (getter)
  Object? get EXT2 => getAttribute("EXT2");

  /// ## EXT2 (setter)
  set EXT2(Object? EXT2) => setAttribute("EXT2", EXT2);

  /// ## EXT4 (getter)
  Object? get EXT4 => getAttribute("EXT4");

  /// ## EXT4 (setter)
  set EXT4(Object? EXT4) => setAttribute("EXT4", EXT4);

  /// ## FALSE (getter)
  Object? get FALSE => getAttribute("FALSE");

  /// ## FALSE (setter)
  set FALSE(Object? FALSE) => setAttribute("FALSE", FALSE);

  /// ## FLOAT (getter)
  Object? get FLOAT => getAttribute("FLOAT");

  /// ## FLOAT (setter)
  set FLOAT(Object? FLOAT) => setAttribute("FLOAT", FLOAT);

  /// ## FRAME (getter)
  Object? get FRAME => getAttribute("FRAME");

  /// ## FRAME (setter)
  set FRAME(Object? FRAME) => setAttribute("FRAME", FRAME);

  /// ## FROZENSET (getter)
  Object? get FROZENSET => getAttribute("FROZENSET");

  /// ## FROZENSET (setter)
  set FROZENSET(Object? FROZENSET) => setAttribute("FROZENSET", FROZENSET);

  /// ## GET (getter)
  Object? get GET => getAttribute("GET");

  /// ## GET (setter)
  set GET(Object? GET) => setAttribute("GET", GET);

  /// ## GLOBAL (getter)
  Object? get GLOBAL => getAttribute("GLOBAL");

  /// ## GLOBAL (setter)
  set GLOBAL(Object? GLOBAL) => setAttribute("GLOBAL", GLOBAL);

  /// ## HIGHEST_PROTOCOL (getter)
  Object? get HIGHEST_PROTOCOL => getAttribute("HIGHEST_PROTOCOL");

  /// ## HIGHEST_PROTOCOL (setter)
  set HIGHEST_PROTOCOL(Object? HIGHEST_PROTOCOL) =>
      setAttribute("HIGHEST_PROTOCOL", HIGHEST_PROTOCOL);

  /// ## INST (getter)
  Object? get INST => getAttribute("INST");

  /// ## INST (setter)
  set INST(Object? INST) => setAttribute("INST", INST);

  /// ## INT (getter)
  Object? get INT => getAttribute("INT");

  /// ## INT (setter)
  set INT(Object? INT) => setAttribute("INT", INT);

  /// ## LIST (getter)
  Object? get LIST => getAttribute("LIST");

  /// ## LIST (setter)
  set LIST(Object? LIST) => setAttribute("LIST", LIST);

  /// ## LONG (getter)
  Object? get LONG => getAttribute("LONG");

  /// ## LONG (setter)
  set LONG(Object? LONG) => setAttribute("LONG", LONG);

  /// ## LONG1 (getter)
  Object? get LONG1 => getAttribute("LONG1");

  /// ## LONG1 (setter)
  set LONG1(Object? LONG1) => setAttribute("LONG1", LONG1);

  /// ## LONG4 (getter)
  Object? get LONG4 => getAttribute("LONG4");

  /// ## LONG4 (setter)
  set LONG4(Object? LONG4) => setAttribute("LONG4", LONG4);

  /// ## LONG_BINGET (getter)
  Object? get LONG_BINGET => getAttribute("LONG_BINGET");

  /// ## LONG_BINGET (setter)
  set LONG_BINGET(Object? LONG_BINGET) =>
      setAttribute("LONG_BINGET", LONG_BINGET);

  /// ## LONG_BINPUT (getter)
  Object? get LONG_BINPUT => getAttribute("LONG_BINPUT");

  /// ## LONG_BINPUT (setter)
  set LONG_BINPUT(Object? LONG_BINPUT) =>
      setAttribute("LONG_BINPUT", LONG_BINPUT);

  /// ## MARK (getter)
  Object? get MARK => getAttribute("MARK");

  /// ## MARK (setter)
  set MARK(Object? MARK) => setAttribute("MARK", MARK);

  /// ## MEMOIZE (getter)
  Object? get MEMOIZE => getAttribute("MEMOIZE");

  /// ## MEMOIZE (setter)
  set MEMOIZE(Object? MEMOIZE) => setAttribute("MEMOIZE", MEMOIZE);

  /// ## NEWFALSE (getter)
  Object? get NEWFALSE => getAttribute("NEWFALSE");

  /// ## NEWFALSE (setter)
  set NEWFALSE(Object? NEWFALSE) => setAttribute("NEWFALSE", NEWFALSE);

  /// ## NEWOBJ (getter)
  Object? get NEWOBJ => getAttribute("NEWOBJ");

  /// ## NEWOBJ (setter)
  set NEWOBJ(Object? NEWOBJ) => setAttribute("NEWOBJ", NEWOBJ);

  /// ## NEWOBJ_EX (getter)
  Object? get NEWOBJ_EX => getAttribute("NEWOBJ_EX");

  /// ## NEWOBJ_EX (setter)
  set NEWOBJ_EX(Object? NEWOBJ_EX) => setAttribute("NEWOBJ_EX", NEWOBJ_EX);

  /// ## NEWTRUE (getter)
  Object? get NEWTRUE => getAttribute("NEWTRUE");

  /// ## NEWTRUE (setter)
  set NEWTRUE(Object? NEWTRUE) => setAttribute("NEWTRUE", NEWTRUE);

  /// ## NEXT_BUFFER (getter)
  Object? get NEXT_BUFFER => getAttribute("NEXT_BUFFER");

  /// ## NEXT_BUFFER (setter)
  set NEXT_BUFFER(Object? NEXT_BUFFER) =>
      setAttribute("NEXT_BUFFER", NEXT_BUFFER);

  /// ## NONE (getter)
  Object? get NONE => getAttribute("NONE");

  /// ## NONE (setter)
  set NONE(Object? NONE) => setAttribute("NONE", NONE);

  /// ## OBJ (getter)
  Object? get OBJ => getAttribute("OBJ");

  /// ## OBJ (setter)
  set OBJ(Object? OBJ) => setAttribute("OBJ", OBJ);

  /// ## PERSID (getter)
  Object? get PERSID => getAttribute("PERSID");

  /// ## PERSID (setter)
  set PERSID(Object? PERSID) => setAttribute("PERSID", PERSID);

  /// ## POP (getter)
  Object? get POP => getAttribute("POP");

  /// ## POP (setter)
  set POP(Object? POP) => setAttribute("POP", POP);

  /// ## POP_MARK (getter)
  Object? get POP_MARK => getAttribute("POP_MARK");

  /// ## POP_MARK (setter)
  set POP_MARK(Object? POP_MARK) => setAttribute("POP_MARK", POP_MARK);

  /// ## PROTO (getter)
  Object? get PROTO => getAttribute("PROTO");

  /// ## PROTO (setter)
  set PROTO(Object? PROTO) => setAttribute("PROTO", PROTO);

  /// ## PUT (getter)
  Object? get PUT => getAttribute("PUT");

  /// ## PUT (setter)
  set PUT(Object? PUT) => setAttribute("PUT", PUT);

  /// ## PyStringMap (getter)
  Object? get PyStringMap => getAttribute("PyStringMap");

  /// ## PyStringMap (setter)
  set PyStringMap(Object? PyStringMap) =>
      setAttribute("PyStringMap", PyStringMap);

  /// ## READONLY_BUFFER (getter)
  Object? get READONLY_BUFFER => getAttribute("READONLY_BUFFER");

  /// ## READONLY_BUFFER (setter)
  set READONLY_BUFFER(Object? READONLY_BUFFER) =>
      setAttribute("READONLY_BUFFER", READONLY_BUFFER);

  /// ## REDUCE (getter)
  Object? get REDUCE => getAttribute("REDUCE");

  /// ## REDUCE (setter)
  set REDUCE(Object? REDUCE) => setAttribute("REDUCE", REDUCE);

  /// ## SETITEM (getter)
  Object? get SETITEM => getAttribute("SETITEM");

  /// ## SETITEM (setter)
  set SETITEM(Object? SETITEM) => setAttribute("SETITEM", SETITEM);

  /// ## SETITEMS (getter)
  Object? get SETITEMS => getAttribute("SETITEMS");

  /// ## SETITEMS (setter)
  set SETITEMS(Object? SETITEMS) => setAttribute("SETITEMS", SETITEMS);

  /// ## SHORT_BINBYTES (getter)
  Object? get SHORT_BINBYTES => getAttribute("SHORT_BINBYTES");

  /// ## SHORT_BINBYTES (setter)
  set SHORT_BINBYTES(Object? SHORT_BINBYTES) =>
      setAttribute("SHORT_BINBYTES", SHORT_BINBYTES);

  /// ## SHORT_BINSTRING (getter)
  Object? get SHORT_BINSTRING => getAttribute("SHORT_BINSTRING");

  /// ## SHORT_BINSTRING (setter)
  set SHORT_BINSTRING(Object? SHORT_BINSTRING) =>
      setAttribute("SHORT_BINSTRING", SHORT_BINSTRING);

  /// ## SHORT_BINUNICODE (getter)
  Object? get SHORT_BINUNICODE => getAttribute("SHORT_BINUNICODE");

  /// ## SHORT_BINUNICODE (setter)
  set SHORT_BINUNICODE(Object? SHORT_BINUNICODE) =>
      setAttribute("SHORT_BINUNICODE", SHORT_BINUNICODE);

  /// ## STACK_GLOBAL (getter)
  Object? get STACK_GLOBAL => getAttribute("STACK_GLOBAL");

  /// ## STACK_GLOBAL (setter)
  set STACK_GLOBAL(Object? STACK_GLOBAL) =>
      setAttribute("STACK_GLOBAL", STACK_GLOBAL);

  /// ## STOP (getter)
  Object? get STOP => getAttribute("STOP");

  /// ## STOP (setter)
  set STOP(Object? STOP) => setAttribute("STOP", STOP);

  /// ## STRING (getter)
  Object? get STRING => getAttribute("STRING");

  /// ## STRING (setter)
  set STRING(Object? STRING) => setAttribute("STRING", STRING);

  /// ## TRUE (getter)
  Object? get TRUE => getAttribute("TRUE");

  /// ## TRUE (setter)
  set TRUE(Object? TRUE) => setAttribute("TRUE", TRUE);

  /// ## TUPLE (getter)
  Object? get TUPLE => getAttribute("TUPLE");

  /// ## TUPLE (setter)
  set TUPLE(Object? TUPLE) => setAttribute("TUPLE", TUPLE);

  /// ## TUPLE1 (getter)
  Object? get TUPLE1 => getAttribute("TUPLE1");

  /// ## TUPLE1 (setter)
  set TUPLE1(Object? TUPLE1) => setAttribute("TUPLE1", TUPLE1);

  /// ## TUPLE2 (getter)
  Object? get TUPLE2 => getAttribute("TUPLE2");

  /// ## TUPLE2 (setter)
  set TUPLE2(Object? TUPLE2) => setAttribute("TUPLE2", TUPLE2);

  /// ## TUPLE3 (getter)
  Object? get TUPLE3 => getAttribute("TUPLE3");

  /// ## TUPLE3 (setter)
  set TUPLE3(Object? TUPLE3) => setAttribute("TUPLE3", TUPLE3);

  /// ## UNICODE (getter)
  Object? get UNICODE => getAttribute("UNICODE");

  /// ## UNICODE (setter)
  set UNICODE(Object? UNICODE) => setAttribute("UNICODE", UNICODE);

  /// ## bytes_types (getter)
  Object? get bytes_types => getAttribute("bytes_types");

  /// ## bytes_types (setter)
  set bytes_types(Object? bytes_types) =>
      setAttribute("bytes_types", bytes_types);

  /// ## compatible_formats (getter)
  Object? get compatible_formats => getAttribute("compatible_formats");

  /// ## compatible_formats (setter)
  set compatible_formats(Object? compatible_formats) =>
      setAttribute("compatible_formats", compatible_formats);

  /// ## dispatch_table (getter)
  Object? get dispatch_table => getAttribute("dispatch_table");

  /// ## dispatch_table (setter)
  set dispatch_table(Object? dispatch_table) =>
      setAttribute("dispatch_table", dispatch_table);

  /// ## format_version (getter)
  Object? get format_version => getAttribute("format_version");

  /// ## format_version (setter)
  set format_version(Object? format_version) =>
      setAttribute("format_version", format_version);

  /// ## maxsize (getter)
  Object? get maxsize => getAttribute("maxsize");

  /// ## maxsize (setter)
  set maxsize(Object? maxsize) => setAttribute("maxsize", maxsize);
}

/// ## codecs
///
/// ### python docstring
///
/// codecs -- Python Codec Registry, API and helpers.
///
///
/// Written by Marc-Andre Lemburg (mal@lemburg.com).
///
/// (c) Copyright CNRI, All Rights Reserved. NO WARRANTY.
///
/// ### python source
/// ```py
/// """ codecs -- Python Codec Registry, API and helpers.
///
///
/// Written by Marc-Andre Lemburg (mal@lemburg.com).
///
/// (c) Copyright CNRI, All Rights Reserved. NO WARRANTY.
///
/// """
///
/// import builtins
/// import sys
///
/// ### Registry and builtin stateless codec functions
///
/// try:
///     from _codecs import *
/// except ImportError as why:
///     raise SystemError('Failed to load the builtin codecs: %s' % why)
///
/// __all__ = ["register", "lookup", "open", "EncodedFile", "BOM", "BOM_BE",
///            "BOM_LE", "BOM32_BE", "BOM32_LE", "BOM64_BE", "BOM64_LE",
///            "BOM_UTF8", "BOM_UTF16", "BOM_UTF16_LE", "BOM_UTF16_BE",
///            "BOM_UTF32", "BOM_UTF32_LE", "BOM_UTF32_BE",
///            "CodecInfo", "Codec", "IncrementalEncoder", "IncrementalDecoder",
///            "StreamReader", "StreamWriter",
///            "StreamReaderWriter", "StreamRecoder",
///            "getencoder", "getdecoder", "getincrementalencoder",
///            "getincrementaldecoder", "getreader", "getwriter",
///            "encode", "decode", "iterencode", "iterdecode",
///            "strict_errors", "ignore_errors", "replace_errors",
///            "xmlcharrefreplace_errors",
///            "backslashreplace_errors", "namereplace_errors",
///            "register_error", "lookup_error"]
///
/// ### Constants
///
/// #
/// # Byte Order Mark (BOM = ZERO WIDTH NO-BREAK SPACE = U+FEFF)
/// # and its possible byte string values
/// # for UTF8/UTF16/UTF32 output and little/big endian machines
/// #
///
/// # UTF-8
/// BOM_UTF8 = b'\xef\xbb\xbf'
///
/// # UTF-16, little endian
/// BOM_LE = BOM_UTF16_LE = b'\xff\xfe'
///
/// # UTF-16, big endian
/// BOM_BE = BOM_UTF16_BE = b'\xfe\xff'
///
/// # UTF-32, little endian
/// BOM_UTF32_LE = b'\xff\xfe\x00\x00'
///
/// # UTF-32, big endian
/// BOM_UTF32_BE = b'\x00\x00\xfe\xff'
///
/// if sys.byteorder == 'little':
///
///     # UTF-16, native endianness
///     BOM = BOM_UTF16 = BOM_UTF16_LE
///
///     # UTF-32, native endianness
///     BOM_UTF32 = BOM_UTF32_LE
///
/// else:
///
///     # UTF-16, native endianness
///     BOM = BOM_UTF16 = BOM_UTF16_BE
///
///     # UTF-32, native endianness
///     BOM_UTF32 = BOM_UTF32_BE
///
/// # Old broken names (don't use in new code)
/// BOM32_LE = BOM_UTF16_LE
/// BOM32_BE = BOM_UTF16_BE
/// BOM64_LE = BOM_UTF32_LE
/// BOM64_BE = BOM_UTF32_BE
///
///
/// ### Codec base classes (defining the API)
///
/// class CodecInfo(tuple):
///     """Codec details when looking up the codec registry"""
///
///     # Private API to allow Python 3.4 to denylist the known non-Unicode
///     # codecs in the standard library. A more general mechanism to
///     # reliably distinguish test encodings from other codecs will hopefully
///     # be defined for Python 3.5
///     #
///     # See http://bugs.python.org/issue19619
///     _is_text_encoding = True # Assume codecs are text encodings by default
///
///     def __new__(cls, encode, decode, streamreader=None, streamwriter=None,
///         incrementalencoder=None, incrementaldecoder=None, name=None,
///         *, _is_text_encoding=None):
///         self = tuple.__new__(cls, (encode, decode, streamreader, streamwriter))
///         self.name = name
///         self.encode = encode
///         self.decode = decode
///         self.incrementalencoder = incrementalencoder
///         self.incrementaldecoder = incrementaldecoder
///         self.streamwriter = streamwriter
///         self.streamreader = streamreader
///         if _is_text_encoding is not None:
///             self._is_text_encoding = _is_text_encoding
///         return self
///
///     def __repr__(self):
///         return "<%s.%s object for encoding %s at %#x>" % \
///                 (self.__class__.__module__, self.__class__.__qualname__,
///                  self.name, id(self))
///
/// class Codec:
///
///     """ Defines the interface for stateless encoders/decoders.
///
///         The .encode()/.decode() methods may use different error
///         handling schemes by providing the errors argument. These
///         string values are predefined:
///
///          'strict' - raise a ValueError error (or a subclass)
///          'ignore' - ignore the character and continue with the next
///          'replace' - replace with a suitable replacement character;
///                     Python will use the official U+FFFD REPLACEMENT
///                     CHARACTER for the builtin Unicode codecs on
///                     decoding and '?' on encoding.
///          'surrogateescape' - replace with private code points U+DCnn.
///          'xmlcharrefreplace' - Replace with the appropriate XML
///                                character reference (only for encoding).
///          'backslashreplace'  - Replace with backslashed escape sequences.
///          'namereplace'       - Replace with \\N{...} escape sequences
///                                (only for encoding).
///
///         The set of allowed values can be extended via register_error.
///
///     """
///     def encode(self, input, errors='strict'):
///
///         """ Encodes the object input and returns a tuple (output
///             object, length consumed).
///
///             errors defines the error handling to apply. It defaults to
///             'strict' handling.
///
///             The method may not store state in the Codec instance. Use
///             StreamWriter for codecs which have to keep state in order to
///             make encoding efficient.
///
///             The encoder must be able to handle zero length input and
///             return an empty object of the output object type in this
///             situation.
///
///         """
///         raise NotImplementedError
///
///     def decode(self, input, errors='strict'):
///
///         """ Decodes the object input and returns a tuple (output
///             object, length consumed).
///
///             input must be an object which provides the bf_getreadbuf
///             buffer slot. Python strings, buffer objects and memory
///             mapped files are examples of objects providing this slot.
///
///             errors defines the error handling to apply. It defaults to
///             'strict' handling.
///
///             The method may not store state in the Codec instance. Use
///             StreamReader for codecs which have to keep state in order to
///             make decoding efficient.
///
///             The decoder must be able to handle zero length input and
///             return an empty object of the output object type in this
///             situation.
///
///         """
///         raise NotImplementedError
///
/// class IncrementalEncoder(object):
///     """
///     An IncrementalEncoder encodes an input in multiple steps. The input can
///     be passed piece by piece to the encode() method. The IncrementalEncoder
///     remembers the state of the encoding process between calls to encode().
///     """
///     def __init__(self, errors='strict'):
///         """
///         Creates an IncrementalEncoder instance.
///
///         The IncrementalEncoder may use different error handling schemes by
///         providing the errors keyword argument. See the module docstring
///         for a list of possible values.
///         """
///         self.errors = errors
///         self.buffer = ""
///
///     def encode(self, input, final=False):
///         """
///         Encodes input and returns the resulting object.
///         """
///         raise NotImplementedError
///
///     def reset(self):
///         """
///         Resets the encoder to the initial state.
///         """
///
///     def getstate(self):
///         """
///         Return the current state of the encoder.
///         """
///         return 0
///
///     def setstate(self, state):
///         """
///         Set the current state of the encoder. state must have been
///         returned by getstate().
///         """
///
/// class BufferedIncrementalEncoder(IncrementalEncoder):
///     """
///     This subclass of IncrementalEncoder can be used as the baseclass for an
///     incremental encoder if the encoder must keep some of the output in a
///     buffer between calls to encode().
///     """
///     def __init__(self, errors='strict'):
///         IncrementalEncoder.__init__(self, errors)
///         # unencoded input that is kept between calls to encode()
///         self.buffer = ""
///
///     def _buffer_encode(self, input, errors, final):
///         # Overwrite this method in subclasses: It must encode input
///         # and return an (output, length consumed) tuple
///         raise NotImplementedError
///
///     def encode(self, input, final=False):
///         # encode input (taking the buffer into account)
///         data = self.buffer + input
///         (result, consumed) = self._buffer_encode(data, self.errors, final)
///         # keep unencoded input until the next call
///         self.buffer = data[consumed:]
///         return result
///
///     def reset(self):
///         IncrementalEncoder.reset(self)
///         self.buffer = ""
///
///     def getstate(self):
///         return self.buffer or 0
///
///     def setstate(self, state):
///         self.buffer = state or ""
///
/// class IncrementalDecoder(object):
///     """
///     An IncrementalDecoder decodes an input in multiple steps. The input can
///     be passed piece by piece to the decode() method. The IncrementalDecoder
///     remembers the state of the decoding process between calls to decode().
///     """
///     def __init__(self, errors='strict'):
///         """
///         Create an IncrementalDecoder instance.
///
///         The IncrementalDecoder may use different error handling schemes by
///         providing the errors keyword argument. See the module docstring
///         for a list of possible values.
///         """
///         self.errors = errors
///
///     def decode(self, input, final=False):
///         """
///         Decode input and returns the resulting object.
///         """
///         raise NotImplementedError
///
///     def reset(self):
///         """
///         Reset the decoder to the initial state.
///         """
///
///     def getstate(self):
///         """
///         Return the current state of the decoder.
///
///         This must be a (buffered_input, additional_state_info) tuple.
///         buffered_input must be a bytes object containing bytes that
///         were passed to decode() that have not yet been converted.
///         additional_state_info must be a non-negative integer
///         representing the state of the decoder WITHOUT yet having
///         processed the contents of buffered_input.  In the initial state
///         and after reset(), getstate() must return (b"", 0).
///         """
///         return (b"", 0)
///
///     def setstate(self, state):
///         """
///         Set the current state of the decoder.
///
///         state must have been returned by getstate().  The effect of
///         setstate((b"", 0)) must be equivalent to reset().
///         """
///
/// class BufferedIncrementalDecoder(IncrementalDecoder):
///     """
///     This subclass of IncrementalDecoder can be used as the baseclass for an
///     incremental decoder if the decoder must be able to handle incomplete
///     byte sequences.
///     """
///     def __init__(self, errors='strict'):
///         IncrementalDecoder.__init__(self, errors)
///         # undecoded input that is kept between calls to decode()
///         self.buffer = b""
///
///     def _buffer_decode(self, input, errors, final):
///         # Overwrite this method in subclasses: It must decode input
///         # and return an (output, length consumed) tuple
///         raise NotImplementedError
///
///     def decode(self, input, final=False):
///         # decode input (taking the buffer into account)
///         data = self.buffer + input
///         (result, consumed) = self._buffer_decode(data, self.errors, final)
///         # keep undecoded input until the next call
///         self.buffer = data[consumed:]
///         return result
///
///     def reset(self):
///         IncrementalDecoder.reset(self)
///         self.buffer = b""
///
///     def getstate(self):
///         # additional state info is always 0
///         return (self.buffer, 0)
///
///     def setstate(self, state):
///         # ignore additional state info
///         self.buffer = state[0]
///
/// #
/// # The StreamWriter and StreamReader class provide generic working
/// # interfaces which can be used to implement new encoding submodules
/// # very easily. See encodings/utf_8.py for an example on how this is
/// # done.
/// #
///
/// class StreamWriter(Codec):
///
///     def __init__(self, stream, errors='strict'):
///
///         """ Creates a StreamWriter instance.
///
///             stream must be a file-like object open for writing.
///
///             The StreamWriter may use different error handling
///             schemes by providing the errors keyword argument. These
///             parameters are predefined:
///
///              'strict' - raise a ValueError (or a subclass)
///              'ignore' - ignore the character and continue with the next
///              'replace'- replace with a suitable replacement character
///              'xmlcharrefreplace' - Replace with the appropriate XML
///                                    character reference.
///              'backslashreplace'  - Replace with backslashed escape
///                                    sequences.
///              'namereplace'       - Replace with \\N{...} escape sequences.
///
///             The set of allowed parameter values can be extended via
///             register_error.
///         """
///         self.stream = stream
///         self.errors = errors
///
///     def write(self, object):
///
///         """ Writes the object's contents encoded to self.stream.
///         """
///         data, consumed = self.encode(object, self.errors)
///         self.stream.write(data)
///
///     def writelines(self, list):
///
///         """ Writes the concatenated list of strings to the stream
///             using .write().
///         """
///         self.write(''.join(list))
///
///     def reset(self):
///
///         """ Resets the codec buffers used for keeping internal state.
///
///             Calling this method should ensure that the data on the
///             output is put into a clean state, that allows appending
///             of new fresh data without having to rescan the whole
///             stream to recover state.
///
///         """
///         pass
///
///     def seek(self, offset, whence=0):
///         self.stream.seek(offset, whence)
///         if whence == 0 and offset == 0:
///             self.reset()
///
///     def __getattr__(self, name,
///                     getattr=getattr):
///
///         """ Inherit all other methods from the underlying stream.
///         """
///         return getattr(self.stream, name)
///
///     def __enter__(self):
///         return self
///
///     def __exit__(self, type, value, tb):
///         self.stream.close()
///
/// ###
///
/// class StreamReader(Codec):
///
///     charbuffertype = str
///
///     def __init__(self, stream, errors='strict'):
///
///         """ Creates a StreamReader instance.
///
///             stream must be a file-like object open for reading.
///
///             The StreamReader may use different error handling
///             schemes by providing the errors keyword argument. These
///             parameters are predefined:
///
///              'strict' - raise a ValueError (or a subclass)
///              'ignore' - ignore the character and continue with the next
///              'replace'- replace with a suitable replacement character
///              'backslashreplace' - Replace with backslashed escape sequences;
///
///             The set of allowed parameter values can be extended via
///             register_error.
///         """
///         self.stream = stream
///         self.errors = errors
///         self.bytebuffer = b""
///         self._empty_charbuffer = self.charbuffertype()
///         self.charbuffer = self._empty_charbuffer
///         self.linebuffer = None
///
///     def decode(self, input, errors='strict'):
///         raise NotImplementedError
///
///     def read(self, size=-1, chars=-1, firstline=False):
///
///         """ Decodes data from the stream self.stream and returns the
///             resulting object.
///
///             chars indicates the number of decoded code points or bytes to
///             return. read() will never return more data than requested,
///             but it might return less, if there is not enough available.
///
///             size indicates the approximate maximum number of decoded
///             bytes or code points to read for decoding. The decoder
///             can modify this setting as appropriate. The default value
///             -1 indicates to read and decode as much as possible.  size
///             is intended to prevent having to decode huge files in one
///             step.
///
///             If firstline is true, and a UnicodeDecodeError happens
///             after the first line terminator in the input only the first line
///             will be returned, the rest of the input will be kept until the
///             next call to read().
///
///             The method should use a greedy read strategy, meaning that
///             it should read as much data as is allowed within the
///             definition of the encoding and the given size, e.g.  if
///             optional encoding endings or state markers are available
///             on the stream, these should be read too.
///         """
///         # If we have lines cached, first merge them back into characters
///         if self.linebuffer:
///             self.charbuffer = self._empty_charbuffer.join(self.linebuffer)
///             self.linebuffer = None
///
///         if chars < 0:
///             # For compatibility with other read() methods that take a
///             # single argument
///             chars = size
///
///         # read until we get the required number of characters (if available)
///         while True:
///             # can the request be satisfied from the character buffer?
///             if chars >= 0:
///                 if len(self.charbuffer) >= chars:
///                     break
///             # we need more data
///             if size < 0:
///                 newdata = self.stream.read()
///             else:
///                 newdata = self.stream.read(size)
///             # decode bytes (those remaining from the last call included)
///             data = self.bytebuffer + newdata
///             if not data:
///                 break
///             try:
///                 newchars, decodedbytes = self.decode(data, self.errors)
///             except UnicodeDecodeError as exc:
///                 if firstline:
///                     newchars, decodedbytes = \
///                         self.decode(data[:exc.start], self.errors)
///                     lines = newchars.splitlines(keepends=True)
///                     if len(lines)<=1:
///                         raise
///                 else:
///                     raise
///             # keep undecoded bytes until the next call
///             self.bytebuffer = data[decodedbytes:]
///             # put new characters in the character buffer
///             self.charbuffer += newchars
///             # there was no data available
///             if not newdata:
///                 break
///         if chars < 0:
///             # Return everything we've got
///             result = self.charbuffer
///             self.charbuffer = self._empty_charbuffer
///         else:
///             # Return the first chars characters
///             result = self.charbuffer[:chars]
///             self.charbuffer = self.charbuffer[chars:]
///         return result
///
///     def readline(self, size=None, keepends=True):
///
///         """ Read one line from the input stream and return the
///             decoded data.
///
///             size, if given, is passed as size argument to the
///             read() method.
///
///         """
///         # If we have lines cached from an earlier read, return
///         # them unconditionally
///         if self.linebuffer:
///             line = self.linebuffer[0]
///             del self.linebuffer[0]
///             if len(self.linebuffer) == 1:
///                 # revert to charbuffer mode; we might need more data
///                 # next time
///                 self.charbuffer = self.linebuffer[0]
///                 self.linebuffer = None
///             if not keepends:
///                 line = line.splitlines(keepends=False)[0]
///             return line
///
///         readsize = size or 72
///         line = self._empty_charbuffer
///         # If size is given, we call read() only once
///         while True:
///             data = self.read(readsize, firstline=True)
///             if data:
///                 # If we're at a "\r" read one extra character (which might
///                 # be a "\n") to get a proper line ending. If the stream is
///                 # temporarily exhausted we return the wrong line ending.
///                 if (isinstance(data, str) and data.endswith("\r")) or \
///                    (isinstance(data, bytes) and data.endswith(b"\r")):
///                     data += self.read(size=1, chars=1)
///
///             line += data
///             lines = line.splitlines(keepends=True)
///             if lines:
///                 if len(lines) > 1:
///                     # More than one line result; the first line is a full line
///                     # to return
///                     line = lines[0]
///                     del lines[0]
///                     if len(lines) > 1:
///                         # cache the remaining lines
///                         lines[-1] += self.charbuffer
///                         self.linebuffer = lines
///                         self.charbuffer = None
///                     else:
///                         # only one remaining line, put it back into charbuffer
///                         self.charbuffer = lines[0] + self.charbuffer
///                     if not keepends:
///                         line = line.splitlines(keepends=False)[0]
///                     break
///                 line0withend = lines[0]
///                 line0withoutend = lines[0].splitlines(keepends=False)[0]
///                 if line0withend != line0withoutend: # We really have a line end
///                     # Put the rest back together and keep it until the next call
///                     self.charbuffer = self._empty_charbuffer.join(lines[1:]) + \
///                                       self.charbuffer
///                     if keepends:
///                         line = line0withend
///                     else:
///                         line = line0withoutend
///                     break
///             # we didn't get anything or this was our only try
///             if not data or size is not None:
///                 if line and not keepends:
///                     line = line.splitlines(keepends=False)[0]
///                 break
///             if readsize < 8000:
///                 readsize *= 2
///         return line
///
///     def readlines(self, sizehint=None, keepends=True):
///
///         """ Read all lines available on the input stream
///             and return them as a list.
///
///             Line breaks are implemented using the codec's decoder
///             method and are included in the list entries.
///
///             sizehint, if given, is ignored since there is no efficient
///             way to finding the true end-of-line.
///
///         """
///         data = self.read()
///         return data.splitlines(keepends)
///
///     def reset(self):
///
///         """ Resets the codec buffers used for keeping internal state.
///
///             Note that no stream repositioning should take place.
///             This method is primarily intended to be able to recover
///             from decoding errors.
///
///         """
///         self.bytebuffer = b""
///         self.charbuffer = self._empty_charbuffer
///         self.linebuffer = None
///
///     def seek(self, offset, whence=0):
///         """ Set the input stream's current position.
///
///             Resets the codec buffers used for keeping state.
///         """
///         self.stream.seek(offset, whence)
///         self.reset()
///
///     def __next__(self):
///
///         """ Return the next decoded line from the input stream."""
///         line = self.readline()
///         if line:
///             return line
///         raise StopIteration
///
///     def __iter__(self):
///         return self
///
///     def __getattr__(self, name,
///                     getattr=getattr):
///
///         """ Inherit all other methods from the underlying stream.
///         """
///         return getattr(self.stream, name)
///
///     def __enter__(self):
///         return self
///
///     def __exit__(self, type, value, tb):
///         self.stream.close()
///
/// ###
///
/// class StreamReaderWriter:
///
///     """ StreamReaderWriter instances allow wrapping streams which
///         work in both read and write modes.
///
///         The design is such that one can use the factory functions
///         returned by the codec.lookup() function to construct the
///         instance.
///
///     """
///     # Optional attributes set by the file wrappers below
///     encoding = 'unknown'
///
///     def __init__(self, stream, Reader, Writer, errors='strict'):
///
///         """ Creates a StreamReaderWriter instance.
///
///             stream must be a Stream-like object.
///
///             Reader, Writer must be factory functions or classes
///             providing the StreamReader, StreamWriter interface resp.
///
///             Error handling is done in the same way as defined for the
///             StreamWriter/Readers.
///
///         """
///         self.stream = stream
///         self.reader = Reader(stream, errors)
///         self.writer = Writer(stream, errors)
///         self.errors = errors
///
///     def read(self, size=-1):
///
///         return self.reader.read(size)
///
///     def readline(self, size=None):
///
///         return self.reader.readline(size)
///
///     def readlines(self, sizehint=None):
///
///         return self.reader.readlines(sizehint)
///
///     def __next__(self):
///
///         """ Return the next decoded line from the input stream."""
///         return next(self.reader)
///
///     def __iter__(self):
///         return self
///
///     def write(self, data):
///
///         return self.writer.write(data)
///
///     def writelines(self, list):
///
///         return self.writer.writelines(list)
///
///     def reset(self):
///
///         self.reader.reset()
///         self.writer.reset()
///
///     def seek(self, offset, whence=0):
///         self.stream.seek(offset, whence)
///         self.reader.reset()
///         if whence == 0 and offset == 0:
///             self.writer.reset()
///
///     def __getattr__(self, name,
///                     getattr=getattr):
///
///         """ Inherit all other methods from the underlying stream.
///         """
///         return getattr(self.stream, name)
///
///     # these are needed to make "with StreamReaderWriter(...)" work properly
///
///     def __enter__(self):
///         return self
///
///     def __exit__(self, type, value, tb):
///         self.stream.close()
///
/// ###
///
/// class StreamRecoder:
///
///     """ StreamRecoder instances translate data from one encoding to another.
///
///         They use the complete set of APIs returned by the
///         codecs.lookup() function to implement their task.
///
///         Data written to the StreamRecoder is first decoded into an
///         intermediate format (depending on the "decode" codec) and then
///         written to the underlying stream using an instance of the provided
///         Writer class.
///
///         In the other direction, data is read from the underlying stream using
///         a Reader instance and then encoded and returned to the caller.
///
///     """
///     # Optional attributes set by the file wrappers below
///     data_encoding = 'unknown'
///     file_encoding = 'unknown'
///
///     def __init__(self, stream, encode, decode, Reader, Writer,
///                  errors='strict'):
///
///         """ Creates a StreamRecoder instance which implements a two-way
///             conversion: encode and decode work on the frontend (the
///             data visible to .read() and .write()) while Reader and Writer
///             work on the backend (the data in stream).
///
///             You can use these objects to do transparent
///             transcodings from e.g. latin-1 to utf-8 and back.
///
///             stream must be a file-like object.
///
///             encode and decode must adhere to the Codec interface; Reader and
///             Writer must be factory functions or classes providing the
///             StreamReader and StreamWriter interfaces resp.
///
///             Error handling is done in the same way as defined for the
///             StreamWriter/Readers.
///
///         """
///         self.stream = stream
///         self.encode = encode
///         self.decode = decode
///         self.reader = Reader(stream, errors)
///         self.writer = Writer(stream, errors)
///         self.errors = errors
///
///     def read(self, size=-1):
///
///         data = self.reader.read(size)
///         data, bytesencoded = self.encode(data, self.errors)
///         return data
///
///     def readline(self, size=None):
///
///         if size is None:
///             data = self.reader.readline()
///         else:
///             data = self.reader.readline(size)
///         data, bytesencoded = self.encode(data, self.errors)
///         return data
///
///     def readlines(self, sizehint=None):
///
///         data = self.reader.read()
///         data, bytesencoded = self.encode(data, self.errors)
///         return data.splitlines(keepends=True)
///
///     def __next__(self):
///
///         """ Return the next decoded line from the input stream."""
///         data = next(self.reader)
///         data, bytesencoded = self.encode(data, self.errors)
///         return data
///
///     def __iter__(self):
///         return self
///
///     def write(self, data):
///
///         data, bytesdecoded = self.decode(data, self.errors)
///         return self.writer.write(data)
///
///     def writelines(self, list):
///
///         data = b''.join(list)
///         data, bytesdecoded = self.decode(data, self.errors)
///         return self.writer.write(data)
///
///     def reset(self):
///
///         self.reader.reset()
///         self.writer.reset()
///
///     def seek(self, offset, whence=0):
///         # Seeks must be propagated to both the readers and writers
///         # as they might need to reset their internal buffers.
///         self.reader.seek(offset, whence)
///         self.writer.seek(offset, whence)
///
///     def __getattr__(self, name,
///                     getattr=getattr):
///
///         """ Inherit all other methods from the underlying stream.
///         """
///         return getattr(self.stream, name)
///
///     def __enter__(self):
///         return self
///
///     def __exit__(self, type, value, tb):
///         self.stream.close()
///
/// ### Shortcuts
///
/// def open(filename, mode='r', encoding=None, errors='strict', buffering=-1):
///
///     """ Open an encoded file using the given mode and return
///         a wrapped version providing transparent encoding/decoding.
///
///         Note: The wrapped version will only accept the object format
///         defined by the codecs, i.e. Unicode objects for most builtin
///         codecs. Output is also codec dependent and will usually be
///         Unicode as well.
///
///         If encoding is not None, then the
///         underlying encoded files are always opened in binary mode.
///         The default file mode is 'r', meaning to open the file in read mode.
///
///         encoding specifies the encoding which is to be used for the
///         file.
///
///         errors may be given to define the error handling. It defaults
///         to 'strict' which causes ValueErrors to be raised in case an
///         encoding error occurs.
///
///         buffering has the same meaning as for the builtin open() API.
///         It defaults to -1 which means that the default buffer size will
///         be used.
///
///         The returned wrapped file object provides an extra attribute
///         .encoding which allows querying the used encoding. This
///         attribute is only available if an encoding was specified as
///         parameter.
///
///     """
///     if encoding is not None and \
///        'b' not in mode:
///         # Force opening of the file in binary mode
///         mode = mode + 'b'
///     file = builtins.open(filename, mode, buffering)
///     if encoding is None:
///         return file
///
///     try:
///         info = lookup(encoding)
///         srw = StreamReaderWriter(file, info.streamreader, info.streamwriter, errors)
///         # Add attributes to simplify introspection
///         srw.encoding = encoding
///         return srw
///     except:
///         file.close()
///         raise
///
/// def EncodedFile(file, data_encoding, file_encoding=None, errors='strict'):
///
///     """ Return a wrapped version of file which provides transparent
///         encoding translation.
///
///         Data written to the wrapped file is decoded according
///         to the given data_encoding and then encoded to the underlying
///         file using file_encoding. The intermediate data type
///         will usually be Unicode but depends on the specified codecs.
///
///         Bytes read from the file are decoded using file_encoding and then
///         passed back to the caller encoded using data_encoding.
///
///         If file_encoding is not given, it defaults to data_encoding.
///
///         errors may be given to define the error handling. It defaults
///         to 'strict' which causes ValueErrors to be raised in case an
///         encoding error occurs.
///
///         The returned wrapped file object provides two extra attributes
///         .data_encoding and .file_encoding which reflect the given
///         parameters of the same name. The attributes can be used for
///         introspection by Python programs.
///
///     """
///     if file_encoding is None:
///         file_encoding = data_encoding
///     data_info = lookup(data_encoding)
///     file_info = lookup(file_encoding)
///     sr = StreamRecoder(file, data_info.encode, data_info.decode,
///                        file_info.streamreader, file_info.streamwriter, errors)
///     # Add attributes to simplify introspection
///     sr.data_encoding = data_encoding
///     sr.file_encoding = file_encoding
///     return sr
///
/// ### Helpers for codec lookup
///
/// def getencoder(encoding):
///
///     """ Lookup up the codec for the given encoding and return
///         its encoder function.
///
///         Raises a LookupError in case the encoding cannot be found.
///
///     """
///     return lookup(encoding).encode
///
/// def getdecoder(encoding):
///
///     """ Lookup up the codec for the given encoding and return
///         its decoder function.
///
///         Raises a LookupError in case the encoding cannot be found.
///
///     """
///     return lookup(encoding).decode
///
/// def getincrementalencoder(encoding):
///
///     """ Lookup up the codec for the given encoding and return
///         its IncrementalEncoder class or factory function.
///
///         Raises a LookupError in case the encoding cannot be found
///         or the codecs doesn't provide an incremental encoder.
///
///     """
///     encoder = lookup(encoding).incrementalencoder
///     if encoder is None:
///         raise LookupError(encoding)
///     return encoder
///
/// def getincrementaldecoder(encoding):
///
///     """ Lookup up the codec for the given encoding and return
///         its IncrementalDecoder class or factory function.
///
///         Raises a LookupError in case the encoding cannot be found
///         or the codecs doesn't provide an incremental decoder.
///
///     """
///     decoder = lookup(encoding).incrementaldecoder
///     if decoder is None:
///         raise LookupError(encoding)
///     return decoder
///
/// def getreader(encoding):
///
///     """ Lookup up the codec for the given encoding and return
///         its StreamReader class or factory function.
///
///         Raises a LookupError in case the encoding cannot be found.
///
///     """
///     return lookup(encoding).streamreader
///
/// def getwriter(encoding):
///
///     """ Lookup up the codec for the given encoding and return
///         its StreamWriter class or factory function.
///
///         Raises a LookupError in case the encoding cannot be found.
///
///     """
///     return lookup(encoding).streamwriter
///
/// def iterencode(iterator, encoding, errors='strict', **kwargs):
///     """
///     Encoding iterator.
///
///     Encodes the input strings from the iterator using an IncrementalEncoder.
///
///     errors and kwargs are passed through to the IncrementalEncoder
///     constructor.
///     """
///     encoder = getincrementalencoder(encoding)(errors, **kwargs)
///     for input in iterator:
///         output = encoder.encode(input)
///         if output:
///             yield output
///     output = encoder.encode("", True)
///     if output:
///         yield output
///
/// def iterdecode(iterator, encoding, errors='strict', **kwargs):
///     """
///     Decoding iterator.
///
///     Decodes the input strings from the iterator using an IncrementalDecoder.
///
///     errors and kwargs are passed through to the IncrementalDecoder
///     constructor.
///     """
///     decoder = getincrementaldecoder(encoding)(errors, **kwargs)
///     for input in iterator:
///         output = decoder.decode(input)
///         if output:
///             yield output
///     output = decoder.decode(b"", True)
///     if output:
///         yield output
///
/// ### Helpers for charmap-based codecs
///
/// def make_identity_dict(rng):
///
///     """ make_identity_dict(rng) -> dict
///
///         Return a dictionary where elements of the rng sequence are
///         mapped to themselves.
///
///     """
///     return {i:i for i in rng}
///
/// def make_encoding_map(decoding_map):
///
///     """ Creates an encoding map from a decoding map.
///
///         If a target mapping in the decoding map occurs multiple
///         times, then that target is mapped to None (undefined mapping),
///         causing an exception when encountered by the charmap codec
///         during translation.
///
///         One example where this happens is cp875.py which decodes
///         multiple character to \\u001a.
///
///     """
///     m = {}
///     for k,v in decoding_map.items():
///         if not v in m:
///             m[v] = k
///         else:
///             m[v] = None
///     return m
///
/// ### error handlers
///
/// try:
///     strict_errors = lookup_error("strict")
///     ignore_errors = lookup_error("ignore")
///     replace_errors = lookup_error("replace")
///     xmlcharrefreplace_errors = lookup_error("xmlcharrefreplace")
///     backslashreplace_errors = lookup_error("backslashreplace")
///     namereplace_errors = lookup_error("namereplace")
/// except LookupError:
///     # In --disable-unicode builds, these error handler are missing
///     strict_errors = None
///     ignore_errors = None
///     replace_errors = None
///     xmlcharrefreplace_errors = None
///     backslashreplace_errors = None
///     namereplace_errors = None
///
/// # Tell modulefinder that using codecs probably needs the encodings
/// # package
/// _false = 0
/// if _false:
///     import encodings
///
/// ### Tests
///
/// if __name__ == '__main__':
///
///     # Make stdout translate Latin-1 output into UTF-8 output
///     sys.stdout = EncodedFile(sys.stdout, 'latin-1', 'utf-8')
///
///     # Have stdin translate Latin-1 input into UTF-8 input
///     sys.stdin = EncodedFile(sys.stdin, 'utf-8', 'latin-1')
/// ```
final class codecs extends PythonModule {
  codecs.from(super.pythonModule) : super.from();

  static codecs import() => PythonFfiDart.instance.importModule(
        "codecs",
        codecs.from,
      );

  /// ## EncodedFile
  ///
  /// ### python docstring
  ///
  /// Return a wrapped version of file which provides transparent
  /// encoding translation.
  ///
  /// Data written to the wrapped file is decoded according
  /// to the given data_encoding and then encoded to the underlying
  /// file using file_encoding. The intermediate data type
  /// will usually be Unicode but depends on the specified codecs.
  ///
  /// Bytes read from the file are decoded using file_encoding and then
  /// passed back to the caller encoded using data_encoding.
  ///
  /// If file_encoding is not given, it defaults to data_encoding.
  ///
  /// errors may be given to define the error handling. It defaults
  /// to 'strict' which causes ValueErrors to be raised in case an
  /// encoding error occurs.
  ///
  /// The returned wrapped file object provides two extra attributes
  /// .data_encoding and .file_encoding which reflect the given
  /// parameters of the same name. The attributes can be used for
  /// introspection by Python programs.
  Object? EncodedFile({
    required Object? file,
    required Object? data_encoding,
    Object? file_encoding,
    Object? errors = "strict",
  }) =>
      getFunction("EncodedFile").call(
        <Object?>[
          file,
          data_encoding,
          file_encoding,
          errors,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## getdecoder
  ///
  /// ### python docstring
  ///
  /// Lookup up the codec for the given encoding and return
  /// its decoder function.
  ///
  /// Raises a LookupError in case the encoding cannot be found.
  Object? getdecoder({
    required Object? encoding,
  }) =>
      getFunction("getdecoder").call(
        <Object?>[
          encoding,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## getencoder
  ///
  /// ### python docstring
  ///
  /// Lookup up the codec for the given encoding and return
  /// its encoder function.
  ///
  /// Raises a LookupError in case the encoding cannot be found.
  Object? getencoder({
    required Object? encoding,
  }) =>
      getFunction("getencoder").call(
        <Object?>[
          encoding,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## getincrementaldecoder
  ///
  /// ### python docstring
  ///
  /// Lookup up the codec for the given encoding and return
  /// its IncrementalDecoder class or factory function.
  ///
  /// Raises a LookupError in case the encoding cannot be found
  /// or the codecs doesn't provide an incremental decoder.
  Object? getincrementaldecoder({
    required Object? encoding,
  }) =>
      getFunction("getincrementaldecoder").call(
        <Object?>[
          encoding,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## getincrementalencoder
  ///
  /// ### python docstring
  ///
  /// Lookup up the codec for the given encoding and return
  /// its IncrementalEncoder class or factory function.
  ///
  /// Raises a LookupError in case the encoding cannot be found
  /// or the codecs doesn't provide an incremental encoder.
  Object? getincrementalencoder({
    required Object? encoding,
  }) =>
      getFunction("getincrementalencoder").call(
        <Object?>[
          encoding,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## getreader
  ///
  /// ### python docstring
  ///
  /// Lookup up the codec for the given encoding and return
  /// its StreamReader class or factory function.
  ///
  /// Raises a LookupError in case the encoding cannot be found.
  Object? getreader({
    required Object? encoding,
  }) =>
      getFunction("getreader").call(
        <Object?>[
          encoding,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## getwriter
  ///
  /// ### python docstring
  ///
  /// Lookup up the codec for the given encoding and return
  /// its StreamWriter class or factory function.
  ///
  /// Raises a LookupError in case the encoding cannot be found.
  Object? getwriter({
    required Object? encoding,
  }) =>
      getFunction("getwriter").call(
        <Object?>[
          encoding,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## iterdecode
  ///
  /// ### python docstring
  ///
  /// Decoding iterator.
  ///
  /// Decodes the input strings from the iterator using an IncrementalDecoder.
  ///
  /// errors and kwargs are passed through to the IncrementalDecoder
  /// constructor.
  Object? iterdecode({
    required Object? iterator,
    required Object? encoding,
    Object? errors = "strict",
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("iterdecode").call(
        <Object?>[
          iterator,
          encoding,
          errors,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## iterencode
  ///
  /// ### python docstring
  ///
  /// Encoding iterator.
  ///
  /// Encodes the input strings from the iterator using an IncrementalEncoder.
  ///
  /// errors and kwargs are passed through to the IncrementalEncoder
  /// constructor.
  Object? iterencode({
    required Object? iterator,
    required Object? encoding,
    Object? errors = "strict",
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("iterencode").call(
        <Object?>[
          iterator,
          encoding,
          errors,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## make_encoding_map
  ///
  /// ### python docstring
  ///
  /// Creates an encoding map from a decoding map.
  ///
  /// If a target mapping in the decoding map occurs multiple
  /// times, then that target is mapped to None (undefined mapping),
  /// causing an exception when encountered by the charmap codec
  /// during translation.
  ///
  /// One example where this happens is cp875.py which decodes
  /// multiple character to \u001a.
  Object? make_encoding_map({
    required Object? decoding_map,
  }) =>
      getFunction("make_encoding_map").call(
        <Object?>[
          decoding_map,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## make_identity_dict
  ///
  /// ### python docstring
  ///
  /// make_identity_dict(rng) -> dict
  ///
  /// Return a dictionary where elements of the rng sequence are
  /// mapped to themselves.
  Object? make_identity_dict({
    required Object? rng,
  }) =>
      getFunction("make_identity_dict").call(
        <Object?>[
          rng,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## open
  ///
  /// ### python docstring
  ///
  /// Open an encoded file using the given mode and return
  /// a wrapped version providing transparent encoding/decoding.
  ///
  /// Note: The wrapped version will only accept the object format
  /// defined by the codecs, i.e. Unicode objects for most builtin
  /// codecs. Output is also codec dependent and will usually be
  /// Unicode as well.
  ///
  /// If encoding is not None, then the
  /// underlying encoded files are always opened in binary mode.
  /// The default file mode is 'r', meaning to open the file in read mode.
  ///
  /// encoding specifies the encoding which is to be used for the
  /// file.
  ///
  /// errors may be given to define the error handling. It defaults
  /// to 'strict' which causes ValueErrors to be raised in case an
  /// encoding error occurs.
  ///
  /// buffering has the same meaning as for the builtin open() API.
  /// It defaults to -1 which means that the default buffer size will
  /// be used.
  ///
  /// The returned wrapped file object provides an extra attribute
  /// .encoding which allows querying the used encoding. This
  /// attribute is only available if an encoding was specified as
  /// parameter.
  Object? open({
    required Object? filename,
    Object? mode = "r",
    Object? encoding,
    Object? errors = "strict",
    Object? buffering = -1,
  }) =>
      getFunction("open").call(
        <Object?>[
          filename,
          mode,
          encoding,
          errors,
          buffering,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## BOM (getter)
  Object? get BOM => getAttribute("BOM");

  /// ## BOM (setter)
  set BOM(Object? BOM) => setAttribute("BOM", BOM);

  /// ## BOM32_BE (getter)
  Object? get BOM32_BE => getAttribute("BOM32_BE");

  /// ## BOM32_BE (setter)
  set BOM32_BE(Object? BOM32_BE) => setAttribute("BOM32_BE", BOM32_BE);

  /// ## BOM32_LE (getter)
  Object? get BOM32_LE => getAttribute("BOM32_LE");

  /// ## BOM32_LE (setter)
  set BOM32_LE(Object? BOM32_LE) => setAttribute("BOM32_LE", BOM32_LE);

  /// ## BOM64_BE (getter)
  Object? get BOM64_BE => getAttribute("BOM64_BE");

  /// ## BOM64_BE (setter)
  set BOM64_BE(Object? BOM64_BE) => setAttribute("BOM64_BE", BOM64_BE);

  /// ## BOM64_LE (getter)
  Object? get BOM64_LE => getAttribute("BOM64_LE");

  /// ## BOM64_LE (setter)
  set BOM64_LE(Object? BOM64_LE) => setAttribute("BOM64_LE", BOM64_LE);

  /// ## BOM_BE (getter)
  Object? get BOM_BE => getAttribute("BOM_BE");

  /// ## BOM_BE (setter)
  set BOM_BE(Object? BOM_BE) => setAttribute("BOM_BE", BOM_BE);

  /// ## BOM_LE (getter)
  Object? get BOM_LE => getAttribute("BOM_LE");

  /// ## BOM_LE (setter)
  set BOM_LE(Object? BOM_LE) => setAttribute("BOM_LE", BOM_LE);

  /// ## BOM_UTF16 (getter)
  Object? get BOM_UTF16 => getAttribute("BOM_UTF16");

  /// ## BOM_UTF16 (setter)
  set BOM_UTF16(Object? BOM_UTF16) => setAttribute("BOM_UTF16", BOM_UTF16);

  /// ## BOM_UTF16_BE (getter)
  Object? get BOM_UTF16_BE => getAttribute("BOM_UTF16_BE");

  /// ## BOM_UTF16_BE (setter)
  set BOM_UTF16_BE(Object? BOM_UTF16_BE) =>
      setAttribute("BOM_UTF16_BE", BOM_UTF16_BE);

  /// ## BOM_UTF16_LE (getter)
  Object? get BOM_UTF16_LE => getAttribute("BOM_UTF16_LE");

  /// ## BOM_UTF16_LE (setter)
  set BOM_UTF16_LE(Object? BOM_UTF16_LE) =>
      setAttribute("BOM_UTF16_LE", BOM_UTF16_LE);

  /// ## BOM_UTF32 (getter)
  Object? get BOM_UTF32 => getAttribute("BOM_UTF32");

  /// ## BOM_UTF32 (setter)
  set BOM_UTF32(Object? BOM_UTF32) => setAttribute("BOM_UTF32", BOM_UTF32);

  /// ## BOM_UTF32_BE (getter)
  Object? get BOM_UTF32_BE => getAttribute("BOM_UTF32_BE");

  /// ## BOM_UTF32_BE (setter)
  set BOM_UTF32_BE(Object? BOM_UTF32_BE) =>
      setAttribute("BOM_UTF32_BE", BOM_UTF32_BE);

  /// ## BOM_UTF32_LE (getter)
  Object? get BOM_UTF32_LE => getAttribute("BOM_UTF32_LE");

  /// ## BOM_UTF32_LE (setter)
  set BOM_UTF32_LE(Object? BOM_UTF32_LE) =>
      setAttribute("BOM_UTF32_LE", BOM_UTF32_LE);

  /// ## BOM_UTF8 (getter)
  Object? get BOM_UTF8 => getAttribute("BOM_UTF8");

  /// ## BOM_UTF8 (setter)
  set BOM_UTF8(Object? BOM_UTF8) => setAttribute("BOM_UTF8", BOM_UTF8);
}

/// ## builtins
final class builtins extends PythonModule {
  builtins.from(super.pythonModule) : super.from();

  static builtins import() => PythonFfiDart.instance.importModule(
        "builtins",
        builtins.from,
      );

  /// ## False (getter)
  Object? get False => getAttribute("False");

  /// ## False (setter)
  set False(Object? False) => setAttribute("False", False);

  /// ## None (getter)
  Object? get None => getAttribute("None");

  /// ## None (setter)
  set None(Object? None) => setAttribute("None", None);

  /// ## True (getter)
  Object? get True => getAttribute("True");

  /// ## True (setter)
  set True(Object? True) => setAttribute("True", True);
}

/// ## re
///
/// ### python docstring
///
/// Support for regular expressions (RE).
///
/// This module provides regular expression matching operations similar to
/// those found in Perl.  It supports both 8-bit and Unicode strings; both
/// the pattern and the strings being processed can contain null bytes and
/// characters outside the US ASCII range.
///
/// Regular expressions can contain both special and ordinary characters.
/// Most ordinary characters, like "A", "a", or "0", are the simplest
/// regular expressions; they simply match themselves.  You can
/// concatenate ordinary characters, so last matches the string 'last'.
///
/// The special characters are:
///     "."      Matches any character except a newline.
///     "^"      Matches the start of the string.
///     "$"      Matches the end of the string or just before the newline at
///              the end of the string.
///     "*"      Matches 0 or more (greedy) repetitions of the preceding RE.
///              Greedy means that it will match as many repetitions as possible.
///     "+"      Matches 1 or more (greedy) repetitions of the preceding RE.
///     "?"      Matches 0 or 1 (greedy) of the preceding RE.
///     *?,+?,?? Non-greedy versions of the previous three special characters.
///     {m,n}    Matches from m to n repetitions of the preceding RE.
///     {m,n}?   Non-greedy version of the above.
///     "\\"     Either escapes special characters or signals a special sequence.
///     []       Indicates a set of characters.
///              A "^" as the first character indicates a complementing set.
///     "|"      A|B, creates an RE that will match either A or B.
///     (...)    Matches the RE inside the parentheses.
///              The contents can be retrieved or matched later in the string.
///     (?aiLmsux) The letters set the corresponding flags defined below.
///     (?:...)  Non-grouping version of regular parentheses.
///     (?P<name>...) The substring matched by the group is accessible by name.
///     (?P=name)     Matches the text matched earlier by the group named name.
///     (?#...)  A comment; ignored.
///     (?=...)  Matches if ... matches next, but doesn't consume the string.
///     (?!...)  Matches if ... doesn't match next.
///     (?<=...) Matches if preceded by ... (must be fixed length).
///     (?<!...) Matches if not preceded by ... (must be fixed length).
///     (?(id/name)yes|no) Matches yes pattern if the group with id/name matched,
///                        the (optional) no pattern otherwise.
///
/// The special sequences consist of "\\" and a character from the list
/// below.  If the ordinary character is not on the list, then the
/// resulting RE will match the second character.
///     \number  Matches the contents of the group of the same number.
///     \A       Matches only at the start of the string.
///     \Z       Matches only at the end of the string.
///     \b       Matches the empty string, but only at the start or end of a word.
///     \B       Matches the empty string, but not at the start or end of a word.
///     \d       Matches any decimal digit; equivalent to the set [0-9] in
///              bytes patterns or string patterns with the ASCII flag.
///              In string patterns without the ASCII flag, it will match the whole
///              range of Unicode digits.
///     \D       Matches any non-digit character; equivalent to [^\d].
///     \s       Matches any whitespace character; equivalent to [ \t\n\r\f\v] in
///              bytes patterns or string patterns with the ASCII flag.
///              In string patterns without the ASCII flag, it will match the whole
///              range of Unicode whitespace characters.
///     \S       Matches any non-whitespace character; equivalent to [^\s].
///     \w       Matches any alphanumeric character; equivalent to [a-zA-Z0-9_]
///              in bytes patterns or string patterns with the ASCII flag.
///              In string patterns without the ASCII flag, it will match the
///              range of Unicode alphanumeric characters (letters plus digits
///              plus underscore).
///              With LOCALE, it will match the set [0-9_] plus characters defined
///              as letters for the current locale.
///     \W       Matches the complement of \w.
///     \\       Matches a literal backslash.
///
/// This module exports the following functions:
///     match     Match a regular expression pattern to the beginning of a string.
///     fullmatch Match a regular expression pattern to all of a string.
///     search    Search a string for the presence of a pattern.
///     sub       Substitute occurrences of a pattern found in a string.
///     subn      Same as sub, but also return the number of substitutions made.
///     split     Split a string by the occurrences of a pattern.
///     findall   Find all occurrences of a pattern in a string.
///     finditer  Return an iterator yielding a Match object for each match.
///     compile   Compile a pattern into a Pattern object.
///     purge     Clear the regular expression cache.
///     escape    Backslash all non-alphanumerics in a string.
///
/// Each function other than purge and escape can take an optional 'flags' argument
/// consisting of one or more of the following module constants, joined by "|".
/// A, L, and U are mutually exclusive.
///     A  ASCII       For string patterns, make \w, \W, \b, \B, \d, \D
///                    match the corresponding ASCII character categories
///                    (rather than the whole Unicode categories, which is the
///                    default).
///                    For bytes patterns, this flag is the only available
///                    behaviour and needn't be specified.
///     I  IGNORECASE  Perform case-insensitive matching.
///     L  LOCALE      Make \w, \W, \b, \B, dependent on the current locale.
///     M  MULTILINE   "^" matches the beginning of lines (after a newline)
///                    as well as the string.
///                    "$" matches the end of lines (before a newline) as well
///                    as the end of the string.
///     S  DOTALL      "." matches any character at all, including the newline.
///     X  VERBOSE     Ignore whitespace and comments for nicer looking RE's.
///     U  UNICODE     For compatibility only. Ignored for string patterns (it
///                    is the default), and forbidden for bytes patterns.
///
/// This module also defines an exception 'error'.
///
/// ### python source
/// ```py
/// #
/// # Secret Labs' Regular Expression Engine
/// #
/// # re-compatible interface for the sre matching engine
/// #
/// # Copyright (c) 1998-2001 by Secret Labs AB.  All rights reserved.
/// #
/// # This version of the SRE library can be redistributed under CNRI's
/// # Python 1.6 license.  For any other use, please contact Secret Labs
/// # AB (info@pythonware.com).
/// #
/// # Portions of this engine have been developed in cooperation with
/// # CNRI.  Hewlett-Packard provided funding for 1.6 integration and
/// # other compatibility work.
/// #
///
/// r"""Support for regular expressions (RE).
///
/// This module provides regular expression matching operations similar to
/// those found in Perl.  It supports both 8-bit and Unicode strings; both
/// the pattern and the strings being processed can contain null bytes and
/// characters outside the US ASCII range.
///
/// Regular expressions can contain both special and ordinary characters.
/// Most ordinary characters, like "A", "a", or "0", are the simplest
/// regular expressions; they simply match themselves.  You can
/// concatenate ordinary characters, so last matches the string 'last'.
///
/// The special characters are:
///     "."      Matches any character except a newline.
///     "^"      Matches the start of the string.
///     "$"      Matches the end of the string or just before the newline at
///              the end of the string.
///     "*"      Matches 0 or more (greedy) repetitions of the preceding RE.
///              Greedy means that it will match as many repetitions as possible.
///     "+"      Matches 1 or more (greedy) repetitions of the preceding RE.
///     "?"      Matches 0 or 1 (greedy) of the preceding RE.
///     *?,+?,?? Non-greedy versions of the previous three special characters.
///     {m,n}    Matches from m to n repetitions of the preceding RE.
///     {m,n}?   Non-greedy version of the above.
///     "\\"     Either escapes special characters or signals a special sequence.
///     []       Indicates a set of characters.
///              A "^" as the first character indicates a complementing set.
///     "|"      A|B, creates an RE that will match either A or B.
///     (...)    Matches the RE inside the parentheses.
///              The contents can be retrieved or matched later in the string.
///     (?aiLmsux) The letters set the corresponding flags defined below.
///     (?:...)  Non-grouping version of regular parentheses.
///     (?P<name>...) The substring matched by the group is accessible by name.
///     (?P=name)     Matches the text matched earlier by the group named name.
///     (?#...)  A comment; ignored.
///     (?=...)  Matches if ... matches next, but doesn't consume the string.
///     (?!...)  Matches if ... doesn't match next.
///     (?<=...) Matches if preceded by ... (must be fixed length).
///     (?<!...) Matches if not preceded by ... (must be fixed length).
///     (?(id/name)yes|no) Matches yes pattern if the group with id/name matched,
///                        the (optional) no pattern otherwise.
///
/// The special sequences consist of "\\" and a character from the list
/// below.  If the ordinary character is not on the list, then the
/// resulting RE will match the second character.
///     \number  Matches the contents of the group of the same number.
///     \A       Matches only at the start of the string.
///     \Z       Matches only at the end of the string.
///     \b       Matches the empty string, but only at the start or end of a word.
///     \B       Matches the empty string, but not at the start or end of a word.
///     \d       Matches any decimal digit; equivalent to the set [0-9] in
///              bytes patterns or string patterns with the ASCII flag.
///              In string patterns without the ASCII flag, it will match the whole
///              range of Unicode digits.
///     \D       Matches any non-digit character; equivalent to [^\d].
///     \s       Matches any whitespace character; equivalent to [ \t\n\r\f\v] in
///              bytes patterns or string patterns with the ASCII flag.
///              In string patterns without the ASCII flag, it will match the whole
///              range of Unicode whitespace characters.
///     \S       Matches any non-whitespace character; equivalent to [^\s].
///     \w       Matches any alphanumeric character; equivalent to [a-zA-Z0-9_]
///              in bytes patterns or string patterns with the ASCII flag.
///              In string patterns without the ASCII flag, it will match the
///              range of Unicode alphanumeric characters (letters plus digits
///              plus underscore).
///              With LOCALE, it will match the set [0-9_] plus characters defined
///              as letters for the current locale.
///     \W       Matches the complement of \w.
///     \\       Matches a literal backslash.
///
/// This module exports the following functions:
///     match     Match a regular expression pattern to the beginning of a string.
///     fullmatch Match a regular expression pattern to all of a string.
///     search    Search a string for the presence of a pattern.
///     sub       Substitute occurrences of a pattern found in a string.
///     subn      Same as sub, but also return the number of substitutions made.
///     split     Split a string by the occurrences of a pattern.
///     findall   Find all occurrences of a pattern in a string.
///     finditer  Return an iterator yielding a Match object for each match.
///     compile   Compile a pattern into a Pattern object.
///     purge     Clear the regular expression cache.
///     escape    Backslash all non-alphanumerics in a string.
///
/// Each function other than purge and escape can take an optional 'flags' argument
/// consisting of one or more of the following module constants, joined by "|".
/// A, L, and U are mutually exclusive.
///     A  ASCII       For string patterns, make \w, \W, \b, \B, \d, \D
///                    match the corresponding ASCII character categories
///                    (rather than the whole Unicode categories, which is the
///                    default).
///                    For bytes patterns, this flag is the only available
///                    behaviour and needn't be specified.
///     I  IGNORECASE  Perform case-insensitive matching.
///     L  LOCALE      Make \w, \W, \b, \B, dependent on the current locale.
///     M  MULTILINE   "^" matches the beginning of lines (after a newline)
///                    as well as the string.
///                    "$" matches the end of lines (before a newline) as well
///                    as the end of the string.
///     S  DOTALL      "." matches any character at all, including the newline.
///     X  VERBOSE     Ignore whitespace and comments for nicer looking RE's.
///     U  UNICODE     For compatibility only. Ignored for string patterns (it
///                    is the default), and forbidden for bytes patterns.
///
/// This module also defines an exception 'error'.
///
/// """
///
/// import enum
/// from . import _compiler, _parser
/// import functools
///
///
/// # public symbols
/// __all__ = [
///     "match", "fullmatch", "search", "sub", "subn", "split",
///     "findall", "finditer", "compile", "purge", "template", "escape",
///     "error", "Pattern", "Match", "A", "I", "L", "M", "S", "X", "U",
///     "ASCII", "IGNORECASE", "LOCALE", "MULTILINE", "DOTALL", "VERBOSE",
///     "UNICODE", "NOFLAG", "RegexFlag",
/// ]
///
/// __version__ = "2.2.1"
///
/// @enum.global_enum
/// @enum._simple_enum(enum.IntFlag, boundary=enum.KEEP)
/// class RegexFlag:
///     NOFLAG = 0
///     ASCII = A = _compiler.SRE_FLAG_ASCII # assume ascii "locale"
///     IGNORECASE = I = _compiler.SRE_FLAG_IGNORECASE # ignore case
///     LOCALE = L = _compiler.SRE_FLAG_LOCALE # assume current 8-bit locale
///     UNICODE = U = _compiler.SRE_FLAG_UNICODE # assume unicode "locale"
///     MULTILINE = M = _compiler.SRE_FLAG_MULTILINE # make anchors look for newline
///     DOTALL = S = _compiler.SRE_FLAG_DOTALL # make dot match newline
///     VERBOSE = X = _compiler.SRE_FLAG_VERBOSE # ignore whitespace and comments
///     # sre extensions (experimental, don't rely on these)
///     TEMPLATE = T = _compiler.SRE_FLAG_TEMPLATE # unknown purpose, deprecated
///     DEBUG = _compiler.SRE_FLAG_DEBUG # dump pattern after compilation
///     __str__ = object.__str__
///     _numeric_repr_ = hex
///
/// # sre exception
/// error = _compiler.error
///
/// # --------------------------------------------------------------------
/// # public interface
///
/// def match(pattern, string, flags=0):
///     """Try to apply the pattern at the start of the string, returning
///     a Match object, or None if no match was found."""
///     return _compile(pattern, flags).match(string)
///
/// def fullmatch(pattern, string, flags=0):
///     """Try to apply the pattern to all of the string, returning
///     a Match object, or None if no match was found."""
///     return _compile(pattern, flags).fullmatch(string)
///
/// def search(pattern, string, flags=0):
///     """Scan through string looking for a match to the pattern, returning
///     a Match object, or None if no match was found."""
///     return _compile(pattern, flags).search(string)
///
/// def sub(pattern, repl, string, count=0, flags=0):
///     """Return the string obtained by replacing the leftmost
///     non-overlapping occurrences of the pattern in string by the
///     replacement repl.  repl can be either a string or a callable;
///     if a string, backslash escapes in it are processed.  If it is
///     a callable, it's passed the Match object and must return
///     a replacement string to be used."""
///     return _compile(pattern, flags).sub(repl, string, count)
///
/// def subn(pattern, repl, string, count=0, flags=0):
///     """Return a 2-tuple containing (new_string, number).
///     new_string is the string obtained by replacing the leftmost
///     non-overlapping occurrences of the pattern in the source
///     string by the replacement repl.  number is the number of
///     substitutions that were made. repl can be either a string or a
///     callable; if a string, backslash escapes in it are processed.
///     If it is a callable, it's passed the Match object and must
///     return a replacement string to be used."""
///     return _compile(pattern, flags).subn(repl, string, count)
///
/// def split(pattern, string, maxsplit=0, flags=0):
///     """Split the source string by the occurrences of the pattern,
///     returning a list containing the resulting substrings.  If
///     capturing parentheses are used in pattern, then the text of all
///     groups in the pattern are also returned as part of the resulting
///     list.  If maxsplit is nonzero, at most maxsplit splits occur,
///     and the remainder of the string is returned as the final element
///     of the list."""
///     return _compile(pattern, flags).split(string, maxsplit)
///
/// def findall(pattern, string, flags=0):
///     """Return a list of all non-overlapping matches in the string.
///
///     If one or more capturing groups are present in the pattern, return
///     a list of groups; this will be a list of tuples if the pattern
///     has more than one group.
///
///     Empty matches are included in the result."""
///     return _compile(pattern, flags).findall(string)
///
/// def finditer(pattern, string, flags=0):
///     """Return an iterator over all non-overlapping matches in the
///     string.  For each match, the iterator returns a Match object.
///
///     Empty matches are included in the result."""
///     return _compile(pattern, flags).finditer(string)
///
/// def compile(pattern, flags=0):
///     "Compile a regular expression pattern, returning a Pattern object."
///     return _compile(pattern, flags)
///
/// def purge():
///     "Clear the regular expression caches"
///     _cache.clear()
///     _compile_repl.cache_clear()
///
/// def template(pattern, flags=0):
///     "Compile a template pattern, returning a Pattern object, deprecated"
///     import warnings
///     warnings.warn("The re.template() function is deprecated "
///                   "as it is an undocumented function "
///                   "without an obvious purpose. "
///                   "Use re.compile() instead.",
///                   DeprecationWarning)
///     with warnings.catch_warnings():
///         warnings.simplefilter("ignore", DeprecationWarning)  # warn just once
///         return _compile(pattern, flags|T)
///
/// # SPECIAL_CHARS
/// # closing ')', '}' and ']'
/// # '-' (a range in character set)
/// # '&', '~', (extended character set operations)
/// # '#' (comment) and WHITESPACE (ignored) in verbose mode
/// _special_chars_map = {i: '\\' + chr(i) for i in b'()[]{}?*+-|^$\\.&~# \t\n\r\v\f'}
///
/// def escape(pattern):
///     """
///     Escape special characters in a string.
///     """
///     if isinstance(pattern, str):
///         return pattern.translate(_special_chars_map)
///     else:
///         pattern = str(pattern, 'latin1')
///         return pattern.translate(_special_chars_map).encode('latin1')
///
/// Pattern = type(_compiler.compile('', 0))
/// Match = type(_compiler.compile('', 0).match(''))
///
/// # --------------------------------------------------------------------
/// # internals
///
/// _cache = {}  # ordered!
///
/// _MAXCACHE = 512
/// def _compile(pattern, flags):
///     # internal: compile pattern
///     if isinstance(flags, RegexFlag):
///         flags = flags.value
///     try:
///         return _cache[type(pattern), pattern, flags]
///     except KeyError:
///         pass
///     if isinstance(pattern, Pattern):
///         if flags:
///             raise ValueError(
///                 "cannot process flags argument with a compiled pattern")
///         return pattern
///     if not _compiler.isstring(pattern):
///         raise TypeError("first argument must be string or compiled pattern")
///     if flags & T:
///         import warnings
///         warnings.warn("The re.TEMPLATE/re.T flag is deprecated "
///                   "as it is an undocumented flag "
///                   "without an obvious purpose. "
///                   "Don't use it.",
///                   DeprecationWarning)
///     p = _compiler.compile(pattern, flags)
///     if not (flags & DEBUG):
///         if len(_cache) >= _MAXCACHE:
///             # Drop the oldest item
///             try:
///                 del _cache[next(iter(_cache))]
///             except (StopIteration, RuntimeError, KeyError):
///                 pass
///         _cache[type(pattern), pattern, flags] = p
///     return p
///
/// @functools.lru_cache(_MAXCACHE)
/// def _compile_repl(repl, pattern):
///     # internal: compile replacement pattern
///     return _parser.parse_template(repl, pattern)
///
/// def _expand(pattern, match, template):
///     # internal: Match.expand implementation hook
///     template = _parser.parse_template(template, pattern)
///     return _parser.expand_template(template, match)
///
/// def _subx(pattern, template):
///     # internal: Pattern.sub/subn implementation helper
///     template = _compile_repl(template, pattern)
///     if not template[0] and len(template[1]) == 1:
///         # literal replacement
///         return template[1][0]
///     def filter(match, template=template):
///         return _parser.expand_template(template, match)
///     return filter
///
/// # register myself for pickling
///
/// import copyreg
///
/// def _pickle(p):
///     return _compile, (p.pattern, p.flags)
///
/// copyreg.pickle(Pattern, _pickle, _compile)
///
/// # --------------------------------------------------------------------
/// # experimental stuff (see python-dev discussions for details)
///
/// class Scanner:
///     def __init__(self, lexicon, flags=0):
///         from ._constants import BRANCH, SUBPATTERN
///         if isinstance(flags, RegexFlag):
///             flags = flags.value
///         self.lexicon = lexicon
///         # combine phrases into a compound pattern
///         p = []
///         s = _parser.State()
///         s.flags = flags
///         for phrase, action in lexicon:
///             gid = s.opengroup()
///             p.append(_parser.SubPattern(s, [
///                 (SUBPATTERN, (gid, 0, 0, _parser.parse(phrase, flags))),
///                 ]))
///             s.closegroup(gid, p[-1])
///         p = _parser.SubPattern(s, [(BRANCH, (None, p))])
///         self.scanner = _compiler.compile(p)
///     def scan(self, string):
///         result = []
///         append = result.append
///         match = self.scanner.scanner(string).match
///         i = 0
///         while True:
///             m = match()
///             if not m:
///                 break
///             j = m.end()
///             if i == j:
///                 break
///             action = self.lexicon[m.lastindex-1][1]
///             if callable(action):
///                 self.match = m
///                 action = action(self, m.group())
///             if action is not None:
///                 append(action)
///             i = j
///         return result, string[i:]
/// ```
final class re extends PythonModule {
  re.from(super.pythonModule) : super.from();

  static re import() => PythonFfiDart.instance.importModule(
        "re",
        re.from,
      );

  /// ## compile
  ///
  /// ### python docstring
  ///
  /// Compile a regular expression pattern, returning a Pattern object.
  ///
  /// ### python source
  /// ```py
  /// def compile(pattern, flags=0):
  ///     "Compile a regular expression pattern, returning a Pattern object."
  ///     return _compile(pattern, flags)
  /// ```
  Object? compile({
    required Object? pattern,
    Object? flags = 0,
  }) =>
      getFunction("compile").call(
        <Object?>[
          pattern,
          flags,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## escape
  ///
  /// ### python docstring
  ///
  /// Escape special characters in a string.
  ///
  /// ### python source
  /// ```py
  /// def escape(pattern):
  ///     """
  ///     Escape special characters in a string.
  ///     """
  ///     if isinstance(pattern, str):
  ///         return pattern.translate(_special_chars_map)
  ///     else:
  ///         pattern = str(pattern, 'latin1')
  ///         return pattern.translate(_special_chars_map).encode('latin1')
  /// ```
  Object? escape({
    required Object? pattern,
  }) =>
      getFunction("escape").call(
        <Object?>[
          pattern,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## findall
  ///
  /// ### python docstring
  ///
  /// Return a list of all non-overlapping matches in the string.
  ///
  /// If one or more capturing groups are present in the pattern, return
  /// a list of groups; this will be a list of tuples if the pattern
  /// has more than one group.
  ///
  /// Empty matches are included in the result.
  ///
  /// ### python source
  /// ```py
  /// def findall(pattern, string, flags=0):
  ///     """Return a list of all non-overlapping matches in the string.
  ///
  ///     If one or more capturing groups are present in the pattern, return
  ///     a list of groups; this will be a list of tuples if the pattern
  ///     has more than one group.
  ///
  ///     Empty matches are included in the result."""
  ///     return _compile(pattern, flags).findall(string)
  /// ```
  Object? findall({
    required Object? pattern,
    required Object? string,
    Object? flags = 0,
  }) =>
      getFunction("findall").call(
        <Object?>[
          pattern,
          string,
          flags,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## finditer
  ///
  /// ### python docstring
  ///
  /// Return an iterator over all non-overlapping matches in the
  /// string.  For each match, the iterator returns a Match object.
  ///
  /// Empty matches are included in the result.
  ///
  /// ### python source
  /// ```py
  /// def finditer(pattern, string, flags=0):
  ///     """Return an iterator over all non-overlapping matches in the
  ///     string.  For each match, the iterator returns a Match object.
  ///
  ///     Empty matches are included in the result."""
  ///     return _compile(pattern, flags).finditer(string)
  /// ```
  Object? finditer({
    required Object? pattern,
    required Object? string,
    Object? flags = 0,
  }) =>
      getFunction("finditer").call(
        <Object?>[
          pattern,
          string,
          flags,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## fullmatch
  ///
  /// ### python docstring
  ///
  /// Try to apply the pattern to all of the string, returning
  /// a Match object, or None if no match was found.
  ///
  /// ### python source
  /// ```py
  /// def fullmatch(pattern, string, flags=0):
  ///     """Try to apply the pattern to all of the string, returning
  ///     a Match object, or None if no match was found."""
  ///     return _compile(pattern, flags).fullmatch(string)
  /// ```
  Object? fullmatch({
    required Object? pattern,
    required Object? string,
    Object? flags = 0,
  }) =>
      getFunction("fullmatch").call(
        <Object?>[
          pattern,
          string,
          flags,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## match
  ///
  /// ### python docstring
  ///
  /// Try to apply the pattern at the start of the string, returning
  /// a Match object, or None if no match was found.
  ///
  /// ### python source
  /// ```py
  /// def match(pattern, string, flags=0):
  ///     """Try to apply the pattern at the start of the string, returning
  ///     a Match object, or None if no match was found."""
  ///     return _compile(pattern, flags).match(string)
  /// ```
  Object? match({
    required Object? pattern,
    required Object? string,
    Object? flags = 0,
  }) =>
      getFunction("match").call(
        <Object?>[
          pattern,
          string,
          flags,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## purge
  ///
  /// ### python docstring
  ///
  /// Clear the regular expression caches
  ///
  /// ### python source
  /// ```py
  /// def purge():
  ///     "Clear the regular expression caches"
  ///     _cache.clear()
  ///     _compile_repl.cache_clear()
  /// ```
  Object? purge() => getFunction("purge").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## search
  ///
  /// ### python docstring
  ///
  /// Scan through string looking for a match to the pattern, returning
  /// a Match object, or None if no match was found.
  ///
  /// ### python source
  /// ```py
  /// def search(pattern, string, flags=0):
  ///     """Scan through string looking for a match to the pattern, returning
  ///     a Match object, or None if no match was found."""
  ///     return _compile(pattern, flags).search(string)
  /// ```
  Object? search({
    required Object? pattern,
    required Object? string,
    Object? flags = 0,
  }) =>
      getFunction("search").call(
        <Object?>[
          pattern,
          string,
          flags,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## split
  ///
  /// ### python docstring
  ///
  /// Split the source string by the occurrences of the pattern,
  /// returning a list containing the resulting substrings.  If
  /// capturing parentheses are used in pattern, then the text of all
  /// groups in the pattern are also returned as part of the resulting
  /// list.  If maxsplit is nonzero, at most maxsplit splits occur,
  /// and the remainder of the string is returned as the final element
  /// of the list.
  ///
  /// ### python source
  /// ```py
  /// def split(pattern, string, maxsplit=0, flags=0):
  ///     """Split the source string by the occurrences of the pattern,
  ///     returning a list containing the resulting substrings.  If
  ///     capturing parentheses are used in pattern, then the text of all
  ///     groups in the pattern are also returned as part of the resulting
  ///     list.  If maxsplit is nonzero, at most maxsplit splits occur,
  ///     and the remainder of the string is returned as the final element
  ///     of the list."""
  ///     return _compile(pattern, flags).split(string, maxsplit)
  /// ```
  Object? split({
    required Object? pattern,
    required Object? string,
    Object? maxsplit = 0,
    Object? flags = 0,
  }) =>
      getFunction("split").call(
        <Object?>[
          pattern,
          string,
          maxsplit,
          flags,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## sub
  ///
  /// ### python docstring
  ///
  /// Return the string obtained by replacing the leftmost
  /// non-overlapping occurrences of the pattern in string by the
  /// replacement repl.  repl can be either a string or a callable;
  /// if a string, backslash escapes in it are processed.  If it is
  /// a callable, it's passed the Match object and must return
  /// a replacement string to be used.
  ///
  /// ### python source
  /// ```py
  /// def sub(pattern, repl, string, count=0, flags=0):
  ///     """Return the string obtained by replacing the leftmost
  ///     non-overlapping occurrences of the pattern in string by the
  ///     replacement repl.  repl can be either a string or a callable;
  ///     if a string, backslash escapes in it are processed.  If it is
  ///     a callable, it's passed the Match object and must return
  ///     a replacement string to be used."""
  ///     return _compile(pattern, flags).sub(repl, string, count)
  /// ```
  Object? sub({
    required Object? pattern,
    required Object? repl,
    required Object? string,
    Object? count = 0,
    Object? flags = 0,
  }) =>
      getFunction("sub").call(
        <Object?>[
          pattern,
          repl,
          string,
          count,
          flags,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## subn
  ///
  /// ### python docstring
  ///
  /// Return a 2-tuple containing (new_string, number).
  /// new_string is the string obtained by replacing the leftmost
  /// non-overlapping occurrences of the pattern in the source
  /// string by the replacement repl.  number is the number of
  /// substitutions that were made. repl can be either a string or a
  /// callable; if a string, backslash escapes in it are processed.
  /// If it is a callable, it's passed the Match object and must
  /// return a replacement string to be used.
  ///
  /// ### python source
  /// ```py
  /// def subn(pattern, repl, string, count=0, flags=0):
  ///     """Return a 2-tuple containing (new_string, number).
  ///     new_string is the string obtained by replacing the leftmost
  ///     non-overlapping occurrences of the pattern in the source
  ///     string by the replacement repl.  number is the number of
  ///     substitutions that were made. repl can be either a string or a
  ///     callable; if a string, backslash escapes in it are processed.
  ///     If it is a callable, it's passed the Match object and must
  ///     return a replacement string to be used."""
  ///     return _compile(pattern, flags).subn(repl, string, count)
  /// ```
  Object? subn({
    required Object? pattern,
    required Object? repl,
    required Object? string,
    Object? count = 0,
    Object? flags = 0,
  }) =>
      getFunction("subn").call(
        <Object?>[
          pattern,
          repl,
          string,
          count,
          flags,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## template
  ///
  /// ### python docstring
  ///
  /// Compile a template pattern, returning a Pattern object, deprecated
  ///
  /// ### python source
  /// ```py
  /// def template(pattern, flags=0):
  ///     "Compile a template pattern, returning a Pattern object, deprecated"
  ///     import warnings
  ///     warnings.warn("The re.template() function is deprecated "
  ///                   "as it is an undocumented function "
  ///                   "without an obvious purpose. "
  ///                   "Use re.compile() instead.",
  ///                   DeprecationWarning)
  ///     with warnings.catch_warnings():
  ///         warnings.simplefilter("ignore", DeprecationWarning)  # warn just once
  ///         return _compile(pattern, flags|T)
  /// ```
  Object? template({
    required Object? pattern,
    Object? flags = 0,
  }) =>
      getFunction("template").call(
        <Object?>[
          pattern,
          flags,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## A (getter)
  Object? get A => getAttribute("A");

  /// ## A (setter)
  set A(Object? A) => setAttribute("A", A);

  /// ## ASCII (getter)
  Object? get ASCII => getAttribute("ASCII");

  /// ## ASCII (setter)
  set ASCII(Object? ASCII) => setAttribute("ASCII", ASCII);

  /// ## DEBUG (getter)
  Object? get DEBUG => getAttribute("DEBUG");

  /// ## DEBUG (setter)
  set DEBUG(Object? DEBUG) => setAttribute("DEBUG", DEBUG);

  /// ## DOTALL (getter)
  Object? get DOTALL => getAttribute("DOTALL");

  /// ## DOTALL (setter)
  set DOTALL(Object? DOTALL) => setAttribute("DOTALL", DOTALL);

  /// ## I (getter)
  Object? get I => getAttribute("I");

  /// ## I (setter)
  set I(Object? I) => setAttribute("I", I);

  /// ## IGNORECASE (getter)
  Object? get IGNORECASE => getAttribute("IGNORECASE");

  /// ## IGNORECASE (setter)
  set IGNORECASE(Object? IGNORECASE) => setAttribute("IGNORECASE", IGNORECASE);

  /// ## L (getter)
  Object? get L => getAttribute("L");

  /// ## L (setter)
  set L(Object? L) => setAttribute("L", L);

  /// ## LOCALE (getter)
  Object? get LOCALE => getAttribute("LOCALE");

  /// ## LOCALE (setter)
  set LOCALE(Object? LOCALE) => setAttribute("LOCALE", LOCALE);

  /// ## M (getter)
  Object? get M => getAttribute("M");

  /// ## M (setter)
  set M(Object? M) => setAttribute("M", M);

  /// ## MULTILINE (getter)
  Object? get MULTILINE => getAttribute("MULTILINE");

  /// ## MULTILINE (setter)
  set MULTILINE(Object? MULTILINE) => setAttribute("MULTILINE", MULTILINE);

  /// ## NOFLAG (getter)
  Object? get NOFLAG => getAttribute("NOFLAG");

  /// ## NOFLAG (setter)
  set NOFLAG(Object? NOFLAG) => setAttribute("NOFLAG", NOFLAG);

  /// ## S (getter)
  Object? get S => getAttribute("S");

  /// ## S (setter)
  set S(Object? S) => setAttribute("S", S);

  /// ## T (getter)
  Object? get T => getAttribute("T");

  /// ## T (setter)
  set T(Object? T) => setAttribute("T", T);

  /// ## TEMPLATE (getter)
  Object? get TEMPLATE => getAttribute("TEMPLATE");

  /// ## TEMPLATE (setter)
  set TEMPLATE(Object? TEMPLATE) => setAttribute("TEMPLATE", TEMPLATE);

  /// ## U (getter)
  Object? get U => getAttribute("U");

  /// ## U (setter)
  set U(Object? U) => setAttribute("U", U);

  /// ## UNICODE (getter)
  Object? get UNICODE => getAttribute("UNICODE");

  /// ## UNICODE (setter)
  set UNICODE(Object? UNICODE) => setAttribute("UNICODE", UNICODE);

  /// ## VERBOSE (getter)
  Object? get VERBOSE => getAttribute("VERBOSE");

  /// ## VERBOSE (setter)
  set VERBOSE(Object? VERBOSE) => setAttribute("VERBOSE", VERBOSE);

  /// ## X (getter)
  Object? get X => getAttribute("X");

  /// ## X (setter)
  set X(Object? X) => setAttribute("X", X);
}

/// ## copyreg
///
/// ### python docstring
///
/// Helper to provide extensibility for pickle.
///
/// This is only useful to add pickle support for extension types defined in
/// C, not for instances of user-defined classes.
///
/// ### python source
/// ```py
/// """Helper to provide extensibility for pickle.
///
/// This is only useful to add pickle support for extension types defined in
/// C, not for instances of user-defined classes.
/// """
///
/// __all__ = ["pickle", "constructor",
///            "add_extension", "remove_extension", "clear_extension_cache"]
///
/// dispatch_table = {}
///
/// def pickle(ob_type, pickle_function, constructor_ob=None):
///     if not callable(pickle_function):
///         raise TypeError("reduction functions must be callable")
///     dispatch_table[ob_type] = pickle_function
///
///     # The constructor_ob function is a vestige of safe for unpickling.
///     # There is no reason for the caller to pass it anymore.
///     if constructor_ob is not None:
///         constructor(constructor_ob)
///
/// def constructor(object):
///     if not callable(object):
///         raise TypeError("constructors must be callable")
///
/// # Example: provide pickling support for complex numbers.
///
/// try:
///     complex
/// except NameError:
///     pass
/// else:
///
///     def pickle_complex(c):
///         return complex, (c.real, c.imag)
///
///     pickle(complex, pickle_complex, complex)
///
/// def pickle_union(obj):
///     import functools, operator
///     return functools.reduce, (operator.or_, obj.__args__)
///
/// pickle(type(int | str), pickle_union)
///
/// # Support for pickling new-style objects
///
/// def _reconstructor(cls, base, state):
///     if base is object:
///         obj = object.__new__(cls)
///     else:
///         obj = base.__new__(cls, state)
///         if base.__init__ != object.__init__:
///             base.__init__(obj, state)
///     return obj
///
/// _HEAPTYPE = 1<<9
/// _new_type = type(int.__new__)
///
/// # Python code for object.__reduce_ex__ for protocols 0 and 1
///
/// def _reduce_ex(self, proto):
///     assert proto < 2
///     cls = self.__class__
///     for base in cls.__mro__:
///         if hasattr(base, '__flags__') and not base.__flags__ & _HEAPTYPE:
///             break
///         new = base.__new__
///         if isinstance(new, _new_type) and new.__self__ is base:
///             break
///     else:
///         base = object # not really reachable
///     if base is object:
///         state = None
///     else:
///         if base is cls:
///             raise TypeError(f"cannot pickle {cls.__name__!r} object")
///         state = base(self)
///     args = (cls, base, state)
///     try:
///         getstate = self.__getstate__
///     except AttributeError:
///         if getattr(self, "__slots__", None):
///             raise TypeError(f"cannot pickle {cls.__name__!r} object: "
///                             f"a class that defines __slots__ without "
///                             f"defining __getstate__ cannot be pickled "
///                             f"with protocol {proto}") from None
///         try:
///             dict = self.__dict__
///         except AttributeError:
///             dict = None
///     else:
///         if (type(self).__getstate__ is object.__getstate__ and
///             getattr(self, "__slots__", None)):
///             raise TypeError("a class that defines __slots__ without "
///                             "defining __getstate__ cannot be pickled")
///         dict = getstate()
///     if dict:
///         return _reconstructor, args, dict
///     else:
///         return _reconstructor, args
///
/// # Helper for __reduce_ex__ protocol 2
///
/// def __newobj__(cls, *args):
///     return cls.__new__(cls, *args)
///
/// def __newobj_ex__(cls, args, kwargs):
///     """Used by pickle protocol 4, instead of __newobj__ to allow classes with
///     keyword-only arguments to be pickled correctly.
///     """
///     return cls.__new__(cls, *args, **kwargs)
///
/// def _slotnames(cls):
///     """Return a list of slot names for a given class.
///
///     This needs to find slots defined by the class and its bases, so we
///     can't simply return the __slots__ attribute.  We must walk down
///     the Method Resolution Order and concatenate the __slots__ of each
///     class found there.  (This assumes classes don't modify their
///     __slots__ attribute to misrepresent their slots after the class is
///     defined.)
///     """
///
///     # Get the value from a cache in the class if possible
///     names = cls.__dict__.get("__slotnames__")
///     if names is not None:
///         return names
///
///     # Not cached -- calculate the value
///     names = []
///     if not hasattr(cls, "__slots__"):
///         # This class has no slots
///         pass
///     else:
///         # Slots found -- gather slot names from all base classes
///         for c in cls.__mro__:
///             if "__slots__" in c.__dict__:
///                 slots = c.__dict__['__slots__']
///                 # if class has a single slot, it can be given as a string
///                 if isinstance(slots, str):
///                     slots = (slots,)
///                 for name in slots:
///                     # special descriptors
///                     if name in ("__dict__", "__weakref__"):
///                         continue
///                     # mangled names
///                     elif name.startswith('__') and not name.endswith('__'):
///                         stripped = c.__name__.lstrip('_')
///                         if stripped:
///                             names.append('_%s%s' % (stripped, name))
///                         else:
///                             names.append(name)
///                     else:
///                         names.append(name)
///
///     # Cache the outcome in the class if at all possible
///     try:
///         cls.__slotnames__ = names
///     except:
///         pass # But don't die if we can't
///
///     return names
///
/// # A registry of extension codes.  This is an ad-hoc compression
/// # mechanism.  Whenever a global reference to <module>, <name> is about
/// # to be pickled, the (<module>, <name>) tuple is looked up here to see
/// # if it is a registered extension code for it.  Extension codes are
/// # universal, so that the meaning of a pickle does not depend on
/// # context.  (There are also some codes reserved for local use that
/// # don't have this restriction.)  Codes are positive ints; 0 is
/// # reserved.
///
/// _extension_registry = {}                # key -> code
/// _inverted_registry = {}                 # code -> key
/// _extension_cache = {}                   # code -> object
/// # Don't ever rebind those names:  pickling grabs a reference to them when
/// # it's initialized, and won't see a rebinding.
///
/// def add_extension(module, name, code):
///     """Register an extension code."""
///     code = int(code)
///     if not 1 <= code <= 0x7fffffff:
///         raise ValueError("code out of range")
///     key = (module, name)
///     if (_extension_registry.get(key) == code and
///         _inverted_registry.get(code) == key):
///         return # Redundant registrations are benign
///     if key in _extension_registry:
///         raise ValueError("key %s is already registered with code %s" %
///                          (key, _extension_registry[key]))
///     if code in _inverted_registry:
///         raise ValueError("code %s is already in use for key %s" %
///                          (code, _inverted_registry[code]))
///     _extension_registry[key] = code
///     _inverted_registry[code] = key
///
/// def remove_extension(module, name, code):
///     """Unregister an extension code.  For testing only."""
///     key = (module, name)
///     if (_extension_registry.get(key) != code or
///         _inverted_registry.get(code) != key):
///         raise ValueError("key %s is not registered with code %s" %
///                          (key, code))
///     del _extension_registry[key]
///     del _inverted_registry[code]
///     if code in _extension_cache:
///         del _extension_cache[code]
///
/// def clear_extension_cache():
///     _extension_cache.clear()
///
/// # Standard extension code assignments
///
/// # Reserved ranges
///
/// # First  Last Count  Purpose
/// #     1   127   127  Reserved for Python standard library
/// #   128   191    64  Reserved for Zope
/// #   192   239    48  Reserved for 3rd parties
/// #   240   255    16  Reserved for private use (will never be assigned)
/// #   256   Inf   Inf  Reserved for future assignment
///
/// # Extension codes are assigned by the Python Software Foundation.
/// ```
final class copyreg extends PythonModule {
  copyreg.from(super.pythonModule) : super.from();

  static copyreg import() => PythonFfiDart.instance.importModule(
        "copyreg",
        copyreg.from,
      );

  /// ## add_extension
  ///
  /// ### python docstring
  ///
  /// Register an extension code.
  ///
  /// ### python source
  /// ```py
  /// def add_extension(module, name, code):
  ///     """Register an extension code."""
  ///     code = int(code)
  ///     if not 1 <= code <= 0x7fffffff:
  ///         raise ValueError("code out of range")
  ///     key = (module, name)
  ///     if (_extension_registry.get(key) == code and
  ///         _inverted_registry.get(code) == key):
  ///         return # Redundant registrations are benign
  ///     if key in _extension_registry:
  ///         raise ValueError("key %s is already registered with code %s" %
  ///                          (key, _extension_registry[key]))
  ///     if code in _inverted_registry:
  ///         raise ValueError("code %s is already in use for key %s" %
  ///                          (code, _inverted_registry[code]))
  ///     _extension_registry[key] = code
  ///     _inverted_registry[code] = key
  /// ```
  Object? add_extension({
    required Object? module,
    required Object? name,
    required Object? code,
  }) =>
      getFunction("add_extension").call(
        <Object?>[
          module,
          name,
          code,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## clear_extension_cache
  ///
  /// ### python source
  /// ```py
  /// def clear_extension_cache():
  ///     _extension_cache.clear()
  /// ```
  Object? clear_extension_cache() => getFunction("clear_extension_cache").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## constructor
  ///
  /// ### python source
  /// ```py
  /// def constructor(object):
  ///     if not callable(object):
  ///         raise TypeError("constructors must be callable")
  /// ```
  Object? constructor({
    required Object? object,
  }) =>
      getFunction("constructor").call(
        <Object?>[
          object,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## pickle
  ///
  /// ### python source
  /// ```py
  /// def pickle(ob_type, pickle_function, constructor_ob=None):
  ///     if not callable(pickle_function):
  ///         raise TypeError("reduction functions must be callable")
  ///     dispatch_table[ob_type] = pickle_function
  ///
  ///     # The constructor_ob function is a vestige of safe for unpickling.
  ///     # There is no reason for the caller to pass it anymore.
  ///     if constructor_ob is not None:
  ///         constructor(constructor_ob)
  /// ```
  Object? pickle({
    required Object? ob_type,
    required Object? pickle_function,
    Object? constructor_ob,
  }) =>
      getFunction("pickle").call(
        <Object?>[
          ob_type,
          pickle_function,
          constructor_ob,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## pickle_complex
  ///
  /// ### python source
  /// ```py
  /// def pickle_complex(c):
  ///         return complex, (c.real, c.imag)
  /// ```
  Object? pickle_complex({
    required Object? c,
  }) =>
      getFunction("pickle_complex").call(
        <Object?>[
          c,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## pickle_union
  ///
  /// ### python source
  /// ```py
  /// def pickle_union(obj):
  ///     import functools, operator
  ///     return functools.reduce, (operator.or_, obj.__args__)
  /// ```
  Object? pickle_union({
    required Object? obj,
  }) =>
      getFunction("pickle_union").call(
        <Object?>[
          obj,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## remove_extension
  ///
  /// ### python docstring
  ///
  /// Unregister an extension code.  For testing only.
  ///
  /// ### python source
  /// ```py
  /// def remove_extension(module, name, code):
  ///     """Unregister an extension code.  For testing only."""
  ///     key = (module, name)
  ///     if (_extension_registry.get(key) != code or
  ///         _inverted_registry.get(code) != key):
  ///         raise ValueError("key %s is not registered with code %s" %
  ///                          (key, code))
  ///     del _extension_registry[key]
  ///     del _inverted_registry[code]
  ///     if code in _extension_cache:
  ///         del _extension_cache[code]
  /// ```
  Object? remove_extension({
    required Object? module,
    required Object? name,
    required Object? code,
  }) =>
      getFunction("remove_extension").call(
        <Object?>[
          module,
          name,
          code,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## dispatch_table (getter)
  Object? get dispatch_table => getAttribute("dispatch_table");

  /// ## dispatch_table (setter)
  set dispatch_table(Object? dispatch_table) =>
      setAttribute("dispatch_table", dispatch_table);
}

/// ## enum
///
/// ### python source
/// ```py
/// import sys
/// import builtins as bltns
/// from types import MappingProxyType, DynamicClassAttribute
/// from operator import or_ as _or_
/// from functools import reduce
///
///
/// __all__ = [
///         'EnumType', 'EnumMeta',
///         'Enum', 'IntEnum', 'StrEnum', 'Flag', 'IntFlag', 'ReprEnum',
///         'auto', 'unique', 'property', 'verify', 'member', 'nonmember',
///         'FlagBoundary', 'STRICT', 'CONFORM', 'EJECT', 'KEEP',
///         'global_flag_repr', 'global_enum_repr', 'global_str', 'global_enum',
///         'EnumCheck', 'CONTINUOUS', 'NAMED_FLAGS', 'UNIQUE',
///         ]
///
///
/// # Dummy value for Enum and Flag as there are explicit checks for them
/// # before they have been created.
/// # This is also why there are checks in EnumType like `if Enum is not None`
/// Enum = Flag = EJECT = _stdlib_enums = ReprEnum = None
///
/// class nonmember(object):
///     """
///     Protects item from becoming an Enum member during class creation.
///     """
///     def __init__(self, value):
///         self.value = value
///
/// class member(object):
///     """
///     Forces item to become an Enum member during class creation.
///     """
///     def __init__(self, value):
///         self.value = value
///
/// def _is_descriptor(obj):
///     """
///     Returns True if obj is a descriptor, False otherwise.
///     """
///     return (
///             hasattr(obj, '__get__') or
///             hasattr(obj, '__set__') or
///             hasattr(obj, '__delete__')
///             )
///
/// def _is_dunder(name):
///     """
///     Returns True if a __dunder__ name, False otherwise.
///     """
///     return (
///             len(name) > 4 and
///             name[:2] == name[-2:] == '__' and
///             name[2] != '_' and
///             name[-3] != '_'
///             )
///
/// def _is_sunder(name):
///     """
///     Returns True if a _sunder_ name, False otherwise.
///     """
///     return (
///             len(name) > 2 and
///             name[0] == name[-1] == '_' and
///             name[1:2] != '_' and
///             name[-2:-1] != '_'
///             )
///
/// def _is_internal_class(cls_name, obj):
///     # do not use `re` as `re` imports `enum`
///     if not isinstance(obj, type):
///         return False
///     qualname = getattr(obj, '__qualname__', '')
///     s_pattern = cls_name + '.' + getattr(obj, '__name__', '')
///     e_pattern = '.' + s_pattern
///     return qualname == s_pattern or qualname.endswith(e_pattern)
///
/// def _is_private(cls_name, name):
///     # do not use `re` as `re` imports `enum`
///     pattern = '_%s__' % (cls_name, )
///     pat_len = len(pattern)
///     if (
///             len(name) > pat_len
///             and name.startswith(pattern)
///             and name[pat_len:pat_len+1] != ['_']
///             and (name[-1] != '_' or name[-2] != '_')
///         ):
///         return True
///     else:
///         return False
///
/// def _is_single_bit(num):
///     """
///     True if only one bit set in num (should be an int)
///     """
///     if num == 0:
///         return False
///     num &= num - 1
///     return num == 0
///
/// def _make_class_unpicklable(obj):
///     """
///     Make the given obj un-picklable.
///
///     obj should be either a dictionary, or an Enum
///     """
///     def _break_on_call_reduce(self, proto):
///         raise TypeError('%r cannot be pickled' % self)
///     if isinstance(obj, dict):
///         obj['__reduce_ex__'] = _break_on_call_reduce
///         obj['__module__'] = '<unknown>'
///     else:
///         setattr(obj, '__reduce_ex__', _break_on_call_reduce)
///         setattr(obj, '__module__', '<unknown>')
///
/// def _iter_bits_lsb(num):
///     # num must be a positive integer
///     original = num
///     if isinstance(num, Enum):
///         num = num.value
///     if num < 0:
///         raise ValueError('%r is not a positive integer' % original)
///     while num:
///         b = num & (~num + 1)
///         yield b
///         num ^= b
///
/// def show_flag_values(value):
///     return list(_iter_bits_lsb(value))
///
/// def bin(num, max_bits=None):
///     """
///     Like built-in bin(), except negative values are represented in
///     twos-compliment, and the leading bit always indicates sign
///     (0=positive, 1=negative).
///
///     >>> bin(10)
///     '0b0 1010'
///     >>> bin(~10)   # ~10 is -11
///     '0b1 0101'
///     """
///
///     ceiling = 2 ** (num).bit_length()
///     if num >= 0:
///         s = bltns.bin(num + ceiling).replace('1', '0', 1)
///     else:
///         s = bltns.bin(~num ^ (ceiling - 1) + ceiling)
///     sign = s[:3]
///     digits = s[3:]
///     if max_bits is not None:
///         if len(digits) < max_bits:
///             digits = (sign[-1] * max_bits + digits)[-max_bits:]
///     return "%s %s" % (sign, digits)
///
/// def _dedent(text):
///     """
///     Like textwrap.dedent.  Rewritten because we cannot import textwrap.
///     """
///     lines = text.split('\n')
///     blanks = 0
///     for i, ch in enumerate(lines[0]):
///         if ch != ' ':
///             break
///     for j, l in enumerate(lines):
///         lines[j] = l[i:]
///     return '\n'.join(lines)
///
/// class _auto_null:
///     def __repr__(self):
///         return '_auto_null'
/// _auto_null = _auto_null()
///
/// class auto:
///     """
///     Instances are replaced with an appropriate value in Enum class suites.
///     """
///     def __init__(self, value=_auto_null):
///         self.value = value
///
///     def __repr__(self):
///         return "auto(%r)" % self.value
///
/// class property(DynamicClassAttribute):
///     """
///     This is a descriptor, used to define attributes that act differently
///     when accessed through an enum member and through an enum class.
///     Instance access is the same as property(), but access to an attribute
///     through the enum class will instead look in the class' _member_map_ for
///     a corresponding enum member.
///     """
///
///     def __get__(self, instance, ownerclass=None):
///         if instance is None:
///             try:
///                 return ownerclass._member_map_[self.name]
///             except KeyError:
///                 raise AttributeError(
///                         '%r has no attribute %r' % (ownerclass, self.name)
///                         )
///         else:
///             if self.fget is None:
///                 raise AttributeError(
///                         '%r member has no attribute %r' % (ownerclass, self.name)
///                         )
///             else:
///                 return self.fget(instance)
///
///     def __set__(self, instance, value):
///         if self.fset is None:
///             raise AttributeError(
///                     "<enum %r> cannot set attribute %r" % (self.clsname, self.name)
///                     )
///         else:
///             return self.fset(instance, value)
///
///     def __delete__(self, instance):
///         if self.fdel is None:
///             raise AttributeError(
///                     "<enum %r> cannot delete attribute %r" % (self.clsname, self.name)
///                     )
///         else:
///             return self.fdel(instance)
///
///     def __set_name__(self, ownerclass, name):
///         self.name = name
///         self.clsname = ownerclass.__name__
///
///
/// class _proto_member:
///     """
///     intermediate step for enum members between class execution and final creation
///     """
///
///     def __init__(self, value):
///         self.value = value
///
///     def __set_name__(self, enum_class, member_name):
///         """
///         convert each quasi-member into an instance of the new enum class
///         """
///         # first step: remove ourself from enum_class
///         delattr(enum_class, member_name)
///         # second step: create member based on enum_class
///         value = self.value
///         if not isinstance(value, tuple):
///             args = (value, )
///         else:
///             args = value
///         if enum_class._member_type_ is tuple:   # special case for tuple enums
///             args = (args, )     # wrap it one more time
///         if not enum_class._use_args_:
///             enum_member = enum_class._new_member_(enum_class)
///         else:
///             enum_member = enum_class._new_member_(enum_class, *args)
///         if not hasattr(enum_member, '_value_'):
///             if enum_class._member_type_ is object:
///                 enum_member._value_ = value
///             else:
///                 try:
///                     enum_member._value_ = enum_class._member_type_(*args)
///                 except Exception as exc:
///                     new_exc = TypeError(
///                             '_value_ not set in __new__, unable to create it'
///                             )
///                     new_exc.__cause__ = exc
///                     raise new_exc
///         value = enum_member._value_
///         enum_member._name_ = member_name
///         enum_member.__objclass__ = enum_class
///         enum_member.__init__(*args)
///         enum_member._sort_order_ = len(enum_class._member_names_)
///         # If another member with the same value was already defined, the
///         # new member becomes an alias to the existing one.
///         try:
///             try:
///                 # try to do a fast lookup to avoid the quadratic loop
///                 enum_member = enum_class._value2member_map_[value]
///             except TypeError:
///                 for name, canonical_member in enum_class._member_map_.items():
///                     if canonical_member._value_ == value:
///                         enum_member = canonical_member
///                         break
///                 else:
///                     raise KeyError
///         except KeyError:
///             # this could still be an alias if the value is multi-bit and the
///             # class is a flag class
///             if (
///                     Flag is None
///                     or not issubclass(enum_class, Flag)
///                 ):
///                 # no other instances found, record this member in _member_names_
///                 enum_class._member_names_.append(member_name)
///             elif (
///                     Flag is not None
///                     and issubclass(enum_class, Flag)
///                     and _is_single_bit(value)
///                 ):
///                 # no other instances found, record this member in _member_names_
///                 enum_class._member_names_.append(member_name)
///         # get redirect in place before adding to _member_map_
///         # but check for other instances in parent classes first
///         need_override = False
///         descriptor = None
///         for base in enum_class.__mro__[1:]:
///             descriptor = base.__dict__.get(member_name)
///             if descriptor is not None:
///                 if isinstance(descriptor, (property, DynamicClassAttribute)):
///                     break
///                 else:
///                     need_override = True
///                     # keep looking for an enum.property
///         if descriptor and not need_override:
///             # previous enum.property found, no further action needed
///             pass
///         elif descriptor and need_override:
///             redirect = property()
///             redirect.__set_name__(enum_class, member_name)
///             # Previous enum.property found, but some other inherited attribute
///             # is in the way; copy fget, fset, fdel to this one.
///             redirect.fget = descriptor.fget
///             redirect.fset = descriptor.fset
///             redirect.fdel = descriptor.fdel
///             setattr(enum_class, member_name, redirect)
///         else:
///             setattr(enum_class, member_name, enum_member)
///         # now add to _member_map_ (even aliases)
///         enum_class._member_map_[member_name] = enum_member
///         try:
///             # This may fail if value is not hashable. We can't add the value
///             # to the map, and by-value lookups for this value will be
///             # linear.
///             enum_class._value2member_map_.setdefault(value, enum_member)
///         except TypeError:
///             # keep track of the value in a list so containment checks are quick
///             enum_class._unhashable_values_.append(value)
///
///
/// class _EnumDict(dict):
///     """
///     Track enum member order and ensure member names are not reused.
///
///     EnumType will use the names found in self._member_names as the
///     enumeration member names.
///     """
///     def __init__(self):
///         super().__init__()
///         self._member_names = {} # use a dict to keep insertion order
///         self._last_values = []
///         self._ignore = []
///         self._auto_called = False
///
///     def __setitem__(self, key, value):
///         """
///         Changes anything not dundered or not a descriptor.
///
///         If an enum member name is used twice, an error is raised; duplicate
///         values are not checked for.
///
///         Single underscore (sunder) names are reserved.
///         """
///         if _is_internal_class(self._cls_name, value):
///             import warnings
///             warnings.warn(
///                     "In 3.13 classes created inside an enum will not become a member.  "
///                     "Use the `member` decorator to keep the current behavior.",
///                     DeprecationWarning,
///                     stacklevel=2,
///                     )
///         if _is_private(self._cls_name, key):
///             # also do nothing, name will be a normal attribute
///             pass
///         elif _is_sunder(key):
///             if key not in (
///                     '_order_',
///                     '_generate_next_value_', '_numeric_repr_', '_missing_', '_ignore_',
///                     '_iter_member_', '_iter_member_by_value_', '_iter_member_by_def_',
///                     ):
///                 raise ValueError(
///                         '_sunder_ names, such as %r, are reserved for future Enum use'
///                         % (key, )
///                         )
///             if key == '_generate_next_value_':
///                 # check if members already defined as auto()
///                 if self._auto_called:
///                     raise TypeError("_generate_next_value_ must be defined before members")
///                 _gnv = value.__func__ if isinstance(value, staticmethod) else value
///                 setattr(self, '_generate_next_value', _gnv)
///             elif key == '_ignore_':
///                 if isinstance(value, str):
///                     value = value.replace(',',' ').split()
///                 else:
///                     value = list(value)
///                 self._ignore = value
///                 already = set(value) & set(self._member_names)
///                 if already:
///                     raise ValueError(
///                             '_ignore_ cannot specify already set names: %r'
///                             % (already, )
///                             )
///         elif _is_dunder(key):
///             if key == '__order__':
///                 key = '_order_'
///         elif key in self._member_names:
///             # descriptor overwriting an enum?
///             raise TypeError('%r already defined as %r' % (key, self[key]))
///         elif key in self._ignore:
///             pass
///         elif isinstance(value, nonmember):
///             # unwrap value here; it won't be processed by the below `else`
///             value = value.value
///         elif _is_descriptor(value):
///             pass
///         # TODO: uncomment next three lines in 3.13
///         # elif _is_internal_class(self._cls_name, value):
///         #     # do nothing, name will be a normal attribute
///         #     pass
///         else:
///             if key in self:
///                 # enum overwriting a descriptor?
///                 raise TypeError('%r already defined as %r' % (key, self[key]))
///             elif isinstance(value, member):
///                 # unwrap value here -- it will become a member
///                 value = value.value
///             non_auto_store = True
///             single = False
///             if isinstance(value, auto):
///                 single = True
///                 value = (value, )
///             if type(value) is tuple and any(isinstance(v, auto) for v in value):
///                 # insist on an actual tuple, no subclasses, in keeping with only supporting
///                 # top-level auto() usage (not contained in any other data structure)
///                 auto_valued = []
///                 for v in value:
///                     if isinstance(v, auto):
///                         non_auto_store = False
///                         if v.value == _auto_null:
///                             v.value = self._generate_next_value(
///                                     key, 1, len(self._member_names), self._last_values[:],
///                                     )
///                             self._auto_called = True
///                         v = v.value
///                         self._last_values.append(v)
///                     auto_valued.append(v)
///                 if single:
///                     value = auto_valued[0]
///                 else:
///                     value = tuple(auto_valued)
///             self._member_names[key] = None
///             if non_auto_store:
///                 self._last_values.append(value)
///         super().__setitem__(key, value)
///
///     def update(self, members, **more_members):
///         try:
///             for name in members.keys():
///                 self[name] = members[name]
///         except AttributeError:
///             for name, value in members:
///                 self[name] = value
///         for name, value in more_members.items():
///             self[name] = value
///
///
/// class EnumType(type):
///     """
///     Metaclass for Enum
///     """
///
///     @classmethod
///     def __prepare__(metacls, cls, bases, **kwds):
///         # check that previous enum members do not exist
///         metacls._check_for_existing_members_(cls, bases)
///         # create the namespace dict
///         enum_dict = _EnumDict()
///         enum_dict._cls_name = cls
///         # inherit previous flags and _generate_next_value_ function
///         member_type, first_enum = metacls._get_mixins_(cls, bases)
///         if first_enum is not None:
///             enum_dict['_generate_next_value_'] = getattr(
///                     first_enum, '_generate_next_value_', None,
///                     )
///         return enum_dict
///
///     def __new__(metacls, cls, bases, classdict, *, boundary=None, _simple=False, **kwds):
///         # an Enum class is final once enumeration items have been defined; it
///         # cannot be mixed with other types (int, float, etc.) if it has an
///         # inherited __new__ unless a new __new__ is defined (or the resulting
///         # class will fail).
///         #
///         if _simple:
///             return super().__new__(metacls, cls, bases, classdict, **kwds)
///         #
///         # remove any keys listed in _ignore_
///         classdict.setdefault('_ignore_', []).append('_ignore_')
///         ignore = classdict['_ignore_']
///         for key in ignore:
///             classdict.pop(key, None)
///         #
///         # grab member names
///         member_names = classdict._member_names
///         #
///         # check for illegal enum names (any others?)
///         invalid_names = set(member_names) & {'mro', ''}
///         if invalid_names:
///             raise ValueError('invalid enum member name(s) %s'  % (
///                     ','.join(repr(n) for n in invalid_names)
///                     ))
///         #
///         # adjust the sunders
///         _order_ = classdict.pop('_order_', None)
///         # convert to normal dict
///         classdict = dict(classdict.items())
///         #
///         # data type of member and the controlling Enum class
///         member_type, first_enum = metacls._get_mixins_(cls, bases)
///         __new__, save_new, use_args = metacls._find_new_(
///                 classdict, member_type, first_enum,
///                 )
///         classdict['_new_member_'] = __new__
///         classdict['_use_args_'] = use_args
///         #
///         # convert future enum members into temporary _proto_members
///         # and record integer values in case this will be a Flag
///         flag_mask = 0
///         for name in member_names:
///             value = classdict[name]
///             if isinstance(value, int):
///                 flag_mask |= value
///             classdict[name] = _proto_member(value)
///         #
///         # house-keeping structures
///         classdict['_member_names_'] = []
///         classdict['_member_map_'] = {}
///         classdict['_value2member_map_'] = {}
///         classdict['_unhashable_values_'] = []
///         classdict['_member_type_'] = member_type
///         # now set the __repr__ for the value
///         classdict['_value_repr_'] = metacls._find_data_repr_(cls, bases)
///         #
///         # Flag structures (will be removed if final class is not a Flag
///         classdict['_boundary_'] = (
///                 boundary
///                 or getattr(first_enum, '_boundary_', None)
///                 )
///         classdict['_flag_mask_'] = flag_mask
///         classdict['_all_bits_'] = 2 ** ((flag_mask).bit_length()) - 1
///         classdict['_inverted_'] = None
///         try:
///             exc = None
///             enum_class = super().__new__(metacls, cls, bases, classdict, **kwds)
///         except RuntimeError as e:
///             # any exceptions raised by member.__new__ will get converted to a
///             # RuntimeError, so get that original exception back and raise it instead
///             exc = e.__cause__ or e
///         if exc is not None:
///             raise exc
///         #
///         # update classdict with any changes made by __init_subclass__
///         classdict.update(enum_class.__dict__)
///         #
///         # double check that repr and friends are not the mixin's or various
///         # things break (such as pickle)
///         # however, if the method is defined in the Enum itself, don't replace
///         # it
///         #
///         # Also, special handling for ReprEnum
///         if ReprEnum is not None and ReprEnum in bases:
///             if member_type is object:
///                 raise TypeError(
///                         'ReprEnum subclasses must be mixed with a data type (i.e.'
///                         ' int, str, float, etc.)'
///                         )
///             if '__format__' not in classdict:
///                 enum_class.__format__ = member_type.__format__
///                 classdict['__format__'] = enum_class.__format__
///             if '__str__' not in classdict:
///                 method = member_type.__str__
///                 if method is object.__str__:
///                     # if member_type does not define __str__, object.__str__ will use
///                     # its __repr__ instead, so we'll also use its __repr__
///                     method = member_type.__repr__
///                 enum_class.__str__ = method
///                 classdict['__str__'] = enum_class.__str__
///         for name in ('__repr__', '__str__', '__format__', '__reduce_ex__'):
///             if name not in classdict:
///                 # check for mixin overrides before replacing
///                 enum_method = getattr(first_enum, name)
///                 found_method = getattr(enum_class, name)
///                 object_method = getattr(object, name)
///                 data_type_method = getattr(member_type, name)
///                 if found_method in (data_type_method, object_method):
///                     setattr(enum_class, name, enum_method)
///         #
///         # for Flag, add __or__, __and__, __xor__, and __invert__
///         if Flag is not None and issubclass(enum_class, Flag):
///             for name in (
///                     '__or__', '__and__', '__xor__',
///                     '__ror__', '__rand__', '__rxor__',
///                     '__invert__'
///                 ):
///                 if name not in classdict:
///                     enum_method = getattr(Flag, name)
///                     setattr(enum_class, name, enum_method)
///                     classdict[name] = enum_method
///         #
///         # replace any other __new__ with our own (as long as Enum is not None,
///         # anyway) -- again, this is to support pickle
///         if Enum is not None:
///             # if the user defined their own __new__, save it before it gets
///             # clobbered in case they subclass later
///             if save_new:
///                 enum_class.__new_member__ = __new__
///             enum_class.__new__ = Enum.__new__
///         #
///         # py3 support for definition order (helps keep py2/py3 code in sync)
///         #
///         # _order_ checking is spread out into three/four steps
///         # - if enum_class is a Flag:
///         #   - remove any non-single-bit flags from _order_
///         # - remove any aliases from _order_
///         # - check that _order_ and _member_names_ match
///         #
///         # step 1: ensure we have a list
///         if _order_ is not None:
///             if isinstance(_order_, str):
///                 _order_ = _order_.replace(',', ' ').split()
///         #
///         # remove Flag structures if final class is not a Flag
///         if (
///                 Flag is None and cls != 'Flag'
///                 or Flag is not None and not issubclass(enum_class, Flag)
///             ):
///             delattr(enum_class, '_boundary_')
///             delattr(enum_class, '_flag_mask_')
///             delattr(enum_class, '_all_bits_')
///             delattr(enum_class, '_inverted_')
///         elif Flag is not None and issubclass(enum_class, Flag):
///             # ensure _all_bits_ is correct and there are no missing flags
///             single_bit_total = 0
///             multi_bit_total = 0
///             for flag in enum_class._member_map_.values():
///                 flag_value = flag._value_
///                 if _is_single_bit(flag_value):
///                     single_bit_total |= flag_value
///                 else:
///                     # multi-bit flags are considered aliases
///                     multi_bit_total |= flag_value
///             enum_class._flag_mask_ = single_bit_total
///             #
///             # set correct __iter__
///             member_list = [m._value_ for m in enum_class]
///             if member_list != sorted(member_list):
///                 enum_class._iter_member_ = enum_class._iter_member_by_def_
///             if _order_:
///                 # _order_ step 2: remove any items from _order_ that are not single-bit
///                 _order_ = [
///                         o
///                         for o in _order_
///                         if o not in enum_class._member_map_ or _is_single_bit(enum_class[o]._value_)
///                         ]
///         #
///         if _order_:
///             # _order_ step 3: remove aliases from _order_
///             _order_ = [
///                     o
///                     for o in _order_
///                     if (
///                         o not in enum_class._member_map_
///                         or
///                         (o in enum_class._member_map_ and o in enum_class._member_names_)
///                         )]
///             # _order_ step 4: verify that _order_ and _member_names_ match
///             if _order_ != enum_class._member_names_:
///                 raise TypeError(
///                         'member order does not match _order_:\n  %r\n  %r'
///                         % (enum_class._member_names_, _order_)
///                         )
///
///         return enum_class
///
///     def __bool__(cls):
///         """
///         classes/types should always be True.
///         """
///         return True
///
///     def __call__(cls, value, names=None, *, module=None, qualname=None, type=None, start=1, boundary=None):
///         """
///         Either returns an existing member, or creates a new enum class.
///
///         This method is used both when an enum class is given a value to match
///         to an enumeration member (i.e. Color(3)) and for the functional API
///         (i.e. Color = Enum('Color', names='RED GREEN BLUE')).
///
///         When used for the functional API:
///
///         `value` will be the name of the new class.
///
///         `names` should be either a string of white-space/comma delimited names
///         (values will start at `start`), or an iterator/mapping of name, value pairs.
///
///         `module` should be set to the module this class is being created in;
///         if it is not set, an attempt to find that module will be made, but if
///         it fails the class will not be picklable.
///
///         `qualname` should be set to the actual location this class can be found
///         at in its module; by default it is set to the global scope.  If this is
///         not correct, unpickling will fail in some circumstances.
///
///         `type`, if set, will be mixed in as the first base class.
///         """
///         if names is None:  # simple value lookup
///             return cls.__new__(cls, value)
///         # otherwise, functional API: we're creating a new Enum type
///         return cls._create_(
///                 value,
///                 names,
///                 module=module,
///                 qualname=qualname,
///                 type=type,
///                 start=start,
///                 boundary=boundary,
///                 )
///
///     def __contains__(cls, member):
///         """
///         Return True if member is a member of this enum
///         raises TypeError if member is not an enum member
///
///         note: in 3.12 TypeError will no longer be raised, and True will also be
///         returned if member is the value of a member in this enum
///         """
///         if not isinstance(member, Enum):
///             import warnings
///             warnings.warn(
///                     "in 3.12 __contains__ will no longer raise TypeError, but will return True or\n"
///                     "False depending on whether the value is a member or the value of a member",
///                     DeprecationWarning,
///                     stacklevel=2,
///                     )
///             raise TypeError(
///                 "unsupported operand type(s) for 'in': '%s' and '%s'" % (
///                     type(member).__qualname__, cls.__class__.__qualname__))
///         return isinstance(member, cls) and member._name_ in cls._member_map_
///
///     def __delattr__(cls, attr):
///         # nicer error message when someone tries to delete an attribute
///         # (see issue19025).
///         if attr in cls._member_map_:
///             raise AttributeError("%r cannot delete member %r." % (cls.__name__, attr))
///         super().__delattr__(attr)
///
///     def __dir__(cls):
///         interesting = set([
///                 '__class__', '__contains__', '__doc__', '__getitem__',
///                 '__iter__', '__len__', '__members__', '__module__',
///                 '__name__', '__qualname__',
///                 ]
///                 + cls._member_names_
///                 )
///         if cls._new_member_ is not object.__new__:
///             interesting.add('__new__')
///         if cls.__init_subclass__ is not object.__init_subclass__:
///             interesting.add('__init_subclass__')
///         if cls._member_type_ is object:
///             return sorted(interesting)
///         else:
///             # return whatever mixed-in data type has
///             return sorted(set(dir(cls._member_type_)) | interesting)
///
///     def __getattr__(cls, name):
///         """
///         Return the enum member matching `name`
///
///         We use __getattr__ instead of descriptors or inserting into the enum
///         class' __dict__ in order to support `name` and `value` being both
///         properties for enum members (which live in the class' __dict__) and
///         enum members themselves.
///         """
///         if _is_dunder(name):
///             raise AttributeError(name)
///         try:
///             return cls._member_map_[name]
///         except KeyError:
///             raise AttributeError(name) from None
///
///     def __getitem__(cls, name):
///         """
///         Return the member matching `name`.
///         """
///         return cls._member_map_[name]
///
///     def __iter__(cls):
///         """
///         Return members in definition order.
///         """
///         return (cls._member_map_[name] for name in cls._member_names_)
///
///     def __len__(cls):
///         """
///         Return the number of members (no aliases)
///         """
///         return len(cls._member_names_)
///
///     @bltns.property
///     def __members__(cls):
///         """
///         Returns a mapping of member name->value.
///
///         This mapping lists all enum members, including aliases. Note that this
///         is a read-only view of the internal mapping.
///         """
///         return MappingProxyType(cls._member_map_)
///
///     def __repr__(cls):
///         if Flag is not None and issubclass(cls, Flag):
///             return "<flag %r>" % cls.__name__
///         else:
///             return "<enum %r>" % cls.__name__
///
///     def __reversed__(cls):
///         """
///         Return members in reverse definition order.
///         """
///         return (cls._member_map_[name] for name in reversed(cls._member_names_))
///
///     def __setattr__(cls, name, value):
///         """
///         Block attempts to reassign Enum members.
///
///         A simple assignment to the class namespace only changes one of the
///         several possible ways to get an Enum member from the Enum class,
///         resulting in an inconsistent Enumeration.
///         """
///         member_map = cls.__dict__.get('_member_map_', {})
///         if name in member_map:
///             raise AttributeError('cannot reassign member %r' % (name, ))
///         super().__setattr__(name, value)
///
///     def _create_(cls, class_name, names, *, module=None, qualname=None, type=None, start=1, boundary=None):
///         """
///         Convenience method to create a new Enum class.
///
///         `names` can be:
///
///         * A string containing member names, separated either with spaces or
///           commas.  Values are incremented by 1 from `start`.
///         * An iterable of member names.  Values are incremented by 1 from `start`.
///         * An iterable of (member name, value) pairs.
///         * A mapping of member name -> value pairs.
///         """
///         metacls = cls.__class__
///         bases = (cls, ) if type is None else (type, cls)
///         _, first_enum = cls._get_mixins_(class_name, bases)
///         classdict = metacls.__prepare__(class_name, bases)
///
///         # special processing needed for names?
///         if isinstance(names, str):
///             names = names.replace(',', ' ').split()
///         if isinstance(names, (tuple, list)) and names and isinstance(names[0], str):
///             original_names, names = names, []
///             last_values = []
///             for count, name in enumerate(original_names):
///                 value = first_enum._generate_next_value_(name, start, count, last_values[:])
///                 last_values.append(value)
///                 names.append((name, value))
///
///         # Here, names is either an iterable of (name, value) or a mapping.
///         for item in names:
///             if isinstance(item, str):
///                 member_name, member_value = item, names[item]
///             else:
///                 member_name, member_value = item
///             classdict[member_name] = member_value
///
///         # TODO: replace the frame hack if a blessed way to know the calling
///         # module is ever developed
///         if module is None:
///             try:
///                 module = sys._getframe(2).f_globals['__name__']
///             except (AttributeError, ValueError, KeyError):
///                 pass
///         if module is None:
///             _make_class_unpicklable(classdict)
///         else:
///             classdict['__module__'] = module
///         if qualname is not None:
///             classdict['__qualname__'] = qualname
///
///         return metacls.__new__(metacls, class_name, bases, classdict, boundary=boundary)
///
///     def _convert_(cls, name, module, filter, source=None, *, boundary=None, as_global=False):
///         """
///         Create a new Enum subclass that replaces a collection of global constants
///         """
///         # convert all constants from source (or module) that pass filter() to
///         # a new Enum called name, and export the enum and its members back to
///         # module;
///         # also, replace the __reduce_ex__ method so unpickling works in
///         # previous Python versions
///         module_globals = sys.modules[module].__dict__
///         if source:
///             source = source.__dict__
///         else:
///             source = module_globals
///         # _value2member_map_ is populated in the same order every time
///         # for a consistent reverse mapping of number to name when there
///         # are multiple names for the same number.
///         members = [
///                 (name, value)
///                 for name, value in source.items()
///                 if filter(name)]
///         try:
///             # sort by value
///             members.sort(key=lambda t: (t[1], t[0]))
///         except TypeError:
///             # unless some values aren't comparable, in which case sort by name
///             members.sort(key=lambda t: t[0])
///         body = {t[0]: t[1] for t in members}
///         body['__module__'] = module
///         tmp_cls = type(name, (object, ), body)
///         cls = _simple_enum(etype=cls, boundary=boundary or KEEP)(tmp_cls)
///         cls.__reduce_ex__ = _reduce_ex_by_global_name
///         if as_global:
///             global_enum(cls)
///         else:
///             sys.modules[cls.__module__].__dict__.update(cls.__members__)
///         module_globals[name] = cls
///         return cls
///
///     @classmethod
///     def _check_for_existing_members_(mcls, class_name, bases):
///         for chain in bases:
///             for base in chain.__mro__:
///                 if isinstance(base, EnumType) and base._member_names_:
///                     raise TypeError(
///                             "<enum %r> cannot extend %r"
///                             % (class_name, base)
///                             )
///
///     @classmethod
///     def _get_mixins_(mcls, class_name, bases):
///         """
///         Returns the type for creating enum members, and the first inherited
///         enum class.
///
///         bases: the tuple of bases that was given to __new__
///         """
///         if not bases:
///             return object, Enum
///
///         mcls._check_for_existing_members_(class_name, bases)
///
///         # ensure final parent class is an Enum derivative, find any concrete
///         # data type, and check that Enum has no members
///         first_enum = bases[-1]
///         if not isinstance(first_enum, EnumType):
///             raise TypeError("new enumerations should be created as "
///                     "`EnumName([mixin_type, ...] [data_type,] enum_type)`")
///         member_type = mcls._find_data_type_(class_name, bases) or object
///         return member_type, first_enum
///
///     @classmethod
///     def _find_data_repr_(mcls, class_name, bases):
///         for chain in bases:
///             for base in chain.__mro__:
///                 if base is object:
///                     continue
///                 elif isinstance(base, EnumType):
///                     # if we hit an Enum, use it's _value_repr_
///                     return base._value_repr_
///                 elif '__repr__' in base.__dict__:
///                     # this is our data repr
///                     return base.__dict__['__repr__']
///         return None
///
///     @classmethod
///     def _find_data_type_(mcls, class_name, bases):
///         data_types = set()
///         base_chain = set()
///         for chain in bases:
///             candidate = None
///             for base in chain.__mro__:
///                 base_chain.add(base)
///                 if base is object:
///                     continue
///                 elif isinstance(base, EnumType):
///                     if base._member_type_ is not object:
///                         data_types.add(base._member_type_)
///                         break
///                 elif '__new__' in base.__dict__ or '__init__' in base.__dict__:
///                     if isinstance(base, EnumType):
///                         continue
///                     data_types.add(candidate or base)
///                     break
///                 else:
///                     candidate = candidate or base
///         if len(data_types) > 1:
///             raise TypeError('too many data types for %r: %r' % (class_name, data_types))
///         elif data_types:
///             return data_types.pop()
///         else:
///             return None
///
///     @classmethod
///     def _find_new_(mcls, classdict, member_type, first_enum):
///         """
///         Returns the __new__ to be used for creating the enum members.
///
///         classdict: the class dictionary given to __new__
///         member_type: the data type whose __new__ will be used by default
///         first_enum: enumeration to check for an overriding __new__
///         """
///         # now find the correct __new__, checking to see of one was defined
///         # by the user; also check earlier enum classes in case a __new__ was
///         # saved as __new_member__
///         __new__ = classdict.get('__new__', None)
///
///         # should __new__ be saved as __new_member__ later?
///         save_new = first_enum is not None and __new__ is not None
///
///         if __new__ is None:
///             # check all possibles for __new_member__ before falling back to
///             # __new__
///             for method in ('__new_member__', '__new__'):
///                 for possible in (member_type, first_enum):
///                     target = getattr(possible, method, None)
///                     if target not in {
///                             None,
///                             None.__new__,
///                             object.__new__,
///                             Enum.__new__,
///                             }:
///                         __new__ = target
///                         break
///                 if __new__ is not None:
///                     break
///             else:
///                 __new__ = object.__new__
///
///         # if a non-object.__new__ is used then whatever value/tuple was
///         # assigned to the enum member name will be passed to __new__ and to the
///         # new enum member's __init__
///         if first_enum is None or __new__ in (Enum.__new__, object.__new__):
///             use_args = False
///         else:
///             use_args = True
///         return __new__, save_new, use_args
/// EnumMeta = EnumType
///
///
/// class Enum(metaclass=EnumType):
///     """
///     Create a collection of name/value pairs.
///
///     Example enumeration:
///
///     >>> class Color(Enum):
///     ...     RED = 1
///     ...     BLUE = 2
///     ...     GREEN = 3
///
///     Access them by:
///
///     - attribute access::
///
///     >>> Color.RED
///     <Color.RED: 1>
///
///     - value lookup:
///
///     >>> Color(1)
///     <Color.RED: 1>
///
///     - name lookup:
///
///     >>> Color['RED']
///     <Color.RED: 1>
///
///     Enumerations can be iterated over, and know how many members they have:
///
///     >>> len(Color)
///     3
///
///     >>> list(Color)
///     [<Color.RED: 1>, <Color.BLUE: 2>, <Color.GREEN: 3>]
///
///     Methods can be added to enumerations, and members can have their own
///     attributes -- see the documentation for details.
///     """
///
///     def __new__(cls, value):
///         # all enum instances are actually created during class construction
///         # without calling this method; this method is called by the metaclass'
///         # __call__ (i.e. Color(3) ), and by pickle
///         if type(value) is cls:
///             # For lookups like Color(Color.RED)
///             return value
///         # by-value search for a matching enum member
///         # see if it's in the reverse mapping (for hashable values)
///         try:
///             return cls._value2member_map_[value]
///         except KeyError:
///             # Not found, no need to do long O(n) search
///             pass
///         except TypeError:
///             # not there, now do long search -- O(n) behavior
///             for member in cls._member_map_.values():
///                 if member._value_ == value:
///                     return member
///         # still not found -- try _missing_ hook
///         try:
///             exc = None
///             result = cls._missing_(value)
///         except Exception as e:
///             exc = e
///             result = None
///         try:
///             if isinstance(result, cls):
///                 return result
///             elif (
///                     Flag is not None and issubclass(cls, Flag)
///                     and cls._boundary_ is EJECT and isinstance(result, int)
///                 ):
///                 return result
///             else:
///                 ve_exc = ValueError("%r is not a valid %s" % (value, cls.__qualname__))
///                 if result is None and exc is None:
///                     raise ve_exc
///                 elif exc is None:
///                     exc = TypeError(
///                             'error in %s._missing_: returned %r instead of None or a valid member'
///                             % (cls.__name__, result)
///                             )
///                 if not isinstance(exc, ValueError):
///                     exc.__context__ = ve_exc
///                 raise exc
///         finally:
///             # ensure all variables that could hold an exception are destroyed
///             exc = None
///             ve_exc = None
///
///     def __init__(self, *args, **kwds):
///         pass
///
///     def _generate_next_value_(name, start, count, last_values):
///         """
///         Generate the next value when not given.
///
///         name: the name of the member
///         start: the initial start value or None
///         count: the number of existing members
///         last_values: the list of values assigned
///         """
///         if not last_values:
///             return start
///         try:
///             last = last_values[-1]
///             last_values.sort()
///             if last == last_values[-1]:
///                 # no difference between old and new methods
///                 return last + 1
///             else:
///                 # trigger old method (with warning)
///                 raise TypeError
///         except TypeError:
///             import warnings
///             warnings.warn(
///                     "In 3.13 the default `auto()`/`_generate_next_value_` will require all values to be sortable and support adding +1\n"
///                     "and the value returned will be the largest value in the enum incremented by 1",
///                     DeprecationWarning,
///                     stacklevel=3,
///                     )
///             for v in last_values:
///                 try:
///                     return v + 1
///                 except TypeError:
///                     pass
///             return start
///
///     @classmethod
///     def _missing_(cls, value):
///         return None
///
///     def __repr__(self):
///         v_repr = self.__class__._value_repr_ or repr
///         return "<%s.%s: %s>" % (self.__class__.__name__, self._name_, v_repr(self._value_))
///
///     def __str__(self):
///         return "%s.%s" % (self.__class__.__name__, self._name_, )
///
///     def __dir__(self):
///         """
///         Returns all members and all public methods
///         """
///         if self.__class__._member_type_ is object:
///             interesting = set(['__class__', '__doc__', '__eq__', '__hash__', '__module__', 'name', 'value'])
///         else:
///             interesting = set(object.__dir__(self))
///         for name in getattr(self, '__dict__', []):
///             if name[0] != '_':
///                 interesting.add(name)
///         for cls in self.__class__.mro():
///             for name, obj in cls.__dict__.items():
///                 if name[0] == '_':
///                     continue
///                 if isinstance(obj, property):
///                     # that's an enum.property
///                     if obj.fget is not None or name not in self._member_map_:
///                         interesting.add(name)
///                     else:
///                         # in case it was added by `dir(self)`
///                         interesting.discard(name)
///                 else:
///                     interesting.add(name)
///         names = sorted(
///                 set(['__class__', '__doc__', '__eq__', '__hash__', '__module__'])
///                 | interesting
///                 )
///         return names
///
///     def __format__(self, format_spec):
///         return str.__format__(str(self), format_spec)
///
///     def __hash__(self):
///         return hash(self._name_)
///
///     def __reduce_ex__(self, proto):
///         return getattr, (self.__class__, self._name_)
///
///     # enum.property is used to provide access to the `name` and
///     # `value` attributes of enum members while keeping some measure of
///     # protection from modification, while still allowing for an enumeration
///     # to have members named `name` and `value`.  This works because enumeration
///     # members are not set directly on the enum class; they are kept in a
///     # separate structure, _member_map_, which is where enum.property looks for
///     # them
///
///     @property
///     def name(self):
///         """The name of the Enum member."""
///         return self._name_
///
///     @property
///     def value(self):
///         """The value of the Enum member."""
///         return self._value_
///
///
/// class ReprEnum(Enum):
///     """
///     Only changes the repr(), leaving str() and format() to the mixed-in type.
///     """
///
///
/// class IntEnum(int, ReprEnum):
///     """
///     Enum where members are also (and must be) ints
///     """
///
///
/// class StrEnum(str, ReprEnum):
///     """
///     Enum where members are also (and must be) strings
///     """
///
///     def __new__(cls, *values):
///         "values must already be of type `str`"
///         if len(values) > 3:
///             raise TypeError('too many arguments for str(): %r' % (values, ))
///         if len(values) == 1:
///             # it must be a string
///             if not isinstance(values[0], str):
///                 raise TypeError('%r is not a string' % (values[0], ))
///         if len(values) >= 2:
///             # check that encoding argument is a string
///             if not isinstance(values[1], str):
///                 raise TypeError('encoding must be a string, not %r' % (values[1], ))
///         if len(values) == 3:
///             # check that errors argument is a string
///             if not isinstance(values[2], str):
///                 raise TypeError('errors must be a string, not %r' % (values[2]))
///         value = str(*values)
///         member = str.__new__(cls, value)
///         member._value_ = value
///         return member
///
///     def _generate_next_value_(name, start, count, last_values):
///         """
///         Return the lower-cased version of the member name.
///         """
///         return name.lower()
///
///
/// def _reduce_ex_by_global_name(self, proto):
///     return self.name
///
/// class FlagBoundary(StrEnum):
///     """
///     control how out of range values are handled
///     "strict" -> error is raised
///     "conform" -> extra bits are discarded   [default for Flag]
///     "eject" -> lose flag status
///     "keep" -> keep flag status and all bits [default for IntFlag]
///     """
///     STRICT = auto()
///     CONFORM = auto()
///     EJECT = auto()
///     KEEP = auto()
/// STRICT, CONFORM, EJECT, KEEP = FlagBoundary
///
///
/// class Flag(Enum, boundary=CONFORM):
///     """
///     Support for flags
///     """
///
///     def __reduce_ex__(self, proto):
///         cls = self.__class__
///         unknown = self._value_ & ~cls._flag_mask_
///         member_value = self._value_ & cls._flag_mask_
///         if unknown and member_value:
///             return _or_, (cls(member_value), unknown)
///         for val in _iter_bits_lsb(member_value):
///             rest = member_value & ~val
///             if rest:
///                 return _or_, (cls(rest), cls._value2member_map_.get(val))
///             else:
///                 break
///         if self._name_ is None:
///             return cls, (self._value_,)
///         else:
///             return getattr, (cls, self._name_)
///
///     _numeric_repr_ = repr
///
///     def _generate_next_value_(name, start, count, last_values):
///         """
///         Generate the next value when not given.
///
///         name: the name of the member
///         start: the initial start value or None
///         count: the number of existing members
///         last_values: the last value assigned or None
///         """
///         if not count:
///             return start if start is not None else 1
///         last_value = max(last_values)
///         try:
///             high_bit = _high_bit(last_value)
///         except Exception:
///             raise TypeError('invalid flag value %r' % last_value) from None
///         return 2 ** (high_bit+1)
///
///     @classmethod
///     def _iter_member_by_value_(cls, value):
///         """
///         Extract all members from the value in definition (i.e. increasing value) order.
///         """
///         for val in _iter_bits_lsb(value & cls._flag_mask_):
///             yield cls._value2member_map_.get(val)
///
///     _iter_member_ = _iter_member_by_value_
///
///     @classmethod
///     def _iter_member_by_def_(cls, value):
///         """
///         Extract all members from the value in definition order.
///         """
///         yield from sorted(
///                 cls._iter_member_by_value_(value),
///                 key=lambda m: m._sort_order_,
///                 )
///
///     @classmethod
///     def _missing_(cls, value):
///         """
///         Create a composite member containing all canonical members present in `value`.
///
///         If non-member values are present, result depends on `_boundary_` setting.
///         """
///         if not isinstance(value, int):
///             raise ValueError(
///                     "%r is not a valid %s" % (value, cls.__qualname__)
///                     )
///         # check boundaries
///         # - value must be in range (e.g. -16 <-> +15, i.e. ~15 <-> 15)
///         # - value must not include any skipped flags (e.g. if bit 2 is not
///         #   defined, then 0d10 is invalid)
///         flag_mask = cls._flag_mask_
///         all_bits = cls._all_bits_
///         neg_value = None
///         if (
///                 not ~all_bits <= value <= all_bits
///                 or value & (all_bits ^ flag_mask)
///             ):
///             if cls._boundary_ is STRICT:
///                 max_bits = max(value.bit_length(), flag_mask.bit_length())
///                 raise ValueError(
///                         "%r invalid value %r\n    given %s\n  allowed %s" % (
///                             cls, value, bin(value, max_bits), bin(flag_mask, max_bits),
///                             ))
///             elif cls._boundary_ is CONFORM:
///                 value = value & flag_mask
///             elif cls._boundary_ is EJECT:
///                 return value
///             elif cls._boundary_ is KEEP:
///                 if value < 0:
///                     value = (
///                             max(all_bits+1, 2**(value.bit_length()))
///                             + value
///                             )
///             else:
///                 raise ValueError(
///                         '%r unknown flag boundary %r' % (cls, cls._boundary_, )
///                         )
///         if value < 0:
///             neg_value = value
///             value = all_bits + 1 + value
///         # get members and unknown
///         unknown = value & ~flag_mask
///         member_value = value & flag_mask
///         if unknown and cls._boundary_ is not KEEP:
///             raise ValueError(
///                     '%s(%r) -->  unknown values %r [%s]'
///                     % (cls.__name__, value, unknown, bin(unknown))
///                     )
///         # normal Flag?
///         if cls._member_type_ is object:
///             # construct a singleton enum pseudo-member
///             pseudo_member = object.__new__(cls)
///         else:
///             pseudo_member = cls._member_type_.__new__(cls, value)
///         if not hasattr(pseudo_member, '_value_'):
///             pseudo_member._value_ = value
///         if member_value:
///             pseudo_member._name_ = '|'.join([
///                 m._name_ for m in cls._iter_member_(member_value)
///                 ])
///             if unknown:
///                 pseudo_member._name_ += '|%s' % cls._numeric_repr_(unknown)
///         else:
///             pseudo_member._name_ = None
///         # use setdefault in case another thread already created a composite
///         # with this value, but only if all members are known
///         # note: zero is a special case -- add it
///         if not unknown:
///             pseudo_member = cls._value2member_map_.setdefault(value, pseudo_member)
///             if neg_value is not None:
///                 cls._value2member_map_[neg_value] = pseudo_member
///         return pseudo_member
///
///     def __contains__(self, other):
///         """
///         Returns True if self has at least the same flags set as other.
///         """
///         if not isinstance(other, self.__class__):
///             raise TypeError(
///                 "unsupported operand type(s) for 'in': %r and %r" % (
///                     type(other).__qualname__, self.__class__.__qualname__))
///         return other._value_ & self._value_ == other._value_
///
///     def __iter__(self):
///         """
///         Returns flags in definition order.
///         """
///         yield from self._iter_member_(self._value_)
///
///     def __len__(self):
///         return self._value_.bit_count()
///
///     def __repr__(self):
///         cls_name = self.__class__.__name__
///         v_repr = self.__class__._value_repr_ or repr
///         if self._name_ is None:
///             return "<%s: %s>" % (cls_name, v_repr(self._value_))
///         else:
///             return "<%s.%s: %s>" % (cls_name, self._name_, v_repr(self._value_))
///
///     def __str__(self):
///         cls_name = self.__class__.__name__
///         if self._name_ is None:
///             return '%s(%r)' % (cls_name, self._value_)
///         else:
///             return "%s.%s" % (cls_name, self._name_)
///
///     def __bool__(self):
///         return bool(self._value_)
///
///     def __or__(self, other):
///         if isinstance(other, self.__class__):
///             other = other._value_
///         elif self._member_type_ is not object and isinstance(other, self._member_type_):
///             other = other
///         else:
///             return NotImplemented
///         value = self._value_
///         return self.__class__(value | other)
///
///     def __and__(self, other):
///         if isinstance(other, self.__class__):
///             other = other._value_
///         elif self._member_type_ is not object and isinstance(other, self._member_type_):
///             other = other
///         else:
///             return NotImplemented
///         value = self._value_
///         return self.__class__(value & other)
///
///     def __xor__(self, other):
///         if isinstance(other, self.__class__):
///             other = other._value_
///         elif self._member_type_ is not object and isinstance(other, self._member_type_):
///             other = other
///         else:
///             return NotImplemented
///         value = self._value_
///         return self.__class__(value ^ other)
///
///     def __invert__(self):
///         if self._inverted_ is None:
///             if self._boundary_ is KEEP:
///                 # use all bits
///                 self._inverted_ = self.__class__(~self._value_)
///             else:
///                 # calculate flags not in this member
///                 self._inverted_ = self.__class__(self._flag_mask_ ^ self._value_)
///             if isinstance(self._inverted_, self.__class__):
///                 self._inverted_._inverted_ = self
///         return self._inverted_
///
///     __rand__ = __and__
///     __ror__ = __or__
///     __rxor__ = __xor__
///
///
/// class IntFlag(int, ReprEnum, Flag, boundary=KEEP):
///     """
///     Support for integer-based Flags
///     """
///
///
/// def _high_bit(value):
///     """
///     returns index of highest bit, or -1 if value is zero or negative
///     """
///     return value.bit_length() - 1
///
/// def unique(enumeration):
///     """
///     Class decorator for enumerations ensuring unique member values.
///     """
///     duplicates = []
///     for name, member in enumeration.__members__.items():
///         if name != member.name:
///             duplicates.append((name, member.name))
///     if duplicates:
///         alias_details = ', '.join(
///                 ["%s -> %s" % (alias, name) for (alias, name) in duplicates])
///         raise ValueError('duplicate values found in %r: %s' %
///                 (enumeration, alias_details))
///     return enumeration
///
/// def _power_of_two(value):
///     if value < 1:
///         return False
///     return value == 2 ** _high_bit(value)
///
/// def global_enum_repr(self):
///     """
///     use module.enum_name instead of class.enum_name
///
///     the module is the last module in case of a multi-module name
///     """
///     module = self.__class__.__module__.split('.')[-1]
///     return '%s.%s' % (module, self._name_)
///
/// def global_flag_repr(self):
///     """
///     use module.flag_name instead of class.flag_name
///
///     the module is the last module in case of a multi-module name
///     """
///     module = self.__class__.__module__.split('.')[-1]
///     cls_name = self.__class__.__name__
///     if self._name_ is None:
///         return "%s.%s(%r)" % (module, cls_name, self._value_)
///     if _is_single_bit(self):
///         return '%s.%s' % (module, self._name_)
///     if self._boundary_ is not FlagBoundary.KEEP:
///         return '|'.join(['%s.%s' % (module, name) for name in self.name.split('|')])
///     else:
///         name = []
///         for n in self._name_.split('|'):
///             if n[0].isdigit():
///                 name.append(n)
///             else:
///                 name.append('%s.%s' % (module, n))
///         return '|'.join(name)
///
/// def global_str(self):
///     """
///     use enum_name instead of class.enum_name
///     """
///     if self._name_ is None:
///         cls_name = self.__class__.__name__
///         return "%s(%r)" % (cls_name, self._value_)
///     else:
///         return self._name_
///
/// def global_enum(cls, update_str=False):
///     """
///     decorator that makes the repr() of an enum member reference its module
///     instead of its class; also exports all members to the enum's module's
///     global namespace
///     """
///     if issubclass(cls, Flag):
///         cls.__repr__ = global_flag_repr
///     else:
///         cls.__repr__ = global_enum_repr
///     if not issubclass(cls, ReprEnum) or update_str:
///         cls.__str__ = global_str
///     sys.modules[cls.__module__].__dict__.update(cls.__members__)
///     return cls
///
/// def _simple_enum(etype=Enum, *, boundary=None, use_args=None):
///     """
///     Class decorator that converts a normal class into an :class:`Enum`.  No
///     safety checks are done, and some advanced behavior (such as
///     :func:`__init_subclass__`) is not available.  Enum creation can be faster
///     using :func:`simple_enum`.
///
///         >>> from enum import Enum, _simple_enum
///         >>> @_simple_enum(Enum)
///         ... class Color:
///         ...     RED = auto()
///         ...     GREEN = auto()
///         ...     BLUE = auto()
///         >>> Color
///         <enum 'Color'>
///     """
///     def convert_class(cls):
///         nonlocal use_args
///         cls_name = cls.__name__
///         if use_args is None:
///             use_args = etype._use_args_
///         __new__ = cls.__dict__.get('__new__')
///         if __new__ is not None:
///             new_member = __new__.__func__
///         else:
///             new_member = etype._member_type_.__new__
///         attrs = {}
///         body = {}
///         if __new__ is not None:
///             body['__new_member__'] = new_member
///         body['_new_member_'] = new_member
///         body['_use_args_'] = use_args
///         body['_generate_next_value_'] = gnv = etype._generate_next_value_
///         body['_member_names_'] = member_names = []
///         body['_member_map_'] = member_map = {}
///         body['_value2member_map_'] = value2member_map = {}
///         body['_unhashable_values_'] = []
///         body['_member_type_'] = member_type = etype._member_type_
///         body['_value_repr_'] = etype._value_repr_
///         if issubclass(etype, Flag):
///             body['_boundary_'] = boundary or etype._boundary_
///             body['_flag_mask_'] = None
///             body['_all_bits_'] = None
///             body['_inverted_'] = None
///             body['__or__'] = Flag.__or__
///             body['__xor__'] = Flag.__xor__
///             body['__and__'] = Flag.__and__
///             body['__ror__'] = Flag.__ror__
///             body['__rxor__'] = Flag.__rxor__
///             body['__rand__'] = Flag.__rand__
///             body['__invert__'] = Flag.__invert__
///         for name, obj in cls.__dict__.items():
///             if name in ('__dict__', '__weakref__'):
///                 continue
///             if _is_dunder(name) or _is_private(cls_name, name) or _is_sunder(name) or _is_descriptor(obj):
///                 body[name] = obj
///             else:
///                 attrs[name] = obj
///         if cls.__dict__.get('__doc__') is None:
///             body['__doc__'] = 'An enumeration.'
///         #
///         # double check that repr and friends are not the mixin's or various
///         # things break (such as pickle)
///         # however, if the method is defined in the Enum itself, don't replace
///         # it
///         enum_class = type(cls_name, (etype, ), body, boundary=boundary, _simple=True)
///         for name in ('__repr__', '__str__', '__format__', '__reduce_ex__'):
///             if name not in body:
///                 # check for mixin overrides before replacing
///                 enum_method = getattr(etype, name)
///                 found_method = getattr(enum_class, name)
///                 object_method = getattr(object, name)
///                 data_type_method = getattr(member_type, name)
///                 if found_method in (data_type_method, object_method):
///                     setattr(enum_class, name, enum_method)
///         gnv_last_values = []
///         if issubclass(enum_class, Flag):
///             # Flag / IntFlag
///             single_bits = multi_bits = 0
///             for name, value in attrs.items():
///                 if isinstance(value, auto) and auto.value is _auto_null:
///                     value = gnv(name, 1, len(member_names), gnv_last_values)
///                 if value in value2member_map:
///                     # an alias to an existing member
///                     redirect = property()
///                     redirect.__set_name__(enum_class, name)
///                     setattr(enum_class, name, redirect)
///                     member_map[name] = value2member_map[value]
///                 else:
///                     # create the member
///                     if use_args:
///                         if not isinstance(value, tuple):
///                             value = (value, )
///                         member = new_member(enum_class, *value)
///                         value = value[0]
///                     else:
///                         member = new_member(enum_class)
///                     if __new__ is None:
///                         member._value_ = value
///                     member._name_ = name
///                     member.__objclass__ = enum_class
///                     member.__init__(value)
///                     redirect = property()
///                     redirect.__set_name__(enum_class, name)
///                     setattr(enum_class, name, redirect)
///                     member_map[name] = member
///                     member._sort_order_ = len(member_names)
///                     value2member_map[value] = member
///                     if _is_single_bit(value):
///                         # not a multi-bit alias, record in _member_names_ and _flag_mask_
///                         member_names.append(name)
///                         single_bits |= value
///                     else:
///                         multi_bits |= value
///                     gnv_last_values.append(value)
///             enum_class._flag_mask_ = single_bits
///             enum_class._all_bits_ = 2 ** ((single_bits|multi_bits).bit_length()) - 1
///             # set correct __iter__
///             member_list = [m._value_ for m in enum_class]
///             if member_list != sorted(member_list):
///                 enum_class._iter_member_ = enum_class._iter_member_by_def_
///         else:
///             # Enum / IntEnum / StrEnum
///             for name, value in attrs.items():
///                 if isinstance(value, auto):
///                     if value.value is _auto_null:
///                         value.value = gnv(name, 1, len(member_names), gnv_last_values)
///                     value = value.value
///                 if value in value2member_map:
///                     # an alias to an existing member
///                     redirect = property()
///                     redirect.__set_name__(enum_class, name)
///                     setattr(enum_class, name, redirect)
///                     member_map[name] = value2member_map[value]
///                 else:
///                     # create the member
///                     if use_args:
///                         if not isinstance(value, tuple):
///                             value = (value, )
///                         member = new_member(enum_class, *value)
///                         value = value[0]
///                     else:
///                         member = new_member(enum_class)
///                     if __new__ is None:
///                         member._value_ = value
///                     member._name_ = name
///                     member.__objclass__ = enum_class
///                     member.__init__(value)
///                     member._sort_order_ = len(member_names)
///                     redirect = property()
///                     redirect.__set_name__(enum_class, name)
///                     setattr(enum_class, name, redirect)
///                     member_map[name] = member
///                     value2member_map[value] = member
///                     member_names.append(name)
///                     gnv_last_values.append(value)
///         if '__new__' in body:
///             enum_class.__new_member__ = enum_class.__new__
///         enum_class.__new__ = Enum.__new__
///         return enum_class
///     return convert_class
///
/// @_simple_enum(StrEnum)
/// class EnumCheck:
///     """
///     various conditions to check an enumeration for
///     """
///     CONTINUOUS = "no skipped integer values"
///     NAMED_FLAGS = "multi-flag aliases may not contain unnamed flags"
///     UNIQUE = "one name per value"
/// CONTINUOUS, NAMED_FLAGS, UNIQUE = EnumCheck
///
///
/// class verify:
///     """
///     Check an enumeration for various constraints. (see EnumCheck)
///     """
///     def __init__(self, *checks):
///         self.checks = checks
///     def __call__(self, enumeration):
///         checks = self.checks
///         cls_name = enumeration.__name__
///         if Flag is not None and issubclass(enumeration, Flag):
///             enum_type = 'flag'
///         elif issubclass(enumeration, Enum):
///             enum_type = 'enum'
///         else:
///             raise TypeError("the 'verify' decorator only works with Enum and Flag")
///         for check in checks:
///             if check is UNIQUE:
///                 # check for duplicate names
///                 duplicates = []
///                 for name, member in enumeration.__members__.items():
///                     if name != member.name:
///                         duplicates.append((name, member.name))
///                 if duplicates:
///                     alias_details = ', '.join(
///                             ["%s -> %s" % (alias, name) for (alias, name) in duplicates])
///                     raise ValueError('aliases found in %r: %s' %
///                             (enumeration, alias_details))
///             elif check is CONTINUOUS:
///                 values = set(e.value for e in enumeration)
///                 if len(values) < 2:
///                     continue
///                 low, high = min(values), max(values)
///                 missing = []
///                 if enum_type == 'flag':
///                     # check for powers of two
///                     for i in range(_high_bit(low)+1, _high_bit(high)):
///                         if 2**i not in values:
///                             missing.append(2**i)
///                 elif enum_type == 'enum':
///                     # check for powers of one
///                     for i in range(low+1, high):
///                         if i not in values:
///                             missing.append(i)
///                 else:
///                     raise Exception('verify: unknown type %r' % enum_type)
///                 if missing:
///                     raise ValueError(('invalid %s %r: missing values %s' % (
///                             enum_type, cls_name, ', '.join((str(m) for m in missing)))
///                             )[:256])
///                             # limit max length to protect against DOS attacks
///             elif check is NAMED_FLAGS:
///                 # examine each alias and check for unnamed flags
///                 member_names = enumeration._member_names_
///                 member_values = [m.value for m in enumeration]
///                 missing_names = []
///                 missing_value = 0
///                 for name, alias in enumeration._member_map_.items():
///                     if name in member_names:
///                         # not an alias
///                         continue
///                     if alias.value < 0:
///                         # negative numbers are not checked
///                         continue
///                     values = list(_iter_bits_lsb(alias.value))
///                     missed = [v for v in values if v not in member_values]
///                     if missed:
///                         missing_names.append(name)
///                         missing_value |= reduce(_or_, missed)
///                 if missing_names:
///                     if len(missing_names) == 1:
///                         alias = 'alias %s is missing' % missing_names[0]
///                     else:
///                         alias = 'aliases %s and %s are missing' % (
///                                 ', '.join(missing_names[:-1]), missing_names[-1]
///                                 )
///                     if _is_single_bit(missing_value):
///                         value = 'value 0x%x' % missing_value
///                     else:
///                         value = 'combined values of 0x%x' % missing_value
///                     raise ValueError(
///                             'invalid Flag %r: %s %s [use enum.show_flag_values(value) for details]'
///                             % (cls_name, alias, value)
///                             )
///         return enumeration
///
/// def _test_simple_enum(checked_enum, simple_enum):
///     """
///     A function that can be used to test an enum created with :func:`_simple_enum`
///     against the version created by subclassing :class:`Enum`::
///
///         >>> from enum import Enum, _simple_enum, _test_simple_enum
///         >>> @_simple_enum(Enum)
///         ... class Color:
///         ...     RED = auto()
///         ...     GREEN = auto()
///         ...     BLUE = auto()
///         >>> class CheckedColor(Enum):
///         ...     RED = auto()
///         ...     GREEN = auto()
///         ...     BLUE = auto()
///         >>> _test_simple_enum(CheckedColor, Color)
///
///     If differences are found, a :exc:`TypeError` is raised.
///     """
///     failed = []
///     if checked_enum.__dict__ != simple_enum.__dict__:
///         checked_dict = checked_enum.__dict__
///         checked_keys = list(checked_dict.keys())
///         simple_dict = simple_enum.__dict__
///         simple_keys = list(simple_dict.keys())
///         member_names = set(
///                 list(checked_enum._member_map_.keys())
///                 + list(simple_enum._member_map_.keys())
///                 )
///         for key in set(checked_keys + simple_keys):
///             if key in ('__module__', '_member_map_', '_value2member_map_', '__doc__'):
///                 # keys known to be different, or very long
///                 continue
///             elif key in member_names:
///                 # members are checked below
///                 continue
///             elif key not in simple_keys:
///                 failed.append("missing key: %r" % (key, ))
///             elif key not in checked_keys:
///                 failed.append("extra key:   %r" % (key, ))
///             else:
///                 checked_value = checked_dict[key]
///                 simple_value = simple_dict[key]
///                 if callable(checked_value) or isinstance(checked_value, bltns.property):
///                     continue
///                 if key == '__doc__':
///                     # remove all spaces/tabs
///                     compressed_checked_value = checked_value.replace(' ','').replace('\t','')
///                     compressed_simple_value = simple_value.replace(' ','').replace('\t','')
///                     if compressed_checked_value != compressed_simple_value:
///                         failed.append("%r:\n         %s\n         %s" % (
///                                 key,
///                                 "checked -> %r" % (checked_value, ),
///                                 "simple  -> %r" % (simple_value, ),
///                                 ))
///                 elif checked_value != simple_value:
///                     failed.append("%r:\n         %s\n         %s" % (
///                             key,
///                             "checked -> %r" % (checked_value, ),
///                             "simple  -> %r" % (simple_value, ),
///                             ))
///         failed.sort()
///         for name in member_names:
///             failed_member = []
///             if name not in simple_keys:
///                 failed.append('missing member from simple enum: %r' % name)
///             elif name not in checked_keys:
///                 failed.append('extra member in simple enum: %r' % name)
///             else:
///                 checked_member_dict = checked_enum[name].__dict__
///                 checked_member_keys = list(checked_member_dict.keys())
///                 simple_member_dict = simple_enum[name].__dict__
///                 simple_member_keys = list(simple_member_dict.keys())
///                 for key in set(checked_member_keys + simple_member_keys):
///                     if key in ('__module__', '__objclass__', '_inverted_'):
///                         # keys known to be different or absent
///                         continue
///                     elif key not in simple_member_keys:
///                         failed_member.append("missing key %r not in the simple enum member %r" % (key, name))
///                     elif key not in checked_member_keys:
///                         failed_member.append("extra key %r in simple enum member %r" % (key, name))
///                     else:
///                         checked_value = checked_member_dict[key]
///                         simple_value = simple_member_dict[key]
///                         if checked_value != simple_value:
///                             failed_member.append("%r:\n         %s\n         %s" % (
///                                     key,
///                                     "checked member -> %r" % (checked_value, ),
///                                     "simple member  -> %r" % (simple_value, ),
///                                     ))
///             if failed_member:
///                 failed.append('%r member mismatch:\n      %s' % (
///                         name, '\n      '.join(failed_member),
///                         ))
///         for method in (
///                 '__str__', '__repr__', '__reduce_ex__', '__format__',
///                 '__getnewargs_ex__', '__getnewargs__', '__reduce_ex__', '__reduce__'
///             ):
///             if method in simple_keys and method in checked_keys:
///                 # cannot compare functions, and it exists in both, so we're good
///                 continue
///             elif method not in simple_keys and method not in checked_keys:
///                 # method is inherited -- check it out
///                 checked_method = getattr(checked_enum, method, None)
///                 simple_method = getattr(simple_enum, method, None)
///                 if hasattr(checked_method, '__func__'):
///                     checked_method = checked_method.__func__
///                     simple_method = simple_method.__func__
///                 if checked_method != simple_method:
///                     failed.append("%r:  %-30s %s" % (
///                             method,
///                             "checked -> %r" % (checked_method, ),
///                             "simple -> %r" % (simple_method, ),
///                             ))
///             else:
///                 # if the method existed in only one of the enums, it will have been caught
///                 # in the first checks above
///                 pass
///     if failed:
///         raise TypeError('enum mismatch:\n   %s' % '\n   '.join(failed))
///
/// def _old_convert_(etype, name, module, filter, source=None, *, boundary=None):
///     """
///     Create a new Enum subclass that replaces a collection of global constants
///     """
///     # convert all constants from source (or module) that pass filter() to
///     # a new Enum called name, and export the enum and its members back to
///     # module;
///     # also, replace the __reduce_ex__ method so unpickling works in
///     # previous Python versions
///     module_globals = sys.modules[module].__dict__
///     if source:
///         source = source.__dict__
///     else:
///         source = module_globals
///     # _value2member_map_ is populated in the same order every time
///     # for a consistent reverse mapping of number to name when there
///     # are multiple names for the same number.
///     members = [
///             (name, value)
///             for name, value in source.items()
///             if filter(name)]
///     try:
///         # sort by value
///         members.sort(key=lambda t: (t[1], t[0]))
///     except TypeError:
///         # unless some values aren't comparable, in which case sort by name
///         members.sort(key=lambda t: t[0])
///     cls = etype(name, members, module=module, boundary=boundary or KEEP)
///     cls.__reduce_ex__ = _reduce_ex_by_global_name
///     return cls
///
/// _stdlib_enums = IntEnum, StrEnum, IntFlag
/// ```
final class $enum extends PythonModule {
  $enum.from(super.pythonModule) : super.from();

  static $enum import() => PythonFfiDart.instance.importModule(
        "enum",
        $enum.from,
      );

  /// ## bin
  ///
  /// ### python docstring
  ///
  /// Like built-in bin(), except negative values are represented in
  /// twos-compliment, and the leading bit always indicates sign
  /// (0=positive, 1=negative).
  ///
  /// >>> bin(10)
  /// '0b0 1010'
  /// >>> bin(~10)   # ~10 is -11
  /// '0b1 0101'
  ///
  /// ### python source
  /// ```py
  /// def bin(num, max_bits=None):
  ///     """
  ///     Like built-in bin(), except negative values are represented in
  ///     twos-compliment, and the leading bit always indicates sign
  ///     (0=positive, 1=negative).
  ///
  ///     >>> bin(10)
  ///     '0b0 1010'
  ///     >>> bin(~10)   # ~10 is -11
  ///     '0b1 0101'
  ///     """
  ///
  ///     ceiling = 2 ** (num).bit_length()
  ///     if num >= 0:
  ///         s = bltns.bin(num + ceiling).replace('1', '0', 1)
  ///     else:
  ///         s = bltns.bin(~num ^ (ceiling - 1) + ceiling)
  ///     sign = s[:3]
  ///     digits = s[3:]
  ///     if max_bits is not None:
  ///         if len(digits) < max_bits:
  ///             digits = (sign[-1] * max_bits + digits)[-max_bits:]
  ///     return "%s %s" % (sign, digits)
  /// ```
  Object? bin({
    required Object? num,
    Object? max_bits,
  }) =>
      getFunction("bin").call(
        <Object?>[
          num,
          max_bits,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## global_enum
  ///
  /// ### python docstring
  ///
  /// decorator that makes the repr() of an enum member reference its module
  /// instead of its class; also exports all members to the enum's module's
  /// global namespace
  ///
  /// ### python source
  /// ```py
  /// def global_enum(cls, update_str=False):
  ///     """
  ///     decorator that makes the repr() of an enum member reference its module
  ///     instead of its class; also exports all members to the enum's module's
  ///     global namespace
  ///     """
  ///     if issubclass(cls, Flag):
  ///         cls.__repr__ = global_flag_repr
  ///     else:
  ///         cls.__repr__ = global_enum_repr
  ///     if not issubclass(cls, ReprEnum) or update_str:
  ///         cls.__str__ = global_str
  ///     sys.modules[cls.__module__].__dict__.update(cls.__members__)
  ///     return cls
  /// ```
  Object? global_enum({
    required Object? cls,
    Object? update_str = false,
  }) =>
      getFunction("global_enum").call(
        <Object?>[
          cls,
          update_str,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## global_enum_repr
  ///
  /// ### python docstring
  ///
  /// use module.enum_name instead of class.enum_name
  ///
  /// the module is the last module in case of a multi-module name
  ///
  /// ### python source
  /// ```py
  /// def global_enum_repr(self):
  ///     """
  ///     use module.enum_name instead of class.enum_name
  ///
  ///     the module is the last module in case of a multi-module name
  ///     """
  ///     module = self.__class__.__module__.split('.')[-1]
  ///     return '%s.%s' % (module, self._name_)
  /// ```
  Object? global_enum_repr({
    required Object? self,
  }) =>
      getFunction("global_enum_repr").call(
        <Object?>[
          self,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## global_flag_repr
  ///
  /// ### python docstring
  ///
  /// use module.flag_name instead of class.flag_name
  ///
  /// the module is the last module in case of a multi-module name
  ///
  /// ### python source
  /// ```py
  /// def global_flag_repr(self):
  ///     """
  ///     use module.flag_name instead of class.flag_name
  ///
  ///     the module is the last module in case of a multi-module name
  ///     """
  ///     module = self.__class__.__module__.split('.')[-1]
  ///     cls_name = self.__class__.__name__
  ///     if self._name_ is None:
  ///         return "%s.%s(%r)" % (module, cls_name, self._value_)
  ///     if _is_single_bit(self):
  ///         return '%s.%s' % (module, self._name_)
  ///     if self._boundary_ is not FlagBoundary.KEEP:
  ///         return '|'.join(['%s.%s' % (module, name) for name in self.name.split('|')])
  ///     else:
  ///         name = []
  ///         for n in self._name_.split('|'):
  ///             if n[0].isdigit():
  ///                 name.append(n)
  ///             else:
  ///                 name.append('%s.%s' % (module, n))
  ///         return '|'.join(name)
  /// ```
  Object? global_flag_repr({
    required Object? self,
  }) =>
      getFunction("global_flag_repr").call(
        <Object?>[
          self,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## global_str
  ///
  /// ### python docstring
  ///
  /// use enum_name instead of class.enum_name
  ///
  /// ### python source
  /// ```py
  /// def global_str(self):
  ///     """
  ///     use enum_name instead of class.enum_name
  ///     """
  ///     if self._name_ is None:
  ///         cls_name = self.__class__.__name__
  ///         return "%s(%r)" % (cls_name, self._value_)
  ///     else:
  ///         return self._name_
  /// ```
  Object? global_str({
    required Object? self,
  }) =>
      getFunction("global_str").call(
        <Object?>[
          self,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## show_flag_values
  ///
  /// ### python source
  /// ```py
  /// def show_flag_values(value):
  ///     return list(_iter_bits_lsb(value))
  /// ```
  Object? show_flag_values({
    required Object? value,
  }) =>
      getFunction("show_flag_values").call(
        <Object?>[
          value,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## unique
  ///
  /// ### python docstring
  ///
  /// Class decorator for enumerations ensuring unique member values.
  ///
  /// ### python source
  /// ```py
  /// def unique(enumeration):
  ///     """
  ///     Class decorator for enumerations ensuring unique member values.
  ///     """
  ///     duplicates = []
  ///     for name, member in enumeration.__members__.items():
  ///         if name != member.name:
  ///             duplicates.append((name, member.name))
  ///     if duplicates:
  ///         alias_details = ', '.join(
  ///                 ["%s -> %s" % (alias, name) for (alias, name) in duplicates])
  ///         raise ValueError('duplicate values found in %r: %s' %
  ///                 (enumeration, alias_details))
  ///     return enumeration
  /// ```
  Object? unique({
    required Object? enumeration,
  }) =>
      getFunction("unique").call(
        <Object?>[
          enumeration,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## CONFORM (getter)
  Object? get CONFORM => getAttribute("CONFORM");

  /// ## CONFORM (setter)
  set CONFORM(Object? CONFORM) => setAttribute("CONFORM", CONFORM);

  /// ## CONTINUOUS (getter)
  Object? get CONTINUOUS => getAttribute("CONTINUOUS");

  /// ## CONTINUOUS (setter)
  set CONTINUOUS(Object? CONTINUOUS) => setAttribute("CONTINUOUS", CONTINUOUS);

  /// ## EJECT (getter)
  Object? get EJECT => getAttribute("EJECT");

  /// ## EJECT (setter)
  set EJECT(Object? EJECT) => setAttribute("EJECT", EJECT);

  /// ## KEEP (getter)
  Object? get KEEP => getAttribute("KEEP");

  /// ## KEEP (setter)
  set KEEP(Object? KEEP) => setAttribute("KEEP", KEEP);

  /// ## NAMED_FLAGS (getter)
  Object? get NAMED_FLAGS => getAttribute("NAMED_FLAGS");

  /// ## NAMED_FLAGS (setter)
  set NAMED_FLAGS(Object? NAMED_FLAGS) =>
      setAttribute("NAMED_FLAGS", NAMED_FLAGS);

  /// ## STRICT (getter)
  Object? get STRICT => getAttribute("STRICT");

  /// ## STRICT (setter)
  set STRICT(Object? STRICT) => setAttribute("STRICT", STRICT);

  /// ## UNIQUE (getter)
  Object? get UNIQUE => getAttribute("UNIQUE");

  /// ## UNIQUE (setter)
  set UNIQUE(Object? UNIQUE) => setAttribute("UNIQUE", UNIQUE);
}

/// ## functools
///
/// ### python docstring
///
/// functools.py - Tools for working with functions and callable objects
///
/// ### python source
/// ```py
/// """functools.py - Tools for working with functions and callable objects
/// """
/// # Python module wrapper for _functools C module
/// # to allow utilities written in Python to be added
/// # to the functools module.
/// # Written by Nick Coghlan <ncoghlan at gmail.com>,
/// # Raymond Hettinger <python at rcn.com>,
/// # and Łukasz Langa <lukasz at langa.pl>.
/// #   Copyright (C) 2006-2013 Python Software Foundation.
/// # See C source code for _functools credits/copyright
///
/// __all__ = ['update_wrapper', 'wraps', 'WRAPPER_ASSIGNMENTS', 'WRAPPER_UPDATES',
///            'total_ordering', 'cache', 'cmp_to_key', 'lru_cache', 'reduce',
///            'partial', 'partialmethod', 'singledispatch', 'singledispatchmethod',
///            'cached_property']
///
/// from abc import get_cache_token
/// from collections import namedtuple
/// # import types, weakref  # Deferred to single_dispatch()
/// from reprlib import recursive_repr
/// from _thread import RLock
/// from types import GenericAlias
///
///
/// ################################################################################
/// ### update_wrapper() and wraps() decorator
/// ################################################################################
///
/// # update_wrapper() and wraps() are tools to help write
/// # wrapper functions that can handle naive introspection
///
/// WRAPPER_ASSIGNMENTS = ('__module__', '__name__', '__qualname__', '__doc__',
///                        '__annotations__')
/// WRAPPER_UPDATES = ('__dict__',)
/// def update_wrapper(wrapper,
///                    wrapped,
///                    assigned = WRAPPER_ASSIGNMENTS,
///                    updated = WRAPPER_UPDATES):
///     """Update a wrapper function to look like the wrapped function
///
///        wrapper is the function to be updated
///        wrapped is the original function
///        assigned is a tuple naming the attributes assigned directly
///        from the wrapped function to the wrapper function (defaults to
///        functools.WRAPPER_ASSIGNMENTS)
///        updated is a tuple naming the attributes of the wrapper that
///        are updated with the corresponding attribute from the wrapped
///        function (defaults to functools.WRAPPER_UPDATES)
///     """
///     for attr in assigned:
///         try:
///             value = getattr(wrapped, attr)
///         except AttributeError:
///             pass
///         else:
///             setattr(wrapper, attr, value)
///     for attr in updated:
///         getattr(wrapper, attr).update(getattr(wrapped, attr, {}))
///     # Issue #17482: set __wrapped__ last so we don't inadvertently copy it
///     # from the wrapped function when updating __dict__
///     wrapper.__wrapped__ = wrapped
///     # Return the wrapper so this can be used as a decorator via partial()
///     return wrapper
///
/// def wraps(wrapped,
///           assigned = WRAPPER_ASSIGNMENTS,
///           updated = WRAPPER_UPDATES):
///     """Decorator factory to apply update_wrapper() to a wrapper function
///
///        Returns a decorator that invokes update_wrapper() with the decorated
///        function as the wrapper argument and the arguments to wraps() as the
///        remaining arguments. Default arguments are as for update_wrapper().
///        This is a convenience function to simplify applying partial() to
///        update_wrapper().
///     """
///     return partial(update_wrapper, wrapped=wrapped,
///                    assigned=assigned, updated=updated)
///
///
/// ################################################################################
/// ### total_ordering class decorator
/// ################################################################################
///
/// # The total ordering functions all invoke the root magic method directly
/// # rather than using the corresponding operator.  This avoids possible
/// # infinite recursion that could occur when the operator dispatch logic
/// # detects a NotImplemented result and then calls a reflected method.
///
/// def _gt_from_lt(self, other):
///     'Return a > b.  Computed by @total_ordering from (not a < b) and (a != b).'
///     op_result = type(self).__lt__(self, other)
///     if op_result is NotImplemented:
///         return op_result
///     return not op_result and self != other
///
/// def _le_from_lt(self, other):
///     'Return a <= b.  Computed by @total_ordering from (a < b) or (a == b).'
///     op_result = type(self).__lt__(self, other)
///     if op_result is NotImplemented:
///         return op_result
///     return op_result or self == other
///
/// def _ge_from_lt(self, other):
///     'Return a >= b.  Computed by @total_ordering from (not a < b).'
///     op_result = type(self).__lt__(self, other)
///     if op_result is NotImplemented:
///         return op_result
///     return not op_result
///
/// def _ge_from_le(self, other):
///     'Return a >= b.  Computed by @total_ordering from (not a <= b) or (a == b).'
///     op_result = type(self).__le__(self, other)
///     if op_result is NotImplemented:
///         return op_result
///     return not op_result or self == other
///
/// def _lt_from_le(self, other):
///     'Return a < b.  Computed by @total_ordering from (a <= b) and (a != b).'
///     op_result = type(self).__le__(self, other)
///     if op_result is NotImplemented:
///         return op_result
///     return op_result and self != other
///
/// def _gt_from_le(self, other):
///     'Return a > b.  Computed by @total_ordering from (not a <= b).'
///     op_result = type(self).__le__(self, other)
///     if op_result is NotImplemented:
///         return op_result
///     return not op_result
///
/// def _lt_from_gt(self, other):
///     'Return a < b.  Computed by @total_ordering from (not a > b) and (a != b).'
///     op_result = type(self).__gt__(self, other)
///     if op_result is NotImplemented:
///         return op_result
///     return not op_result and self != other
///
/// def _ge_from_gt(self, other):
///     'Return a >= b.  Computed by @total_ordering from (a > b) or (a == b).'
///     op_result = type(self).__gt__(self, other)
///     if op_result is NotImplemented:
///         return op_result
///     return op_result or self == other
///
/// def _le_from_gt(self, other):
///     'Return a <= b.  Computed by @total_ordering from (not a > b).'
///     op_result = type(self).__gt__(self, other)
///     if op_result is NotImplemented:
///         return op_result
///     return not op_result
///
/// def _le_from_ge(self, other):
///     'Return a <= b.  Computed by @total_ordering from (not a >= b) or (a == b).'
///     op_result = type(self).__ge__(self, other)
///     if op_result is NotImplemented:
///         return op_result
///     return not op_result or self == other
///
/// def _gt_from_ge(self, other):
///     'Return a > b.  Computed by @total_ordering from (a >= b) and (a != b).'
///     op_result = type(self).__ge__(self, other)
///     if op_result is NotImplemented:
///         return op_result
///     return op_result and self != other
///
/// def _lt_from_ge(self, other):
///     'Return a < b.  Computed by @total_ordering from (not a >= b).'
///     op_result = type(self).__ge__(self, other)
///     if op_result is NotImplemented:
///         return op_result
///     return not op_result
///
/// _convert = {
///     '__lt__': [('__gt__', _gt_from_lt),
///                ('__le__', _le_from_lt),
///                ('__ge__', _ge_from_lt)],
///     '__le__': [('__ge__', _ge_from_le),
///                ('__lt__', _lt_from_le),
///                ('__gt__', _gt_from_le)],
///     '__gt__': [('__lt__', _lt_from_gt),
///                ('__ge__', _ge_from_gt),
///                ('__le__', _le_from_gt)],
///     '__ge__': [('__le__', _le_from_ge),
///                ('__gt__', _gt_from_ge),
///                ('__lt__', _lt_from_ge)]
/// }
///
/// def total_ordering(cls):
///     """Class decorator that fills in missing ordering methods"""
///     # Find user-defined comparisons (not those inherited from object).
///     roots = {op for op in _convert if getattr(cls, op, None) is not getattr(object, op, None)}
///     if not roots:
///         raise ValueError('must define at least one ordering operation: < > <= >=')
///     root = max(roots)       # prefer __lt__ to __le__ to __gt__ to __ge__
///     for opname, opfunc in _convert[root]:
///         if opname not in roots:
///             opfunc.__name__ = opname
///             setattr(cls, opname, opfunc)
///     return cls
///
///
/// ################################################################################
/// ### cmp_to_key() function converter
/// ################################################################################
///
/// def cmp_to_key(mycmp):
///     """Convert a cmp= function into a key= function"""
///     class K(object):
///         __slots__ = ['obj']
///         def __init__(self, obj):
///             self.obj = obj
///         def __lt__(self, other):
///             return mycmp(self.obj, other.obj) < 0
///         def __gt__(self, other):
///             return mycmp(self.obj, other.obj) > 0
///         def __eq__(self, other):
///             return mycmp(self.obj, other.obj) == 0
///         def __le__(self, other):
///             return mycmp(self.obj, other.obj) <= 0
///         def __ge__(self, other):
///             return mycmp(self.obj, other.obj) >= 0
///         __hash__ = None
///     return K
///
/// try:
///     from _functools import cmp_to_key
/// except ImportError:
///     pass
///
///
/// ################################################################################
/// ### reduce() sequence to a single item
/// ################################################################################
///
/// _initial_missing = object()
///
/// def reduce(function, sequence, initial=_initial_missing):
///     """
///     reduce(function, iterable[, initial]) -> value
///
///     Apply a function of two arguments cumulatively to the items of a sequence
///     or iterable, from left to right, so as to reduce the iterable to a single
///     value.  For example, reduce(lambda x, y: x+y, [1, 2, 3, 4, 5]) calculates
///     ((((1+2)+3)+4)+5).  If initial is present, it is placed before the items
///     of the iterable in the calculation, and serves as a default when the
///     iterable is empty.
///     """
///
///     it = iter(sequence)
///
///     if initial is _initial_missing:
///         try:
///             value = next(it)
///         except StopIteration:
///             raise TypeError(
///                 "reduce() of empty iterable with no initial value") from None
///     else:
///         value = initial
///
///     for element in it:
///         value = function(value, element)
///
///     return value
///
/// try:
///     from _functools import reduce
/// except ImportError:
///     pass
///
///
/// ################################################################################
/// ### partial() argument application
/// ################################################################################
///
/// # Purely functional, no descriptor behaviour
/// class partial:
///     """New function with partial application of the given arguments
///     and keywords.
///     """
///
///     __slots__ = "func", "args", "keywords", "__dict__", "__weakref__"
///
///     def __new__(cls, func, /, *args, **keywords):
///         if not callable(func):
///             raise TypeError("the first argument must be callable")
///
///         if hasattr(func, "func"):
///             args = func.args + args
///             keywords = {**func.keywords, **keywords}
///             func = func.func
///
///         self = super(partial, cls).__new__(cls)
///
///         self.func = func
///         self.args = args
///         self.keywords = keywords
///         return self
///
///     def __call__(self, /, *args, **keywords):
///         keywords = {**self.keywords, **keywords}
///         return self.func(*self.args, *args, **keywords)
///
///     @recursive_repr()
///     def __repr__(self):
///         qualname = type(self).__qualname__
///         args = [repr(self.func)]
///         args.extend(repr(x) for x in self.args)
///         args.extend(f"{k}={v!r}" for (k, v) in self.keywords.items())
///         if type(self).__module__ == "functools":
///             return f"functools.{qualname}({', '.join(args)})"
///         return f"{qualname}({', '.join(args)})"
///
///     def __reduce__(self):
///         return type(self), (self.func,), (self.func, self.args,
///                self.keywords or None, self.__dict__ or None)
///
///     def __setstate__(self, state):
///         if not isinstance(state, tuple):
///             raise TypeError("argument to __setstate__ must be a tuple")
///         if len(state) != 4:
///             raise TypeError(f"expected 4 items in state, got {len(state)}")
///         func, args, kwds, namespace = state
///         if (not callable(func) or not isinstance(args, tuple) or
///            (kwds is not None and not isinstance(kwds, dict)) or
///            (namespace is not None and not isinstance(namespace, dict))):
///             raise TypeError("invalid partial state")
///
///         args = tuple(args) # just in case it's a subclass
///         if kwds is None:
///             kwds = {}
///         elif type(kwds) is not dict: # XXX does it need to be *exactly* dict?
///             kwds = dict(kwds)
///         if namespace is None:
///             namespace = {}
///
///         self.__dict__ = namespace
///         self.func = func
///         self.args = args
///         self.keywords = kwds
///
/// try:
///     from _functools import partial
/// except ImportError:
///     pass
///
/// # Descriptor version
/// class partialmethod(object):
///     """Method descriptor with partial application of the given arguments
///     and keywords.
///
///     Supports wrapping existing descriptors and handles non-descriptor
///     callables as instance methods.
///     """
///
///     def __init__(self, func, /, *args, **keywords):
///         if not callable(func) and not hasattr(func, "__get__"):
///             raise TypeError("{!r} is not callable or a descriptor"
///                                  .format(func))
///
///         # func could be a descriptor like classmethod which isn't callable,
///         # so we can't inherit from partial (it verifies func is callable)
///         if isinstance(func, partialmethod):
///             # flattening is mandatory in order to place cls/self before all
///             # other arguments
///             # it's also more efficient since only one function will be called
///             self.func = func.func
///             self.args = func.args + args
///             self.keywords = {**func.keywords, **keywords}
///         else:
///             self.func = func
///             self.args = args
///             self.keywords = keywords
///
///     def __repr__(self):
///         args = ", ".join(map(repr, self.args))
///         keywords = ", ".join("{}={!r}".format(k, v)
///                                  for k, v in self.keywords.items())
///         format_string = "{module}.{cls}({func}, {args}, {keywords})"
///         return format_string.format(module=self.__class__.__module__,
///                                     cls=self.__class__.__qualname__,
///                                     func=self.func,
///                                     args=args,
///                                     keywords=keywords)
///
///     def _make_unbound_method(self):
///         def _method(cls_or_self, /, *args, **keywords):
///             keywords = {**self.keywords, **keywords}
///             return self.func(cls_or_self, *self.args, *args, **keywords)
///         _method.__isabstractmethod__ = self.__isabstractmethod__
///         _method._partialmethod = self
///         return _method
///
///     def __get__(self, obj, cls=None):
///         get = getattr(self.func, "__get__", None)
///         result = None
///         if get is not None:
///             new_func = get(obj, cls)
///             if new_func is not self.func:
///                 # Assume __get__ returning something new indicates the
///                 # creation of an appropriate callable
///                 result = partial(new_func, *self.args, **self.keywords)
///                 try:
///                     result.__self__ = new_func.__self__
///                 except AttributeError:
///                     pass
///         if result is None:
///             # If the underlying descriptor didn't do anything, treat this
///             # like an instance method
///             result = self._make_unbound_method().__get__(obj, cls)
///         return result
///
///     @property
///     def __isabstractmethod__(self):
///         return getattr(self.func, "__isabstractmethod__", False)
///
///     __class_getitem__ = classmethod(GenericAlias)
///
///
/// # Helper functions
///
/// def _unwrap_partial(func):
///     while isinstance(func, partial):
///         func = func.func
///     return func
///
/// ################################################################################
/// ### LRU Cache function decorator
/// ################################################################################
///
/// _CacheInfo = namedtuple("CacheInfo", ["hits", "misses", "maxsize", "currsize"])
///
/// class _HashedSeq(list):
///     """ This class guarantees that hash() will be called no more than once
///         per element.  This is important because the lru_cache() will hash
///         the key multiple times on a cache miss.
///
///     """
///
///     __slots__ = 'hashvalue'
///
///     def __init__(self, tup, hash=hash):
///         self[:] = tup
///         self.hashvalue = hash(tup)
///
///     def __hash__(self):
///         return self.hashvalue
///
/// def _make_key(args, kwds, typed,
///              kwd_mark = (object(),),
///              fasttypes = {int, str},
///              tuple=tuple, type=type, len=len):
///     """Make a cache key from optionally typed positional and keyword arguments
///
///     The key is constructed in a way that is flat as possible rather than
///     as a nested structure that would take more memory.
///
///     If there is only a single argument and its data type is known to cache
///     its hash value, then that argument is returned without a wrapper.  This
///     saves space and improves lookup speed.
///
///     """
///     # All of code below relies on kwds preserving the order input by the user.
///     # Formerly, we sorted() the kwds before looping.  The new way is *much*
///     # faster; however, it means that f(x=1, y=2) will now be treated as a
///     # distinct call from f(y=2, x=1) which will be cached separately.
///     key = args
///     if kwds:
///         key += kwd_mark
///         for item in kwds.items():
///             key += item
///     if typed:
///         key += tuple(type(v) for v in args)
///         if kwds:
///             key += tuple(type(v) for v in kwds.values())
///     elif len(key) == 1 and type(key[0]) in fasttypes:
///         return key[0]
///     return _HashedSeq(key)
///
/// def lru_cache(maxsize=128, typed=False):
///     """Least-recently-used cache decorator.
///
///     If *maxsize* is set to None, the LRU features are disabled and the cache
///     can grow without bound.
///
///     If *typed* is True, arguments of different types will be cached separately.
///     For example, f(3.0) and f(3) will be treated as distinct calls with
///     distinct results.
///
///     Arguments to the cached function must be hashable.
///
///     View the cache statistics named tuple (hits, misses, maxsize, currsize)
///     with f.cache_info().  Clear the cache and statistics with f.cache_clear().
///     Access the underlying function with f.__wrapped__.
///
///     See:  https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)
///
///     """
///
///     # Users should only access the lru_cache through its public API:
///     #       cache_info, cache_clear, and f.__wrapped__
///     # The internals of the lru_cache are encapsulated for thread safety and
///     # to allow the implementation to change (including a possible C version).
///
///     if isinstance(maxsize, int):
///         # Negative maxsize is treated as 0
///         if maxsize < 0:
///             maxsize = 0
///     elif callable(maxsize) and isinstance(typed, bool):
///         # The user_function was passed in directly via the maxsize argument
///         user_function, maxsize = maxsize, 128
///         wrapper = _lru_cache_wrapper(user_function, maxsize, typed, _CacheInfo)
///         wrapper.cache_parameters = lambda : {'maxsize': maxsize, 'typed': typed}
///         return update_wrapper(wrapper, user_function)
///     elif maxsize is not None:
///         raise TypeError(
///             'Expected first argument to be an integer, a callable, or None')
///
///     def decorating_function(user_function):
///         wrapper = _lru_cache_wrapper(user_function, maxsize, typed, _CacheInfo)
///         wrapper.cache_parameters = lambda : {'maxsize': maxsize, 'typed': typed}
///         return update_wrapper(wrapper, user_function)
///
///     return decorating_function
///
/// def _lru_cache_wrapper(user_function, maxsize, typed, _CacheInfo):
///     # Constants shared by all lru cache instances:
///     sentinel = object()          # unique object used to signal cache misses
///     make_key = _make_key         # build a key from the function arguments
///     PREV, NEXT, KEY, RESULT = 0, 1, 2, 3   # names for the link fields
///
///     cache = {}
///     hits = misses = 0
///     full = False
///     cache_get = cache.get    # bound method to lookup a key or return None
///     cache_len = cache.__len__  # get cache size without calling len()
///     lock = RLock()           # because linkedlist updates aren't threadsafe
///     root = []                # root of the circular doubly linked list
///     root[:] = [root, root, None, None]     # initialize by pointing to self
///
///     if maxsize == 0:
///
///         def wrapper(*args, **kwds):
///             # No caching -- just a statistics update
///             nonlocal misses
///             misses += 1
///             result = user_function(*args, **kwds)
///             return result
///
///     elif maxsize is None:
///
///         def wrapper(*args, **kwds):
///             # Simple caching without ordering or size limit
///             nonlocal hits, misses
///             key = make_key(args, kwds, typed)
///             result = cache_get(key, sentinel)
///             if result is not sentinel:
///                 hits += 1
///                 return result
///             misses += 1
///             result = user_function(*args, **kwds)
///             cache[key] = result
///             return result
///
///     else:
///
///         def wrapper(*args, **kwds):
///             # Size limited caching that tracks accesses by recency
///             nonlocal root, hits, misses, full
///             key = make_key(args, kwds, typed)
///             with lock:
///                 link = cache_get(key)
///                 if link is not None:
///                     # Move the link to the front of the circular queue
///                     link_prev, link_next, _key, result = link
///                     link_prev[NEXT] = link_next
///                     link_next[PREV] = link_prev
///                     last = root[PREV]
///                     last[NEXT] = root[PREV] = link
///                     link[PREV] = last
///                     link[NEXT] = root
///                     hits += 1
///                     return result
///                 misses += 1
///             result = user_function(*args, **kwds)
///             with lock:
///                 if key in cache:
///                     # Getting here means that this same key was added to the
///                     # cache while the lock was released.  Since the link
///                     # update is already done, we need only return the
///                     # computed result and update the count of misses.
///                     pass
///                 elif full:
///                     # Use the old root to store the new key and result.
///                     oldroot = root
///                     oldroot[KEY] = key
///                     oldroot[RESULT] = result
///                     # Empty the oldest link and make it the new root.
///                     # Keep a reference to the old key and old result to
///                     # prevent their ref counts from going to zero during the
///                     # update. That will prevent potentially arbitrary object
///                     # clean-up code (i.e. __del__) from running while we're
///                     # still adjusting the links.
///                     root = oldroot[NEXT]
///                     oldkey = root[KEY]
///                     oldresult = root[RESULT]
///                     root[KEY] = root[RESULT] = None
///                     # Now update the cache dictionary.
///                     del cache[oldkey]
///                     # Save the potentially reentrant cache[key] assignment
///                     # for last, after the root and links have been put in
///                     # a consistent state.
///                     cache[key] = oldroot
///                 else:
///                     # Put result in a new link at the front of the queue.
///                     last = root[PREV]
///                     link = [last, root, key, result]
///                     last[NEXT] = root[PREV] = cache[key] = link
///                     # Use the cache_len bound method instead of the len() function
///                     # which could potentially be wrapped in an lru_cache itself.
///                     full = (cache_len() >= maxsize)
///             return result
///
///     def cache_info():
///         """Report cache statistics"""
///         with lock:
///             return _CacheInfo(hits, misses, maxsize, cache_len())
///
///     def cache_clear():
///         """Clear the cache and cache statistics"""
///         nonlocal hits, misses, full
///         with lock:
///             cache.clear()
///             root[:] = [root, root, None, None]
///             hits = misses = 0
///             full = False
///
///     wrapper.cache_info = cache_info
///     wrapper.cache_clear = cache_clear
///     return wrapper
///
/// try:
///     from _functools import _lru_cache_wrapper
/// except ImportError:
///     pass
///
///
/// ################################################################################
/// ### cache -- simplified access to the infinity cache
/// ################################################################################
///
/// def cache(user_function, /):
///     'Simple lightweight unbounded cache.  Sometimes called "memoize".'
///     return lru_cache(maxsize=None)(user_function)
///
///
/// ################################################################################
/// ### singledispatch() - single-dispatch generic function decorator
/// ################################################################################
///
/// def _c3_merge(sequences):
///     """Merges MROs in *sequences* to a single MRO using the C3 algorithm.
///
///     Adapted from https://www.python.org/download/releases/2.3/mro/.
///
///     """
///     result = []
///     while True:
///         sequences = [s for s in sequences if s]   # purge empty sequences
///         if not sequences:
///             return result
///         for s1 in sequences:   # find merge candidates among seq heads
///             candidate = s1[0]
///             for s2 in sequences:
///                 if candidate in s2[1:]:
///                     candidate = None
///                     break      # reject the current head, it appears later
///             else:
///                 break
///         if candidate is None:
///             raise RuntimeError("Inconsistent hierarchy")
///         result.append(candidate)
///         # remove the chosen candidate
///         for seq in sequences:
///             if seq[0] == candidate:
///                 del seq[0]
///
/// def _c3_mro(cls, abcs=None):
///     """Computes the method resolution order using extended C3 linearization.
///
///     If no *abcs* are given, the algorithm works exactly like the built-in C3
///     linearization used for method resolution.
///
///     If given, *abcs* is a list of abstract base classes that should be inserted
///     into the resulting MRO. Unrelated ABCs are ignored and don't end up in the
///     result. The algorithm inserts ABCs where their functionality is introduced,
///     i.e. issubclass(cls, abc) returns True for the class itself but returns
///     False for all its direct base classes. Implicit ABCs for a given class
///     (either registered or inferred from the presence of a special method like
///     __len__) are inserted directly after the last ABC explicitly listed in the
///     MRO of said class. If two implicit ABCs end up next to each other in the
///     resulting MRO, their ordering depends on the order of types in *abcs*.
///
///     """
///     for i, base in enumerate(reversed(cls.__bases__)):
///         if hasattr(base, '__abstractmethods__'):
///             boundary = len(cls.__bases__) - i
///             break   # Bases up to the last explicit ABC are considered first.
///     else:
///         boundary = 0
///     abcs = list(abcs) if abcs else []
///     explicit_bases = list(cls.__bases__[:boundary])
///     abstract_bases = []
///     other_bases = list(cls.__bases__[boundary:])
///     for base in abcs:
///         if issubclass(cls, base) and not any(
///                 issubclass(b, base) for b in cls.__bases__
///             ):
///             # If *cls* is the class that introduces behaviour described by
///             # an ABC *base*, insert said ABC to its MRO.
///             abstract_bases.append(base)
///     for base in abstract_bases:
///         abcs.remove(base)
///     explicit_c3_mros = [_c3_mro(base, abcs=abcs) for base in explicit_bases]
///     abstract_c3_mros = [_c3_mro(base, abcs=abcs) for base in abstract_bases]
///     other_c3_mros = [_c3_mro(base, abcs=abcs) for base in other_bases]
///     return _c3_merge(
///         [[cls]] +
///         explicit_c3_mros + abstract_c3_mros + other_c3_mros +
///         [explicit_bases] + [abstract_bases] + [other_bases]
///     )
///
/// def _compose_mro(cls, types):
///     """Calculates the method resolution order for a given class *cls*.
///
///     Includes relevant abstract base classes (with their respective bases) from
///     the *types* iterable. Uses a modified C3 linearization algorithm.
///
///     """
///     bases = set(cls.__mro__)
///     # Remove entries which are already present in the __mro__ or unrelated.
///     def is_related(typ):
///         return (typ not in bases and hasattr(typ, '__mro__')
///                                  and not isinstance(typ, GenericAlias)
///                                  and issubclass(cls, typ))
///     types = [n for n in types if is_related(n)]
///     # Remove entries which are strict bases of other entries (they will end up
///     # in the MRO anyway.
///     def is_strict_base(typ):
///         for other in types:
///             if typ != other and typ in other.__mro__:
///                 return True
///         return False
///     types = [n for n in types if not is_strict_base(n)]
///     # Subclasses of the ABCs in *types* which are also implemented by
///     # *cls* can be used to stabilize ABC ordering.
///     type_set = set(types)
///     mro = []
///     for typ in types:
///         found = []
///         for sub in typ.__subclasses__():
///             if sub not in bases and issubclass(cls, sub):
///                 found.append([s for s in sub.__mro__ if s in type_set])
///         if not found:
///             mro.append(typ)
///             continue
///         # Favor subclasses with the biggest number of useful bases
///         found.sort(key=len, reverse=True)
///         for sub in found:
///             for subcls in sub:
///                 if subcls not in mro:
///                     mro.append(subcls)
///     return _c3_mro(cls, abcs=mro)
///
/// def _find_impl(cls, registry):
///     """Returns the best matching implementation from *registry* for type *cls*.
///
///     Where there is no registered implementation for a specific type, its method
///     resolution order is used to find a more generic implementation.
///
///     Note: if *registry* does not contain an implementation for the base
///     *object* type, this function may return None.
///
///     """
///     mro = _compose_mro(cls, registry.keys())
///     match = None
///     for t in mro:
///         if match is not None:
///             # If *match* is an implicit ABC but there is another unrelated,
///             # equally matching implicit ABC, refuse the temptation to guess.
///             if (t in registry and t not in cls.__mro__
///                               and match not in cls.__mro__
///                               and not issubclass(match, t)):
///                 raise RuntimeError("Ambiguous dispatch: {} or {}".format(
///                     match, t))
///             break
///         if t in registry:
///             match = t
///     return registry.get(match)
///
/// def singledispatch(func):
///     """Single-dispatch generic function decorator.
///
///     Transforms a function into a generic function, which can have different
///     behaviours depending upon the type of its first argument. The decorated
///     function acts as the default implementation, and additional
///     implementations can be registered using the register() attribute of the
///     generic function.
///     """
///     # There are many programs that use functools without singledispatch, so we
///     # trade-off making singledispatch marginally slower for the benefit of
///     # making start-up of such applications slightly faster.
///     import types, weakref
///
///     registry = {}
///     dispatch_cache = weakref.WeakKeyDictionary()
///     cache_token = None
///
///     def dispatch(cls):
///         """generic_func.dispatch(cls) -> <function implementation>
///
///         Runs the dispatch algorithm to return the best available implementation
///         for the given *cls* registered on *generic_func*.
///
///         """
///         nonlocal cache_token
///         if cache_token is not None:
///             current_token = get_cache_token()
///             if cache_token != current_token:
///                 dispatch_cache.clear()
///                 cache_token = current_token
///         try:
///             impl = dispatch_cache[cls]
///         except KeyError:
///             try:
///                 impl = registry[cls]
///             except KeyError:
///                 impl = _find_impl(cls, registry)
///             dispatch_cache[cls] = impl
///         return impl
///
///     def _is_union_type(cls):
///         from typing import get_origin, Union
///         return get_origin(cls) in {Union, types.UnionType}
///
///     def _is_valid_dispatch_type(cls):
///         if isinstance(cls, type):
///             return True
///         from typing import get_args
///         return (_is_union_type(cls) and
///                 all(isinstance(arg, type) for arg in get_args(cls)))
///
///     def register(cls, func=None):
///         """generic_func.register(cls, func) -> func
///
///         Registers a new implementation for the given *cls* on a *generic_func*.
///
///         """
///         nonlocal cache_token
///         if _is_valid_dispatch_type(cls):
///             if func is None:
///                 return lambda f: register(cls, f)
///         else:
///             if func is not None:
///                 raise TypeError(
///                     f"Invalid first argument to `register()`. "
///                     f"{cls!r} is not a class or union type."
///                 )
///             ann = getattr(cls, '__annotations__', {})
///             if not ann:
///                 raise TypeError(
///                     f"Invalid first argument to `register()`: {cls!r}. "
///                     f"Use either `@register(some_class)` or plain `@register` "
///                     f"on an annotated function."
///                 )
///             func = cls
///
///             # only import typing if annotation parsing is necessary
///             from typing import get_type_hints
///             argname, cls = next(iter(get_type_hints(func).items()))
///             if not _is_valid_dispatch_type(cls):
///                 if _is_union_type(cls):
///                     raise TypeError(
///                         f"Invalid annotation for {argname!r}. "
///                         f"{cls!r} not all arguments are classes."
///                     )
///                 else:
///                     raise TypeError(
///                         f"Invalid annotation for {argname!r}. "
///                         f"{cls!r} is not a class."
///                     )
///
///         if _is_union_type(cls):
///             from typing import get_args
///
///             for arg in get_args(cls):
///                 registry[arg] = func
///         else:
///             registry[cls] = func
///         if cache_token is None and hasattr(cls, '__abstractmethods__'):
///             cache_token = get_cache_token()
///         dispatch_cache.clear()
///         return func
///
///     def wrapper(*args, **kw):
///         if not args:
///             raise TypeError(f'{funcname} requires at least '
///                             '1 positional argument')
///
///         return dispatch(args[0].__class__)(*args, **kw)
///
///     funcname = getattr(func, '__name__', 'singledispatch function')
///     registry[object] = func
///     wrapper.register = register
///     wrapper.dispatch = dispatch
///     wrapper.registry = types.MappingProxyType(registry)
///     wrapper._clear_cache = dispatch_cache.clear
///     update_wrapper(wrapper, func)
///     return wrapper
///
///
/// # Descriptor version
/// class singledispatchmethod:
///     """Single-dispatch generic method descriptor.
///
///     Supports wrapping existing descriptors and handles non-descriptor
///     callables as instance methods.
///     """
///
///     def __init__(self, func):
///         if not callable(func) and not hasattr(func, "__get__"):
///             raise TypeError(f"{func!r} is not callable or a descriptor")
///
///         self.dispatcher = singledispatch(func)
///         self.func = func
///
///     def register(self, cls, method=None):
///         """generic_method.register(cls, func) -> func
///
///         Registers a new implementation for the given *cls* on a *generic_method*.
///         """
///         return self.dispatcher.register(cls, func=method)
///
///     def __get__(self, obj, cls=None):
///         def _method(*args, **kwargs):
///             method = self.dispatcher.dispatch(args[0].__class__)
///             return method.__get__(obj, cls)(*args, **kwargs)
///
///         _method.__isabstractmethod__ = self.__isabstractmethod__
///         _method.register = self.register
///         update_wrapper(_method, self.func)
///         return _method
///
///     @property
///     def __isabstractmethod__(self):
///         return getattr(self.func, '__isabstractmethod__', False)
///
///
/// ################################################################################
/// ### cached_property() - computed once per instance, cached as attribute
/// ################################################################################
///
/// _NOT_FOUND = object()
///
///
/// class cached_property:
///     def __init__(self, func):
///         self.func = func
///         self.attrname = None
///         self.__doc__ = func.__doc__
///         self.lock = RLock()
///
///     def __set_name__(self, owner, name):
///         if self.attrname is None:
///             self.attrname = name
///         elif name != self.attrname:
///             raise TypeError(
///                 "Cannot assign the same cached_property to two different names "
///                 f"({self.attrname!r} and {name!r})."
///             )
///
///     def __get__(self, instance, owner=None):
///         if instance is None:
///             return self
///         if self.attrname is None:
///             raise TypeError(
///                 "Cannot use cached_property instance without calling __set_name__ on it.")
///         try:
///             cache = instance.__dict__
///         except AttributeError:  # not all objects have __dict__ (e.g. class defines slots)
///             msg = (
///                 f"No '__dict__' attribute on {type(instance).__name__!r} "
///                 f"instance to cache {self.attrname!r} property."
///             )
///             raise TypeError(msg) from None
///         val = cache.get(self.attrname, _NOT_FOUND)
///         if val is _NOT_FOUND:
///             with self.lock:
///                 # check if another thread filled cache while we awaited lock
///                 val = cache.get(self.attrname, _NOT_FOUND)
///                 if val is _NOT_FOUND:
///                     val = self.func(instance)
///                     try:
///                         cache[self.attrname] = val
///                     except TypeError:
///                         msg = (
///                             f"The '__dict__' attribute on {type(instance).__name__!r} instance "
///                             f"does not support item assignment for caching {self.attrname!r} property."
///                         )
///                         raise TypeError(msg) from None
///         return val
///
///     __class_getitem__ = classmethod(GenericAlias)
/// ```
final class functools extends PythonModule {
  functools.from(super.pythonModule) : super.from();

  static functools import() => PythonFfiDart.instance.importModule(
        "functools",
        functools.from,
      );

  /// ## cache
  ///
  /// ### python docstring
  ///
  /// Simple lightweight unbounded cache.  Sometimes called "memoize".
  ///
  /// ### python source
  /// ```py
  /// def cache(user_function, /):
  ///     'Simple lightweight unbounded cache.  Sometimes called "memoize".'
  ///     return lru_cache(maxsize=None)(user_function)
  /// ```
  Object? cache(
    Object? user_function,
  ) =>
      getFunction("cache").call(
        <Object?>[
          user_function,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## lru_cache
  ///
  /// ### python docstring
  ///
  /// Least-recently-used cache decorator.
  ///
  /// If *maxsize* is set to None, the LRU features are disabled and the cache
  /// can grow without bound.
  ///
  /// If *typed* is True, arguments of different types will be cached separately.
  /// For example, f(3.0) and f(3) will be treated as distinct calls with
  /// distinct results.
  ///
  /// Arguments to the cached function must be hashable.
  ///
  /// View the cache statistics named tuple (hits, misses, maxsize, currsize)
  /// with f.cache_info().  Clear the cache and statistics with f.cache_clear().
  /// Access the underlying function with f.__wrapped__.
  ///
  /// See:  https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)
  ///
  /// ### python source
  /// ```py
  /// def lru_cache(maxsize=128, typed=False):
  ///     """Least-recently-used cache decorator.
  ///
  ///     If *maxsize* is set to None, the LRU features are disabled and the cache
  ///     can grow without bound.
  ///
  ///     If *typed* is True, arguments of different types will be cached separately.
  ///     For example, f(3.0) and f(3) will be treated as distinct calls with
  ///     distinct results.
  ///
  ///     Arguments to the cached function must be hashable.
  ///
  ///     View the cache statistics named tuple (hits, misses, maxsize, currsize)
  ///     with f.cache_info().  Clear the cache and statistics with f.cache_clear().
  ///     Access the underlying function with f.__wrapped__.
  ///
  ///     See:  https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)
  ///
  ///     """
  ///
  ///     # Users should only access the lru_cache through its public API:
  ///     #       cache_info, cache_clear, and f.__wrapped__
  ///     # The internals of the lru_cache are encapsulated for thread safety and
  ///     # to allow the implementation to change (including a possible C version).
  ///
  ///     if isinstance(maxsize, int):
  ///         # Negative maxsize is treated as 0
  ///         if maxsize < 0:
  ///             maxsize = 0
  ///     elif callable(maxsize) and isinstance(typed, bool):
  ///         # The user_function was passed in directly via the maxsize argument
  ///         user_function, maxsize = maxsize, 128
  ///         wrapper = _lru_cache_wrapper(user_function, maxsize, typed, _CacheInfo)
  ///         wrapper.cache_parameters = lambda : {'maxsize': maxsize, 'typed': typed}
  ///         return update_wrapper(wrapper, user_function)
  ///     elif maxsize is not None:
  ///         raise TypeError(
  ///             'Expected first argument to be an integer, a callable, or None')
  ///
  ///     def decorating_function(user_function):
  ///         wrapper = _lru_cache_wrapper(user_function, maxsize, typed, _CacheInfo)
  ///         wrapper.cache_parameters = lambda : {'maxsize': maxsize, 'typed': typed}
  ///         return update_wrapper(wrapper, user_function)
  ///
  ///     return decorating_function
  /// ```
  Object? lru_cache({
    Object? maxsize = 128,
    Object? typed = false,
  }) =>
      getFunction("lru_cache").call(
        <Object?>[
          maxsize,
          typed,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## singledispatch
  ///
  /// ### python docstring
  ///
  /// Single-dispatch generic function decorator.
  ///
  /// Transforms a function into a generic function, which can have different
  /// behaviours depending upon the type of its first argument. The decorated
  /// function acts as the default implementation, and additional
  /// implementations can be registered using the register() attribute of the
  /// generic function.
  ///
  /// ### python source
  /// ```py
  /// def singledispatch(func):
  ///     """Single-dispatch generic function decorator.
  ///
  ///     Transforms a function into a generic function, which can have different
  ///     behaviours depending upon the type of its first argument. The decorated
  ///     function acts as the default implementation, and additional
  ///     implementations can be registered using the register() attribute of the
  ///     generic function.
  ///     """
  ///     # There are many programs that use functools without singledispatch, so we
  ///     # trade-off making singledispatch marginally slower for the benefit of
  ///     # making start-up of such applications slightly faster.
  ///     import types, weakref
  ///
  ///     registry = {}
  ///     dispatch_cache = weakref.WeakKeyDictionary()
  ///     cache_token = None
  ///
  ///     def dispatch(cls):
  ///         """generic_func.dispatch(cls) -> <function implementation>
  ///
  ///         Runs the dispatch algorithm to return the best available implementation
  ///         for the given *cls* registered on *generic_func*.
  ///
  ///         """
  ///         nonlocal cache_token
  ///         if cache_token is not None:
  ///             current_token = get_cache_token()
  ///             if cache_token != current_token:
  ///                 dispatch_cache.clear()
  ///                 cache_token = current_token
  ///         try:
  ///             impl = dispatch_cache[cls]
  ///         except KeyError:
  ///             try:
  ///                 impl = registry[cls]
  ///             except KeyError:
  ///                 impl = _find_impl(cls, registry)
  ///             dispatch_cache[cls] = impl
  ///         return impl
  ///
  ///     def _is_union_type(cls):
  ///         from typing import get_origin, Union
  ///         return get_origin(cls) in {Union, types.UnionType}
  ///
  ///     def _is_valid_dispatch_type(cls):
  ///         if isinstance(cls, type):
  ///             return True
  ///         from typing import get_args
  ///         return (_is_union_type(cls) and
  ///                 all(isinstance(arg, type) for arg in get_args(cls)))
  ///
  ///     def register(cls, func=None):
  ///         """generic_func.register(cls, func) -> func
  ///
  ///         Registers a new implementation for the given *cls* on a *generic_func*.
  ///
  ///         """
  ///         nonlocal cache_token
  ///         if _is_valid_dispatch_type(cls):
  ///             if func is None:
  ///                 return lambda f: register(cls, f)
  ///         else:
  ///             if func is not None:
  ///                 raise TypeError(
  ///                     f"Invalid first argument to `register()`. "
  ///                     f"{cls!r} is not a class or union type."
  ///                 )
  ///             ann = getattr(cls, '__annotations__', {})
  ///             if not ann:
  ///                 raise TypeError(
  ///                     f"Invalid first argument to `register()`: {cls!r}. "
  ///                     f"Use either `@register(some_class)` or plain `@register` "
  ///                     f"on an annotated function."
  ///                 )
  ///             func = cls
  ///
  ///             # only import typing if annotation parsing is necessary
  ///             from typing import get_type_hints
  ///             argname, cls = next(iter(get_type_hints(func).items()))
  ///             if not _is_valid_dispatch_type(cls):
  ///                 if _is_union_type(cls):
  ///                     raise TypeError(
  ///                         f"Invalid annotation for {argname!r}. "
  ///                         f"{cls!r} not all arguments are classes."
  ///                     )
  ///                 else:
  ///                     raise TypeError(
  ///                         f"Invalid annotation for {argname!r}. "
  ///                         f"{cls!r} is not a class."
  ///                     )
  ///
  ///         if _is_union_type(cls):
  ///             from typing import get_args
  ///
  ///             for arg in get_args(cls):
  ///                 registry[arg] = func
  ///         else:
  ///             registry[cls] = func
  ///         if cache_token is None and hasattr(cls, '__abstractmethods__'):
  ///             cache_token = get_cache_token()
  ///         dispatch_cache.clear()
  ///         return func
  ///
  ///     def wrapper(*args, **kw):
  ///         if not args:
  ///             raise TypeError(f'{funcname} requires at least '
  ///                             '1 positional argument')
  ///
  ///         return dispatch(args[0].__class__)(*args, **kw)
  ///
  ///     funcname = getattr(func, '__name__', 'singledispatch function')
  ///     registry[object] = func
  ///     wrapper.register = register
  ///     wrapper.dispatch = dispatch
  ///     wrapper.registry = types.MappingProxyType(registry)
  ///     wrapper._clear_cache = dispatch_cache.clear
  ///     update_wrapper(wrapper, func)
  ///     return wrapper
  /// ```
  Object? singledispatch({
    required Object? func,
  }) =>
      getFunction("singledispatch").call(
        <Object?>[
          func,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## total_ordering
  ///
  /// ### python docstring
  ///
  /// Class decorator that fills in missing ordering methods
  ///
  /// ### python source
  /// ```py
  /// def total_ordering(cls):
  ///     """Class decorator that fills in missing ordering methods"""
  ///     # Find user-defined comparisons (not those inherited from object).
  ///     roots = {op for op in _convert if getattr(cls, op, None) is not getattr(object, op, None)}
  ///     if not roots:
  ///         raise ValueError('must define at least one ordering operation: < > <= >=')
  ///     root = max(roots)       # prefer __lt__ to __le__ to __gt__ to __ge__
  ///     for opname, opfunc in _convert[root]:
  ///         if opname not in roots:
  ///             opfunc.__name__ = opname
  ///             setattr(cls, opname, opfunc)
  ///     return cls
  /// ```
  Object? total_ordering({
    required Object? cls,
  }) =>
      getFunction("total_ordering").call(
        <Object?>[
          cls,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## update_wrapper
  ///
  /// ### python docstring
  ///
  /// Update a wrapper function to look like the wrapped function
  ///
  /// wrapper is the function to be updated
  /// wrapped is the original function
  /// assigned is a tuple naming the attributes assigned directly
  /// from the wrapped function to the wrapper function (defaults to
  /// functools.WRAPPER_ASSIGNMENTS)
  /// updated is a tuple naming the attributes of the wrapper that
  /// are updated with the corresponding attribute from the wrapped
  /// function (defaults to functools.WRAPPER_UPDATES)
  ///
  /// ### python source
  /// ```py
  /// def update_wrapper(wrapper,
  ///                    wrapped,
  ///                    assigned = WRAPPER_ASSIGNMENTS,
  ///                    updated = WRAPPER_UPDATES):
  ///     """Update a wrapper function to look like the wrapped function
  ///
  ///        wrapper is the function to be updated
  ///        wrapped is the original function
  ///        assigned is a tuple naming the attributes assigned directly
  ///        from the wrapped function to the wrapper function (defaults to
  ///        functools.WRAPPER_ASSIGNMENTS)
  ///        updated is a tuple naming the attributes of the wrapper that
  ///        are updated with the corresponding attribute from the wrapped
  ///        function (defaults to functools.WRAPPER_UPDATES)
  ///     """
  ///     for attr in assigned:
  ///         try:
  ///             value = getattr(wrapped, attr)
  ///         except AttributeError:
  ///             pass
  ///         else:
  ///             setattr(wrapper, attr, value)
  ///     for attr in updated:
  ///         getattr(wrapper, attr).update(getattr(wrapped, attr, {}))
  ///     # Issue #17482: set __wrapped__ last so we don't inadvertently copy it
  ///     # from the wrapped function when updating __dict__
  ///     wrapper.__wrapped__ = wrapped
  ///     # Return the wrapper so this can be used as a decorator via partial()
  ///     return wrapper
  /// ```
  Object? update_wrapper({
    required Object? wrapper,
    required Object? wrapped,
    Object? assigned = const [
      "__module__",
      "__name__",
      "__qualname__",
      "__doc__",
      "__annotations__"
    ],
    Object? updated = const ["__dict__"],
  }) =>
      getFunction("update_wrapper").call(
        <Object?>[
          wrapper,
          wrapped,
          assigned,
          updated,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## wraps
  ///
  /// ### python docstring
  ///
  /// Decorator factory to apply update_wrapper() to a wrapper function
  ///
  /// Returns a decorator that invokes update_wrapper() with the decorated
  /// function as the wrapper argument and the arguments to wraps() as the
  /// remaining arguments. Default arguments are as for update_wrapper().
  /// This is a convenience function to simplify applying partial() to
  /// update_wrapper().
  ///
  /// ### python source
  /// ```py
  /// def wraps(wrapped,
  ///           assigned = WRAPPER_ASSIGNMENTS,
  ///           updated = WRAPPER_UPDATES):
  ///     """Decorator factory to apply update_wrapper() to a wrapper function
  ///
  ///        Returns a decorator that invokes update_wrapper() with the decorated
  ///        function as the wrapper argument and the arguments to wraps() as the
  ///        remaining arguments. Default arguments are as for update_wrapper().
  ///        This is a convenience function to simplify applying partial() to
  ///        update_wrapper().
  ///     """
  ///     return partial(update_wrapper, wrapped=wrapped,
  ///                    assigned=assigned, updated=updated)
  /// ```
  Object? wraps({
    required Object? wrapped,
    Object? assigned = const [
      "__module__",
      "__name__",
      "__qualname__",
      "__doc__",
      "__annotations__"
    ],
    Object? updated = const ["__dict__"],
  }) =>
      getFunction("wraps").call(
        <Object?>[
          wrapped,
          assigned,
          updated,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## WRAPPER_ASSIGNMENTS (getter)
  Object? get WRAPPER_ASSIGNMENTS => getAttribute("WRAPPER_ASSIGNMENTS");

  /// ## WRAPPER_ASSIGNMENTS (setter)
  set WRAPPER_ASSIGNMENTS(Object? WRAPPER_ASSIGNMENTS) =>
      setAttribute("WRAPPER_ASSIGNMENTS", WRAPPER_ASSIGNMENTS);

  /// ## WRAPPER_UPDATES (getter)
  Object? get WRAPPER_UPDATES => getAttribute("WRAPPER_UPDATES");

  /// ## WRAPPER_UPDATES (setter)
  set WRAPPER_UPDATES(Object? WRAPPER_UPDATES) =>
      setAttribute("WRAPPER_UPDATES", WRAPPER_UPDATES);
}

/// ## tempfile
///
/// ### python docstring
///
/// Temporary files.
///
/// This module provides generic, low- and high-level interfaces for
/// creating temporary files and directories.  All of the interfaces
/// provided by this module can be used without fear of race conditions
/// except for 'mktemp'.  'mktemp' is subject to race conditions and
/// should not be used; it is provided for backward compatibility only.
///
/// The default path names are returned as str.  If you supply bytes as
/// input, all return values will be in bytes.  Ex:
///
///     >>> tempfile.mkstemp()
///     (4, '/tmp/tmptpu9nin8')
///     >>> tempfile.mkdtemp(suffix=b'')
///     b'/tmp/tmppbi8f0hy'
///
/// This module also provides some data items to the user:
///
///   TMP_MAX  - maximum number of names that will be tried before
///              giving up.
///   tempdir  - If this is set to a string before the first use of
///              any routine from this module, it will be considered as
///              another candidate location to store temporary files.
///
/// ### python source
/// ```py
/// """Temporary files.
///
/// This module provides generic, low- and high-level interfaces for
/// creating temporary files and directories.  All of the interfaces
/// provided by this module can be used without fear of race conditions
/// except for 'mktemp'.  'mktemp' is subject to race conditions and
/// should not be used; it is provided for backward compatibility only.
///
/// The default path names are returned as str.  If you supply bytes as
/// input, all return values will be in bytes.  Ex:
///
///     >>> tempfile.mkstemp()
///     (4, '/tmp/tmptpu9nin8')
///     >>> tempfile.mkdtemp(suffix=b'')
///     b'/tmp/tmppbi8f0hy'
///
/// This module also provides some data items to the user:
///
///   TMP_MAX  - maximum number of names that will be tried before
///              giving up.
///   tempdir  - If this is set to a string before the first use of
///              any routine from this module, it will be considered as
///              another candidate location to store temporary files.
/// """
///
/// __all__ = [
///     "NamedTemporaryFile", "TemporaryFile", # high level safe interfaces
///     "SpooledTemporaryFile", "TemporaryDirectory",
///     "mkstemp", "mkdtemp",                  # low level safe interfaces
///     "mktemp",                              # deprecated unsafe interface
///     "TMP_MAX", "gettempprefix",            # constants
///     "tempdir", "gettempdir",
///     "gettempprefixb", "gettempdirb",
///    ]
///
///
/// # Imports.
///
/// import functools as _functools
/// import warnings as _warnings
/// import io as _io
/// import os as _os
/// import shutil as _shutil
/// import errno as _errno
/// from random import Random as _Random
/// import sys as _sys
/// import types as _types
/// import weakref as _weakref
/// import _thread
/// _allocate_lock = _thread.allocate_lock
///
/// _text_openflags = _os.O_RDWR | _os.O_CREAT | _os.O_EXCL
/// if hasattr(_os, 'O_NOFOLLOW'):
///     _text_openflags |= _os.O_NOFOLLOW
///
/// _bin_openflags = _text_openflags
/// if hasattr(_os, 'O_BINARY'):
///     _bin_openflags |= _os.O_BINARY
///
/// if hasattr(_os, 'TMP_MAX'):
///     TMP_MAX = _os.TMP_MAX
/// else:
///     TMP_MAX = 10000
///
/// # This variable _was_ unused for legacy reasons, see issue 10354.
/// # But as of 3.5 we actually use it at runtime so changing it would
/// # have a possibly desirable side effect...  But we do not want to support
/// # that as an API.  It is undocumented on purpose.  Do not depend on this.
/// template = "tmp"
///
/// # Internal routines.
///
/// _once_lock = _allocate_lock()
///
///
/// def _exists(fn):
///     try:
///         _os.lstat(fn)
///     except OSError:
///         return False
///     else:
///         return True
///
///
/// def _infer_return_type(*args):
///     """Look at the type of all args and divine their implied return type."""
///     return_type = None
///     for arg in args:
///         if arg is None:
///             continue
///
///         if isinstance(arg, _os.PathLike):
///             arg = _os.fspath(arg)
///
///         if isinstance(arg, bytes):
///             if return_type is str:
///                 raise TypeError("Can't mix bytes and non-bytes in "
///                                 "path components.")
///             return_type = bytes
///         else:
///             if return_type is bytes:
///                 raise TypeError("Can't mix bytes and non-bytes in "
///                                 "path components.")
///             return_type = str
///     if return_type is None:
///         if tempdir is None or isinstance(tempdir, str):
///             return str  # tempfile APIs return a str by default.
///         else:
///             # we could check for bytes but it'll fail later on anyway
///             return bytes
///     return return_type
///
///
/// def _sanitize_params(prefix, suffix, dir):
///     """Common parameter processing for most APIs in this module."""
///     output_type = _infer_return_type(prefix, suffix, dir)
///     if suffix is None:
///         suffix = output_type()
///     if prefix is None:
///         if output_type is str:
///             prefix = template
///         else:
///             prefix = _os.fsencode(template)
///     if dir is None:
///         if output_type is str:
///             dir = gettempdir()
///         else:
///             dir = gettempdirb()
///     return prefix, suffix, dir, output_type
///
///
/// class _RandomNameSequence:
///     """An instance of _RandomNameSequence generates an endless
///     sequence of unpredictable strings which can safely be incorporated
///     into file names.  Each string is eight characters long.  Multiple
///     threads can safely use the same instance at the same time.
///
///     _RandomNameSequence is an iterator."""
///
///     characters = "abcdefghijklmnopqrstuvwxyz0123456789_"
///
///     @property
///     def rng(self):
///         cur_pid = _os.getpid()
///         if cur_pid != getattr(self, '_rng_pid', None):
///             self._rng = _Random()
///             self._rng_pid = cur_pid
///         return self._rng
///
///     def __iter__(self):
///         return self
///
///     def __next__(self):
///         return ''.join(self.rng.choices(self.characters, k=8))
///
/// def _candidate_tempdir_list():
///     """Generate a list of candidate temporary directories which
///     _get_default_tempdir will try."""
///
///     dirlist = []
///
///     # First, try the environment.
///     for envname in 'TMPDIR', 'TEMP', 'TMP':
///         dirname = _os.getenv(envname)
///         if dirname: dirlist.append(dirname)
///
///     # Failing that, try OS-specific locations.
///     if _os.name == 'nt':
///         dirlist.extend([ _os.path.expanduser(r'~\AppData\Local\Temp'),
///                          _os.path.expandvars(r'%SYSTEMROOT%\Temp'),
///                          r'c:\temp', r'c:\tmp', r'\temp', r'\tmp' ])
///     else:
///         dirlist.extend([ '/tmp', '/var/tmp', '/usr/tmp' ])
///
///     # As a last resort, the current directory.
///     try:
///         dirlist.append(_os.getcwd())
///     except (AttributeError, OSError):
///         dirlist.append(_os.curdir)
///
///     return dirlist
///
/// def _get_default_tempdir():
///     """Calculate the default directory to use for temporary files.
///     This routine should be called exactly once.
///
///     We determine whether or not a candidate temp dir is usable by
///     trying to create and write to a file in that directory.  If this
///     is successful, the test file is deleted.  To prevent denial of
///     service, the name of the test file must be randomized."""
///
///     namer = _RandomNameSequence()
///     dirlist = _candidate_tempdir_list()
///
///     for dir in dirlist:
///         if dir != _os.curdir:
///             dir = _os.path.abspath(dir)
///         # Try only a few names per directory.
///         for seq in range(100):
///             name = next(namer)
///             filename = _os.path.join(dir, name)
///             try:
///                 fd = _os.open(filename, _bin_openflags, 0o600)
///                 try:
///                     try:
///                         _os.write(fd, b'blat')
///                     finally:
///                         _os.close(fd)
///                 finally:
///                     _os.unlink(filename)
///                 return dir
///             except FileExistsError:
///                 pass
///             except PermissionError:
///                 # This exception is thrown when a directory with the chosen name
///                 # already exists on windows.
///                 if (_os.name == 'nt' and _os.path.isdir(dir) and
///                     _os.access(dir, _os.W_OK)):
///                     continue
///                 break   # no point trying more names in this directory
///             except OSError:
///                 break   # no point trying more names in this directory
///     raise FileNotFoundError(_errno.ENOENT,
///                             "No usable temporary directory found in %s" %
///                             dirlist)
///
/// _name_sequence = None
///
/// def _get_candidate_names():
///     """Common setup sequence for all user-callable interfaces."""
///
///     global _name_sequence
///     if _name_sequence is None:
///         _once_lock.acquire()
///         try:
///             if _name_sequence is None:
///                 _name_sequence = _RandomNameSequence()
///         finally:
///             _once_lock.release()
///     return _name_sequence
///
///
/// def _mkstemp_inner(dir, pre, suf, flags, output_type):
///     """Code common to mkstemp, TemporaryFile, and NamedTemporaryFile."""
///
///     dir = _os.path.abspath(dir)
///     names = _get_candidate_names()
///     if output_type is bytes:
///         names = map(_os.fsencode, names)
///
///     for seq in range(TMP_MAX):
///         name = next(names)
///         file = _os.path.join(dir, pre + name + suf)
///         _sys.audit("tempfile.mkstemp", file)
///         try:
///             fd = _os.open(file, flags, 0o600)
///         except FileExistsError:
///             continue    # try again
///         except PermissionError:
///             # This exception is thrown when a directory with the chosen name
///             # already exists on windows.
///             if (_os.name == 'nt' and _os.path.isdir(dir) and
///                 _os.access(dir, _os.W_OK)):
///                 continue
///             else:
///                 raise
///         return fd, file
///
///     raise FileExistsError(_errno.EEXIST,
///                           "No usable temporary file name found")
///
///
/// # User visible interfaces.
///
/// def gettempprefix():
///     """The default prefix for temporary directories as string."""
///     return _os.fsdecode(template)
///
/// def gettempprefixb():
///     """The default prefix for temporary directories as bytes."""
///     return _os.fsencode(template)
///
/// tempdir = None
///
/// def _gettempdir():
///     """Private accessor for tempfile.tempdir."""
///     global tempdir
///     if tempdir is None:
///         _once_lock.acquire()
///         try:
///             if tempdir is None:
///                 tempdir = _get_default_tempdir()
///         finally:
///             _once_lock.release()
///     return tempdir
///
/// def gettempdir():
///     """Returns tempfile.tempdir as str."""
///     return _os.fsdecode(_gettempdir())
///
/// def gettempdirb():
///     """Returns tempfile.tempdir as bytes."""
///     return _os.fsencode(_gettempdir())
///
/// def mkstemp(suffix=None, prefix=None, dir=None, text=False):
///     """User-callable function to create and return a unique temporary
///     file.  The return value is a pair (fd, name) where fd is the
///     file descriptor returned by os.open, and name is the filename.
///
///     If 'suffix' is not None, the file name will end with that suffix,
///     otherwise there will be no suffix.
///
///     If 'prefix' is not None, the file name will begin with that prefix,
///     otherwise a default prefix is used.
///
///     If 'dir' is not None, the file will be created in that directory,
///     otherwise a default directory is used.
///
///     If 'text' is specified and true, the file is opened in text
///     mode.  Else (the default) the file is opened in binary mode.
///
///     If any of 'suffix', 'prefix' and 'dir' are not None, they must be the
///     same type.  If they are bytes, the returned name will be bytes; str
///     otherwise.
///
///     The file is readable and writable only by the creating user ID.
///     If the operating system uses permission bits to indicate whether a
///     file is executable, the file is executable by no one. The file
///     descriptor is not inherited by children of this process.
///
///     Caller is responsible for deleting the file when done with it.
///     """
///
///     prefix, suffix, dir, output_type = _sanitize_params(prefix, suffix, dir)
///
///     if text:
///         flags = _text_openflags
///     else:
///         flags = _bin_openflags
///
///     return _mkstemp_inner(dir, prefix, suffix, flags, output_type)
///
///
/// def mkdtemp(suffix=None, prefix=None, dir=None):
///     """User-callable function to create and return a unique temporary
///     directory.  The return value is the pathname of the directory.
///
///     Arguments are as for mkstemp, except that the 'text' argument is
///     not accepted.
///
///     The directory is readable, writable, and searchable only by the
///     creating user.
///
///     Caller is responsible for deleting the directory when done with it.
///     """
///
///     prefix, suffix, dir, output_type = _sanitize_params(prefix, suffix, dir)
///
///     names = _get_candidate_names()
///     if output_type is bytes:
///         names = map(_os.fsencode, names)
///
///     for seq in range(TMP_MAX):
///         name = next(names)
///         file = _os.path.join(dir, prefix + name + suffix)
///         _sys.audit("tempfile.mkdtemp", file)
///         try:
///             _os.mkdir(file, 0o700)
///         except FileExistsError:
///             continue    # try again
///         except PermissionError:
///             # This exception is thrown when a directory with the chosen name
///             # already exists on windows.
///             if (_os.name == 'nt' and _os.path.isdir(dir) and
///                 _os.access(dir, _os.W_OK)):
///                 continue
///             else:
///                 raise
///         return file
///
///     raise FileExistsError(_errno.EEXIST,
///                           "No usable temporary directory name found")
///
/// def mktemp(suffix="", prefix=template, dir=None):
///     """User-callable function to return a unique temporary file name.  The
///     file is not created.
///
///     Arguments are similar to mkstemp, except that the 'text' argument is
///     not accepted, and suffix=None, prefix=None and bytes file names are not
///     supported.
///
///     THIS FUNCTION IS UNSAFE AND SHOULD NOT BE USED.  The file name may
///     refer to a file that did not exist at some point, but by the time
///     you get around to creating it, someone else may have beaten you to
///     the punch.
///     """
///
/// ##    from warnings import warn as _warn
/// ##    _warn("mktemp is a potential security risk to your program",
/// ##          RuntimeWarning, stacklevel=2)
///
///     if dir is None:
///         dir = gettempdir()
///
///     names = _get_candidate_names()
///     for seq in range(TMP_MAX):
///         name = next(names)
///         file = _os.path.join(dir, prefix + name + suffix)
///         if not _exists(file):
///             return file
///
///     raise FileExistsError(_errno.EEXIST,
///                           "No usable temporary filename found")
///
///
/// class _TemporaryFileCloser:
///     """A separate object allowing proper closing of a temporary file's
///     underlying file object, without adding a __del__ method to the
///     temporary file."""
///
///     file = None  # Set here since __del__ checks it
///     close_called = False
///
///     def __init__(self, file, name, delete=True):
///         self.file = file
///         self.name = name
///         self.delete = delete
///
///     # NT provides delete-on-close as a primitive, so we don't need
///     # the wrapper to do anything special.  We still use it so that
///     # file.name is useful (i.e. not "(fdopen)") with NamedTemporaryFile.
///     if _os.name != 'nt':
///         # Cache the unlinker so we don't get spurious errors at
///         # shutdown when the module-level "os" is None'd out.  Note
///         # that this must be referenced as self.unlink, because the
///         # name TemporaryFileWrapper may also get None'd out before
///         # __del__ is called.
///
///         def close(self, unlink=_os.unlink):
///             if not self.close_called and self.file is not None:
///                 self.close_called = True
///                 try:
///                     self.file.close()
///                 finally:
///                     if self.delete:
///                         unlink(self.name)
///
///         # Need to ensure the file is deleted on __del__
///         def __del__(self):
///             self.close()
///
///     else:
///         def close(self):
///             if not self.close_called:
///                 self.close_called = True
///                 self.file.close()
///
///
/// class _TemporaryFileWrapper:
///     """Temporary file wrapper
///
///     This class provides a wrapper around files opened for
///     temporary use.  In particular, it seeks to automatically
///     remove the file when it is no longer needed.
///     """
///
///     def __init__(self, file, name, delete=True):
///         self.file = file
///         self.name = name
///         self.delete = delete
///         self._closer = _TemporaryFileCloser(file, name, delete)
///
///     def __getattr__(self, name):
///         # Attribute lookups are delegated to the underlying file
///         # and cached for non-numeric results
///         # (i.e. methods are cached, closed and friends are not)
///         file = self.__dict__['file']
///         a = getattr(file, name)
///         if hasattr(a, '__call__'):
///             func = a
///             @_functools.wraps(func)
///             def func_wrapper(*args, **kwargs):
///                 return func(*args, **kwargs)
///             # Avoid closing the file as long as the wrapper is alive,
///             # see issue #18879.
///             func_wrapper._closer = self._closer
///             a = func_wrapper
///         if not isinstance(a, int):
///             setattr(self, name, a)
///         return a
///
///     # The underlying __enter__ method returns the wrong object
///     # (self.file) so override it to return the wrapper
///     def __enter__(self):
///         self.file.__enter__()
///         return self
///
///     # Need to trap __exit__ as well to ensure the file gets
///     # deleted when used in a with statement
///     def __exit__(self, exc, value, tb):
///         result = self.file.__exit__(exc, value, tb)
///         self.close()
///         return result
///
///     def close(self):
///         """
///         Close the temporary file, possibly deleting it.
///         """
///         self._closer.close()
///
///     # iter() doesn't use __getattr__ to find the __iter__ method
///     def __iter__(self):
///         # Don't return iter(self.file), but yield from it to avoid closing
///         # file as long as it's being used as iterator (see issue #23700).  We
///         # can't use 'yield from' here because iter(file) returns the file
///         # object itself, which has a close method, and thus the file would get
///         # closed when the generator is finalized, due to PEP380 semantics.
///         for line in self.file:
///             yield line
///
///
/// def NamedTemporaryFile(mode='w+b', buffering=-1, encoding=None,
///                        newline=None, suffix=None, prefix=None,
///                        dir=None, delete=True, *, errors=None):
///     """Create and return a temporary file.
///     Arguments:
///     'prefix', 'suffix', 'dir' -- as for mkstemp.
///     'mode' -- the mode argument to io.open (default "w+b").
///     'buffering' -- the buffer size argument to io.open (default -1).
///     'encoding' -- the encoding argument to io.open (default None)
///     'newline' -- the newline argument to io.open (default None)
///     'delete' -- whether the file is deleted on close (default True).
///     'errors' -- the errors argument to io.open (default None)
///     The file is created as mkstemp() would do it.
///
///     Returns an object with a file-like interface; the name of the file
///     is accessible as its 'name' attribute.  The file will be automatically
///     deleted when it is closed unless the 'delete' argument is set to False.
///
///     On POSIX, NamedTemporaryFiles cannot be automatically deleted if
///     the creating process is terminated abruptly with a SIGKILL signal.
///     Windows can delete the file even in this case.
///     """
///
///     prefix, suffix, dir, output_type = _sanitize_params(prefix, suffix, dir)
///
///     flags = _bin_openflags
///
///     # Setting O_TEMPORARY in the flags causes the OS to delete
///     # the file when it is closed.  This is only supported by Windows.
///     if _os.name == 'nt' and delete:
///         flags |= _os.O_TEMPORARY
///
///     if "b" not in mode:
///         encoding = _io.text_encoding(encoding)
///
///     name = None
///     def opener(*args):
///         nonlocal name
///         fd, name = _mkstemp_inner(dir, prefix, suffix, flags, output_type)
///         return fd
///     try:
///         file = _io.open(dir, mode, buffering=buffering,
///                         newline=newline, encoding=encoding, errors=errors,
///                         opener=opener)
///         try:
///             raw = getattr(file, 'buffer', file)
///             raw = getattr(raw, 'raw', raw)
///             raw.name = name
///             return _TemporaryFileWrapper(file, name, delete)
///         except:
///             file.close()
///             raise
///     except:
///         if name is not None and not (_os.name == 'nt' and delete):
///             _os.unlink(name)
///         raise
///
/// if _os.name != 'posix' or _sys.platform == 'cygwin':
///     # On non-POSIX and Cygwin systems, assume that we cannot unlink a file
///     # while it is open.
///     TemporaryFile = NamedTemporaryFile
///
/// else:
///     # Is the O_TMPFILE flag available and does it work?
///     # The flag is set to False if os.open(dir, os.O_TMPFILE) raises an
///     # IsADirectoryError exception
///     _O_TMPFILE_WORKS = hasattr(_os, 'O_TMPFILE')
///
///     def TemporaryFile(mode='w+b', buffering=-1, encoding=None,
///                       newline=None, suffix=None, prefix=None,
///                       dir=None, *, errors=None):
///         """Create and return a temporary file.
///         Arguments:
///         'prefix', 'suffix', 'dir' -- as for mkstemp.
///         'mode' -- the mode argument to io.open (default "w+b").
///         'buffering' -- the buffer size argument to io.open (default -1).
///         'encoding' -- the encoding argument to io.open (default None)
///         'newline' -- the newline argument to io.open (default None)
///         'errors' -- the errors argument to io.open (default None)
///         The file is created as mkstemp() would do it.
///
///         Returns an object with a file-like interface.  The file has no
///         name, and will cease to exist when it is closed.
///         """
///         global _O_TMPFILE_WORKS
///
///         if "b" not in mode:
///             encoding = _io.text_encoding(encoding)
///
///         prefix, suffix, dir, output_type = _sanitize_params(prefix, suffix, dir)
///
///         flags = _bin_openflags
///         if _O_TMPFILE_WORKS:
///             fd = None
///             def opener(*args):
///                 nonlocal fd
///                 flags2 = (flags | _os.O_TMPFILE) & ~_os.O_CREAT
///                 fd = _os.open(dir, flags2, 0o600)
///                 return fd
///             try:
///                 file = _io.open(dir, mode, buffering=buffering,
///                                 newline=newline, encoding=encoding,
///                                 errors=errors, opener=opener)
///                 raw = getattr(file, 'buffer', file)
///                 raw = getattr(raw, 'raw', raw)
///                 raw.name = fd
///                 return file
///             except IsADirectoryError:
///                 # Linux kernel older than 3.11 ignores the O_TMPFILE flag:
///                 # O_TMPFILE is read as O_DIRECTORY. Trying to open a directory
///                 # with O_RDWR|O_DIRECTORY fails with IsADirectoryError, a
///                 # directory cannot be open to write. Set flag to False to not
///                 # try again.
///                 _O_TMPFILE_WORKS = False
///             except OSError:
///                 # The filesystem of the directory does not support O_TMPFILE.
///                 # For example, OSError(95, 'Operation not supported').
///                 #
///                 # On Linux kernel older than 3.11, trying to open a regular
///                 # file (or a symbolic link to a regular file) with O_TMPFILE
///                 # fails with NotADirectoryError, because O_TMPFILE is read as
///                 # O_DIRECTORY.
///                 pass
///             # Fallback to _mkstemp_inner().
///
///         fd = None
///         def opener(*args):
///             nonlocal fd
///             fd, name = _mkstemp_inner(dir, prefix, suffix, flags, output_type)
///             try:
///                 _os.unlink(name)
///             except BaseException as e:
///                 _os.close(fd)
///                 raise
///             return fd
///         file = _io.open(dir, mode, buffering=buffering,
///                         newline=newline, encoding=encoding, errors=errors,
///                         opener=opener)
///         raw = getattr(file, 'buffer', file)
///         raw = getattr(raw, 'raw', raw)
///         raw.name = fd
///         return file
///
/// class SpooledTemporaryFile(_io.IOBase):
///     """Temporary file wrapper, specialized to switch from BytesIO
///     or StringIO to a real file when it exceeds a certain size or
///     when a fileno is needed.
///     """
///     _rolled = False
///
///     def __init__(self, max_size=0, mode='w+b', buffering=-1,
///                  encoding=None, newline=None,
///                  suffix=None, prefix=None, dir=None, *, errors=None):
///         if 'b' in mode:
///             self._file = _io.BytesIO()
///         else:
///             encoding = _io.text_encoding(encoding)
///             self._file = _io.TextIOWrapper(_io.BytesIO(),
///                             encoding=encoding, errors=errors,
///                             newline=newline)
///         self._max_size = max_size
///         self._rolled = False
///         self._TemporaryFileArgs = {'mode': mode, 'buffering': buffering,
///                                    'suffix': suffix, 'prefix': prefix,
///                                    'encoding': encoding, 'newline': newline,
///                                    'dir': dir, 'errors': errors}
///
///     __class_getitem__ = classmethod(_types.GenericAlias)
///
///     def _check(self, file):
///         if self._rolled: return
///         max_size = self._max_size
///         if max_size and file.tell() > max_size:
///             self.rollover()
///
///     def rollover(self):
///         if self._rolled: return
///         file = self._file
///         newfile = self._file = TemporaryFile(**self._TemporaryFileArgs)
///         del self._TemporaryFileArgs
///
///         pos = file.tell()
///         if hasattr(newfile, 'buffer'):
///             newfile.buffer.write(file.detach().getvalue())
///         else:
///             newfile.write(file.getvalue())
///         newfile.seek(pos, 0)
///
///         self._rolled = True
///
///     # The method caching trick from NamedTemporaryFile
///     # won't work here, because _file may change from a
///     # BytesIO/StringIO instance to a real file. So we list
///     # all the methods directly.
///
///     # Context management protocol
///     def __enter__(self):
///         if self._file.closed:
///             raise ValueError("Cannot enter context with closed file")
///         return self
///
///     def __exit__(self, exc, value, tb):
///         self._file.close()
///
///     # file protocol
///     def __iter__(self):
///         return self._file.__iter__()
///
///     def __del__(self):
///         if not self.closed:
///             _warnings.warn(
///                 "Unclosed file {!r}".format(self),
///                 ResourceWarning,
///                 stacklevel=2,
///                 source=self
///             )
///             self.close()
///
///     def close(self):
///         self._file.close()
///
///     @property
///     def closed(self):
///         return self._file.closed
///
///     @property
///     def encoding(self):
///         return self._file.encoding
///
///     @property
///     def errors(self):
///         return self._file.errors
///
///     def fileno(self):
///         self.rollover()
///         return self._file.fileno()
///
///     def flush(self):
///         self._file.flush()
///
///     def isatty(self):
///         return self._file.isatty()
///
///     @property
///     def mode(self):
///         try:
///             return self._file.mode
///         except AttributeError:
///             return self._TemporaryFileArgs['mode']
///
///     @property
///     def name(self):
///         try:
///             return self._file.name
///         except AttributeError:
///             return None
///
///     @property
///     def newlines(self):
///         return self._file.newlines
///
///     def readable(self):
///         return self._file.readable()
///
///     def read(self, *args):
///         return self._file.read(*args)
///
///     def read1(self, *args):
///         return self._file.read1(*args)
///
///     def readinto(self, b):
///         return self._file.readinto(b)
///
///     def readinto1(self, b):
///         return self._file.readinto1(b)
///
///     def readline(self, *args):
///         return self._file.readline(*args)
///
///     def readlines(self, *args):
///         return self._file.readlines(*args)
///
///     def seekable(self):
///         return self._file.seekable()
///
///     def seek(self, *args):
///         return self._file.seek(*args)
///
///     def tell(self):
///         return self._file.tell()
///
///     def truncate(self, size=None):
///         if size is None:
///             return self._file.truncate()
///         else:
///             if size > self._max_size:
///                 self.rollover()
///             return self._file.truncate(size)
///
///     def writable(self):
///         return self._file.writable()
///
///     def write(self, s):
///         file = self._file
///         rv = file.write(s)
///         self._check(file)
///         return rv
///
///     def writelines(self, iterable):
///         file = self._file
///         rv = file.writelines(iterable)
///         self._check(file)
///         return rv
///
///     def detach(self):
///         return self._file.detach()
///
///
/// class TemporaryDirectory:
///     """Create and return a temporary directory.  This has the same
///     behavior as mkdtemp but can be used as a context manager.  For
///     example:
///
///         with TemporaryDirectory() as tmpdir:
///             ...
///
///     Upon exiting the context, the directory and everything contained
///     in it are removed.
///     """
///
///     def __init__(self, suffix=None, prefix=None, dir=None,
///                  ignore_cleanup_errors=False):
///         self.name = mkdtemp(suffix, prefix, dir)
///         self._ignore_cleanup_errors = ignore_cleanup_errors
///         self._finalizer = _weakref.finalize(
///             self, self._cleanup, self.name,
///             warn_message="Implicitly cleaning up {!r}".format(self),
///             ignore_errors=self._ignore_cleanup_errors)
///
///     @classmethod
///     def _rmtree(cls, name, ignore_errors=False):
///         def onerror(func, path, exc_info):
///             if issubclass(exc_info[0], PermissionError):
///                 def resetperms(path):
///                     try:
///                         _os.chflags(path, 0)
///                     except AttributeError:
///                         pass
///                     _os.chmod(path, 0o700)
///
///                 try:
///                     if path != name:
///                         resetperms(_os.path.dirname(path))
///                     resetperms(path)
///
///                     try:
///                         _os.unlink(path)
///                     # PermissionError is raised on FreeBSD for directories
///                     except (IsADirectoryError, PermissionError):
///                         cls._rmtree(path, ignore_errors=ignore_errors)
///                 except FileNotFoundError:
///                     pass
///             elif issubclass(exc_info[0], FileNotFoundError):
///                 pass
///             else:
///                 if not ignore_errors:
///                     raise
///
///         _shutil.rmtree(name, onerror=onerror)
///
///     @classmethod
///     def _cleanup(cls, name, warn_message, ignore_errors=False):
///         cls._rmtree(name, ignore_errors=ignore_errors)
///         _warnings.warn(warn_message, ResourceWarning)
///
///     def __repr__(self):
///         return "<{} {!r}>".format(self.__class__.__name__, self.name)
///
///     def __enter__(self):
///         return self.name
///
///     def __exit__(self, exc, value, tb):
///         self.cleanup()
///
///     def cleanup(self):
///         if self._finalizer.detach() or _os.path.exists(self.name):
///             self._rmtree(self.name, ignore_errors=self._ignore_cleanup_errors)
///
///     __class_getitem__ = classmethod(_types.GenericAlias)
/// ```
final class tempfile extends PythonModule {
  tempfile.from(super.pythonModule) : super.from();

  static tempfile import() => PythonFfiDart.instance.importModule(
        "tempfile",
        tempfile.from,
      );

  /// ## NamedTemporaryFile
  ///
  /// ### python docstring
  ///
  /// Create and return a temporary file.
  /// Arguments:
  /// 'prefix', 'suffix', 'dir' -- as for mkstemp.
  /// 'mode' -- the mode argument to io.open (default "w+b").
  /// 'buffering' -- the buffer size argument to io.open (default -1).
  /// 'encoding' -- the encoding argument to io.open (default None)
  /// 'newline' -- the newline argument to io.open (default None)
  /// 'delete' -- whether the file is deleted on close (default True).
  /// 'errors' -- the errors argument to io.open (default None)
  /// The file is created as mkstemp() would do it.
  ///
  /// Returns an object with a file-like interface; the name of the file
  /// is accessible as its 'name' attribute.  The file will be automatically
  /// deleted when it is closed unless the 'delete' argument is set to False.
  ///
  /// On POSIX, NamedTemporaryFiles cannot be automatically deleted if
  /// the creating process is terminated abruptly with a SIGKILL signal.
  /// Windows can delete the file even in this case.
  ///
  /// ### python source
  /// ```py
  /// def NamedTemporaryFile(mode='w+b', buffering=-1, encoding=None,
  ///                        newline=None, suffix=None, prefix=None,
  ///                        dir=None, delete=True, *, errors=None):
  ///     """Create and return a temporary file.
  ///     Arguments:
  ///     'prefix', 'suffix', 'dir' -- as for mkstemp.
  ///     'mode' -- the mode argument to io.open (default "w+b").
  ///     'buffering' -- the buffer size argument to io.open (default -1).
  ///     'encoding' -- the encoding argument to io.open (default None)
  ///     'newline' -- the newline argument to io.open (default None)
  ///     'delete' -- whether the file is deleted on close (default True).
  ///     'errors' -- the errors argument to io.open (default None)
  ///     The file is created as mkstemp() would do it.
  ///
  ///     Returns an object with a file-like interface; the name of the file
  ///     is accessible as its 'name' attribute.  The file will be automatically
  ///     deleted when it is closed unless the 'delete' argument is set to False.
  ///
  ///     On POSIX, NamedTemporaryFiles cannot be automatically deleted if
  ///     the creating process is terminated abruptly with a SIGKILL signal.
  ///     Windows can delete the file even in this case.
  ///     """
  ///
  ///     prefix, suffix, dir, output_type = _sanitize_params(prefix, suffix, dir)
  ///
  ///     flags = _bin_openflags
  ///
  ///     # Setting O_TEMPORARY in the flags causes the OS to delete
  ///     # the file when it is closed.  This is only supported by Windows.
  ///     if _os.name == 'nt' and delete:
  ///         flags |= _os.O_TEMPORARY
  ///
  ///     if "b" not in mode:
  ///         encoding = _io.text_encoding(encoding)
  ///
  ///     name = None
  ///     def opener(*args):
  ///         nonlocal name
  ///         fd, name = _mkstemp_inner(dir, prefix, suffix, flags, output_type)
  ///         return fd
  ///     try:
  ///         file = _io.open(dir, mode, buffering=buffering,
  ///                         newline=newline, encoding=encoding, errors=errors,
  ///                         opener=opener)
  ///         try:
  ///             raw = getattr(file, 'buffer', file)
  ///             raw = getattr(raw, 'raw', raw)
  ///             raw.name = name
  ///             return _TemporaryFileWrapper(file, name, delete)
  ///         except:
  ///             file.close()
  ///             raise
  ///     except:
  ///         if name is not None and not (_os.name == 'nt' and delete):
  ///             _os.unlink(name)
  ///         raise
  /// ```
  Object? NamedTemporaryFile({
    Object? mode = "w+b",
    Object? buffering = -1,
    Object? encoding,
    Object? newline,
    Object? suffix,
    Object? prefix,
    Object? dir,
    Object? delete = true,
    Object? errors,
  }) =>
      getFunction("NamedTemporaryFile").call(
        <Object?>[
          mode,
          buffering,
          encoding,
          newline,
          suffix,
          prefix,
          dir,
          delete,
        ],
        kwargs: <String, Object?>{
          "errors": errors,
        },
      );

  /// ## TemporaryFile
  ///
  /// ### python docstring
  ///
  /// Create and return a temporary file.
  /// Arguments:
  /// 'prefix', 'suffix', 'dir' -- as for mkstemp.
  /// 'mode' -- the mode argument to io.open (default "w+b").
  /// 'buffering' -- the buffer size argument to io.open (default -1).
  /// 'encoding' -- the encoding argument to io.open (default None)
  /// 'newline' -- the newline argument to io.open (default None)
  /// 'errors' -- the errors argument to io.open (default None)
  /// The file is created as mkstemp() would do it.
  ///
  /// Returns an object with a file-like interface.  The file has no
  /// name, and will cease to exist when it is closed.
  ///
  /// ### python source
  /// ```py
  /// def TemporaryFile(mode='w+b', buffering=-1, encoding=None,
  ///                       newline=None, suffix=None, prefix=None,
  ///                       dir=None, *, errors=None):
  ///         """Create and return a temporary file.
  ///         Arguments:
  ///         'prefix', 'suffix', 'dir' -- as for mkstemp.
  ///         'mode' -- the mode argument to io.open (default "w+b").
  ///         'buffering' -- the buffer size argument to io.open (default -1).
  ///         'encoding' -- the encoding argument to io.open (default None)
  ///         'newline' -- the newline argument to io.open (default None)
  ///         'errors' -- the errors argument to io.open (default None)
  ///         The file is created as mkstemp() would do it.
  ///
  ///         Returns an object with a file-like interface.  The file has no
  ///         name, and will cease to exist when it is closed.
  ///         """
  ///         global _O_TMPFILE_WORKS
  ///
  ///         if "b" not in mode:
  ///             encoding = _io.text_encoding(encoding)
  ///
  ///         prefix, suffix, dir, output_type = _sanitize_params(prefix, suffix, dir)
  ///
  ///         flags = _bin_openflags
  ///         if _O_TMPFILE_WORKS:
  ///             fd = None
  ///             def opener(*args):
  ///                 nonlocal fd
  ///                 flags2 = (flags | _os.O_TMPFILE) & ~_os.O_CREAT
  ///                 fd = _os.open(dir, flags2, 0o600)
  ///                 return fd
  ///             try:
  ///                 file = _io.open(dir, mode, buffering=buffering,
  ///                                 newline=newline, encoding=encoding,
  ///                                 errors=errors, opener=opener)
  ///                 raw = getattr(file, 'buffer', file)
  ///                 raw = getattr(raw, 'raw', raw)
  ///                 raw.name = fd
  ///                 return file
  ///             except IsADirectoryError:
  ///                 # Linux kernel older than 3.11 ignores the O_TMPFILE flag:
  ///                 # O_TMPFILE is read as O_DIRECTORY. Trying to open a directory
  ///                 # with O_RDWR|O_DIRECTORY fails with IsADirectoryError, a
  ///                 # directory cannot be open to write. Set flag to False to not
  ///                 # try again.
  ///                 _O_TMPFILE_WORKS = False
  ///             except OSError:
  ///                 # The filesystem of the directory does not support O_TMPFILE.
  ///                 # For example, OSError(95, 'Operation not supported').
  ///                 #
  ///                 # On Linux kernel older than 3.11, trying to open a regular
  ///                 # file (or a symbolic link to a regular file) with O_TMPFILE
  ///                 # fails with NotADirectoryError, because O_TMPFILE is read as
  ///                 # O_DIRECTORY.
  ///                 pass
  ///             # Fallback to _mkstemp_inner().
  ///
  ///         fd = None
  ///         def opener(*args):
  ///             nonlocal fd
  ///             fd, name = _mkstemp_inner(dir, prefix, suffix, flags, output_type)
  ///             try:
  ///                 _os.unlink(name)
  ///             except BaseException as e:
  ///                 _os.close(fd)
  ///                 raise
  ///             return fd
  ///         file = _io.open(dir, mode, buffering=buffering,
  ///                         newline=newline, encoding=encoding, errors=errors,
  ///                         opener=opener)
  ///         raw = getattr(file, 'buffer', file)
  ///         raw = getattr(raw, 'raw', raw)
  ///         raw.name = fd
  ///         return file
  /// ```
  Object? TemporaryFile({
    Object? mode = "w+b",
    Object? buffering = -1,
    Object? encoding,
    Object? newline,
    Object? suffix,
    Object? prefix,
    Object? dir,
    Object? errors,
  }) =>
      getFunction("TemporaryFile").call(
        <Object?>[
          mode,
          buffering,
          encoding,
          newline,
          suffix,
          prefix,
          dir,
        ],
        kwargs: <String, Object?>{
          "errors": errors,
        },
      );

  /// ## gettempdir
  ///
  /// ### python docstring
  ///
  /// Returns tempfile.tempdir as str.
  ///
  /// ### python source
  /// ```py
  /// def gettempdir():
  ///     """Returns tempfile.tempdir as str."""
  ///     return _os.fsdecode(_gettempdir())
  /// ```
  Object? gettempdir() => getFunction("gettempdir").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## gettempdirb
  ///
  /// ### python docstring
  ///
  /// Returns tempfile.tempdir as bytes.
  ///
  /// ### python source
  /// ```py
  /// def gettempdirb():
  ///     """Returns tempfile.tempdir as bytes."""
  ///     return _os.fsencode(_gettempdir())
  /// ```
  Object? gettempdirb() => getFunction("gettempdirb").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## gettempprefix
  ///
  /// ### python docstring
  ///
  /// The default prefix for temporary directories as string.
  ///
  /// ### python source
  /// ```py
  /// def gettempprefix():
  ///     """The default prefix for temporary directories as string."""
  ///     return _os.fsdecode(template)
  /// ```
  Object? gettempprefix() => getFunction("gettempprefix").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## gettempprefixb
  ///
  /// ### python docstring
  ///
  /// The default prefix for temporary directories as bytes.
  ///
  /// ### python source
  /// ```py
  /// def gettempprefixb():
  ///     """The default prefix for temporary directories as bytes."""
  ///     return _os.fsencode(template)
  /// ```
  Object? gettempprefixb() => getFunction("gettempprefixb").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## mkdtemp
  ///
  /// ### python docstring
  ///
  /// User-callable function to create and return a unique temporary
  /// directory.  The return value is the pathname of the directory.
  ///
  /// Arguments are as for mkstemp, except that the 'text' argument is
  /// not accepted.
  ///
  /// The directory is readable, writable, and searchable only by the
  /// creating user.
  ///
  /// Caller is responsible for deleting the directory when done with it.
  ///
  /// ### python source
  /// ```py
  /// def mkdtemp(suffix=None, prefix=None, dir=None):
  ///     """User-callable function to create and return a unique temporary
  ///     directory.  The return value is the pathname of the directory.
  ///
  ///     Arguments are as for mkstemp, except that the 'text' argument is
  ///     not accepted.
  ///
  ///     The directory is readable, writable, and searchable only by the
  ///     creating user.
  ///
  ///     Caller is responsible for deleting the directory when done with it.
  ///     """
  ///
  ///     prefix, suffix, dir, output_type = _sanitize_params(prefix, suffix, dir)
  ///
  ///     names = _get_candidate_names()
  ///     if output_type is bytes:
  ///         names = map(_os.fsencode, names)
  ///
  ///     for seq in range(TMP_MAX):
  ///         name = next(names)
  ///         file = _os.path.join(dir, prefix + name + suffix)
  ///         _sys.audit("tempfile.mkdtemp", file)
  ///         try:
  ///             _os.mkdir(file, 0o700)
  ///         except FileExistsError:
  ///             continue    # try again
  ///         except PermissionError:
  ///             # This exception is thrown when a directory with the chosen name
  ///             # already exists on windows.
  ///             if (_os.name == 'nt' and _os.path.isdir(dir) and
  ///                 _os.access(dir, _os.W_OK)):
  ///                 continue
  ///             else:
  ///                 raise
  ///         return file
  ///
  ///     raise FileExistsError(_errno.EEXIST,
  ///                           "No usable temporary directory name found")
  /// ```
  Object? mkdtemp({
    Object? suffix,
    Object? prefix,
    Object? dir,
  }) =>
      getFunction("mkdtemp").call(
        <Object?>[
          suffix,
          prefix,
          dir,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## mkstemp
  ///
  /// ### python docstring
  ///
  /// User-callable function to create and return a unique temporary
  /// file.  The return value is a pair (fd, name) where fd is the
  /// file descriptor returned by os.open, and name is the filename.
  ///
  /// If 'suffix' is not None, the file name will end with that suffix,
  /// otherwise there will be no suffix.
  ///
  /// If 'prefix' is not None, the file name will begin with that prefix,
  /// otherwise a default prefix is used.
  ///
  /// If 'dir' is not None, the file will be created in that directory,
  /// otherwise a default directory is used.
  ///
  /// If 'text' is specified and true, the file is opened in text
  /// mode.  Else (the default) the file is opened in binary mode.
  ///
  /// If any of 'suffix', 'prefix' and 'dir' are not None, they must be the
  /// same type.  If they are bytes, the returned name will be bytes; str
  /// otherwise.
  ///
  /// The file is readable and writable only by the creating user ID.
  /// If the operating system uses permission bits to indicate whether a
  /// file is executable, the file is executable by no one. The file
  /// descriptor is not inherited by children of this process.
  ///
  /// Caller is responsible for deleting the file when done with it.
  ///
  /// ### python source
  /// ```py
  /// def mkstemp(suffix=None, prefix=None, dir=None, text=False):
  ///     """User-callable function to create and return a unique temporary
  ///     file.  The return value is a pair (fd, name) where fd is the
  ///     file descriptor returned by os.open, and name is the filename.
  ///
  ///     If 'suffix' is not None, the file name will end with that suffix,
  ///     otherwise there will be no suffix.
  ///
  ///     If 'prefix' is not None, the file name will begin with that prefix,
  ///     otherwise a default prefix is used.
  ///
  ///     If 'dir' is not None, the file will be created in that directory,
  ///     otherwise a default directory is used.
  ///
  ///     If 'text' is specified and true, the file is opened in text
  ///     mode.  Else (the default) the file is opened in binary mode.
  ///
  ///     If any of 'suffix', 'prefix' and 'dir' are not None, they must be the
  ///     same type.  If they are bytes, the returned name will be bytes; str
  ///     otherwise.
  ///
  ///     The file is readable and writable only by the creating user ID.
  ///     If the operating system uses permission bits to indicate whether a
  ///     file is executable, the file is executable by no one. The file
  ///     descriptor is not inherited by children of this process.
  ///
  ///     Caller is responsible for deleting the file when done with it.
  ///     """
  ///
  ///     prefix, suffix, dir, output_type = _sanitize_params(prefix, suffix, dir)
  ///
  ///     if text:
  ///         flags = _text_openflags
  ///     else:
  ///         flags = _bin_openflags
  ///
  ///     return _mkstemp_inner(dir, prefix, suffix, flags, output_type)
  /// ```
  Object? mkstemp({
    Object? suffix,
    Object? prefix,
    Object? dir,
    Object? text = false,
  }) =>
      getFunction("mkstemp").call(
        <Object?>[
          suffix,
          prefix,
          dir,
          text,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## mktemp
  ///
  /// ### python docstring
  ///
  /// User-callable function to return a unique temporary file name.  The
  /// file is not created.
  ///
  /// Arguments are similar to mkstemp, except that the 'text' argument is
  /// not accepted, and suffix=None, prefix=None and bytes file names are not
  /// supported.
  ///
  /// THIS FUNCTION IS UNSAFE AND SHOULD NOT BE USED.  The file name may
  /// refer to a file that did not exist at some point, but by the time
  /// you get around to creating it, someone else may have beaten you to
  /// the punch.
  ///
  /// ### python source
  /// ```py
  /// def mktemp(suffix="", prefix=template, dir=None):
  ///     """User-callable function to return a unique temporary file name.  The
  ///     file is not created.
  ///
  ///     Arguments are similar to mkstemp, except that the 'text' argument is
  ///     not accepted, and suffix=None, prefix=None and bytes file names are not
  ///     supported.
  ///
  ///     THIS FUNCTION IS UNSAFE AND SHOULD NOT BE USED.  The file name may
  ///     refer to a file that did not exist at some point, but by the time
  ///     you get around to creating it, someone else may have beaten you to
  ///     the punch.
  ///     """
  ///
  /// ##    from warnings import warn as _warn
  /// ##    _warn("mktemp is a potential security risk to your program",
  /// ##          RuntimeWarning, stacklevel=2)
  ///
  ///     if dir is None:
  ///         dir = gettempdir()
  ///
  ///     names = _get_candidate_names()
  ///     for seq in range(TMP_MAX):
  ///         name = next(names)
  ///         file = _os.path.join(dir, prefix + name + suffix)
  ///         if not _exists(file):
  ///             return file
  ///
  ///     raise FileExistsError(_errno.EEXIST,
  ///                           "No usable temporary filename found")
  /// ```
  Object? mktemp({
    Object? suffix = "",
    Object? prefix = "tmp",
    Object? dir,
  }) =>
      getFunction("mktemp").call(
        <Object?>[
          suffix,
          prefix,
          dir,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## TMP_MAX (getter)
  Object? get TMP_MAX => getAttribute("TMP_MAX");

  /// ## TMP_MAX (setter)
  set TMP_MAX(Object? TMP_MAX) => setAttribute("TMP_MAX", TMP_MAX);

  /// ## tempdir (getter)
  Object? get tempdir => getAttribute("tempdir");

  /// ## tempdir (setter)
  set tempdir(Object? tempdir) => setAttribute("tempdir", tempdir);

  /// ## template (getter)
  Object? get template => getAttribute("template");

  /// ## template (setter)
  set template(Object? template) => setAttribute("template", template);
}

/// ## types
///
/// ### python docstring
///
/// Define names for built-in types that aren't directly accessible as a builtin.
///
/// ### python source
/// ```py
/// """
/// Define names for built-in types that aren't directly accessible as a builtin.
/// """
/// import sys
///
/// # Iterators in Python aren't a matter of type but of protocol.  A large
/// # and changing number of builtin types implement *some* flavor of
/// # iterator.  Don't check the type!  Use hasattr to check for both
/// # "__iter__" and "__next__" attributes instead.
///
/// def _f(): pass
/// FunctionType = type(_f)
/// LambdaType = type(lambda: None)         # Same as FunctionType
/// CodeType = type(_f.__code__)
/// MappingProxyType = type(type.__dict__)
/// SimpleNamespace = type(sys.implementation)
///
/// def _cell_factory():
///     a = 1
///     def f():
///         nonlocal a
///     return f.__closure__[0]
/// CellType = type(_cell_factory())
///
/// def _g():
///     yield 1
/// GeneratorType = type(_g())
///
/// async def _c(): pass
/// _c = _c()
/// CoroutineType = type(_c)
/// _c.close()  # Prevent ResourceWarning
///
/// async def _ag():
///     yield
/// _ag = _ag()
/// AsyncGeneratorType = type(_ag)
///
/// class _C:
///     def _m(self): pass
/// MethodType = type(_C()._m)
///
/// BuiltinFunctionType = type(len)
/// BuiltinMethodType = type([].append)     # Same as BuiltinFunctionType
///
/// WrapperDescriptorType = type(object.__init__)
/// MethodWrapperType = type(object().__str__)
/// MethodDescriptorType = type(str.join)
/// ClassMethodDescriptorType = type(dict.__dict__['fromkeys'])
///
/// ModuleType = type(sys)
///
/// try:
///     raise TypeError
/// except TypeError as exc:
///     TracebackType = type(exc.__traceback__)
///     FrameType = type(exc.__traceback__.tb_frame)
///
/// # For Jython, the following two types are identical
/// GetSetDescriptorType = type(FunctionType.__code__)
/// MemberDescriptorType = type(FunctionType.__globals__)
///
/// del sys, _f, _g, _C, _c, _ag  # Not for export
///
///
/// # Provide a PEP 3115 compliant mechanism for class creation
/// def new_class(name, bases=(), kwds=None, exec_body=None):
///     """Create a class object dynamically using the appropriate metaclass."""
///     resolved_bases = resolve_bases(bases)
///     meta, ns, kwds = prepare_class(name, resolved_bases, kwds)
///     if exec_body is not None:
///         exec_body(ns)
///     if resolved_bases is not bases:
///         ns['__orig_bases__'] = bases
///     return meta(name, resolved_bases, ns, **kwds)
///
/// def resolve_bases(bases):
///     """Resolve MRO entries dynamically as specified by PEP 560."""
///     new_bases = list(bases)
///     updated = False
///     shift = 0
///     for i, base in enumerate(bases):
///         if isinstance(base, type):
///             continue
///         if not hasattr(base, "__mro_entries__"):
///             continue
///         new_base = base.__mro_entries__(bases)
///         updated = True
///         if not isinstance(new_base, tuple):
///             raise TypeError("__mro_entries__ must return a tuple")
///         else:
///             new_bases[i+shift:i+shift+1] = new_base
///             shift += len(new_base) - 1
///     if not updated:
///         return bases
///     return tuple(new_bases)
///
/// def prepare_class(name, bases=(), kwds=None):
///     """Call the __prepare__ method of the appropriate metaclass.
///
///     Returns (metaclass, namespace, kwds) as a 3-tuple
///
///     *metaclass* is the appropriate metaclass
///     *namespace* is the prepared class namespace
///     *kwds* is an updated copy of the passed in kwds argument with any
///     'metaclass' entry removed. If no kwds argument is passed in, this will
///     be an empty dict.
///     """
///     if kwds is None:
///         kwds = {}
///     else:
///         kwds = dict(kwds) # Don't alter the provided mapping
///     if 'metaclass' in kwds:
///         meta = kwds.pop('metaclass')
///     else:
///         if bases:
///             meta = type(bases[0])
///         else:
///             meta = type
///     if isinstance(meta, type):
///         # when meta is a type, we first determine the most-derived metaclass
///         # instead of invoking the initial candidate directly
///         meta = _calculate_meta(meta, bases)
///     if hasattr(meta, '__prepare__'):
///         ns = meta.__prepare__(name, bases, **kwds)
///     else:
///         ns = {}
///     return meta, ns, kwds
///
/// def _calculate_meta(meta, bases):
///     """Calculate the most derived metaclass."""
///     winner = meta
///     for base in bases:
///         base_meta = type(base)
///         if issubclass(winner, base_meta):
///             continue
///         if issubclass(base_meta, winner):
///             winner = base_meta
///             continue
///         # else:
///         raise TypeError("metaclass conflict: "
///                         "the metaclass of a derived class "
///                         "must be a (non-strict) subclass "
///                         "of the metaclasses of all its bases")
///     return winner
///
/// class DynamicClassAttribute:
///     """Route attribute access on a class to __getattr__.
///
///     This is a descriptor, used to define attributes that act differently when
///     accessed through an instance and through a class.  Instance access remains
///     normal, but access to an attribute through a class will be routed to the
///     class's __getattr__ method; this is done by raising AttributeError.
///
///     This allows one to have properties active on an instance, and have virtual
///     attributes on the class with the same name.  (Enum used this between Python
///     versions 3.4 - 3.9 .)
///
///     Subclass from this to use a different method of accessing virtual attributes
///     and still be treated properly by the inspect module. (Enum uses this since
///     Python 3.10 .)
///
///     """
///     def __init__(self, fget=None, fset=None, fdel=None, doc=None):
///         self.fget = fget
///         self.fset = fset
///         self.fdel = fdel
///         # next two lines make DynamicClassAttribute act the same as property
///         self.__doc__ = doc or fget.__doc__
///         self.overwrite_doc = doc is None
///         # support for abstract methods
///         self.__isabstractmethod__ = bool(getattr(fget, '__isabstractmethod__', False))
///
///     def __get__(self, instance, ownerclass=None):
///         if instance is None:
///             if self.__isabstractmethod__:
///                 return self
///             raise AttributeError()
///         elif self.fget is None:
///             raise AttributeError("unreadable attribute")
///         return self.fget(instance)
///
///     def __set__(self, instance, value):
///         if self.fset is None:
///             raise AttributeError("can't set attribute")
///         self.fset(instance, value)
///
///     def __delete__(self, instance):
///         if self.fdel is None:
///             raise AttributeError("can't delete attribute")
///         self.fdel(instance)
///
///     def getter(self, fget):
///         fdoc = fget.__doc__ if self.overwrite_doc else None
///         result = type(self)(fget, self.fset, self.fdel, fdoc or self.__doc__)
///         result.overwrite_doc = self.overwrite_doc
///         return result
///
///     def setter(self, fset):
///         result = type(self)(self.fget, fset, self.fdel, self.__doc__)
///         result.overwrite_doc = self.overwrite_doc
///         return result
///
///     def deleter(self, fdel):
///         result = type(self)(self.fget, self.fset, fdel, self.__doc__)
///         result.overwrite_doc = self.overwrite_doc
///         return result
///
///
/// class _GeneratorWrapper:
///     # TODO: Implement this in C.
///     def __init__(self, gen):
///         self.__wrapped = gen
///         self.__isgen = gen.__class__ is GeneratorType
///         self.__name__ = getattr(gen, '__name__', None)
///         self.__qualname__ = getattr(gen, '__qualname__', None)
///     def send(self, val):
///         return self.__wrapped.send(val)
///     def throw(self, tp, *rest):
///         return self.__wrapped.throw(tp, *rest)
///     def close(self):
///         return self.__wrapped.close()
///     @property
///     def gi_code(self):
///         return self.__wrapped.gi_code
///     @property
///     def gi_frame(self):
///         return self.__wrapped.gi_frame
///     @property
///     def gi_running(self):
///         return self.__wrapped.gi_running
///     @property
///     def gi_yieldfrom(self):
///         return self.__wrapped.gi_yieldfrom
///     cr_code = gi_code
///     cr_frame = gi_frame
///     cr_running = gi_running
///     cr_await = gi_yieldfrom
///     def __next__(self):
///         return next(self.__wrapped)
///     def __iter__(self):
///         if self.__isgen:
///             return self.__wrapped
///         return self
///     __await__ = __iter__
///
/// def coroutine(func):
///     """Convert regular generator function to a coroutine."""
///
///     if not callable(func):
///         raise TypeError('types.coroutine() expects a callable')
///
///     if (func.__class__ is FunctionType and
///         getattr(func, '__code__', None).__class__ is CodeType):
///
///         co_flags = func.__code__.co_flags
///
///         # Check if 'func' is a coroutine function.
///         # (0x180 == CO_COROUTINE | CO_ITERABLE_COROUTINE)
///         if co_flags & 0x180:
///             return func
///
///         # Check if 'func' is a generator function.
///         # (0x20 == CO_GENERATOR)
///         if co_flags & 0x20:
///             # TODO: Implement this in C.
///             co = func.__code__
///             # 0x100 == CO_ITERABLE_COROUTINE
///             func.__code__ = co.replace(co_flags=co.co_flags | 0x100)
///             return func
///
///     # The following code is primarily to support functions that
///     # return generator-like objects (for instance generators
///     # compiled with Cython).
///
///     # Delay functools and _collections_abc import for speeding up types import.
///     import functools
///     import _collections_abc
///     @functools.wraps(func)
///     def wrapped(*args, **kwargs):
///         coro = func(*args, **kwargs)
///         if (coro.__class__ is CoroutineType or
///             coro.__class__ is GeneratorType and coro.gi_code.co_flags & 0x100):
///             # 'coro' is a native coroutine object or an iterable coroutine
///             return coro
///         if (isinstance(coro, _collections_abc.Generator) and
///             not isinstance(coro, _collections_abc.Coroutine)):
///             # 'coro' is either a pure Python generator iterator, or it
///             # implements collections.abc.Generator (and does not implement
///             # collections.abc.Coroutine).
///             return _GeneratorWrapper(coro)
///         # 'coro' is either an instance of collections.abc.Coroutine or
///         # some other object -- pass it through.
///         return coro
///
///     return wrapped
///
/// GenericAlias = type(list[int])
/// UnionType = type(int | str)
///
/// EllipsisType = type(Ellipsis)
/// NoneType = type(None)
/// NotImplementedType = type(NotImplemented)
///
/// __all__ = [n for n in globals() if n[:1] != '_']
/// ```
final class types extends PythonModule {
  types.from(super.pythonModule) : super.from();

  static types import() => PythonFfiDart.instance.importModule(
        "types",
        types.from,
      );

  /// ## coroutine
  ///
  /// ### python docstring
  ///
  /// Convert regular generator function to a coroutine.
  ///
  /// ### python source
  /// ```py
  /// def coroutine(func):
  ///     """Convert regular generator function to a coroutine."""
  ///
  ///     if not callable(func):
  ///         raise TypeError('types.coroutine() expects a callable')
  ///
  ///     if (func.__class__ is FunctionType and
  ///         getattr(func, '__code__', None).__class__ is CodeType):
  ///
  ///         co_flags = func.__code__.co_flags
  ///
  ///         # Check if 'func' is a coroutine function.
  ///         # (0x180 == CO_COROUTINE | CO_ITERABLE_COROUTINE)
  ///         if co_flags & 0x180:
  ///             return func
  ///
  ///         # Check if 'func' is a generator function.
  ///         # (0x20 == CO_GENERATOR)
  ///         if co_flags & 0x20:
  ///             # TODO: Implement this in C.
  ///             co = func.__code__
  ///             # 0x100 == CO_ITERABLE_COROUTINE
  ///             func.__code__ = co.replace(co_flags=co.co_flags | 0x100)
  ///             return func
  ///
  ///     # The following code is primarily to support functions that
  ///     # return generator-like objects (for instance generators
  ///     # compiled with Cython).
  ///
  ///     # Delay functools and _collections_abc import for speeding up types import.
  ///     import functools
  ///     import _collections_abc
  ///     @functools.wraps(func)
  ///     def wrapped(*args, **kwargs):
  ///         coro = func(*args, **kwargs)
  ///         if (coro.__class__ is CoroutineType or
  ///             coro.__class__ is GeneratorType and coro.gi_code.co_flags & 0x100):
  ///             # 'coro' is a native coroutine object or an iterable coroutine
  ///             return coro
  ///         if (isinstance(coro, _collections_abc.Generator) and
  ///             not isinstance(coro, _collections_abc.Coroutine)):
  ///             # 'coro' is either a pure Python generator iterator, or it
  ///             # implements collections.abc.Generator (and does not implement
  ///             # collections.abc.Coroutine).
  ///             return _GeneratorWrapper(coro)
  ///         # 'coro' is either an instance of collections.abc.Coroutine or
  ///         # some other object -- pass it through.
  ///         return coro
  ///
  ///     return wrapped
  /// ```
  Object? coroutine({
    required Object? func,
  }) =>
      getFunction("coroutine").call(
        <Object?>[
          func,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## new_class
  ///
  /// ### python docstring
  ///
  /// Create a class object dynamically using the appropriate metaclass.
  ///
  /// ### python source
  /// ```py
  /// def new_class(name, bases=(), kwds=None, exec_body=None):
  ///     """Create a class object dynamically using the appropriate metaclass."""
  ///     resolved_bases = resolve_bases(bases)
  ///     meta, ns, kwds = prepare_class(name, resolved_bases, kwds)
  ///     if exec_body is not None:
  ///         exec_body(ns)
  ///     if resolved_bases is not bases:
  ///         ns['__orig_bases__'] = bases
  ///     return meta(name, resolved_bases, ns, **kwds)
  /// ```
  Object? new_class({
    required Object? name,
    Object? bases = const [],
    Object? kwds,
    Object? exec_body,
  }) =>
      getFunction("new_class").call(
        <Object?>[
          name,
          bases,
          kwds,
          exec_body,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## prepare_class
  ///
  /// ### python docstring
  ///
  /// Call the __prepare__ method of the appropriate metaclass.
  ///
  /// Returns (metaclass, namespace, kwds) as a 3-tuple
  ///
  /// *metaclass* is the appropriate metaclass
  /// *namespace* is the prepared class namespace
  /// *kwds* is an updated copy of the passed in kwds argument with any
  /// 'metaclass' entry removed. If no kwds argument is passed in, this will
  /// be an empty dict.
  ///
  /// ### python source
  /// ```py
  /// def prepare_class(name, bases=(), kwds=None):
  ///     """Call the __prepare__ method of the appropriate metaclass.
  ///
  ///     Returns (metaclass, namespace, kwds) as a 3-tuple
  ///
  ///     *metaclass* is the appropriate metaclass
  ///     *namespace* is the prepared class namespace
  ///     *kwds* is an updated copy of the passed in kwds argument with any
  ///     'metaclass' entry removed. If no kwds argument is passed in, this will
  ///     be an empty dict.
  ///     """
  ///     if kwds is None:
  ///         kwds = {}
  ///     else:
  ///         kwds = dict(kwds) # Don't alter the provided mapping
  ///     if 'metaclass' in kwds:
  ///         meta = kwds.pop('metaclass')
  ///     else:
  ///         if bases:
  ///             meta = type(bases[0])
  ///         else:
  ///             meta = type
  ///     if isinstance(meta, type):
  ///         # when meta is a type, we first determine the most-derived metaclass
  ///         # instead of invoking the initial candidate directly
  ///         meta = _calculate_meta(meta, bases)
  ///     if hasattr(meta, '__prepare__'):
  ///         ns = meta.__prepare__(name, bases, **kwds)
  ///     else:
  ///         ns = {}
  ///     return meta, ns, kwds
  /// ```
  Object? prepare_class({
    required Object? name,
    Object? bases = const [],
    Object? kwds,
  }) =>
      getFunction("prepare_class").call(
        <Object?>[
          name,
          bases,
          kwds,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## resolve_bases
  ///
  /// ### python docstring
  ///
  /// Resolve MRO entries dynamically as specified by PEP 560.
  ///
  /// ### python source
  /// ```py
  /// def resolve_bases(bases):
  ///     """Resolve MRO entries dynamically as specified by PEP 560."""
  ///     new_bases = list(bases)
  ///     updated = False
  ///     shift = 0
  ///     for i, base in enumerate(bases):
  ///         if isinstance(base, type):
  ///             continue
  ///         if not hasattr(base, "__mro_entries__"):
  ///             continue
  ///         new_base = base.__mro_entries__(bases)
  ///         updated = True
  ///         if not isinstance(new_base, tuple):
  ///             raise TypeError("__mro_entries__ must return a tuple")
  ///         else:
  ///             new_bases[i+shift:i+shift+1] = new_base
  ///             shift += len(new_base) - 1
  ///     if not updated:
  ///         return bases
  ///     return tuple(new_bases)
  /// ```
  Object? resolve_bases({
    required Object? bases,
  }) =>
      getFunction("resolve_bases").call(
        <Object?>[
          bases,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## lexer
///
/// ### python source
/// ```py
/// # Lexer Implementation
///
/// from abc import abstractmethod, ABC
/// import re
/// from contextlib import suppress
/// from typing import (
///     TypeVar, Type, List, Dict, Iterator, Collection, Callable, Optional, FrozenSet, Any,
///     Pattern as REPattern, ClassVar, TYPE_CHECKING, overload
/// )
/// from types import ModuleType
/// import warnings
/// if TYPE_CHECKING:
///     from .common import LexerConf
///
/// from .utils import classify, get_regexp_width, Serialize
/// from .exceptions import UnexpectedCharacters, LexError, UnexpectedToken
/// from .grammar import TOKEN_DEFAULT_PRIORITY
///
/// ###{standalone
/// from copy import copy
///
///
/// class Pattern(Serialize, ABC):
///
///     value: str
///     flags: Collection[str]
///     raw: Optional[str]
///     type: ClassVar[str]
///
///     def __init__(self, value: str, flags: Collection[str]=(), raw: Optional[str]=None) -> None:
///         self.value = value
///         self.flags = frozenset(flags)
///         self.raw = raw
///
///     def __repr__(self):
///         return repr(self.to_regexp())
///
///     # Pattern Hashing assumes all subclasses have a different priority!
///     def __hash__(self):
///         return hash((type(self), self.value, self.flags))
///
///     def __eq__(self, other):
///         return type(self) == type(other) and self.value == other.value and self.flags == other.flags
///
///     @abstractmethod
///     def to_regexp(self) -> str:
///         raise NotImplementedError()
///
///     @property
///     @abstractmethod
///     def min_width(self) -> int:
///         raise NotImplementedError()
///
///     @property
///     @abstractmethod
///     def max_width(self) -> int:
///         raise NotImplementedError()
///
///     def _get_flags(self, value):
///         for f in self.flags:
///             value = ('(?%s:%s)' % (f, value))
///         return value
///
///
/// class PatternStr(Pattern):
///     __serialize_fields__ = 'value', 'flags'
///
///     type: ClassVar[str] = "str"
///
///     def to_regexp(self) -> str:
///         return self._get_flags(re.escape(self.value))
///
///     @property
///     def min_width(self) -> int:
///         return len(self.value)
///
///     @property
///     def max_width(self) -> int:
///         return len(self.value)
///
///
/// class PatternRE(Pattern):
///     __serialize_fields__ = 'value', 'flags', '_width'
///
///     type: ClassVar[str] = "re"
///
///     def to_regexp(self) -> str:
///         return self._get_flags(self.value)
///
///     _width = None
///     def _get_width(self):
///         if self._width is None:
///             self._width = get_regexp_width(self.to_regexp())
///         return self._width
///
///     @property
///     def min_width(self) -> int:
///         return self._get_width()[0]
///
///     @property
///     def max_width(self) -> int:
///         return self._get_width()[1]
///
///
/// class TerminalDef(Serialize):
///     __serialize_fields__ = 'name', 'pattern', 'priority'
///     __serialize_namespace__ = PatternStr, PatternRE
///
///     name: str
///     pattern: Pattern
///     priority: int
///
///     def __init__(self, name: str, pattern: Pattern, priority: int=TOKEN_DEFAULT_PRIORITY) -> None:
///         assert isinstance(pattern, Pattern), pattern
///         self.name = name
///         self.pattern = pattern
///         self.priority = priority
///
///     def __repr__(self):
///         return '%s(%r, %r)' % (type(self).__name__, self.name, self.pattern)
///
///     def user_repr(self) -> str:
///         if self.name.startswith('__'): # We represent a generated terminal
///             return self.pattern.raw or self.name
///         else:
///             return self.name
///
/// _T = TypeVar('_T', bound="Token")
///
/// class Token(str):
///     """A string with meta-information, that is produced by the lexer.
///
///     When parsing text, the resulting chunks of the input that haven't been discarded,
///     will end up in the tree as Token instances. The Token class inherits from Python's ``str``,
///     so normal string comparisons and operations will work as expected.
///
///     Attributes:
///         type: Name of the token (as specified in grammar)
///         value: Value of the token (redundant, as ``token.value == token`` will always be true)
///         start_pos: The index of the token in the text
///         line: The line of the token in the text (starting with 1)
///         column: The column of the token in the text (starting with 1)
///         end_line: The line where the token ends
///         end_column: The next column after the end of the token. For example,
///             if the token is a single character with a column value of 4,
///             end_column will be 5.
///         end_pos: the index where the token ends (basically ``start_pos + len(token)``)
///     """
///     __slots__ = ('type', 'start_pos', 'value', 'line', 'column', 'end_line', 'end_column', 'end_pos')
///
///     __match_args__ = ('type', 'value')
///
///     type: str
///     start_pos: Optional[int]
///     value: Any
///     line: Optional[int]
///     column: Optional[int]
///     end_line: Optional[int]
///     end_column: Optional[int]
///     end_pos: Optional[int]
///
///
///     @overload
///     def __new__(
///         cls,
///         type: str,
///         value: Any,
///         start_pos: Optional[int]=None,
///         line: Optional[int]=None,
///         column: Optional[int]=None,
///         end_line: Optional[int]=None,
///         end_column: Optional[int]=None,
///         end_pos: Optional[int]=None
///     ) -> 'Token':
///         ...
///
///     @overload
///     def __new__(
///         cls,
///         type_: str,
///         value: Any,
///         start_pos: Optional[int]=None,
///         line: Optional[int]=None,
///         column: Optional[int]=None,
///         end_line: Optional[int]=None,
///         end_column: Optional[int]=None,
///         end_pos: Optional[int]=None
///     ) -> 'Token':        ...
///
///     def __new__(cls, *args, **kwargs):
///         if "type_" in kwargs:
///             warnings.warn("`type_` is deprecated use `type` instead", DeprecationWarning)
///
///             if "type" in kwargs:
///                 raise TypeError("Error: using both 'type' and the deprecated 'type_' as arguments.")
///             kwargs["type"] = kwargs.pop("type_")
///
///         return cls._future_new(*args, **kwargs)
///
///
///     @classmethod
///     def _future_new(cls, type, value, start_pos=None, line=None, column=None, end_line=None, end_column=None, end_pos=None):
///         inst = super(Token, cls).__new__(cls, value)
///
///         inst.type = type
///         inst.start_pos = start_pos
///         inst.value = value
///         inst.line = line
///         inst.column = column
///         inst.end_line = end_line
///         inst.end_column = end_column
///         inst.end_pos = end_pos
///         return inst
///
///     @overload
///     def update(self, type: Optional[str]=None, value: Optional[Any]=None) -> 'Token':
///         ...
///
///     @overload
///     def update(self, type_: Optional[str]=None, value: Optional[Any]=None) -> 'Token':
///         ...
///
///     def update(self, *args, **kwargs):
///         if "type_" in kwargs:
///             warnings.warn("`type_` is deprecated use `type` instead", DeprecationWarning)
///
///             if "type" in kwargs:
///                 raise TypeError("Error: using both 'type' and the deprecated 'type_' as arguments.")
///             kwargs["type"] = kwargs.pop("type_")
///
///         return self._future_update(*args, **kwargs)
///
///     def _future_update(self, type: Optional[str]=None, value: Optional[Any]=None) -> 'Token':
///         return Token.new_borrow_pos(
///             type if type is not None else self.type,
///             value if value is not None else self.value,
///             self
///         )
///
///     @classmethod
///     def new_borrow_pos(cls: Type[_T], type_: str, value: Any, borrow_t: 'Token') -> _T:
///         return cls(type_, value, borrow_t.start_pos, borrow_t.line, borrow_t.column, borrow_t.end_line, borrow_t.end_column, borrow_t.end_pos)
///
///     def __reduce__(self):
///         return (self.__class__, (self.type, self.value, self.start_pos, self.line, self.column))
///
///     def __repr__(self):
///         return 'Token(%r, %r)' % (self.type, self.value)
///
///     def __deepcopy__(self, memo):
///         return Token(self.type, self.value, self.start_pos, self.line, self.column)
///
///     def __eq__(self, other):
///         if isinstance(other, Token) and self.type != other.type:
///             return False
///
///         return str.__eq__(self, other)
///
///     __hash__ = str.__hash__
///
///
/// class LineCounter:
///     __slots__ = 'char_pos', 'line', 'column', 'line_start_pos', 'newline_char'
///
///     def __init__(self, newline_char):
///         self.newline_char = newline_char
///         self.char_pos = 0
///         self.line = 1
///         self.column = 1
///         self.line_start_pos = 0
///
///     def __eq__(self, other):
///         if not isinstance(other, LineCounter):
///             return NotImplemented
///
///         return self.char_pos == other.char_pos and self.newline_char == other.newline_char
///
///     def feed(self, token: Token, test_newline=True):
///         """Consume a token and calculate the new line & column.
///
///         As an optional optimization, set test_newline=False if token doesn't contain a newline.
///         """
///         if test_newline:
///             newlines = token.count(self.newline_char)
///             if newlines:
///                 self.line += newlines
///                 self.line_start_pos = self.char_pos + token.rindex(self.newline_char) + 1
///
///         self.char_pos += len(token)
///         self.column = self.char_pos - self.line_start_pos + 1
///
///
/// class UnlessCallback:
///     def __init__(self, scanner):
///         self.scanner = scanner
///
///     def __call__(self, t):
///         res = self.scanner.match(t.value, 0)
///         if res:
///             _value, t.type = res
///         return t
///
///
/// class CallChain:
///     def __init__(self, callback1, callback2, cond):
///         self.callback1 = callback1
///         self.callback2 = callback2
///         self.cond = cond
///
///     def __call__(self, t):
///         t2 = self.callback1(t)
///         return self.callback2(t) if self.cond(t2) else t2
///
///
/// def _get_match(re_, regexp, s, flags):
///     m = re_.match(regexp, s, flags)
///     if m:
///         return m.group(0)
///
/// def _create_unless(terminals, g_regex_flags, re_, use_bytes):
///     tokens_by_type = classify(terminals, lambda t: type(t.pattern))
///     assert len(tokens_by_type) <= 2, tokens_by_type.keys()
///     embedded_strs = set()
///     callback = {}
///     for retok in tokens_by_type.get(PatternRE, []):
///         unless = []
///         for strtok in tokens_by_type.get(PatternStr, []):
///             if strtok.priority != retok.priority:
///                 continue
///             s = strtok.pattern.value
///             if s == _get_match(re_, retok.pattern.to_regexp(), s, g_regex_flags):
///                 unless.append(strtok)
///                 if strtok.pattern.flags <= retok.pattern.flags:
///                     embedded_strs.add(strtok)
///         if unless:
///             callback[retok.name] = UnlessCallback(Scanner(unless, g_regex_flags, re_, match_whole=True, use_bytes=use_bytes))
///
///     new_terminals = [t for t in terminals if t not in embedded_strs]
///     return new_terminals, callback
///
///
/// class Scanner:
///     def __init__(self, terminals, g_regex_flags, re_, use_bytes, match_whole=False):
///         self.terminals = terminals
///         self.g_regex_flags = g_regex_flags
///         self.re_ = re_
///         self.use_bytes = use_bytes
///         self.match_whole = match_whole
///
///         self.allowed_types = {t.name for t in self.terminals}
///
///         self._mres = self._build_mres(terminals, len(terminals))
///
///     def _build_mres(self, terminals, max_size):
///         # Python sets an unreasonable group limit (currently 100) in its re module
///         # Worse, the only way to know we reached it is by catching an AssertionError!
///         # This function recursively tries less and less groups until it's successful.
///         postfix = '$' if self.match_whole else ''
///         mres = []
///         while terminals:
///             pattern = u'|'.join(u'(?P<%s>%s)' % (t.name, t.pattern.to_regexp() + postfix) for t in terminals[:max_size])
///             if self.use_bytes:
///                 pattern = pattern.encode('latin-1')
///             try:
///                 mre = self.re_.compile(pattern, self.g_regex_flags)
///             except AssertionError:  # Yes, this is what Python provides us.. :/
///                 return self._build_mres(terminals, max_size//2)
///
///             mres.append(mre)
///             terminals = terminals[max_size:]
///         return mres
///
///     def match(self, text, pos):
///         for mre in self._mres:
///             m = mre.match(text, pos)
///             if m:
///                 return m.group(0), m.lastgroup
///
///
/// def _regexp_has_newline(r: str):
///     r"""Expressions that may indicate newlines in a regexp:
///         - newlines (\n)
///         - escaped newline (\\n)
///         - anything but ([^...])
///         - any-char (.) when the flag (?s) exists
///         - spaces (\s)
///     """
///     return '\n' in r or '\\n' in r or '\\s' in r or '[^' in r or ('(?s' in r and '.' in r)
///
///
/// class LexerState:
///     """Represents the current state of the lexer as it scans the text
///     (Lexer objects are only instanciated per grammar, not per text)
///     """
///
///     __slots__ = 'text', 'line_ctr', 'last_token'
///
///     def __init__(self, text, line_ctr=None, last_token=None):
///         self.text = text
///         self.line_ctr = line_ctr or LineCounter(b'\n' if isinstance(text, bytes) else '\n')
///         self.last_token = last_token
///
///     def __eq__(self, other):
///         if not isinstance(other, LexerState):
///             return NotImplemented
///
///         return self.text is other.text and self.line_ctr == other.line_ctr and self.last_token == other.last_token
///
///     def __copy__(self):
///         return type(self)(self.text, copy(self.line_ctr), self.last_token)
///
///
/// class LexerThread:
///     """A thread that ties a lexer instance and a lexer state, to be used by the parser
///     """
///
///     def __init__(self, lexer: 'Lexer', lexer_state: LexerState):
///         self.lexer = lexer
///         self.state = lexer_state
///
///     @classmethod
///     def from_text(cls, lexer: 'Lexer', text: str):
///         return cls(lexer, LexerState(text))
///
///     def lex(self, parser_state):
///         return self.lexer.lex(self.state, parser_state)
///
///     def __copy__(self):
///         return type(self)(self.lexer, copy(self.state))
///
///     _Token = Token
///
///
/// _Callback = Callable[[Token], Token]
///
/// class Lexer(ABC):
///     """Lexer interface
///
///     Method Signatures:
///         lex(self, lexer_state, parser_state) -> Iterator[Token]
///     """
///     @abstractmethod
///     def lex(self, lexer_state: LexerState, parser_state: Any) -> Iterator[Token]:
///         return NotImplemented
///
///     def make_lexer_state(self, text):
///         "Deprecated"
///         return LexerState(text)
///
///
/// class BasicLexer(Lexer):
///
///     terminals: Collection[TerminalDef]
///     ignore_types: FrozenSet[str]
///     newline_types: FrozenSet[str]
///     user_callbacks: Dict[str, _Callback]
///     callback: Dict[str, _Callback]
///     re: ModuleType
///
///     def __init__(self, conf: 'LexerConf') -> None:
///         terminals = list(conf.terminals)
///         assert all(isinstance(t, TerminalDef) for t in terminals), terminals
///
///         self.re = conf.re_module
///
///         if not conf.skip_validation:
///             # Sanitization
///             for t in terminals:
///                 try:
///                     self.re.compile(t.pattern.to_regexp(), conf.g_regex_flags)
///                 except self.re.error:
///                     raise LexError("Cannot compile token %s: %s" % (t.name, t.pattern))
///
///                 if t.pattern.min_width == 0:
///                     raise LexError("Lexer does not allow zero-width terminals. (%s: %s)" % (t.name, t.pattern))
///
///             if not (set(conf.ignore) <= {t.name for t in terminals}):
///                 raise LexError("Ignore terminals are not defined: %s" % (set(conf.ignore) - {t.name for t in terminals}))
///
///         # Init
///         self.newline_types = frozenset(t.name for t in terminals if _regexp_has_newline(t.pattern.to_regexp()))
///         self.ignore_types = frozenset(conf.ignore)
///
///         terminals.sort(key=lambda x: (-x.priority, -x.pattern.max_width, -len(x.pattern.value), x.name))
///         self.terminals = terminals
///         self.user_callbacks = conf.callbacks
///         self.g_regex_flags = conf.g_regex_flags
///         self.use_bytes = conf.use_bytes
///         self.terminals_by_name = conf.terminals_by_name
///
///         self._scanner = None
///
///     def _build_scanner(self):
///         terminals, self.callback = _create_unless(self.terminals, self.g_regex_flags, self.re, self.use_bytes)
///         assert all(self.callback.values())
///
///         for type_, f in self.user_callbacks.items():
///             if type_ in self.callback:
///                 # Already a callback there, probably UnlessCallback
///                 self.callback[type_] = CallChain(self.callback[type_], f, lambda t: t.type == type_)
///             else:
///                 self.callback[type_] = f
///
///         self._scanner = Scanner(terminals, self.g_regex_flags, self.re, self.use_bytes)
///
///     @property
///     def scanner(self):
///         if self._scanner is None:
///             self._build_scanner()
///         return self._scanner
///
///     def match(self, text, pos):
///         return self.scanner.match(text, pos)
///
///     def lex(self, state: LexerState, parser_state: Any) -> Iterator[Token]:
///         with suppress(EOFError):
///             while True:
///                 yield self.next_token(state, parser_state)
///
///     def next_token(self, lex_state: LexerState, parser_state: Any=None) -> Token:
///         line_ctr = lex_state.line_ctr
///         while line_ctr.char_pos < len(lex_state.text):
///             res = self.match(lex_state.text, line_ctr.char_pos)
///             if not res:
///                 allowed = self.scanner.allowed_types - self.ignore_types
///                 if not allowed:
///                     allowed = {"<END-OF-FILE>"}
///                 raise UnexpectedCharacters(lex_state.text, line_ctr.char_pos, line_ctr.line, line_ctr.column,
///                                            allowed=allowed, token_history=lex_state.last_token and [lex_state.last_token],
///                                            state=parser_state, terminals_by_name=self.terminals_by_name)
///
///             value, type_ = res
///
///             if type_ not in self.ignore_types:
///                 t = Token(type_, value, line_ctr.char_pos, line_ctr.line, line_ctr.column)
///                 line_ctr.feed(value, type_ in self.newline_types)
///                 t.end_line = line_ctr.line
///                 t.end_column = line_ctr.column
///                 t.end_pos = line_ctr.char_pos
///                 if t.type in self.callback:
///                     t = self.callback[t.type](t)
///                     if not isinstance(t, Token):
///                         raise LexError("Callbacks must return a token (returned %r)" % t)
///                 lex_state.last_token = t
///                 return t
///             else:
///                 if type_ in self.callback:
///                     t2 = Token(type_, value, line_ctr.char_pos, line_ctr.line, line_ctr.column)
///                     self.callback[type_](t2)
///                 line_ctr.feed(value, type_ in self.newline_types)
///
///         # EOF
///         raise EOFError(self)
///
///
/// class ContextualLexer(Lexer):
///
///     lexers: Dict[str, BasicLexer]
///     root_lexer: BasicLexer
///
///     def __init__(self, conf: 'LexerConf', states: Dict[str, Collection[str]], always_accept: Collection[str]=()) -> None:
///         terminals = list(conf.terminals)
///         terminals_by_name = conf.terminals_by_name
///
///         trad_conf = copy(conf)
///         trad_conf.terminals = terminals
///
///         lexer_by_tokens: Dict[FrozenSet[str], BasicLexer] = {}
///         self.lexers = {}
///         for state, accepts in states.items():
///             key = frozenset(accepts)
///             try:
///                 lexer = lexer_by_tokens[key]
///             except KeyError:
///                 accepts = set(accepts) | set(conf.ignore) | set(always_accept)
///                 lexer_conf = copy(trad_conf)
///                 lexer_conf.terminals = [terminals_by_name[n] for n in accepts if n in terminals_by_name]
///                 lexer = BasicLexer(lexer_conf)
///                 lexer_by_tokens[key] = lexer
///
///             self.lexers[state] = lexer
///
///         assert trad_conf.terminals is terminals
///         self.root_lexer = BasicLexer(trad_conf)
///
///     def lex(self, lexer_state: LexerState, parser_state: Any) -> Iterator[Token]:
///         try:
///             while True:
///                 lexer = self.lexers[parser_state.position]
///                 yield lexer.next_token(lexer_state, parser_state)
///         except EOFError:
///             pass
///         except UnexpectedCharacters as e:
///             # In the contextual lexer, UnexpectedCharacters can mean that the terminal is defined, but not in the current context.
///             # This tests the input against the global context, to provide a nicer error.
///             try:
///                 last_token = lexer_state.last_token  # Save last_token. Calling root_lexer.next_token will change this to the wrong token
///                 token = self.root_lexer.next_token(lexer_state, parser_state)
///                 raise UnexpectedToken(token, e.allowed, state=parser_state, token_history=[last_token], terminals_by_name=self.root_lexer.terminals_by_name)
///             except UnexpectedCharacters:
///                 raise e  # Raise the original UnexpectedCharacters. The root lexer raises it with the wrong expected set.
///
/// ###}
/// ```
final class lexer extends PythonModule {
  lexer.from(super.pythonModule) : super.from();

  static lexer import() => PythonFfiDart.instance.importModule(
        "lark.lexer",
        lexer.from,
      );

  /// ## TOKEN_DEFAULT_PRIORITY (getter)
  Object? get TOKEN_DEFAULT_PRIORITY => getAttribute("TOKEN_DEFAULT_PRIORITY");

  /// ## TOKEN_DEFAULT_PRIORITY (setter)
  set TOKEN_DEFAULT_PRIORITY(Object? TOKEN_DEFAULT_PRIORITY) =>
      setAttribute("TOKEN_DEFAULT_PRIORITY", TOKEN_DEFAULT_PRIORITY);

  /// ## TYPE_CHECKING (getter)
  Object? get TYPE_CHECKING => getAttribute("TYPE_CHECKING");

  /// ## TYPE_CHECKING (setter)
  set TYPE_CHECKING(Object? TYPE_CHECKING) =>
      setAttribute("TYPE_CHECKING", TYPE_CHECKING);
}

/// ## load_grammar
///
/// ### python docstring
///
/// Parses and creates Grammar objects
///
/// ### python source
/// ```py
/// """Parses and creates Grammar objects"""
/// import hashlib
/// import os.path
/// import sys
/// from collections import namedtuple
/// from copy import copy, deepcopy
/// import pkgutil
/// from ast import literal_eval
/// from contextlib import suppress
/// from typing import List, Tuple, Union, Callable, Dict, Optional, Sequence
///
/// from .utils import bfs, logger, classify_bool, is_id_continue, is_id_start, bfs_all_unique, small_factors
/// from .lexer import Token, TerminalDef, PatternStr, PatternRE
///
/// from .parse_tree_builder import ParseTreeBuilder
/// from .parser_frontends import ParsingFrontend
/// from .common import LexerConf, ParserConf
/// from .grammar import RuleOptions, Rule, Terminal, NonTerminal, Symbol, TOKEN_DEFAULT_PRIORITY
/// from .utils import classify, dedup_list
/// from .exceptions import GrammarError, UnexpectedCharacters, UnexpectedToken, ParseError, UnexpectedInput
///
/// from .tree import Tree, SlottedTree as ST
/// from .visitors import Transformer, Visitor, v_args, Transformer_InPlace, Transformer_NonRecursive
/// inline_args = v_args(inline=True)
///
/// __path__ = os.path.dirname(__file__)
/// IMPORT_PATHS = ['grammars']
///
/// EXT = '.lark'
///
/// _RE_FLAGS = 'imslux'
///
/// _EMPTY = Symbol('__empty__')
///
/// _TERMINAL_NAMES = {
///     '.' : 'DOT',
///     ',' : 'COMMA',
///     ':' : 'COLON',
///     ';' : 'SEMICOLON',
///     '+' : 'PLUS',
///     '-' : 'MINUS',
///     '*' : 'STAR',
///     '/' : 'SLASH',
///     '\\' : 'BACKSLASH',
///     '|' : 'VBAR',
///     '?' : 'QMARK',
///     '!' : 'BANG',
///     '@' : 'AT',
///     '#' : 'HASH',
///     '$' : 'DOLLAR',
///     '%' : 'PERCENT',
///     '^' : 'CIRCUMFLEX',
///     '&' : 'AMPERSAND',
///     '_' : 'UNDERSCORE',
///     '<' : 'LESSTHAN',
///     '>' : 'MORETHAN',
///     '=' : 'EQUAL',
///     '"' : 'DBLQUOTE',
///     '\'' : 'QUOTE',
///     '`' : 'BACKQUOTE',
///     '~' : 'TILDE',
///     '(' : 'LPAR',
///     ')' : 'RPAR',
///     '{' : 'LBRACE',
///     '}' : 'RBRACE',
///     '[' : 'LSQB',
///     ']' : 'RSQB',
///     '\n' : 'NEWLINE',
///     '\r\n' : 'CRLF',
///     '\t' : 'TAB',
///     ' ' : 'SPACE',
/// }
///
/// # Grammar Parser
/// TERMINALS = {
///     '_LPAR': r'\(',
///     '_RPAR': r'\)',
///     '_LBRA': r'\[',
///     '_RBRA': r'\]',
///     '_LBRACE': r'\{',
///     '_RBRACE': r'\}',
///     'OP': '[+*]|[?](?![a-z])',
///     '_COLON': ':',
///     '_COMMA': ',',
///     '_OR': r'\|',
///     '_DOT': r'\.(?!\.)',
///     '_DOTDOT': r'\.\.',
///     'TILDE': '~',
///     'RULE_MODIFIERS': '(!|![?]?|[?]!?)(?=[_a-z])',
///     'RULE': '_?[a-z][_a-z0-9]*',
///     'TERMINAL': '_?[A-Z][_A-Z0-9]*',
///     'STRING': r'"(\\"|\\\\|[^"\n])*?"i?',
///     'REGEXP': r'/(?!/)(\\/|\\\\|[^/])*?/[%s]*' % _RE_FLAGS,
///     '_NL': r'(\r?\n)+\s*',
///     '_NL_OR': r'(\r?\n)+\s*\|',
///     'WS': r'[ \t]+',
///     'COMMENT': r'\s*//[^\n]*',
///     'BACKSLASH': r'\\[ ]*\n',
///     '_TO': '->',
///     '_IGNORE': r'%ignore',
///     '_OVERRIDE': r'%override',
///     '_DECLARE': r'%declare',
///     '_EXTEND': r'%extend',
///     '_IMPORT': r'%import',
///     'NUMBER': r'[+-]?\d+',
/// }
///
/// RULES = {
///     'start': ['_list'],
///     '_list':  ['_item', '_list _item'],
///     '_item':  ['rule', 'term', 'ignore', 'import', 'declare', 'override', 'extend', '_NL'],
///
///     'rule': ['rule_modifiers RULE template_params priority _COLON expansions _NL'],
///     'rule_modifiers': ['RULE_MODIFIERS',
///                        ''],
///     'priority': ['_DOT NUMBER',
///                  ''],
///     'template_params': ['_LBRACE _template_params _RBRACE',
///                         ''],
///     '_template_params': ['RULE',
///                          '_template_params _COMMA RULE'],
///     'expansions': ['_expansions'],
///     '_expansions': ['alias',
///                     '_expansions _OR alias',
///                     '_expansions _NL_OR alias'],
///
///     '?alias':     ['expansion _TO nonterminal', 'expansion'],
///     'expansion': ['_expansion'],
///
///     '_expansion': ['', '_expansion expr'],
///
///     '?expr': ['atom',
///               'atom OP',
///               'atom TILDE NUMBER',
///               'atom TILDE NUMBER _DOTDOT NUMBER',
///               ],
///
///     '?atom': ['_LPAR expansions _RPAR',
///               'maybe',
///               'value'],
///
///     'value': ['terminal',
///               'nonterminal',
///               'literal',
///               'range',
///               'template_usage'],
///
///     'terminal': ['TERMINAL'],
///     'nonterminal': ['RULE'],
///
///     '?name': ['RULE', 'TERMINAL'],
///     '?symbol': ['terminal', 'nonterminal'],
///
///     'maybe': ['_LBRA expansions _RBRA'],
///     'range': ['STRING _DOTDOT STRING'],
///
///     'template_usage': ['nonterminal _LBRACE _template_args _RBRACE'],
///     '_template_args': ['value',
///                        '_template_args _COMMA value'],
///
///     'term': ['TERMINAL _COLON expansions _NL',
///              'TERMINAL _DOT NUMBER _COLON expansions _NL'],
///     'override': ['_OVERRIDE rule',
///                  '_OVERRIDE term'],
///     'extend': ['_EXTEND rule',
///                '_EXTEND term'],
///     'ignore': ['_IGNORE expansions _NL'],
///     'declare': ['_DECLARE _declare_args _NL'],
///     'import': ['_IMPORT _import_path _NL',
///                '_IMPORT _import_path _LPAR name_list _RPAR _NL',
///                '_IMPORT _import_path _TO name _NL'],
///
///     '_import_path': ['import_lib', 'import_rel'],
///     'import_lib': ['_import_args'],
///     'import_rel': ['_DOT _import_args'],
///     '_import_args': ['name', '_import_args _DOT name'],
///
///     'name_list': ['_name_list'],
///     '_name_list': ['name', '_name_list _COMMA name'],
///
///     '_declare_args': ['symbol', '_declare_args symbol'],
///     'literal': ['REGEXP', 'STRING'],
/// }
///
///
/// # Value 5 keeps the number of states in the lalr parser somewhat minimal
/// # It isn't optimal, but close to it. See PR #949
/// SMALL_FACTOR_THRESHOLD = 5
/// # The Threshold whether repeat via ~ are split up into different rules
/// # 50 is chosen since it keeps the number of states low and therefore lalr analysis time low,
/// # while not being to overaggressive and unnecessarily creating rules that might create shift/reduce conflicts.
/// # (See PR #949)
/// REPEAT_BREAK_THRESHOLD = 50
///
///
/// class FindRuleSize(Transformer):
///     def __init__(self, keep_all_tokens):
///         self.keep_all_tokens = keep_all_tokens
///
///     def _will_not_get_removed(self, sym):
///         if isinstance(sym, NonTerminal):
///             return not sym.name.startswith('_')
///         if isinstance(sym, Terminal):
///             return self.keep_all_tokens or not sym.filter_out
///         if sym is _EMPTY:
///             return False
///         assert False, sym
///
///     def _args_as_int(self, args):
///         for a in args:
///             if isinstance(a, int):
///                 yield a
///             elif isinstance(a, Symbol):
///                 yield 1 if self._will_not_get_removed(a) else 0
///             else:
///                 assert False
///
///     def expansion(self, args):
///         return sum(self._args_as_int(args))
///
///     def expansions(self, args):
///         return max(self._args_as_int(args))
///
///
/// @inline_args
/// class EBNF_to_BNF(Transformer_InPlace):
///     def __init__(self):
///         self.new_rules = []
///         self.rules_cache = {}
///         self.prefix = 'anon'
///         self.i = 0
///         self.rule_options = None
///
///     def _name_rule(self, inner):
///         new_name = '__%s_%s_%d' % (self.prefix, inner, self.i)
///         self.i += 1
///         return new_name
///
///     def _add_rule(self, key, name, expansions):
///         t = NonTerminal(name)
///         self.new_rules.append((name, expansions, self.rule_options))
///         self.rules_cache[key] = t
///         return t
///
///     def _add_recurse_rule(self, type_, expr):
///         try:
///             return self.rules_cache[expr]
///         except KeyError:
///             new_name = self._name_rule(type_)
///             t = NonTerminal(new_name)
///             tree = ST('expansions', [
///                 ST('expansion', [expr]),
///                 ST('expansion', [t, expr])
///             ])
///             return self._add_rule(expr, new_name, tree)
///
///     def _add_repeat_rule(self, a, b, target, atom):
///         """Generate a rule that repeats target ``a`` times, and repeats atom ``b`` times.
///
///         When called recursively (into target), it repeats atom for x(n) times, where:
///             x(0) = 1
///             x(n) = a(n) * x(n-1) + b
///
///         Example rule when a=3, b=4:
///
///             new_rule: target target target atom atom atom atom
///
///         """
///         key = (a, b, target, atom)
///         try:
///             return self.rules_cache[key]
///         except KeyError:
///             new_name = self._name_rule('repeat_a%d_b%d' % (a, b))
///             tree = ST('expansions', [ST('expansion', [target] * a + [atom] * b)])
///             return self._add_rule(key, new_name, tree)
///
///     def _add_repeat_opt_rule(self, a, b, target, target_opt, atom):
///         """Creates a rule that matches atom 0 to (a*n+b)-1 times.
///
///         When target matches n times atom, and target_opt 0 to n-1 times target_opt,
///
///         First we generate target * i followed by target_opt, for i from 0 to a-1
///         These match 0 to n*a - 1 times atom
///
///         Then we generate target * a followed by atom * i, for i from 0 to b-1
///         These match n*a to n*a + b-1 times atom
///
///         The created rule will not have any shift/reduce conflicts so that it can be used with lalr
///
///         Example rule when a=3, b=4:
///
///             new_rule: target_opt
///                     | target target_opt
///                     | target target target_opt
///
///                     | target target target
///                     | target target target atom
///                     | target target target atom atom
///                     | target target target atom atom atom
///
///         """
///         key = (a, b, target, atom, "opt")
///         try:
///             return self.rules_cache[key]
///         except KeyError:
///             new_name = self._name_rule('repeat_a%d_b%d_opt' % (a, b))
///             tree = ST('expansions', [
///                 ST('expansion', [target]*i + [target_opt]) for i in range(a)
///             ] + [
///                 ST('expansion', [target]*a + [atom]*i) for i in range(b)
///             ])
///             return self._add_rule(key, new_name, tree)
///
///     def _generate_repeats(self, rule, mn, mx):
///         """Generates a rule tree that repeats ``rule`` exactly between ``mn`` to ``mx`` times.
///         """
///         # For a small number of repeats, we can take the naive approach
///         if mx < REPEAT_BREAK_THRESHOLD:
///             return ST('expansions', [ST('expansion', [rule] * n) for n in range(mn, mx + 1)])
///
///         # For large repeat values, we break the repetition into sub-rules.
///         # We treat ``rule~mn..mx`` as ``rule~mn rule~0..(diff=mx-mn)``.
///         # We then use small_factors to split up mn and diff up into values [(a, b), ...]
///         # This values are used with the help of _add_repeat_rule and _add_repeat_rule_opt
///         # to generate a complete rule/expression that matches the corresponding number of repeats
///         mn_target = rule
///         for a, b in small_factors(mn, SMALL_FACTOR_THRESHOLD):
///             mn_target = self._add_repeat_rule(a, b, mn_target, rule)
///         if mx == mn:
///             return mn_target
///
///         diff = mx - mn + 1  # We add one because _add_repeat_opt_rule generates rules that match one less
///         diff_factors = small_factors(diff, SMALL_FACTOR_THRESHOLD)
///         diff_target = rule  # Match rule 1 times
///         diff_opt_target = ST('expansion', [])  # match rule 0 times (e.g. up to 1 -1 times)
///         for a, b in diff_factors[:-1]:
///             diff_opt_target = self._add_repeat_opt_rule(a, b, diff_target, diff_opt_target, rule)
///             diff_target = self._add_repeat_rule(a, b, diff_target, rule)
///
///         a, b = diff_factors[-1]
///         diff_opt_target = self._add_repeat_opt_rule(a, b, diff_target, diff_opt_target, rule)
///
///         return ST('expansions', [ST('expansion', [mn_target] + [diff_opt_target])])
///
///     def expr(self, rule, op, *args):
///         if op.value == '?':
///             empty = ST('expansion', [])
///             return ST('expansions', [rule, empty])
///         elif op.value == '+':
///             # a : b c+ d
///             #   -->
///             # a : b _c d
///             # _c : _c c | c;
///             return self._add_recurse_rule('plus', rule)
///         elif op.value == '*':
///             # a : b c* d
///             #   -->
///             # a : b _c? d
///             # _c : _c c | c;
///             new_name = self._add_recurse_rule('star', rule)
///             return ST('expansions', [new_name, ST('expansion', [])])
///         elif op.value == '~':
///             if len(args) == 1:
///                 mn = mx = int(args[0])
///             else:
///                 mn, mx = map(int, args)
///                 if mx < mn or mn < 0:
///                     raise GrammarError("Bad Range for %s (%d..%d isn't allowed)" % (rule, mn, mx))
///
///             return self._generate_repeats(rule, mn, mx)
///
///         assert False, op
///
///     def maybe(self, rule):
///         keep_all_tokens = self.rule_options and self.rule_options.keep_all_tokens
///         rule_size = FindRuleSize(keep_all_tokens).transform(rule)
///         empty = ST('expansion', [_EMPTY] * rule_size)
///         return ST('expansions', [rule, empty])
///
///
/// class SimplifyRule_Visitor(Visitor):
///
///     @staticmethod
///     def _flatten(tree):
///         while tree.expand_kids_by_data(tree.data):
///             pass
///
///     def expansion(self, tree):
///         # rules_list unpacking
///         # a : b (c|d) e
///         #  -->
///         # a : b c e | b d e
///         #
///         # In AST terms:
///         # expansion(b, expansions(c, d), e)
///         #   -->
///         # expansions( expansion(b, c, e), expansion(b, d, e) )
///
///         self._flatten(tree)
///
///         for i, child in enumerate(tree.children):
///             if isinstance(child, Tree) and child.data == 'expansions':
///                 tree.data = 'expansions'
///                 tree.children = [self.visit(ST('expansion', [option if i == j else other
///                                                              for j, other in enumerate(tree.children)]))
///                                  for option in dedup_list(child.children)]
///                 self._flatten(tree)
///                 break
///
///     def alias(self, tree):
///         rule, alias_name = tree.children
///         if rule.data == 'expansions':
///             aliases = []
///             for child in tree.children[0].children:
///                 aliases.append(ST('alias', [child, alias_name]))
///             tree.data = 'expansions'
///             tree.children = aliases
///
///     def expansions(self, tree):
///         self._flatten(tree)
///         # Ensure all children are unique
///         if len(set(tree.children)) != len(tree.children):
///             tree.children = dedup_list(tree.children)   # dedup is expensive, so try to minimize its use
///
///
/// class RuleTreeToText(Transformer):
///     def expansions(self, x):
///         return x
///
///     def expansion(self, symbols):
///         return symbols, None
///
///     def alias(self, x):
///         (expansion, _alias), alias = x
///         assert _alias is None, (alias, expansion, '-', _alias)  # Double alias not allowed
///         return expansion, alias.name
///
///
/// class PrepareAnonTerminals(Transformer_InPlace):
///     """Create a unique list of anonymous terminals. Attempt to give meaningful names to them when we add them"""
///
///     def __init__(self, terminals):
///         self.terminals = terminals
///         self.term_set = {td.name for td in self.terminals}
///         self.term_reverse = {td.pattern: td for td in terminals}
///         self.i = 0
///         self.rule_options = None
///
///     @inline_args
///     def pattern(self, p):
///         value = p.value
///         if p in self.term_reverse and p.flags != self.term_reverse[p].pattern.flags:
///             raise GrammarError(u'Conflicting flags for the same terminal: %s' % p)
///
///         term_name = None
///
///         if isinstance(p, PatternStr):
///             try:
///                 # If already defined, use the user-defined terminal name
///                 term_name = self.term_reverse[p].name
///             except KeyError:
///                 # Try to assign an indicative anon-terminal name
///                 try:
///                     term_name = _TERMINAL_NAMES[value]
///                 except KeyError:
///                     if value and is_id_continue(value) and is_id_start(value[0]) and value.upper() not in self.term_set:
///                         term_name = value.upper()
///
///                 if term_name in self.term_set:
///                     term_name = None
///
///         elif isinstance(p, PatternRE):
///             if p in self.term_reverse:  # Kind of a weird placement.name
///                 term_name = self.term_reverse[p].name
///         else:
///             assert False, p
///
///         if term_name is None:
///             term_name = '__ANON_%d' % self.i
///             self.i += 1
///
///         if term_name not in self.term_set:
///             assert p not in self.term_reverse
///             self.term_set.add(term_name)
///             termdef = TerminalDef(term_name, p)
///             self.term_reverse[p] = termdef
///             self.terminals.append(termdef)
///
///         filter_out = False if self.rule_options and self.rule_options.keep_all_tokens else isinstance(p, PatternStr)
///
///         return Terminal(term_name, filter_out=filter_out)
///
///
/// class _ReplaceSymbols(Transformer_InPlace):
///     """Helper for ApplyTemplates"""
///
///     def __init__(self):
///         self.names = {}
///
///     def value(self, c):
///         if len(c) == 1 and isinstance(c[0], Symbol) and c[0].name in self.names:
///             return self.names[c[0].name]
///         return self.__default__('value', c, None)
///
///     def template_usage(self, c):
///         name = c[0].name
///         if name in self.names:
///             return self.__default__('template_usage', [self.names[name]] + c[1:], None)
///         return self.__default__('template_usage', c, None)
///
///
/// class ApplyTemplates(Transformer_InPlace):
///     """Apply the templates, creating new rules that represent the used templates"""
///
///     def __init__(self, rule_defs):
///         self.rule_defs = rule_defs
///         self.replacer = _ReplaceSymbols()
///         self.created_templates = set()
///
///     def template_usage(self, c):
///         name = c[0].name
///         args = c[1:]
///         result_name = "%s{%s}" % (name, ",".join(a.name for a in args))
///         if result_name not in self.created_templates:
///             self.created_templates.add(result_name)
///             (_n, params, tree, options) ,= (t for t in self.rule_defs if t[0] == name)
///             assert len(params) == len(args), args
///             result_tree = deepcopy(tree)
///             self.replacer.names = dict(zip(params, args))
///             self.replacer.transform(result_tree)
///             self.rule_defs.append((result_name, [], result_tree, deepcopy(options)))
///         return NonTerminal(result_name)
///
///
/// def _rfind(s, choices):
///     return max(s.rfind(c) for c in choices)
///
///
/// def eval_escaping(s):
///     w = ''
///     i = iter(s)
///     for n in i:
///         w += n
///         if n == '\\':
///             try:
///                 n2 = next(i)
///             except StopIteration:
///                 raise GrammarError("Literal ended unexpectedly (bad escaping): `%r`" % s)
///             if n2 == '\\':
///                 w += '\\\\'
///             elif n2 not in 'Uuxnftr':
///                 w += '\\'
///             w += n2
///     w = w.replace('\\"', '"').replace("'", "\\'")
///
///     to_eval = "u'''%s'''" % w
///     try:
///         s = literal_eval(to_eval)
///     except SyntaxError as e:
///         raise GrammarError(s, e)
///
///     return s
///
///
/// def _literal_to_pattern(literal):
///     assert isinstance(literal, Token)
///     v = literal.value
///     flag_start = _rfind(v, '/"')+1
///     assert flag_start > 0
///     flags = v[flag_start:]
///     assert all(f in _RE_FLAGS for f in flags), flags
///
///     if literal.type == 'STRING' and '\n' in v:
///         raise GrammarError('You cannot put newlines in string literals')
///
///     if literal.type == 'REGEXP' and '\n' in v and 'x' not in flags:
///         raise GrammarError('You can only use newlines in regular expressions '
///                            'with the `x` (verbose) flag')
///
///     v = v[:flag_start]
///     assert v[0] == v[-1] and v[0] in '"/'
///     x = v[1:-1]
///
///     s = eval_escaping(x)
///
///     if s == "":
///         raise GrammarError("Empty terminals are not allowed (%s)" % literal)
///
///     if literal.type == 'STRING':
///         s = s.replace('\\\\', '\\')
///         return PatternStr(s, flags, raw=literal.value)
///     elif literal.type == 'REGEXP':
///         return PatternRE(s, flags, raw=literal.value)
///     else:
///         assert False, 'Invariant failed: literal.type not in ["STRING", "REGEXP"]'
///
///
/// @inline_args
/// class PrepareLiterals(Transformer_InPlace):
///     def literal(self, literal):
///         return ST('pattern', [_literal_to_pattern(literal)])
///
///     def range(self, start, end):
///         assert start.type == end.type == 'STRING'
///         start = start.value[1:-1]
///         end = end.value[1:-1]
///         assert len(eval_escaping(start)) == len(eval_escaping(end)) == 1
///         regexp = '[%s-%s]' % (start, end)
///         return ST('pattern', [PatternRE(regexp)])
///
///
/// def _make_joined_pattern(regexp, flags_set):
///     return PatternRE(regexp, ())
///
/// class TerminalTreeToPattern(Transformer_NonRecursive):
///     def pattern(self, ps):
///         p ,= ps
///         return p
///
///     def expansion(self, items):
///         assert items
///         if len(items) == 1:
///             return items[0]
///
///         pattern = ''.join(i.to_regexp() for i in items)
///         return _make_joined_pattern(pattern, {i.flags for i in items})
///
///     def expansions(self, exps):
///         if len(exps) == 1:
///             return exps[0]
///
///         # Do a bit of sorting to make sure that the longest option is returned
///         # (Python's re module otherwise prefers just 'l' when given (l|ll) and both could match)
///         exps.sort(key=lambda x: (-x.max_width, -x.min_width, -len(x.value)))
///
///         pattern = '(?:%s)' % ('|'.join(i.to_regexp() for i in exps))
///         return _make_joined_pattern(pattern, {i.flags for i in exps})
///
///     def expr(self, args):
///         inner, op = args[:2]
///         if op == '~':
///             if len(args) == 3:
///                 op = "{%d}" % int(args[2])
///             else:
///                 mn, mx = map(int, args[2:])
///                 if mx < mn:
///                     raise GrammarError("Bad Range for %s (%d..%d isn't allowed)" % (inner, mn, mx))
///                 op = "{%d,%d}" % (mn, mx)
///         else:
///             assert len(args) == 2
///         return PatternRE('(?:%s)%s' % (inner.to_regexp(), op), inner.flags)
///
///     def maybe(self, expr):
///         return self.expr(expr + ['?'])
///
///     def alias(self, t):
///         raise GrammarError("Aliasing not allowed in terminals (You used -> in the wrong place)")
///
///     def value(self, v):
///         return v[0]
///
///
/// class ValidateSymbols(Transformer_InPlace):
///     def value(self, v):
///         v ,= v
///         assert isinstance(v, (Tree, Symbol))
///         return v
///
///
/// def nr_deepcopy_tree(t):
///     """Deepcopy tree `t` without recursion"""
///     return Transformer_NonRecursive(False).transform(t)
///
///
/// class Grammar:
///
///     term_defs: List[Tuple[str, Tuple[Tree, int]]]
///     rule_defs: List[Tuple[str, Tuple[str, ...], Tree, RuleOptions]]
///     ignore: List[str]
///
///     def __init__(self, rule_defs: List[Tuple[str, Tuple[str, ...], Tree, RuleOptions]], term_defs: List[Tuple[str, Tuple[Tree, int]]], ignore: List[str]) -> None:
///         self.term_defs = term_defs
///         self.rule_defs = rule_defs
///         self.ignore = ignore
///
///     def compile(self, start, terminals_to_keep):
///         # We change the trees in-place (to support huge grammars)
///         # So deepcopy allows calling compile more than once.
///         term_defs = [(n, (nr_deepcopy_tree(t), p)) for n, (t, p) in self.term_defs]
///         rule_defs = [(n, p, nr_deepcopy_tree(t), o) for n, p, t, o in self.rule_defs]
///
///         # ===================
///         #  Compile Terminals
///         # ===================
///
///         # Convert terminal-trees to strings/regexps
///
///         for name, (term_tree, priority) in term_defs:
///             if term_tree is None:  # Terminal added through %declare
///                 continue
///             expansions = list(term_tree.find_data('expansion'))
///             if len(expansions) == 1 and not expansions[0].children:
///                 raise GrammarError("Terminals cannot be empty (%s)" % name)
///
///         transformer = PrepareLiterals() * TerminalTreeToPattern()
///         terminals = [TerminalDef(name, transformer.transform(term_tree), priority)
///                      for name, (term_tree, priority) in term_defs if term_tree]
///
///         # =================
///         #  Compile Rules
///         # =================
///
///         # 1. Pre-process terminals
///         anon_tokens_transf = PrepareAnonTerminals(terminals)
///         transformer = PrepareLiterals() * ValidateSymbols() * anon_tokens_transf  # Adds to terminals
///
///         # 2. Inline Templates
///
///         transformer *= ApplyTemplates(rule_defs)
///
///         # 3. Convert EBNF to BNF (and apply step 1 & 2)
///         ebnf_to_bnf = EBNF_to_BNF()
///         rules = []
///         i = 0
///         while i < len(rule_defs):  # We have to do it like this because rule_defs might grow due to templates
///             name, params, rule_tree, options = rule_defs[i]
///             i += 1
///             if len(params) != 0:  # Dont transform templates
///                 continue
///             rule_options = RuleOptions(keep_all_tokens=True) if options and options.keep_all_tokens else None
///             ebnf_to_bnf.rule_options = rule_options
///             ebnf_to_bnf.prefix = name
///             anon_tokens_transf.rule_options = rule_options
///             tree = transformer.transform(rule_tree)
///             res = ebnf_to_bnf.transform(tree)
///             rules.append((name, res, options))
///         rules += ebnf_to_bnf.new_rules
///
///         assert len(rules) == len({name for name, _t, _o in rules}), "Whoops, name collision"
///
///         # 4. Compile tree to Rule objects
///         rule_tree_to_text = RuleTreeToText()
///
///         simplify_rule = SimplifyRule_Visitor()
///         compiled_rules = []
///         for rule_content in rules:
///             name, tree, options = rule_content
///             simplify_rule.visit(tree)
///             expansions = rule_tree_to_text.transform(tree)
///
///             for i, (expansion, alias) in enumerate(expansions):
///                 if alias and name.startswith('_'):
///                     raise GrammarError("Rule %s is marked for expansion (it starts with an underscore) and isn't allowed to have aliases (alias=%s)"% (name, alias))
///
///                 empty_indices = [x==_EMPTY for x in expansion]
///                 if any(empty_indices):
///                     exp_options = copy(options) or RuleOptions()
///                     exp_options.empty_indices = empty_indices
///                     expansion = [x for x in expansion if x!=_EMPTY]
///                 else:
///                     exp_options = options
///
///                 for sym in expansion:
///                     assert isinstance(sym, Symbol)
///                     if sym.is_term and exp_options and exp_options.keep_all_tokens:
///                         sym.filter_out = False
///                 rule = Rule(NonTerminal(name), expansion, i, alias, exp_options)
///                 compiled_rules.append(rule)
///
///         # Remove duplicates of empty rules, throw error for non-empty duplicates
///         if len(set(compiled_rules)) != len(compiled_rules):
///             duplicates = classify(compiled_rules, lambda x: x)
///             for dups in duplicates.values():
///                 if len(dups) > 1:
///                     if dups[0].expansion:
///                         raise GrammarError("Rules defined twice: %s\n\n(Might happen due to colliding expansion of optionals: [] or ?)"
///                                            % ''.join('\n  * %s' % i for i in dups))
///
///                     # Empty rule; assert all other attributes are equal
///                     assert len({(r.alias, r.order, r.options) for r in dups}) == len(dups)
///
///             # Remove duplicates
///             compiled_rules = list(set(compiled_rules))
///
///         # Filter out unused rules
///         while True:
///             c = len(compiled_rules)
///             used_rules = {s for r in compiled_rules
///                             for s in r.expansion
///                             if isinstance(s, NonTerminal)
///                             and s != r.origin}
///             used_rules |= {NonTerminal(s) for s in start}
///             compiled_rules, unused = classify_bool(compiled_rules, lambda r: r.origin in used_rules)
///             for r in unused:
///                 logger.debug("Unused rule: %s", r)
///             if len(compiled_rules) == c:
///                 break
///
///         # Filter out unused terminals
///         if terminals_to_keep != '*':
///             used_terms = {t.name for r in compiled_rules
///                                  for t in r.expansion
///                                  if isinstance(t, Terminal)}
///             terminals, unused = classify_bool(terminals, lambda t: t.name in used_terms or t.name in self.ignore or t.name in terminals_to_keep)
///             if unused:
///                 logger.debug("Unused terminals: %s", [t.name for t in unused])
///
///         return terminals, compiled_rules, self.ignore
///
///
/// PackageResource = namedtuple('PackageResource', 'pkg_name path')
///
///
/// class FromPackageLoader:
///     """
///     Provides a simple way of creating custom import loaders that load from packages via ``pkgutil.get_data`` instead of using `open`.
///     This allows them to be compatible even from within zip files.
///
///     Relative imports are handled, so you can just freely use them.
///
///     pkg_name: The name of the package. You can probably provide `__name__` most of the time
///     search_paths: All the path that will be search on absolute imports.
///     """
///
///     pkg_name: str
///     search_paths: Sequence[str]
///
///     def __init__(self, pkg_name: str, search_paths: Sequence[str]=("", )) -> None:
///         self.pkg_name = pkg_name
///         self.search_paths = search_paths
///
///     def __repr__(self):
///         return "%s(%r, %r)" % (type(self).__name__, self.pkg_name, self.search_paths)
///
///     def __call__(self, base_path: Union[None, str, PackageResource], grammar_path: str) -> Tuple[PackageResource, str]:
///         if base_path is None:
///             to_try = self.search_paths
///         else:
///             # Check whether or not the importing grammar was loaded by this module.
///             if not isinstance(base_path, PackageResource) or base_path.pkg_name != self.pkg_name:
///                 # Technically false, but FileNotFound doesn't exist in python2.7, and this message should never reach the end user anyway
///                 raise IOError()
///             to_try = [base_path.path]
///
///         err = None
///         for path in to_try:
///             full_path = os.path.join(path, grammar_path)
///             try:
///                 text: Optional[bytes] = pkgutil.get_data(self.pkg_name, full_path)
///             except IOError as e:
///                 err = e
///                 continue
///             else:
///                 return PackageResource(self.pkg_name, full_path), (text.decode() if text else '')
///
///         raise IOError('Cannot find grammar in given paths') from err
///
///
/// stdlib_loader = FromPackageLoader('lark', IMPORT_PATHS)
///
///
///
/// def resolve_term_references(term_dict):
///     # TODO Solve with transitive closure (maybe)
///
///     while True:
///         changed = False
///         for name, token_tree in term_dict.items():
///             if token_tree is None:  # Terminal added through %declare
///                 continue
///             for exp in token_tree.find_data('value'):
///                 item ,= exp.children
///                 if isinstance(item, NonTerminal):
///                     raise GrammarError("Rules aren't allowed inside terminals (%s in %s)" % (item, name))
///                 elif isinstance(item, Terminal):
///                     try:
///                         term_value = term_dict[item.name]
///                     except KeyError:
///                         raise GrammarError("Terminal used but not defined: %s" % item.name)
///                     assert term_value is not None
///                     exp.children[0] = term_value
///                     changed = True
///                 else:
///                     assert isinstance(item, Tree)
///         if not changed:
///             break
///
///     for name, term in term_dict.items():
///         if term:    # Not just declared
///             for child in term.children:
///                 ids = [id(x) for x in child.iter_subtrees()]
///                 if id(term) in ids:
///                     raise GrammarError("Recursion in terminal '%s' (recursion is only allowed in rules, not terminals)" % name)
///
///
///
/// def symbol_from_strcase(s):
///     assert isinstance(s, str)
///     return Terminal(s, filter_out=s.startswith('_')) if s.isupper() else NonTerminal(s)
///
/// @inline_args
/// class PrepareGrammar(Transformer_InPlace):
///     def terminal(self, name):
///         return Terminal(str(name), filter_out=name.startswith('_'))
///
///     def nonterminal(self, name):
///         return NonTerminal(name.value)
///
///
/// def _find_used_symbols(tree):
///     assert tree.data == 'expansions'
///     return {t.name for x in tree.find_data('expansion')
///             for t in x.scan_values(lambda t: isinstance(t, Symbol))}
///
///
/// def _get_parser():
///     try:
///         return _get_parser.cache
///     except AttributeError:
///         terminals = [TerminalDef(name, PatternRE(value)) for name, value in TERMINALS.items()]
///
///         rules = [(name.lstrip('?'), x, RuleOptions(expand1=name.startswith('?')))
///                 for name, x in RULES.items()]
///         rules = [Rule(NonTerminal(r), [symbol_from_strcase(s) for s in x.split()], i, None, o)
///                  for r, xs, o in rules for i, x in enumerate(xs)]
///
///         callback = ParseTreeBuilder(rules, ST).create_callback()
///         import re
///         lexer_conf = LexerConf(terminals, re, ['WS', 'COMMENT', 'BACKSLASH'])
///         parser_conf = ParserConf(rules, callback, ['start'])
///         lexer_conf.lexer_type = 'basic'
///         parser_conf.parser_type = 'lalr'
///         _get_parser.cache = ParsingFrontend(lexer_conf, parser_conf, None)
///         return _get_parser.cache
///
/// GRAMMAR_ERRORS = [
///         ('Incorrect type of value', ['a: 1\n']),
///         ('Unclosed parenthesis', ['a: (\n']),
///         ('Unmatched closing parenthesis', ['a: )\n', 'a: [)\n', 'a: (]\n']),
///         ('Expecting rule or terminal definition (missing colon)', ['a\n', 'A\n', 'a->\n', 'A->\n', 'a A\n']),
///         ('Illegal name for rules or terminals', ['Aa:\n']),
///         ('Alias expects lowercase name', ['a: -> "a"\n']),
///         ('Unexpected colon', ['a::\n', 'a: b:\n', 'a: B:\n', 'a: "a":\n']),
///         ('Misplaced operator', ['a: b??', 'a: b(?)', 'a:+\n', 'a:?\n', 'a:*\n', 'a:|*\n']),
///         ('Expecting option ("|") or a new rule or terminal definition', ['a:a\n()\n']),
///         ('Terminal names cannot contain dots', ['A.B\n']),
///         ('Expecting rule or terminal definition', ['"a"\n']),
///         ('%import expects a name', ['%import "a"\n']),
///         ('%ignore expects a value', ['%ignore %import\n']),
///     ]
///
/// def _translate_parser_exception(parse, e):
///         error = e.match_examples(parse, GRAMMAR_ERRORS, use_accepts=True)
///         if error:
///             return error
///         elif 'STRING' in e.expected:
///             return "Expecting a value"
///
/// def _parse_grammar(text, name, start='start'):
///     try:
///         tree = _get_parser().parse(text + '\n', start)
///     except UnexpectedCharacters as e:
///         context = e.get_context(text)
///         raise GrammarError("Unexpected input at line %d column %d in %s: \n\n%s" %
///                            (e.line, e.column, name, context))
///     except UnexpectedToken as e:
///         context = e.get_context(text)
///         error = _translate_parser_exception(_get_parser().parse, e)
///         if error:
///             raise GrammarError("%s, at line %s column %s\n\n%s" % (error, e.line, e.column, context))
///         raise
///
///     return PrepareGrammar().transform(tree)
///
///
/// def _error_repr(error):
///     if isinstance(error, UnexpectedToken):
///         error2 = _translate_parser_exception(_get_parser().parse, error)
///         if error2:
///             return error2
///         expected = ', '.join(error.accepts or error.expected)
///         return "Unexpected token %r. Expected one of: {%s}" % (str(error.token), expected)
///     else:
///         return str(error)
///
/// def _search_interactive_parser(interactive_parser, predicate):
///     def expand(node):
///         path, p = node
///         for choice in p.choices():
///             t = Token(choice, '')
///             try:
///                 new_p = p.feed_token(t)
///             except ParseError:    # Illegal
///                 pass
///             else:
///                 yield path + (choice,), new_p
///
///     for path, p in bfs_all_unique([((), interactive_parser)], expand):
///         if predicate(p):
///             return path, p
///
/// def find_grammar_errors(text: str, start: str='start') -> List[Tuple[UnexpectedInput, str]]:
///     errors = []
///     def on_error(e):
///         errors.append((e, _error_repr(e)))
///
///         # recover to a new line
///         token_path, _ = _search_interactive_parser(e.interactive_parser.as_immutable(), lambda p: '_NL' in p.choices())
///         for token_type in token_path:
///             e.interactive_parser.feed_token(Token(token_type, ''))
///         e.interactive_parser.feed_token(Token('_NL', '\n'))
///         return True
///
///     _tree = _get_parser().parse(text + '\n', start, on_error=on_error)
///
///     errors_by_line = classify(errors, lambda e: e[0].line)
///     errors = [el[0] for el in errors_by_line.values()]      # already sorted
///
///     for e in errors:
///         e[0].interactive_parser = None
///     return errors
///
///
/// def _get_mangle(prefix, aliases, base_mangle=None):
///     def mangle(s):
///         if s in aliases:
///             s = aliases[s]
///         else:
///             if s[0] == '_':
///                 s = '_%s__%s' % (prefix, s[1:])
///             else:
///                 s = '%s__%s' % (prefix, s)
///         if base_mangle is not None:
///             s = base_mangle(s)
///         return s
///     return mangle
///
/// def _mangle_definition_tree(exp, mangle):
///     if mangle is None:
///         return exp
///     exp = deepcopy(exp) # TODO: is this needed?
///     for t in exp.iter_subtrees():
///         for i, c in enumerate(t.children):
///             if isinstance(c, Symbol):
///                 t.children[i] = c.renamed(mangle)
///
///     return exp
///
/// def _make_rule_tuple(modifiers_tree, name, params, priority_tree, expansions):
///     if modifiers_tree.children:
///         m ,= modifiers_tree.children
///         expand1 = '?' in m
///         if expand1 and name.startswith('_'):
///             raise GrammarError("Inlined rules (_rule) cannot use the ?rule modifier.")
///         keep_all_tokens = '!' in m
///     else:
///         keep_all_tokens = False
///         expand1 = False
///
///     if priority_tree.children:
///         p ,= priority_tree.children
///         priority = int(p)
///     else:
///         priority = None
///
///     if params is not None:
///         params = [t.value for t in params.children]  # For the grammar parser
///
///     return name, params, expansions, RuleOptions(keep_all_tokens, expand1, priority=priority,
///                                                  template_source=(name if params else None))
///
///
/// class Definition:
///     def __init__(self, is_term, tree, params=(), options=None):
///         self.is_term = is_term
///         self.tree = tree
///         self.params = tuple(params)
///         self.options = options
///
/// class GrammarBuilder:
///
///     global_keep_all_tokens: bool
///     import_paths: List[Union[str, Callable]]
///     used_files: Dict[str, str]
///
///     _definitions: Dict[str, Definition]
///     _ignore_names: List[str]
///
///     def __init__(self, global_keep_all_tokens: bool=False, import_paths: Optional[List[Union[str, Callable]]]=None, used_files: Optional[Dict[str, str]]=None) -> None:
///         self.global_keep_all_tokens = global_keep_all_tokens
///         self.import_paths = import_paths or []
///         self.used_files = used_files or {}
///
///         self._definitions: Dict[str, Definition] = {}
///         self._ignore_names: List[str] = []
///
///     def _grammar_error(self, is_term, msg, *names):
///         args = {}
///         for i, name in enumerate(names, start=1):
///             postfix = '' if i == 1 else str(i)
///             args['name' + postfix] = name
///             args['type' + postfix] = lowercase_type = ("rule", "terminal")[is_term]
///             args['Type' + postfix] = lowercase_type.title()
///         raise GrammarError(msg.format(**args))
///
///     def _check_options(self, is_term, options):
///         if is_term:
///             if options is None:
///                 options = 1
///             elif not isinstance(options, int):
///                 raise GrammarError("Terminal require a single int as 'options' (e.g. priority), got %s" % (type(options),))
///         else:
///             if options is None:
///                 options = RuleOptions()
///             elif not isinstance(options, RuleOptions):
///                 raise GrammarError("Rules require a RuleOptions instance as 'options'")
///             if self.global_keep_all_tokens:
///                 options.keep_all_tokens = True
///         return options
///
///
///     def _define(self, name, is_term, exp, params=(), options=None, *, override=False):
///         if name in self._definitions:
///             if not override:
///                 self._grammar_error(is_term, "{Type} '{name}' defined more than once", name)
///         elif override:
///             self._grammar_error(is_term, "Cannot override a nonexisting {type} {name}", name)
///
///         if name.startswith('__'):
///             self._grammar_error(is_term, 'Names starting with double-underscore are reserved (Error at {name})', name)
///
///         self._definitions[name] = Definition(is_term, exp, params, self._check_options(is_term, options))
///
///     def _extend(self, name, is_term, exp, params=(), options=None):
///         if name not in self._definitions:
///             self._grammar_error(is_term, "Can't extend {type} {name} as it wasn't defined before", name)
///
///         d = self._definitions[name]
///
///         if is_term != d.is_term:
///             self._grammar_error(is_term, "Cannot extend {type} {name} - one is a terminal, while the other is not.", name)
///         if tuple(params) != d.params:
///             self._grammar_error(is_term, "Cannot extend {type} with different parameters: {name}", name)
///
///         if d.tree is None:
///             self._grammar_error(is_term, "Can't extend {type} {name} - it is abstract.", name)
///
///         # TODO: think about what to do with 'options'
///         base = d.tree
///
///         assert isinstance(base, Tree) and base.data == 'expansions'
///         base.children.insert(0, exp)
///
///     def _ignore(self, exp_or_name):
///         if isinstance(exp_or_name, str):
///             self._ignore_names.append(exp_or_name)
///         else:
///             assert isinstance(exp_or_name, Tree)
///             t = exp_or_name
///             if t.data == 'expansions' and len(t.children) == 1:
///                 t2 ,= t.children
///                 if t2.data=='expansion' and len(t2.children) == 1:
///                     item ,= t2.children
///                     if item.data == 'value':
///                         item ,= item.children
///                         if isinstance(item, Terminal):
///                             # Keep terminal name, no need to create a new definition
///                             self._ignore_names.append(item.name)
///                             return
///
///             name = '__IGNORE_%d'% len(self._ignore_names)
///             self._ignore_names.append(name)
///             self._definitions[name] = Definition(True, t, options=TOKEN_DEFAULT_PRIORITY)
///
///     def _unpack_import(self, stmt, grammar_name):
///         if len(stmt.children) > 1:
///             path_node, arg1 = stmt.children
///         else:
///             path_node, = stmt.children
///             arg1 = None
///
///         if isinstance(arg1, Tree):  # Multi import
///             dotted_path = tuple(path_node.children)
///             names = arg1.children
///             aliases = dict(zip(names, names))  # Can't have aliased multi import, so all aliases will be the same as names
///         else:  # Single import
///             dotted_path = tuple(path_node.children[:-1])
///             if not dotted_path:
///                 name ,= path_node.children
///                 raise GrammarError("Nothing was imported from grammar `%s`" % name)
///             name = path_node.children[-1]  # Get name from dotted path
///             aliases = {name.value: (arg1 or name).value}  # Aliases if exist
///
///         if path_node.data == 'import_lib':  # Import from library
///             base_path = None
///         else:  # Relative import
///             if grammar_name == '<string>':  # Import relative to script file path if grammar is coded in script
///                 try:
///                     base_file = os.path.abspath(sys.modules['__main__'].__file__)
///                 except AttributeError:
///                     base_file = None
///             else:
///                 base_file = grammar_name  # Import relative to grammar file path if external grammar file
///             if base_file:
///                 if isinstance(base_file, PackageResource):
///                     base_path = PackageResource(base_file.pkg_name, os.path.split(base_file.path)[0])
///                 else:
///                     base_path = os.path.split(base_file)[0]
///             else:
///                 base_path = os.path.abspath(os.path.curdir)
///
///         return dotted_path, base_path, aliases
///
///     def _unpack_definition(self, tree, mangle):
///
///         if tree.data == 'rule':
///             name, params, exp, opts = _make_rule_tuple(*tree.children)
///             is_term = False
///         else:
///             name = tree.children[0].value
///             params = ()     # TODO terminal templates
///             opts = int(tree.children[1]) if len(tree.children) == 3 else TOKEN_DEFAULT_PRIORITY # priority
///             exp = tree.children[-1]
///             is_term = True
///
///         if mangle is not None:
///             params = tuple(mangle(p) for p in params)
///             name = mangle(name)
///
///         exp = _mangle_definition_tree(exp, mangle)
///         return name, is_term, exp, params, opts
///
///
///     def load_grammar(self, grammar_text: str, grammar_name: str="<?>", mangle: Optional[Callable[[str], str]]=None) -> None:
///         tree = _parse_grammar(grammar_text, grammar_name)
///
///         imports: Dict[Tuple[str, ...], Tuple[Optional[str], Dict[str, str]]] = {}
///
///         for stmt in tree.children:
///             if stmt.data == 'import':
///                 dotted_path, base_path, aliases = self._unpack_import(stmt, grammar_name)
///                 try:
///                     import_base_path, import_aliases = imports[dotted_path]
///                     assert base_path == import_base_path, 'Inconsistent base_path for %s.' % '.'.join(dotted_path)
///                     import_aliases.update(aliases)
///                 except KeyError:
///                     imports[dotted_path] = base_path, aliases
///
///         for dotted_path, (base_path, aliases) in imports.items():
///             self.do_import(dotted_path, base_path, aliases, mangle)
///
///         for stmt in tree.children:
///             if stmt.data in ('term', 'rule'):
///                 self._define(*self._unpack_definition(stmt, mangle))
///             elif stmt.data == 'override':
///                 r ,= stmt.children
///                 self._define(*self._unpack_definition(r, mangle), override=True)
///             elif stmt.data == 'extend':
///                 r ,= stmt.children
///                 self._extend(*self._unpack_definition(r, mangle))
///             elif stmt.data == 'ignore':
///                 # if mangle is not None, we shouldn't apply ignore, since we aren't in a toplevel grammar
///                 if mangle is None:
///                     self._ignore(*stmt.children)
///             elif stmt.data == 'declare':
///                 for symbol in stmt.children:
///                     assert isinstance(symbol, Symbol), symbol
///                     is_term = isinstance(symbol, Terminal)
///                     if mangle is None:
///                         name = symbol.name
///                     else:
///                         name = mangle(symbol.name)
///                     self._define(name, is_term, None)
///             elif stmt.data == 'import':
///                 pass
///             else:
///                 assert False, stmt
///
///
///         term_defs = { name: d.tree
///             for name, d in self._definitions.items()
///             if d.is_term
///         }
///         resolve_term_references(term_defs)
///
///
///     def _remove_unused(self, used):
///         def rule_dependencies(symbol):
///             try:
///                 d = self._definitions[symbol]
///             except KeyError:
///                 return []
///             if d.is_term:
///                 return []
///             return _find_used_symbols(d.tree) - set(d.params)
///
///         _used = set(bfs(used, rule_dependencies))
///         self._definitions = {k: v for k, v in self._definitions.items() if k in _used}
///
///
///     def do_import(self, dotted_path: Tuple[str, ...], base_path: Optional[str], aliases: Dict[str, str], base_mangle: Optional[Callable[[str], str]]=None) -> None:
///         assert dotted_path
///         mangle = _get_mangle('__'.join(dotted_path), aliases, base_mangle)
///         grammar_path = os.path.join(*dotted_path) + EXT
///         to_try = self.import_paths + ([base_path] if base_path is not None else []) + [stdlib_loader]
///         for source in to_try:
///             try:
///                 if callable(source):
///                     joined_path, text = source(base_path, grammar_path)
///                 else:
///                     joined_path = os.path.join(source, grammar_path)
///                     with open(joined_path, encoding='utf8') as f:
///                         text = f.read()
///             except IOError:
///                 continue
///             else:
///                 h = md5_digest(text)
///                 if self.used_files.get(joined_path, h) != h:
///                     raise RuntimeError("Grammar file was changed during importing")
///                 self.used_files[joined_path] = h
///
///                 gb = GrammarBuilder(self.global_keep_all_tokens, self.import_paths, self.used_files)
///                 gb.load_grammar(text, joined_path, mangle)
///                 gb._remove_unused(map(mangle, aliases))
///                 for name in gb._definitions:
///                     if name in self._definitions:
///                         raise GrammarError("Cannot import '%s' from '%s': Symbol already defined." % (name, grammar_path))
///
///                 self._definitions.update(**gb._definitions)
///                 break
///         else:
///             # Search failed. Make Python throw a nice error.
///             open(grammar_path, encoding='utf8')
///             assert False, "Couldn't import grammar %s, but a corresponding file was found at a place where lark doesn't search for it" % (dotted_path,)
///
///
///     def validate(self) -> None:
///         for name, d in self._definitions.items():
///             params = d.params
///             exp = d.tree
///
///             for i, p in enumerate(params):
///                 if p in self._definitions:
///                     raise GrammarError("Template Parameter conflicts with rule %s (in template %s)" % (p, name))
///                 if p in params[:i]:
///                     raise GrammarError("Duplicate Template Parameter %s (in template %s)" % (p, name))
///
///             if exp is None: # Remaining checks don't apply to abstract rules/terminals (created with %declare)
///                 continue
///
///             for temp in exp.find_data('template_usage'):
///                 sym = temp.children[0].name
///                 args = temp.children[1:]
///                 if sym not in params:
///                     if sym not in self._definitions:
///                         self._grammar_error(d.is_term, "Template '%s' used but not defined (in {type} {name})" % sym, name)
///                     if len(args) != len(self._definitions[sym].params):
///                         expected, actual = len(self._definitions[sym].params), len(args)
///                         self._grammar_error(d.is_term, "Wrong number of template arguments used for {name} "
///                                             "(expected %s, got %s) (in {type2} {name2})" % (expected, actual), sym, name)
///
///             for sym in _find_used_symbols(exp):
///                 if sym not in self._definitions and sym not in params:
///                     self._grammar_error(d.is_term, "{Type} '{name}' used but not defined (in {type2} {name2})", sym, name)
///
///         if not set(self._definitions).issuperset(self._ignore_names):
///             raise GrammarError("Terminals %s were marked to ignore but were not defined!" % (set(self._ignore_names) - set(self._definitions)))
///
///     def build(self) -> Grammar:
///         self.validate()
///         rule_defs = []
///         term_defs = []
///         for name, d in self._definitions.items():
///             (params, exp, options) = d.params, d.tree, d.options
///             if d.is_term:
///                 assert len(params) == 0
///                 term_defs.append((name, (exp, options)))
///             else:
///                 rule_defs.append((name, params, exp, options))
///         # resolve_term_references(term_defs)
///         return Grammar(rule_defs, term_defs, self._ignore_names)
///
///
/// def verify_used_files(file_hashes):
///     for path, old in file_hashes.items():
///         text = None
///         if isinstance(path, str) and os.path.exists(path):
///             with open(path, encoding='utf8') as f:
///                 text = f.read()
///         elif isinstance(path, PackageResource):
///             with suppress(IOError):
///                 text = pkgutil.get_data(*path).decode('utf-8')
///         if text is None: # We don't know how to load the path. ignore it.
///             continue
///
///         current = md5_digest(text)
///         if old != current:
///             logger.info("File %r changed, rebuilding Parser" % path)
///             return False
///     return True
///
/// def list_grammar_imports(grammar, import_paths=[]):
///     "Returns a list of paths to the lark grammars imported by the given grammar (recursively)"
///     builder = GrammarBuilder(False, import_paths)
///     builder.load_grammar(grammar, '<string>')
///     return list(builder.used_files.keys())
///
/// def load_grammar(grammar, source, import_paths, global_keep_all_tokens):
///     builder = GrammarBuilder(global_keep_all_tokens, import_paths)
///     builder.load_grammar(grammar, source)
///     return builder.build(), builder.used_files
///
///
/// def md5_digest(s: str) -> str:
///     """Get the md5 digest of a string
///
///     Supports the `usedforsecurity` argument for Python 3.9+ to allow running on
///     a FIPS-enabled system.
///     """
///     if sys.version_info >= (3, 9):
///         return hashlib.md5(s.encode('utf8'), usedforsecurity=False).hexdigest()
///     else:
///         return hashlib.md5(s.encode('utf8')).hexdigest()
/// ```
final class load_grammar extends PythonModule {
  load_grammar.from(super.pythonModule) : super.from();

  static load_grammar import() => PythonFfiDart.instance.importModule(
        "lark.load_grammar",
        load_grammar.from,
      );

  /// ## eval_escaping
  ///
  /// ### python source
  /// ```py
  /// def eval_escaping(s):
  ///     w = ''
  ///     i = iter(s)
  ///     for n in i:
  ///         w += n
  ///         if n == '\\':
  ///             try:
  ///                 n2 = next(i)
  ///             except StopIteration:
  ///                 raise GrammarError("Literal ended unexpectedly (bad escaping): `%r`" % s)
  ///             if n2 == '\\':
  ///                 w += '\\\\'
  ///             elif n2 not in 'Uuxnftr':
  ///                 w += '\\'
  ///             w += n2
  ///     w = w.replace('\\"', '"').replace("'", "\\'")
  ///
  ///     to_eval = "u'''%s'''" % w
  ///     try:
  ///         s = literal_eval(to_eval)
  ///     except SyntaxError as e:
  ///         raise GrammarError(s, e)
  ///
  ///     return s
  /// ```
  Object? eval_escaping({
    required Object? s,
  }) =>
      getFunction("eval_escaping").call(
        <Object?>[
          s,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## find_grammar_errors
  ///
  /// ### python source
  /// ```py
  /// def find_grammar_errors(text: str, start: str='start') -> List[Tuple[UnexpectedInput, str]]:
  ///     errors = []
  ///     def on_error(e):
  ///         errors.append((e, _error_repr(e)))
  ///
  ///         # recover to a new line
  ///         token_path, _ = _search_interactive_parser(e.interactive_parser.as_immutable(), lambda p: '_NL' in p.choices())
  ///         for token_type in token_path:
  ///             e.interactive_parser.feed_token(Token(token_type, ''))
  ///         e.interactive_parser.feed_token(Token('_NL', '\n'))
  ///         return True
  ///
  ///     _tree = _get_parser().parse(text + '\n', start, on_error=on_error)
  ///
  ///     errors_by_line = classify(errors, lambda e: e[0].line)
  ///     errors = [el[0] for el in errors_by_line.values()]      # already sorted
  ///
  ///     for e in errors:
  ///         e[0].interactive_parser = None
  ///     return errors
  /// ```
  Object? find_grammar_errors({
    required Object? text,
    Object? start = "start",
  }) =>
      getFunction("find_grammar_errors").call(
        <Object?>[
          text,
          start,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## list_grammar_imports
  ///
  /// ### python docstring
  ///
  /// Returns a list of paths to the lark grammars imported by the given grammar (recursively)
  ///
  /// ### python source
  /// ```py
  /// def list_grammar_imports(grammar, import_paths=[]):
  ///     "Returns a list of paths to the lark grammars imported by the given grammar (recursively)"
  ///     builder = GrammarBuilder(False, import_paths)
  ///     builder.load_grammar(grammar, '<string>')
  ///     return list(builder.used_files.keys())
  /// ```
  Object? list_grammar_imports({
    required Object? grammar,
    Object? import_paths = const [],
  }) =>
      getFunction("list_grammar_imports").call(
        <Object?>[
          grammar,
          import_paths,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## md5_digest
  ///
  /// ### python docstring
  ///
  /// Get the md5 digest of a string
  ///
  /// Supports the `usedforsecurity` argument for Python 3.9+ to allow running on
  /// a FIPS-enabled system.
  ///
  /// ### python source
  /// ```py
  /// def md5_digest(s: str) -> str:
  ///     """Get the md5 digest of a string
  ///
  ///     Supports the `usedforsecurity` argument for Python 3.9+ to allow running on
  ///     a FIPS-enabled system.
  ///     """
  ///     if sys.version_info >= (3, 9):
  ///         return hashlib.md5(s.encode('utf8'), usedforsecurity=False).hexdigest()
  ///     else:
  ///         return hashlib.md5(s.encode('utf8')).hexdigest()
  /// ```
  Object? md5_digest({
    required Object? s,
  }) =>
      getFunction("md5_digest").call(
        <Object?>[
          s,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## nr_deepcopy_tree
  ///
  /// ### python docstring
  ///
  /// Deepcopy tree `t` without recursion
  ///
  /// ### python source
  /// ```py
  /// def nr_deepcopy_tree(t):
  ///     """Deepcopy tree `t` without recursion"""
  ///     return Transformer_NonRecursive(False).transform(t)
  /// ```
  Object? nr_deepcopy_tree({
    required Object? t,
  }) =>
      getFunction("nr_deepcopy_tree").call(
        <Object?>[
          t,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## resolve_term_references
  ///
  /// ### python source
  /// ```py
  /// def resolve_term_references(term_dict):
  ///     # TODO Solve with transitive closure (maybe)
  ///
  ///     while True:
  ///         changed = False
  ///         for name, token_tree in term_dict.items():
  ///             if token_tree is None:  # Terminal added through %declare
  ///                 continue
  ///             for exp in token_tree.find_data('value'):
  ///                 item ,= exp.children
  ///                 if isinstance(item, NonTerminal):
  ///                     raise GrammarError("Rules aren't allowed inside terminals (%s in %s)" % (item, name))
  ///                 elif isinstance(item, Terminal):
  ///                     try:
  ///                         term_value = term_dict[item.name]
  ///                     except KeyError:
  ///                         raise GrammarError("Terminal used but not defined: %s" % item.name)
  ///                     assert term_value is not None
  ///                     exp.children[0] = term_value
  ///                     changed = True
  ///                 else:
  ///                     assert isinstance(item, Tree)
  ///         if not changed:
  ///             break
  ///
  ///     for name, term in term_dict.items():
  ///         if term:    # Not just declared
  ///             for child in term.children:
  ///                 ids = [id(x) for x in child.iter_subtrees()]
  ///                 if id(term) in ids:
  ///                     raise GrammarError("Recursion in terminal '%s' (recursion is only allowed in rules, not terminals)" % name)
  /// ```
  Object? resolve_term_references({
    required Object? term_dict,
  }) =>
      getFunction("resolve_term_references").call(
        <Object?>[
          term_dict,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## symbol_from_strcase
  ///
  /// ### python source
  /// ```py
  /// def symbol_from_strcase(s):
  ///     assert isinstance(s, str)
  ///     return Terminal(s, filter_out=s.startswith('_')) if s.isupper() else NonTerminal(s)
  /// ```
  Object? symbol_from_strcase({
    required Object? s,
  }) =>
      getFunction("symbol_from_strcase").call(
        <Object?>[
          s,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## verify_used_files
  ///
  /// ### python source
  /// ```py
  /// def verify_used_files(file_hashes):
  ///     for path, old in file_hashes.items():
  ///         text = None
  ///         if isinstance(path, str) and os.path.exists(path):
  ///             with open(path, encoding='utf8') as f:
  ///                 text = f.read()
  ///         elif isinstance(path, PackageResource):
  ///             with suppress(IOError):
  ///                 text = pkgutil.get_data(*path).decode('utf-8')
  ///         if text is None: # We don't know how to load the path. ignore it.
  ///             continue
  ///
  ///         current = md5_digest(text)
  ///         if old != current:
  ///             logger.info("File %r changed, rebuilding Parser" % path)
  ///             return False
  ///     return True
  /// ```
  Object? verify_used_files({
    required Object? file_hashes,
  }) =>
      getFunction("verify_used_files").call(
        <Object?>[
          file_hashes,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## stdlib_loader (getter)
  ///
  /// ### python docstring
  ///
  /// Provides a simple way of creating custom import loaders that load from packages via ``pkgutil.get_data`` instead of using `open`.
  /// This allows them to be compatible even from within zip files.
  ///
  /// Relative imports are handled, so you can just freely use them.
  ///
  /// pkg_name: The name of the package. You can probably provide `__name__` most of the time
  /// search_paths: All the path that will be search on absolute imports.
  Object? get stdlib_loader => getAttribute("stdlib_loader");

  /// ## stdlib_loader (setter)
  ///
  /// ### python docstring
  ///
  /// Provides a simple way of creating custom import loaders that load from packages via ``pkgutil.get_data`` instead of using `open`.
  /// This allows them to be compatible even from within zip files.
  ///
  /// Relative imports are handled, so you can just freely use them.
  ///
  /// pkg_name: The name of the package. You can probably provide `__name__` most of the time
  /// search_paths: All the path that will be search on absolute imports.
  set stdlib_loader(Object? stdlib_loader) =>
      setAttribute("stdlib_loader", stdlib_loader);

  /// ## EXT (getter)
  Object? get EXT => getAttribute("EXT");

  /// ## EXT (setter)
  set EXT(Object? EXT) => setAttribute("EXT", EXT);

  /// ## GRAMMAR_ERRORS (getter)
  Object? get GRAMMAR_ERRORS => getAttribute("GRAMMAR_ERRORS");

  /// ## GRAMMAR_ERRORS (setter)
  set GRAMMAR_ERRORS(Object? GRAMMAR_ERRORS) =>
      setAttribute("GRAMMAR_ERRORS", GRAMMAR_ERRORS);

  /// ## IMPORT_PATHS (getter)
  Object? get IMPORT_PATHS => getAttribute("IMPORT_PATHS");

  /// ## IMPORT_PATHS (setter)
  set IMPORT_PATHS(Object? IMPORT_PATHS) =>
      setAttribute("IMPORT_PATHS", IMPORT_PATHS);

  /// ## REPEAT_BREAK_THRESHOLD (getter)
  Object? get REPEAT_BREAK_THRESHOLD => getAttribute("REPEAT_BREAK_THRESHOLD");

  /// ## REPEAT_BREAK_THRESHOLD (setter)
  set REPEAT_BREAK_THRESHOLD(Object? REPEAT_BREAK_THRESHOLD) =>
      setAttribute("REPEAT_BREAK_THRESHOLD", REPEAT_BREAK_THRESHOLD);

  /// ## RULES (getter)
  Object? get RULES => getAttribute("RULES");

  /// ## RULES (setter)
  set RULES(Object? RULES) => setAttribute("RULES", RULES);

  /// ## SMALL_FACTOR_THRESHOLD (getter)
  Object? get SMALL_FACTOR_THRESHOLD => getAttribute("SMALL_FACTOR_THRESHOLD");

  /// ## SMALL_FACTOR_THRESHOLD (setter)
  set SMALL_FACTOR_THRESHOLD(Object? SMALL_FACTOR_THRESHOLD) =>
      setAttribute("SMALL_FACTOR_THRESHOLD", SMALL_FACTOR_THRESHOLD);

  /// ## TERMINALS (getter)
  Object? get TERMINALS => getAttribute("TERMINALS");

  /// ## TERMINALS (setter)
  set TERMINALS(Object? TERMINALS) => setAttribute("TERMINALS", TERMINALS);

  /// ## TOKEN_DEFAULT_PRIORITY (getter)
  Object? get TOKEN_DEFAULT_PRIORITY => getAttribute("TOKEN_DEFAULT_PRIORITY");

  /// ## TOKEN_DEFAULT_PRIORITY (setter)
  set TOKEN_DEFAULT_PRIORITY(Object? TOKEN_DEFAULT_PRIORITY) =>
      setAttribute("TOKEN_DEFAULT_PRIORITY", TOKEN_DEFAULT_PRIORITY);
}

/// ## hashlib
///
/// ### python docstring
///
/// hashlib module - A common interface to many hash functions.
///
/// new(name, data=b'', **kwargs) - returns a new hash object implementing the
///                                 given hash function; initializing the hash
///                                 using the given binary data.
///
/// Named constructor functions are also available, these are faster
/// than using new(name):
///
/// md5(), sha1(), sha224(), sha256(), sha384(), sha512(), blake2b(), blake2s(),
/// sha3_224, sha3_256, sha3_384, sha3_512, shake_128, and shake_256.
///
/// More algorithms may be available on your platform but the above are guaranteed
/// to exist.  See the algorithms_guaranteed and algorithms_available attributes
/// to find out what algorithm names can be passed to new().
///
/// NOTE: If you want the adler32 or crc32 hash functions they are available in
/// the zlib module.
///
/// Choose your hash function wisely.  Some have known collision weaknesses.
/// sha384 and sha512 will be slow on 32 bit platforms.
///
/// Hash objects have these methods:
///  - update(data): Update the hash object with the bytes in data. Repeated calls
///                  are equivalent to a single call with the concatenation of all
///                  the arguments.
///  - digest():     Return the digest of the bytes passed to the update() method
///                  so far as a bytes object.
///  - hexdigest():  Like digest() except the digest is returned as a string
///                  of double length, containing only hexadecimal digits.
///  - copy():       Return a copy (clone) of the hash object. This can be used to
///                  efficiently compute the digests of datas that share a common
///                  initial substring.
///
/// For example, to obtain the digest of the byte string 'Nobody inspects the
/// spammish repetition':
///
///     >>> import hashlib
///     >>> m = hashlib.md5()
///     >>> m.update(b"Nobody inspects")
///     >>> m.update(b" the spammish repetition")
///     >>> m.digest()
///     b'\xbbd\x9c\x83\xdd\x1e\xa5\xc9\xd9\xde\xc9\xa1\x8d\xf0\xff\xe9'
///
/// More condensed:
///
///     >>> hashlib.sha224(b"Nobody inspects the spammish repetition").hexdigest()
///     'a4337bc45a8fc544c03f52dc550cd6e1e87021bc896588bd79e901e2'
///
/// ### python source
/// ```py
/// #.  Copyright (C) 2005-2010   Gregory P. Smith (greg@krypto.org)
/// #  Licensed to PSF under a Contributor Agreement.
/// #
///
/// __doc__ = """hashlib module - A common interface to many hash functions.
///
/// new(name, data=b'', **kwargs) - returns a new hash object implementing the
///                                 given hash function; initializing the hash
///                                 using the given binary data.
///
/// Named constructor functions are also available, these are faster
/// than using new(name):
///
/// md5(), sha1(), sha224(), sha256(), sha384(), sha512(), blake2b(), blake2s(),
/// sha3_224, sha3_256, sha3_384, sha3_512, shake_128, and shake_256.
///
/// More algorithms may be available on your platform but the above are guaranteed
/// to exist.  See the algorithms_guaranteed and algorithms_available attributes
/// to find out what algorithm names can be passed to new().
///
/// NOTE: If you want the adler32 or crc32 hash functions they are available in
/// the zlib module.
///
/// Choose your hash function wisely.  Some have known collision weaknesses.
/// sha384 and sha512 will be slow on 32 bit platforms.
///
/// Hash objects have these methods:
///  - update(data): Update the hash object with the bytes in data. Repeated calls
///                  are equivalent to a single call with the concatenation of all
///                  the arguments.
///  - digest():     Return the digest of the bytes passed to the update() method
///                  so far as a bytes object.
///  - hexdigest():  Like digest() except the digest is returned as a string
///                  of double length, containing only hexadecimal digits.
///  - copy():       Return a copy (clone) of the hash object. This can be used to
///                  efficiently compute the digests of datas that share a common
///                  initial substring.
///
/// For example, to obtain the digest of the byte string 'Nobody inspects the
/// spammish repetition':
///
///     >>> import hashlib
///     >>> m = hashlib.md5()
///     >>> m.update(b"Nobody inspects")
///     >>> m.update(b" the spammish repetition")
///     >>> m.digest()
///     b'\\xbbd\\x9c\\x83\\xdd\\x1e\\xa5\\xc9\\xd9\\xde\\xc9\\xa1\\x8d\\xf0\\xff\\xe9'
///
/// More condensed:
///
///     >>> hashlib.sha224(b"Nobody inspects the spammish repetition").hexdigest()
///     'a4337bc45a8fc544c03f52dc550cd6e1e87021bc896588bd79e901e2'
///
/// """
///
/// # This tuple and __get_builtin_constructor() must be modified if a new
/// # always available algorithm is added.
/// __always_supported = ('md5', 'sha1', 'sha224', 'sha256', 'sha384', 'sha512',
///                       'blake2b', 'blake2s',
///                       'sha3_224', 'sha3_256', 'sha3_384', 'sha3_512',
///                       'shake_128', 'shake_256')
///
///
/// algorithms_guaranteed = set(__always_supported)
/// algorithms_available = set(__always_supported)
///
/// __all__ = __always_supported + ('new', 'algorithms_guaranteed',
///                                 'algorithms_available', 'pbkdf2_hmac', 'file_digest')
///
///
/// __builtin_constructor_cache = {}
///
/// # Prefer our blake2 implementation
/// # OpenSSL 1.1.0 comes with a limited implementation of blake2b/s. The OpenSSL
/// # implementations neither support keyed blake2 (blake2 MAC) nor advanced
/// # features like salt, personalization, or tree hashing. OpenSSL hash-only
/// # variants are available as 'blake2b512' and 'blake2s256', though.
/// __block_openssl_constructor = {
///     'blake2b', 'blake2s',
/// }
///
/// def __get_builtin_constructor(name):
///     cache = __builtin_constructor_cache
///     constructor = cache.get(name)
///     if constructor is not None:
///         return constructor
///     try:
///         if name in {'SHA1', 'sha1'}:
///             import _sha1
///             cache['SHA1'] = cache['sha1'] = _sha1.sha1
///         elif name in {'MD5', 'md5'}:
///             import _md5
///             cache['MD5'] = cache['md5'] = _md5.md5
///         elif name in {'SHA256', 'sha256', 'SHA224', 'sha224'}:
///             import _sha256
///             cache['SHA224'] = cache['sha224'] = _sha256.sha224
///             cache['SHA256'] = cache['sha256'] = _sha256.sha256
///         elif name in {'SHA512', 'sha512', 'SHA384', 'sha384'}:
///             import _sha512
///             cache['SHA384'] = cache['sha384'] = _sha512.sha384
///             cache['SHA512'] = cache['sha512'] = _sha512.sha512
///         elif name in {'blake2b', 'blake2s'}:
///             import _blake2
///             cache['blake2b'] = _blake2.blake2b
///             cache['blake2s'] = _blake2.blake2s
///         elif name in {'sha3_224', 'sha3_256', 'sha3_384', 'sha3_512'}:
///             import _sha3
///             cache['sha3_224'] = _sha3.sha3_224
///             cache['sha3_256'] = _sha3.sha3_256
///             cache['sha3_384'] = _sha3.sha3_384
///             cache['sha3_512'] = _sha3.sha3_512
///         elif name in {'shake_128', 'shake_256'}:
///             import _sha3
///             cache['shake_128'] = _sha3.shake_128
///             cache['shake_256'] = _sha3.shake_256
///     except ImportError:
///         pass  # no extension module, this hash is unsupported.
///
///     constructor = cache.get(name)
///     if constructor is not None:
///         return constructor
///
///     raise ValueError('unsupported hash type ' + name)
///
///
/// def __get_openssl_constructor(name):
///     if name in __block_openssl_constructor:
///         # Prefer our builtin blake2 implementation.
///         return __get_builtin_constructor(name)
///     try:
///         # MD5, SHA1, and SHA2 are in all supported OpenSSL versions
///         # SHA3/shake are available in OpenSSL 1.1.1+
///         f = getattr(_hashlib, 'openssl_' + name)
///         # Allow the C module to raise ValueError.  The function will be
///         # defined but the hash not actually available.  Don't fall back to
///         # builtin if the current security policy blocks a digest, bpo#40695.
///         f(usedforsecurity=False)
///         # Use the C function directly (very fast)
///         return f
///     except (AttributeError, ValueError):
///         return __get_builtin_constructor(name)
///
///
/// def __py_new(name, data=b'', **kwargs):
///     """new(name, data=b'', **kwargs) - Return a new hashing object using the
///     named algorithm; optionally initialized with data (which must be
///     a bytes-like object).
///     """
///     return __get_builtin_constructor(name)(data, **kwargs)
///
///
/// def __hash_new(name, data=b'', **kwargs):
///     """new(name, data=b'') - Return a new hashing object using the named algorithm;
///     optionally initialized with data (which must be a bytes-like object).
///     """
///     if name in __block_openssl_constructor:
///         # Prefer our builtin blake2 implementation.
///         return __get_builtin_constructor(name)(data, **kwargs)
///     try:
///         return _hashlib.new(name, data, **kwargs)
///     except ValueError:
///         # If the _hashlib module (OpenSSL) doesn't support the named
///         # hash, try using our builtin implementations.
///         # This allows for SHA224/256 and SHA384/512 support even though
///         # the OpenSSL library prior to 0.9.8 doesn't provide them.
///         return __get_builtin_constructor(name)(data)
///
///
/// try:
///     import _hashlib
///     new = __hash_new
///     __get_hash = __get_openssl_constructor
///     algorithms_available = algorithms_available.union(
///             _hashlib.openssl_md_meth_names)
/// except ImportError:
///     _hashlib = None
///     new = __py_new
///     __get_hash = __get_builtin_constructor
///
/// try:
///     # OpenSSL's PKCS5_PBKDF2_HMAC requires OpenSSL 1.0+ with HMAC and SHA
///     from _hashlib import pbkdf2_hmac
/// except ImportError:
///     from warnings import warn as _warn
///     _trans_5C = bytes((x ^ 0x5C) for x in range(256))
///     _trans_36 = bytes((x ^ 0x36) for x in range(256))
///
///     def pbkdf2_hmac(hash_name, password, salt, iterations, dklen=None):
///         """Password based key derivation function 2 (PKCS #5 v2.0)
///
///         This Python implementations based on the hmac module about as fast
///         as OpenSSL's PKCS5_PBKDF2_HMAC for short passwords and much faster
///         for long passwords.
///         """
///         _warn(
///             "Python implementation of pbkdf2_hmac() is deprecated.",
///             category=DeprecationWarning,
///             stacklevel=2
///         )
///         if not isinstance(hash_name, str):
///             raise TypeError(hash_name)
///
///         if not isinstance(password, (bytes, bytearray)):
///             password = bytes(memoryview(password))
///         if not isinstance(salt, (bytes, bytearray)):
///             salt = bytes(memoryview(salt))
///
///         # Fast inline HMAC implementation
///         inner = new(hash_name)
///         outer = new(hash_name)
///         blocksize = getattr(inner, 'block_size', 64)
///         if len(password) > blocksize:
///             password = new(hash_name, password).digest()
///         password = password + b'\x00' * (blocksize - len(password))
///         inner.update(password.translate(_trans_36))
///         outer.update(password.translate(_trans_5C))
///
///         def prf(msg, inner=inner, outer=outer):
///             # PBKDF2_HMAC uses the password as key. We can re-use the same
///             # digest objects and just update copies to skip initialization.
///             icpy = inner.copy()
///             ocpy = outer.copy()
///             icpy.update(msg)
///             ocpy.update(icpy.digest())
///             return ocpy.digest()
///
///         if iterations < 1:
///             raise ValueError(iterations)
///         if dklen is None:
///             dklen = outer.digest_size
///         if dklen < 1:
///             raise ValueError(dklen)
///
///         dkey = b''
///         loop = 1
///         from_bytes = int.from_bytes
///         while len(dkey) < dklen:
///             prev = prf(salt + loop.to_bytes(4))
///             # endianness doesn't matter here as long to / from use the same
///             rkey = from_bytes(prev)
///             for i in range(iterations - 1):
///                 prev = prf(prev)
///                 # rkey = rkey ^ prev
///                 rkey ^= from_bytes(prev)
///             loop += 1
///             dkey += rkey.to_bytes(inner.digest_size)
///
///         return dkey[:dklen]
///
/// try:
///     # OpenSSL's scrypt requires OpenSSL 1.1+
///     from _hashlib import scrypt
/// except ImportError:
///     pass
///
///
/// def file_digest(fileobj, digest, /, *, _bufsize=2**18):
///     """Hash the contents of a file-like object. Returns a digest object.
///
///     *fileobj* must be a file-like object opened for reading in binary mode.
///     It accepts file objects from open(), io.BytesIO(), and SocketIO objects.
///     The function may bypass Python's I/O and use the file descriptor *fileno*
///     directly.
///
///     *digest* must either be a hash algorithm name as a *str*, a hash
///     constructor, or a callable that returns a hash object.
///     """
///     # On Linux we could use AF_ALG sockets and sendfile() to archive zero-copy
///     # hashing with hardware acceleration.
///     if isinstance(digest, str):
///         digestobj = new(digest)
///     else:
///         digestobj = digest()
///
///     if hasattr(fileobj, "getbuffer"):
///         # io.BytesIO object, use zero-copy buffer
///         digestobj.update(fileobj.getbuffer())
///         return digestobj
///
///     # Only binary files implement readinto().
///     if not (
///         hasattr(fileobj, "readinto")
///         and hasattr(fileobj, "readable")
///         and fileobj.readable()
///     ):
///         raise ValueError(
///             f"'{fileobj!r}' is not a file-like object in binary reading mode."
///         )
///
///     # binary file, socket.SocketIO object
///     # Note: socket I/O uses different syscalls than file I/O.
///     buf = bytearray(_bufsize)  # Reusable buffer to reduce allocations.
///     view = memoryview(buf)
///     while True:
///         size = fileobj.readinto(buf)
///         if size == 0:
///             break  # EOF
///         digestobj.update(view[:size])
///
///     return digestobj
///
///
/// for __func_name in __always_supported:
///     # try them all, some may not work due to the OpenSSL
///     # version not supporting that algorithm.
///     try:
///         globals()[__func_name] = __get_hash(__func_name)
///     except ValueError:
///         import logging
///         logging.exception('code for hash %s was not found.', __func_name)
///
///
/// # Cleanup locals()
/// del __always_supported, __func_name, __get_hash
/// del __py_new, __hash_new, __get_openssl_constructor
/// ```
final class hashlib extends PythonModule {
  hashlib.from(super.pythonModule) : super.from();

  static hashlib import() => PythonFfiDart.instance.importModule(
        "hashlib",
        hashlib.from,
      );

  /// ## file_digest
  ///
  /// ### python docstring
  ///
  /// Hash the contents of a file-like object. Returns a digest object.
  ///
  /// *fileobj* must be a file-like object opened for reading in binary mode.
  /// It accepts file objects from open(), io.BytesIO(), and SocketIO objects.
  /// The function may bypass Python's I/O and use the file descriptor *fileno*
  /// directly.
  ///
  /// *digest* must either be a hash algorithm name as a *str*, a hash
  /// constructor, or a callable that returns a hash object.
  ///
  /// ### python source
  /// ```py
  /// def file_digest(fileobj, digest, /, *, _bufsize=2**18):
  ///     """Hash the contents of a file-like object. Returns a digest object.
  ///
  ///     *fileobj* must be a file-like object opened for reading in binary mode.
  ///     It accepts file objects from open(), io.BytesIO(), and SocketIO objects.
  ///     The function may bypass Python's I/O and use the file descriptor *fileno*
  ///     directly.
  ///
  ///     *digest* must either be a hash algorithm name as a *str*, a hash
  ///     constructor, or a callable that returns a hash object.
  ///     """
  ///     # On Linux we could use AF_ALG sockets and sendfile() to archive zero-copy
  ///     # hashing with hardware acceleration.
  ///     if isinstance(digest, str):
  ///         digestobj = new(digest)
  ///     else:
  ///         digestobj = digest()
  ///
  ///     if hasattr(fileobj, "getbuffer"):
  ///         # io.BytesIO object, use zero-copy buffer
  ///         digestobj.update(fileobj.getbuffer())
  ///         return digestobj
  ///
  ///     # Only binary files implement readinto().
  ///     if not (
  ///         hasattr(fileobj, "readinto")
  ///         and hasattr(fileobj, "readable")
  ///         and fileobj.readable()
  ///     ):
  ///         raise ValueError(
  ///             f"'{fileobj!r}' is not a file-like object in binary reading mode."
  ///         )
  ///
  ///     # binary file, socket.SocketIO object
  ///     # Note: socket I/O uses different syscalls than file I/O.
  ///     buf = bytearray(_bufsize)  # Reusable buffer to reduce allocations.
  ///     view = memoryview(buf)
  ///     while True:
  ///         size = fileobj.readinto(buf)
  ///         if size == 0:
  ///             break  # EOF
  ///         digestobj.update(view[:size])
  ///
  ///     return digestobj
  /// ```
  Object? file_digest(
    Object? fileobj,
    Object? digest, {
    Object? $_bufsize = 262144,
  }) =>
      getFunction("file_digest").call(
        <Object?>[
          fileobj,
          digest,
        ],
        kwargs: <String, Object?>{
          "_bufsize": $_bufsize,
        },
      );

  /// ## new
  ///
  /// ### python docstring
  ///
  /// new(name, data=b'', **kwargs) - Return a new hashing object using the
  /// named algorithm; optionally initialized with data (which must be
  /// a bytes-like object).
  ///
  /// ### python source
  /// ```py
  /// def __py_new(name, data=b'', **kwargs):
  ///     """new(name, data=b'', **kwargs) - Return a new hashing object using the
  ///     named algorithm; optionally initialized with data (which must be
  ///     a bytes-like object).
  ///     """
  ///     return __get_builtin_constructor(name)(data, **kwargs)
  /// ```
  Object? $new({
    required Object? name,
    Object? data = const [],
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("new").call(
        <Object?>[
          name,
          data,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## pbkdf2_hmac
  ///
  /// ### python docstring
  ///
  /// Password based key derivation function 2 (PKCS #5 v2.0)
  ///
  /// This Python implementations based on the hmac module about as fast
  /// as OpenSSL's PKCS5_PBKDF2_HMAC for short passwords and much faster
  /// for long passwords.
  Object? pbkdf2_hmac({
    required Object? hash_name,
    required Object? password,
    required Object? salt,
    required Object? iterations,
    Object? dklen,
  }) =>
      getFunction("pbkdf2_hmac").call(
        <Object?>[
          hash_name,
          password,
          salt,
          iterations,
          dklen,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## algorithms_available (getter)
  Object? get algorithms_available => getAttribute("algorithms_available");

  /// ## algorithms_available (setter)
  set algorithms_available(Object? algorithms_available) =>
      setAttribute("algorithms_available", algorithms_available);

  /// ## algorithms_guaranteed (getter)
  Object? get algorithms_guaranteed => getAttribute("algorithms_guaranteed");

  /// ## algorithms_guaranteed (setter)
  set algorithms_guaranteed(Object? algorithms_guaranteed) =>
      setAttribute("algorithms_guaranteed", algorithms_guaranteed);
}

/// ## pkgutil
///
/// ### python docstring
///
/// Utilities to support packages.
///
/// ### python source
/// ```py
/// """Utilities to support packages."""
///
/// from collections import namedtuple
/// from functools import singledispatch as simplegeneric
/// import importlib
/// import importlib.util
/// import importlib.machinery
/// import os
/// import os.path
/// import sys
/// from types import ModuleType
/// import warnings
///
/// __all__ = [
///     'get_importer', 'iter_importers', 'get_loader', 'find_loader',
///     'walk_packages', 'iter_modules', 'get_data',
///     'ImpImporter', 'ImpLoader', 'read_code', 'extend_path',
///     'ModuleInfo',
/// ]
///
///
/// ModuleInfo = namedtuple('ModuleInfo', 'module_finder name ispkg')
/// ModuleInfo.__doc__ = 'A namedtuple with minimal info about a module.'
///
///
/// def _get_spec(finder, name):
///     """Return the finder-specific module spec."""
///     # Works with legacy finders.
///     try:
///         find_spec = finder.find_spec
///     except AttributeError:
///         loader = finder.find_module(name)
///         if loader is None:
///             return None
///         return importlib.util.spec_from_loader(name, loader)
///     else:
///         return find_spec(name)
///
///
/// def read_code(stream):
///     # This helper is needed in order for the PEP 302 emulation to
///     # correctly handle compiled files
///     import marshal
///
///     magic = stream.read(4)
///     if magic != importlib.util.MAGIC_NUMBER:
///         return None
///
///     stream.read(12) # Skip rest of the header
///     return marshal.load(stream)
///
///
/// def walk_packages(path=None, prefix='', onerror=None):
///     """Yields ModuleInfo for all modules recursively
///     on path, or, if path is None, all accessible modules.
///
///     'path' should be either None or a list of paths to look for
///     modules in.
///
///     'prefix' is a string to output on the front of every module name
///     on output.
///
///     Note that this function must import all *packages* (NOT all
///     modules!) on the given path, in order to access the __path__
///     attribute to find submodules.
///
///     'onerror' is a function which gets called with one argument (the
///     name of the package which was being imported) if any exception
///     occurs while trying to import a package.  If no onerror function is
///     supplied, ImportErrors are caught and ignored, while all other
///     exceptions are propagated, terminating the search.
///
///     Examples:
///
///     # list all modules python can access
///     walk_packages()
///
///     # list all submodules of ctypes
///     walk_packages(ctypes.__path__, ctypes.__name__+'.')
///     """
///
///     def seen(p, m={}):
///         if p in m:
///             return True
///         m[p] = True
///
///     for info in iter_modules(path, prefix):
///         yield info
///
///         if info.ispkg:
///             try:
///                 __import__(info.name)
///             except ImportError:
///                 if onerror is not None:
///                     onerror(info.name)
///             except Exception:
///                 if onerror is not None:
///                     onerror(info.name)
///                 else:
///                     raise
///             else:
///                 path = getattr(sys.modules[info.name], '__path__', None) or []
///
///                 # don't traverse path items we've seen before
///                 path = [p for p in path if not seen(p)]
///
///                 yield from walk_packages(path, info.name+'.', onerror)
///
///
/// def iter_modules(path=None, prefix=''):
///     """Yields ModuleInfo for all submodules on path,
///     or, if path is None, all top-level modules on sys.path.
///
///     'path' should be either None or a list of paths to look for
///     modules in.
///
///     'prefix' is a string to output on the front of every module name
///     on output.
///     """
///     if path is None:
///         importers = iter_importers()
///     elif isinstance(path, str):
///         raise ValueError("path must be None or list of paths to look for "
///                         "modules in")
///     else:
///         importers = map(get_importer, path)
///
///     yielded = {}
///     for i in importers:
///         for name, ispkg in iter_importer_modules(i, prefix):
///             if name not in yielded:
///                 yielded[name] = 1
///                 yield ModuleInfo(i, name, ispkg)
///
///
/// @simplegeneric
/// def iter_importer_modules(importer, prefix=''):
///     if not hasattr(importer, 'iter_modules'):
///         return []
///     return importer.iter_modules(prefix)
///
///
/// # Implement a file walker for the normal importlib path hook
/// def _iter_file_finder_modules(importer, prefix=''):
///     if importer.path is None or not os.path.isdir(importer.path):
///         return
///
///     yielded = {}
///     import inspect
///     try:
///         filenames = os.listdir(importer.path)
///     except OSError:
///         # ignore unreadable directories like import does
///         filenames = []
///     filenames.sort()  # handle packages before same-named modules
///
///     for fn in filenames:
///         modname = inspect.getmodulename(fn)
///         if modname=='__init__' or modname in yielded:
///             continue
///
///         path = os.path.join(importer.path, fn)
///         ispkg = False
///
///         if not modname and os.path.isdir(path) and '.' not in fn:
///             modname = fn
///             try:
///                 dircontents = os.listdir(path)
///             except OSError:
///                 # ignore unreadable directories like import does
///                 dircontents = []
///             for fn in dircontents:
///                 subname = inspect.getmodulename(fn)
///                 if subname=='__init__':
///                     ispkg = True
///                     break
///             else:
///                 continue    # not a package
///
///         if modname and '.' not in modname:
///             yielded[modname] = 1
///             yield prefix + modname, ispkg
///
/// iter_importer_modules.register(
///     importlib.machinery.FileFinder, _iter_file_finder_modules)
///
///
/// def _import_imp():
///     global imp
///     with warnings.catch_warnings():
///         warnings.simplefilter('ignore', DeprecationWarning)
///         imp = importlib.import_module('imp')
///
/// class ImpImporter:
///     """PEP 302 Finder that wraps Python's "classic" import algorithm
///
///     ImpImporter(dirname) produces a PEP 302 finder that searches that
///     directory.  ImpImporter(None) produces a PEP 302 finder that searches
///     the current sys.path, plus any modules that are frozen or built-in.
///
///     Note that ImpImporter does not currently support being used by placement
///     on sys.meta_path.
///     """
///
///     def __init__(self, path=None):
///         global imp
///         warnings.warn("This emulation is deprecated and slated for removal "
///                       "in Python 3.12; use 'importlib' instead",
///              DeprecationWarning)
///         _import_imp()
///         self.path = path
///
///     def find_module(self, fullname, path=None):
///         # Note: we ignore 'path' argument since it is only used via meta_path
///         subname = fullname.split(".")[-1]
///         if subname != fullname and self.path is None:
///             return None
///         if self.path is None:
///             path = None
///         else:
///             path = [os.path.realpath(self.path)]
///         try:
///             file, filename, etc = imp.find_module(subname, path)
///         except ImportError:
///             return None
///         return ImpLoader(fullname, file, filename, etc)
///
///     def iter_modules(self, prefix=''):
///         if self.path is None or not os.path.isdir(self.path):
///             return
///
///         yielded = {}
///         import inspect
///         try:
///             filenames = os.listdir(self.path)
///         except OSError:
///             # ignore unreadable directories like import does
///             filenames = []
///         filenames.sort()  # handle packages before same-named modules
///
///         for fn in filenames:
///             modname = inspect.getmodulename(fn)
///             if modname=='__init__' or modname in yielded:
///                 continue
///
///             path = os.path.join(self.path, fn)
///             ispkg = False
///
///             if not modname and os.path.isdir(path) and '.' not in fn:
///                 modname = fn
///                 try:
///                     dircontents = os.listdir(path)
///                 except OSError:
///                     # ignore unreadable directories like import does
///                     dircontents = []
///                 for fn in dircontents:
///                     subname = inspect.getmodulename(fn)
///                     if subname=='__init__':
///                         ispkg = True
///                         break
///                 else:
///                     continue    # not a package
///
///             if modname and '.' not in modname:
///                 yielded[modname] = 1
///                 yield prefix + modname, ispkg
///
///
/// class ImpLoader:
///     """PEP 302 Loader that wraps Python's "classic" import algorithm
///     """
///     code = source = None
///
///     def __init__(self, fullname, file, filename, etc):
///         warnings.warn("This emulation is deprecated and slated for removal in "
///                       "Python 3.12; use 'importlib' instead",
///                       DeprecationWarning)
///         _import_imp()
///         self.file = file
///         self.filename = filename
///         self.fullname = fullname
///         self.etc = etc
///
///     def load_module(self, fullname):
///         self._reopen()
///         try:
///             mod = imp.load_module(fullname, self.file, self.filename, self.etc)
///         finally:
///             if self.file:
///                 self.file.close()
///         # Note: we don't set __loader__ because we want the module to look
///         # normal; i.e. this is just a wrapper for standard import machinery
///         return mod
///
///     def get_data(self, pathname):
///         with open(pathname, "rb") as file:
///             return file.read()
///
///     def _reopen(self):
///         if self.file and self.file.closed:
///             mod_type = self.etc[2]
///             if mod_type==imp.PY_SOURCE:
///                 self.file = open(self.filename, 'r')
///             elif mod_type in (imp.PY_COMPILED, imp.C_EXTENSION):
///                 self.file = open(self.filename, 'rb')
///
///     def _fix_name(self, fullname):
///         if fullname is None:
///             fullname = self.fullname
///         elif fullname != self.fullname:
///             raise ImportError("Loader for module %s cannot handle "
///                               "module %s" % (self.fullname, fullname))
///         return fullname
///
///     def is_package(self, fullname):
///         fullname = self._fix_name(fullname)
///         return self.etc[2]==imp.PKG_DIRECTORY
///
///     def get_code(self, fullname=None):
///         fullname = self._fix_name(fullname)
///         if self.code is None:
///             mod_type = self.etc[2]
///             if mod_type==imp.PY_SOURCE:
///                 source = self.get_source(fullname)
///                 self.code = compile(source, self.filename, 'exec')
///             elif mod_type==imp.PY_COMPILED:
///                 self._reopen()
///                 try:
///                     self.code = read_code(self.file)
///                 finally:
///                     self.file.close()
///             elif mod_type==imp.PKG_DIRECTORY:
///                 self.code = self._get_delegate().get_code()
///         return self.code
///
///     def get_source(self, fullname=None):
///         fullname = self._fix_name(fullname)
///         if self.source is None:
///             mod_type = self.etc[2]
///             if mod_type==imp.PY_SOURCE:
///                 self._reopen()
///                 try:
///                     self.source = self.file.read()
///                 finally:
///                     self.file.close()
///             elif mod_type==imp.PY_COMPILED:
///                 if os.path.exists(self.filename[:-1]):
///                     with open(self.filename[:-1], 'r') as f:
///                         self.source = f.read()
///             elif mod_type==imp.PKG_DIRECTORY:
///                 self.source = self._get_delegate().get_source()
///         return self.source
///
///     def _get_delegate(self):
///         finder = ImpImporter(self.filename)
///         spec = _get_spec(finder, '__init__')
///         return spec.loader
///
///     def get_filename(self, fullname=None):
///         fullname = self._fix_name(fullname)
///         mod_type = self.etc[2]
///         if mod_type==imp.PKG_DIRECTORY:
///             return self._get_delegate().get_filename()
///         elif mod_type in (imp.PY_SOURCE, imp.PY_COMPILED, imp.C_EXTENSION):
///             return self.filename
///         return None
///
///
/// try:
///     import zipimport
///     from zipimport import zipimporter
///
///     def iter_zipimport_modules(importer, prefix=''):
///         dirlist = sorted(zipimport._zip_directory_cache[importer.archive])
///         _prefix = importer.prefix
///         plen = len(_prefix)
///         yielded = {}
///         import inspect
///         for fn in dirlist:
///             if not fn.startswith(_prefix):
///                 continue
///
///             fn = fn[plen:].split(os.sep)
///
///             if len(fn)==2 and fn[1].startswith('__init__.py'):
///                 if fn[0] not in yielded:
///                     yielded[fn[0]] = 1
///                     yield prefix + fn[0], True
///
///             if len(fn)!=1:
///                 continue
///
///             modname = inspect.getmodulename(fn[0])
///             if modname=='__init__':
///                 continue
///
///             if modname and '.' not in modname and modname not in yielded:
///                 yielded[modname] = 1
///                 yield prefix + modname, False
///
///     iter_importer_modules.register(zipimporter, iter_zipimport_modules)
///
/// except ImportError:
///     pass
///
///
/// def get_importer(path_item):
///     """Retrieve a finder for the given path item
///
///     The returned finder is cached in sys.path_importer_cache
///     if it was newly created by a path hook.
///
///     The cache (or part of it) can be cleared manually if a
///     rescan of sys.path_hooks is necessary.
///     """
///     path_item = os.fsdecode(path_item)
///     try:
///         importer = sys.path_importer_cache[path_item]
///     except KeyError:
///         for path_hook in sys.path_hooks:
///             try:
///                 importer = path_hook(path_item)
///                 sys.path_importer_cache.setdefault(path_item, importer)
///                 break
///             except ImportError:
///                 pass
///         else:
///             importer = None
///     return importer
///
///
/// def iter_importers(fullname=""):
///     """Yield finders for the given module name
///
///     If fullname contains a '.', the finders will be for the package
///     containing fullname, otherwise they will be all registered top level
///     finders (i.e. those on both sys.meta_path and sys.path_hooks).
///
///     If the named module is in a package, that package is imported as a side
///     effect of invoking this function.
///
///     If no module name is specified, all top level finders are produced.
///     """
///     if fullname.startswith('.'):
///         msg = "Relative module name {!r} not supported".format(fullname)
///         raise ImportError(msg)
///     if '.' in fullname:
///         # Get the containing package's __path__
///         pkg_name = fullname.rpartition(".")[0]
///         pkg = importlib.import_module(pkg_name)
///         path = getattr(pkg, '__path__', None)
///         if path is None:
///             return
///     else:
///         yield from sys.meta_path
///         path = sys.path
///     for item in path:
///         yield get_importer(item)
///
///
/// def get_loader(module_or_name):
///     """Get a "loader" object for module_or_name
///
///     Returns None if the module cannot be found or imported.
///     If the named module is not already imported, its containing package
///     (if any) is imported, in order to establish the package __path__.
///     """
///     if module_or_name in sys.modules:
///         module_or_name = sys.modules[module_or_name]
///         if module_or_name is None:
///             return None
///     if isinstance(module_or_name, ModuleType):
///         module = module_or_name
///         loader = getattr(module, '__loader__', None)
///         if loader is not None:
///             return loader
///         if getattr(module, '__spec__', None) is None:
///             return None
///         fullname = module.__name__
///     else:
///         fullname = module_or_name
///     return find_loader(fullname)
///
///
/// def find_loader(fullname):
///     """Find a "loader" object for fullname
///
///     This is a backwards compatibility wrapper around
///     importlib.util.find_spec that converts most failures to ImportError
///     and only returns the loader rather than the full spec
///     """
///     if fullname.startswith('.'):
///         msg = "Relative module name {!r} not supported".format(fullname)
///         raise ImportError(msg)
///     try:
///         spec = importlib.util.find_spec(fullname)
///     except (ImportError, AttributeError, TypeError, ValueError) as ex:
///         # This hack fixes an impedance mismatch between pkgutil and
///         # importlib, where the latter raises other errors for cases where
///         # pkgutil previously raised ImportError
///         msg = "Error while finding loader for {!r} ({}: {})"
///         raise ImportError(msg.format(fullname, type(ex), ex)) from ex
///     return spec.loader if spec is not None else None
///
///
/// def extend_path(path, name):
///     """Extend a package's path.
///
///     Intended use is to place the following code in a package's __init__.py:
///
///         from pkgutil import extend_path
///         __path__ = extend_path(__path__, __name__)
///
///     This will add to the package's __path__ all subdirectories of
///     directories on sys.path named after the package.  This is useful
///     if one wants to distribute different parts of a single logical
///     package as multiple directories.
///
///     It also looks for *.pkg files beginning where * matches the name
///     argument.  This feature is similar to *.pth files (see site.py),
///     except that it doesn't special-case lines starting with 'import'.
///     A *.pkg file is trusted at face value: apart from checking for
///     duplicates, all entries found in a *.pkg file are added to the
///     path, regardless of whether they are exist the filesystem.  (This
///     is a feature.)
///
///     If the input path is not a list (as is the case for frozen
///     packages) it is returned unchanged.  The input path is not
///     modified; an extended copy is returned.  Items are only appended
///     to the copy at the end.
///
///     It is assumed that sys.path is a sequence.  Items of sys.path that
///     are not (unicode or 8-bit) strings referring to existing
///     directories are ignored.  Unicode items of sys.path that cause
///     errors when used as filenames may cause this function to raise an
///     exception (in line with os.path.isdir() behavior).
///     """
///
///     if not isinstance(path, list):
///         # This could happen e.g. when this is called from inside a
///         # frozen package.  Return the path unchanged in that case.
///         return path
///
///     sname_pkg = name + ".pkg"
///
///     path = path[:] # Start with a copy of the existing path
///
///     parent_package, _, final_name = name.rpartition('.')
///     if parent_package:
///         try:
///             search_path = sys.modules[parent_package].__path__
///         except (KeyError, AttributeError):
///             # We can't do anything: find_loader() returns None when
///             # passed a dotted name.
///             return path
///     else:
///         search_path = sys.path
///
///     for dir in search_path:
///         if not isinstance(dir, str):
///             continue
///
///         finder = get_importer(dir)
///         if finder is not None:
///             portions = []
///             if hasattr(finder, 'find_spec'):
///                 spec = finder.find_spec(final_name)
///                 if spec is not None:
///                     portions = spec.submodule_search_locations or []
///             # Is this finder PEP 420 compliant?
///             elif hasattr(finder, 'find_loader'):
///                 _, portions = finder.find_loader(final_name)
///
///             for portion in portions:
///                 # XXX This may still add duplicate entries to path on
///                 # case-insensitive filesystems
///                 if portion not in path:
///                     path.append(portion)
///
///         # XXX Is this the right thing for subpackages like zope.app?
///         # It looks for a file named "zope.app.pkg"
///         pkgfile = os.path.join(dir, sname_pkg)
///         if os.path.isfile(pkgfile):
///             try:
///                 f = open(pkgfile)
///             except OSError as msg:
///                 sys.stderr.write("Can't open %s: %s\n" %
///                                  (pkgfile, msg))
///             else:
///                 with f:
///                     for line in f:
///                         line = line.rstrip('\n')
///                         if not line or line.startswith('#'):
///                             continue
///                         path.append(line) # Don't check for existence!
///
///     return path
///
///
/// def get_data(package, resource):
///     """Get a resource from a package.
///
///     This is a wrapper round the PEP 302 loader get_data API. The package
///     argument should be the name of a package, in standard module format
///     (foo.bar). The resource argument should be in the form of a relative
///     filename, using '/' as the path separator. The parent directory name '..'
///     is not allowed, and nor is a rooted name (starting with a '/').
///
///     The function returns a binary string, which is the contents of the
///     specified resource.
///
///     For packages located in the filesystem, which have already been imported,
///     this is the rough equivalent of
///
///         d = os.path.dirname(sys.modules[package].__file__)
///         data = open(os.path.join(d, resource), 'rb').read()
///
///     If the package cannot be located or loaded, or it uses a PEP 302 loader
///     which does not support get_data(), then None is returned.
///     """
///
///     spec = importlib.util.find_spec(package)
///     if spec is None:
///         return None
///     loader = spec.loader
///     if loader is None or not hasattr(loader, 'get_data'):
///         return None
///     # XXX needs test
///     mod = (sys.modules.get(package) or
///            importlib._bootstrap._load(spec))
///     if mod is None or not hasattr(mod, '__file__'):
///         return None
///
///     # Modify the resource name to be compatible with the loader.get_data
///     # signature - an os.path format "filename" starting with the dirname of
///     # the package's __file__
///     parts = resource.split('/')
///     parts.insert(0, os.path.dirname(mod.__file__))
///     resource_name = os.path.join(*parts)
///     return loader.get_data(resource_name)
///
///
/// _NAME_PATTERN = None
///
/// def resolve_name(name):
///     """
///     Resolve a name to an object.
///
///     It is expected that `name` will be a string in one of the following
///     formats, where W is shorthand for a valid Python identifier and dot stands
///     for a literal period in these pseudo-regexes:
///
///     W(.W)*
///     W(.W)*:(W(.W)*)?
///
///     The first form is intended for backward compatibility only. It assumes that
///     some part of the dotted name is a package, and the rest is an object
///     somewhere within that package, possibly nested inside other objects.
///     Because the place where the package stops and the object hierarchy starts
///     can't be inferred by inspection, repeated attempts to import must be done
///     with this form.
///
///     In the second form, the caller makes the division point clear through the
///     provision of a single colon: the dotted name to the left of the colon is a
///     package to be imported, and the dotted name to the right is the object
///     hierarchy within that package. Only one import is needed in this form. If
///     it ends with the colon, then a module object is returned.
///
///     The function will return an object (which might be a module), or raise one
///     of the following exceptions:
///
///     ValueError - if `name` isn't in a recognised format
///     ImportError - if an import failed when it shouldn't have
///     AttributeError - if a failure occurred when traversing the object hierarchy
///                      within the imported package to get to the desired object.
///     """
///     global _NAME_PATTERN
///     if _NAME_PATTERN is None:
///         # Lazy import to speedup Python startup time
///         import re
///         dotted_words = r'(?!\d)(\w+)(\.(?!\d)(\w+))*'
///         _NAME_PATTERN = re.compile(f'^(?P<pkg>{dotted_words})'
///                                    f'(?P<cln>:(?P<obj>{dotted_words})?)?$',
///                                    re.UNICODE)
///
///     m = _NAME_PATTERN.match(name)
///     if not m:
///         raise ValueError(f'invalid format: {name!r}')
///     gd = m.groupdict()
///     if gd.get('cln'):
///         # there is a colon - a one-step import is all that's needed
///         mod = importlib.import_module(gd['pkg'])
///         parts = gd.get('obj')
///         parts = parts.split('.') if parts else []
///     else:
///         # no colon - have to iterate to find the package boundary
///         parts = name.split('.')
///         modname = parts.pop(0)
///         # first part *must* be a module/package.
///         mod = importlib.import_module(modname)
///         while parts:
///             p = parts[0]
///             s = f'{modname}.{p}'
///             try:
///                 mod = importlib.import_module(s)
///                 parts.pop(0)
///                 modname = s
///             except ImportError:
///                 break
///     # if we reach this point, mod is the module, already imported, and
///     # parts is the list of parts in the object hierarchy to be traversed, or
///     # an empty list if just the module is wanted.
///     result = mod
///     for p in parts:
///         result = getattr(result, p)
///     return result
/// ```
final class pkgutil extends PythonModule {
  pkgutil.from(super.pythonModule) : super.from();

  static pkgutil import() => PythonFfiDart.instance.importModule(
        "pkgutil",
        pkgutil.from,
      );

  /// ## extend_path
  ///
  /// ### python docstring
  ///
  /// Extend a package's path.
  ///
  /// Intended use is to place the following code in a package's __init__.py:
  ///
  ///     from pkgutil import extend_path
  ///     __path__ = extend_path(__path__, __name__)
  ///
  /// This will add to the package's __path__ all subdirectories of
  /// directories on sys.path named after the package.  This is useful
  /// if one wants to distribute different parts of a single logical
  /// package as multiple directories.
  ///
  /// It also looks for *.pkg files beginning where * matches the name
  /// argument.  This feature is similar to *.pth files (see site.py),
  /// except that it doesn't special-case lines starting with 'import'.
  /// A *.pkg file is trusted at face value: apart from checking for
  /// duplicates, all entries found in a *.pkg file are added to the
  /// path, regardless of whether they are exist the filesystem.  (This
  /// is a feature.)
  ///
  /// If the input path is not a list (as is the case for frozen
  /// packages) it is returned unchanged.  The input path is not
  /// modified; an extended copy is returned.  Items are only appended
  /// to the copy at the end.
  ///
  /// It is assumed that sys.path is a sequence.  Items of sys.path that
  /// are not (unicode or 8-bit) strings referring to existing
  /// directories are ignored.  Unicode items of sys.path that cause
  /// errors when used as filenames may cause this function to raise an
  /// exception (in line with os.path.isdir() behavior).
  ///
  /// ### python source
  /// ```py
  /// def extend_path(path, name):
  ///     """Extend a package's path.
  ///
  ///     Intended use is to place the following code in a package's __init__.py:
  ///
  ///         from pkgutil import extend_path
  ///         __path__ = extend_path(__path__, __name__)
  ///
  ///     This will add to the package's __path__ all subdirectories of
  ///     directories on sys.path named after the package.  This is useful
  ///     if one wants to distribute different parts of a single logical
  ///     package as multiple directories.
  ///
  ///     It also looks for *.pkg files beginning where * matches the name
  ///     argument.  This feature is similar to *.pth files (see site.py),
  ///     except that it doesn't special-case lines starting with 'import'.
  ///     A *.pkg file is trusted at face value: apart from checking for
  ///     duplicates, all entries found in a *.pkg file are added to the
  ///     path, regardless of whether they are exist the filesystem.  (This
  ///     is a feature.)
  ///
  ///     If the input path is not a list (as is the case for frozen
  ///     packages) it is returned unchanged.  The input path is not
  ///     modified; an extended copy is returned.  Items are only appended
  ///     to the copy at the end.
  ///
  ///     It is assumed that sys.path is a sequence.  Items of sys.path that
  ///     are not (unicode or 8-bit) strings referring to existing
  ///     directories are ignored.  Unicode items of sys.path that cause
  ///     errors when used as filenames may cause this function to raise an
  ///     exception (in line with os.path.isdir() behavior).
  ///     """
  ///
  ///     if not isinstance(path, list):
  ///         # This could happen e.g. when this is called from inside a
  ///         # frozen package.  Return the path unchanged in that case.
  ///         return path
  ///
  ///     sname_pkg = name + ".pkg"
  ///
  ///     path = path[:] # Start with a copy of the existing path
  ///
  ///     parent_package, _, final_name = name.rpartition('.')
  ///     if parent_package:
  ///         try:
  ///             search_path = sys.modules[parent_package].__path__
  ///         except (KeyError, AttributeError):
  ///             # We can't do anything: find_loader() returns None when
  ///             # passed a dotted name.
  ///             return path
  ///     else:
  ///         search_path = sys.path
  ///
  ///     for dir in search_path:
  ///         if not isinstance(dir, str):
  ///             continue
  ///
  ///         finder = get_importer(dir)
  ///         if finder is not None:
  ///             portions = []
  ///             if hasattr(finder, 'find_spec'):
  ///                 spec = finder.find_spec(final_name)
  ///                 if spec is not None:
  ///                     portions = spec.submodule_search_locations or []
  ///             # Is this finder PEP 420 compliant?
  ///             elif hasattr(finder, 'find_loader'):
  ///                 _, portions = finder.find_loader(final_name)
  ///
  ///             for portion in portions:
  ///                 # XXX This may still add duplicate entries to path on
  ///                 # case-insensitive filesystems
  ///                 if portion not in path:
  ///                     path.append(portion)
  ///
  ///         # XXX Is this the right thing for subpackages like zope.app?
  ///         # It looks for a file named "zope.app.pkg"
  ///         pkgfile = os.path.join(dir, sname_pkg)
  ///         if os.path.isfile(pkgfile):
  ///             try:
  ///                 f = open(pkgfile)
  ///             except OSError as msg:
  ///                 sys.stderr.write("Can't open %s: %s\n" %
  ///                                  (pkgfile, msg))
  ///             else:
  ///                 with f:
  ///                     for line in f:
  ///                         line = line.rstrip('\n')
  ///                         if not line or line.startswith('#'):
  ///                             continue
  ///                         path.append(line) # Don't check for existence!
  ///
  ///     return path
  /// ```
  Object? extend_path({
    required Object? path,
    required Object? name,
  }) =>
      getFunction("extend_path").call(
        <Object?>[
          path,
          name,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## find_loader
  ///
  /// ### python docstring
  ///
  /// Find a "loader" object for fullname
  ///
  /// This is a backwards compatibility wrapper around
  /// importlib.util.find_spec that converts most failures to ImportError
  /// and only returns the loader rather than the full spec
  ///
  /// ### python source
  /// ```py
  /// def find_loader(fullname):
  ///     """Find a "loader" object for fullname
  ///
  ///     This is a backwards compatibility wrapper around
  ///     importlib.util.find_spec that converts most failures to ImportError
  ///     and only returns the loader rather than the full spec
  ///     """
  ///     if fullname.startswith('.'):
  ///         msg = "Relative module name {!r} not supported".format(fullname)
  ///         raise ImportError(msg)
  ///     try:
  ///         spec = importlib.util.find_spec(fullname)
  ///     except (ImportError, AttributeError, TypeError, ValueError) as ex:
  ///         # This hack fixes an impedance mismatch between pkgutil and
  ///         # importlib, where the latter raises other errors for cases where
  ///         # pkgutil previously raised ImportError
  ///         msg = "Error while finding loader for {!r} ({}: {})"
  ///         raise ImportError(msg.format(fullname, type(ex), ex)) from ex
  ///     return spec.loader if spec is not None else None
  /// ```
  Object? find_loader({
    required Object? fullname,
  }) =>
      getFunction("find_loader").call(
        <Object?>[
          fullname,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## get_data
  ///
  /// ### python docstring
  ///
  /// Get a resource from a package.
  ///
  /// This is a wrapper round the PEP 302 loader get_data API. The package
  /// argument should be the name of a package, in standard module format
  /// (foo.bar). The resource argument should be in the form of a relative
  /// filename, using '/' as the path separator. The parent directory name '..'
  /// is not allowed, and nor is a rooted name (starting with a '/').
  ///
  /// The function returns a binary string, which is the contents of the
  /// specified resource.
  ///
  /// For packages located in the filesystem, which have already been imported,
  /// this is the rough equivalent of
  ///
  ///     d = os.path.dirname(sys.modules[package].__file__)
  ///     data = open(os.path.join(d, resource), 'rb').read()
  ///
  /// If the package cannot be located or loaded, or it uses a PEP 302 loader
  /// which does not support get_data(), then None is returned.
  ///
  /// ### python source
  /// ```py
  /// def get_data(package, resource):
  ///     """Get a resource from a package.
  ///
  ///     This is a wrapper round the PEP 302 loader get_data API. The package
  ///     argument should be the name of a package, in standard module format
  ///     (foo.bar). The resource argument should be in the form of a relative
  ///     filename, using '/' as the path separator. The parent directory name '..'
  ///     is not allowed, and nor is a rooted name (starting with a '/').
  ///
  ///     The function returns a binary string, which is the contents of the
  ///     specified resource.
  ///
  ///     For packages located in the filesystem, which have already been imported,
  ///     this is the rough equivalent of
  ///
  ///         d = os.path.dirname(sys.modules[package].__file__)
  ///         data = open(os.path.join(d, resource), 'rb').read()
  ///
  ///     If the package cannot be located or loaded, or it uses a PEP 302 loader
  ///     which does not support get_data(), then None is returned.
  ///     """
  ///
  ///     spec = importlib.util.find_spec(package)
  ///     if spec is None:
  ///         return None
  ///     loader = spec.loader
  ///     if loader is None or not hasattr(loader, 'get_data'):
  ///         return None
  ///     # XXX needs test
  ///     mod = (sys.modules.get(package) or
  ///            importlib._bootstrap._load(spec))
  ///     if mod is None or not hasattr(mod, '__file__'):
  ///         return None
  ///
  ///     # Modify the resource name to be compatible with the loader.get_data
  ///     # signature - an os.path format "filename" starting with the dirname of
  ///     # the package's __file__
  ///     parts = resource.split('/')
  ///     parts.insert(0, os.path.dirname(mod.__file__))
  ///     resource_name = os.path.join(*parts)
  ///     return loader.get_data(resource_name)
  /// ```
  Object? get_data({
    required Object? package,
    required Object? resource,
  }) =>
      getFunction("get_data").call(
        <Object?>[
          package,
          resource,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## get_importer
  ///
  /// ### python docstring
  ///
  /// Retrieve a finder for the given path item
  ///
  /// The returned finder is cached in sys.path_importer_cache
  /// if it was newly created by a path hook.
  ///
  /// The cache (or part of it) can be cleared manually if a
  /// rescan of sys.path_hooks is necessary.
  ///
  /// ### python source
  /// ```py
  /// def get_importer(path_item):
  ///     """Retrieve a finder for the given path item
  ///
  ///     The returned finder is cached in sys.path_importer_cache
  ///     if it was newly created by a path hook.
  ///
  ///     The cache (or part of it) can be cleared manually if a
  ///     rescan of sys.path_hooks is necessary.
  ///     """
  ///     path_item = os.fsdecode(path_item)
  ///     try:
  ///         importer = sys.path_importer_cache[path_item]
  ///     except KeyError:
  ///         for path_hook in sys.path_hooks:
  ///             try:
  ///                 importer = path_hook(path_item)
  ///                 sys.path_importer_cache.setdefault(path_item, importer)
  ///                 break
  ///             except ImportError:
  ///                 pass
  ///         else:
  ///             importer = None
  ///     return importer
  /// ```
  Object? get_importer({
    required Object? path_item,
  }) =>
      getFunction("get_importer").call(
        <Object?>[
          path_item,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## get_loader
  ///
  /// ### python docstring
  ///
  /// Get a "loader" object for module_or_name
  ///
  /// Returns None if the module cannot be found or imported.
  /// If the named module is not already imported, its containing package
  /// (if any) is imported, in order to establish the package __path__.
  ///
  /// ### python source
  /// ```py
  /// def get_loader(module_or_name):
  ///     """Get a "loader" object for module_or_name
  ///
  ///     Returns None if the module cannot be found or imported.
  ///     If the named module is not already imported, its containing package
  ///     (if any) is imported, in order to establish the package __path__.
  ///     """
  ///     if module_or_name in sys.modules:
  ///         module_or_name = sys.modules[module_or_name]
  ///         if module_or_name is None:
  ///             return None
  ///     if isinstance(module_or_name, ModuleType):
  ///         module = module_or_name
  ///         loader = getattr(module, '__loader__', None)
  ///         if loader is not None:
  ///             return loader
  ///         if getattr(module, '__spec__', None) is None:
  ///             return None
  ///         fullname = module.__name__
  ///     else:
  ///         fullname = module_or_name
  ///     return find_loader(fullname)
  /// ```
  Object? get_loader({
    required Object? module_or_name,
  }) =>
      getFunction("get_loader").call(
        <Object?>[
          module_or_name,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## iter_importer_modules
  ///
  /// ### python source
  /// ```py
  /// @simplegeneric
  /// def iter_importer_modules(importer, prefix=''):
  ///     if not hasattr(importer, 'iter_modules'):
  ///         return []
  ///     return importer.iter_modules(prefix)
  /// ```
  Object? iter_importer_modules({
    required Object? importer,
    Object? prefix = "",
  }) =>
      getFunction("iter_importer_modules").call(
        <Object?>[
          importer,
          prefix,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## iter_importers
  ///
  /// ### python docstring
  ///
  /// Yield finders for the given module name
  ///
  /// If fullname contains a '.', the finders will be for the package
  /// containing fullname, otherwise they will be all registered top level
  /// finders (i.e. those on both sys.meta_path and sys.path_hooks).
  ///
  /// If the named module is in a package, that package is imported as a side
  /// effect of invoking this function.
  ///
  /// If no module name is specified, all top level finders are produced.
  ///
  /// ### python source
  /// ```py
  /// def iter_importers(fullname=""):
  ///     """Yield finders for the given module name
  ///
  ///     If fullname contains a '.', the finders will be for the package
  ///     containing fullname, otherwise they will be all registered top level
  ///     finders (i.e. those on both sys.meta_path and sys.path_hooks).
  ///
  ///     If the named module is in a package, that package is imported as a side
  ///     effect of invoking this function.
  ///
  ///     If no module name is specified, all top level finders are produced.
  ///     """
  ///     if fullname.startswith('.'):
  ///         msg = "Relative module name {!r} not supported".format(fullname)
  ///         raise ImportError(msg)
  ///     if '.' in fullname:
  ///         # Get the containing package's __path__
  ///         pkg_name = fullname.rpartition(".")[0]
  ///         pkg = importlib.import_module(pkg_name)
  ///         path = getattr(pkg, '__path__', None)
  ///         if path is None:
  ///             return
  ///     else:
  ///         yield from sys.meta_path
  ///         path = sys.path
  ///     for item in path:
  ///         yield get_importer(item)
  /// ```
  Object? iter_importers({
    Object? fullname = "",
  }) =>
      getFunction("iter_importers").call(
        <Object?>[
          fullname,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## iter_modules
  ///
  /// ### python docstring
  ///
  /// Yields ModuleInfo for all submodules on path,
  /// or, if path is None, all top-level modules on sys.path.
  ///
  /// 'path' should be either None or a list of paths to look for
  /// modules in.
  ///
  /// 'prefix' is a string to output on the front of every module name
  /// on output.
  ///
  /// ### python source
  /// ```py
  /// def iter_modules(path=None, prefix=''):
  ///     """Yields ModuleInfo for all submodules on path,
  ///     or, if path is None, all top-level modules on sys.path.
  ///
  ///     'path' should be either None or a list of paths to look for
  ///     modules in.
  ///
  ///     'prefix' is a string to output on the front of every module name
  ///     on output.
  ///     """
  ///     if path is None:
  ///         importers = iter_importers()
  ///     elif isinstance(path, str):
  ///         raise ValueError("path must be None or list of paths to look for "
  ///                         "modules in")
  ///     else:
  ///         importers = map(get_importer, path)
  ///
  ///     yielded = {}
  ///     for i in importers:
  ///         for name, ispkg in iter_importer_modules(i, prefix):
  ///             if name not in yielded:
  ///                 yielded[name] = 1
  ///                 yield ModuleInfo(i, name, ispkg)
  /// ```
  Object? iter_modules({
    Object? path,
    Object? prefix = "",
  }) =>
      getFunction("iter_modules").call(
        <Object?>[
          path,
          prefix,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## iter_zipimport_modules
  ///
  /// ### python source
  /// ```py
  /// def iter_zipimport_modules(importer, prefix=''):
  ///         dirlist = sorted(zipimport._zip_directory_cache[importer.archive])
  ///         _prefix = importer.prefix
  ///         plen = len(_prefix)
  ///         yielded = {}
  ///         import inspect
  ///         for fn in dirlist:
  ///             if not fn.startswith(_prefix):
  ///                 continue
  ///
  ///             fn = fn[plen:].split(os.sep)
  ///
  ///             if len(fn)==2 and fn[1].startswith('__init__.py'):
  ///                 if fn[0] not in yielded:
  ///                     yielded[fn[0]] = 1
  ///                     yield prefix + fn[0], True
  ///
  ///             if len(fn)!=1:
  ///                 continue
  ///
  ///             modname = inspect.getmodulename(fn[0])
  ///             if modname=='__init__':
  ///                 continue
  ///
  ///             if modname and '.' not in modname and modname not in yielded:
  ///                 yielded[modname] = 1
  ///                 yield prefix + modname, False
  /// ```
  Object? iter_zipimport_modules({
    required Object? importer,
    Object? prefix = "",
  }) =>
      getFunction("iter_zipimport_modules").call(
        <Object?>[
          importer,
          prefix,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## read_code
  ///
  /// ### python source
  /// ```py
  /// def read_code(stream):
  ///     # This helper is needed in order for the PEP 302 emulation to
  ///     # correctly handle compiled files
  ///     import marshal
  ///
  ///     magic = stream.read(4)
  ///     if magic != importlib.util.MAGIC_NUMBER:
  ///         return None
  ///
  ///     stream.read(12) # Skip rest of the header
  ///     return marshal.load(stream)
  /// ```
  Object? read_code({
    required Object? stream,
  }) =>
      getFunction("read_code").call(
        <Object?>[
          stream,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## resolve_name
  ///
  /// ### python docstring
  ///
  /// Resolve a name to an object.
  ///
  /// It is expected that `name` will be a string in one of the following
  /// formats, where W is shorthand for a valid Python identifier and dot stands
  /// for a literal period in these pseudo-regexes:
  ///
  /// W(.W)*
  /// W(.W)*:(W(.W)*)?
  ///
  /// The first form is intended for backward compatibility only. It assumes that
  /// some part of the dotted name is a package, and the rest is an object
  /// somewhere within that package, possibly nested inside other objects.
  /// Because the place where the package stops and the object hierarchy starts
  /// can't be inferred by inspection, repeated attempts to import must be done
  /// with this form.
  ///
  /// In the second form, the caller makes the division point clear through the
  /// provision of a single colon: the dotted name to the left of the colon is a
  /// package to be imported, and the dotted name to the right is the object
  /// hierarchy within that package. Only one import is needed in this form. If
  /// it ends with the colon, then a module object is returned.
  ///
  /// The function will return an object (which might be a module), or raise one
  /// of the following exceptions:
  ///
  /// ValueError - if `name` isn't in a recognised format
  /// ImportError - if an import failed when it shouldn't have
  /// AttributeError - if a failure occurred when traversing the object hierarchy
  ///                  within the imported package to get to the desired object.
  ///
  /// ### python source
  /// ```py
  /// def resolve_name(name):
  ///     """
  ///     Resolve a name to an object.
  ///
  ///     It is expected that `name` will be a string in one of the following
  ///     formats, where W is shorthand for a valid Python identifier and dot stands
  ///     for a literal period in these pseudo-regexes:
  ///
  ///     W(.W)*
  ///     W(.W)*:(W(.W)*)?
  ///
  ///     The first form is intended for backward compatibility only. It assumes that
  ///     some part of the dotted name is a package, and the rest is an object
  ///     somewhere within that package, possibly nested inside other objects.
  ///     Because the place where the package stops and the object hierarchy starts
  ///     can't be inferred by inspection, repeated attempts to import must be done
  ///     with this form.
  ///
  ///     In the second form, the caller makes the division point clear through the
  ///     provision of a single colon: the dotted name to the left of the colon is a
  ///     package to be imported, and the dotted name to the right is the object
  ///     hierarchy within that package. Only one import is needed in this form. If
  ///     it ends with the colon, then a module object is returned.
  ///
  ///     The function will return an object (which might be a module), or raise one
  ///     of the following exceptions:
  ///
  ///     ValueError - if `name` isn't in a recognised format
  ///     ImportError - if an import failed when it shouldn't have
  ///     AttributeError - if a failure occurred when traversing the object hierarchy
  ///                      within the imported package to get to the desired object.
  ///     """
  ///     global _NAME_PATTERN
  ///     if _NAME_PATTERN is None:
  ///         # Lazy import to speedup Python startup time
  ///         import re
  ///         dotted_words = r'(?!\d)(\w+)(\.(?!\d)(\w+))*'
  ///         _NAME_PATTERN = re.compile(f'^(?P<pkg>{dotted_words})'
  ///                                    f'(?P<cln>:(?P<obj>{dotted_words})?)?$',
  ///                                    re.UNICODE)
  ///
  ///     m = _NAME_PATTERN.match(name)
  ///     if not m:
  ///         raise ValueError(f'invalid format: {name!r}')
  ///     gd = m.groupdict()
  ///     if gd.get('cln'):
  ///         # there is a colon - a one-step import is all that's needed
  ///         mod = importlib.import_module(gd['pkg'])
  ///         parts = gd.get('obj')
  ///         parts = parts.split('.') if parts else []
  ///     else:
  ///         # no colon - have to iterate to find the package boundary
  ///         parts = name.split('.')
  ///         modname = parts.pop(0)
  ///         # first part *must* be a module/package.
  ///         mod = importlib.import_module(modname)
  ///         while parts:
  ///             p = parts[0]
  ///             s = f'{modname}.{p}'
  ///             try:
  ///                 mod = importlib.import_module(s)
  ///                 parts.pop(0)
  ///                 modname = s
  ///             except ImportError:
  ///                 break
  ///     # if we reach this point, mod is the module, already imported, and
  ///     # parts is the list of parts in the object hierarchy to be traversed, or
  ///     # an empty list if just the module is wanted.
  ///     result = mod
  ///     for p in parts:
  ///         result = getattr(result, p)
  ///     return result
  /// ```
  Object? resolve_name({
    required Object? name,
  }) =>
      getFunction("resolve_name").call(
        <Object?>[
          name,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## walk_packages
  ///
  /// ### python docstring
  ///
  /// Yields ModuleInfo for all modules recursively
  /// on path, or, if path is None, all accessible modules.
  ///
  /// 'path' should be either None or a list of paths to look for
  /// modules in.
  ///
  /// 'prefix' is a string to output on the front of every module name
  /// on output.
  ///
  /// Note that this function must import all *packages* (NOT all
  /// modules!) on the given path, in order to access the __path__
  /// attribute to find submodules.
  ///
  /// 'onerror' is a function which gets called with one argument (the
  /// name of the package which was being imported) if any exception
  /// occurs while trying to import a package.  If no onerror function is
  /// supplied, ImportErrors are caught and ignored, while all other
  /// exceptions are propagated, terminating the search.
  ///
  /// Examples:
  ///
  /// # list all modules python can access
  /// walk_packages()
  ///
  /// # list all submodules of ctypes
  /// walk_packages(ctypes.__path__, ctypes.__name__+'.')
  ///
  /// ### python source
  /// ```py
  /// def walk_packages(path=None, prefix='', onerror=None):
  ///     """Yields ModuleInfo for all modules recursively
  ///     on path, or, if path is None, all accessible modules.
  ///
  ///     'path' should be either None or a list of paths to look for
  ///     modules in.
  ///
  ///     'prefix' is a string to output on the front of every module name
  ///     on output.
  ///
  ///     Note that this function must import all *packages* (NOT all
  ///     modules!) on the given path, in order to access the __path__
  ///     attribute to find submodules.
  ///
  ///     'onerror' is a function which gets called with one argument (the
  ///     name of the package which was being imported) if any exception
  ///     occurs while trying to import a package.  If no onerror function is
  ///     supplied, ImportErrors are caught and ignored, while all other
  ///     exceptions are propagated, terminating the search.
  ///
  ///     Examples:
  ///
  ///     # list all modules python can access
  ///     walk_packages()
  ///
  ///     # list all submodules of ctypes
  ///     walk_packages(ctypes.__path__, ctypes.__name__+'.')
  ///     """
  ///
  ///     def seen(p, m={}):
  ///         if p in m:
  ///             return True
  ///         m[p] = True
  ///
  ///     for info in iter_modules(path, prefix):
  ///         yield info
  ///
  ///         if info.ispkg:
  ///             try:
  ///                 __import__(info.name)
  ///             except ImportError:
  ///                 if onerror is not None:
  ///                     onerror(info.name)
  ///             except Exception:
  ///                 if onerror is not None:
  ///                     onerror(info.name)
  ///                 else:
  ///                     raise
  ///             else:
  ///                 path = getattr(sys.modules[info.name], '__path__', None) or []
  ///
  ///                 # don't traverse path items we've seen before
  ///                 path = [p for p in path if not seen(p)]
  ///
  ///                 yield from walk_packages(path, info.name+'.', onerror)
  /// ```
  Object? walk_packages({
    Object? path,
    Object? prefix = "",
    Object? onerror,
  }) =>
      getFunction("walk_packages").call(
        <Object?>[
          path,
          prefix,
          onerror,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## importlib
///
/// ### python docstring
///
/// A pure Python implementation of import.
///
/// ### python source
/// ```py
/// """A pure Python implementation of import."""
/// __all__ = ['__import__', 'import_module', 'invalidate_caches', 'reload']
///
/// # Bootstrap help #####################################################
///
/// # Until bootstrapping is complete, DO NOT import any modules that attempt
/// # to import importlib._bootstrap (directly or indirectly). Since this
/// # partially initialised package would be present in sys.modules, those
/// # modules would get an uninitialised copy of the source version, instead
/// # of a fully initialised version (either the frozen one or the one
/// # initialised below if the frozen one is not available).
/// import _imp  # Just the builtin component, NOT the full Python module
/// import sys
///
/// try:
///     import _frozen_importlib as _bootstrap
/// except ImportError:
///     from . import _bootstrap
///     _bootstrap._setup(sys, _imp)
/// else:
///     # importlib._bootstrap is the built-in import, ensure we don't create
///     # a second copy of the module.
///     _bootstrap.__name__ = 'importlib._bootstrap'
///     _bootstrap.__package__ = 'importlib'
///     try:
///         _bootstrap.__file__ = __file__.replace('__init__.py', '_bootstrap.py')
///     except NameError:
///         # __file__ is not guaranteed to be defined, e.g. if this code gets
///         # frozen by a tool like cx_Freeze.
///         pass
///     sys.modules['importlib._bootstrap'] = _bootstrap
///
/// try:
///     import _frozen_importlib_external as _bootstrap_external
/// except ImportError:
///     from . import _bootstrap_external
///     _bootstrap_external._set_bootstrap_module(_bootstrap)
///     _bootstrap._bootstrap_external = _bootstrap_external
/// else:
///     _bootstrap_external.__name__ = 'importlib._bootstrap_external'
///     _bootstrap_external.__package__ = 'importlib'
///     try:
///         _bootstrap_external.__file__ = __file__.replace('__init__.py', '_bootstrap_external.py')
///     except NameError:
///         # __file__ is not guaranteed to be defined, e.g. if this code gets
///         # frozen by a tool like cx_Freeze.
///         pass
///     sys.modules['importlib._bootstrap_external'] = _bootstrap_external
///
/// # To simplify imports in test code
/// _pack_uint32 = _bootstrap_external._pack_uint32
/// _unpack_uint32 = _bootstrap_external._unpack_uint32
///
/// # Fully bootstrapped at this point, import whatever you like, circular
/// # dependencies and startup overhead minimisation permitting :)
///
/// import warnings
///
///
/// # Public API #########################################################
///
/// from ._bootstrap import __import__
///
///
/// def invalidate_caches():
///     """Call the invalidate_caches() method on all meta path finders stored in
///     sys.meta_path (where implemented)."""
///     for finder in sys.meta_path:
///         if hasattr(finder, 'invalidate_caches'):
///             finder.invalidate_caches()
///
///
/// def find_loader(name, path=None):
///     """Return the loader for the specified module.
///
///     This is a backward-compatible wrapper around find_spec().
///
///     This function is deprecated in favor of importlib.util.find_spec().
///
///     """
///     warnings.warn('Deprecated since Python 3.4 and slated for removal in '
///                   'Python 3.12; use importlib.util.find_spec() instead',
///                   DeprecationWarning, stacklevel=2)
///     try:
///         loader = sys.modules[name].__loader__
///         if loader is None:
///             raise ValueError('{}.__loader__ is None'.format(name))
///         else:
///             return loader
///     except KeyError:
///         pass
///     except AttributeError:
///         raise ValueError('{}.__loader__ is not set'.format(name)) from None
///
///     spec = _bootstrap._find_spec(name, path)
///     # We won't worry about malformed specs (missing attributes).
///     if spec is None:
///         return None
///     if spec.loader is None:
///         if spec.submodule_search_locations is None:
///             raise ImportError('spec for {} missing loader'.format(name),
///                               name=name)
///         raise ImportError('namespace packages do not have loaders',
///                           name=name)
///     return spec.loader
///
///
/// def import_module(name, package=None):
///     """Import a module.
///
///     The 'package' argument is required when performing a relative import. It
///     specifies the package to use as the anchor point from which to resolve the
///     relative import to an absolute import.
///
///     """
///     level = 0
///     if name.startswith('.'):
///         if not package:
///             msg = ("the 'package' argument is required to perform a relative "
///                    "import for {!r}")
///             raise TypeError(msg.format(name))
///         for character in name:
///             if character != '.':
///                 break
///             level += 1
///     return _bootstrap._gcd_import(name[level:], package, level)
///
///
/// _RELOADING = {}
///
///
/// def reload(module):
///     """Reload the module and return it.
///
///     The module must have been successfully imported before.
///
///     """
///     try:
///         name = module.__spec__.name
///     except AttributeError:
///         try:
///             name = module.__name__
///         except AttributeError:
///             raise TypeError("reload() argument must be a module")
///
///     if sys.modules.get(name) is not module:
///         msg = "module {} not in sys.modules"
///         raise ImportError(msg.format(name), name=name)
///     if name in _RELOADING:
///         return _RELOADING[name]
///     _RELOADING[name] = module
///     try:
///         parent_name = name.rpartition('.')[0]
///         if parent_name:
///             try:
///                 parent = sys.modules[parent_name]
///             except KeyError:
///                 msg = "parent {!r} not in sys.modules"
///                 raise ImportError(msg.format(parent_name),
///                                   name=parent_name) from None
///             else:
///                 pkgpath = parent.__path__
///         else:
///             pkgpath = None
///         target = module
///         spec = module.__spec__ = _bootstrap._find_spec(name, pkgpath, target)
///         if spec is None:
///             raise ModuleNotFoundError(f"spec not found for the module {name!r}", name=name)
///         _bootstrap._exec(spec, module)
///         # The module may have replaced itself in sys.modules!
///         return sys.modules[name]
///     finally:
///         try:
///             del _RELOADING[name]
///         except KeyError:
///             pass
/// ```
final class importlib extends PythonModule {
  importlib.from(super.pythonModule) : super.from();

  static importlib import() => PythonFfiDart.instance.importModule(
        "importlib",
        importlib.from,
      );

  /// ## find_loader
  ///
  /// ### python docstring
  ///
  /// Return the loader for the specified module.
  ///
  /// This is a backward-compatible wrapper around find_spec().
  ///
  /// This function is deprecated in favor of importlib.util.find_spec().
  ///
  /// ### python source
  /// ```py
  /// def find_loader(name, path=None):
  ///     """Return the loader for the specified module.
  ///
  ///     This is a backward-compatible wrapper around find_spec().
  ///
  ///     This function is deprecated in favor of importlib.util.find_spec().
  ///
  ///     """
  ///     warnings.warn('Deprecated since Python 3.4 and slated for removal in '
  ///                   'Python 3.12; use importlib.util.find_spec() instead',
  ///                   DeprecationWarning, stacklevel=2)
  ///     try:
  ///         loader = sys.modules[name].__loader__
  ///         if loader is None:
  ///             raise ValueError('{}.__loader__ is None'.format(name))
  ///         else:
  ///             return loader
  ///     except KeyError:
  ///         pass
  ///     except AttributeError:
  ///         raise ValueError('{}.__loader__ is not set'.format(name)) from None
  ///
  ///     spec = _bootstrap._find_spec(name, path)
  ///     # We won't worry about malformed specs (missing attributes).
  ///     if spec is None:
  ///         return None
  ///     if spec.loader is None:
  ///         if spec.submodule_search_locations is None:
  ///             raise ImportError('spec for {} missing loader'.format(name),
  ///                               name=name)
  ///         raise ImportError('namespace packages do not have loaders',
  ///                           name=name)
  ///     return spec.loader
  /// ```
  Object? find_loader({
    required Object? name,
    Object? path,
  }) =>
      getFunction("find_loader").call(
        <Object?>[
          name,
          path,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## import_module
  ///
  /// ### python docstring
  ///
  /// Import a module.
  ///
  /// The 'package' argument is required when performing a relative import. It
  /// specifies the package to use as the anchor point from which to resolve the
  /// relative import to an absolute import.
  ///
  /// ### python source
  /// ```py
  /// def import_module(name, package=None):
  ///     """Import a module.
  ///
  ///     The 'package' argument is required when performing a relative import. It
  ///     specifies the package to use as the anchor point from which to resolve the
  ///     relative import to an absolute import.
  ///
  ///     """
  ///     level = 0
  ///     if name.startswith('.'):
  ///         if not package:
  ///             msg = ("the 'package' argument is required to perform a relative "
  ///                    "import for {!r}")
  ///             raise TypeError(msg.format(name))
  ///         for character in name:
  ///             if character != '.':
  ///                 break
  ///             level += 1
  ///     return _bootstrap._gcd_import(name[level:], package, level)
  /// ```
  Object? import_module({
    required Object? name,
    Object? package,
  }) =>
      getFunction("import_module").call(
        <Object?>[
          name,
          package,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## invalidate_caches
  ///
  /// ### python docstring
  ///
  /// Call the invalidate_caches() method on all meta path finders stored in
  /// sys.meta_path (where implemented).
  ///
  /// ### python source
  /// ```py
  /// def invalidate_caches():
  ///     """Call the invalidate_caches() method on all meta path finders stored in
  ///     sys.meta_path (where implemented)."""
  ///     for finder in sys.meta_path:
  ///         if hasattr(finder, 'invalidate_caches'):
  ///             finder.invalidate_caches()
  /// ```
  Object? invalidate_caches() => getFunction("invalidate_caches").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## reload
  ///
  /// ### python docstring
  ///
  /// Reload the module and return it.
  ///
  /// The module must have been successfully imported before.
  ///
  /// ### python source
  /// ```py
  /// def reload(module):
  ///     """Reload the module and return it.
  ///
  ///     The module must have been successfully imported before.
  ///
  ///     """
  ///     try:
  ///         name = module.__spec__.name
  ///     except AttributeError:
  ///         try:
  ///             name = module.__name__
  ///         except AttributeError:
  ///             raise TypeError("reload() argument must be a module")
  ///
  ///     if sys.modules.get(name) is not module:
  ///         msg = "module {} not in sys.modules"
  ///         raise ImportError(msg.format(name), name=name)
  ///     if name in _RELOADING:
  ///         return _RELOADING[name]
  ///     _RELOADING[name] = module
  ///     try:
  ///         parent_name = name.rpartition('.')[0]
  ///         if parent_name:
  ///             try:
  ///                 parent = sys.modules[parent_name]
  ///             except KeyError:
  ///                 msg = "parent {!r} not in sys.modules"
  ///                 raise ImportError(msg.format(parent_name),
  ///                                   name=parent_name) from None
  ///             else:
  ///                 pkgpath = parent.__path__
  ///         else:
  ///             pkgpath = None
  ///         target = module
  ///         spec = module.__spec__ = _bootstrap._find_spec(name, pkgpath, target)
  ///         if spec is None:
  ///             raise ModuleNotFoundError(f"spec not found for the module {name!r}", name=name)
  ///         _bootstrap._exec(spec, module)
  ///         # The module may have replaced itself in sys.modules!
  ///         return sys.modules[name]
  ///     finally:
  ///         try:
  ///             del _RELOADING[name]
  ///         except KeyError:
  ///             pass
  /// ```
  Object? reload({
    required Object? module,
  }) =>
      getFunction("reload").call(
        <Object?>[
          module,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## machinery
///
/// ### python docstring
///
/// The machinery of importlib: finders, loaders, hooks, etc.
///
/// ### python source
/// ```py
/// """The machinery of importlib: finders, loaders, hooks, etc."""
///
/// from ._bootstrap import ModuleSpec
/// from ._bootstrap import BuiltinImporter
/// from ._bootstrap import FrozenImporter
/// from ._bootstrap_external import (SOURCE_SUFFIXES, DEBUG_BYTECODE_SUFFIXES,
///                      OPTIMIZED_BYTECODE_SUFFIXES, BYTECODE_SUFFIXES,
///                      EXTENSION_SUFFIXES)
/// from ._bootstrap_external import WindowsRegistryFinder
/// from ._bootstrap_external import PathFinder
/// from ._bootstrap_external import FileFinder
/// from ._bootstrap_external import SourceFileLoader
/// from ._bootstrap_external import SourcelessFileLoader
/// from ._bootstrap_external import ExtensionFileLoader
/// from ._bootstrap_external import NamespaceLoader
///
///
/// def all_suffixes():
///     """Returns a list of all recognized module suffixes for this process"""
///     return SOURCE_SUFFIXES + BYTECODE_SUFFIXES + EXTENSION_SUFFIXES
/// ```
final class machinery extends PythonModule {
  machinery.from(super.pythonModule) : super.from();

  static machinery import() => PythonFfiDart.instance.importModule(
        "importlib.machinery",
        machinery.from,
      );

  /// ## all_suffixes
  ///
  /// ### python docstring
  ///
  /// Returns a list of all recognized module suffixes for this process
  Object? all_suffixes() => getFunction("all_suffixes").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## BYTECODE_SUFFIXES (getter)
  Object? get BYTECODE_SUFFIXES => getAttribute("BYTECODE_SUFFIXES");

  /// ## BYTECODE_SUFFIXES (setter)
  set BYTECODE_SUFFIXES(Object? BYTECODE_SUFFIXES) =>
      setAttribute("BYTECODE_SUFFIXES", BYTECODE_SUFFIXES);

  /// ## DEBUG_BYTECODE_SUFFIXES (getter)
  Object? get DEBUG_BYTECODE_SUFFIXES =>
      getAttribute("DEBUG_BYTECODE_SUFFIXES");

  /// ## DEBUG_BYTECODE_SUFFIXES (setter)
  set DEBUG_BYTECODE_SUFFIXES(Object? DEBUG_BYTECODE_SUFFIXES) =>
      setAttribute("DEBUG_BYTECODE_SUFFIXES", DEBUG_BYTECODE_SUFFIXES);

  /// ## EXTENSION_SUFFIXES (getter)
  Object? get EXTENSION_SUFFIXES => getAttribute("EXTENSION_SUFFIXES");

  /// ## EXTENSION_SUFFIXES (setter)
  set EXTENSION_SUFFIXES(Object? EXTENSION_SUFFIXES) =>
      setAttribute("EXTENSION_SUFFIXES", EXTENSION_SUFFIXES);

  /// ## OPTIMIZED_BYTECODE_SUFFIXES (getter)
  Object? get OPTIMIZED_BYTECODE_SUFFIXES =>
      getAttribute("OPTIMIZED_BYTECODE_SUFFIXES");

  /// ## OPTIMIZED_BYTECODE_SUFFIXES (setter)
  set OPTIMIZED_BYTECODE_SUFFIXES(Object? OPTIMIZED_BYTECODE_SUFFIXES) =>
      setAttribute("OPTIMIZED_BYTECODE_SUFFIXES", OPTIMIZED_BYTECODE_SUFFIXES);

  /// ## SOURCE_SUFFIXES (getter)
  Object? get SOURCE_SUFFIXES => getAttribute("SOURCE_SUFFIXES");

  /// ## SOURCE_SUFFIXES (setter)
  set SOURCE_SUFFIXES(Object? SOURCE_SUFFIXES) =>
      setAttribute("SOURCE_SUFFIXES", SOURCE_SUFFIXES);
}

/// ## util
///
/// ### python docstring
///
/// Utility code for constructing importers, etc.
///
/// ### python source
/// ```py
/// """Utility code for constructing importers, etc."""
/// from ._abc import Loader
/// from ._bootstrap import module_from_spec
/// from ._bootstrap import _resolve_name
/// from ._bootstrap import spec_from_loader
/// from ._bootstrap import _find_spec
/// from ._bootstrap_external import MAGIC_NUMBER
/// from ._bootstrap_external import _RAW_MAGIC_NUMBER
/// from ._bootstrap_external import cache_from_source
/// from ._bootstrap_external import decode_source
/// from ._bootstrap_external import source_from_cache
/// from ._bootstrap_external import spec_from_file_location
///
/// from contextlib import contextmanager
/// import _imp
/// import functools
/// import sys
/// import types
/// import warnings
///
///
/// def source_hash(source_bytes):
///     "Return the hash of *source_bytes* as used in hash-based pyc files."
///     return _imp.source_hash(_RAW_MAGIC_NUMBER, source_bytes)
///
///
/// def resolve_name(name, package):
///     """Resolve a relative module name to an absolute one."""
///     if not name.startswith('.'):
///         return name
///     elif not package:
///         raise ImportError(f'no package specified for {repr(name)} '
///                           '(required for relative module names)')
///     level = 0
///     for character in name:
///         if character != '.':
///             break
///         level += 1
///     return _resolve_name(name[level:], package, level)
///
///
/// def _find_spec_from_path(name, path=None):
///     """Return the spec for the specified module.
///
///     First, sys.modules is checked to see if the module was already imported. If
///     so, then sys.modules[name].__spec__ is returned. If that happens to be
///     set to None, then ValueError is raised. If the module is not in
///     sys.modules, then sys.meta_path is searched for a suitable spec with the
///     value of 'path' given to the finders. None is returned if no spec could
///     be found.
///
///     Dotted names do not have their parent packages implicitly imported. You will
///     most likely need to explicitly import all parent packages in the proper
///     order for a submodule to get the correct spec.
///
///     """
///     if name not in sys.modules:
///         return _find_spec(name, path)
///     else:
///         module = sys.modules[name]
///         if module is None:
///             return None
///         try:
///             spec = module.__spec__
///         except AttributeError:
///             raise ValueError('{}.__spec__ is not set'.format(name)) from None
///         else:
///             if spec is None:
///                 raise ValueError('{}.__spec__ is None'.format(name))
///             return spec
///
///
/// def find_spec(name, package=None):
///     """Return the spec for the specified module.
///
///     First, sys.modules is checked to see if the module was already imported. If
///     so, then sys.modules[name].__spec__ is returned. If that happens to be
///     set to None, then ValueError is raised. If the module is not in
///     sys.modules, then sys.meta_path is searched for a suitable spec with the
///     value of 'path' given to the finders. None is returned if no spec could
///     be found.
///
///     If the name is for submodule (contains a dot), the parent module is
///     automatically imported.
///
///     The name and package arguments work the same as importlib.import_module().
///     In other words, relative module names (with leading dots) work.
///
///     """
///     fullname = resolve_name(name, package) if name.startswith('.') else name
///     if fullname not in sys.modules:
///         parent_name = fullname.rpartition('.')[0]
///         if parent_name:
///             parent = __import__(parent_name, fromlist=['__path__'])
///             try:
///                 parent_path = parent.__path__
///             except AttributeError as e:
///                 raise ModuleNotFoundError(
///                     f"__path__ attribute not found on {parent_name!r} "
///                     f"while trying to find {fullname!r}", name=fullname) from e
///         else:
///             parent_path = None
///         return _find_spec(fullname, parent_path)
///     else:
///         module = sys.modules[fullname]
///         if module is None:
///             return None
///         try:
///             spec = module.__spec__
///         except AttributeError:
///             raise ValueError('{}.__spec__ is not set'.format(name)) from None
///         else:
///             if spec is None:
///                 raise ValueError('{}.__spec__ is None'.format(name))
///             return spec
///
///
/// @contextmanager
/// def _module_to_load(name):
///     is_reload = name in sys.modules
///
///     module = sys.modules.get(name)
///     if not is_reload:
///         # This must be done before open() is called as the 'io' module
///         # implicitly imports 'locale' and would otherwise trigger an
///         # infinite loop.
///         module = type(sys)(name)
///         # This must be done before putting the module in sys.modules
///         # (otherwise an optimization shortcut in import.c becomes wrong)
///         module.__initializing__ = True
///         sys.modules[name] = module
///     try:
///         yield module
///     except Exception:
///         if not is_reload:
///             try:
///                 del sys.modules[name]
///             except KeyError:
///                 pass
///     finally:
///         module.__initializing__ = False
///
///
/// def set_package(fxn):
///     """Set __package__ on the returned module.
///
///     This function is deprecated.
///
///     """
///     @functools.wraps(fxn)
///     def set_package_wrapper(*args, **kwargs):
///         warnings.warn('The import system now takes care of this automatically; '
///                       'this decorator is slated for removal in Python 3.12',
///                       DeprecationWarning, stacklevel=2)
///         module = fxn(*args, **kwargs)
///         if getattr(module, '__package__', None) is None:
///             module.__package__ = module.__name__
///             if not hasattr(module, '__path__'):
///                 module.__package__ = module.__package__.rpartition('.')[0]
///         return module
///     return set_package_wrapper
///
///
/// def set_loader(fxn):
///     """Set __loader__ on the returned module.
///
///     This function is deprecated.
///
///     """
///     @functools.wraps(fxn)
///     def set_loader_wrapper(self, *args, **kwargs):
///         warnings.warn('The import system now takes care of this automatically; '
///                       'this decorator is slated for removal in Python 3.12',
///                       DeprecationWarning, stacklevel=2)
///         module = fxn(self, *args, **kwargs)
///         if getattr(module, '__loader__', None) is None:
///             module.__loader__ = self
///         return module
///     return set_loader_wrapper
///
///
/// def module_for_loader(fxn):
///     """Decorator to handle selecting the proper module for loaders.
///
///     The decorated function is passed the module to use instead of the module
///     name. The module passed in to the function is either from sys.modules if
///     it already exists or is a new module. If the module is new, then __name__
///     is set the first argument to the method, __loader__ is set to self, and
///     __package__ is set accordingly (if self.is_package() is defined) will be set
///     before it is passed to the decorated function (if self.is_package() does
///     not work for the module it will be set post-load).
///
///     If an exception is raised and the decorator created the module it is
///     subsequently removed from sys.modules.
///
///     The decorator assumes that the decorated function takes the module name as
///     the second argument.
///
///     """
///     warnings.warn('The import system now takes care of this automatically; '
///                   'this decorator is slated for removal in Python 3.12',
///                   DeprecationWarning, stacklevel=2)
///     @functools.wraps(fxn)
///     def module_for_loader_wrapper(self, fullname, *args, **kwargs):
///         with _module_to_load(fullname) as module:
///             module.__loader__ = self
///             try:
///                 is_package = self.is_package(fullname)
///             except (ImportError, AttributeError):
///                 pass
///             else:
///                 if is_package:
///                     module.__package__ = fullname
///                 else:
///                     module.__package__ = fullname.rpartition('.')[0]
///             # If __package__ was not set above, __import__() will do it later.
///             return fxn(self, module, *args, **kwargs)
///
///     return module_for_loader_wrapper
///
///
/// class _LazyModule(types.ModuleType):
///
///     """A subclass of the module type which triggers loading upon attribute access."""
///
///     def __getattribute__(self, attr):
///         """Trigger the load of the module and return the attribute."""
///         # All module metadata must be garnered from __spec__ in order to avoid
///         # using mutated values.
///         # Stop triggering this method.
///         self.__class__ = types.ModuleType
///         # Get the original name to make sure no object substitution occurred
///         # in sys.modules.
///         original_name = self.__spec__.name
///         # Figure out exactly what attributes were mutated between the creation
///         # of the module and now.
///         attrs_then = self.__spec__.loader_state['__dict__']
///         attrs_now = self.__dict__
///         attrs_updated = {}
///         for key, value in attrs_now.items():
///             # Code that set the attribute may have kept a reference to the
///             # assigned object, making identity more important than equality.
///             if key not in attrs_then:
///                 attrs_updated[key] = value
///             elif id(attrs_now[key]) != id(attrs_then[key]):
///                 attrs_updated[key] = value
///         self.__spec__.loader.exec_module(self)
///         # If exec_module() was used directly there is no guarantee the module
///         # object was put into sys.modules.
///         if original_name in sys.modules:
///             if id(self) != id(sys.modules[original_name]):
///                 raise ValueError(f"module object for {original_name!r} "
///                                   "substituted in sys.modules during a lazy "
///                                   "load")
///         # Update after loading since that's what would happen in an eager
///         # loading situation.
///         self.__dict__.update(attrs_updated)
///         return getattr(self, attr)
///
///     def __delattr__(self, attr):
///         """Trigger the load and then perform the deletion."""
///         # To trigger the load and raise an exception if the attribute
///         # doesn't exist.
///         self.__getattribute__(attr)
///         delattr(self, attr)
///
///
/// class LazyLoader(Loader):
///
///     """A loader that creates a module which defers loading until attribute access."""
///
///     @staticmethod
///     def __check_eager_loader(loader):
///         if not hasattr(loader, 'exec_module'):
///             raise TypeError('loader must define exec_module()')
///
///     @classmethod
///     def factory(cls, loader):
///         """Construct a callable which returns the eager loader made lazy."""
///         cls.__check_eager_loader(loader)
///         return lambda *args, **kwargs: cls(loader(*args, **kwargs))
///
///     def __init__(self, loader):
///         self.__check_eager_loader(loader)
///         self.loader = loader
///
///     def create_module(self, spec):
///         return self.loader.create_module(spec)
///
///     def exec_module(self, module):
///         """Make the module load lazily."""
///         module.__spec__.loader = self.loader
///         module.__loader__ = self.loader
///         # Don't need to worry about deep-copying as trying to set an attribute
///         # on an object would have triggered the load,
///         # e.g. ``module.__spec__.loader = None`` would trigger a load from
///         # trying to access module.__spec__.
///         loader_state = {}
///         loader_state['__dict__'] = module.__dict__.copy()
///         loader_state['__class__'] = module.__class__
///         module.__spec__.loader_state = loader_state
///         module.__class__ = _LazyModule
/// ```
final class util extends PythonModule {
  util.from(super.pythonModule) : super.from();

  static util import() => PythonFfiDart.instance.importModule(
        "importlib.util",
        util.from,
      );

  /// ## find_spec
  ///
  /// ### python docstring
  ///
  /// Return the spec for the specified module.
  ///
  /// First, sys.modules is checked to see if the module was already imported. If
  /// so, then sys.modules[name].__spec__ is returned. If that happens to be
  /// set to None, then ValueError is raised. If the module is not in
  /// sys.modules, then sys.meta_path is searched for a suitable spec with the
  /// value of 'path' given to the finders. None is returned if no spec could
  /// be found.
  ///
  /// If the name is for submodule (contains a dot), the parent module is
  /// automatically imported.
  ///
  /// The name and package arguments work the same as importlib.import_module().
  /// In other words, relative module names (with leading dots) work.
  Object? find_spec({
    required Object? name,
    Object? package,
  }) =>
      getFunction("find_spec").call(
        <Object?>[
          name,
          package,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## module_for_loader
  ///
  /// ### python docstring
  ///
  /// Decorator to handle selecting the proper module for loaders.
  ///
  /// The decorated function is passed the module to use instead of the module
  /// name. The module passed in to the function is either from sys.modules if
  /// it already exists or is a new module. If the module is new, then __name__
  /// is set the first argument to the method, __loader__ is set to self, and
  /// __package__ is set accordingly (if self.is_package() is defined) will be set
  /// before it is passed to the decorated function (if self.is_package() does
  /// not work for the module it will be set post-load).
  ///
  /// If an exception is raised and the decorator created the module it is
  /// subsequently removed from sys.modules.
  ///
  /// The decorator assumes that the decorated function takes the module name as
  /// the second argument.
  Object? module_for_loader({
    required Object? fxn,
  }) =>
      getFunction("module_for_loader").call(
        <Object?>[
          fxn,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## resolve_name
  ///
  /// ### python docstring
  ///
  /// Resolve a relative module name to an absolute one.
  Object? resolve_name({
    required Object? name,
    required Object? package,
  }) =>
      getFunction("resolve_name").call(
        <Object?>[
          name,
          package,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## set_loader
  ///
  /// ### python docstring
  ///
  /// Set __loader__ on the returned module.
  ///
  /// This function is deprecated.
  Object? set_loader({
    required Object? fxn,
  }) =>
      getFunction("set_loader").call(
        <Object?>[
          fxn,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## set_package
  ///
  /// ### python docstring
  ///
  /// Set __package__ on the returned module.
  ///
  /// This function is deprecated.
  Object? set_package({
    required Object? fxn,
  }) =>
      getFunction("set_package").call(
        <Object?>[
          fxn,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## source_hash
  ///
  /// ### python docstring
  ///
  /// Return the hash of *source_bytes* as used in hash-based pyc files.
  Object? source_hash({
    required Object? source_bytes,
  }) =>
      getFunction("source_hash").call(
        <Object?>[
          source_bytes,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## MAGIC_NUMBER (getter)
  Object? get MAGIC_NUMBER => getAttribute("MAGIC_NUMBER");

  /// ## MAGIC_NUMBER (setter)
  set MAGIC_NUMBER(Object? MAGIC_NUMBER) =>
      setAttribute("MAGIC_NUMBER", MAGIC_NUMBER);
}

/// ## zipimport
///
/// ### python docstring
///
/// zipimport provides support for importing Python modules from Zip archives.
///
/// This module exports three objects:
/// - zipimporter: a class; its constructor takes a path to a Zip archive.
/// - ZipImportError: exception raised by zipimporter objects. It's a
///   subclass of ImportError, so it can be caught as ImportError, too.
/// - _zip_directory_cache: a dict, mapping archive paths to zip directory
///   info dicts, as used in zipimporter._files.
///
/// It is usually not needed to use the zipimport module explicitly; it is
/// used by the builtin import mechanism for sys.path items that are paths
/// to Zip archives.
///
/// ### python source
/// ```py
/// """zipimport provides support for importing Python modules from Zip archives.
///
/// This module exports three objects:
/// - zipimporter: a class; its constructor takes a path to a Zip archive.
/// - ZipImportError: exception raised by zipimporter objects. It's a
///   subclass of ImportError, so it can be caught as ImportError, too.
/// - _zip_directory_cache: a dict, mapping archive paths to zip directory
///   info dicts, as used in zipimporter._files.
///
/// It is usually not needed to use the zipimport module explicitly; it is
/// used by the builtin import mechanism for sys.path items that are paths
/// to Zip archives.
/// """
///
/// #from importlib import _bootstrap_external
/// #from importlib import _bootstrap  # for _verbose_message
/// import _frozen_importlib_external as _bootstrap_external
/// from _frozen_importlib_external import _unpack_uint16, _unpack_uint32
/// import _frozen_importlib as _bootstrap  # for _verbose_message
/// import _imp  # for check_hash_based_pycs
/// import _io  # for open
/// import marshal  # for loads
/// import sys  # for modules
/// import time  # for mktime
/// import _warnings  # For warn()
///
/// __all__ = ['ZipImportError', 'zipimporter']
///
///
/// path_sep = _bootstrap_external.path_sep
/// alt_path_sep = _bootstrap_external.path_separators[1:]
///
///
/// class ZipImportError(ImportError):
///     pass
///
/// # _read_directory() cache
/// _zip_directory_cache = {}
///
/// _module_type = type(sys)
///
/// END_CENTRAL_DIR_SIZE = 22
/// STRING_END_ARCHIVE = b'PK\x05\x06'
/// MAX_COMMENT_LEN = (1 << 16) - 1
///
/// class zipimporter(_bootstrap_external._LoaderBasics):
///     """zipimporter(archivepath) -> zipimporter object
///
///     Create a new zipimporter instance. 'archivepath' must be a path to
///     a zipfile, or to a specific path inside a zipfile. For example, it can be
///     '/tmp/myimport.zip', or '/tmp/myimport.zip/mydirectory', if mydirectory is a
///     valid directory inside the archive.
///
///     'ZipImportError is raised if 'archivepath' doesn't point to a valid Zip
///     archive.
///
///     The 'archive' attribute of zipimporter objects contains the name of the
///     zipfile targeted.
///     """
///
///     # Split the "subdirectory" from the Zip archive path, lookup a matching
///     # entry in sys.path_importer_cache, fetch the file directory from there
///     # if found, or else read it from the archive.
///     def __init__(self, path):
///         if not isinstance(path, str):
///             raise TypeError(f"expected str, not {type(path)!r}")
///         if not path:
///             raise ZipImportError('archive path is empty', path=path)
///         if alt_path_sep:
///             path = path.replace(alt_path_sep, path_sep)
///
///         prefix = []
///         while True:
///             try:
///                 st = _bootstrap_external._path_stat(path)
///             except (OSError, ValueError):
///                 # On Windows a ValueError is raised for too long paths.
///                 # Back up one path element.
///                 dirname, basename = _bootstrap_external._path_split(path)
///                 if dirname == path:
///                     raise ZipImportError('not a Zip file', path=path)
///                 path = dirname
///                 prefix.append(basename)
///             else:
///                 # it exists
///                 if (st.st_mode & 0o170000) != 0o100000:  # stat.S_ISREG
///                     # it's a not file
///                     raise ZipImportError('not a Zip file', path=path)
///                 break
///
///         try:
///             files = _zip_directory_cache[path]
///         except KeyError:
///             files = _read_directory(path)
///             _zip_directory_cache[path] = files
///         self._files = files
///         self.archive = path
///         # a prefix directory following the ZIP file path.
///         self.prefix = _bootstrap_external._path_join(*prefix[::-1])
///         if self.prefix:
///             self.prefix += path_sep
///
///
///     # Check whether we can satisfy the import of the module named by
///     # 'fullname', or whether it could be a portion of a namespace
///     # package. Return self if we can load it, a string containing the
///     # full path if it's a possible namespace portion, None if we
///     # can't load it.
///     def find_loader(self, fullname, path=None):
///         """find_loader(fullname, path=None) -> self, str or None.
///
///         Search for a module specified by 'fullname'. 'fullname' must be the
///         fully qualified (dotted) module name. It returns the zipimporter
///         instance itself if the module was found, a string containing the
///         full path name if it's possibly a portion of a namespace package,
///         or None otherwise. The optional 'path' argument is ignored -- it's
///         there for compatibility with the importer protocol.
///
///         Deprecated since Python 3.10. Use find_spec() instead.
///         """
///         _warnings.warn("zipimporter.find_loader() is deprecated and slated for "
///                        "removal in Python 3.12; use find_spec() instead",
///                        DeprecationWarning)
///         mi = _get_module_info(self, fullname)
///         if mi is not None:
///             # This is a module or package.
///             return self, []
///
///         # Not a module or regular package. See if this is a directory, and
///         # therefore possibly a portion of a namespace package.
///
///         # We're only interested in the last path component of fullname
///         # earlier components are recorded in self.prefix.
///         modpath = _get_module_path(self, fullname)
///         if _is_dir(self, modpath):
///             # This is possibly a portion of a namespace
///             # package. Return the string representing its path,
///             # without a trailing separator.
///             return None, [f'{self.archive}{path_sep}{modpath}']
///
///         return None, []
///
///
///     # Check whether we can satisfy the import of the module named by
///     # 'fullname'. Return self if we can, None if we can't.
///     def find_module(self, fullname, path=None):
///         """find_module(fullname, path=None) -> self or None.
///
///         Search for a module specified by 'fullname'. 'fullname' must be the
///         fully qualified (dotted) module name. It returns the zipimporter
///         instance itself if the module was found, or None if it wasn't.
///         The optional 'path' argument is ignored -- it's there for compatibility
///         with the importer protocol.
///
///         Deprecated since Python 3.10. Use find_spec() instead.
///         """
///         _warnings.warn("zipimporter.find_module() is deprecated and slated for "
///                        "removal in Python 3.12; use find_spec() instead",
///                        DeprecationWarning)
///         return self.find_loader(fullname, path)[0]
///
///     def find_spec(self, fullname, target=None):
///         """Create a ModuleSpec for the specified module.
///
///         Returns None if the module cannot be found.
///         """
///         module_info = _get_module_info(self, fullname)
///         if module_info is not None:
///             return _bootstrap.spec_from_loader(fullname, self, is_package=module_info)
///         else:
///             # Not a module or regular package. See if this is a directory, and
///             # therefore possibly a portion of a namespace package.
///
///             # We're only interested in the last path component of fullname
///             # earlier components are recorded in self.prefix.
///             modpath = _get_module_path(self, fullname)
///             if _is_dir(self, modpath):
///                 # This is possibly a portion of a namespace
///                 # package. Return the string representing its path,
///                 # without a trailing separator.
///                 path = f'{self.archive}{path_sep}{modpath}'
///                 spec = _bootstrap.ModuleSpec(name=fullname, loader=None,
///                                              is_package=True)
///                 spec.submodule_search_locations.append(path)
///                 return spec
///             else:
///                 return None
///
///     def get_code(self, fullname):
///         """get_code(fullname) -> code object.
///
///         Return the code object for the specified module. Raise ZipImportError
///         if the module couldn't be imported.
///         """
///         code, ispackage, modpath = _get_module_code(self, fullname)
///         return code
///
///
///     def get_data(self, pathname):
///         """get_data(pathname) -> string with file data.
///
///         Return the data associated with 'pathname'. Raise OSError if
///         the file wasn't found.
///         """
///         if alt_path_sep:
///             pathname = pathname.replace(alt_path_sep, path_sep)
///
///         key = pathname
///         if pathname.startswith(self.archive + path_sep):
///             key = pathname[len(self.archive + path_sep):]
///
///         try:
///             toc_entry = self._files[key]
///         except KeyError:
///             raise OSError(0, '', key)
///         return _get_data(self.archive, toc_entry)
///
///
///     # Return a string matching __file__ for the named module
///     def get_filename(self, fullname):
///         """get_filename(fullname) -> filename string.
///
///         Return the filename for the specified module or raise ZipImportError
///         if it couldn't be imported.
///         """
///         # Deciding the filename requires working out where the code
///         # would come from if the module was actually loaded
///         code, ispackage, modpath = _get_module_code(self, fullname)
///         return modpath
///
///
///     def get_source(self, fullname):
///         """get_source(fullname) -> source string.
///
///         Return the source code for the specified module. Raise ZipImportError
///         if the module couldn't be found, return None if the archive does
///         contain the module, but has no source for it.
///         """
///         mi = _get_module_info(self, fullname)
///         if mi is None:
///             raise ZipImportError(f"can't find module {fullname!r}", name=fullname)
///
///         path = _get_module_path(self, fullname)
///         if mi:
///             fullpath = _bootstrap_external._path_join(path, '__init__.py')
///         else:
///             fullpath = f'{path}.py'
///
///         try:
///             toc_entry = self._files[fullpath]
///         except KeyError:
///             # we have the module, but no source
///             return None
///         return _get_data(self.archive, toc_entry).decode()
///
///
///     # Return a bool signifying whether the module is a package or not.
///     def is_package(self, fullname):
///         """is_package(fullname) -> bool.
///
///         Return True if the module specified by fullname is a package.
///         Raise ZipImportError if the module couldn't be found.
///         """
///         mi = _get_module_info(self, fullname)
///         if mi is None:
///             raise ZipImportError(f"can't find module {fullname!r}", name=fullname)
///         return mi
///
///
///     # Load and return the module named by 'fullname'.
///     def load_module(self, fullname):
///         """load_module(fullname) -> module.
///
///         Load the module specified by 'fullname'. 'fullname' must be the
///         fully qualified (dotted) module name. It returns the imported
///         module, or raises ZipImportError if it could not be imported.
///
///         Deprecated since Python 3.10. Use exec_module() instead.
///         """
///         msg = ("zipimport.zipimporter.load_module() is deprecated and slated for "
///                "removal in Python 3.12; use exec_module() instead")
///         _warnings.warn(msg, DeprecationWarning)
///         code, ispackage, modpath = _get_module_code(self, fullname)
///         mod = sys.modules.get(fullname)
///         if mod is None or not isinstance(mod, _module_type):
///             mod = _module_type(fullname)
///             sys.modules[fullname] = mod
///         mod.__loader__ = self
///
///         try:
///             if ispackage:
///                 # add __path__ to the module *before* the code gets
///                 # executed
///                 path = _get_module_path(self, fullname)
///                 fullpath = _bootstrap_external._path_join(self.archive, path)
///                 mod.__path__ = [fullpath]
///
///             if not hasattr(mod, '__builtins__'):
///                 mod.__builtins__ = __builtins__
///             _bootstrap_external._fix_up_module(mod.__dict__, fullname, modpath)
///             exec(code, mod.__dict__)
///         except:
///             del sys.modules[fullname]
///             raise
///
///         try:
///             mod = sys.modules[fullname]
///         except KeyError:
///             raise ImportError(f'Loaded module {fullname!r} not found in sys.modules')
///         _bootstrap._verbose_message('import {} # loaded from Zip {}', fullname, modpath)
///         return mod
///
///
///     def get_resource_reader(self, fullname):
///         """Return the ResourceReader for a package in a zip file.
///
///         If 'fullname' is a package within the zip file, return the
///         'ResourceReader' object for the package.  Otherwise return None.
///         """
///         try:
///             if not self.is_package(fullname):
///                 return None
///         except ZipImportError:
///             return None
///         from importlib.readers import ZipReader
///         return ZipReader(self, fullname)
///
///
///     def invalidate_caches(self):
///         """Reload the file data of the archive path."""
///         try:
///             self._files = _read_directory(self.archive)
///             _zip_directory_cache[self.archive] = self._files
///         except ZipImportError:
///             _zip_directory_cache.pop(self.archive, None)
///             self._files = {}
///
///
///     def __repr__(self):
///         return f'<zipimporter object "{self.archive}{path_sep}{self.prefix}">'
///
///
/// # _zip_searchorder defines how we search for a module in the Zip
/// # archive: we first search for a package __init__, then for
/// # non-package .pyc, and .py entries. The .pyc entries
/// # are swapped by initzipimport() if we run in optimized mode. Also,
/// # '/' is replaced by path_sep there.
/// _zip_searchorder = (
///     (path_sep + '__init__.pyc', True, True),
///     (path_sep + '__init__.py', False, True),
///     ('.pyc', True, False),
///     ('.py', False, False),
/// )
///
/// # Given a module name, return the potential file path in the
/// # archive (without extension).
/// def _get_module_path(self, fullname):
///     return self.prefix + fullname.rpartition('.')[2]
///
/// # Does this path represent a directory?
/// def _is_dir(self, path):
///     # See if this is a "directory". If so, it's eligible to be part
///     # of a namespace package. We test by seeing if the name, with an
///     # appended path separator, exists.
///     dirpath = path + path_sep
///     # If dirpath is present in self._files, we have a directory.
///     return dirpath in self._files
///
/// # Return some information about a module.
/// def _get_module_info(self, fullname):
///     path = _get_module_path(self, fullname)
///     for suffix, isbytecode, ispackage in _zip_searchorder:
///         fullpath = path + suffix
///         if fullpath in self._files:
///             return ispackage
///     return None
///
///
/// # implementation
///
/// # _read_directory(archive) -> files dict (new reference)
/// #
/// # Given a path to a Zip archive, build a dict, mapping file names
/// # (local to the archive, using SEP as a separator) to toc entries.
/// #
/// # A toc_entry is a tuple:
/// #
/// # (__file__,        # value to use for __file__, available for all files,
/// #                   # encoded to the filesystem encoding
/// #  compress,        # compression kind; 0 for uncompressed
/// #  data_size,       # size of compressed data on disk
/// #  file_size,       # size of decompressed data
/// #  file_offset,     # offset of file header from start of archive
/// #  time,            # mod time of file (in dos format)
/// #  date,            # mod data of file (in dos format)
/// #  crc,             # crc checksum of the data
/// # )
/// #
/// # Directories can be recognized by the trailing path_sep in the name,
/// # data_size and file_offset are 0.
/// def _read_directory(archive):
///     try:
///         fp = _io.open_code(archive)
///     except OSError:
///         raise ZipImportError(f"can't open Zip file: {archive!r}", path=archive)
///
///     with fp:
///         # GH-87235: On macOS all file descriptors for /dev/fd/N share the same
///         # file offset, reset the file offset after scanning the zipfile diretory
///         # to not cause problems when some runs 'python3 /dev/fd/9 9<some_script'
///         start_offset = fp.tell()
///         try:
///             try:
///                 fp.seek(-END_CENTRAL_DIR_SIZE, 2)
///                 header_position = fp.tell()
///                 buffer = fp.read(END_CENTRAL_DIR_SIZE)
///             except OSError:
///                 raise ZipImportError(f"can't read Zip file: {archive!r}", path=archive)
///             if len(buffer) != END_CENTRAL_DIR_SIZE:
///                 raise ZipImportError(f"can't read Zip file: {archive!r}", path=archive)
///             if buffer[:4] != STRING_END_ARCHIVE:
///                 # Bad: End of Central Dir signature
///                 # Check if there's a comment.
///                 try:
///                     fp.seek(0, 2)
///                     file_size = fp.tell()
///                 except OSError:
///                     raise ZipImportError(f"can't read Zip file: {archive!r}",
///                                          path=archive)
///                 max_comment_start = max(file_size - MAX_COMMENT_LEN -
///                                         END_CENTRAL_DIR_SIZE, 0)
///                 try:
///                     fp.seek(max_comment_start)
///                     data = fp.read()
///                 except OSError:
///                     raise ZipImportError(f"can't read Zip file: {archive!r}",
///                                          path=archive)
///                 pos = data.rfind(STRING_END_ARCHIVE)
///                 if pos < 0:
///                     raise ZipImportError(f'not a Zip file: {archive!r}',
///                                          path=archive)
///                 buffer = data[pos:pos+END_CENTRAL_DIR_SIZE]
///                 if len(buffer) != END_CENTRAL_DIR_SIZE:
///                     raise ZipImportError(f"corrupt Zip file: {archive!r}",
///                                          path=archive)
///                 header_position = file_size - len(data) + pos
///
///             header_size = _unpack_uint32(buffer[12:16])
///             header_offset = _unpack_uint32(buffer[16:20])
///             if header_position < header_size:
///                 raise ZipImportError(f'bad central directory size: {archive!r}', path=archive)
///             if header_position < header_offset:
///                 raise ZipImportError(f'bad central directory offset: {archive!r}', path=archive)
///             header_position -= header_size
///             arc_offset = header_position - header_offset
///             if arc_offset < 0:
///                 raise ZipImportError(f'bad central directory size or offset: {archive!r}', path=archive)
///
///             files = {}
///             # Start of Central Directory
///             count = 0
///             try:
///                 fp.seek(header_position)
///             except OSError:
///                 raise ZipImportError(f"can't read Zip file: {archive!r}", path=archive)
///             while True:
///                 buffer = fp.read(46)
///                 if len(buffer) < 4:
///                     raise EOFError('EOF read where not expected')
///                 # Start of file header
///                 if buffer[:4] != b'PK\x01\x02':
///                     break                                # Bad: Central Dir File Header
///                 if len(buffer) != 46:
///                     raise EOFError('EOF read where not expected')
///                 flags = _unpack_uint16(buffer[8:10])
///                 compress = _unpack_uint16(buffer[10:12])
///                 time = _unpack_uint16(buffer[12:14])
///                 date = _unpack_uint16(buffer[14:16])
///                 crc = _unpack_uint32(buffer[16:20])
///                 data_size = _unpack_uint32(buffer[20:24])
///                 file_size = _unpack_uint32(buffer[24:28])
///                 name_size = _unpack_uint16(buffer[28:30])
///                 extra_size = _unpack_uint16(buffer[30:32])
///                 comment_size = _unpack_uint16(buffer[32:34])
///                 file_offset = _unpack_uint32(buffer[42:46])
///                 header_size = name_size + extra_size + comment_size
///                 if file_offset > header_offset:
///                     raise ZipImportError(f'bad local header offset: {archive!r}', path=archive)
///                 file_offset += arc_offset
///
///                 try:
///                     name = fp.read(name_size)
///                 except OSError:
///                     raise ZipImportError(f"can't read Zip file: {archive!r}", path=archive)
///                 if len(name) != name_size:
///                     raise ZipImportError(f"can't read Zip file: {archive!r}", path=archive)
///                 # On Windows, calling fseek to skip over the fields we don't use is
///                 # slower than reading the data because fseek flushes stdio's
///                 # internal buffers.    See issue #8745.
///                 try:
///                     if len(fp.read(header_size - name_size)) != header_size - name_size:
///                         raise ZipImportError(f"can't read Zip file: {archive!r}", path=archive)
///                 except OSError:
///                     raise ZipImportError(f"can't read Zip file: {archive!r}", path=archive)
///
///                 if flags & 0x800:
///                     # UTF-8 file names extension
///                     name = name.decode()
///                 else:
///                     # Historical ZIP filename encoding
///                     try:
///                         name = name.decode('ascii')
///                     except UnicodeDecodeError:
///                         name = name.decode('latin1').translate(cp437_table)
///
///                 name = name.replace('/', path_sep)
///                 path = _bootstrap_external._path_join(archive, name)
///                 t = (path, compress, data_size, file_size, file_offset, time, date, crc)
///                 files[name] = t
///                 count += 1
///         finally:
///             fp.seek(start_offset)
///     _bootstrap._verbose_message('zipimport: found {} names in {!r}', count, archive)
///     return files
///
/// # During bootstrap, we may need to load the encodings
/// # package from a ZIP file. But the cp437 encoding is implemented
/// # in Python in the encodings package.
/// #
/// # Break out of this dependency by using the translation table for
/// # the cp437 encoding.
/// cp437_table = (
///     # ASCII part, 8 rows x 16 chars
///     '\x00\x01\x02\x03\x04\x05\x06\x07\x08\t\n\x0b\x0c\r\x0e\x0f'
///     '\x10\x11\x12\x13\x14\x15\x16\x17\x18\x19\x1a\x1b\x1c\x1d\x1e\x1f'
///     ' !"#$%&\'()*+,-./'
///     '0123456789:;<=>?'
///     '@ABCDEFGHIJKLMNO'
///     'PQRSTUVWXYZ[\\]^_'
///     '`abcdefghijklmno'
///     'pqrstuvwxyz{|}~\x7f'
///     # non-ASCII part, 16 rows x 8 chars
///     '\xc7\xfc\xe9\xe2\xe4\xe0\xe5\xe7'
///     '\xea\xeb\xe8\xef\xee\xec\xc4\xc5'
///     '\xc9\xe6\xc6\xf4\xf6\xf2\xfb\xf9'
///     '\xff\xd6\xdc\xa2\xa3\xa5\u20a7\u0192'
///     '\xe1\xed\xf3\xfa\xf1\xd1\xaa\xba'
///     '\xbf\u2310\xac\xbd\xbc\xa1\xab\xbb'
///     '\u2591\u2592\u2593\u2502\u2524\u2561\u2562\u2556'
///     '\u2555\u2563\u2551\u2557\u255d\u255c\u255b\u2510'
///     '\u2514\u2534\u252c\u251c\u2500\u253c\u255e\u255f'
///     '\u255a\u2554\u2569\u2566\u2560\u2550\u256c\u2567'
///     '\u2568\u2564\u2565\u2559\u2558\u2552\u2553\u256b'
///     '\u256a\u2518\u250c\u2588\u2584\u258c\u2590\u2580'
///     '\u03b1\xdf\u0393\u03c0\u03a3\u03c3\xb5\u03c4'
///     '\u03a6\u0398\u03a9\u03b4\u221e\u03c6\u03b5\u2229'
///     '\u2261\xb1\u2265\u2264\u2320\u2321\xf7\u2248'
///     '\xb0\u2219\xb7\u221a\u207f\xb2\u25a0\xa0'
/// )
///
/// _importing_zlib = False
///
/// # Return the zlib.decompress function object, or NULL if zlib couldn't
/// # be imported. The function is cached when found, so subsequent calls
/// # don't import zlib again.
/// def _get_decompress_func():
///     global _importing_zlib
///     if _importing_zlib:
///         # Someone has a zlib.py[co] in their Zip file
///         # let's avoid a stack overflow.
///         _bootstrap._verbose_message('zipimport: zlib UNAVAILABLE')
///         raise ZipImportError("can't decompress data; zlib not available")
///
///     _importing_zlib = True
///     try:
///         from zlib import decompress
///     except Exception:
///         _bootstrap._verbose_message('zipimport: zlib UNAVAILABLE')
///         raise ZipImportError("can't decompress data; zlib not available")
///     finally:
///         _importing_zlib = False
///
///     _bootstrap._verbose_message('zipimport: zlib available')
///     return decompress
///
/// # Given a path to a Zip file and a toc_entry, return the (uncompressed) data.
/// def _get_data(archive, toc_entry):
///     datapath, compress, data_size, file_size, file_offset, time, date, crc = toc_entry
///     if data_size < 0:
///         raise ZipImportError('negative data size')
///
///     with _io.open_code(archive) as fp:
///         # Check to make sure the local file header is correct
///         try:
///             fp.seek(file_offset)
///         except OSError:
///             raise ZipImportError(f"can't read Zip file: {archive!r}", path=archive)
///         buffer = fp.read(30)
///         if len(buffer) != 30:
///             raise EOFError('EOF read where not expected')
///
///         if buffer[:4] != b'PK\x03\x04':
///             # Bad: Local File Header
///             raise ZipImportError(f'bad local file header: {archive!r}', path=archive)
///
///         name_size = _unpack_uint16(buffer[26:28])
///         extra_size = _unpack_uint16(buffer[28:30])
///         header_size = 30 + name_size + extra_size
///         file_offset += header_size  # Start of file data
///         try:
///             fp.seek(file_offset)
///         except OSError:
///             raise ZipImportError(f"can't read Zip file: {archive!r}", path=archive)
///         raw_data = fp.read(data_size)
///         if len(raw_data) != data_size:
///             raise OSError("zipimport: can't read data")
///
///     if compress == 0:
///         # data is not compressed
///         return raw_data
///
///     # Decompress with zlib
///     try:
///         decompress = _get_decompress_func()
///     except Exception:
///         raise ZipImportError("can't decompress data; zlib not available")
///     return decompress(raw_data, -15)
///
///
/// # Lenient date/time comparison function. The precision of the mtime
/// # in the archive is lower than the mtime stored in a .pyc: we
/// # must allow a difference of at most one second.
/// def _eq_mtime(t1, t2):
///     # dostime only stores even seconds, so be lenient
///     return abs(t1 - t2) <= 1
///
///
/// # Given the contents of a .py[co] file, unmarshal the data
/// # and return the code object. Raises ImportError it the magic word doesn't
/// # match, or if the recorded .py[co] metadata does not match the source.
/// def _unmarshal_code(self, pathname, fullpath, fullname, data):
///     exc_details = {
///         'name': fullname,
///         'path': fullpath,
///     }
///
///     flags = _bootstrap_external._classify_pyc(data, fullname, exc_details)
///
///     hash_based = flags & 0b1 != 0
///     if hash_based:
///         check_source = flags & 0b10 != 0
///         if (_imp.check_hash_based_pycs != 'never' and
///                 (check_source or _imp.check_hash_based_pycs == 'always')):
///             source_bytes = _get_pyc_source(self, fullpath)
///             if source_bytes is not None:
///                 source_hash = _imp.source_hash(
///                     _bootstrap_external._RAW_MAGIC_NUMBER,
///                     source_bytes,
///                 )
///
///                 _bootstrap_external._validate_hash_pyc(
///                     data, source_hash, fullname, exc_details)
///     else:
///         source_mtime, source_size = \
///             _get_mtime_and_size_of_source(self, fullpath)
///
///         if source_mtime:
///             # We don't use _bootstrap_external._validate_timestamp_pyc
///             # to allow for a more lenient timestamp check.
///             if (not _eq_mtime(_unpack_uint32(data[8:12]), source_mtime) or
///                     _unpack_uint32(data[12:16]) != source_size):
///                 _bootstrap._verbose_message(
///                     f'bytecode is stale for {fullname!r}')
///                 return None
///
///     code = marshal.loads(data[16:])
///     if not isinstance(code, _code_type):
///         raise TypeError(f'compiled module {pathname!r} is not a code object')
///     return code
///
/// _code_type = type(_unmarshal_code.__code__)
///
///
/// # Replace any occurrences of '\r\n?' in the input string with '\n'.
/// # This converts DOS and Mac line endings to Unix line endings.
/// def _normalize_line_endings(source):
///     source = source.replace(b'\r\n', b'\n')
///     source = source.replace(b'\r', b'\n')
///     return source
///
/// # Given a string buffer containing Python source code, compile it
/// # and return a code object.
/// def _compile_source(pathname, source):
///     source = _normalize_line_endings(source)
///     return compile(source, pathname, 'exec', dont_inherit=True)
///
/// # Convert the date/time values found in the Zip archive to a value
/// # that's compatible with the time stamp stored in .pyc files.
/// def _parse_dostime(d, t):
///     return time.mktime((
///         (d >> 9) + 1980,    # bits 9..15: year
///         (d >> 5) & 0xF,     # bits 5..8: month
///         d & 0x1F,           # bits 0..4: day
///         t >> 11,            # bits 11..15: hours
///         (t >> 5) & 0x3F,    # bits 8..10: minutes
///         (t & 0x1F) * 2,     # bits 0..7: seconds / 2
///         -1, -1, -1))
///
/// # Given a path to a .pyc file in the archive, return the
/// # modification time of the matching .py file and its size,
/// # or (0, 0) if no source is available.
/// def _get_mtime_and_size_of_source(self, path):
///     try:
///         # strip 'c' or 'o' from *.py[co]
///         assert path[-1:] in ('c', 'o')
///         path = path[:-1]
///         toc_entry = self._files[path]
///         # fetch the time stamp of the .py file for comparison
///         # with an embedded pyc time stamp
///         time = toc_entry[5]
///         date = toc_entry[6]
///         uncompressed_size = toc_entry[3]
///         return _parse_dostime(date, time), uncompressed_size
///     except (KeyError, IndexError, TypeError):
///         return 0, 0
///
///
/// # Given a path to a .pyc file in the archive, return the
/// # contents of the matching .py file, or None if no source
/// # is available.
/// def _get_pyc_source(self, path):
///     # strip 'c' or 'o' from *.py[co]
///     assert path[-1:] in ('c', 'o')
///     path = path[:-1]
///
///     try:
///         toc_entry = self._files[path]
///     except KeyError:
///         return None
///     else:
///         return _get_data(self.archive, toc_entry)
///
///
/// # Get the code object associated with the module specified by
/// # 'fullname'.
/// def _get_module_code(self, fullname):
///     path = _get_module_path(self, fullname)
///     import_error = None
///     for suffix, isbytecode, ispackage in _zip_searchorder:
///         fullpath = path + suffix
///         _bootstrap._verbose_message('trying {}{}{}', self.archive, path_sep, fullpath, verbosity=2)
///         try:
///             toc_entry = self._files[fullpath]
///         except KeyError:
///             pass
///         else:
///             modpath = toc_entry[0]
///             data = _get_data(self.archive, toc_entry)
///             code = None
///             if isbytecode:
///                 try:
///                     code = _unmarshal_code(self, modpath, fullpath, fullname, data)
///                 except ImportError as exc:
///                     import_error = exc
///             else:
///                 code = _compile_source(modpath, data)
///             if code is None:
///                 # bad magic number or non-matching mtime
///                 # in byte code, try next
///                 continue
///             modpath = toc_entry[0]
///             return code, ispackage, modpath
///     else:
///         if import_error:
///             msg = f"module load failed: {import_error}"
///             raise ZipImportError(msg, name=fullname) from import_error
///         else:
///             raise ZipImportError(f"can't find module {fullname!r}", name=fullname)
/// ```
final class zipimport extends PythonModule {
  zipimport.from(super.pythonModule) : super.from();

  static zipimport import() => PythonFfiDart.instance.importModule(
        "zipimport",
        zipimport.from,
      );

  /// ## END_CENTRAL_DIR_SIZE (getter)
  Object? get END_CENTRAL_DIR_SIZE => getAttribute("END_CENTRAL_DIR_SIZE");

  /// ## END_CENTRAL_DIR_SIZE (setter)
  set END_CENTRAL_DIR_SIZE(Object? END_CENTRAL_DIR_SIZE) =>
      setAttribute("END_CENTRAL_DIR_SIZE", END_CENTRAL_DIR_SIZE);

  /// ## MAX_COMMENT_LEN (getter)
  Object? get MAX_COMMENT_LEN => getAttribute("MAX_COMMENT_LEN");

  /// ## MAX_COMMENT_LEN (setter)
  set MAX_COMMENT_LEN(Object? MAX_COMMENT_LEN) =>
      setAttribute("MAX_COMMENT_LEN", MAX_COMMENT_LEN);

  /// ## STRING_END_ARCHIVE (getter)
  Object? get STRING_END_ARCHIVE => getAttribute("STRING_END_ARCHIVE");

  /// ## STRING_END_ARCHIVE (setter)
  set STRING_END_ARCHIVE(Object? STRING_END_ARCHIVE) =>
      setAttribute("STRING_END_ARCHIVE", STRING_END_ARCHIVE);

  /// ## alt_path_sep (getter)
  Object? get alt_path_sep => getAttribute("alt_path_sep");

  /// ## alt_path_sep (setter)
  set alt_path_sep(Object? alt_path_sep) =>
      setAttribute("alt_path_sep", alt_path_sep);

  /// ## cp437_table (getter)
  Object? get cp437_table => getAttribute("cp437_table");

  /// ## cp437_table (setter)
  set cp437_table(Object? cp437_table) =>
      setAttribute("cp437_table", cp437_table);

  /// ## path_sep (getter)
  Object? get path_sep => getAttribute("path_sep");

  /// ## path_sep (setter)
  set path_sep(Object? path_sep) => setAttribute("path_sep", path_sep);
}

/// ## marshal
final class marshal extends PythonModule {
  marshal.from(super.pythonModule) : super.from();

  static marshal import() => PythonFfiDart.instance.importModule(
        "marshal",
        marshal.from,
      );

  /// ## version (getter)
  Object? get version => getAttribute("version");

  /// ## version (setter)
  set version(Object? version) => setAttribute("version", version);
}

/// ## time
final class time extends PythonModule {
  time.from(super.pythonModule) : super.from();

  static time import() => PythonFfiDart.instance.importModule(
        "time",
        time.from,
      );

  /// ## CLOCK_MONOTONIC (getter)
  Object? get CLOCK_MONOTONIC => getAttribute("CLOCK_MONOTONIC");

  /// ## CLOCK_MONOTONIC (setter)
  set CLOCK_MONOTONIC(Object? CLOCK_MONOTONIC) =>
      setAttribute("CLOCK_MONOTONIC", CLOCK_MONOTONIC);

  /// ## CLOCK_MONOTONIC_RAW (getter)
  Object? get CLOCK_MONOTONIC_RAW => getAttribute("CLOCK_MONOTONIC_RAW");

  /// ## CLOCK_MONOTONIC_RAW (setter)
  set CLOCK_MONOTONIC_RAW(Object? CLOCK_MONOTONIC_RAW) =>
      setAttribute("CLOCK_MONOTONIC_RAW", CLOCK_MONOTONIC_RAW);

  /// ## CLOCK_PROCESS_CPUTIME_ID (getter)
  Object? get CLOCK_PROCESS_CPUTIME_ID =>
      getAttribute("CLOCK_PROCESS_CPUTIME_ID");

  /// ## CLOCK_PROCESS_CPUTIME_ID (setter)
  set CLOCK_PROCESS_CPUTIME_ID(Object? CLOCK_PROCESS_CPUTIME_ID) =>
      setAttribute("CLOCK_PROCESS_CPUTIME_ID", CLOCK_PROCESS_CPUTIME_ID);

  /// ## CLOCK_REALTIME (getter)
  Object? get CLOCK_REALTIME => getAttribute("CLOCK_REALTIME");

  /// ## CLOCK_REALTIME (setter)
  set CLOCK_REALTIME(Object? CLOCK_REALTIME) =>
      setAttribute("CLOCK_REALTIME", CLOCK_REALTIME);

  /// ## CLOCK_THREAD_CPUTIME_ID (getter)
  Object? get CLOCK_THREAD_CPUTIME_ID =>
      getAttribute("CLOCK_THREAD_CPUTIME_ID");

  /// ## CLOCK_THREAD_CPUTIME_ID (setter)
  set CLOCK_THREAD_CPUTIME_ID(Object? CLOCK_THREAD_CPUTIME_ID) =>
      setAttribute("CLOCK_THREAD_CPUTIME_ID", CLOCK_THREAD_CPUTIME_ID);

  /// ## CLOCK_UPTIME_RAW (getter)
  Object? get CLOCK_UPTIME_RAW => getAttribute("CLOCK_UPTIME_RAW");

  /// ## CLOCK_UPTIME_RAW (setter)
  set CLOCK_UPTIME_RAW(Object? CLOCK_UPTIME_RAW) =>
      setAttribute("CLOCK_UPTIME_RAW", CLOCK_UPTIME_RAW);

  /// ## altzone (getter)
  Object? get altzone => getAttribute("altzone");

  /// ## altzone (setter)
  set altzone(Object? altzone) => setAttribute("altzone", altzone);

  /// ## daylight (getter)
  Object? get daylight => getAttribute("daylight");

  /// ## daylight (setter)
  set daylight(Object? daylight) => setAttribute("daylight", daylight);

  /// ## timezone (getter)
  Object? get timezone => getAttribute("timezone");

  /// ## timezone (setter)
  set timezone(Object? timezone) => setAttribute("timezone", timezone);

  /// ## tzname (getter)
  Object? get tzname => getAttribute("tzname");

  /// ## tzname (setter)
  set tzname(Object? tzname) => setAttribute("tzname", tzname);
}

/// ## parse_tree_builder
///
/// ### python source
/// ```py
/// from typing import List
///
/// from .exceptions import GrammarError, ConfigurationError
/// from .lexer import Token
/// from .tree import Tree
/// from .visitors import Transformer_InPlace
/// from .visitors import _vargs_meta, _vargs_meta_inline
///
/// ###{standalone
/// from functools import partial, wraps
/// from itertools import product
///
///
/// class ExpandSingleChild:
///     def __init__(self, node_builder):
///         self.node_builder = node_builder
///
///     def __call__(self, children):
///         if len(children) == 1:
///             return children[0]
///         else:
///             return self.node_builder(children)
///
///
///
/// class PropagatePositions:
///     def __init__(self, node_builder, node_filter=None):
///         self.node_builder = node_builder
///         self.node_filter = node_filter
///
///     def __call__(self, children):
///         res = self.node_builder(children)
///
///         if isinstance(res, Tree):
///             # Calculate positions while the tree is streaming, according to the rule:
///             # - nodes start at the start of their first child's container,
///             #   and end at the end of their last child's container.
///             # Containers are nodes that take up space in text, but have been inlined in the tree.
///
///             res_meta = res.meta
///
///             first_meta = self._pp_get_meta(children)
///             if first_meta is not None:
///                 if not hasattr(res_meta, 'line'):
///                     # meta was already set, probably because the rule has been inlined (e.g. `?rule`)
///                     res_meta.line = getattr(first_meta, 'container_line', first_meta.line)
///                     res_meta.column = getattr(first_meta, 'container_column', first_meta.column)
///                     res_meta.start_pos = getattr(first_meta, 'container_start_pos', first_meta.start_pos)
///                     res_meta.empty = False
///
///                 res_meta.container_line = getattr(first_meta, 'container_line', first_meta.line)
///                 res_meta.container_column = getattr(first_meta, 'container_column', first_meta.column)
///
///             last_meta = self._pp_get_meta(reversed(children))
///             if last_meta is not None:
///                 if not hasattr(res_meta, 'end_line'):
///                     res_meta.end_line = getattr(last_meta, 'container_end_line', last_meta.end_line)
///                     res_meta.end_column = getattr(last_meta, 'container_end_column', last_meta.end_column)
///                     res_meta.end_pos = getattr(last_meta, 'container_end_pos', last_meta.end_pos)
///                     res_meta.empty = False
///
///                 res_meta.container_end_line = getattr(last_meta, 'container_end_line', last_meta.end_line)
///                 res_meta.container_end_column = getattr(last_meta, 'container_end_column', last_meta.end_column)
///
///         return res
///
///     def _pp_get_meta(self, children):
///         for c in children:
///             if self.node_filter is not None and not self.node_filter(c):
///                 continue
///             if isinstance(c, Tree):
///                 if not c.meta.empty:
///                     return c.meta
///             elif isinstance(c, Token):
///                 return c
///             elif hasattr(c, '__lark_meta__'):
///                 return c.__lark_meta__()
///
/// def make_propagate_positions(option):
///     if callable(option):
///         return partial(PropagatePositions, node_filter=option)
///     elif option is True:
///         return PropagatePositions
///     elif option is False:
///         return None
///
///     raise ConfigurationError('Invalid option for propagate_positions: %r' % option)
///
///
/// class ChildFilter:
///     def __init__(self, to_include, append_none, node_builder):
///         self.node_builder = node_builder
///         self.to_include = to_include
///         self.append_none = append_none
///
///     def __call__(self, children):
///         filtered = []
///
///         for i, to_expand, add_none in self.to_include:
///             if add_none:
///                 filtered += [None] * add_none
///             if to_expand:
///                 filtered += children[i].children
///             else:
///                 filtered.append(children[i])
///
///         if self.append_none:
///             filtered += [None] * self.append_none
///
///         return self.node_builder(filtered)
///
///
/// class ChildFilterLALR(ChildFilter):
///     """Optimized childfilter for LALR (assumes no duplication in parse tree, so it's safe to change it)"""
///
///     def __call__(self, children):
///         filtered = []
///         for i, to_expand, add_none in self.to_include:
///             if add_none:
///                 filtered += [None] * add_none
///             if to_expand:
///                 if filtered:
///                     filtered += children[i].children
///                 else:   # Optimize for left-recursion
///                     filtered = children[i].children
///             else:
///                 filtered.append(children[i])
///
///         if self.append_none:
///             filtered += [None] * self.append_none
///
///         return self.node_builder(filtered)
///
///
/// class ChildFilterLALR_NoPlaceholders(ChildFilter):
///     "Optimized childfilter for LALR (assumes no duplication in parse tree, so it's safe to change it)"
///     def __init__(self, to_include, node_builder):
///         self.node_builder = node_builder
///         self.to_include = to_include
///
///     def __call__(self, children):
///         filtered = []
///         for i, to_expand in self.to_include:
///             if to_expand:
///                 if filtered:
///                     filtered += children[i].children
///                 else:   # Optimize for left-recursion
///                     filtered = children[i].children
///             else:
///                 filtered.append(children[i])
///         return self.node_builder(filtered)
///
///
/// def _should_expand(sym):
///     return not sym.is_term and sym.name.startswith('_')
///
///
/// def maybe_create_child_filter(expansion, keep_all_tokens, ambiguous, _empty_indices: List[bool]):
///     # Prepare empty_indices as: How many Nones to insert at each index?
///     if _empty_indices:
///         assert _empty_indices.count(False) == len(expansion)
///         s = ''.join(str(int(b)) for b in _empty_indices)
///         empty_indices = [len(ones) for ones in s.split('0')]
///         assert len(empty_indices) == len(expansion)+1, (empty_indices, len(expansion))
///     else:
///         empty_indices = [0] * (len(expansion)+1)
///
///     to_include = []
///     nones_to_add = 0
///     for i, sym in enumerate(expansion):
///         nones_to_add += empty_indices[i]
///         if keep_all_tokens or not (sym.is_term and sym.filter_out):
///             to_include.append((i, _should_expand(sym), nones_to_add))
///             nones_to_add = 0
///
///     nones_to_add += empty_indices[len(expansion)]
///
///     if _empty_indices or len(to_include) < len(expansion) or any(to_expand for i, to_expand,_ in to_include):
///         if _empty_indices or ambiguous:
///             return partial(ChildFilter if ambiguous else ChildFilterLALR, to_include, nones_to_add)
///         else:
///             # LALR without placeholders
///             return partial(ChildFilterLALR_NoPlaceholders, [(i, x) for i,x,_ in to_include])
///
///
/// class AmbiguousExpander:
///     """Deal with the case where we're expanding children ('_rule') into a parent but the children
///        are ambiguous. i.e. (parent->_ambig->_expand_this_rule). In this case, make the parent itself
///        ambiguous with as many copies as there are ambiguous children, and then copy the ambiguous children
///        into the right parents in the right places, essentially shifting the ambiguity up the tree."""
///     def __init__(self, to_expand, tree_class, node_builder):
///         self.node_builder = node_builder
///         self.tree_class = tree_class
///         self.to_expand = to_expand
///
///     def __call__(self, children):
///         def _is_ambig_tree(t):
///             return hasattr(t, 'data') and t.data == '_ambig'
///
///         # -- When we're repeatedly expanding ambiguities we can end up with nested ambiguities.
///         #    All children of an _ambig node should be a derivation of that ambig node, hence
///         #    it is safe to assume that if we see an _ambig node nested within an ambig node
///         #    it is safe to simply expand it into the parent _ambig node as an alternative derivation.
///         ambiguous = []
///         for i, child in enumerate(children):
///             if _is_ambig_tree(child):
///                 if i in self.to_expand:
///                     ambiguous.append(i)
///
///                 child.expand_kids_by_data('_ambig')
///
///         if not ambiguous:
///             return self.node_builder(children)
///
///         expand = [child.children if i in ambiguous else (child,) for i, child in enumerate(children)]
///         return self.tree_class('_ambig', [self.node_builder(list(f)) for f in product(*expand)])
///
///
/// def maybe_create_ambiguous_expander(tree_class, expansion, keep_all_tokens):
///     to_expand = [i for i, sym in enumerate(expansion)
///                  if keep_all_tokens or ((not (sym.is_term and sym.filter_out)) and _should_expand(sym))]
///     if to_expand:
///         return partial(AmbiguousExpander, to_expand, tree_class)
///
///
/// class AmbiguousIntermediateExpander:
///     """
///     Propagate ambiguous intermediate nodes and their derivations up to the
///     current rule.
///
///     In general, converts
///
///     rule
///       _iambig
///         _inter
///           someChildren1
///           ...
///         _inter
///           someChildren2
///           ...
///       someChildren3
///       ...
///
///     to
///
///     _ambig
///       rule
///         someChildren1
///         ...
///         someChildren3
///         ...
///       rule
///         someChildren2
///         ...
///         someChildren3
///         ...
///       rule
///         childrenFromNestedIambigs
///         ...
///         someChildren3
///         ...
///       ...
///
///     propagating up any nested '_iambig' nodes along the way.
///     """
///
///     def __init__(self, tree_class, node_builder):
///         self.node_builder = node_builder
///         self.tree_class = tree_class
///
///     def __call__(self, children):
///         def _is_iambig_tree(child):
///             return hasattr(child, 'data') and child.data == '_iambig'
///
///         def _collapse_iambig(children):
///             """
///             Recursively flatten the derivations of the parent of an '_iambig'
///             node. Returns a list of '_inter' nodes guaranteed not
///             to contain any nested '_iambig' nodes, or None if children does
///             not contain an '_iambig' node.
///             """
///
///             # Due to the structure of the SPPF,
///             # an '_iambig' node can only appear as the first child
///             if children and _is_iambig_tree(children[0]):
///                 iambig_node = children[0]
///                 result = []
///                 for grandchild in iambig_node.children:
///                     collapsed = _collapse_iambig(grandchild.children)
///                     if collapsed:
///                         for child in collapsed:
///                             child.children += children[1:]
///                         result += collapsed
///                     else:
///                         new_tree = self.tree_class('_inter', grandchild.children + children[1:])
///                         result.append(new_tree)
///                 return result
///
///         collapsed = _collapse_iambig(children)
///         if collapsed:
///             processed_nodes = [self.node_builder(c.children) for c in collapsed]
///             return self.tree_class('_ambig', processed_nodes)
///
///         return self.node_builder(children)
///
///
///
/// def inplace_transformer(func):
///     @wraps(func)
///     def f(children):
///         # function name in a Transformer is a rule name.
///         tree = Tree(func.__name__, children)
///         return func(tree)
///     return f
///
///
/// def apply_visit_wrapper(func, name, wrapper):
///     if wrapper is _vargs_meta or wrapper is _vargs_meta_inline:
///         raise NotImplementedError("Meta args not supported for internal transformer")
///
///     @wraps(func)
///     def f(children):
///         return wrapper(func, name, children, None)
///     return f
///
///
/// class ParseTreeBuilder:
///     def __init__(self, rules, tree_class, propagate_positions=False, ambiguous=False, maybe_placeholders=False):
///         self.tree_class = tree_class
///         self.propagate_positions = propagate_positions
///         self.ambiguous = ambiguous
///         self.maybe_placeholders = maybe_placeholders
///
///         self.rule_builders = list(self._init_builders(rules))
///
///     def _init_builders(self, rules):
///         propagate_positions = make_propagate_positions(self.propagate_positions)
///
///         for rule in rules:
///             options = rule.options
///             keep_all_tokens = options.keep_all_tokens
///             expand_single_child = options.expand1
///
///             wrapper_chain = list(filter(None, [
///                 (expand_single_child and not rule.alias) and ExpandSingleChild,
///                 maybe_create_child_filter(rule.expansion, keep_all_tokens, self.ambiguous, options.empty_indices if self.maybe_placeholders else None),
///                 propagate_positions,
///                 self.ambiguous and maybe_create_ambiguous_expander(self.tree_class, rule.expansion, keep_all_tokens),
///                 self.ambiguous and partial(AmbiguousIntermediateExpander, self.tree_class)
///             ]))
///
///             yield rule, wrapper_chain
///
///     def create_callback(self, transformer=None):
///         callbacks = {}
///
///         default_handler = getattr(transformer, '__default__', None)
///         if default_handler:
///             def default_callback(data, children):
///                 return default_handler(data, children, None)
///         else:
///             default_callback = self.tree_class
///
///         for rule, wrapper_chain in self.rule_builders:
///
///             user_callback_name = rule.alias or rule.options.template_source or rule.origin.name
///             try:
///                 f = getattr(transformer, user_callback_name)
///                 wrapper = getattr(f, 'visit_wrapper', None)
///                 if wrapper is not None:
///                     f = apply_visit_wrapper(f, user_callback_name, wrapper)
///                 elif isinstance(transformer, Transformer_InPlace):
///                     f = inplace_transformer(f)
///             except AttributeError:
///                 f = partial(default_callback, user_callback_name)
///
///             for w in wrapper_chain:
///                 f = w(f)
///
///             if rule in callbacks:
///                 raise GrammarError("Rule '%s' already exists" % (rule,))
///
///             callbacks[rule] = f
///
///         return callbacks
///
/// ###}
/// ```
final class parse_tree_builder extends PythonModule {
  parse_tree_builder.from(super.pythonModule) : super.from();

  static parse_tree_builder import() => PythonFfiDart.instance.importModule(
        "lark.parse_tree_builder",
        parse_tree_builder.from,
      );

  /// ## apply_visit_wrapper
  ///
  /// ### python source
  /// ```py
  /// def apply_visit_wrapper(func, name, wrapper):
  ///     if wrapper is _vargs_meta or wrapper is _vargs_meta_inline:
  ///         raise NotImplementedError("Meta args not supported for internal transformer")
  ///
  ///     @wraps(func)
  ///     def f(children):
  ///         return wrapper(func, name, children, None)
  ///     return f
  /// ```
  Object? apply_visit_wrapper({
    required Object? func,
    required Object? name,
    required Object? wrapper,
  }) =>
      getFunction("apply_visit_wrapper").call(
        <Object?>[
          func,
          name,
          wrapper,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## inplace_transformer
  ///
  /// ### python source
  /// ```py
  /// def inplace_transformer(func):
  ///     @wraps(func)
  ///     def f(children):
  ///         # function name in a Transformer is a rule name.
  ///         tree = Tree(func.__name__, children)
  ///         return func(tree)
  ///     return f
  /// ```
  Object? inplace_transformer({
    required Object? func,
  }) =>
      getFunction("inplace_transformer").call(
        <Object?>[
          func,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## make_propagate_positions
  ///
  /// ### python source
  /// ```py
  /// def make_propagate_positions(option):
  ///     if callable(option):
  ///         return partial(PropagatePositions, node_filter=option)
  ///     elif option is True:
  ///         return PropagatePositions
  ///     elif option is False:
  ///         return None
  ///
  ///     raise ConfigurationError('Invalid option for propagate_positions: %r' % option)
  /// ```
  Object? make_propagate_positions({
    required Object? option,
  }) =>
      getFunction("make_propagate_positions").call(
        <Object?>[
          option,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## maybe_create_ambiguous_expander
  ///
  /// ### python source
  /// ```py
  /// def maybe_create_ambiguous_expander(tree_class, expansion, keep_all_tokens):
  ///     to_expand = [i for i, sym in enumerate(expansion)
  ///                  if keep_all_tokens or ((not (sym.is_term and sym.filter_out)) and _should_expand(sym))]
  ///     if to_expand:
  ///         return partial(AmbiguousExpander, to_expand, tree_class)
  /// ```
  Object? maybe_create_ambiguous_expander({
    required Object? tree_class,
    required Object? expansion,
    required Object? keep_all_tokens,
  }) =>
      getFunction("maybe_create_ambiguous_expander").call(
        <Object?>[
          tree_class,
          expansion,
          keep_all_tokens,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## maybe_create_child_filter
  ///
  /// ### python source
  /// ```py
  /// def maybe_create_child_filter(expansion, keep_all_tokens, ambiguous, _empty_indices: List[bool]):
  ///     # Prepare empty_indices as: How many Nones to insert at each index?
  ///     if _empty_indices:
  ///         assert _empty_indices.count(False) == len(expansion)
  ///         s = ''.join(str(int(b)) for b in _empty_indices)
  ///         empty_indices = [len(ones) for ones in s.split('0')]
  ///         assert len(empty_indices) == len(expansion)+1, (empty_indices, len(expansion))
  ///     else:
  ///         empty_indices = [0] * (len(expansion)+1)
  ///
  ///     to_include = []
  ///     nones_to_add = 0
  ///     for i, sym in enumerate(expansion):
  ///         nones_to_add += empty_indices[i]
  ///         if keep_all_tokens or not (sym.is_term and sym.filter_out):
  ///             to_include.append((i, _should_expand(sym), nones_to_add))
  ///             nones_to_add = 0
  ///
  ///     nones_to_add += empty_indices[len(expansion)]
  ///
  ///     if _empty_indices or len(to_include) < len(expansion) or any(to_expand for i, to_expand,_ in to_include):
  ///         if _empty_indices or ambiguous:
  ///             return partial(ChildFilter if ambiguous else ChildFilterLALR, to_include, nones_to_add)
  ///         else:
  ///             # LALR without placeholders
  ///             return partial(ChildFilterLALR_NoPlaceholders, [(i, x) for i,x,_ in to_include])
  /// ```
  Object? maybe_create_child_filter({
    required Object? expansion,
    required Object? keep_all_tokens,
    required Object? ambiguous,
    required Object? $_empty_indices,
  }) =>
      getFunction("maybe_create_child_filter").call(
        <Object?>[
          expansion,
          keep_all_tokens,
          ambiguous,
          $_empty_indices,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## parser_frontends
///
/// ### python source
/// ```py
/// from typing import Any, Callable, Dict, Tuple
///
/// from .exceptions import ConfigurationError, GrammarError, assert_config
/// from .utils import get_regexp_width, Serialize
/// from .parsers.grammar_analysis import GrammarAnalyzer
/// from .lexer import LexerThread, BasicLexer, ContextualLexer, Lexer
/// from .parsers import earley, xearley, cyk
/// from .parsers.lalr_parser import LALR_Parser
/// from .tree import Tree
/// from .common import LexerConf, ParserConf, _ParserArgType, _LexerArgType
///
/// ###{standalone
///
/// def _wrap_lexer(lexer_class):
///     future_interface = getattr(lexer_class, '__future_interface__', False)
///     if future_interface:
///         return lexer_class
///     else:
///         class CustomLexerWrapper(Lexer):
///             def __init__(self, lexer_conf):
///                 self.lexer = lexer_class(lexer_conf)
///             def lex(self, lexer_state, parser_state):
///                 return self.lexer.lex(lexer_state.text)
///         return CustomLexerWrapper
///
///
/// def _deserialize_parsing_frontend(data, memo, lexer_conf, callbacks, options):
///     parser_conf = ParserConf.deserialize(data['parser_conf'], memo)
///     cls = (options and options._plugins.get('LALR_Parser')) or LALR_Parser
///     parser = cls.deserialize(data['parser'], memo, callbacks, options.debug)
///     parser_conf.callbacks = callbacks
///     return ParsingFrontend(lexer_conf, parser_conf, options, parser=parser)
///
///
/// _parser_creators: 'Dict[str, Callable[[LexerConf, Any, Any], Any]]' = {}
///
///
/// class ParsingFrontend(Serialize):
///     __serialize_fields__ = 'lexer_conf', 'parser_conf', 'parser'
///
///     def __init__(self, lexer_conf, parser_conf, options, parser=None):
///         self.parser_conf = parser_conf
///         self.lexer_conf = lexer_conf
///         self.options = options
///
///         # Set-up parser
///         if parser:  # From cache
///             self.parser = parser
///         else:
///             create_parser = _parser_creators.get(parser_conf.parser_type)
///             assert create_parser is not None, "{} is not supported in standalone mode".format(
///                     parser_conf.parser_type
///                 )
///             self.parser = create_parser(lexer_conf, parser_conf, options)
///
///         # Set-up lexer
///         lexer_type = lexer_conf.lexer_type
///         self.skip_lexer = False
///         if lexer_type in ('dynamic', 'dynamic_complete'):
///             assert lexer_conf.postlex is None
///             self.skip_lexer = True
///             return
///
///         try:
///             create_lexer = {
///                 'basic': create_basic_lexer,
///                 'contextual': create_contextual_lexer,
///             }[lexer_type]
///         except KeyError:
///             assert issubclass(lexer_type, Lexer), lexer_type
///             self.lexer = _wrap_lexer(lexer_type)(lexer_conf)
///         else:
///             self.lexer = create_lexer(lexer_conf, self.parser, lexer_conf.postlex, options)
///
///         if lexer_conf.postlex:
///             self.lexer = PostLexConnector(self.lexer, lexer_conf.postlex)
///
///     def _verify_start(self, start=None):
///         if start is None:
///             start_decls = self.parser_conf.start
///             if len(start_decls) > 1:
///                 raise ConfigurationError("Lark initialized with more than 1 possible start rule. Must specify which start rule to parse", start_decls)
///             start ,= start_decls
///         elif start not in self.parser_conf.start:
///             raise ConfigurationError("Unknown start rule %s. Must be one of %r" % (start, self.parser_conf.start))
///         return start
///
///     def _make_lexer_thread(self, text):
///         cls = (self.options and self.options._plugins.get('LexerThread')) or LexerThread
///         return text if self.skip_lexer else cls.from_text(self.lexer, text)
///
///     def parse(self, text, start=None, on_error=None):
///         chosen_start = self._verify_start(start)
///         kw = {} if on_error is None else {'on_error': on_error}
///         stream = self._make_lexer_thread(text)
///         return self.parser.parse(stream, chosen_start, **kw)
///
///     def parse_interactive(self, text=None, start=None):
///         chosen_start = self._verify_start(start)
///         if self.parser_conf.parser_type != 'lalr':
///             raise ConfigurationError("parse_interactive() currently only works with parser='lalr' ")
///         stream = self._make_lexer_thread(text)
///         return self.parser.parse_interactive(stream, chosen_start)
///
///
/// def _validate_frontend_args(parser, lexer) -> None:
///     assert_config(parser, ('lalr', 'earley', 'cyk'))
///     if not isinstance(lexer, type):     # not custom lexer?
///         expected = {
///             'lalr': ('basic', 'contextual'),
///             'earley': ('basic', 'dynamic', 'dynamic_complete'),
///             'cyk': ('basic', ),
///          }[parser]
///         assert_config(lexer, expected, 'Parser %r does not support lexer %%r, expected one of %%s' % parser)
///
///
/// def _get_lexer_callbacks(transformer, terminals):
///     result = {}
///     for terminal in terminals:
///         callback = getattr(transformer, terminal.name, None)
///         if callback is not None:
///             result[terminal.name] = callback
///     return result
///
/// class PostLexConnector:
///     def __init__(self, lexer, postlexer):
///         self.lexer = lexer
///         self.postlexer = postlexer
///
///     def lex(self, lexer_state, parser_state):
///         i = self.lexer.lex(lexer_state, parser_state)
///         return self.postlexer.process(i)
///
///
///
/// def create_basic_lexer(lexer_conf, parser, postlex, options):
///     cls = (options and options._plugins.get('BasicLexer')) or BasicLexer
///     return cls(lexer_conf)
///
/// def create_contextual_lexer(lexer_conf, parser, postlex, options):
///     cls = (options and options._plugins.get('ContextualLexer')) or ContextualLexer
///     states = {idx:list(t.keys()) for idx, t in parser._parse_table.states.items()}
///     always_accept = postlex.always_accept if postlex else ()
///     return cls(lexer_conf, states, always_accept=always_accept)
///
/// def create_lalr_parser(lexer_conf, parser_conf, options=None):
///     debug = options.debug if options else False
///     cls = (options and options._plugins.get('LALR_Parser')) or LALR_Parser
///     return cls(parser_conf, debug=debug)
///
/// _parser_creators['lalr'] = create_lalr_parser
///
/// ###}
///
/// class EarleyRegexpMatcher:
///     def __init__(self, lexer_conf):
///         self.regexps = {}
///         for t in lexer_conf.terminals:
///             regexp = t.pattern.to_regexp()
///             try:
///                 width = get_regexp_width(regexp)[0]
///             except ValueError:
///                 raise GrammarError("Bad regexp in token %s: %s" % (t.name, regexp))
///             else:
///                 if width == 0:
///                     raise GrammarError("Dynamic Earley doesn't allow zero-width regexps", t)
///             if lexer_conf.use_bytes:
///                 regexp = regexp.encode('utf-8')
///
///             self.regexps[t.name] = lexer_conf.re_module.compile(regexp, lexer_conf.g_regex_flags)
///
///     def match(self, term, text, index=0):
///         return self.regexps[term.name].match(text, index)
///
///
/// def create_earley_parser__dynamic(lexer_conf, parser_conf, options=None, **kw):
///     if lexer_conf.callbacks:
///         raise GrammarError("Earley's dynamic lexer doesn't support lexer_callbacks.")
///
///     earley_matcher = EarleyRegexpMatcher(lexer_conf)
///     return xearley.Parser(lexer_conf, parser_conf, earley_matcher.match, **kw)
///
/// def _match_earley_basic(term, token):
///     return term.name == token.type
///
/// def create_earley_parser__basic(lexer_conf, parser_conf, options, **kw):
///     return earley.Parser(lexer_conf, parser_conf, _match_earley_basic, **kw)
///
/// def create_earley_parser(lexer_conf, parser_conf, options):
///     resolve_ambiguity = options.ambiguity == 'resolve'
///     debug = options.debug if options else False
///     tree_class = options.tree_class or Tree if options.ambiguity != 'forest' else None
///
///     extra = {}
///     if lexer_conf.lexer_type == 'dynamic':
///         f = create_earley_parser__dynamic
///     elif lexer_conf.lexer_type == 'dynamic_complete':
///         extra['complete_lex'] =True
///         f = create_earley_parser__dynamic
///     else:
///         f = create_earley_parser__basic
///
///     return f(lexer_conf, parser_conf, options, resolve_ambiguity=resolve_ambiguity, debug=debug, tree_class=tree_class, **extra)
///
///
///
/// class CYK_FrontEnd:
///     def __init__(self, lexer_conf, parser_conf, options=None):
///         self._analysis = GrammarAnalyzer(parser_conf)
///         self.parser = cyk.Parser(parser_conf.rules)
///
///         self.callbacks = parser_conf.callbacks
///
///     def parse(self, lexer_thread, start):
///         tokens = list(lexer_thread.lex(None))
///         tree = self.parser.parse(tokens, start)
///         return self._transform(tree)
///
///     def _transform(self, tree):
///         subtrees = list(tree.iter_subtrees())
///         for subtree in subtrees:
///             subtree.children = [self._apply_callback(c) if isinstance(c, Tree) else c for c in subtree.children]
///
///         return self._apply_callback(tree)
///
///     def _apply_callback(self, tree):
///         return self.callbacks[tree.rule](tree.children)
///
///
/// _parser_creators['earley'] = create_earley_parser
/// _parser_creators['cyk'] = CYK_FrontEnd
///
///
/// def _construct_parsing_frontend(
///         parser_type: _ParserArgType,
///         lexer_type: _LexerArgType,
///         lexer_conf,
///         parser_conf,
///         options
/// ):
///     assert isinstance(lexer_conf, LexerConf)
///     assert isinstance(parser_conf, ParserConf)
///     parser_conf.parser_type = parser_type
///     lexer_conf.lexer_type = lexer_type
///     return ParsingFrontend(lexer_conf, parser_conf, options)
/// ```
final class parser_frontends extends PythonModule {
  parser_frontends.from(super.pythonModule) : super.from();

  static parser_frontends import() => PythonFfiDart.instance.importModule(
        "lark.parser_frontends",
        parser_frontends.from,
      );

  /// ## create_basic_lexer
  ///
  /// ### python source
  /// ```py
  /// def create_basic_lexer(lexer_conf, parser, postlex, options):
  ///     cls = (options and options._plugins.get('BasicLexer')) or BasicLexer
  ///     return cls(lexer_conf)
  /// ```
  Object? create_basic_lexer({
    required Object? lexer_conf,
    required Object? parser,
    required Object? postlex,
    required Object? options,
  }) =>
      getFunction("create_basic_lexer").call(
        <Object?>[
          lexer_conf,
          parser,
          postlex,
          options,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## create_contextual_lexer
  ///
  /// ### python source
  /// ```py
  /// def create_contextual_lexer(lexer_conf, parser, postlex, options):
  ///     cls = (options and options._plugins.get('ContextualLexer')) or ContextualLexer
  ///     states = {idx:list(t.keys()) for idx, t in parser._parse_table.states.items()}
  ///     always_accept = postlex.always_accept if postlex else ()
  ///     return cls(lexer_conf, states, always_accept=always_accept)
  /// ```
  Object? create_contextual_lexer({
    required Object? lexer_conf,
    required Object? parser,
    required Object? postlex,
    required Object? options,
  }) =>
      getFunction("create_contextual_lexer").call(
        <Object?>[
          lexer_conf,
          parser,
          postlex,
          options,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## create_earley_parser
  ///
  /// ### python source
  /// ```py
  /// def create_earley_parser(lexer_conf, parser_conf, options):
  ///     resolve_ambiguity = options.ambiguity == 'resolve'
  ///     debug = options.debug if options else False
  ///     tree_class = options.tree_class or Tree if options.ambiguity != 'forest' else None
  ///
  ///     extra = {}
  ///     if lexer_conf.lexer_type == 'dynamic':
  ///         f = create_earley_parser__dynamic
  ///     elif lexer_conf.lexer_type == 'dynamic_complete':
  ///         extra['complete_lex'] =True
  ///         f = create_earley_parser__dynamic
  ///     else:
  ///         f = create_earley_parser__basic
  ///
  ///     return f(lexer_conf, parser_conf, options, resolve_ambiguity=resolve_ambiguity, debug=debug, tree_class=tree_class, **extra)
  /// ```
  Object? create_earley_parser({
    required Object? lexer_conf,
    required Object? parser_conf,
    required Object? options,
  }) =>
      getFunction("create_earley_parser").call(
        <Object?>[
          lexer_conf,
          parser_conf,
          options,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## create_earley_parser__basic
  ///
  /// ### python source
  /// ```py
  /// def create_earley_parser__basic(lexer_conf, parser_conf, options, **kw):
  ///     return earley.Parser(lexer_conf, parser_conf, _match_earley_basic, **kw)
  /// ```
  Object? create_earley_parser__basic({
    required Object? lexer_conf,
    required Object? parser_conf,
    required Object? options,
    Map<String, Object?> kw = const <String, Object?>{},
  }) =>
      getFunction("create_earley_parser__basic").call(
        <Object?>[
          lexer_conf,
          parser_conf,
          options,
        ],
        kwargs: <String, Object?>{
          ...kw,
        },
      );

  /// ## create_earley_parser__dynamic
  ///
  /// ### python source
  /// ```py
  /// def create_earley_parser__dynamic(lexer_conf, parser_conf, options=None, **kw):
  ///     if lexer_conf.callbacks:
  ///         raise GrammarError("Earley's dynamic lexer doesn't support lexer_callbacks.")
  ///
  ///     earley_matcher = EarleyRegexpMatcher(lexer_conf)
  ///     return xearley.Parser(lexer_conf, parser_conf, earley_matcher.match, **kw)
  /// ```
  Object? create_earley_parser__dynamic({
    required Object? lexer_conf,
    required Object? parser_conf,
    Object? options,
    Map<String, Object?> kw = const <String, Object?>{},
  }) =>
      getFunction("create_earley_parser__dynamic").call(
        <Object?>[
          lexer_conf,
          parser_conf,
          options,
        ],
        kwargs: <String, Object?>{
          ...kw,
        },
      );

  /// ## create_lalr_parser
  ///
  /// ### python source
  /// ```py
  /// def create_lalr_parser(lexer_conf, parser_conf, options=None):
  ///     debug = options.debug if options else False
  ///     cls = (options and options._plugins.get('LALR_Parser')) or LALR_Parser
  ///     return cls(parser_conf, debug=debug)
  /// ```
  Object? create_lalr_parser({
    required Object? lexer_conf,
    required Object? parser_conf,
    Object? options,
  }) =>
      getFunction("create_lalr_parser").call(
        <Object?>[
          lexer_conf,
          parser_conf,
          options,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## cyk
///
/// ### python docstring
///
/// This module implements a CYK parser.
///
/// ### python source
/// ```py
/// """This module implements a CYK parser."""
///
/// # Author: https://github.com/ehudt (2018)
/// #
/// # Adapted by Erez
///
///
/// from collections import defaultdict
/// import itertools
///
/// from ..exceptions import ParseError
/// from ..lexer import Token
/// from ..tree import Tree
/// from ..grammar import Terminal as T, NonTerminal as NT, Symbol
///
/// try:
///     xrange
/// except NameError:
///     xrange = range
///
/// def match(t, s):
///     assert isinstance(t, T)
///     return t.name == s.type
///
///
/// class Rule:
///     """Context-free grammar rule."""
///
///     def __init__(self, lhs, rhs, weight, alias):
///         super(Rule, self).__init__()
///         assert isinstance(lhs, NT), lhs
///         assert all(isinstance(x, NT) or isinstance(x, T) for x in rhs), rhs
///         self.lhs = lhs
///         self.rhs = rhs
///         self.weight = weight
///         self.alias = alias
///
///     def __str__(self):
///         return '%s -> %s' % (str(self.lhs), ' '.join(str(x) for x in self.rhs))
///
///     def __repr__(self):
///         return str(self)
///
///     def __hash__(self):
///         return hash((self.lhs, tuple(self.rhs)))
///
///     def __eq__(self, other):
///         return self.lhs == other.lhs and self.rhs == other.rhs
///
///     def __ne__(self, other):
///         return not (self == other)
///
///
/// class Grammar:
///     """Context-free grammar."""
///
///     def __init__(self, rules):
///         self.rules = frozenset(rules)
///
///     def __eq__(self, other):
///         return self.rules == other.rules
///
///     def __str__(self):
///         return '\n' + '\n'.join(sorted(repr(x) for x in self.rules)) + '\n'
///
///     def __repr__(self):
///         return str(self)
///
///
/// # Parse tree data structures
/// class RuleNode:
///     """A node in the parse tree, which also contains the full rhs rule."""
///
///     def __init__(self, rule, children, weight=0):
///         self.rule = rule
///         self.children = children
///         self.weight = weight
///
///     def __repr__(self):
///         return 'RuleNode(%s, [%s])' % (repr(self.rule.lhs), ', '.join(str(x) for x in self.children))
///
///
///
/// class Parser:
///     """Parser wrapper."""
///
///     def __init__(self, rules):
///         super(Parser, self).__init__()
///         self.orig_rules = {rule: rule for rule in rules}
///         rules = [self._to_rule(rule) for rule in rules]
///         self.grammar = to_cnf(Grammar(rules))
///
///     def _to_rule(self, lark_rule):
///         """Converts a lark rule, (lhs, rhs, callback, options), to a Rule."""
///         assert isinstance(lark_rule.origin, NT)
///         assert all(isinstance(x, Symbol) for x in lark_rule.expansion)
///         return Rule(
///             lark_rule.origin, lark_rule.expansion,
///             weight=lark_rule.options.priority if lark_rule.options.priority else 0,
///             alias=lark_rule)
///
///     def parse(self, tokenized, start):  # pylint: disable=invalid-name
///         """Parses input, which is a list of tokens."""
///         assert start
///         start = NT(start)
///
///         table, trees = _parse(tokenized, self.grammar)
///         # Check if the parse succeeded.
///         if all(r.lhs != start for r in table[(0, len(tokenized) - 1)]):
///             raise ParseError('Parsing failed.')
///         parse = trees[(0, len(tokenized) - 1)][start]
///         return self._to_tree(revert_cnf(parse))
///
///     def _to_tree(self, rule_node):
///         """Converts a RuleNode parse tree to a lark Tree."""
///         orig_rule = self.orig_rules[rule_node.rule.alias]
///         children = []
///         for child in rule_node.children:
///             if isinstance(child, RuleNode):
///                 children.append(self._to_tree(child))
///             else:
///                 assert isinstance(child.name, Token)
///                 children.append(child.name)
///         t = Tree(orig_rule.origin, children)
///         t.rule=orig_rule
///         return t
///
///
/// def print_parse(node, indent=0):
///     if isinstance(node, RuleNode):
///         print(' ' * (indent * 2) + str(node.rule.lhs))
///         for child in node.children:
///             print_parse(child, indent + 1)
///     else:
///         print(' ' * (indent * 2) + str(node.s))
///
///
/// def _parse(s, g):
///     """Parses sentence 's' using CNF grammar 'g'."""
///     # The CYK table. Indexed with a 2-tuple: (start pos, end pos)
///     table = defaultdict(set)
///     # Top-level structure is similar to the CYK table. Each cell is a dict from
///     # rule name to the best (lightest) tree for that rule.
///     trees = defaultdict(dict)
///     # Populate base case with existing terminal production rules
///     for i, w in enumerate(s):
///         for terminal, rules in g.terminal_rules.items():
///             if match(terminal, w):
///                 for rule in rules:
///                     table[(i, i)].add(rule)
///                     if (rule.lhs not in trees[(i, i)] or
///                         rule.weight < trees[(i, i)][rule.lhs].weight):
///                         trees[(i, i)][rule.lhs] = RuleNode(rule, [T(w)], weight=rule.weight)
///
///     # Iterate over lengths of sub-sentences
///     for l in xrange(2, len(s) + 1):
///         # Iterate over sub-sentences with the given length
///         for i in xrange(len(s) - l + 1):
///             # Choose partition of the sub-sentence in [1, l)
///             for p in xrange(i + 1, i + l):
///                 span1 = (i, p - 1)
///                 span2 = (p, i + l - 1)
///                 for r1, r2 in itertools.product(table[span1], table[span2]):
///                     for rule in g.nonterminal_rules.get((r1.lhs, r2.lhs), []):
///                         table[(i, i + l - 1)].add(rule)
///                         r1_tree = trees[span1][r1.lhs]
///                         r2_tree = trees[span2][r2.lhs]
///                         rule_total_weight = rule.weight + r1_tree.weight + r2_tree.weight
///                         if (rule.lhs not in trees[(i, i + l - 1)]
///                             or rule_total_weight < trees[(i, i + l - 1)][rule.lhs].weight):
///                             trees[(i, i + l - 1)][rule.lhs] = RuleNode(rule, [r1_tree, r2_tree], weight=rule_total_weight)
///     return table, trees
///
///
/// # This section implements context-free grammar converter to Chomsky normal form.
/// # It also implements a conversion of parse trees from its CNF to the original
/// # grammar.
/// # Overview:
/// # Applies the following operations in this order:
/// # * TERM: Eliminates non-solitary terminals from all rules
/// # * BIN: Eliminates rules with more than 2 symbols on their right-hand-side.
/// # * UNIT: Eliminates non-terminal unit rules
/// #
/// # The following grammar characteristics aren't featured:
/// # * Start symbol appears on RHS
/// # * Empty rules (epsilon rules)
///
///
/// class CnfWrapper:
///     """CNF wrapper for grammar.
///
///   Validates that the input grammar is CNF and provides helper data structures.
///   """
///
///     def __init__(self, grammar):
///         super(CnfWrapper, self).__init__()
///         self.grammar = grammar
///         self.rules = grammar.rules
///         self.terminal_rules = defaultdict(list)
///         self.nonterminal_rules = defaultdict(list)
///         for r in self.rules:
///             # Validate that the grammar is CNF and populate auxiliary data structures.
///             assert isinstance(r.lhs, NT), r
///             if len(r.rhs) not in [1, 2]:
///                 raise ParseError("CYK doesn't support empty rules")
///             if len(r.rhs) == 1 and isinstance(r.rhs[0], T):
///                 self.terminal_rules[r.rhs[0]].append(r)
///             elif len(r.rhs) == 2 and all(isinstance(x, NT) for x in r.rhs):
///                 self.nonterminal_rules[tuple(r.rhs)].append(r)
///             else:
///                 assert False, r
///
///     def __eq__(self, other):
///         return self.grammar == other.grammar
///
///     def __repr__(self):
///         return repr(self.grammar)
///
///
/// class UnitSkipRule(Rule):
///     """A rule that records NTs that were skipped during transformation."""
///
///     def __init__(self, lhs, rhs, skipped_rules, weight, alias):
///         super(UnitSkipRule, self).__init__(lhs, rhs, weight, alias)
///         self.skipped_rules = skipped_rules
///
///     def __eq__(self, other):
///         return isinstance(other, type(self)) and self.skipped_rules == other.skipped_rules
///
///     __hash__ = Rule.__hash__
///
///
/// def build_unit_skiprule(unit_rule, target_rule):
///     skipped_rules = []
///     if isinstance(unit_rule, UnitSkipRule):
///         skipped_rules += unit_rule.skipped_rules
///     skipped_rules.append(target_rule)
///     if isinstance(target_rule, UnitSkipRule):
///         skipped_rules += target_rule.skipped_rules
///     return UnitSkipRule(unit_rule.lhs, target_rule.rhs, skipped_rules,
///                       weight=unit_rule.weight + target_rule.weight, alias=unit_rule.alias)
///
///
/// def get_any_nt_unit_rule(g):
///     """Returns a non-terminal unit rule from 'g', or None if there is none."""
///     for rule in g.rules:
///         if len(rule.rhs) == 1 and isinstance(rule.rhs[0], NT):
///             return rule
///     return None
///
///
/// def _remove_unit_rule(g, rule):
///     """Removes 'rule' from 'g' without changing the langugage produced by 'g'."""
///     new_rules = [x for x in g.rules if x != rule]
///     refs = [x for x in g.rules if x.lhs == rule.rhs[0]]
///     new_rules += [build_unit_skiprule(rule, ref) for ref in refs]
///     return Grammar(new_rules)
///
///
/// def _split(rule):
///     """Splits a rule whose len(rhs) > 2 into shorter rules."""
///     rule_str = str(rule.lhs) + '__' + '_'.join(str(x) for x in rule.rhs)
///     rule_name = '__SP_%s' % (rule_str) + '_%d'
///     yield Rule(rule.lhs, [rule.rhs[0], NT(rule_name % 1)], weight=rule.weight, alias=rule.alias)
///     for i in xrange(1, len(rule.rhs) - 2):
///         yield Rule(NT(rule_name % i), [rule.rhs[i], NT(rule_name % (i + 1))], weight=0, alias='Split')
///     yield Rule(NT(rule_name % (len(rule.rhs) - 2)), rule.rhs[-2:], weight=0, alias='Split')
///
///
/// def _term(g):
///     """Applies the TERM rule on 'g' (see top comment)."""
///     all_t = {x for rule in g.rules for x in rule.rhs if isinstance(x, T)}
///     t_rules = {t: Rule(NT('__T_%s' % str(t)), [t], weight=0, alias='Term') for t in all_t}
///     new_rules = []
///     for rule in g.rules:
///         if len(rule.rhs) > 1 and any(isinstance(x, T) for x in rule.rhs):
///             new_rhs = [t_rules[x].lhs if isinstance(x, T) else x for x in rule.rhs]
///             new_rules.append(Rule(rule.lhs, new_rhs, weight=rule.weight, alias=rule.alias))
///             new_rules.extend(v for k, v in t_rules.items() if k in rule.rhs)
///         else:
///             new_rules.append(rule)
///     return Grammar(new_rules)
///
///
/// def _bin(g):
///     """Applies the BIN rule to 'g' (see top comment)."""
///     new_rules = []
///     for rule in g.rules:
///         if len(rule.rhs) > 2:
///             new_rules += _split(rule)
///         else:
///             new_rules.append(rule)
///     return Grammar(new_rules)
///
///
/// def _unit(g):
///     """Applies the UNIT rule to 'g' (see top comment)."""
///     nt_unit_rule = get_any_nt_unit_rule(g)
///     while nt_unit_rule:
///         g = _remove_unit_rule(g, nt_unit_rule)
///         nt_unit_rule = get_any_nt_unit_rule(g)
///     return g
///
///
/// def to_cnf(g):
///     """Creates a CNF grammar from a general context-free grammar 'g'."""
///     g = _unit(_bin(_term(g)))
///     return CnfWrapper(g)
///
///
/// def unroll_unit_skiprule(lhs, orig_rhs, skipped_rules, children, weight, alias):
///     if not skipped_rules:
///         return RuleNode(Rule(lhs, orig_rhs, weight=weight, alias=alias), children, weight=weight)
///     else:
///         weight = weight - skipped_rules[0].weight
///         return RuleNode(
///             Rule(lhs, [skipped_rules[0].lhs], weight=weight, alias=alias), [
///                 unroll_unit_skiprule(skipped_rules[0].lhs, orig_rhs,
///                                 skipped_rules[1:], children,
///                                 skipped_rules[0].weight, skipped_rules[0].alias)
///             ], weight=weight)
///
///
/// def revert_cnf(node):
///     """Reverts a parse tree (RuleNode) to its original non-CNF form (Node)."""
///     if isinstance(node, T):
///         return node
///     # Reverts TERM rule.
///     if node.rule.lhs.name.startswith('__T_'):
///         return node.children[0]
///     else:
///         children = []
///         for child in map(revert_cnf, node.children):
///             # Reverts BIN rule.
///             if isinstance(child, RuleNode) and child.rule.lhs.name.startswith('__SP_'):
///                 children += child.children
///             else:
///                 children.append(child)
///         # Reverts UNIT rule.
///         if isinstance(node.rule, UnitSkipRule):
///             return unroll_unit_skiprule(node.rule.lhs, node.rule.rhs,
///                                     node.rule.skipped_rules, children,
///                                     node.rule.weight, node.rule.alias)
///         else:
///             return RuleNode(node.rule, children)
/// ```
final class cyk extends PythonModule {
  cyk.from(super.pythonModule) : super.from();

  static cyk import() => PythonFfiDart.instance.importModule(
        "lark.parsers.cyk",
        cyk.from,
      );

  /// ## build_unit_skiprule
  ///
  /// ### python source
  /// ```py
  /// def build_unit_skiprule(unit_rule, target_rule):
  ///     skipped_rules = []
  ///     if isinstance(unit_rule, UnitSkipRule):
  ///         skipped_rules += unit_rule.skipped_rules
  ///     skipped_rules.append(target_rule)
  ///     if isinstance(target_rule, UnitSkipRule):
  ///         skipped_rules += target_rule.skipped_rules
  ///     return UnitSkipRule(unit_rule.lhs, target_rule.rhs, skipped_rules,
  ///                       weight=unit_rule.weight + target_rule.weight, alias=unit_rule.alias)
  /// ```
  Object? build_unit_skiprule({
    required Object? unit_rule,
    required Object? target_rule,
  }) =>
      getFunction("build_unit_skiprule").call(
        <Object?>[
          unit_rule,
          target_rule,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## get_any_nt_unit_rule
  ///
  /// ### python docstring
  ///
  /// Returns a non-terminal unit rule from 'g', or None if there is none.
  ///
  /// ### python source
  /// ```py
  /// def get_any_nt_unit_rule(g):
  ///     """Returns a non-terminal unit rule from 'g', or None if there is none."""
  ///     for rule in g.rules:
  ///         if len(rule.rhs) == 1 and isinstance(rule.rhs[0], NT):
  ///             return rule
  ///     return None
  /// ```
  Object? get_any_nt_unit_rule({
    required Object? g,
  }) =>
      getFunction("get_any_nt_unit_rule").call(
        <Object?>[
          g,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## match
  ///
  /// ### python source
  /// ```py
  /// def match(t, s):
  ///     assert isinstance(t, T)
  ///     return t.name == s.type
  /// ```
  Object? match({
    required Object? t,
    required Object? s,
  }) =>
      getFunction("match").call(
        <Object?>[
          t,
          s,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## print_parse
  ///
  /// ### python source
  /// ```py
  /// def print_parse(node, indent=0):
  ///     if isinstance(node, RuleNode):
  ///         print(' ' * (indent * 2) + str(node.rule.lhs))
  ///         for child in node.children:
  ///             print_parse(child, indent + 1)
  ///     else:
  ///         print(' ' * (indent * 2) + str(node.s))
  /// ```
  Object? print_parse({
    required Object? node,
    Object? indent = 0,
  }) =>
      getFunction("print_parse").call(
        <Object?>[
          node,
          indent,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## revert_cnf
  ///
  /// ### python docstring
  ///
  /// Reverts a parse tree (RuleNode) to its original non-CNF form (Node).
  ///
  /// ### python source
  /// ```py
  /// def revert_cnf(node):
  ///     """Reverts a parse tree (RuleNode) to its original non-CNF form (Node)."""
  ///     if isinstance(node, T):
  ///         return node
  ///     # Reverts TERM rule.
  ///     if node.rule.lhs.name.startswith('__T_'):
  ///         return node.children[0]
  ///     else:
  ///         children = []
  ///         for child in map(revert_cnf, node.children):
  ///             # Reverts BIN rule.
  ///             if isinstance(child, RuleNode) and child.rule.lhs.name.startswith('__SP_'):
  ///                 children += child.children
  ///             else:
  ///                 children.append(child)
  ///         # Reverts UNIT rule.
  ///         if isinstance(node.rule, UnitSkipRule):
  ///             return unroll_unit_skiprule(node.rule.lhs, node.rule.rhs,
  ///                                     node.rule.skipped_rules, children,
  ///                                     node.rule.weight, node.rule.alias)
  ///         else:
  ///             return RuleNode(node.rule, children)
  /// ```
  Object? revert_cnf({
    required Object? node,
  }) =>
      getFunction("revert_cnf").call(
        <Object?>[
          node,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## to_cnf
  ///
  /// ### python docstring
  ///
  /// Creates a CNF grammar from a general context-free grammar 'g'.
  ///
  /// ### python source
  /// ```py
  /// def to_cnf(g):
  ///     """Creates a CNF grammar from a general context-free grammar 'g'."""
  ///     g = _unit(_bin(_term(g)))
  ///     return CnfWrapper(g)
  /// ```
  Object? to_cnf({
    required Object? g,
  }) =>
      getFunction("to_cnf").call(
        <Object?>[
          g,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## unroll_unit_skiprule
  ///
  /// ### python source
  /// ```py
  /// def unroll_unit_skiprule(lhs, orig_rhs, skipped_rules, children, weight, alias):
  ///     if not skipped_rules:
  ///         return RuleNode(Rule(lhs, orig_rhs, weight=weight, alias=alias), children, weight=weight)
  ///     else:
  ///         weight = weight - skipped_rules[0].weight
  ///         return RuleNode(
  ///             Rule(lhs, [skipped_rules[0].lhs], weight=weight, alias=alias), [
  ///                 unroll_unit_skiprule(skipped_rules[0].lhs, orig_rhs,
  ///                                 skipped_rules[1:], children,
  ///                                 skipped_rules[0].weight, skipped_rules[0].alias)
  ///             ], weight=weight)
  /// ```
  Object? unroll_unit_skiprule({
    required Object? lhs,
    required Object? orig_rhs,
    required Object? skipped_rules,
    required Object? children,
    required Object? weight,
    required Object? alias,
  }) =>
      getFunction("unroll_unit_skiprule").call(
        <Object?>[
          lhs,
          orig_rhs,
          skipped_rules,
          children,
          weight,
          alias,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## itertools
final class itertools extends PythonModule {
  itertools.from(super.pythonModule) : super.from();

  static itertools import() => PythonFfiDart.instance.importModule(
        "itertools",
        itertools.from,
      );
}

/// ## earley
///
/// ### python docstring
///
/// This module implements an Earley parser.
///
/// The core Earley algorithm used here is based on Elizabeth Scott's implementation, here:
///     https://www.sciencedirect.com/science/article/pii/S1571066108001497
///
/// That is probably the best reference for understanding the algorithm here.
///
/// The Earley parser outputs an SPPF-tree as per that document. The SPPF tree format
/// is explained here: https://lark-parser.readthedocs.io/en/latest/_static/sppf/sppf.html
///
/// ### python source
/// ```py
/// """This module implements an Earley parser.
///
/// The core Earley algorithm used here is based on Elizabeth Scott's implementation, here:
///     https://www.sciencedirect.com/science/article/pii/S1571066108001497
///
/// That is probably the best reference for understanding the algorithm here.
///
/// The Earley parser outputs an SPPF-tree as per that document. The SPPF tree format
/// is explained here: https://lark-parser.readthedocs.io/en/latest/_static/sppf/sppf.html
/// """
///
/// from collections import deque
///
/// from ..lexer import Token
/// from ..tree import Tree
/// from ..exceptions import UnexpectedEOF, UnexpectedToken
/// from ..utils import logger
/// from .grammar_analysis import GrammarAnalyzer
/// from ..grammar import NonTerminal
/// from .earley_common import Item
/// from .earley_forest import ForestSumVisitor, SymbolNode, TokenNode, ForestToParseTree
///
/// class Parser:
///     def __init__(self, lexer_conf, parser_conf, term_matcher, resolve_ambiguity=True, debug=False, tree_class=Tree):
///         analysis = GrammarAnalyzer(parser_conf)
///         self.lexer_conf = lexer_conf
///         self.parser_conf = parser_conf
///         self.resolve_ambiguity = resolve_ambiguity
///         self.debug = debug
///         self.tree_class = tree_class
///
///         self.FIRST = analysis.FIRST
///         self.NULLABLE = analysis.NULLABLE
///         self.callbacks = parser_conf.callbacks
///         self.predictions = {}
///
///         ## These could be moved to the grammar analyzer. Pre-computing these is *much* faster than
///         #  the slow 'isupper' in is_terminal.
///         self.TERMINALS = { sym for r in parser_conf.rules for sym in r.expansion if sym.is_term }
///         self.NON_TERMINALS = { sym for r in parser_conf.rules for sym in r.expansion if not sym.is_term }
///
///         self.forest_sum_visitor = None
///         for rule in parser_conf.rules:
///             if rule.origin not in self.predictions:
///                 self.predictions[rule.origin] = [x.rule for x in analysis.expand_rule(rule.origin)]
///
///             ## Detect if any rules/terminals have priorities set. If the user specified priority = None, then
///             #  the priorities will be stripped from all rules/terminals before they reach us, allowing us to
///             #  skip the extra tree walk. We'll also skip this if the user just didn't specify priorities
///             #  on any rules/terminals.
///             if self.forest_sum_visitor is None and rule.options.priority is not None:
///                 self.forest_sum_visitor = ForestSumVisitor
///
///         # Check terminals for priorities
///         # Ignore terminal priorities if the basic lexer is used
///         if self.lexer_conf.lexer_type != 'basic' and self.forest_sum_visitor is None:
///             for term in self.lexer_conf.terminals:
///                 if term.priority:
///                     self.forest_sum_visitor = ForestSumVisitor
///                     break
///
///         self.term_matcher = term_matcher
///
///
///     def predict_and_complete(self, i, to_scan, columns, transitives):
///         """The core Earley Predictor and Completer.
///
///         At each stage of the input, we handling any completed items (things
///         that matched on the last cycle) and use those to predict what should
///         come next in the input stream. The completions and any predicted
///         non-terminals are recursively processed until we reach a set of,
///         which can be added to the scan list for the next scanner cycle."""
///         # Held Completions (H in E.Scotts paper).
///         node_cache = {}
///         held_completions = {}
///
///         column = columns[i]
///         # R (items) = Ei (column.items)
///         items = deque(column)
///         while items:
///             item = items.pop()    # remove an element, A say, from R
///
///             ### The Earley completer
///             if item.is_complete:   ### (item.s == string)
///                 if item.node is None:
///                     label = (item.s, item.start, i)
///                     item.node = node_cache[label] if label in node_cache else node_cache.setdefault(label, SymbolNode(*label))
///                     item.node.add_family(item.s, item.rule, item.start, None, None)
///
///                 # create_leo_transitives(item.rule.origin, item.start)
///
///                 ###R Joop Leo right recursion Completer
///                 if item.rule.origin in transitives[item.start]:
///                     transitive = transitives[item.start][item.s]
///                     if transitive.previous in transitives[transitive.column]:
///                         root_transitive = transitives[transitive.column][transitive.previous]
///                     else:
///                         root_transitive = transitive
///
///                     new_item = Item(transitive.rule, transitive.ptr, transitive.start)
///                     label = (root_transitive.s, root_transitive.start, i)
///                     new_item.node = node_cache[label] if label in node_cache else node_cache.setdefault(label, SymbolNode(*label))
///                     new_item.node.add_path(root_transitive, item.node)
///                     if new_item.expect in self.TERMINALS:
///                         # Add (B :: aC.B, h, y) to Q
///                         to_scan.add(new_item)
///                     elif new_item not in column:
///                         # Add (B :: aC.B, h, y) to Ei and R
///                         column.add(new_item)
///                         items.append(new_item)
///                 ###R Regular Earley completer
///                 else:
///                     # Empty has 0 length. If we complete an empty symbol in a particular
///                     # parse step, we need to be able to use that same empty symbol to complete
///                     # any predictions that result, that themselves require empty. Avoids
///                     # infinite recursion on empty symbols.
///                     # held_completions is 'H' in E.Scott's paper.
///                     is_empty_item = item.start == i
///                     if is_empty_item:
///                         held_completions[item.rule.origin] = item.node
///
///                     originators = [originator for originator in columns[item.start] if originator.expect is not None and originator.expect == item.s]
///                     for originator in originators:
///                         new_item = originator.advance()
///                         label = (new_item.s, originator.start, i)
///                         new_item.node = node_cache[label] if label in node_cache else node_cache.setdefault(label, SymbolNode(*label))
///                         new_item.node.add_family(new_item.s, new_item.rule, i, originator.node, item.node)
///                         if new_item.expect in self.TERMINALS:
///                             # Add (B :: aC.B, h, y) to Q
///                             to_scan.add(new_item)
///                         elif new_item not in column:
///                             # Add (B :: aC.B, h, y) to Ei and R
///                             column.add(new_item)
///                             items.append(new_item)
///
///             ### The Earley predictor
///             elif item.expect in self.NON_TERMINALS: ### (item.s == lr0)
///                 new_items = []
///                 for rule in self.predictions[item.expect]:
///                     new_item = Item(rule, 0, i)
///                     new_items.append(new_item)
///
///                 # Process any held completions (H).
///                 if item.expect in held_completions:
///                     new_item = item.advance()
///                     label = (new_item.s, item.start, i)
///                     new_item.node = node_cache[label] if label in node_cache else node_cache.setdefault(label, SymbolNode(*label))
///                     new_item.node.add_family(new_item.s, new_item.rule, new_item.start, item.node, held_completions[item.expect])
///                     new_items.append(new_item)
///
///                 for new_item in new_items:
///                     if new_item.expect in self.TERMINALS:
///                         to_scan.add(new_item)
///                     elif new_item not in column:
///                         column.add(new_item)
///                         items.append(new_item)
///
///     def _parse(self, lexer, columns, to_scan, start_symbol=None):
///         def is_quasi_complete(item):
///             if item.is_complete:
///                 return True
///
///             quasi = item.advance()
///             while not quasi.is_complete:
///                 if quasi.expect not in self.NULLABLE:
///                     return False
///                 if quasi.rule.origin == start_symbol and quasi.expect == start_symbol:
///                     return False
///                 quasi = quasi.advance()
///             return True
///
///         # def create_leo_transitives(origin, start):
///         #   ...   # removed at commit 4c1cfb2faf24e8f8bff7112627a00b94d261b420
///
///         def scan(i, token, to_scan):
///             """The core Earley Scanner.
///
///             This is a custom implementation of the scanner that uses the
///             Lark lexer to match tokens. The scan list is built by the
///             Earley predictor, based on the previously completed tokens.
///             This ensures that at each phase of the parse we have a custom
///             lexer context, allowing for more complex ambiguities."""
///             next_to_scan = set()
///             next_set = set()
///             columns.append(next_set)
///             transitives.append({})
///             node_cache = {}
///
///             for item in set(to_scan):
///                 if match(item.expect, token):
///                     new_item = item.advance()
///                     label = (new_item.s, new_item.start, i)
///                     # 'terminals' may not contain token.type when using %declare
///                     # Additionally, token is not always a Token
///                     # For example, it can be a Tree when using TreeMatcher
///                     term = terminals.get(token.type) if isinstance(token, Token) else None
///                     # Set the priority of the token node to 0 so that the
///                     # terminal priorities do not affect the Tree chosen by
///                     # ForestSumVisitor after the basic lexer has already
///                     # "used up" the terminal priorities
///                     token_node = TokenNode(token, term, priority=0)
///                     new_item.node = node_cache[label] if label in node_cache else node_cache.setdefault(label, SymbolNode(*label))
///                     new_item.node.add_family(new_item.s, item.rule, new_item.start, item.node, token_node)
///
///                     if new_item.expect in self.TERMINALS:
///                         # add (B ::= Aai+1.B, h, y) to Q'
///                         next_to_scan.add(new_item)
///                     else:
///                         # add (B ::= Aa+1.B, h, y) to Ei+1
///                         next_set.add(new_item)
///
///             if not next_set and not next_to_scan:
///                 expect = {i.expect.name for i in to_scan}
///                 raise UnexpectedToken(token, expect, considered_rules=set(to_scan), state=frozenset(i.s for i in to_scan))
///
///             return next_to_scan
///
///
///         # Define parser functions
///         match = self.term_matcher
///
///         terminals = self.lexer_conf.terminals_by_name
///
///         # Cache for nodes & tokens created in a particular parse step.
///         transitives = [{}]
///
///         ## The main Earley loop.
///         # Run the Prediction/Completion cycle for any Items in the current Earley set.
///         # Completions will be added to the SPPF tree, and predictions will be recursively
///         # processed down to terminals/empty nodes to be added to the scanner for the next
///         # step.
///         expects = {i.expect for i in to_scan}
///         i = 0
///         for token in lexer.lex(expects):
///             self.predict_and_complete(i, to_scan, columns, transitives)
///
///             to_scan = scan(i, token, to_scan)
///             i += 1
///
///             expects.clear()
///             expects |= {i.expect for i in to_scan}
///
///         self.predict_and_complete(i, to_scan, columns, transitives)
///
///         ## Column is now the final column in the parse.
///         assert i == len(columns)-1
///         return to_scan
///
///     def parse(self, lexer, start):
///         assert start, start
///         start_symbol = NonTerminal(start)
///
///         columns = [set()]
///         to_scan = set()     # The scan buffer. 'Q' in E.Scott's paper.
///
///         ## Predict for the start_symbol.
///         # Add predicted items to the first Earley set (for the predictor) if they
///         # result in a non-terminal, or the scanner if they result in a terminal.
///         for rule in self.predictions[start_symbol]:
///             item = Item(rule, 0, 0)
///             if item.expect in self.TERMINALS:
///                 to_scan.add(item)
///             else:
///                 columns[0].add(item)
///
///         to_scan = self._parse(lexer, columns, to_scan, start_symbol)
///
///         # If the parse was successful, the start
///         # symbol should have been completed in the last step of the Earley cycle, and will be in
///         # this column. Find the item for the start_symbol, which is the root of the SPPF tree.
///         solutions = [n.node for n in columns[-1] if n.is_complete and n.node is not None and n.s == start_symbol and n.start == 0]
///         if not solutions:
///             expected_terminals = [t.expect.name for t in to_scan]
///             raise UnexpectedEOF(expected_terminals, state=frozenset(i.s for i in to_scan))
///
///         if self.debug:
///             from .earley_forest import ForestToPyDotVisitor
///             try:
///                 debug_walker = ForestToPyDotVisitor()
///             except ImportError:
///                 logger.warning("Cannot find dependency 'pydot', will not generate sppf debug image")
///             else:
///                 debug_walker.visit(solutions[0], "sppf.png")
///
///
///         if len(solutions) > 1:
///             assert False, 'Earley should not generate multiple start symbol items!'
///
///         if self.tree_class is not None:
///             # Perform our SPPF -> AST conversion
///             transformer = ForestToParseTree(self.tree_class, self.callbacks, self.forest_sum_visitor and self.forest_sum_visitor(), self.resolve_ambiguity)
///             return transformer.transform(solutions[0])
///
///         # return the root of the SPPF
///         return solutions[0]
/// ```
final class earley extends PythonModule {
  earley.from(super.pythonModule) : super.from();

  static earley import() => PythonFfiDart.instance.importModule(
        "lark.parsers.earley",
        earley.from,
      );
}

/// ## xearley
///
/// ### python docstring
///
/// This module implements an experimental Earley parser with a dynamic lexer
///
/// The core Earley algorithm used here is based on Elizabeth Scott's implementation, here:
///     https://www.sciencedirect.com/science/article/pii/S1571066108001497
///
/// That is probably the best reference for understanding the algorithm here.
///
/// The Earley parser outputs an SPPF-tree as per that document. The SPPF tree format
/// is better documented here:
///     http://www.bramvandersanden.com/post/2014/06/shared-packed-parse-forest/
///
/// Instead of running a lexer beforehand, or using a costy char-by-char method, this parser
/// uses regular expressions by necessity, achieving high-performance while maintaining all of
/// Earley's power in parsing any CFG.
///
/// ### python source
/// ```py
/// """This module implements an experimental Earley parser with a dynamic lexer
///
/// The core Earley algorithm used here is based on Elizabeth Scott's implementation, here:
///     https://www.sciencedirect.com/science/article/pii/S1571066108001497
///
/// That is probably the best reference for understanding the algorithm here.
///
/// The Earley parser outputs an SPPF-tree as per that document. The SPPF tree format
/// is better documented here:
///     http://www.bramvandersanden.com/post/2014/06/shared-packed-parse-forest/
///
/// Instead of running a lexer beforehand, or using a costy char-by-char method, this parser
/// uses regular expressions by necessity, achieving high-performance while maintaining all of
/// Earley's power in parsing any CFG.
/// """
///
/// from collections import defaultdict
///
/// from ..tree import Tree
/// from ..exceptions import UnexpectedCharacters
/// from ..lexer import Token
/// from ..grammar import Terminal
/// from .earley import Parser as BaseParser
/// from .earley_forest import SymbolNode, TokenNode
///
///
/// class Parser(BaseParser):
///     def __init__(self, lexer_conf, parser_conf, term_matcher, resolve_ambiguity=True, complete_lex = False, debug=False, tree_class=Tree):
///         BaseParser.__init__(self, lexer_conf, parser_conf, term_matcher, resolve_ambiguity, debug, tree_class)
///         self.ignore = [Terminal(t) for t in lexer_conf.ignore]
///         self.complete_lex = complete_lex
///
///     def _parse(self, stream, columns, to_scan, start_symbol=None):
///
///         def scan(i, to_scan):
///             """The core Earley Scanner.
///
///             This is a custom implementation of the scanner that uses the
///             Lark lexer to match tokens. The scan list is built by the
///             Earley predictor, based on the previously completed tokens.
///             This ensures that at each phase of the parse we have a custom
///             lexer context, allowing for more complex ambiguities."""
///
///             node_cache = {}
///
///             # 1) Loop the expectations and ask the lexer to match.
///             # Since regexp is forward looking on the input stream, and we only
///             # want to process tokens when we hit the point in the stream at which
///             # they complete, we push all tokens into a buffer (delayed_matches), to
///             # be held possibly for a later parse step when we reach the point in the
///             # input stream at which they complete.
///             for item in set(to_scan):
///                 m = match(item.expect, stream, i)
///                 if m:
///                     t = Token(item.expect.name, m.group(0), i, text_line, text_column)
///                     delayed_matches[m.end()].append( (item, i, t) )
///
///                     if self.complete_lex:
///                         s = m.group(0)
///                         for j in range(1, len(s)):
///                             m = match(item.expect, s[:-j])
///                             if m:
///                                 t = Token(item.expect.name, m.group(0), i, text_line, text_column)
///                                 delayed_matches[i+m.end()].append( (item, i, t) )
///
///                     # XXX The following 3 lines were commented out for causing a bug. See issue #768
///                     # # Remove any items that successfully matched in this pass from the to_scan buffer.
///                     # # This ensures we don't carry over tokens that already matched, if we're ignoring below.
///                     # to_scan.remove(item)
///
///             # 3) Process any ignores. This is typically used for e.g. whitespace.
///             # We carry over any unmatched items from the to_scan buffer to be matched again after
///             # the ignore. This should allow us to use ignored symbols in non-terminals to implement
///             # e.g. mandatory spacing.
///             for x in self.ignore:
///                 m = match(x, stream, i)
///                 if m:
///                     # Carry over any items still in the scan buffer, to past the end of the ignored items.
///                     delayed_matches[m.end()].extend([(item, i, None) for item in to_scan ])
///
///                     # If we're ignoring up to the end of the file, # carry over the start symbol if it already completed.
///                     delayed_matches[m.end()].extend([(item, i, None) for item in columns[i] if item.is_complete and item.s == start_symbol])
///
///             next_to_scan = set()
///             next_set = set()
///             columns.append(next_set)
///             transitives.append({})
///
///             ## 4) Process Tokens from delayed_matches.
///             # This is the core of the Earley scanner. Create an SPPF node for each Token,
///             # and create the symbol node in the SPPF tree. Advance the item that completed,
///             # and add the resulting new item to either the Earley set (for processing by the
///             # completer/predictor) or the to_scan buffer for the next parse step.
///             for item, start, token in delayed_matches[i+1]:
///                 if token is not None:
///                     token.end_line = text_line
///                     token.end_column = text_column + 1
///                     token.end_pos = i + 1
///
///                     new_item = item.advance()
///                     label = (new_item.s, new_item.start, i)
///                     token_node = TokenNode(token, terminals[token.type])
///                     new_item.node = node_cache[label] if label in node_cache else node_cache.setdefault(label, SymbolNode(*label))
///                     new_item.node.add_family(new_item.s, item.rule, new_item.start, item.node, token_node)
///                 else:
///                     new_item = item
///
///                 if new_item.expect in self.TERMINALS:
///                     # add (B ::= Aai+1.B, h, y) to Q'
///                     next_to_scan.add(new_item)
///                 else:
///                     # add (B ::= Aa+1.B, h, y) to Ei+1
///                     next_set.add(new_item)
///
///             del delayed_matches[i+1]    # No longer needed, so unburden memory
///
///             if not next_set and not delayed_matches and not next_to_scan:
///                 considered_rules = list(sorted(to_scan, key=lambda key: key.rule.origin.name))
///                 raise UnexpectedCharacters(stream, i, text_line, text_column, {item.expect.name for item in to_scan},
///                                            set(to_scan), state=frozenset(i.s for i in to_scan),
///                                            considered_rules=considered_rules
///                                            )
///
///             return next_to_scan
///
///
///         delayed_matches = defaultdict(list)
///         match = self.term_matcher
///         terminals = self.lexer_conf.terminals_by_name
///
///         # Cache for nodes & tokens created in a particular parse step.
///         transitives = [{}]
///
///         text_line = 1
///         text_column = 1
///
///         ## The main Earley loop.
///         # Run the Prediction/Completion cycle for any Items in the current Earley set.
///         # Completions will be added to the SPPF tree, and predictions will be recursively
///         # processed down to terminals/empty nodes to be added to the scanner for the next
///         # step.
///         i = 0
///         for token in stream:
///             self.predict_and_complete(i, to_scan, columns, transitives)
///
///             to_scan = scan(i, to_scan)
///
///             if token == '\n':
///                 text_line += 1
///                 text_column = 1
///             else:
///                 text_column += 1
///             i += 1
///
///         self.predict_and_complete(i, to_scan, columns, transitives)
///
///         ## Column is now the final column in the parse.
///         assert i == len(columns)-1
///         return to_scan
/// ```
final class xearley extends PythonModule {
  xearley.from(super.pythonModule) : super.from();

  static xearley import() => PythonFfiDart.instance.importModule(
        "lark.parsers.xearley",
        xearley.from,
      );
}

/// ## parsers
final class parsers extends PythonModule {
  parsers.from(super.pythonModule) : super.from();

  static parsers import() => PythonFfiDart.instance.importModule(
        "lark.parsers",
        parsers.from,
      );
}

/// ## earley_common
///
/// ### python docstring
///
/// This module implements useful building blocks for the Earley parser
///
/// ### python source
/// ```py
/// """This module implements useful building blocks for the Earley parser
/// """
///
///
/// class Item:
///     "An Earley Item, the atom of the algorithm."
///
///     __slots__ = ('s', 'rule', 'ptr', 'start', 'is_complete', 'expect', 'previous', 'node', '_hash')
///     def __init__(self, rule, ptr, start):
///         self.is_complete = len(rule.expansion) == ptr
///         self.rule = rule    # rule
///         self.ptr = ptr      # ptr
///         self.start = start  # j
///         self.node = None    # w
///         if self.is_complete:
///             self.s = rule.origin
///             self.expect = None
///             self.previous = rule.expansion[ptr - 1] if ptr > 0 and len(rule.expansion) else None
///         else:
///             self.s = (rule, ptr)
///             self.expect = rule.expansion[ptr]
///             self.previous = rule.expansion[ptr - 1] if ptr > 0 and len(rule.expansion) else None
///         self._hash = hash((self.s, self.start))
///
///     def advance(self):
///         return Item(self.rule, self.ptr + 1, self.start)
///
///     def __eq__(self, other):
///         return self is other or (self.s == other.s and self.start == other.start)
///
///     def __hash__(self):
///         return self._hash
///
///     def __repr__(self):
///         before = ( expansion.name for expansion in self.rule.expansion[:self.ptr] )
///         after = ( expansion.name for expansion in self.rule.expansion[self.ptr:] )
///         symbol = "{} ::= {}* {}".format(self.rule.origin.name, ' '.join(before), ' '.join(after))
///         return '%s (%d)' % (symbol, self.start)
///
///
/// # class TransitiveItem(Item):
/// #   ...   # removed at commit 4c1cfb2faf24e8f8bff7112627a00b94d261b420
/// ```
final class earley_common extends PythonModule {
  earley_common.from(super.pythonModule) : super.from();

  static earley_common import() => PythonFfiDart.instance.importModule(
        "lark.parsers.earley_common",
        earley_common.from,
      );
}

/// ## earley_forest
///
/// ### python docstring
///
/// "This module implements an SPPF implementation
///
/// This is used as the primary output mechanism for the Earley parser
/// in order to store complex ambiguities.
///
/// Full reference and more details is here:
/// https://web.archive.org/web/20190616123959/http://www.bramvandersanden.com/post/2014/06/shared-packed-parse-forest/
///
/// ### python source
/// ```py
/// """"This module implements an SPPF implementation
///
/// This is used as the primary output mechanism for the Earley parser
/// in order to store complex ambiguities.
///
/// Full reference and more details is here:
/// https://web.archive.org/web/20190616123959/http://www.bramvandersanden.com/post/2014/06/shared-packed-parse-forest/
/// """
///
/// from random import randint
/// from collections import deque
/// from operator import attrgetter
/// from importlib import import_module
/// from functools import partial
///
/// from ..parse_tree_builder import AmbiguousIntermediateExpander
/// from ..visitors import Discard
/// from ..lexer import Token
/// from ..utils import logger
/// from ..tree import Tree
///
/// class ForestNode:
///     pass
///
/// class SymbolNode(ForestNode):
///     """
///     A Symbol Node represents a symbol (or Intermediate LR0).
///
///     Symbol nodes are keyed by the symbol (s). For intermediate nodes
///     s will be an LR0, stored as a tuple of (rule, ptr). For completed symbol
///     nodes, s will be a string representing the non-terminal origin (i.e.
///     the left hand side of the rule).
///
///     The children of a Symbol or Intermediate Node will always be Packed Nodes;
///     with each Packed Node child representing a single derivation of a production.
///
///     Hence a Symbol Node with a single child is unambiguous.
///
///     Parameters:
///         s: A Symbol, or a tuple of (rule, ptr) for an intermediate node.
///         start: The index of the start of the substring matched by this symbol (inclusive).
///         end: The index of the end of the substring matched by this symbol (exclusive).
///
///     Properties:
///         is_intermediate: True if this node is an intermediate node.
///         priority: The priority of the node's symbol.
///     """
///     __slots__ = ('s', 'start', 'end', '_children', 'paths', 'paths_loaded', 'priority', 'is_intermediate', '_hash')
///     def __init__(self, s, start, end):
///         self.s = s
///         self.start = start
///         self.end = end
///         self._children = set()
///         self.paths = set()
///         self.paths_loaded = False
///
///         ### We use inf here as it can be safely negated without resorting to conditionals,
///         #   unlike None or float('NaN'), and sorts appropriately.
///         self.priority = float('-inf')
///         self.is_intermediate = isinstance(s, tuple)
///         self._hash = hash((self.s, self.start, self.end))
///
///     def add_family(self, lr0, rule, start, left, right):
///         self._children.add(PackedNode(self, lr0, rule, start, left, right))
///
///     def add_path(self, transitive, node):
///         self.paths.add((transitive, node))
///
///     def load_paths(self):
///         for transitive, node in self.paths:
///             if transitive.next_titem is not None:
///                 vn = SymbolNode(transitive.next_titem.s, transitive.next_titem.start, self.end)
///                 vn.add_path(transitive.next_titem, node)
///                 self.add_family(transitive.reduction.rule.origin, transitive.reduction.rule, transitive.reduction.start, transitive.reduction.node, vn)
///             else:
///                 self.add_family(transitive.reduction.rule.origin, transitive.reduction.rule, transitive.reduction.start, transitive.reduction.node, node)
///         self.paths_loaded = True
///
///     @property
///     def is_ambiguous(self):
///         """Returns True if this node is ambiguous."""
///         return len(self.children) > 1
///
///     @property
///     def children(self):
///         """Returns a list of this node's children sorted from greatest to
///         least priority."""
///         if not self.paths_loaded: self.load_paths()
///         return sorted(self._children, key=attrgetter('sort_key'))
///
///     def __iter__(self):
///         return iter(self._children)
///
///     def __eq__(self, other):
///         if not isinstance(other, SymbolNode):
///             return False
///         return self is other or (type(self.s) == type(other.s) and self.s == other.s and self.start == other.start and self.end is other.end)
///
///     def __hash__(self):
///         return self._hash
///
///     def __repr__(self):
///         if self.is_intermediate:
///             rule = self.s[0]
///             ptr = self.s[1]
///             before = ( expansion.name for expansion in rule.expansion[:ptr] )
///             after = ( expansion.name for expansion in rule.expansion[ptr:] )
///             symbol = "{} ::= {}* {}".format(rule.origin.name, ' '.join(before), ' '.join(after))
///         else:
///             symbol = self.s.name
///         return "({}, {}, {}, {})".format(symbol, self.start, self.end, self.priority)
///
/// class PackedNode(ForestNode):
///     """
///     A Packed Node represents a single derivation in a symbol node.
///
///     Parameters:
///         rule: The rule associated with this node.
///         parent: The parent of this node.
///         left: The left child of this node. ``None`` if one does not exist.
///         right: The right child of this node. ``None`` if one does not exist.
///         priority: The priority of this node.
///     """
///     __slots__ = ('parent', 's', 'rule', 'start', 'left', 'right', 'priority', '_hash')
///     def __init__(self, parent, s, rule, start, left, right):
///         self.parent = parent
///         self.s = s
///         self.start = start
///         self.rule = rule
///         self.left = left
///         self.right = right
///         self.priority = float('-inf')
///         self._hash = hash((self.left, self.right))
///
///     @property
///     def is_empty(self):
///         return self.left is None and self.right is None
///
///     @property
///     def sort_key(self):
///         """
///         Used to sort PackedNode children of SymbolNodes.
///         A SymbolNode has multiple PackedNodes if it matched
///         ambiguously. Hence, we use the sort order to identify
///         the order in which ambiguous children should be considered.
///         """
///         return self.is_empty, -self.priority, self.rule.order
///
///     @property
///     def children(self):
///         """Returns a list of this node's children."""
///         return [x for x in [self.left, self.right] if x is not None]
///
///     def __iter__(self):
///         yield self.left
///         yield self.right
///
///     def __eq__(self, other):
///         if not isinstance(other, PackedNode):
///             return False
///         return self is other or (self.left == other.left and self.right == other.right)
///
///     def __hash__(self):
///         return self._hash
///
///     def __repr__(self):
///         if isinstance(self.s, tuple):
///             rule = self.s[0]
///             ptr = self.s[1]
///             before = ( expansion.name for expansion in rule.expansion[:ptr] )
///             after = ( expansion.name for expansion in rule.expansion[ptr:] )
///             symbol = "{} ::= {}* {}".format(rule.origin.name, ' '.join(before), ' '.join(after))
///         else:
///             symbol = self.s.name
///         return "({}, {}, {}, {})".format(symbol, self.start, self.priority, self.rule.order)
///
/// class TokenNode(ForestNode):
///     """
///     A Token Node represents a matched terminal and is always a leaf node.
///
///     Parameters:
///         token: The Token associated with this node.
///         term: The TerminalDef matched by the token.
///         priority: The priority of this node.
///     """
///     __slots__ = ('token', 'term', 'priority', '_hash')
///     def __init__(self, token, term, priority=None):
///         self.token = token
///         self.term = term
///         if priority is not None:
///             self.priority = priority
///         else:
///             self.priority = term.priority if term is not None else 0
///         self._hash = hash(token)
///
///     def __eq__(self, other):
///         if not isinstance(other, TokenNode):
///             return False
///         return self is other or (self.token == other.token)
///
///     def __hash__(self):
///         return self._hash
///
///     def __repr__(self):
///         return repr(self.token)
///
/// class ForestVisitor:
///     """
///     An abstract base class for building forest visitors.
///
///     This class performs a controllable depth-first walk of an SPPF.
///     The visitor will not enter cycles and will backtrack if one is encountered.
///     Subclasses are notified of cycles through the ``on_cycle`` method.
///
///     Behavior for visit events is defined by overriding the
///     ``visit*node*`` functions.
///
///     The walk is controlled by the return values of the ``visit*node_in``
///     methods. Returning a node(s) will schedule them to be visited. The visitor
///     will begin to backtrack if no nodes are returned.
///
///     Parameters:
///         single_visit: If ``True``, non-Token nodes will only be visited once.
///     """
///
///     def __init__(self, single_visit=False):
///         self.single_visit = single_visit
///
///     def visit_token_node(self, node):
///         """Called when a ``Token`` is visited. ``Token`` nodes are always leaves."""
///         pass
///
///     def visit_symbol_node_in(self, node):
///         """Called when a symbol node is visited. Nodes that are returned
///         will be scheduled to be visited. If ``visit_intermediate_node_in``
///         is not implemented, this function will be called for intermediate
///         nodes as well."""
///         pass
///
///     def visit_symbol_node_out(self, node):
///         """Called after all nodes returned from a corresponding ``visit_symbol_node_in``
///         call have been visited. If ``visit_intermediate_node_out``
///         is not implemented, this function will be called for intermediate
///         nodes as well."""
///         pass
///
///     def visit_packed_node_in(self, node):
///         """Called when a packed node is visited. Nodes that are returned
///         will be scheduled to be visited. """
///         pass
///
///     def visit_packed_node_out(self, node):
///         """Called after all nodes returned from a corresponding ``visit_packed_node_in``
///         call have been visited."""
///         pass
///
///     def on_cycle(self, node, path):
///         """Called when a cycle is encountered.
///
///         Parameters:
///             node: The node that causes a cycle.
///             path: The list of nodes being visited: nodes that have been
///                 entered but not exited. The first element is the root in a forest
///                 visit, and the last element is the node visited most recently.
///                 ``path`` should be treated as read-only.
///         """
///         pass
///
///     def get_cycle_in_path(self, node, path):
///         """A utility function for use in ``on_cycle`` to obtain a slice of
///         ``path`` that only contains the nodes that make up the cycle."""
///         index = len(path) - 1
///         while id(path[index]) != id(node):
///             index -= 1
///         return path[index:]
///
///     def visit(self, root):
///         # Visiting is a list of IDs of all symbol/intermediate nodes currently in
///         # the stack. It serves two purposes: to detect when we 'recurse' in and out
///         # of a symbol/intermediate so that we can process both up and down. Also,
///         # since the SPPF can have cycles it allows us to detect if we're trying
///         # to recurse into a node that's already on the stack (infinite recursion).
///         visiting = set()
///
///         # set of all nodes that have been visited
///         visited = set()
///
///         # a list of nodes that are currently being visited
///         # used for the `on_cycle` callback
///         path = []
///
///         # We do not use recursion here to walk the Forest due to the limited
///         # stack size in python. Therefore input_stack is essentially our stack.
///         input_stack = deque([root])
///
///         # It is much faster to cache these as locals since they are called
///         # many times in large parses.
///         vpno = getattr(self, 'visit_packed_node_out')
///         vpni = getattr(self, 'visit_packed_node_in')
///         vsno = getattr(self, 'visit_symbol_node_out')
///         vsni = getattr(self, 'visit_symbol_node_in')
///         vino = getattr(self, 'visit_intermediate_node_out', vsno)
///         vini = getattr(self, 'visit_intermediate_node_in', vsni)
///         vtn = getattr(self, 'visit_token_node')
///         oc = getattr(self, 'on_cycle')
///
///         while input_stack:
///             current = next(reversed(input_stack))
///             try:
///                 next_node = next(current)
///             except StopIteration:
///                 input_stack.pop()
///                 continue
///             except TypeError:
///                 ### If the current object is not an iterator, pass through to Token/SymbolNode
///                 pass
///             else:
///                 if next_node is None:
///                     continue
///
///                 if id(next_node) in visiting:
///                     oc(next_node, path)
///                     continue
///
///                 input_stack.append(next_node)
///                 continue
///
///             if isinstance(current, TokenNode):
///                 vtn(current.token)
///                 input_stack.pop()
///                 continue
///
///             current_id = id(current)
///             if current_id in visiting:
///                 if isinstance(current, PackedNode):
///                     vpno(current)
///                 elif current.is_intermediate:
///                     vino(current)
///                 else:
///                     vsno(current)
///                 input_stack.pop()
///                 path.pop()
///                 visiting.remove(current_id)
///                 visited.add(current_id)
///             elif self.single_visit and current_id in visited:
///                 input_stack.pop()
///             else:
///                 visiting.add(current_id)
///                 path.append(current)
///                 if isinstance(current, PackedNode):
///                     next_node = vpni(current)
///                 elif current.is_intermediate:
///                     next_node = vini(current)
///                 else:
///                     next_node = vsni(current)
///                 if next_node is None:
///                     continue
///
///                 if not isinstance(next_node, ForestNode):
///                     next_node = iter(next_node)
///                 elif id(next_node) in visiting:
///                     oc(next_node, path)
///                     continue
///
///                 input_stack.append(next_node)
///
/// class ForestTransformer(ForestVisitor):
///     """The base class for a bottom-up forest transformation. Most users will
///     want to use ``TreeForestTransformer`` instead as it has a friendlier
///     interface and covers most use cases.
///
///     Transformations are applied via inheritance and overriding of the
///     ``transform*node`` methods.
///
///     ``transform_token_node`` receives a ``Token`` as an argument.
///     All other methods receive the node that is being transformed and
///     a list of the results of the transformations of that node's children.
///     The return value of these methods are the resulting transformations.
///
///     If ``Discard`` is raised in a node's transformation, no data from that node
///     will be passed to its parent's transformation.
///     """
///
///     def __init__(self):
///         super(ForestTransformer, self).__init__()
///         # results of transformations
///         self.data = dict()
///         # used to track parent nodes
///         self.node_stack = deque()
///
///     def transform(self, root):
///         """Perform a transformation on an SPPF."""
///         self.node_stack.append('result')
///         self.data['result'] = []
///         self.visit(root)
///         assert len(self.data['result']) <= 1
///         if self.data['result']:
///             return self.data['result'][0]
///
///     def transform_symbol_node(self, node, data):
///         """Transform a symbol node."""
///         return node
///
///     def transform_intermediate_node(self, node, data):
///         """Transform an intermediate node."""
///         return node
///
///     def transform_packed_node(self, node, data):
///         """Transform a packed node."""
///         return node
///
///     def transform_token_node(self, node):
///         """Transform a ``Token``."""
///         return node
///
///     def visit_symbol_node_in(self, node):
///         self.node_stack.append(id(node))
///         self.data[id(node)] = []
///         return node.children
///
///     def visit_packed_node_in(self, node):
///         self.node_stack.append(id(node))
///         self.data[id(node)] = []
///         return node.children
///
///     def visit_token_node(self, node):
///         transformed = self.transform_token_node(node)
///         if transformed is not Discard:
///             self.data[self.node_stack[-1]].append(transformed)
///
///     def _visit_node_out_helper(self, node, method):
///         self.node_stack.pop()
///         transformed = method(node, self.data[id(node)])
///         if transformed is not Discard:
///             self.data[self.node_stack[-1]].append(transformed)
///         del self.data[id(node)]
///
///     def visit_symbol_node_out(self, node):
///         self._visit_node_out_helper(node, self.transform_symbol_node)
///
///     def visit_intermediate_node_out(self, node):
///         self._visit_node_out_helper(node, self.transform_intermediate_node)
///
///     def visit_packed_node_out(self, node):
///         self._visit_node_out_helper(node, self.transform_packed_node)
///
///
/// class ForestSumVisitor(ForestVisitor):
///     """
///     A visitor for prioritizing ambiguous parts of the Forest.
///
///     This visitor is used when support for explicit priorities on
///     rules is requested (whether normal, or invert). It walks the
///     forest (or subsets thereof) and cascades properties upwards
///     from the leaves.
///
///     It would be ideal to do this during parsing, however this would
///     require processing each Earley item multiple times. That's
///     a big performance drawback; so running a forest walk is the
///     lesser of two evils: there can be significantly more Earley
///     items created during parsing than there are SPPF nodes in the
///     final tree.
///     """
///     def __init__(self):
///         super(ForestSumVisitor, self).__init__(single_visit=True)
///
///     def visit_packed_node_in(self, node):
///         yield node.left
///         yield node.right
///
///     def visit_symbol_node_in(self, node):
///         return iter(node.children)
///
///     def visit_packed_node_out(self, node):
///         priority = node.rule.options.priority if not node.parent.is_intermediate and node.rule.options.priority else 0
///         priority += getattr(node.right, 'priority', 0)
///         priority += getattr(node.left, 'priority', 0)
///         node.priority = priority
///
///     def visit_symbol_node_out(self, node):
///         node.priority = max(child.priority for child in node.children)
///
/// class PackedData():
///     """Used in transformationss of packed nodes to distinguish the data
///     that comes from the left child and the right child.
///     """
///
///     class _NoData():
///         pass
///
///     NO_DATA = _NoData()
///
///     def __init__(self, node, data):
///         self.left = self.NO_DATA
///         self.right = self.NO_DATA
///         if data:
///             if node.left is not None:
///                 self.left = data[0]
///                 if len(data) > 1:
///                     self.right = data[1]
///             else:
///                 self.right = data[0]
///
/// class ForestToParseTree(ForestTransformer):
///     """Used by the earley parser when ambiguity equals 'resolve' or
///     'explicit'. Transforms an SPPF into an (ambiguous) parse tree.
///
///     Parameters:
///         tree_class: The tree class to use for construction
///         callbacks: A dictionary of rules to functions that output a tree
///         prioritizer: A ``ForestVisitor`` that manipulates the priorities of ForestNodes
///         resolve_ambiguity: If True, ambiguities will be resolved based on
///                         priorities. Otherwise, `_ambig` nodes will be in the resulting tree.
///         use_cache: If True, the results of packed node transformations will be cached.
///     """
///
///     def __init__(self, tree_class=Tree, callbacks=dict(), prioritizer=ForestSumVisitor(), resolve_ambiguity=True, use_cache=True):
///         super(ForestToParseTree, self).__init__()
///         self.tree_class = tree_class
///         self.callbacks = callbacks
///         self.prioritizer = prioritizer
///         self.resolve_ambiguity = resolve_ambiguity
///         self._use_cache = use_cache
///         self._cache = {}
///         self._on_cycle_retreat = False
///         self._cycle_node = None
///         self._successful_visits = set()
///
///     def visit(self, root):
///         if self.prioritizer:
///             self.prioritizer.visit(root)
///         super(ForestToParseTree, self).visit(root)
///         self._cache = {}
///
///     def on_cycle(self, node, path):
///         logger.debug("Cycle encountered in the SPPF at node: %s. "
///                 "As infinite ambiguities cannot be represented in a tree, "
///                 "this family of derivations will be discarded.", node)
///         self._cycle_node = node
///         self._on_cycle_retreat = True
///
///     def _check_cycle(self, node):
///         if self._on_cycle_retreat:
///             if id(node) == id(self._cycle_node) or id(node) in self._successful_visits:
///                 self._cycle_node = None
///                 self._on_cycle_retreat = False
///             else:
///                 return Discard
///
///     def _collapse_ambig(self, children):
///         new_children = []
///         for child in children:
///             if hasattr(child, 'data') and child.data == '_ambig':
///                 new_children += child.children
///             else:
///                 new_children.append(child)
///         return new_children
///
///     def _call_rule_func(self, node, data):
///         # called when transforming children of symbol nodes
///         # data is a list of trees or tokens that correspond to the
///         # symbol's rule expansion
///         return self.callbacks[node.rule](data)
///
///     def _call_ambig_func(self, node, data):
///         # called when transforming a symbol node
///         # data is a list of trees where each tree's data is
///         # equal to the name of the symbol or one of its aliases.
///         if len(data) > 1:
///             return self.tree_class('_ambig', data)
///         elif data:
///             return data[0]
///         return Discard
///
///     def transform_symbol_node(self, node, data):
///         if id(node) not in self._successful_visits:
///             return Discard
///         r = self._check_cycle(node)
///         if r is Discard:
///             return r
///         self._successful_visits.remove(id(node))
///         data = self._collapse_ambig(data)
///         return self._call_ambig_func(node, data)
///
///     def transform_intermediate_node(self, node, data):
///         if id(node) not in self._successful_visits:
///             return Discard
///         r = self._check_cycle(node)
///         if r is Discard:
///             return r
///         self._successful_visits.remove(id(node))
///         if len(data) > 1:
///             children = [self.tree_class('_inter', c) for c in data]
///             return self.tree_class('_iambig', children)
///         return data[0]
///
///     def transform_packed_node(self, node, data):
///         r = self._check_cycle(node)
///         if r is Discard:
///             return r
///         if self.resolve_ambiguity and id(node.parent) in self._successful_visits:
///             return Discard
///         if self._use_cache and id(node) in self._cache:
///             return self._cache[id(node)]
///         children = []
///         assert len(data) <= 2
///         data = PackedData(node, data)
///         if data.left is not PackedData.NO_DATA:
///             if node.left.is_intermediate and isinstance(data.left, list):
///                 children += data.left
///             else:
///                 children.append(data.left)
///         if data.right is not PackedData.NO_DATA:
///             children.append(data.right)
///         if node.parent.is_intermediate:
///             return self._cache.setdefault(id(node), children)
///         return self._cache.setdefault(id(node), self._call_rule_func(node, children))
///
///     def visit_symbol_node_in(self, node):
///         super(ForestToParseTree, self).visit_symbol_node_in(node)
///         if self._on_cycle_retreat:
///             return
///         return node.children
///
///     def visit_packed_node_in(self, node):
///         self._on_cycle_retreat = False
///         to_visit = super(ForestToParseTree, self).visit_packed_node_in(node)
///         if not self.resolve_ambiguity or id(node.parent) not in self._successful_visits:
///             if not self._use_cache or id(node) not in self._cache:
///                 return to_visit
///
///     def visit_packed_node_out(self, node):
///         super(ForestToParseTree, self).visit_packed_node_out(node)
///         if not self._on_cycle_retreat:
///             self._successful_visits.add(id(node.parent))
///
/// def handles_ambiguity(func):
///     """Decorator for methods of subclasses of ``TreeForestTransformer``.
///     Denotes that the method should receive a list of transformed derivations."""
///     func.handles_ambiguity = True
///     return func
///
/// class TreeForestTransformer(ForestToParseTree):
///     """A ``ForestTransformer`` with a tree ``Transformer``-like interface.
///     By default, it will construct a tree.
///
///     Methods provided via inheritance are called based on the rule/symbol
///     names of nodes in the forest.
///
///     Methods that act on rules will receive a list of the results of the
///     transformations of the rule's children. By default, trees and tokens.
///
///     Methods that act on tokens will receive a token.
///
///     Alternatively, methods that act on rules may be annotated with
///     ``handles_ambiguity``. In this case, the function will receive a list
///     of all the transformations of all the derivations of the rule.
///     By default, a list of trees where each tree.data is equal to the
///     rule name or one of its aliases.
///
///     Non-tree transformations are made possible by override of
///     ``__default__``, ``__default_token__``, and ``__default_ambig__``.
///
///     Note:
///         Tree shaping features such as inlined rules and token filtering are
///         not built into the transformation. Positions are also not propagated.
///
///     Parameters:
///         tree_class: The tree class to use for construction
///         prioritizer: A ``ForestVisitor`` that manipulates the priorities of nodes in the SPPF.
///         resolve_ambiguity: If True, ambiguities will be resolved based on priorities.
///         use_cache (bool): If True, caches the results of some transformations,
///                           potentially improving performance when ``resolve_ambiguity==False``.
///                           Only use if you know what you are doing: i.e. All transformation
///                           functions are pure and referentially transparent.
///     """
///
///     def __init__(self, tree_class=Tree, prioritizer=ForestSumVisitor(), resolve_ambiguity=True, use_cache=False):
///         super(TreeForestTransformer, self).__init__(tree_class, dict(), prioritizer, resolve_ambiguity, use_cache)
///
///     def __default__(self, name, data):
///         """Default operation on tree (for override).
///
///         Returns a tree with name with data as children.
///         """
///         return self.tree_class(name, data)
///
///     def __default_ambig__(self, name, data):
///         """Default operation on ambiguous rule (for override).
///
///         Wraps data in an '_ambig_' node if it contains more than
///         one element.
///         """
///         if len(data) > 1:
///             return self.tree_class('_ambig', data)
///         elif data:
///             return data[0]
///         return Discard
///
///     def __default_token__(self, node):
///         """Default operation on ``Token`` (for override).
///
///         Returns ``node``.
///         """
///         return node
///
///     def transform_token_node(self, node):
///         return getattr(self, node.type, self.__default_token__)(node)
///
///     def _call_rule_func(self, node, data):
///         name = node.rule.alias or node.rule.options.template_source or node.rule.origin.name
///         user_func = getattr(self, name, self.__default__)
///         if user_func == self.__default__ or hasattr(user_func, 'handles_ambiguity'):
///             user_func = partial(self.__default__, name)
///         if not self.resolve_ambiguity:
///             wrapper = partial(AmbiguousIntermediateExpander, self.tree_class)
///             user_func = wrapper(user_func)
///         return user_func(data)
///
///     def _call_ambig_func(self, node, data):
///         name = node.s.name
///         user_func = getattr(self, name, self.__default_ambig__)
///         if user_func == self.__default_ambig__ or not hasattr(user_func, 'handles_ambiguity'):
///             user_func = partial(self.__default_ambig__, name)
///         return user_func(data)
///
/// class ForestToPyDotVisitor(ForestVisitor):
///     """
///     A Forest visitor which writes the SPPF to a PNG.
///
///     The SPPF can get really large, really quickly because
///     of the amount of meta-data it stores, so this is probably
///     only useful for trivial trees and learning how the SPPF
///     is structured.
///     """
///     def __init__(self, rankdir="TB"):
///         super(ForestToPyDotVisitor, self).__init__(single_visit=True)
///         self.pydot = import_module('pydot')
///         self.graph = self.pydot.Dot(graph_type='digraph', rankdir=rankdir)
///
///     def visit(self, root, filename):
///         super(ForestToPyDotVisitor, self).visit(root)
///         try:
///             self.graph.write_png(filename)
///         except FileNotFoundError as e:
///             logger.error("Could not write png: ", e)
///
///     def visit_token_node(self, node):
///         graph_node_id = str(id(node))
///         graph_node_label = "\"{}\"".format(node.value.replace('"', '\\"'))
///         graph_node_color = 0x808080
///         graph_node_style = "\"filled,rounded\""
///         graph_node_shape = "diamond"
///         graph_node = self.pydot.Node(graph_node_id, style=graph_node_style, fillcolor="#{:06x}".format(graph_node_color), shape=graph_node_shape, label=graph_node_label)
///         self.graph.add_node(graph_node)
///
///     def visit_packed_node_in(self, node):
///         graph_node_id = str(id(node))
///         graph_node_label = repr(node)
///         graph_node_color = 0x808080
///         graph_node_style = "filled"
///         graph_node_shape = "diamond"
///         graph_node = self.pydot.Node(graph_node_id, style=graph_node_style, fillcolor="#{:06x}".format(graph_node_color), shape=graph_node_shape, label=graph_node_label)
///         self.graph.add_node(graph_node)
///         yield node.left
///         yield node.right
///
///     def visit_packed_node_out(self, node):
///         graph_node_id = str(id(node))
///         graph_node = self.graph.get_node(graph_node_id)[0]
///         for child in [node.left, node.right]:
///             if child is not None:
///                 child_graph_node_id = str(id(child.token if isinstance(child, TokenNode) else child))
///                 child_graph_node = self.graph.get_node(child_graph_node_id)[0]
///                 self.graph.add_edge(self.pydot.Edge(graph_node, child_graph_node))
///             else:
///                 #### Try and be above the Python object ID range; probably impl. specific, but maybe this is okay.
///                 child_graph_node_id = str(randint(100000000000000000000000000000,123456789012345678901234567890))
///                 child_graph_node_style = "invis"
///                 child_graph_node = self.pydot.Node(child_graph_node_id, style=child_graph_node_style, label="None")
///                 child_edge_style = "invis"
///                 self.graph.add_node(child_graph_node)
///                 self.graph.add_edge(self.pydot.Edge(graph_node, child_graph_node, style=child_edge_style))
///
///     def visit_symbol_node_in(self, node):
///         graph_node_id = str(id(node))
///         graph_node_label = repr(node)
///         graph_node_color = 0x808080
///         graph_node_style = "\"filled\""
///         if node.is_intermediate:
///             graph_node_shape = "ellipse"
///         else:
///             graph_node_shape = "rectangle"
///         graph_node = self.pydot.Node(graph_node_id, style=graph_node_style, fillcolor="#{:06x}".format(graph_node_color), shape=graph_node_shape, label=graph_node_label)
///         self.graph.add_node(graph_node)
///         return iter(node.children)
///
///     def visit_symbol_node_out(self, node):
///         graph_node_id = str(id(node))
///         graph_node = self.graph.get_node(graph_node_id)[0]
///         for child in node.children:
///             child_graph_node_id = str(id(child))
///             child_graph_node = self.graph.get_node(child_graph_node_id)[0]
///             self.graph.add_edge(self.pydot.Edge(graph_node, child_graph_node))
/// ```
final class earley_forest extends PythonModule {
  earley_forest.from(super.pythonModule) : super.from();

  static earley_forest import() => PythonFfiDart.instance.importModule(
        "lark.parsers.earley_forest",
        earley_forest.from,
      );

  /// ## handles_ambiguity
  ///
  /// ### python docstring
  ///
  /// Decorator for methods of subclasses of ``TreeForestTransformer``.
  /// Denotes that the method should receive a list of transformed derivations.
  ///
  /// ### python source
  /// ```py
  /// def handles_ambiguity(func):
  ///     """Decorator for methods of subclasses of ``TreeForestTransformer``.
  ///     Denotes that the method should receive a list of transformed derivations."""
  ///     func.handles_ambiguity = True
  ///     return func
  /// ```
  Object? handles_ambiguity({
    required Object? func,
  }) =>
      getFunction("handles_ambiguity").call(
        <Object?>[
          func,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## grammar_analysis
///
/// ### python source
/// ```py
/// from collections import Counter, defaultdict
///
/// from ..utils import bfs, fzset, classify
/// from ..exceptions import GrammarError
/// from ..grammar import Rule, Terminal, NonTerminal
///
///
/// class RulePtr:
///     __slots__ = ('rule', 'index')
///
///     def __init__(self, rule, index):
///         assert isinstance(rule, Rule)
///         assert index <= len(rule.expansion)
///         self.rule = rule
///         self.index = index
///
///     def __repr__(self):
///         before = [x.name for x in self.rule.expansion[:self.index]]
///         after = [x.name for x in self.rule.expansion[self.index:]]
///         return '<%s : %s * %s>' % (self.rule.origin.name, ' '.join(before), ' '.join(after))
///
///     @property
///     def next(self):
///         return self.rule.expansion[self.index]
///
///     def advance(self, sym):
///         assert self.next == sym
///         return RulePtr(self.rule, self.index+1)
///
///     @property
///     def is_satisfied(self):
///         return self.index == len(self.rule.expansion)
///
///     def __eq__(self, other):
///         return self.rule == other.rule and self.index == other.index
///     def __hash__(self):
///         return hash((self.rule, self.index))
///
///
/// # state generation ensures no duplicate LR0ItemSets
/// class LR0ItemSet:
///     __slots__ = ('kernel', 'closure', 'transitions', 'lookaheads')
///
///     def __init__(self, kernel, closure):
///         self.kernel = fzset(kernel)
///         self.closure = fzset(closure)
///         self.transitions = {}
///         self.lookaheads = defaultdict(set)
///
///     def __repr__(self):
///         return '{%s | %s}' % (', '.join([repr(r) for r in self.kernel]), ', '.join([repr(r) for r in self.closure]))
///
///
/// def update_set(set1, set2):
///     if not set2 or set1 > set2:
///         return False
///
///     copy = set(set1)
///     set1 |= set2
///     return set1 != copy
///
/// def calculate_sets(rules):
///     """Calculate FOLLOW sets.
///
///     Adapted from: http://lara.epfl.ch/w/cc09:algorithm_for_first_and_follow_sets"""
///     symbols = {sym for rule in rules for sym in rule.expansion} | {rule.origin for rule in rules}
///
///     # foreach grammar rule X ::= Y(1) ... Y(k)
///     # if k=0 or {Y(1),...,Y(k)} subset of NULLABLE then
///     #   NULLABLE = NULLABLE union {X}
///     # for i = 1 to k
///     #   if i=1 or {Y(1),...,Y(i-1)} subset of NULLABLE then
///     #     FIRST(X) = FIRST(X) union FIRST(Y(i))
///     #   for j = i+1 to k
///     #     if i=k or {Y(i+1),...Y(k)} subset of NULLABLE then
///     #       FOLLOW(Y(i)) = FOLLOW(Y(i)) union FOLLOW(X)
///     #     if i+1=j or {Y(i+1),...,Y(j-1)} subset of NULLABLE then
///     #       FOLLOW(Y(i)) = FOLLOW(Y(i)) union FIRST(Y(j))
///     # until none of NULLABLE,FIRST,FOLLOW changed in last iteration
///
///     NULLABLE = set()
///     FIRST = {}
///     FOLLOW = {}
///     for sym in symbols:
///         FIRST[sym]={sym} if sym.is_term else set()
///         FOLLOW[sym]=set()
///
///     # Calculate NULLABLE and FIRST
///     changed = True
///     while changed:
///         changed = False
///
///         for rule in rules:
///             if set(rule.expansion) <= NULLABLE:
///                 if update_set(NULLABLE, {rule.origin}):
///                     changed = True
///
///             for i, sym in enumerate(rule.expansion):
///                 if set(rule.expansion[:i]) <= NULLABLE:
///                     if update_set(FIRST[rule.origin], FIRST[sym]):
///                         changed = True
///                 else:
///                     break
///
///     # Calculate FOLLOW
///     changed = True
///     while changed:
///         changed = False
///
///         for rule in rules:
///             for i, sym in enumerate(rule.expansion):
///                 if i==len(rule.expansion)-1 or set(rule.expansion[i+1:]) <= NULLABLE:
///                     if update_set(FOLLOW[sym], FOLLOW[rule.origin]):
///                         changed = True
///
///                 for j in range(i+1, len(rule.expansion)):
///                     if set(rule.expansion[i+1:j]) <= NULLABLE:
///                         if update_set(FOLLOW[sym], FIRST[rule.expansion[j]]):
///                             changed = True
///
///     return FIRST, FOLLOW, NULLABLE
///
///
/// class GrammarAnalyzer:
///     def __init__(self, parser_conf, debug=False):
///         self.debug = debug
///
///         root_rules = {start: Rule(NonTerminal('$root_' + start), [NonTerminal(start), Terminal('$END')])
///                       for start in parser_conf.start}
///
///         rules = parser_conf.rules + list(root_rules.values())
///         self.rules_by_origin = classify(rules, lambda r: r.origin)
///
///         if len(rules) != len(set(rules)):
///             duplicates = [item for item, count in Counter(rules).items() if count > 1]
///             raise GrammarError("Rules defined twice: %s" % ', '.join(str(i) for i in duplicates))
///
///         for r in rules:
///             for sym in r.expansion:
///                 if not (sym.is_term or sym in self.rules_by_origin):
///                     raise GrammarError("Using an undefined rule: %s" % sym)
///
///         self.start_states = {start: self.expand_rule(root_rule.origin)
///                              for start, root_rule in root_rules.items()}
///
///         self.end_states = {start: fzset({RulePtr(root_rule, len(root_rule.expansion))})
///                            for start, root_rule in root_rules.items()}
///
///         lr0_root_rules = {start: Rule(NonTerminal('$root_' + start), [NonTerminal(start)])
///                 for start in parser_conf.start}
///
///         lr0_rules = parser_conf.rules + list(lr0_root_rules.values())
///         assert(len(lr0_rules) == len(set(lr0_rules)))
///
///         self.lr0_rules_by_origin = classify(lr0_rules, lambda r: r.origin)
///
///         # cache RulePtr(r, 0) in r (no duplicate RulePtr objects)
///         self.lr0_start_states = {start: LR0ItemSet([RulePtr(root_rule, 0)], self.expand_rule(root_rule.origin, self.lr0_rules_by_origin))
///                 for start, root_rule in lr0_root_rules.items()}
///
///         self.FIRST, self.FOLLOW, self.NULLABLE = calculate_sets(rules)
///
///     def expand_rule(self, source_rule, rules_by_origin=None):
///         "Returns all init_ptrs accessible by rule (recursive)"
///
///         if rules_by_origin is None:
///             rules_by_origin = self.rules_by_origin
///
///         init_ptrs = set()
///         def _expand_rule(rule):
///             assert not rule.is_term, rule
///
///             for r in rules_by_origin[rule]:
///                 init_ptr = RulePtr(r, 0)
///                 init_ptrs.add(init_ptr)
///
///                 if r.expansion: # if not empty rule
///                     new_r = init_ptr.next
///                     if not new_r.is_term:
///                         yield new_r
///
///         for _ in bfs([source_rule], _expand_rule):
///             pass
///
///         return fzset(init_ptrs)
/// ```
final class grammar_analysis extends PythonModule {
  grammar_analysis.from(super.pythonModule) : super.from();

  static grammar_analysis import() => PythonFfiDart.instance.importModule(
        "lark.parsers.grammar_analysis",
        grammar_analysis.from,
      );

  /// ## calculate_sets
  ///
  /// ### python docstring
  ///
  /// Calculate FOLLOW sets.
  ///
  /// Adapted from: http://lara.epfl.ch/w/cc09:algorithm_for_first_and_follow_sets
  ///
  /// ### python source
  /// ```py
  /// def calculate_sets(rules):
  ///     """Calculate FOLLOW sets.
  ///
  ///     Adapted from: http://lara.epfl.ch/w/cc09:algorithm_for_first_and_follow_sets"""
  ///     symbols = {sym for rule in rules for sym in rule.expansion} | {rule.origin for rule in rules}
  ///
  ///     # foreach grammar rule X ::= Y(1) ... Y(k)
  ///     # if k=0 or {Y(1),...,Y(k)} subset of NULLABLE then
  ///     #   NULLABLE = NULLABLE union {X}
  ///     # for i = 1 to k
  ///     #   if i=1 or {Y(1),...,Y(i-1)} subset of NULLABLE then
  ///     #     FIRST(X) = FIRST(X) union FIRST(Y(i))
  ///     #   for j = i+1 to k
  ///     #     if i=k or {Y(i+1),...Y(k)} subset of NULLABLE then
  ///     #       FOLLOW(Y(i)) = FOLLOW(Y(i)) union FOLLOW(X)
  ///     #     if i+1=j or {Y(i+1),...,Y(j-1)} subset of NULLABLE then
  ///     #       FOLLOW(Y(i)) = FOLLOW(Y(i)) union FIRST(Y(j))
  ///     # until none of NULLABLE,FIRST,FOLLOW changed in last iteration
  ///
  ///     NULLABLE = set()
  ///     FIRST = {}
  ///     FOLLOW = {}
  ///     for sym in symbols:
  ///         FIRST[sym]={sym} if sym.is_term else set()
  ///         FOLLOW[sym]=set()
  ///
  ///     # Calculate NULLABLE and FIRST
  ///     changed = True
  ///     while changed:
  ///         changed = False
  ///
  ///         for rule in rules:
  ///             if set(rule.expansion) <= NULLABLE:
  ///                 if update_set(NULLABLE, {rule.origin}):
  ///                     changed = True
  ///
  ///             for i, sym in enumerate(rule.expansion):
  ///                 if set(rule.expansion[:i]) <= NULLABLE:
  ///                     if update_set(FIRST[rule.origin], FIRST[sym]):
  ///                         changed = True
  ///                 else:
  ///                     break
  ///
  ///     # Calculate FOLLOW
  ///     changed = True
  ///     while changed:
  ///         changed = False
  ///
  ///         for rule in rules:
  ///             for i, sym in enumerate(rule.expansion):
  ///                 if i==len(rule.expansion)-1 or set(rule.expansion[i+1:]) <= NULLABLE:
  ///                     if update_set(FOLLOW[sym], FOLLOW[rule.origin]):
  ///                         changed = True
  ///
  ///                 for j in range(i+1, len(rule.expansion)):
  ///                     if set(rule.expansion[i+1:j]) <= NULLABLE:
  ///                         if update_set(FOLLOW[sym], FIRST[rule.expansion[j]]):
  ///                             changed = True
  ///
  ///     return FIRST, FOLLOW, NULLABLE
  /// ```
  Object? calculate_sets({
    required Object? rules,
  }) =>
      getFunction("calculate_sets").call(
        <Object?>[
          rules,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## update_set
  ///
  /// ### python source
  /// ```py
  /// def update_set(set1, set2):
  ///     if not set2 or set1 > set2:
  ///         return False
  ///
  ///     copy = set(set1)
  ///     set1 |= set2
  ///     return set1 != copy
  /// ```
  Object? update_set({
    required Object? set1,
    required Object? set2,
  }) =>
      getFunction("update_set").call(
        <Object?>[
          set1,
          set2,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## lalr_analysis
///
/// ### python docstring
///
/// This module builds a LALR(1) transition-table for lalr_parser.py
///
/// For now, shift/reduce conflicts are automatically resolved as shifts.
///
/// ### python source
/// ```py
/// """This module builds a LALR(1) transition-table for lalr_parser.py
///
/// For now, shift/reduce conflicts are automatically resolved as shifts.
/// """
///
/// # Author: Erez Shinan (2017)
/// # Email : erezshin@gmail.com
///
/// from collections import defaultdict
///
/// from ..utils import classify, classify_bool, bfs, fzset, Enumerator, logger
/// from ..exceptions import GrammarError
///
/// from .grammar_analysis import GrammarAnalyzer, Terminal, LR0ItemSet
/// from ..grammar import Rule
///
/// ###{standalone
///
/// class Action:
///     def __init__(self, name):
///         self.name = name
///     def __str__(self):
///         return self.name
///     def __repr__(self):
///         return str(self)
///
/// Shift = Action('Shift')
/// Reduce = Action('Reduce')
///
///
/// class ParseTable:
///     def __init__(self, states, start_states, end_states):
///         self.states = states
///         self.start_states = start_states
///         self.end_states = end_states
///
///     def serialize(self, memo):
///         tokens = Enumerator()
///
///         states = {
///             state: {tokens.get(token): ((1, arg.serialize(memo)) if action is Reduce else (0, arg))
///                     for token, (action, arg) in actions.items()}
///             for state, actions in self.states.items()
///         }
///
///         return {
///             'tokens': tokens.reversed(),
///             'states': states,
///             'start_states': self.start_states,
///             'end_states': self.end_states,
///         }
///
///     @classmethod
///     def deserialize(cls, data, memo):
///         tokens = data['tokens']
///         states = {
///             state: {tokens[token]: ((Reduce, Rule.deserialize(arg, memo)) if action==1 else (Shift, arg))
///                     for token, (action, arg) in actions.items()}
///             for state, actions in data['states'].items()
///         }
///         return cls(states, data['start_states'], data['end_states'])
///
///
/// class IntParseTable(ParseTable):
///
///     @classmethod
///     def from_ParseTable(cls, parse_table):
///         enum = list(parse_table.states)
///         state_to_idx = {s:i for i,s in enumerate(enum)}
///         int_states = {}
///
///         for s, la in parse_table.states.items():
///             la = {k:(v[0], state_to_idx[v[1]]) if v[0] is Shift else v
///                   for k,v in la.items()}
///             int_states[ state_to_idx[s] ] = la
///
///
///         start_states = {start:state_to_idx[s] for start, s in parse_table.start_states.items()}
///         end_states = {start:state_to_idx[s] for start, s in parse_table.end_states.items()}
///         return cls(int_states, start_states, end_states)
///
/// ###}
///
///
/// # digraph and traverse, see The Theory and Practice of Compiler Writing
///
/// # computes F(x) = G(x) union (union { G(y) | x R y })
/// # X: nodes
/// # R: relation (function mapping node -> list of nodes that satisfy the relation)
/// # G: set valued function
/// def digraph(X, R, G):
///     F = {}
///     S = []
///     N = {}
///     for x in X:
///         N[x] = 0
///     for x in X:
///         # this is always true for the first iteration, but N[x] may be updated in traverse below
///         if N[x] == 0:
///             traverse(x, S, N, X, R, G, F)
///     return F
///
/// # x: single node
/// # S: stack
/// # N: weights
/// # X: nodes
/// # R: relation (see above)
/// # G: set valued function
/// # F: set valued function we are computing (map of input -> output)
/// def traverse(x, S, N, X, R, G, F):
///     S.append(x)
///     d = len(S)
///     N[x] = d
///     F[x] = G[x]
///     for y in R[x]:
///         if N[y] == 0:
///             traverse(y, S, N, X, R, G, F)
///         n_x = N[x]
///         assert(n_x > 0)
///         n_y = N[y]
///         assert(n_y != 0)
///         if (n_y > 0) and (n_y < n_x):
///             N[x] = n_y
///         F[x].update(F[y])
///     if N[x] == d:
///         f_x = F[x]
///         while True:
///             z = S.pop()
///             N[z] = -1
///             F[z] = f_x
///             if z == x:
///                 break
///
///
/// class LALR_Analyzer(GrammarAnalyzer):
///     def __init__(self, parser_conf, debug=False):
///         GrammarAnalyzer.__init__(self, parser_conf, debug)
///         self.nonterminal_transitions = []
///         self.directly_reads = defaultdict(set)
///         self.reads = defaultdict(set)
///         self.includes = defaultdict(set)
///         self.lookback = defaultdict(set)
///
///
///     def compute_lr0_states(self):
///         self.lr0_states = set()
///         # map of kernels to LR0ItemSets
///         cache = {}
///
///         def step(state):
///             _, unsat = classify_bool(state.closure, lambda rp: rp.is_satisfied)
///
///             d = classify(unsat, lambda rp: rp.next)
///             for sym, rps in d.items():
///                 kernel = fzset({rp.advance(sym) for rp in rps})
///                 new_state = cache.get(kernel, None)
///                 if new_state is None:
///                     closure = set(kernel)
///                     for rp in kernel:
///                         if not rp.is_satisfied and not rp.next.is_term:
///                             closure |= self.expand_rule(rp.next, self.lr0_rules_by_origin)
///                     new_state = LR0ItemSet(kernel, closure)
///                     cache[kernel] = new_state
///
///                 state.transitions[sym] = new_state
///                 yield new_state
///
///             self.lr0_states.add(state)
///
///         for _ in bfs(self.lr0_start_states.values(), step):
///             pass
///
///     def compute_reads_relations(self):
///         # handle start state
///         for root in self.lr0_start_states.values():
///             assert(len(root.kernel) == 1)
///             for rp in root.kernel:
///                 assert(rp.index == 0)
///                 self.directly_reads[(root, rp.next)] = set([ Terminal('$END') ])
///
///         for state in self.lr0_states:
///             seen = set()
///             for rp in state.closure:
///                 if rp.is_satisfied:
///                     continue
///                 s = rp.next
///                 # if s is a not a nonterminal
///                 if s not in self.lr0_rules_by_origin:
///                     continue
///                 if s in seen:
///                     continue
///                 seen.add(s)
///                 nt = (state, s)
///                 self.nonterminal_transitions.append(nt)
///                 dr = self.directly_reads[nt]
///                 r = self.reads[nt]
///                 next_state = state.transitions[s]
///                 for rp2 in next_state.closure:
///                     if rp2.is_satisfied:
///                         continue
///                     s2 = rp2.next
///                     # if s2 is a terminal
///                     if s2 not in self.lr0_rules_by_origin:
///                         dr.add(s2)
///                     if s2 in self.NULLABLE:
///                         r.add((next_state, s2))
///
///     def compute_includes_lookback(self):
///         for nt in self.nonterminal_transitions:
///             state, nonterminal = nt
///             includes = []
///             lookback = self.lookback[nt]
///             for rp in state.closure:
///                 if rp.rule.origin != nonterminal:
///                     continue
///                 # traverse the states for rp(.rule)
///                 state2 = state
///                 for i in range(rp.index, len(rp.rule.expansion)):
///                     s = rp.rule.expansion[i]
///                     nt2 = (state2, s)
///                     state2 = state2.transitions[s]
///                     if nt2 not in self.reads:
///                         continue
///                     for j in range(i + 1, len(rp.rule.expansion)):
///                         if not rp.rule.expansion[j] in self.NULLABLE:
///                             break
///                     else:
///                         includes.append(nt2)
///                 # state2 is at the final state for rp.rule
///                 if rp.index == 0:
///                     for rp2 in state2.closure:
///                         if (rp2.rule == rp.rule) and rp2.is_satisfied:
///                             lookback.add((state2, rp2.rule))
///             for nt2 in includes:
///                 self.includes[nt2].add(nt)
///
///     def compute_lookaheads(self):
///         read_sets = digraph(self.nonterminal_transitions, self.reads, self.directly_reads)
///         follow_sets = digraph(self.nonterminal_transitions, self.includes, read_sets)
///
///         for nt, lookbacks in self.lookback.items():
///             for state, rule in lookbacks:
///                 for s in follow_sets[nt]:
///                     state.lookaheads[s].add(rule)
///
///     def compute_lalr1_states(self):
///         m = {}
///         reduce_reduce = []
///         for state in self.lr0_states:
///             actions = {}
///             for la, next_state in state.transitions.items():
///                 actions[la] = (Shift, next_state.closure)
///             for la, rules in state.lookaheads.items():
///                 if len(rules) > 1:
///                     # Try to resolve conflict based on priority
///                     p = [(r.options.priority or 0, r) for r in rules]
///                     p.sort(key=lambda r: r[0], reverse=True)
///                     best, second_best = p[:2]
///                     if best[0] > second_best[0]:
///                         rules = [best[1]]
///                     else:
///                         reduce_reduce.append((state, la, rules))
///                 if la in actions:
///                     if self.debug:
///                         logger.warning('Shift/Reduce conflict for terminal %s: (resolving as shift)', la.name)
///                         logger.warning(' * %s', list(rules)[0])
///                 else:
///                     actions[la] = (Reduce, list(rules)[0])
///             m[state] = { k.name: v for k, v in actions.items() }
///
///         if reduce_reduce:
///             msgs = []
///             for state, la, rules in reduce_reduce:
///                 msg = 'Reduce/Reduce collision in %s between the following rules: %s' % (la, ''.join([ '\n\t- ' + str(r) for r in rules ]))
///                 if self.debug:
///                     msg += '\n    collision occurred in state: {%s\n    }' % ''.join(['\n\t' + str(x) for x in state.closure])
///                 msgs.append(msg)
///             raise GrammarError('\n\n'.join(msgs))
///
///         states = { k.closure: v for k, v in m.items() }
///
///         # compute end states
///         end_states = {}
///         for state in states:
///             for rp in state:
///                 for start in self.lr0_start_states:
///                     if rp.rule.origin.name == ('$root_' + start) and rp.is_satisfied:
///                         assert(start not in end_states)
///                         end_states[start] = state
///
///         _parse_table = ParseTable(states, { start: state.closure for start, state in self.lr0_start_states.items() }, end_states)
///
///         if self.debug:
///             self.parse_table = _parse_table
///         else:
///             self.parse_table = IntParseTable.from_ParseTable(_parse_table)
///
///     def compute_lalr(self):
///         self.compute_lr0_states()
///         self.compute_reads_relations()
///         self.compute_includes_lookback()
///         self.compute_lookaheads()
///         self.compute_lalr1_states()
/// ```
final class lalr_analysis extends PythonModule {
  lalr_analysis.from(super.pythonModule) : super.from();

  static lalr_analysis import() => PythonFfiDart.instance.importModule(
        "lark.parsers.lalr_analysis",
        lalr_analysis.from,
      );

  /// ## digraph
  ///
  /// ### python source
  /// ```py
  /// def digraph(X, R, G):
  ///     F = {}
  ///     S = []
  ///     N = {}
  ///     for x in X:
  ///         N[x] = 0
  ///     for x in X:
  ///         # this is always true for the first iteration, but N[x] may be updated in traverse below
  ///         if N[x] == 0:
  ///             traverse(x, S, N, X, R, G, F)
  ///     return F
  /// ```
  Object? digraph({
    required Object? X,
    required Object? R,
    required Object? G,
  }) =>
      getFunction("digraph").call(
        <Object?>[
          X,
          R,
          G,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## traverse
  ///
  /// ### python source
  /// ```py
  /// def traverse(x, S, N, X, R, G, F):
  ///     S.append(x)
  ///     d = len(S)
  ///     N[x] = d
  ///     F[x] = G[x]
  ///     for y in R[x]:
  ///         if N[y] == 0:
  ///             traverse(y, S, N, X, R, G, F)
  ///         n_x = N[x]
  ///         assert(n_x > 0)
  ///         n_y = N[y]
  ///         assert(n_y != 0)
  ///         if (n_y > 0) and (n_y < n_x):
  ///             N[x] = n_y
  ///         F[x].update(F[y])
  ///     if N[x] == d:
  ///         f_x = F[x]
  ///         while True:
  ///             z = S.pop()
  ///             N[z] = -1
  ///             F[z] = f_x
  ///             if z == x:
  ///                 break
  /// ```
  Object? traverse({
    required Object? x,
    required Object? S,
    required Object? N,
    required Object? X,
    required Object? R,
    required Object? G,
    required Object? F,
  }) =>
      getFunction("traverse").call(
        <Object?>[
          x,
          S,
          N,
          X,
          R,
          G,
          F,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## Reduce (getter)
  Object? get Reduce => getAttribute("Reduce");

  /// ## Reduce (setter)
  set Reduce(Object? Reduce) => setAttribute("Reduce", Reduce);

  /// ## Shift (getter)
  Object? get Shift => getAttribute("Shift");

  /// ## Shift (setter)
  set Shift(Object? Shift) => setAttribute("Shift", Shift);
}

/// ## lalr_interactive_parser
///
/// ### python source
/// ```py
/// # This module provides a LALR interactive parser, which is used for debugging and error handling
///
/// from typing import Iterator, List
/// from copy import copy
/// import warnings
///
/// from lark.exceptions import UnexpectedToken
/// from lark.lexer import Token, LexerThread
///
///
/// class InteractiveParser:
///     """InteractiveParser gives you advanced control over parsing and error handling when parsing with LALR.
///
///     For a simpler interface, see the ``on_error`` argument to ``Lark.parse()``.
///     """
///     def __init__(self, parser, parser_state, lexer_thread: LexerThread):
///         self.parser = parser
///         self.parser_state = parser_state
///         self.lexer_thread = lexer_thread
///         self.result = None
///
///     @property
///     def lexer_state(self) -> LexerThread:
///         warnings.warn("lexer_state will be removed in subsequent releases. Use lexer_thread instead.", DeprecationWarning)
///         return self.lexer_thread
///
///     def feed_token(self, token: Token):
///         """Feed the parser with a token, and advance it to the next state, as if it received it from the lexer.
///
///         Note that ``token`` has to be an instance of ``Token``.
///         """
///         return self.parser_state.feed_token(token, token.type == '$END')
///
///     def iter_parse(self) -> Iterator[Token]:
///         """Step through the different stages of the parse, by reading tokens from the lexer
///         and feeding them to the parser, one per iteration.
///
///         Returns an iterator of the tokens it encounters.
///
///         When the parse is over, the resulting tree can be found in ``InteractiveParser.result``.
///         """
///         for token in self.lexer_thread.lex(self.parser_state):
///             yield token
///             self.result = self.feed_token(token)
///
///     def exhaust_lexer(self) -> List[Token]:
///         """Try to feed the rest of the lexer state into the interactive parser.
///
///         Note that this modifies the instance in place and does not feed an '$END' Token
///         """
///         return list(self.iter_parse())
///
///
///     def feed_eof(self, last_token=None):
///         """Feed a '$END' Token. Borrows from 'last_token' if given."""
///         eof = Token.new_borrow_pos('$END', '', last_token) if last_token is not None else self.lexer_thread._Token('$END', '', 0, 1, 1)
///         return self.feed_token(eof)
///
///
///     def __copy__(self):
///         """Create a new interactive parser with a separate state.
///
///         Calls to feed_token() won't affect the old instance, and vice-versa.
///         """
///         return type(self)(
///             self.parser,
///             copy(self.parser_state),
///             copy(self.lexer_thread),
///         )
///
///     def copy(self):
///         return copy(self)
///
///     def __eq__(self, other):
///         if not isinstance(other, InteractiveParser):
///             return False
///
///         return self.parser_state == other.parser_state and self.lexer_thread == other.lexer_thread
///
///     def as_immutable(self):
///         """Convert to an ``ImmutableInteractiveParser``."""
///         p = copy(self)
///         return ImmutableInteractiveParser(p.parser, p.parser_state, p.lexer_thread)
///
///     def pretty(self):
///         """Print the output of ``choices()`` in a way that's easier to read."""
///         out = ["Parser choices:"]
///         for k, v in self.choices().items():
///             out.append('\t- %s -> %r' % (k, v))
///         out.append('stack size: %s' % len(self.parser_state.state_stack))
///         return '\n'.join(out)
///
///     def choices(self):
///         """Returns a dictionary of token types, matched to their action in the parser.
///
///         Only returns token types that are accepted by the current state.
///
///         Updated by ``feed_token()``.
///         """
///         return self.parser_state.parse_conf.parse_table.states[self.parser_state.position]
///
///     def accepts(self):
///         """Returns the set of possible tokens that will advance the parser into a new valid state."""
///         accepts = set()
///         for t in self.choices():
///             if t.isupper(): # is terminal?
///                 new_cursor = copy(self)
///                 try:
///                     new_cursor.feed_token(self.lexer_thread._Token(t, ''))
///                 except UnexpectedToken:
///                     pass
///                 else:
///                     accepts.add(t)
///         return accepts
///
///     def resume_parse(self):
///         """Resume automated parsing from the current state.
///         """
///         return self.parser.parse_from_state(self.parser_state, last_token=self.lexer_state.state.last_token)
///
///
///
/// class ImmutableInteractiveParser(InteractiveParser):
///     """Same as ``InteractiveParser``, but operations create a new instance instead
///     of changing it in-place.
///     """
///
///     result = None
///
///     def __hash__(self):
///         return hash((self.parser_state, self.lexer_thread))
///
///     def feed_token(self, token):
///         c = copy(self)
///         c.result = InteractiveParser.feed_token(c, token)
///         return c
///
///     def exhaust_lexer(self):
///         """Try to feed the rest of the lexer state into the parser.
///
///         Note that this returns a new ImmutableInteractiveParser and does not feed an '$END' Token"""
///         cursor = self.as_mutable()
///         cursor.exhaust_lexer()
///         return cursor.as_immutable()
///
///     def as_mutable(self):
///         """Convert to an ``InteractiveParser``."""
///         p = copy(self)
///         return InteractiveParser(p.parser, p.parser_state, p.lexer_thread)
/// ```
final class lalr_interactive_parser extends PythonModule {
  lalr_interactive_parser.from(super.pythonModule) : super.from();

  static lalr_interactive_parser import() =>
      PythonFfiDart.instance.importModule(
        "lark.parsers.lalr_interactive_parser",
        lalr_interactive_parser.from,
      );
}

/// ## lalr_parser
///
/// ### python docstring
///
/// This module implements a LALR(1) Parser
///
/// ### python source
/// ```py
/// """This module implements a LALR(1) Parser
/// """
/// # Author: Erez Shinan (2017)
/// # Email : erezshin@gmail.com
/// from copy import deepcopy, copy
/// from typing import Dict, Any
/// from ..lexer import Token
/// from ..utils import Serialize
///
/// from .lalr_analysis import LALR_Analyzer, Shift, Reduce, IntParseTable
/// from .lalr_interactive_parser import InteractiveParser
/// from lark.exceptions import UnexpectedCharacters, UnexpectedInput, UnexpectedToken
///
/// ###{standalone
///
/// class LALR_Parser(Serialize):
///     def __init__(self, parser_conf, debug=False):
///         analysis = LALR_Analyzer(parser_conf, debug=debug)
///         analysis.compute_lalr()
///         callbacks = parser_conf.callbacks
///
///         self._parse_table = analysis.parse_table
///         self.parser_conf = parser_conf
///         self.parser = _Parser(analysis.parse_table, callbacks, debug)
///
///     @classmethod
///     def deserialize(cls, data, memo, callbacks, debug=False):
///         inst = cls.__new__(cls)
///         inst._parse_table = IntParseTable.deserialize(data, memo)
///         inst.parser = _Parser(inst._parse_table, callbacks, debug)
///         return inst
///
///     def serialize(self, memo: Any = None) -> Dict[str, Any]:
///         return self._parse_table.serialize(memo)
///
///     def parse_interactive(self, lexer, start):
///         return self.parser.parse(lexer, start, start_interactive=True)
///
///     def parse(self, lexer, start, on_error=None):
///         try:
///             return self.parser.parse(lexer, start)
///         except UnexpectedInput as e:
///             if on_error is None:
///                 raise
///
///             while True:
///                 if isinstance(e, UnexpectedCharacters):
///                     s = e.interactive_parser.lexer_thread.state
///                     p = s.line_ctr.char_pos
///
///                 if not on_error(e):
///                     raise e
///
///                 if isinstance(e, UnexpectedCharacters):
///                     # If user didn't change the character position, then we should
///                     if p == s.line_ctr.char_pos:
///                         s.line_ctr.feed(s.text[p:p+1])
///
///                 try:
///                     return e.interactive_parser.resume_parse()
///                 except UnexpectedToken as e2:
///                     if (isinstance(e, UnexpectedToken)
///                         and e.token.type == e2.token.type == '$END'
///                         and e.interactive_parser == e2.interactive_parser):
///                         # Prevent infinite loop
///                         raise e2
///                     e = e2
///                 except UnexpectedCharacters as e2:
///                     e = e2
///
///
/// class ParseConf:
///     __slots__ = 'parse_table', 'callbacks', 'start', 'start_state', 'end_state', 'states'
///
///     def __init__(self, parse_table, callbacks, start):
///         self.parse_table = parse_table
///
///         self.start_state = self.parse_table.start_states[start]
///         self.end_state = self.parse_table.end_states[start]
///         self.states = self.parse_table.states
///
///         self.callbacks = callbacks
///         self.start = start
///
///
/// class ParserState:
///     __slots__ = 'parse_conf', 'lexer', 'state_stack', 'value_stack'
///
///     def __init__(self, parse_conf, lexer, state_stack=None, value_stack=None):
///         self.parse_conf = parse_conf
///         self.lexer = lexer
///         self.state_stack = state_stack or [self.parse_conf.start_state]
///         self.value_stack = value_stack or []
///
///     @property
///     def position(self):
///         return self.state_stack[-1]
///
///     # Necessary for match_examples() to work
///     def __eq__(self, other):
///         if not isinstance(other, ParserState):
///             return NotImplemented
///         return len(self.state_stack) == len(other.state_stack) and self.position == other.position
///
///     def __copy__(self):
///         return type(self)(
///             self.parse_conf,
///             self.lexer, # XXX copy
///             copy(self.state_stack),
///             deepcopy(self.value_stack),
///         )
///
///     def copy(self):
///         return copy(self)
///
///     def feed_token(self, token, is_end=False):
///         state_stack = self.state_stack
///         value_stack = self.value_stack
///         states = self.parse_conf.states
///         end_state = self.parse_conf.end_state
///         callbacks = self.parse_conf.callbacks
///
///         while True:
///             state = state_stack[-1]
///             try:
///                 action, arg = states[state][token.type]
///             except KeyError:
///                 expected = {s for s in states[state].keys() if s.isupper()}
///                 raise UnexpectedToken(token, expected, state=self, interactive_parser=None)
///
///             assert arg != end_state
///
///             if action is Shift:
///                 # shift once and return
///                 assert not is_end
///                 state_stack.append(arg)
///                 value_stack.append(token if token.type not in callbacks else callbacks[token.type](token))
///                 return
///             else:
///                 # reduce+shift as many times as necessary
///                 rule = arg
///                 size = len(rule.expansion)
///                 if size:
///                     s = value_stack[-size:]
///                     del state_stack[-size:]
///                     del value_stack[-size:]
///                 else:
///                     s = []
///
///                 value = callbacks[rule](s)
///
///                 _action, new_state = states[state_stack[-1]][rule.origin.name]
///                 assert _action is Shift
///                 state_stack.append(new_state)
///                 value_stack.append(value)
///
///                 if is_end and state_stack[-1] == end_state:
///                     return value_stack[-1]
///
/// class _Parser:
///     def __init__(self, parse_table, callbacks, debug=False):
///         self.parse_table = parse_table
///         self.callbacks = callbacks
///         self.debug = debug
///
///     def parse(self, lexer, start, value_stack=None, state_stack=None, start_interactive=False):
///         parse_conf = ParseConf(self.parse_table, self.callbacks, start)
///         parser_state = ParserState(parse_conf, lexer, state_stack, value_stack)
///         if start_interactive:
///             return InteractiveParser(self, parser_state, parser_state.lexer)
///         return self.parse_from_state(parser_state)
///
///
///     def parse_from_state(self, state, last_token=None):
///         """Run the main LALR parser loop
///
///         Parameters:
///             state (ParseState) - the initial state. Changed in-place.
///             last_token (optional, Token) - Used only for line information in case of an empty lexer.
///         """
///         try:
///             token = last_token
///             for token in state.lexer.lex(state):
///                 state.feed_token(token)
///
///             end_token = Token.new_borrow_pos('$END', '', token) if token else Token('$END', '', 0, 1, 1)
///             return state.feed_token(end_token, True)
///         except UnexpectedInput as e:
///             try:
///                 e.interactive_parser = InteractiveParser(self, state, state.lexer)
///             except NameError:
///                 pass
///             raise e
///         except Exception as e:
///             if self.debug:
///                 print("")
///                 print("STATE STACK DUMP")
///                 print("----------------")
///                 for i, s in enumerate(state.state_stack):
///                     print('%d)' % i , s)
///                 print("")
///
///             raise
/// ###}
/// ```
final class lalr_parser extends PythonModule {
  lalr_parser.from(super.pythonModule) : super.from();

  static lalr_parser import() => PythonFfiDart.instance.importModule(
        "lark.parsers.lalr_parser",
        lalr_parser.from,
      );
}

/// ## tree
///
/// ### python source
/// ```py
/// import sys
/// from copy import deepcopy
///
/// from typing import List, Callable, Iterator, Union, Optional, Generic, TypeVar, Any, TYPE_CHECKING
///
/// if TYPE_CHECKING:
///     from .lexer import TerminalDef, Token
///     import rich
///     if sys.version_info >= (3, 8):
///         from typing import Literal
///     else:
///         from typing_extensions import Literal
///
/// ###{standalone
/// from collections import OrderedDict
///
/// class Meta:
///
///     empty: bool
///     line: int
///     column: int
///     start_pos: int
///     end_line: int
///     end_column: int
///     end_pos: int
///     orig_expansion: 'List[TerminalDef]'
///     match_tree: bool
///
///     def __init__(self):
///         self.empty = True
///
///
/// _Leaf_T = TypeVar("_Leaf_T")
/// Branch = Union[_Leaf_T, 'Tree[_Leaf_T]']
///
///
/// class Tree(Generic[_Leaf_T]):
///     """The main tree class.
///
///     Creates a new tree, and stores "data" and "children" in attributes of the same name.
///     Trees can be hashed and compared.
///
///     Parameters:
///         data: The name of the rule or alias
///         children: List of matched sub-rules and terminals
///         meta: Line & Column numbers (if ``propagate_positions`` is enabled).
///             meta attributes: line, column, start_pos, end_line, end_column, end_pos
///     """
///
///     data: str
///     children: 'List[Branch[_Leaf_T]]'
///
///     def __init__(self, data: str, children: 'List[Branch[_Leaf_T]]', meta: Optional[Meta]=None) -> None:
///         self.data = data
///         self.children = children
///         self._meta = meta
///
///     @property
///     def meta(self) -> Meta:
///         if self._meta is None:
///             self._meta = Meta()
///         return self._meta
///
///     def __repr__(self):
///         return 'Tree(%r, %r)' % (self.data, self.children)
///
///     def _pretty_label(self):
///         return self.data
///
///     def _pretty(self, level, indent_str):
///         yield f'{indent_str*level}{self._pretty_label()}'
///         if len(self.children) == 1 and not isinstance(self.children[0], Tree):
///             yield f'\t{self.children[0]}\n'
///         else:
///             yield '\n'
///             for n in self.children:
///                 if isinstance(n, Tree):
///                     yield from n._pretty(level+1, indent_str)
///                 else:
///                     yield f'{indent_str*(level+1)}{n}\n'
///
///     def pretty(self, indent_str: str='  ') -> str:
///         """Returns an indented string representation of the tree.
///
///         Great for debugging.
///         """
///         return ''.join(self._pretty(0, indent_str))
///
///     def __rich__(self, parent:'rich.tree.Tree'=None) -> 'rich.tree.Tree':
///         """Returns a tree widget for the 'rich' library.
///
///         Example:
///             ::
///                 from rich import print
///                 from lark import Tree
///
///                 tree = Tree('root', ['node1', 'node2'])
///                 print(tree)
///         """
///         return self._rich(parent)
///
///     def _rich(self, parent):
///         if parent:
///             tree = parent.add(f'[bold]{self.data}[/bold]')
///         else:
///             import rich.tree
///             tree = rich.tree.Tree(self.data)
///
///         for c in self.children:
///             if isinstance(c, Tree):
///                 c._rich(tree)
///             else:
///                 tree.add(f'[green]{c}[/green]')
///
///         return tree
///
///     def __eq__(self, other):
///         try:
///             return self.data == other.data and self.children == other.children
///         except AttributeError:
///             return False
///
///     def __ne__(self, other):
///         return not (self == other)
///
///     def __hash__(self) -> int:
///         return hash((self.data, tuple(self.children)))
///
///     def iter_subtrees(self) -> 'Iterator[Tree[_Leaf_T]]':
///         """Depth-first iteration.
///
///         Iterates over all the subtrees, never returning to the same node twice (Lark's parse-tree is actually a DAG).
///         """
///         queue = [self]
///         subtrees = OrderedDict()
///         for subtree in queue:
///             subtrees[id(subtree)] = subtree
///             # Reason for type ignore https://github.com/python/mypy/issues/10999
///             queue += [c for c in reversed(subtree.children)  # type: ignore[misc]
///                       if isinstance(c, Tree) and id(c) not in subtrees]
///
///         del queue
///         return reversed(list(subtrees.values()))
///
///     def iter_subtrees_topdown(self):
///         """Breadth-first iteration.
///
///         Iterates over all the subtrees, return nodes in order like pretty() does.
///         """
///         stack = [self]
///         stack_append = stack.append
///         stack_pop = stack.pop
///         while stack:
///             node = stack_pop()
///             if not isinstance(node, Tree):
///                 continue
///             yield node
///             for child in reversed(node.children):
///                 stack_append(child)
///
///     def find_pred(self, pred: 'Callable[[Tree[_Leaf_T]], bool]') -> 'Iterator[Tree[_Leaf_T]]':
///         """Returns all nodes of the tree that evaluate pred(node) as true."""
///         return filter(pred, self.iter_subtrees())
///
///     def find_data(self, data: str) -> 'Iterator[Tree[_Leaf_T]]':
///         """Returns all nodes of the tree whose data equals the given data."""
///         return self.find_pred(lambda t: t.data == data)
///
/// ###}
///
///     def expand_kids_by_data(self, *data_values):
///         """Expand (inline) children with any of the given data values. Returns True if anything changed"""
///         changed = False
///         for i in range(len(self.children)-1, -1, -1):
///             child = self.children[i]
///             if isinstance(child, Tree) and child.data in data_values:
///                 self.children[i:i+1] = child.children
///                 changed = True
///         return changed
///
///
///     def scan_values(self, pred: 'Callable[[Branch[_Leaf_T]], bool]') -> Iterator[_Leaf_T]:
///         """Return all values in the tree that evaluate pred(value) as true.
///
///         This can be used to find all the tokens in the tree.
///
///         Example:
///             >>> all_tokens = tree.scan_values(lambda v: isinstance(v, Token))
///         """
///         for c in self.children:
///             if isinstance(c, Tree):
///                 for t in c.scan_values(pred):
///                     yield t
///             else:
///                 if pred(c):
///                     yield c
///
///     def __deepcopy__(self, memo):
///         return type(self)(self.data, deepcopy(self.children, memo), meta=self._meta)
///
///     def copy(self) -> 'Tree[_Leaf_T]':
///         return type(self)(self.data, self.children)
///
///     def set(self, data: str, children: 'List[Branch[_Leaf_T]]') -> None:
///         self.data = data
///         self.children = children
///
///
/// ParseTree = Tree['Token']
///
///
/// class SlottedTree(Tree):
///     __slots__ = 'data', 'children', 'rule', '_meta'
///
///
/// def pydot__tree_to_png(tree: Tree, filename: str, rankdir: 'Literal["TB", "LR", "BT", "RL"]'="LR", **kwargs) -> None:
///     graph = pydot__tree_to_graph(tree, rankdir, **kwargs)
///     graph.write_png(filename)
///
///
/// def pydot__tree_to_dot(tree: Tree, filename, rankdir="LR", **kwargs):
///     graph = pydot__tree_to_graph(tree, rankdir, **kwargs)
///     graph.write(filename)
///
///
/// def pydot__tree_to_graph(tree: Tree, rankdir="LR", **kwargs):
///     """Creates a colorful image that represents the tree (data+children, without meta)
///
///     Possible values for `rankdir` are "TB", "LR", "BT", "RL", corresponding to
///     directed graphs drawn from top to bottom, from left to right, from bottom to
///     top, and from right to left, respectively.
///
///     `kwargs` can be any graph attribute (e. g. `dpi=200`). For a list of
///     possible attributes, see https://www.graphviz.org/doc/info/attrs.html.
///     """
///
///     import pydot  # type: ignore[import]
///     graph = pydot.Dot(graph_type='digraph', rankdir=rankdir, **kwargs)
///
///     i = [0]
///
///     def new_leaf(leaf):
///         node = pydot.Node(i[0], label=repr(leaf))
///         i[0] += 1
///         graph.add_node(node)
///         return node
///
///     def _to_pydot(subtree):
///         color = hash(subtree.data) & 0xffffff
///         color |= 0x808080
///
///         subnodes = [_to_pydot(child) if isinstance(child, Tree) else new_leaf(child)
///                     for child in subtree.children]
///         node = pydot.Node(i[0], style="filled", fillcolor="#%x" % color, label=subtree.data)
///         i[0] += 1
///         graph.add_node(node)
///
///         for subnode in subnodes:
///             graph.add_edge(pydot.Edge(node, subnode))
///
///         return node
///
///     _to_pydot(tree)
///     return graph
/// ```
final class tree extends PythonModule {
  tree.from(super.pythonModule) : super.from();

  static tree import() => PythonFfiDart.instance.importModule(
        "lark.tree",
        tree.from,
      );

  /// ## pydot__tree_to_dot
  ///
  /// ### python source
  /// ```py
  /// def pydot__tree_to_dot(tree: Tree, filename, rankdir="LR", **kwargs):
  ///     graph = pydot__tree_to_graph(tree, rankdir, **kwargs)
  ///     graph.write(filename)
  /// ```
  Object? pydot__tree_to_dot({
    required Object? tree,
    required Object? filename,
    Object? rankdir = "LR",
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("pydot__tree_to_dot").call(
        <Object?>[
          tree,
          filename,
          rankdir,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## pydot__tree_to_graph
  ///
  /// ### python docstring
  ///
  /// Creates a colorful image that represents the tree (data+children, without meta)
  ///
  /// Possible values for `rankdir` are "TB", "LR", "BT", "RL", corresponding to
  /// directed graphs drawn from top to bottom, from left to right, from bottom to
  /// top, and from right to left, respectively.
  ///
  /// `kwargs` can be any graph attribute (e. g. `dpi=200`). For a list of
  /// possible attributes, see https://www.graphviz.org/doc/info/attrs.html.
  ///
  /// ### python source
  /// ```py
  /// def pydot__tree_to_graph(tree: Tree, rankdir="LR", **kwargs):
  ///     """Creates a colorful image that represents the tree (data+children, without meta)
  ///
  ///     Possible values for `rankdir` are "TB", "LR", "BT", "RL", corresponding to
  ///     directed graphs drawn from top to bottom, from left to right, from bottom to
  ///     top, and from right to left, respectively.
  ///
  ///     `kwargs` can be any graph attribute (e. g. `dpi=200`). For a list of
  ///     possible attributes, see https://www.graphviz.org/doc/info/attrs.html.
  ///     """
  ///
  ///     import pydot  # type: ignore[import]
  ///     graph = pydot.Dot(graph_type='digraph', rankdir=rankdir, **kwargs)
  ///
  ///     i = [0]
  ///
  ///     def new_leaf(leaf):
  ///         node = pydot.Node(i[0], label=repr(leaf))
  ///         i[0] += 1
  ///         graph.add_node(node)
  ///         return node
  ///
  ///     def _to_pydot(subtree):
  ///         color = hash(subtree.data) & 0xffffff
  ///         color |= 0x808080
  ///
  ///         subnodes = [_to_pydot(child) if isinstance(child, Tree) else new_leaf(child)
  ///                     for child in subtree.children]
  ///         node = pydot.Node(i[0], style="filled", fillcolor="#%x" % color, label=subtree.data)
  ///         i[0] += 1
  ///         graph.add_node(node)
  ///
  ///         for subnode in subnodes:
  ///             graph.add_edge(pydot.Edge(node, subnode))
  ///
  ///         return node
  ///
  ///     _to_pydot(tree)
  ///     return graph
  /// ```
  Object? pydot__tree_to_graph({
    required Object? tree,
    Object? rankdir = "LR",
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("pydot__tree_to_graph").call(
        <Object?>[
          tree,
          rankdir,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## pydot__tree_to_png
  ///
  /// ### python source
  /// ```py
  /// def pydot__tree_to_png(tree: Tree, filename: str, rankdir: 'Literal["TB", "LR", "BT", "RL"]'="LR", **kwargs) -> None:
  ///     graph = pydot__tree_to_graph(tree, rankdir, **kwargs)
  ///     graph.write_png(filename)
  /// ```
  Object? pydot__tree_to_png({
    required Object? tree,
    required Object? filename,
    Object? rankdir = "LR",
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("pydot__tree_to_png").call(
        <Object?>[
          tree,
          filename,
          rankdir,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## ParseTree (getter)
  Object? get ParseTree => getAttribute("ParseTree");

  /// ## ParseTree (setter)
  set ParseTree(Object? ParseTree) => setAttribute("ParseTree", ParseTree);

  /// ## TYPE_CHECKING (getter)
  Object? get TYPE_CHECKING => getAttribute("TYPE_CHECKING");

  /// ## TYPE_CHECKING (setter)
  set TYPE_CHECKING(Object? TYPE_CHECKING) =>
      setAttribute("TYPE_CHECKING", TYPE_CHECKING);
}

/// ## utils
///
/// ### python source
/// ```py
/// import unicodedata
/// import os
/// from functools import reduce
/// from collections import deque
/// from typing import Callable, Iterator, List, Optional, Tuple, Type, TypeVar, Union, Dict, Any, Sequence
///
/// ###{standalone
/// import sys, re
/// import logging
///
/// logger: logging.Logger = logging.getLogger("lark")
/// logger.addHandler(logging.StreamHandler())
/// # Set to highest level, since we have some warnings amongst the code
/// # By default, we should not output any log messages
/// logger.setLevel(logging.CRITICAL)
///
///
/// NO_VALUE = object()
///
/// T = TypeVar("T")
///
///
/// def classify(seq: Sequence, key: Optional[Callable] = None, value: Optional[Callable] = None) -> Dict:
///     d: Dict[Any, Any] = {}
///     for item in seq:
///         k = key(item) if (key is not None) else item
///         v = value(item) if (value is not None) else item
///         if k in d:
///             d[k].append(v)
///         else:
///             d[k] = [v]
///     return d
///
///
/// def _deserialize(data: Any, namespace: Dict[str, Any], memo: Dict) -> Any:
///     if isinstance(data, dict):
///         if '__type__' in data:  # Object
///             class_ = namespace[data['__type__']]
///             return class_.deserialize(data, memo)
///         elif '@' in data:
///             return memo[data['@']]
///         return {key:_deserialize(value, namespace, memo) for key, value in data.items()}
///     elif isinstance(data, list):
///         return [_deserialize(value, namespace, memo) for value in data]
///     return data
///
///
/// _T = TypeVar("_T", bound="Serialize")
///
/// class Serialize:
///     """Safe-ish serialization interface that doesn't rely on Pickle
///
///     Attributes:
///         __serialize_fields__ (List[str]): Fields (aka attributes) to serialize.
///         __serialize_namespace__ (list): List of classes that deserialization is allowed to instantiate.
///                                         Should include all field types that aren't builtin types.
///     """
///
///     def memo_serialize(self, types_to_memoize: List) -> Any:
///         memo = SerializeMemoizer(types_to_memoize)
///         return self.serialize(memo), memo.serialize()
///
///     def serialize(self, memo = None) -> Dict[str, Any]:
///         if memo and memo.in_types(self):
///             return {'@': memo.memoized.get(self)}
///
///         fields = getattr(self, '__serialize_fields__')
///         res = {f: _serialize(getattr(self, f), memo) for f in fields}
///         res['__type__'] = type(self).__name__
///         if hasattr(self, '_serialize'):
///             self._serialize(res, memo)  # type: ignore[attr-defined]
///         return res
///
///     @classmethod
///     def deserialize(cls: Type[_T], data: Dict[str, Any], memo: Dict[int, Any]) -> _T:
///         namespace = getattr(cls, '__serialize_namespace__', [])
///         namespace = {c.__name__:c for c in namespace}
///
///         fields = getattr(cls, '__serialize_fields__')
///
///         if '@' in data:
///             return memo[data['@']]
///
///         inst = cls.__new__(cls)
///         for f in fields:
///             try:
///                 setattr(inst, f, _deserialize(data[f], namespace, memo))
///             except KeyError as e:
///                 raise KeyError("Cannot find key for class", cls, e)
///
///         if hasattr(inst, '_deserialize'):
///             inst._deserialize()  # type: ignore[attr-defined]
///
///         return inst
///
///
/// class SerializeMemoizer(Serialize):
///     "A version of serialize that memoizes objects to reduce space"
///
///     __serialize_fields__ = 'memoized',
///
///     def __init__(self, types_to_memoize: List) -> None:
///         self.types_to_memoize = tuple(types_to_memoize)
///         self.memoized = Enumerator()
///
///     def in_types(self, value: Serialize) -> bool:
///         return isinstance(value, self.types_to_memoize)
///
///     def serialize(self) -> Dict[int, Any]:  # type: ignore[override]
///         return _serialize(self.memoized.reversed(), None)
///
///     @classmethod
///     def deserialize(cls, data: Dict[int, Any], namespace: Dict[str, Any], memo: Dict[Any, Any]) -> Dict[int, Any]:  # type: ignore[override]
///         return _deserialize(data, namespace, memo)
///
///
/// try:
///     import regex
///     _has_regex = True
/// except ImportError:
///     _has_regex = False
///
/// if sys.version_info >= (3, 11):
///     import re._parser as sre_parse
///     import re._constants as sre_constants
/// else:
///     import sre_parse
///     import sre_constants
///
/// categ_pattern = re.compile(r'\\p{[A-Za-z_]+}')
///
/// def get_regexp_width(expr: str) -> Union[Tuple[int, int], List[int]]:
///     if _has_regex:
///         # Since `sre_parse` cannot deal with Unicode categories of the form `\p{Mn}`, we replace these with
///         # a simple letter, which makes no difference as we are only trying to get the possible lengths of the regex
///         # match here below.
///         regexp_final = re.sub(categ_pattern, 'A', expr)
///     else:
///         if re.search(categ_pattern, expr):
///             raise ImportError('`regex` module must be installed in order to use Unicode categories.', expr)
///         regexp_final = expr
///     try:
///         # Fixed in next version (past 0.960) of typeshed
///         return [int(x) for x in sre_parse.parse(regexp_final).getwidth()]   # type: ignore[attr-defined]
///     except sre_constants.error:
///         if not _has_regex:
///             raise ValueError(expr)
///         else:
///             # sre_parse does not support the new features in regex. To not completely fail in that case,
///             # we manually test for the most important info (whether the empty string is matched)
///             c = regex.compile(regexp_final)
///             if c.match('') is None:
///                 # MAXREPEAT is a none pickable subclass of int, therefore needs to be converted to enable caching
///                 return 1, int(sre_constants.MAXREPEAT)
///             else:
///                 return 0, int(sre_constants.MAXREPEAT)
///
/// ###}
///
///
/// _ID_START =    'Lu', 'Ll', 'Lt', 'Lm', 'Lo', 'Mn', 'Mc', 'Pc'
/// _ID_CONTINUE = _ID_START + ('Nd', 'Nl',)
///
/// def _test_unicode_category(s: str, categories: Sequence[str]) -> bool:
///     if len(s) != 1:
///         return all(_test_unicode_category(char, categories) for char in s)
///     return s == '_' or unicodedata.category(s) in categories
///
/// def is_id_continue(s: str) -> bool:
///     """
///     Checks if all characters in `s` are alphanumeric characters (Unicode standard, so diacritics, indian vowels, non-latin
///     numbers, etc. all pass). Synonymous with a Python `ID_CONTINUE` identifier. See PEP 3131 for details.
///     """
///     return _test_unicode_category(s, _ID_CONTINUE)
///
/// def is_id_start(s: str) -> bool:
///     """
///     Checks if all characters in `s` are alphabetic characters (Unicode standard, so diacritics, indian vowels, non-latin
///     numbers, etc. all pass). Synonymous with a Python `ID_START` identifier. See PEP 3131 for details.
///     """
///     return _test_unicode_category(s, _ID_START)
///
///
/// def dedup_list(l: List[T]) -> List[T]:
///     """Given a list (l) will removing duplicates from the list,
///        preserving the original order of the list. Assumes that
///        the list entries are hashable."""
///     dedup = set()
///     # This returns None, but that's expected
///     return [x for x in l if not (x in dedup or dedup.add(x))]  # type: ignore[func-returns-value]
///     # 2x faster (ordered in PyPy and CPython 3.6+, gaurenteed to be ordered in Python 3.7+)
///     # return list(dict.fromkeys(l))
///
///
/// class Enumerator(Serialize):
///     def __init__(self) -> None:
///         self.enums: Dict[Any, int] = {}
///
///     def get(self, item) -> int:
///         if item not in self.enums:
///             self.enums[item] = len(self.enums)
///         return self.enums[item]
///
///     def __len__(self):
///         return len(self.enums)
///
///     def reversed(self) -> Dict[int, Any]:
///         r = {v: k for k, v in self.enums.items()}
///         assert len(r) == len(self.enums)
///         return r
///
///
///
/// def combine_alternatives(lists):
///     """
///     Accepts a list of alternatives, and enumerates all their possible concatinations.
///
///     Examples:
///         >>> combine_alternatives([range(2), [4,5]])
///         [[0, 4], [0, 5], [1, 4], [1, 5]]
///
///         >>> combine_alternatives(["abc", "xy", '$'])
///         [['a', 'x', '$'], ['a', 'y', '$'], ['b', 'x', '$'], ['b', 'y', '$'], ['c', 'x', '$'], ['c', 'y', '$']]
///
///         >>> combine_alternatives([])
///         [[]]
///     """
///     if not lists:
///         return [[]]
///     assert all(l for l in lists), lists
///     init = [[x] for x in lists[0]]
///     return reduce(lambda a,b: [i+[j] for i in a for j in b], lists[1:], init)
///
///
/// try:
///     import atomicwrites
///     _has_atomicwrites = True
/// except ImportError:
///     _has_atomicwrites = False
///
/// class FS:
///     exists = staticmethod(os.path.exists)
///
///     @staticmethod
///     def open(name, mode="r", **kwargs):
///         if _has_atomicwrites and "w" in mode:
///             return atomicwrites.atomic_write(name, mode=mode, overwrite=True, **kwargs)
///         else:
///             return open(name, mode, **kwargs)
///
///
///
/// def isascii(s: str) -> bool:
///     """ str.isascii only exists in python3.7+ """
///     if sys.version_info >= (3, 7):
///         return s.isascii()
///     else:
///         try:
///             s.encode('ascii')
///             return True
///         except (UnicodeDecodeError, UnicodeEncodeError):
///             return False
///
///
/// class fzset(frozenset):
///     def __repr__(self):
///         return '{%s}' % ', '.join(map(repr, self))
///
///
/// def classify_bool(seq: Sequence, pred: Callable) -> Any:
///     true_elems = []
///     false_elems = []
///
///     for elem in seq:
///         if pred(elem):
///             true_elems.append(elem)
///         else:
///             false_elems.append(elem)
///
///     return true_elems, false_elems
///
///
/// def bfs(initial: Sequence, expand: Callable) -> Iterator:
///     open_q = deque(list(initial))
///     visited = set(open_q)
///     while open_q:
///         node = open_q.popleft()
///         yield node
///         for next_node in expand(node):
///             if next_node not in visited:
///                 visited.add(next_node)
///                 open_q.append(next_node)
///
/// def bfs_all_unique(initial, expand):
///     "bfs, but doesn't keep track of visited (aka seen), because there can be no repetitions"
///     open_q = deque(list(initial))
///     while open_q:
///         node = open_q.popleft()
///         yield node
///         open_q += expand(node)
///
///
/// def _serialize(value: Any, memo: Optional[SerializeMemoizer]) -> Any:
///     if isinstance(value, Serialize):
///         return value.serialize(memo)
///     elif isinstance(value, list):
///         return [_serialize(elem, memo) for elem in value]
///     elif isinstance(value, frozenset):
///         return list(value)  # TODO reversible?
///     elif isinstance(value, dict):
///         return {key:_serialize(elem, memo) for key, elem in value.items()}
///     # assert value is None or isinstance(value, (int, float, str, tuple)), value
///     return value
///
///
///
///
/// def small_factors(n: int, max_factor: int) -> List[Tuple[int, int]]:
///     """
///     Splits n up into smaller factors and summands <= max_factor.
///     Returns a list of [(a, b), ...]
///     so that the following code returns n:
///
///     n = 1
///     for a, b in values:
///         n = n * a + b
///
///     Currently, we also keep a + b <= max_factor, but that might change
///     """
///     assert n >= 0
///     assert max_factor > 2
///     if n <= max_factor:
///         return [(n, 0)]
///
///     for a in range(max_factor, 1, -1):
///         r, b = divmod(n, a)
///         if a + b <= max_factor:
///             return small_factors(r, max_factor) + [(a, b)]
///     assert False, "Failed to factorize %s" % n
/// ```
final class utils extends PythonModule {
  utils.from(super.pythonModule) : super.from();

  static utils import() => PythonFfiDart.instance.importModule(
        "lark.utils",
        utils.from,
      );

  /// ## bfs
  ///
  /// ### python source
  /// ```py
  /// def bfs(initial: Sequence, expand: Callable) -> Iterator:
  ///     open_q = deque(list(initial))
  ///     visited = set(open_q)
  ///     while open_q:
  ///         node = open_q.popleft()
  ///         yield node
  ///         for next_node in expand(node):
  ///             if next_node not in visited:
  ///                 visited.add(next_node)
  ///                 open_q.append(next_node)
  /// ```
  Object? bfs({
    required Object? initial,
    required Object? expand,
  }) =>
      getFunction("bfs").call(
        <Object?>[
          initial,
          expand,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## bfs_all_unique
  ///
  /// ### python docstring
  ///
  /// bfs, but doesn't keep track of visited (aka seen), because there can be no repetitions
  ///
  /// ### python source
  /// ```py
  /// def bfs_all_unique(initial, expand):
  ///     "bfs, but doesn't keep track of visited (aka seen), because there can be no repetitions"
  ///     open_q = deque(list(initial))
  ///     while open_q:
  ///         node = open_q.popleft()
  ///         yield node
  ///         open_q += expand(node)
  /// ```
  Object? bfs_all_unique({
    required Object? initial,
    required Object? expand,
  }) =>
      getFunction("bfs_all_unique").call(
        <Object?>[
          initial,
          expand,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## classify
  ///
  /// ### python source
  /// ```py
  /// def classify(seq: Sequence, key: Optional[Callable] = None, value: Optional[Callable] = None) -> Dict:
  ///     d: Dict[Any, Any] = {}
  ///     for item in seq:
  ///         k = key(item) if (key is not None) else item
  ///         v = value(item) if (value is not None) else item
  ///         if k in d:
  ///             d[k].append(v)
  ///         else:
  ///             d[k] = [v]
  ///     return d
  /// ```
  Object? classify({
    required Object? seq,
    Object? key,
    Object? value,
  }) =>
      getFunction("classify").call(
        <Object?>[
          seq,
          key,
          value,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## classify_bool
  ///
  /// ### python source
  /// ```py
  /// def classify_bool(seq: Sequence, pred: Callable) -> Any:
  ///     true_elems = []
  ///     false_elems = []
  ///
  ///     for elem in seq:
  ///         if pred(elem):
  ///             true_elems.append(elem)
  ///         else:
  ///             false_elems.append(elem)
  ///
  ///     return true_elems, false_elems
  /// ```
  Object? classify_bool({
    required Object? seq,
    required Object? pred,
  }) =>
      getFunction("classify_bool").call(
        <Object?>[
          seq,
          pred,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## combine_alternatives
  ///
  /// ### python docstring
  ///
  /// Accepts a list of alternatives, and enumerates all their possible concatinations.
  ///
  /// Examples:
  ///     >>> combine_alternatives([range(2), [4,5]])
  ///     [[0, 4], [0, 5], [1, 4], [1, 5]]
  ///
  ///     >>> combine_alternatives(["abc", "xy", '$'])
  ///     [['a', 'x', '$'], ['a', 'y', '$'], ['b', 'x', '$'], ['b', 'y', '$'], ['c', 'x', '$'], ['c', 'y', '$']]
  ///
  ///     >>> combine_alternatives([])
  ///     [[]]
  ///
  /// ### python source
  /// ```py
  /// def combine_alternatives(lists):
  ///     """
  ///     Accepts a list of alternatives, and enumerates all their possible concatinations.
  ///
  ///     Examples:
  ///         >>> combine_alternatives([range(2), [4,5]])
  ///         [[0, 4], [0, 5], [1, 4], [1, 5]]
  ///
  ///         >>> combine_alternatives(["abc", "xy", '$'])
  ///         [['a', 'x', '$'], ['a', 'y', '$'], ['b', 'x', '$'], ['b', 'y', '$'], ['c', 'x', '$'], ['c', 'y', '$']]
  ///
  ///         >>> combine_alternatives([])
  ///         [[]]
  ///     """
  ///     if not lists:
  ///         return [[]]
  ///     assert all(l for l in lists), lists
  ///     init = [[x] for x in lists[0]]
  ///     return reduce(lambda a,b: [i+[j] for i in a for j in b], lists[1:], init)
  /// ```
  Object? combine_alternatives({
    required Object? lists,
  }) =>
      getFunction("combine_alternatives").call(
        <Object?>[
          lists,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## dedup_list
  ///
  /// ### python docstring
  ///
  /// Given a list (l) will removing duplicates from the list,
  /// preserving the original order of the list. Assumes that
  /// the list entries are hashable.
  ///
  /// ### python source
  /// ```py
  /// def dedup_list(l: List[T]) -> List[T]:
  ///     """Given a list (l) will removing duplicates from the list,
  ///        preserving the original order of the list. Assumes that
  ///        the list entries are hashable."""
  ///     dedup = set()
  ///     # This returns None, but that's expected
  ///     return [x for x in l if not (x in dedup or dedup.add(x))]  # type: ignore[func-returns-value]
  ///     # 2x faster (ordered in PyPy and CPython 3.6+, gaurenteed to be ordered in Python 3.7+)
  ///     # return list(dict.fromkeys(l))
  /// ```
  Object? dedup_list({
    required Object? l,
  }) =>
      getFunction("dedup_list").call(
        <Object?>[
          l,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## get_regexp_width
  ///
  /// ### python source
  /// ```py
  /// def get_regexp_width(expr: str) -> Union[Tuple[int, int], List[int]]:
  ///     if _has_regex:
  ///         # Since `sre_parse` cannot deal with Unicode categories of the form `\p{Mn}`, we replace these with
  ///         # a simple letter, which makes no difference as we are only trying to get the possible lengths of the regex
  ///         # match here below.
  ///         regexp_final = re.sub(categ_pattern, 'A', expr)
  ///     else:
  ///         if re.search(categ_pattern, expr):
  ///             raise ImportError('`regex` module must be installed in order to use Unicode categories.', expr)
  ///         regexp_final = expr
  ///     try:
  ///         # Fixed in next version (past 0.960) of typeshed
  ///         return [int(x) for x in sre_parse.parse(regexp_final).getwidth()]   # type: ignore[attr-defined]
  ///     except sre_constants.error:
  ///         if not _has_regex:
  ///             raise ValueError(expr)
  ///         else:
  ///             # sre_parse does not support the new features in regex. To not completely fail in that case,
  ///             # we manually test for the most important info (whether the empty string is matched)
  ///             c = regex.compile(regexp_final)
  ///             if c.match('') is None:
  ///                 # MAXREPEAT is a none pickable subclass of int, therefore needs to be converted to enable caching
  ///                 return 1, int(sre_constants.MAXREPEAT)
  ///             else:
  ///                 return 0, int(sre_constants.MAXREPEAT)
  /// ```
  Object? get_regexp_width({
    required Object? expr,
  }) =>
      getFunction("get_regexp_width").call(
        <Object?>[
          expr,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## is_id_continue
  ///
  /// ### python docstring
  ///
  /// Checks if all characters in `s` are alphanumeric characters (Unicode standard, so diacritics, indian vowels, non-latin
  /// numbers, etc. all pass). Synonymous with a Python `ID_CONTINUE` identifier. See PEP 3131 for details.
  ///
  /// ### python source
  /// ```py
  /// def is_id_continue(s: str) -> bool:
  ///     """
  ///     Checks if all characters in `s` are alphanumeric characters (Unicode standard, so diacritics, indian vowels, non-latin
  ///     numbers, etc. all pass). Synonymous with a Python `ID_CONTINUE` identifier. See PEP 3131 for details.
  ///     """
  ///     return _test_unicode_category(s, _ID_CONTINUE)
  /// ```
  Object? is_id_continue({
    required Object? s,
  }) =>
      getFunction("is_id_continue").call(
        <Object?>[
          s,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## is_id_start
  ///
  /// ### python docstring
  ///
  /// Checks if all characters in `s` are alphabetic characters (Unicode standard, so diacritics, indian vowels, non-latin
  /// numbers, etc. all pass). Synonymous with a Python `ID_START` identifier. See PEP 3131 for details.
  ///
  /// ### python source
  /// ```py
  /// def is_id_start(s: str) -> bool:
  ///     """
  ///     Checks if all characters in `s` are alphabetic characters (Unicode standard, so diacritics, indian vowels, non-latin
  ///     numbers, etc. all pass). Synonymous with a Python `ID_START` identifier. See PEP 3131 for details.
  ///     """
  ///     return _test_unicode_category(s, _ID_START)
  /// ```
  Object? is_id_start({
    required Object? s,
  }) =>
      getFunction("is_id_start").call(
        <Object?>[
          s,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## isascii
  ///
  /// ### python docstring
  ///
  /// str.isascii only exists in python3.7+
  ///
  /// ### python source
  /// ```py
  /// def isascii(s: str) -> bool:
  ///     """ str.isascii only exists in python3.7+ """
  ///     if sys.version_info >= (3, 7):
  ///         return s.isascii()
  ///     else:
  ///         try:
  ///             s.encode('ascii')
  ///             return True
  ///         except (UnicodeDecodeError, UnicodeEncodeError):
  ///             return False
  /// ```
  Object? isascii({
    required Object? s,
  }) =>
      getFunction("isascii").call(
        <Object?>[
          s,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## small_factors
  ///
  /// ### python docstring
  ///
  /// Splits n up into smaller factors and summands <= max_factor.
  /// Returns a list of [(a, b), ...]
  /// so that the following code returns n:
  ///
  /// n = 1
  /// for a, b in values:
  ///     n = n * a + b
  ///
  /// Currently, we also keep a + b <= max_factor, but that might change
  ///
  /// ### python source
  /// ```py
  /// def small_factors(n: int, max_factor: int) -> List[Tuple[int, int]]:
  ///     """
  ///     Splits n up into smaller factors and summands <= max_factor.
  ///     Returns a list of [(a, b), ...]
  ///     so that the following code returns n:
  ///
  ///     n = 1
  ///     for a, b in values:
  ///         n = n * a + b
  ///
  ///     Currently, we also keep a + b <= max_factor, but that might change
  ///     """
  ///     assert n >= 0
  ///     assert max_factor > 2
  ///     if n <= max_factor:
  ///         return [(n, 0)]
  ///
  ///     for a in range(max_factor, 1, -1):
  ///         r, b = divmod(n, a)
  ///         if a + b <= max_factor:
  ///             return small_factors(r, max_factor) + [(a, b)]
  ///     assert False, "Failed to factorize %s" % n
  /// ```
  Object? small_factors({
    required Object? n,
    required Object? max_factor,
  }) =>
      getFunction("small_factors").call(
        <Object?>[
          n,
          max_factor,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## T (getter)
  ///
  /// ### python docstring
  ///
  /// Type variable.
  ///
  /// Usage::
  ///
  ///   T = TypeVar('T')  # Can be anything
  ///   A = TypeVar('A', str, bytes)  # Must be str or bytes
  ///
  /// Type variables exist primarily for the benefit of static type
  /// checkers.  They serve as the parameters for generic types as well
  /// as for generic function definitions.  See class Generic for more
  /// information on generic types.  Generic functions work as follows:
  ///
  ///   def repeat(x: T, n: int) -> List[T]:
  ///       '''Return a list containing n references to x.'''
  ///       return [x]*n
  ///
  ///   def longest(x: A, y: A) -> A:
  ///       '''Return the longest of two strings.'''
  ///       return x if len(x) >= len(y) else y
  ///
  /// The latter example's signature is essentially the overloading
  /// of (str, str) -> str and (bytes, bytes) -> bytes.  Also note
  /// that if the arguments are instances of some subclass of str,
  /// the return type is still plain str.
  ///
  /// At runtime, isinstance(x, T) and issubclass(C, T) will raise TypeError.
  ///
  /// Type variables defined with covariant=True or contravariant=True
  /// can be used to declare covariant or contravariant generic types.
  /// See PEP 484 for more details. By default generic types are invariant
  /// in all type variables.
  ///
  /// Type variables can be introspected. e.g.:
  ///
  ///   T.__name__ == 'T'
  ///   T.__constraints__ == ()
  ///   T.__covariant__ == False
  ///   T.__contravariant__ = False
  ///   A.__constraints__ == (str, bytes)
  ///
  /// Note that only type variables defined in global scope can be pickled.
  Object? get T => getAttribute("T");

  /// ## T (setter)
  ///
  /// ### python docstring
  ///
  /// Type variable.
  ///
  /// Usage::
  ///
  ///   T = TypeVar('T')  # Can be anything
  ///   A = TypeVar('A', str, bytes)  # Must be str or bytes
  ///
  /// Type variables exist primarily for the benefit of static type
  /// checkers.  They serve as the parameters for generic types as well
  /// as for generic function definitions.  See class Generic for more
  /// information on generic types.  Generic functions work as follows:
  ///
  ///   def repeat(x: T, n: int) -> List[T]:
  ///       '''Return a list containing n references to x.'''
  ///       return [x]*n
  ///
  ///   def longest(x: A, y: A) -> A:
  ///       '''Return the longest of two strings.'''
  ///       return x if len(x) >= len(y) else y
  ///
  /// The latter example's signature is essentially the overloading
  /// of (str, str) -> str and (bytes, bytes) -> bytes.  Also note
  /// that if the arguments are instances of some subclass of str,
  /// the return type is still plain str.
  ///
  /// At runtime, isinstance(x, T) and issubclass(C, T) will raise TypeError.
  ///
  /// Type variables defined with covariant=True or contravariant=True
  /// can be used to declare covariant or contravariant generic types.
  /// See PEP 484 for more details. By default generic types are invariant
  /// in all type variables.
  ///
  /// Type variables can be introspected. e.g.:
  ///
  ///   T.__name__ == 'T'
  ///   T.__constraints__ == ()
  ///   T.__covariant__ == False
  ///   T.__contravariant__ = False
  ///   A.__constraints__ == (str, bytes)
  ///
  /// Note that only type variables defined in global scope can be pickled.
  set T(Object? T) => setAttribute("T", T);
}

/// ## logging
///
/// ### python docstring
///
/// Logging package for Python. Based on PEP 282 and comments thereto in
/// comp.lang.python.
///
/// Copyright (C) 2001-2019 Vinay Sajip. All Rights Reserved.
///
/// To use, simply 'import logging' and log away!
///
/// ### python source
/// ```py
/// # Copyright 2001-2019 by Vinay Sajip. All Rights Reserved.
/// #
/// # Permission to use, copy, modify, and distribute this software and its
/// # documentation for any purpose and without fee is hereby granted,
/// # provided that the above copyright notice appear in all copies and that
/// # both that copyright notice and this permission notice appear in
/// # supporting documentation, and that the name of Vinay Sajip
/// # not be used in advertising or publicity pertaining to distribution
/// # of the software without specific, written prior permission.
/// # VINAY SAJIP DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE, INCLUDING
/// # ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL
/// # VINAY SAJIP BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR
/// # ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER
/// # IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
/// # OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
///
/// """
/// Logging package for Python. Based on PEP 282 and comments thereto in
/// comp.lang.python.
///
/// Copyright (C) 2001-2019 Vinay Sajip. All Rights Reserved.
///
/// To use, simply 'import logging' and log away!
/// """
///
/// import sys, os, time, io, re, traceback, warnings, weakref, collections.abc
///
/// from types import GenericAlias
/// from string import Template
/// from string import Formatter as StrFormatter
///
///
/// __all__ = ['BASIC_FORMAT', 'BufferingFormatter', 'CRITICAL', 'DEBUG', 'ERROR',
///            'FATAL', 'FileHandler', 'Filter', 'Formatter', 'Handler', 'INFO',
///            'LogRecord', 'Logger', 'LoggerAdapter', 'NOTSET', 'NullHandler',
///            'StreamHandler', 'WARN', 'WARNING', 'addLevelName', 'basicConfig',
///            'captureWarnings', 'critical', 'debug', 'disable', 'error',
///            'exception', 'fatal', 'getLevelName', 'getLogger', 'getLoggerClass',
///            'info', 'log', 'makeLogRecord', 'setLoggerClass', 'shutdown',
///            'warn', 'warning', 'getLogRecordFactory', 'setLogRecordFactory',
///            'lastResort', 'raiseExceptions', 'getLevelNamesMapping']
///
/// import threading
///
/// __author__  = "Vinay Sajip <vinay_sajip@red-dove.com>"
/// __status__  = "production"
/// # The following module attributes are no longer updated.
/// __version__ = "0.5.1.2"
/// __date__    = "07 February 2010"
///
/// #---------------------------------------------------------------------------
/// #   Miscellaneous module data
/// #---------------------------------------------------------------------------
///
/// #
/// #_startTime is used as the base when calculating the relative time of events
/// #
/// _startTime = time.time()
///
/// #
/// #raiseExceptions is used to see if exceptions during handling should be
/// #propagated
/// #
/// raiseExceptions = True
///
/// #
/// # If you don't want threading information in the log, set this to zero
/// #
/// logThreads = True
///
/// #
/// # If you don't want multiprocessing information in the log, set this to zero
/// #
/// logMultiprocessing = True
///
/// #
/// # If you don't want process information in the log, set this to zero
/// #
/// logProcesses = True
///
/// #---------------------------------------------------------------------------
/// #   Level related stuff
/// #---------------------------------------------------------------------------
/// #
/// # Default levels and level names, these can be replaced with any positive set
/// # of values having corresponding names. There is a pseudo-level, NOTSET, which
/// # is only really there as a lower limit for user-defined levels. Handlers and
/// # loggers are initialized with NOTSET so that they will log all messages, even
/// # at user-defined levels.
/// #
///
/// CRITICAL = 50
/// FATAL = CRITICAL
/// ERROR = 40
/// WARNING = 30
/// WARN = WARNING
/// INFO = 20
/// DEBUG = 10
/// NOTSET = 0
///
/// _levelToName = {
///     CRITICAL: 'CRITICAL',
///     ERROR: 'ERROR',
///     WARNING: 'WARNING',
///     INFO: 'INFO',
///     DEBUG: 'DEBUG',
///     NOTSET: 'NOTSET',
/// }
/// _nameToLevel = {
///     'CRITICAL': CRITICAL,
///     'FATAL': FATAL,
///     'ERROR': ERROR,
///     'WARN': WARNING,
///     'WARNING': WARNING,
///     'INFO': INFO,
///     'DEBUG': DEBUG,
///     'NOTSET': NOTSET,
/// }
///
/// def getLevelNamesMapping():
///     return _nameToLevel.copy()
///
/// def getLevelName(level):
///     """
///     Return the textual or numeric representation of logging level 'level'.
///
///     If the level is one of the predefined levels (CRITICAL, ERROR, WARNING,
///     INFO, DEBUG) then you get the corresponding string. If you have
///     associated levels with names using addLevelName then the name you have
///     associated with 'level' is returned.
///
///     If a numeric value corresponding to one of the defined levels is passed
///     in, the corresponding string representation is returned.
///
///     If a string representation of the level is passed in, the corresponding
///     numeric value is returned.
///
///     If no matching numeric or string value is passed in, the string
///     'Level %s' % level is returned.
///     """
///     # See Issues #22386, #27937 and #29220 for why it's this way
///     result = _levelToName.get(level)
///     if result is not None:
///         return result
///     result = _nameToLevel.get(level)
///     if result is not None:
///         return result
///     return "Level %s" % level
///
/// def addLevelName(level, levelName):
///     """
///     Associate 'levelName' with 'level'.
///
///     This is used when converting levels to text during message formatting.
///     """
///     _acquireLock()
///     try:    #unlikely to cause an exception, but you never know...
///         _levelToName[level] = levelName
///         _nameToLevel[levelName] = level
///     finally:
///         _releaseLock()
///
/// if hasattr(sys, "_getframe"):
///     currentframe = lambda: sys._getframe(1)
/// else: #pragma: no cover
///     def currentframe():
///         """Return the frame object for the caller's stack frame."""
///         try:
///             raise Exception
///         except Exception:
///             return sys.exc_info()[2].tb_frame.f_back
///
/// #
/// # _srcfile is used when walking the stack to check when we've got the first
/// # caller stack frame, by skipping frames whose filename is that of this
/// # module's source. It therefore should contain the filename of this module's
/// # source file.
/// #
/// # Ordinarily we would use __file__ for this, but frozen modules don't always
/// # have __file__ set, for some reason (see Issue #21736). Thus, we get the
/// # filename from a handy code object from a function defined in this module.
/// # (There's no particular reason for picking addLevelName.)
/// #
///
/// _srcfile = os.path.normcase(addLevelName.__code__.co_filename)
///
/// # _srcfile is only used in conjunction with sys._getframe().
/// # Setting _srcfile to None will prevent findCaller() from being called. This
/// # way, you can avoid the overhead of fetching caller information.
///
/// # The following is based on warnings._is_internal_frame. It makes sure that
/// # frames of the import mechanism are skipped when logging at module level and
/// # using a stacklevel value greater than one.
/// def _is_internal_frame(frame):
///     """Signal whether the frame is a CPython or logging module internal."""
///     filename = os.path.normcase(frame.f_code.co_filename)
///     return filename == _srcfile or (
///         "importlib" in filename and "_bootstrap" in filename
///     )
///
///
/// def _checkLevel(level):
///     if isinstance(level, int):
///         rv = level
///     elif str(level) == level:
///         if level not in _nameToLevel:
///             raise ValueError("Unknown level: %r" % level)
///         rv = _nameToLevel[level]
///     else:
///         raise TypeError("Level not an integer or a valid string: %r"
///                         % (level,))
///     return rv
///
/// #---------------------------------------------------------------------------
/// #   Thread-related stuff
/// #---------------------------------------------------------------------------
///
/// #
/// #_lock is used to serialize access to shared data structures in this module.
/// #This needs to be an RLock because fileConfig() creates and configures
/// #Handlers, and so might arbitrary user threads. Since Handler code updates the
/// #shared dictionary _handlers, it needs to acquire the lock. But if configuring,
/// #the lock would already have been acquired - so we need an RLock.
/// #The same argument applies to Loggers and Manager.loggerDict.
/// #
/// _lock = threading.RLock()
///
/// def _acquireLock():
///     """
///     Acquire the module-level lock for serializing access to shared data.
///
///     This should be released with _releaseLock().
///     """
///     if _lock:
///         _lock.acquire()
///
/// def _releaseLock():
///     """
///     Release the module-level lock acquired by calling _acquireLock().
///     """
///     if _lock:
///         _lock.release()
///
///
/// # Prevent a held logging lock from blocking a child from logging.
///
/// if not hasattr(os, 'register_at_fork'):  # Windows and friends.
///     def _register_at_fork_reinit_lock(instance):
///         pass  # no-op when os.register_at_fork does not exist.
/// else:
///     # A collection of instances with a _at_fork_reinit method (logging.Handler)
///     # to be called in the child after forking.  The weakref avoids us keeping
///     # discarded Handler instances alive.
///     _at_fork_reinit_lock_weakset = weakref.WeakSet()
///
///     def _register_at_fork_reinit_lock(instance):
///         _acquireLock()
///         try:
///             _at_fork_reinit_lock_weakset.add(instance)
///         finally:
///             _releaseLock()
///
///     def _after_at_fork_child_reinit_locks():
///         for handler in _at_fork_reinit_lock_weakset:
///             handler._at_fork_reinit()
///
///         # _acquireLock() was called in the parent before forking.
///         # The lock is reinitialized to unlocked state.
///         _lock._at_fork_reinit()
///
///     os.register_at_fork(before=_acquireLock,
///                         after_in_child=_after_at_fork_child_reinit_locks,
///                         after_in_parent=_releaseLock)
///
///
/// #---------------------------------------------------------------------------
/// #   The logging record
/// #---------------------------------------------------------------------------
///
/// class LogRecord(object):
///     """
///     A LogRecord instance represents an event being logged.
///
///     LogRecord instances are created every time something is logged. They
///     contain all the information pertinent to the event being logged. The
///     main information passed in is in msg and args, which are combined
///     using str(msg) % args to create the message field of the record. The
///     record also includes information such as when the record was created,
///     the source line where the logging call was made, and any exception
///     information to be logged.
///     """
///     def __init__(self, name, level, pathname, lineno,
///                  msg, args, exc_info, func=None, sinfo=None, **kwargs):
///         """
///         Initialize a logging record with interesting information.
///         """
///         ct = time.time()
///         self.name = name
///         self.msg = msg
///         #
///         # The following statement allows passing of a dictionary as a sole
///         # argument, so that you can do something like
///         #  logging.debug("a %(a)d b %(b)s", {'a':1, 'b':2})
///         # Suggested by Stefan Behnel.
///         # Note that without the test for args[0], we get a problem because
///         # during formatting, we test to see if the arg is present using
///         # 'if self.args:'. If the event being logged is e.g. 'Value is %d'
///         # and if the passed arg fails 'if self.args:' then no formatting
///         # is done. For example, logger.warning('Value is %d', 0) would log
///         # 'Value is %d' instead of 'Value is 0'.
///         # For the use case of passing a dictionary, this should not be a
///         # problem.
///         # Issue #21172: a request was made to relax the isinstance check
///         # to hasattr(args[0], '__getitem__'). However, the docs on string
///         # formatting still seem to suggest a mapping object is required.
///         # Thus, while not removing the isinstance check, it does now look
///         # for collections.abc.Mapping rather than, as before, dict.
///         if (args and len(args) == 1 and isinstance(args[0], collections.abc.Mapping)
///             and args[0]):
///             args = args[0]
///         self.args = args
///         self.levelname = getLevelName(level)
///         self.levelno = level
///         self.pathname = pathname
///         try:
///             self.filename = os.path.basename(pathname)
///             self.module = os.path.splitext(self.filename)[0]
///         except (TypeError, ValueError, AttributeError):
///             self.filename = pathname
///             self.module = "Unknown module"
///         self.exc_info = exc_info
///         self.exc_text = None      # used to cache the traceback text
///         self.stack_info = sinfo
///         self.lineno = lineno
///         self.funcName = func
///         self.created = ct
///         self.msecs = int((ct - int(ct)) * 1000) + 0.0  # see gh-89047
///         self.relativeCreated = (self.created - _startTime) * 1000
///         if logThreads:
///             self.thread = threading.get_ident()
///             self.threadName = threading.current_thread().name
///         else: # pragma: no cover
///             self.thread = None
///             self.threadName = None
///         if not logMultiprocessing: # pragma: no cover
///             self.processName = None
///         else:
///             self.processName = 'MainProcess'
///             mp = sys.modules.get('multiprocessing')
///             if mp is not None:
///                 # Errors may occur if multiprocessing has not finished loading
///                 # yet - e.g. if a custom import hook causes third-party code
///                 # to run when multiprocessing calls import. See issue 8200
///                 # for an example
///                 try:
///                     self.processName = mp.current_process().name
///                 except Exception: #pragma: no cover
///                     pass
///         if logProcesses and hasattr(os, 'getpid'):
///             self.process = os.getpid()
///         else:
///             self.process = None
///
///     def __repr__(self):
///         return '<LogRecord: %s, %s, %s, %s, "%s">'%(self.name, self.levelno,
///             self.pathname, self.lineno, self.msg)
///
///     def getMessage(self):
///         """
///         Return the message for this LogRecord.
///
///         Return the message for this LogRecord after merging any user-supplied
///         arguments with the message.
///         """
///         msg = str(self.msg)
///         if self.args:
///             msg = msg % self.args
///         return msg
///
/// #
/// #   Determine which class to use when instantiating log records.
/// #
/// _logRecordFactory = LogRecord
///
/// def setLogRecordFactory(factory):
///     """
///     Set the factory to be used when instantiating a log record.
///
///     :param factory: A callable which will be called to instantiate
///     a log record.
///     """
///     global _logRecordFactory
///     _logRecordFactory = factory
///
/// def getLogRecordFactory():
///     """
///     Return the factory to be used when instantiating a log record.
///     """
///
///     return _logRecordFactory
///
/// def makeLogRecord(dict):
///     """
///     Make a LogRecord whose attributes are defined by the specified dictionary,
///     This function is useful for converting a logging event received over
///     a socket connection (which is sent as a dictionary) into a LogRecord
///     instance.
///     """
///     rv = _logRecordFactory(None, None, "", 0, "", (), None, None)
///     rv.__dict__.update(dict)
///     return rv
///
///
/// #---------------------------------------------------------------------------
/// #   Formatter classes and functions
/// #---------------------------------------------------------------------------
/// _str_formatter = StrFormatter()
/// del StrFormatter
///
///
/// class PercentStyle(object):
///
///     default_format = '%(message)s'
///     asctime_format = '%(asctime)s'
///     asctime_search = '%(asctime)'
///     validation_pattern = re.compile(r'%\(\w+\)[#0+ -]*(\*|\d+)?(\.(\*|\d+))?[diouxefgcrsa%]', re.I)
///
///     def __init__(self, fmt, *, defaults=None):
///         self._fmt = fmt or self.default_format
///         self._defaults = defaults
///
///     def usesTime(self):
///         return self._fmt.find(self.asctime_search) >= 0
///
///     def validate(self):
///         """Validate the input format, ensure it matches the correct style"""
///         if not self.validation_pattern.search(self._fmt):
///             raise ValueError("Invalid format '%s' for '%s' style" % (self._fmt, self.default_format[0]))
///
///     def _format(self, record):
///         if defaults := self._defaults:
///             values = defaults | record.__dict__
///         else:
///             values = record.__dict__
///         return self._fmt % values
///
///     def format(self, record):
///         try:
///             return self._format(record)
///         except KeyError as e:
///             raise ValueError('Formatting field not found in record: %s' % e)
///
///
/// class StrFormatStyle(PercentStyle):
///     default_format = '{message}'
///     asctime_format = '{asctime}'
///     asctime_search = '{asctime'
///
///     fmt_spec = re.compile(r'^(.?[<>=^])?[+ -]?#?0?(\d+|{\w+})?[,_]?(\.(\d+|{\w+}))?[bcdefgnosx%]?$', re.I)
///     field_spec = re.compile(r'^(\d+|\w+)(\.\w+|\[[^]]+\])*$')
///
///     def _format(self, record):
///         if defaults := self._defaults:
///             values = defaults | record.__dict__
///         else:
///             values = record.__dict__
///         return self._fmt.format(**values)
///
///     def validate(self):
///         """Validate the input format, ensure it is the correct string formatting style"""
///         fields = set()
///         try:
///             for _, fieldname, spec, conversion in _str_formatter.parse(self._fmt):
///                 if fieldname:
///                     if not self.field_spec.match(fieldname):
///                         raise ValueError('invalid field name/expression: %r' % fieldname)
///                     fields.add(fieldname)
///                 if conversion and conversion not in 'rsa':
///                     raise ValueError('invalid conversion: %r' % conversion)
///                 if spec and not self.fmt_spec.match(spec):
///                     raise ValueError('bad specifier: %r' % spec)
///         except ValueError as e:
///             raise ValueError('invalid format: %s' % e)
///         if not fields:
///             raise ValueError('invalid format: no fields')
///
///
/// class StringTemplateStyle(PercentStyle):
///     default_format = '${message}'
///     asctime_format = '${asctime}'
///     asctime_search = '${asctime}'
///
///     def __init__(self, *args, **kwargs):
///         super().__init__(*args, **kwargs)
///         self._tpl = Template(self._fmt)
///
///     def usesTime(self):
///         fmt = self._fmt
///         return fmt.find('$asctime') >= 0 or fmt.find(self.asctime_search) >= 0
///
///     def validate(self):
///         pattern = Template.pattern
///         fields = set()
///         for m in pattern.finditer(self._fmt):
///             d = m.groupdict()
///             if d['named']:
///                 fields.add(d['named'])
///             elif d['braced']:
///                 fields.add(d['braced'])
///             elif m.group(0) == '$':
///                 raise ValueError('invalid format: bare \'$\' not allowed')
///         if not fields:
///             raise ValueError('invalid format: no fields')
///
///     def _format(self, record):
///         if defaults := self._defaults:
///             values = defaults | record.__dict__
///         else:
///             values = record.__dict__
///         return self._tpl.substitute(**values)
///
///
/// BASIC_FORMAT = "%(levelname)s:%(name)s:%(message)s"
///
/// _STYLES = {
///     '%': (PercentStyle, BASIC_FORMAT),
///     '{': (StrFormatStyle, '{levelname}:{name}:{message}'),
///     '$': (StringTemplateStyle, '${levelname}:${name}:${message}'),
/// }
///
/// class Formatter(object):
///     """
///     Formatter instances are used to convert a LogRecord to text.
///
///     Formatters need to know how a LogRecord is constructed. They are
///     responsible for converting a LogRecord to (usually) a string which can
///     be interpreted by either a human or an external system. The base Formatter
///     allows a formatting string to be specified. If none is supplied, the
///     style-dependent default value, "%(message)s", "{message}", or
///     "${message}", is used.
///
///     The Formatter can be initialized with a format string which makes use of
///     knowledge of the LogRecord attributes - e.g. the default value mentioned
///     above makes use of the fact that the user's message and arguments are pre-
///     formatted into a LogRecord's message attribute. Currently, the useful
///     attributes in a LogRecord are described by:
///
///     %(name)s            Name of the logger (logging channel)
///     %(levelno)s         Numeric logging level for the message (DEBUG, INFO,
///                         WARNING, ERROR, CRITICAL)
///     %(levelname)s       Text logging level for the message ("DEBUG", "INFO",
///                         "WARNING", "ERROR", "CRITICAL")
///     %(pathname)s        Full pathname of the source file where the logging
///                         call was issued (if available)
///     %(filename)s        Filename portion of pathname
///     %(module)s          Module (name portion of filename)
///     %(lineno)d          Source line number where the logging call was issued
///                         (if available)
///     %(funcName)s        Function name
///     %(created)f         Time when the LogRecord was created (time.time()
///                         return value)
///     %(asctime)s         Textual time when the LogRecord was created
///     %(msecs)d           Millisecond portion of the creation time
///     %(relativeCreated)d Time in milliseconds when the LogRecord was created,
///                         relative to the time the logging module was loaded
///                         (typically at application startup time)
///     %(thread)d          Thread ID (if available)
///     %(threadName)s      Thread name (if available)
///     %(process)d         Process ID (if available)
///     %(message)s         The result of record.getMessage(), computed just as
///                         the record is emitted
///     """
///
///     converter = time.localtime
///
///     def __init__(self, fmt=None, datefmt=None, style='%', validate=True, *,
///                  defaults=None):
///         """
///         Initialize the formatter with specified format strings.
///
///         Initialize the formatter either with the specified format string, or a
///         default as described above. Allow for specialized date formatting with
///         the optional datefmt argument. If datefmt is omitted, you get an
///         ISO8601-like (or RFC 3339-like) format.
///
///         Use a style parameter of '%', '{' or '$' to specify that you want to
///         use one of %-formatting, :meth:`str.format` (``{}``) formatting or
///         :class:`string.Template` formatting in your format string.
///
///         .. versionchanged:: 3.2
///            Added the ``style`` parameter.
///         """
///         if style not in _STYLES:
///             raise ValueError('Style must be one of: %s' % ','.join(
///                              _STYLES.keys()))
///         self._style = _STYLES[style][0](fmt, defaults=defaults)
///         if validate:
///             self._style.validate()
///
///         self._fmt = self._style._fmt
///         self.datefmt = datefmt
///
///     default_time_format = '%Y-%m-%d %H:%M:%S'
///     default_msec_format = '%s,%03d'
///
///     def formatTime(self, record, datefmt=None):
///         """
///         Return the creation time of the specified LogRecord as formatted text.
///
///         This method should be called from format() by a formatter which
///         wants to make use of a formatted time. This method can be overridden
///         in formatters to provide for any specific requirement, but the
///         basic behaviour is as follows: if datefmt (a string) is specified,
///         it is used with time.strftime() to format the creation time of the
///         record. Otherwise, an ISO8601-like (or RFC 3339-like) format is used.
///         The resulting string is returned. This function uses a user-configurable
///         function to convert the creation time to a tuple. By default,
///         time.localtime() is used; to change this for a particular formatter
///         instance, set the 'converter' attribute to a function with the same
///         signature as time.localtime() or time.gmtime(). To change it for all
///         formatters, for example if you want all logging times to be shown in GMT,
///         set the 'converter' attribute in the Formatter class.
///         """
///         ct = self.converter(record.created)
///         if datefmt:
///             s = time.strftime(datefmt, ct)
///         else:
///             s = time.strftime(self.default_time_format, ct)
///             if self.default_msec_format:
///                 s = self.default_msec_format % (s, record.msecs)
///         return s
///
///     def formatException(self, ei):
///         """
///         Format and return the specified exception information as a string.
///
///         This default implementation just uses
///         traceback.print_exception()
///         """
///         sio = io.StringIO()
///         tb = ei[2]
///         # See issues #9427, #1553375. Commented out for now.
///         #if getattr(self, 'fullstack', False):
///         #    traceback.print_stack(tb.tb_frame.f_back, file=sio)
///         traceback.print_exception(ei[0], ei[1], tb, None, sio)
///         s = sio.getvalue()
///         sio.close()
///         if s[-1:] == "\n":
///             s = s[:-1]
///         return s
///
///     def usesTime(self):
///         """
///         Check if the format uses the creation time of the record.
///         """
///         return self._style.usesTime()
///
///     def formatMessage(self, record):
///         return self._style.format(record)
///
///     def formatStack(self, stack_info):
///         """
///         This method is provided as an extension point for specialized
///         formatting of stack information.
///
///         The input data is a string as returned from a call to
///         :func:`traceback.print_stack`, but with the last trailing newline
///         removed.
///
///         The base implementation just returns the value passed in.
///         """
///         return stack_info
///
///     def format(self, record):
///         """
///         Format the specified record as text.
///
///         The record's attribute dictionary is used as the operand to a
///         string formatting operation which yields the returned string.
///         Before formatting the dictionary, a couple of preparatory steps
///         are carried out. The message attribute of the record is computed
///         using LogRecord.getMessage(). If the formatting string uses the
///         time (as determined by a call to usesTime(), formatTime() is
///         called to format the event time. If there is exception information,
///         it is formatted using formatException() and appended to the message.
///         """
///         record.message = record.getMessage()
///         if self.usesTime():
///             record.asctime = self.formatTime(record, self.datefmt)
///         s = self.formatMessage(record)
///         if record.exc_info:
///             # Cache the traceback text to avoid converting it multiple times
///             # (it's constant anyway)
///             if not record.exc_text:
///                 record.exc_text = self.formatException(record.exc_info)
///         if record.exc_text:
///             if s[-1:] != "\n":
///                 s = s + "\n"
///             s = s + record.exc_text
///         if record.stack_info:
///             if s[-1:] != "\n":
///                 s = s + "\n"
///             s = s + self.formatStack(record.stack_info)
///         return s
///
/// #
/// #   The default formatter to use when no other is specified
/// #
/// _defaultFormatter = Formatter()
///
/// class BufferingFormatter(object):
///     """
///     A formatter suitable for formatting a number of records.
///     """
///     def __init__(self, linefmt=None):
///         """
///         Optionally specify a formatter which will be used to format each
///         individual record.
///         """
///         if linefmt:
///             self.linefmt = linefmt
///         else:
///             self.linefmt = _defaultFormatter
///
///     def formatHeader(self, records):
///         """
///         Return the header string for the specified records.
///         """
///         return ""
///
///     def formatFooter(self, records):
///         """
///         Return the footer string for the specified records.
///         """
///         return ""
///
///     def format(self, records):
///         """
///         Format the specified records and return the result as a string.
///         """
///         rv = ""
///         if len(records) > 0:
///             rv = rv + self.formatHeader(records)
///             for record in records:
///                 rv = rv + self.linefmt.format(record)
///             rv = rv + self.formatFooter(records)
///         return rv
///
/// #---------------------------------------------------------------------------
/// #   Filter classes and functions
/// #---------------------------------------------------------------------------
///
/// class Filter(object):
///     """
///     Filter instances are used to perform arbitrary filtering of LogRecords.
///
///     Loggers and Handlers can optionally use Filter instances to filter
///     records as desired. The base filter class only allows events which are
///     below a certain point in the logger hierarchy. For example, a filter
///     initialized with "A.B" will allow events logged by loggers "A.B",
///     "A.B.C", "A.B.C.D", "A.B.D" etc. but not "A.BB", "B.A.B" etc. If
///     initialized with the empty string, all events are passed.
///     """
///     def __init__(self, name=''):
///         """
///         Initialize a filter.
///
///         Initialize with the name of the logger which, together with its
///         children, will have its events allowed through the filter. If no
///         name is specified, allow every event.
///         """
///         self.name = name
///         self.nlen = len(name)
///
///     def filter(self, record):
///         """
///         Determine if the specified record is to be logged.
///
///         Returns True if the record should be logged, or False otherwise.
///         If deemed appropriate, the record may be modified in-place.
///         """
///         if self.nlen == 0:
///             return True
///         elif self.name == record.name:
///             return True
///         elif record.name.find(self.name, 0, self.nlen) != 0:
///             return False
///         return (record.name[self.nlen] == ".")
///
/// class Filterer(object):
///     """
///     A base class for loggers and handlers which allows them to share
///     common code.
///     """
///     def __init__(self):
///         """
///         Initialize the list of filters to be an empty list.
///         """
///         self.filters = []
///
///     def addFilter(self, filter):
///         """
///         Add the specified filter to this handler.
///         """
///         if not (filter in self.filters):
///             self.filters.append(filter)
///
///     def removeFilter(self, filter):
///         """
///         Remove the specified filter from this handler.
///         """
///         if filter in self.filters:
///             self.filters.remove(filter)
///
///     def filter(self, record):
///         """
///         Determine if a record is loggable by consulting all the filters.
///
///         The default is to allow the record to be logged; any filter can veto
///         this and the record is then dropped. Returns a zero value if a record
///         is to be dropped, else non-zero.
///
///         .. versionchanged:: 3.2
///
///            Allow filters to be just callables.
///         """
///         rv = True
///         for f in self.filters:
///             if hasattr(f, 'filter'):
///                 result = f.filter(record)
///             else:
///                 result = f(record) # assume callable - will raise if not
///             if not result:
///                 rv = False
///                 break
///         return rv
///
/// #---------------------------------------------------------------------------
/// #   Handler classes and functions
/// #---------------------------------------------------------------------------
///
/// _handlers = weakref.WeakValueDictionary()  #map of handler names to handlers
/// _handlerList = [] # added to allow handlers to be removed in reverse of order initialized
///
/// def _removeHandlerRef(wr):
///     """
///     Remove a handler reference from the internal cleanup list.
///     """
///     # This function can be called during module teardown, when globals are
///     # set to None. It can also be called from another thread. So we need to
///     # pre-emptively grab the necessary globals and check if they're None,
///     # to prevent race conditions and failures during interpreter shutdown.
///     acquire, release, handlers = _acquireLock, _releaseLock, _handlerList
///     if acquire and release and handlers:
///         acquire()
///         try:
///             handlers.remove(wr)
///         except ValueError:
///             pass
///         finally:
///             release()
///
/// def _addHandlerRef(handler):
///     """
///     Add a handler to the internal cleanup list using a weak reference.
///     """
///     _acquireLock()
///     try:
///         _handlerList.append(weakref.ref(handler, _removeHandlerRef))
///     finally:
///         _releaseLock()
///
/// class Handler(Filterer):
///     """
///     Handler instances dispatch logging events to specific destinations.
///
///     The base handler class. Acts as a placeholder which defines the Handler
///     interface. Handlers can optionally use Formatter instances to format
///     records as desired. By default, no formatter is specified; in this case,
///     the 'raw' message as determined by record.message is logged.
///     """
///     def __init__(self, level=NOTSET):
///         """
///         Initializes the instance - basically setting the formatter to None
///         and the filter list to empty.
///         """
///         Filterer.__init__(self)
///         self._name = None
///         self.level = _checkLevel(level)
///         self.formatter = None
///         self._closed = False
///         # Add the handler to the global _handlerList (for cleanup on shutdown)
///         _addHandlerRef(self)
///         self.createLock()
///
///     def get_name(self):
///         return self._name
///
///     def set_name(self, name):
///         _acquireLock()
///         try:
///             if self._name in _handlers:
///                 del _handlers[self._name]
///             self._name = name
///             if name:
///                 _handlers[name] = self
///         finally:
///             _releaseLock()
///
///     name = property(get_name, set_name)
///
///     def createLock(self):
///         """
///         Acquire a thread lock for serializing access to the underlying I/O.
///         """
///         self.lock = threading.RLock()
///         _register_at_fork_reinit_lock(self)
///
///     def _at_fork_reinit(self):
///         self.lock._at_fork_reinit()
///
///     def acquire(self):
///         """
///         Acquire the I/O thread lock.
///         """
///         if self.lock:
///             self.lock.acquire()
///
///     def release(self):
///         """
///         Release the I/O thread lock.
///         """
///         if self.lock:
///             self.lock.release()
///
///     def setLevel(self, level):
///         """
///         Set the logging level of this handler.  level must be an int or a str.
///         """
///         self.level = _checkLevel(level)
///
///     def format(self, record):
///         """
///         Format the specified record.
///
///         If a formatter is set, use it. Otherwise, use the default formatter
///         for the module.
///         """
///         if self.formatter:
///             fmt = self.formatter
///         else:
///             fmt = _defaultFormatter
///         return fmt.format(record)
///
///     def emit(self, record):
///         """
///         Do whatever it takes to actually log the specified logging record.
///
///         This version is intended to be implemented by subclasses and so
///         raises a NotImplementedError.
///         """
///         raise NotImplementedError('emit must be implemented '
///                                   'by Handler subclasses')
///
///     def handle(self, record):
///         """
///         Conditionally emit the specified logging record.
///
///         Emission depends on filters which may have been added to the handler.
///         Wrap the actual emission of the record with acquisition/release of
///         the I/O thread lock. Returns whether the filter passed the record for
///         emission.
///         """
///         rv = self.filter(record)
///         if rv:
///             self.acquire()
///             try:
///                 self.emit(record)
///             finally:
///                 self.release()
///         return rv
///
///     def setFormatter(self, fmt):
///         """
///         Set the formatter for this handler.
///         """
///         self.formatter = fmt
///
///     def flush(self):
///         """
///         Ensure all logging output has been flushed.
///
///         This version does nothing and is intended to be implemented by
///         subclasses.
///         """
///         pass
///
///     def close(self):
///         """
///         Tidy up any resources used by the handler.
///
///         This version removes the handler from an internal map of handlers,
///         _handlers, which is used for handler lookup by name. Subclasses
///         should ensure that this gets called from overridden close()
///         methods.
///         """
///         #get the module data lock, as we're updating a shared structure.
///         _acquireLock()
///         try:    #unlikely to raise an exception, but you never know...
///             self._closed = True
///             if self._name and self._name in _handlers:
///                 del _handlers[self._name]
///         finally:
///             _releaseLock()
///
///     def handleError(self, record):
///         """
///         Handle errors which occur during an emit() call.
///
///         This method should be called from handlers when an exception is
///         encountered during an emit() call. If raiseExceptions is false,
///         exceptions get silently ignored. This is what is mostly wanted
///         for a logging system - most users will not care about errors in
///         the logging system, they are more interested in application errors.
///         You could, however, replace this with a custom handler if you wish.
///         The record which was being processed is passed in to this method.
///         """
///         if raiseExceptions and sys.stderr:  # see issue 13807
///             t, v, tb = sys.exc_info()
///             try:
///                 sys.stderr.write('--- Logging error ---\n')
///                 traceback.print_exception(t, v, tb, None, sys.stderr)
///                 sys.stderr.write('Call stack:\n')
///                 # Walk the stack frame up until we're out of logging,
///                 # so as to print the calling context.
///                 frame = tb.tb_frame
///                 while (frame and os.path.dirname(frame.f_code.co_filename) ==
///                        __path__[0]):
///                     frame = frame.f_back
///                 if frame:
///                     traceback.print_stack(frame, file=sys.stderr)
///                 else:
///                     # couldn't find the right stack frame, for some reason
///                     sys.stderr.write('Logged from file %s, line %s\n' % (
///                                      record.filename, record.lineno))
///                 # Issue 18671: output logging message and arguments
///                 try:
///                     sys.stderr.write('Message: %r\n'
///                                      'Arguments: %s\n' % (record.msg,
///                                                           record.args))
///                 except RecursionError:  # See issue 36272
///                     raise
///                 except Exception:
///                     sys.stderr.write('Unable to print the message and arguments'
///                                      ' - possible formatting error.\nUse the'
///                                      ' traceback above to help find the error.\n'
///                                     )
///             except OSError: #pragma: no cover
///                 pass    # see issue 5971
///             finally:
///                 del t, v, tb
///
///     def __repr__(self):
///         level = getLevelName(self.level)
///         return '<%s (%s)>' % (self.__class__.__name__, level)
///
/// class StreamHandler(Handler):
///     """
///     A handler class which writes logging records, appropriately formatted,
///     to a stream. Note that this class does not close the stream, as
///     sys.stdout or sys.stderr may be used.
///     """
///
///     terminator = '\n'
///
///     def __init__(self, stream=None):
///         """
///         Initialize the handler.
///
///         If stream is not specified, sys.stderr is used.
///         """
///         Handler.__init__(self)
///         if stream is None:
///             stream = sys.stderr
///         self.stream = stream
///
///     def flush(self):
///         """
///         Flushes the stream.
///         """
///         self.acquire()
///         try:
///             if self.stream and hasattr(self.stream, "flush"):
///                 self.stream.flush()
///         finally:
///             self.release()
///
///     def emit(self, record):
///         """
///         Emit a record.
///
///         If a formatter is specified, it is used to format the record.
///         The record is then written to the stream with a trailing newline.  If
///         exception information is present, it is formatted using
///         traceback.print_exception and appended to the stream.  If the stream
///         has an 'encoding' attribute, it is used to determine how to do the
///         output to the stream.
///         """
///         try:
///             msg = self.format(record)
///             stream = self.stream
///             # issue 35046: merged two stream.writes into one.
///             stream.write(msg + self.terminator)
///             self.flush()
///         except RecursionError:  # See issue 36272
///             raise
///         except Exception:
///             self.handleError(record)
///
///     def setStream(self, stream):
///         """
///         Sets the StreamHandler's stream to the specified value,
///         if it is different.
///
///         Returns the old stream, if the stream was changed, or None
///         if it wasn't.
///         """
///         if stream is self.stream:
///             result = None
///         else:
///             result = self.stream
///             self.acquire()
///             try:
///                 self.flush()
///                 self.stream = stream
///             finally:
///                 self.release()
///         return result
///
///     def __repr__(self):
///         level = getLevelName(self.level)
///         name = getattr(self.stream, 'name', '')
///         #  bpo-36015: name can be an int
///         name = str(name)
///         if name:
///             name += ' '
///         return '<%s %s(%s)>' % (self.__class__.__name__, name, level)
///
///     __class_getitem__ = classmethod(GenericAlias)
///
///
/// class FileHandler(StreamHandler):
///     """
///     A handler class which writes formatted logging records to disk files.
///     """
///     def __init__(self, filename, mode='a', encoding=None, delay=False, errors=None):
///         """
///         Open the specified file and use it as the stream for logging.
///         """
///         # Issue #27493: add support for Path objects to be passed in
///         filename = os.fspath(filename)
///         #keep the absolute path, otherwise derived classes which use this
///         #may come a cropper when the current directory changes
///         self.baseFilename = os.path.abspath(filename)
///         self.mode = mode
///         self.encoding = encoding
///         if "b" not in mode:
///             self.encoding = io.text_encoding(encoding)
///         self.errors = errors
///         self.delay = delay
///         # bpo-26789: FileHandler keeps a reference to the builtin open()
///         # function to be able to open or reopen the file during Python
///         # finalization.
///         self._builtin_open = open
///         if delay:
///             #We don't open the stream, but we still need to call the
///             #Handler constructor to set level, formatter, lock etc.
///             Handler.__init__(self)
///             self.stream = None
///         else:
///             StreamHandler.__init__(self, self._open())
///
///     def close(self):
///         """
///         Closes the stream.
///         """
///         self.acquire()
///         try:
///             try:
///                 if self.stream:
///                     try:
///                         self.flush()
///                     finally:
///                         stream = self.stream
///                         self.stream = None
///                         if hasattr(stream, "close"):
///                             stream.close()
///             finally:
///                 # Issue #19523: call unconditionally to
///                 # prevent a handler leak when delay is set
///                 # Also see Issue #42378: we also rely on
///                 # self._closed being set to True there
///                 StreamHandler.close(self)
///         finally:
///             self.release()
///
///     def _open(self):
///         """
///         Open the current base file with the (original) mode and encoding.
///         Return the resulting stream.
///         """
///         open_func = self._builtin_open
///         return open_func(self.baseFilename, self.mode,
///                          encoding=self.encoding, errors=self.errors)
///
///     def emit(self, record):
///         """
///         Emit a record.
///
///         If the stream was not opened because 'delay' was specified in the
///         constructor, open it before calling the superclass's emit.
///
///         If stream is not open, current mode is 'w' and `_closed=True`, record
///         will not be emitted (see Issue #42378).
///         """
///         if self.stream is None:
///             if self.mode != 'w' or not self._closed:
///                 self.stream = self._open()
///         if self.stream:
///             StreamHandler.emit(self, record)
///
///     def __repr__(self):
///         level = getLevelName(self.level)
///         return '<%s %s (%s)>' % (self.__class__.__name__, self.baseFilename, level)
///
///
/// class _StderrHandler(StreamHandler):
///     """
///     This class is like a StreamHandler using sys.stderr, but always uses
///     whatever sys.stderr is currently set to rather than the value of
///     sys.stderr at handler construction time.
///     """
///     def __init__(self, level=NOTSET):
///         """
///         Initialize the handler.
///         """
///         Handler.__init__(self, level)
///
///     @property
///     def stream(self):
///         return sys.stderr
///
///
/// _defaultLastResort = _StderrHandler(WARNING)
/// lastResort = _defaultLastResort
///
/// #---------------------------------------------------------------------------
/// #   Manager classes and functions
/// #---------------------------------------------------------------------------
///
/// class PlaceHolder(object):
///     """
///     PlaceHolder instances are used in the Manager logger hierarchy to take
///     the place of nodes for which no loggers have been defined. This class is
///     intended for internal use only and not as part of the public API.
///     """
///     def __init__(self, alogger):
///         """
///         Initialize with the specified logger being a child of this placeholder.
///         """
///         self.loggerMap = { alogger : None }
///
///     def append(self, alogger):
///         """
///         Add the specified logger as a child of this placeholder.
///         """
///         if alogger not in self.loggerMap:
///             self.loggerMap[alogger] = None
///
/// #
/// #   Determine which class to use when instantiating loggers.
/// #
///
/// def setLoggerClass(klass):
///     """
///     Set the class to be used when instantiating a logger. The class should
///     define __init__() such that only a name argument is required, and the
///     __init__() should call Logger.__init__()
///     """
///     if klass != Logger:
///         if not issubclass(klass, Logger):
///             raise TypeError("logger not derived from logging.Logger: "
///                             + klass.__name__)
///     global _loggerClass
///     _loggerClass = klass
///
/// def getLoggerClass():
///     """
///     Return the class to be used when instantiating a logger.
///     """
///     return _loggerClass
///
/// class Manager(object):
///     """
///     There is [under normal circumstances] just one Manager instance, which
///     holds the hierarchy of loggers.
///     """
///     def __init__(self, rootnode):
///         """
///         Initialize the manager with the root node of the logger hierarchy.
///         """
///         self.root = rootnode
///         self.disable = 0
///         self.emittedNoHandlerWarning = False
///         self.loggerDict = {}
///         self.loggerClass = None
///         self.logRecordFactory = None
///
///     @property
///     def disable(self):
///         return self._disable
///
///     @disable.setter
///     def disable(self, value):
///         self._disable = _checkLevel(value)
///
///     def getLogger(self, name):
///         """
///         Get a logger with the specified name (channel name), creating it
///         if it doesn't yet exist. This name is a dot-separated hierarchical
///         name, such as "a", "a.b", "a.b.c" or similar.
///
///         If a PlaceHolder existed for the specified name [i.e. the logger
///         didn't exist but a child of it did], replace it with the created
///         logger and fix up the parent/child references which pointed to the
///         placeholder to now point to the logger.
///         """
///         rv = None
///         if not isinstance(name, str):
///             raise TypeError('A logger name must be a string')
///         _acquireLock()
///         try:
///             if name in self.loggerDict:
///                 rv = self.loggerDict[name]
///                 if isinstance(rv, PlaceHolder):
///                     ph = rv
///                     rv = (self.loggerClass or _loggerClass)(name)
///                     rv.manager = self
///                     self.loggerDict[name] = rv
///                     self._fixupChildren(ph, rv)
///                     self._fixupParents(rv)
///             else:
///                 rv = (self.loggerClass or _loggerClass)(name)
///                 rv.manager = self
///                 self.loggerDict[name] = rv
///                 self._fixupParents(rv)
///         finally:
///             _releaseLock()
///         return rv
///
///     def setLoggerClass(self, klass):
///         """
///         Set the class to be used when instantiating a logger with this Manager.
///         """
///         if klass != Logger:
///             if not issubclass(klass, Logger):
///                 raise TypeError("logger not derived from logging.Logger: "
///                                 + klass.__name__)
///         self.loggerClass = klass
///
///     def setLogRecordFactory(self, factory):
///         """
///         Set the factory to be used when instantiating a log record with this
///         Manager.
///         """
///         self.logRecordFactory = factory
///
///     def _fixupParents(self, alogger):
///         """
///         Ensure that there are either loggers or placeholders all the way
///         from the specified logger to the root of the logger hierarchy.
///         """
///         name = alogger.name
///         i = name.rfind(".")
///         rv = None
///         while (i > 0) and not rv:
///             substr = name[:i]
///             if substr not in self.loggerDict:
///                 self.loggerDict[substr] = PlaceHolder(alogger)
///             else:
///                 obj = self.loggerDict[substr]
///                 if isinstance(obj, Logger):
///                     rv = obj
///                 else:
///                     assert isinstance(obj, PlaceHolder)
///                     obj.append(alogger)
///             i = name.rfind(".", 0, i - 1)
///         if not rv:
///             rv = self.root
///         alogger.parent = rv
///
///     def _fixupChildren(self, ph, alogger):
///         """
///         Ensure that children of the placeholder ph are connected to the
///         specified logger.
///         """
///         name = alogger.name
///         namelen = len(name)
///         for c in ph.loggerMap.keys():
///             #The if means ... if not c.parent.name.startswith(nm)
///             if c.parent.name[:namelen] != name:
///                 alogger.parent = c.parent
///                 c.parent = alogger
///
///     def _clear_cache(self):
///         """
///         Clear the cache for all loggers in loggerDict
///         Called when level changes are made
///         """
///
///         _acquireLock()
///         for logger in self.loggerDict.values():
///             if isinstance(logger, Logger):
///                 logger._cache.clear()
///         self.root._cache.clear()
///         _releaseLock()
///
/// #---------------------------------------------------------------------------
/// #   Logger classes and functions
/// #---------------------------------------------------------------------------
///
/// class Logger(Filterer):
///     """
///     Instances of the Logger class represent a single logging channel. A
///     "logging channel" indicates an area of an application. Exactly how an
///     "area" is defined is up to the application developer. Since an
///     application can have any number of areas, logging channels are identified
///     by a unique string. Application areas can be nested (e.g. an area
///     of "input processing" might include sub-areas "read CSV files", "read
///     XLS files" and "read Gnumeric files"). To cater for this natural nesting,
///     channel names are organized into a namespace hierarchy where levels are
///     separated by periods, much like the Java or Python package namespace. So
///     in the instance given above, channel names might be "input" for the upper
///     level, and "input.csv", "input.xls" and "input.gnu" for the sub-levels.
///     There is no arbitrary limit to the depth of nesting.
///     """
///     def __init__(self, name, level=NOTSET):
///         """
///         Initialize the logger with a name and an optional level.
///         """
///         Filterer.__init__(self)
///         self.name = name
///         self.level = _checkLevel(level)
///         self.parent = None
///         self.propagate = True
///         self.handlers = []
///         self.disabled = False
///         self._cache = {}
///
///     def setLevel(self, level):
///         """
///         Set the logging level of this logger.  level must be an int or a str.
///         """
///         self.level = _checkLevel(level)
///         self.manager._clear_cache()
///
///     def debug(self, msg, *args, **kwargs):
///         """
///         Log 'msg % args' with severity 'DEBUG'.
///
///         To pass exception information, use the keyword argument exc_info with
///         a true value, e.g.
///
///         logger.debug("Houston, we have a %s", "thorny problem", exc_info=1)
///         """
///         if self.isEnabledFor(DEBUG):
///             self._log(DEBUG, msg, args, **kwargs)
///
///     def info(self, msg, *args, **kwargs):
///         """
///         Log 'msg % args' with severity 'INFO'.
///
///         To pass exception information, use the keyword argument exc_info with
///         a true value, e.g.
///
///         logger.info("Houston, we have a %s", "interesting problem", exc_info=1)
///         """
///         if self.isEnabledFor(INFO):
///             self._log(INFO, msg, args, **kwargs)
///
///     def warning(self, msg, *args, **kwargs):
///         """
///         Log 'msg % args' with severity 'WARNING'.
///
///         To pass exception information, use the keyword argument exc_info with
///         a true value, e.g.
///
///         logger.warning("Houston, we have a %s", "bit of a problem", exc_info=1)
///         """
///         if self.isEnabledFor(WARNING):
///             self._log(WARNING, msg, args, **kwargs)
///
///     def warn(self, msg, *args, **kwargs):
///         warnings.warn("The 'warn' method is deprecated, "
///             "use 'warning' instead", DeprecationWarning, 2)
///         self.warning(msg, *args, **kwargs)
///
///     def error(self, msg, *args, **kwargs):
///         """
///         Log 'msg % args' with severity 'ERROR'.
///
///         To pass exception information, use the keyword argument exc_info with
///         a true value, e.g.
///
///         logger.error("Houston, we have a %s", "major problem", exc_info=1)
///         """
///         if self.isEnabledFor(ERROR):
///             self._log(ERROR, msg, args, **kwargs)
///
///     def exception(self, msg, *args, exc_info=True, **kwargs):
///         """
///         Convenience method for logging an ERROR with exception information.
///         """
///         self.error(msg, *args, exc_info=exc_info, **kwargs)
///
///     def critical(self, msg, *args, **kwargs):
///         """
///         Log 'msg % args' with severity 'CRITICAL'.
///
///         To pass exception information, use the keyword argument exc_info with
///         a true value, e.g.
///
///         logger.critical("Houston, we have a %s", "major disaster", exc_info=1)
///         """
///         if self.isEnabledFor(CRITICAL):
///             self._log(CRITICAL, msg, args, **kwargs)
///
///     def fatal(self, msg, *args, **kwargs):
///         """
///         Don't use this method, use critical() instead.
///         """
///         self.critical(msg, *args, **kwargs)
///
///     def log(self, level, msg, *args, **kwargs):
///         """
///         Log 'msg % args' with the integer severity 'level'.
///
///         To pass exception information, use the keyword argument exc_info with
///         a true value, e.g.
///
///         logger.log(level, "We have a %s", "mysterious problem", exc_info=1)
///         """
///         if not isinstance(level, int):
///             if raiseExceptions:
///                 raise TypeError("level must be an integer")
///             else:
///                 return
///         if self.isEnabledFor(level):
///             self._log(level, msg, args, **kwargs)
///
///     def findCaller(self, stack_info=False, stacklevel=1):
///         """
///         Find the stack frame of the caller so that we can note the source
///         file name, line number and function name.
///         """
///         f = currentframe()
///         #On some versions of IronPython, currentframe() returns None if
///         #IronPython isn't run with -X:Frames.
///         if f is None:
///             return "(unknown file)", 0, "(unknown function)", None
///         while stacklevel > 0:
///             next_f = f.f_back
///             if next_f is None:
///                 ## We've got options here.
///                 ## If we want to use the last (deepest) frame:
///                 break
///                 ## If we want to mimic the warnings module:
///                 #return ("sys", 1, "(unknown function)", None)
///                 ## If we want to be pedantic:
///                 #raise ValueError("call stack is not deep enough")
///             f = next_f
///             if not _is_internal_frame(f):
///                 stacklevel -= 1
///         co = f.f_code
///         sinfo = None
///         if stack_info:
///             with io.StringIO() as sio:
///                 sio.write("Stack (most recent call last):\n")
///                 traceback.print_stack(f, file=sio)
///                 sinfo = sio.getvalue()
///                 if sinfo[-1] == '\n':
///                     sinfo = sinfo[:-1]
///         return co.co_filename, f.f_lineno, co.co_name, sinfo
///
///     def makeRecord(self, name, level, fn, lno, msg, args, exc_info,
///                    func=None, extra=None, sinfo=None):
///         """
///         A factory method which can be overridden in subclasses to create
///         specialized LogRecords.
///         """
///         rv = _logRecordFactory(name, level, fn, lno, msg, args, exc_info, func,
///                              sinfo)
///         if extra is not None:
///             for key in extra:
///                 if (key in ["message", "asctime"]) or (key in rv.__dict__):
///                     raise KeyError("Attempt to overwrite %r in LogRecord" % key)
///                 rv.__dict__[key] = extra[key]
///         return rv
///
///     def _log(self, level, msg, args, exc_info=None, extra=None, stack_info=False,
///              stacklevel=1):
///         """
///         Low-level logging routine which creates a LogRecord and then calls
///         all the handlers of this logger to handle the record.
///         """
///         sinfo = None
///         if _srcfile:
///             #IronPython doesn't track Python frames, so findCaller raises an
///             #exception on some versions of IronPython. We trap it here so that
///             #IronPython can use logging.
///             try:
///                 fn, lno, func, sinfo = self.findCaller(stack_info, stacklevel)
///             except ValueError: # pragma: no cover
///                 fn, lno, func = "(unknown file)", 0, "(unknown function)"
///         else: # pragma: no cover
///             fn, lno, func = "(unknown file)", 0, "(unknown function)"
///         if exc_info:
///             if isinstance(exc_info, BaseException):
///                 exc_info = (type(exc_info), exc_info, exc_info.__traceback__)
///             elif not isinstance(exc_info, tuple):
///                 exc_info = sys.exc_info()
///         record = self.makeRecord(self.name, level, fn, lno, msg, args,
///                                  exc_info, func, extra, sinfo)
///         self.handle(record)
///
///     def handle(self, record):
///         """
///         Call the handlers for the specified record.
///
///         This method is used for unpickled records received from a socket, as
///         well as those created locally. Logger-level filtering is applied.
///         """
///         if (not self.disabled) and self.filter(record):
///             self.callHandlers(record)
///
///     def addHandler(self, hdlr):
///         """
///         Add the specified handler to this logger.
///         """
///         _acquireLock()
///         try:
///             if not (hdlr in self.handlers):
///                 self.handlers.append(hdlr)
///         finally:
///             _releaseLock()
///
///     def removeHandler(self, hdlr):
///         """
///         Remove the specified handler from this logger.
///         """
///         _acquireLock()
///         try:
///             if hdlr in self.handlers:
///                 self.handlers.remove(hdlr)
///         finally:
///             _releaseLock()
///
///     def hasHandlers(self):
///         """
///         See if this logger has any handlers configured.
///
///         Loop through all handlers for this logger and its parents in the
///         logger hierarchy. Return True if a handler was found, else False.
///         Stop searching up the hierarchy whenever a logger with the "propagate"
///         attribute set to zero is found - that will be the last logger which
///         is checked for the existence of handlers.
///         """
///         c = self
///         rv = False
///         while c:
///             if c.handlers:
///                 rv = True
///                 break
///             if not c.propagate:
///                 break
///             else:
///                 c = c.parent
///         return rv
///
///     def callHandlers(self, record):
///         """
///         Pass a record to all relevant handlers.
///
///         Loop through all handlers for this logger and its parents in the
///         logger hierarchy. If no handler was found, output a one-off error
///         message to sys.stderr. Stop searching up the hierarchy whenever a
///         logger with the "propagate" attribute set to zero is found - that
///         will be the last logger whose handlers are called.
///         """
///         c = self
///         found = 0
///         while c:
///             for hdlr in c.handlers:
///                 found = found + 1
///                 if record.levelno >= hdlr.level:
///                     hdlr.handle(record)
///             if not c.propagate:
///                 c = None    #break out
///             else:
///                 c = c.parent
///         if (found == 0):
///             if lastResort:
///                 if record.levelno >= lastResort.level:
///                     lastResort.handle(record)
///             elif raiseExceptions and not self.manager.emittedNoHandlerWarning:
///                 sys.stderr.write("No handlers could be found for logger"
///                                  " \"%s\"\n" % self.name)
///                 self.manager.emittedNoHandlerWarning = True
///
///     def getEffectiveLevel(self):
///         """
///         Get the effective level for this logger.
///
///         Loop through this logger and its parents in the logger hierarchy,
///         looking for a non-zero logging level. Return the first one found.
///         """
///         logger = self
///         while logger:
///             if logger.level:
///                 return logger.level
///             logger = logger.parent
///         return NOTSET
///
///     def isEnabledFor(self, level):
///         """
///         Is this logger enabled for level 'level'?
///         """
///         if self.disabled:
///             return False
///
///         try:
///             return self._cache[level]
///         except KeyError:
///             _acquireLock()
///             try:
///                 if self.manager.disable >= level:
///                     is_enabled = self._cache[level] = False
///                 else:
///                     is_enabled = self._cache[level] = (
///                         level >= self.getEffectiveLevel()
///                     )
///             finally:
///                 _releaseLock()
///             return is_enabled
///
///     def getChild(self, suffix):
///         """
///         Get a logger which is a descendant to this one.
///
///         This is a convenience method, such that
///
///         logging.getLogger('abc').getChild('def.ghi')
///
///         is the same as
///
///         logging.getLogger('abc.def.ghi')
///
///         It's useful, for example, when the parent logger is named using
///         __name__ rather than a literal string.
///         """
///         if self.root is not self:
///             suffix = '.'.join((self.name, suffix))
///         return self.manager.getLogger(suffix)
///
///     def __repr__(self):
///         level = getLevelName(self.getEffectiveLevel())
///         return '<%s %s (%s)>' % (self.__class__.__name__, self.name, level)
///
///     def __reduce__(self):
///         if getLogger(self.name) is not self:
///             import pickle
///             raise pickle.PicklingError('logger cannot be pickled')
///         return getLogger, (self.name,)
///
///
/// class RootLogger(Logger):
///     """
///     A root logger is not that different to any other logger, except that
///     it must have a logging level and there is only one instance of it in
///     the hierarchy.
///     """
///     def __init__(self, level):
///         """
///         Initialize the logger with the name "root".
///         """
///         Logger.__init__(self, "root", level)
///
///     def __reduce__(self):
///         return getLogger, ()
///
/// _loggerClass = Logger
///
/// class LoggerAdapter(object):
///     """
///     An adapter for loggers which makes it easier to specify contextual
///     information in logging output.
///     """
///
///     def __init__(self, logger, extra=None):
///         """
///         Initialize the adapter with a logger and a dict-like object which
///         provides contextual information. This constructor signature allows
///         easy stacking of LoggerAdapters, if so desired.
///
///         You can effectively pass keyword arguments as shown in the
///         following example:
///
///         adapter = LoggerAdapter(someLogger, dict(p1=v1, p2="v2"))
///         """
///         self.logger = logger
///         self.extra = extra
///
///     def process(self, msg, kwargs):
///         """
///         Process the logging message and keyword arguments passed in to
///         a logging call to insert contextual information. You can either
///         manipulate the message itself, the keyword args or both. Return
///         the message and kwargs modified (or not) to suit your needs.
///
///         Normally, you'll only need to override this one method in a
///         LoggerAdapter subclass for your specific needs.
///         """
///         kwargs["extra"] = self.extra
///         return msg, kwargs
///
///     #
///     # Boilerplate convenience methods
///     #
///     def debug(self, msg, *args, **kwargs):
///         """
///         Delegate a debug call to the underlying logger.
///         """
///         self.log(DEBUG, msg, *args, **kwargs)
///
///     def info(self, msg, *args, **kwargs):
///         """
///         Delegate an info call to the underlying logger.
///         """
///         self.log(INFO, msg, *args, **kwargs)
///
///     def warning(self, msg, *args, **kwargs):
///         """
///         Delegate a warning call to the underlying logger.
///         """
///         self.log(WARNING, msg, *args, **kwargs)
///
///     def warn(self, msg, *args, **kwargs):
///         warnings.warn("The 'warn' method is deprecated, "
///             "use 'warning' instead", DeprecationWarning, 2)
///         self.warning(msg, *args, **kwargs)
///
///     def error(self, msg, *args, **kwargs):
///         """
///         Delegate an error call to the underlying logger.
///         """
///         self.log(ERROR, msg, *args, **kwargs)
///
///     def exception(self, msg, *args, exc_info=True, **kwargs):
///         """
///         Delegate an exception call to the underlying logger.
///         """
///         self.log(ERROR, msg, *args, exc_info=exc_info, **kwargs)
///
///     def critical(self, msg, *args, **kwargs):
///         """
///         Delegate a critical call to the underlying logger.
///         """
///         self.log(CRITICAL, msg, *args, **kwargs)
///
///     def log(self, level, msg, *args, **kwargs):
///         """
///         Delegate a log call to the underlying logger, after adding
///         contextual information from this adapter instance.
///         """
///         if self.isEnabledFor(level):
///             msg, kwargs = self.process(msg, kwargs)
///             self.logger.log(level, msg, *args, **kwargs)
///
///     def isEnabledFor(self, level):
///         """
///         Is this logger enabled for level 'level'?
///         """
///         return self.logger.isEnabledFor(level)
///
///     def setLevel(self, level):
///         """
///         Set the specified level on the underlying logger.
///         """
///         self.logger.setLevel(level)
///
///     def getEffectiveLevel(self):
///         """
///         Get the effective level for the underlying logger.
///         """
///         return self.logger.getEffectiveLevel()
///
///     def hasHandlers(self):
///         """
///         See if the underlying logger has any handlers.
///         """
///         return self.logger.hasHandlers()
///
///     def _log(self, level, msg, args, exc_info=None, extra=None, stack_info=False):
///         """
///         Low-level log implementation, proxied to allow nested logger adapters.
///         """
///         return self.logger._log(
///             level,
///             msg,
///             args,
///             exc_info=exc_info,
///             extra=extra,
///             stack_info=stack_info,
///         )
///
///     @property
///     def manager(self):
///         return self.logger.manager
///
///     @manager.setter
///     def manager(self, value):
///         self.logger.manager = value
///
///     @property
///     def name(self):
///         return self.logger.name
///
///     def __repr__(self):
///         logger = self.logger
///         level = getLevelName(logger.getEffectiveLevel())
///         return '<%s %s (%s)>' % (self.__class__.__name__, logger.name, level)
///
///     __class_getitem__ = classmethod(GenericAlias)
///
/// root = RootLogger(WARNING)
/// Logger.root = root
/// Logger.manager = Manager(Logger.root)
///
/// #---------------------------------------------------------------------------
/// # Configuration classes and functions
/// #---------------------------------------------------------------------------
///
/// def basicConfig(**kwargs):
///     """
///     Do basic configuration for the logging system.
///
///     This function does nothing if the root logger already has handlers
///     configured, unless the keyword argument *force* is set to ``True``.
///     It is a convenience method intended for use by simple scripts
///     to do one-shot configuration of the logging package.
///
///     The default behaviour is to create a StreamHandler which writes to
///     sys.stderr, set a formatter using the BASIC_FORMAT format string, and
///     add the handler to the root logger.
///
///     A number of optional keyword arguments may be specified, which can alter
///     the default behaviour.
///
///     filename  Specifies that a FileHandler be created, using the specified
///               filename, rather than a StreamHandler.
///     filemode  Specifies the mode to open the file, if filename is specified
///               (if filemode is unspecified, it defaults to 'a').
///     format    Use the specified format string for the handler.
///     datefmt   Use the specified date/time format.
///     style     If a format string is specified, use this to specify the
///               type of format string (possible values '%', '{', '$', for
///               %-formatting, :meth:`str.format` and :class:`string.Template`
///               - defaults to '%').
///     level     Set the root logger level to the specified level.
///     stream    Use the specified stream to initialize the StreamHandler. Note
///               that this argument is incompatible with 'filename' - if both
///               are present, 'stream' is ignored.
///     handlers  If specified, this should be an iterable of already created
///               handlers, which will be added to the root handler. Any handler
///               in the list which does not have a formatter assigned will be
///               assigned the formatter created in this function.
///     force     If this keyword  is specified as true, any existing handlers
///               attached to the root logger are removed and closed, before
///               carrying out the configuration as specified by the other
///               arguments.
///     encoding  If specified together with a filename, this encoding is passed to
///               the created FileHandler, causing it to be used when the file is
///               opened.
///     errors    If specified together with a filename, this value is passed to the
///               created FileHandler, causing it to be used when the file is
///               opened in text mode. If not specified, the default value is
///               `backslashreplace`.
///
///     Note that you could specify a stream created using open(filename, mode)
///     rather than passing the filename and mode in. However, it should be
///     remembered that StreamHandler does not close its stream (since it may be
///     using sys.stdout or sys.stderr), whereas FileHandler closes its stream
///     when the handler is closed.
///
///     .. versionchanged:: 3.2
///        Added the ``style`` parameter.
///
///     .. versionchanged:: 3.3
///        Added the ``handlers`` parameter. A ``ValueError`` is now thrown for
///        incompatible arguments (e.g. ``handlers`` specified together with
///        ``filename``/``filemode``, or ``filename``/``filemode`` specified
///        together with ``stream``, or ``handlers`` specified together with
///        ``stream``.
///
///     .. versionchanged:: 3.8
///        Added the ``force`` parameter.
///
///     .. versionchanged:: 3.9
///        Added the ``encoding`` and ``errors`` parameters.
///     """
///     # Add thread safety in case someone mistakenly calls
///     # basicConfig() from multiple threads
///     _acquireLock()
///     try:
///         force = kwargs.pop('force', False)
///         encoding = kwargs.pop('encoding', None)
///         errors = kwargs.pop('errors', 'backslashreplace')
///         if force:
///             for h in root.handlers[:]:
///                 root.removeHandler(h)
///                 h.close()
///         if len(root.handlers) == 0:
///             handlers = kwargs.pop("handlers", None)
///             if handlers is None:
///                 if "stream" in kwargs and "filename" in kwargs:
///                     raise ValueError("'stream' and 'filename' should not be "
///                                      "specified together")
///             else:
///                 if "stream" in kwargs or "filename" in kwargs:
///                     raise ValueError("'stream' or 'filename' should not be "
///                                      "specified together with 'handlers'")
///             if handlers is None:
///                 filename = kwargs.pop("filename", None)
///                 mode = kwargs.pop("filemode", 'a')
///                 if filename:
///                     if 'b' in mode:
///                         errors = None
///                     else:
///                         encoding = io.text_encoding(encoding)
///                     h = FileHandler(filename, mode,
///                                     encoding=encoding, errors=errors)
///                 else:
///                     stream = kwargs.pop("stream", None)
///                     h = StreamHandler(stream)
///                 handlers = [h]
///             dfs = kwargs.pop("datefmt", None)
///             style = kwargs.pop("style", '%')
///             if style not in _STYLES:
///                 raise ValueError('Style must be one of: %s' % ','.join(
///                                  _STYLES.keys()))
///             fs = kwargs.pop("format", _STYLES[style][1])
///             fmt = Formatter(fs, dfs, style)
///             for h in handlers:
///                 if h.formatter is None:
///                     h.setFormatter(fmt)
///                 root.addHandler(h)
///             level = kwargs.pop("level", None)
///             if level is not None:
///                 root.setLevel(level)
///             if kwargs:
///                 keys = ', '.join(kwargs.keys())
///                 raise ValueError('Unrecognised argument(s): %s' % keys)
///     finally:
///         _releaseLock()
///
/// #---------------------------------------------------------------------------
/// # Utility functions at module level.
/// # Basically delegate everything to the root logger.
/// #---------------------------------------------------------------------------
///
/// def getLogger(name=None):
///     """
///     Return a logger with the specified name, creating it if necessary.
///
///     If no name is specified, return the root logger.
///     """
///     if not name or isinstance(name, str) and name == root.name:
///         return root
///     return Logger.manager.getLogger(name)
///
/// def critical(msg, *args, **kwargs):
///     """
///     Log a message with severity 'CRITICAL' on the root logger. If the logger
///     has no handlers, call basicConfig() to add a console handler with a
///     pre-defined format.
///     """
///     if len(root.handlers) == 0:
///         basicConfig()
///     root.critical(msg, *args, **kwargs)
///
/// def fatal(msg, *args, **kwargs):
///     """
///     Don't use this function, use critical() instead.
///     """
///     critical(msg, *args, **kwargs)
///
/// def error(msg, *args, **kwargs):
///     """
///     Log a message with severity 'ERROR' on the root logger. If the logger has
///     no handlers, call basicConfig() to add a console handler with a pre-defined
///     format.
///     """
///     if len(root.handlers) == 0:
///         basicConfig()
///     root.error(msg, *args, **kwargs)
///
/// def exception(msg, *args, exc_info=True, **kwargs):
///     """
///     Log a message with severity 'ERROR' on the root logger, with exception
///     information. If the logger has no handlers, basicConfig() is called to add
///     a console handler with a pre-defined format.
///     """
///     error(msg, *args, exc_info=exc_info, **kwargs)
///
/// def warning(msg, *args, **kwargs):
///     """
///     Log a message with severity 'WARNING' on the root logger. If the logger has
///     no handlers, call basicConfig() to add a console handler with a pre-defined
///     format.
///     """
///     if len(root.handlers) == 0:
///         basicConfig()
///     root.warning(msg, *args, **kwargs)
///
/// def warn(msg, *args, **kwargs):
///     warnings.warn("The 'warn' function is deprecated, "
///         "use 'warning' instead", DeprecationWarning, 2)
///     warning(msg, *args, **kwargs)
///
/// def info(msg, *args, **kwargs):
///     """
///     Log a message with severity 'INFO' on the root logger. If the logger has
///     no handlers, call basicConfig() to add a console handler with a pre-defined
///     format.
///     """
///     if len(root.handlers) == 0:
///         basicConfig()
///     root.info(msg, *args, **kwargs)
///
/// def debug(msg, *args, **kwargs):
///     """
///     Log a message with severity 'DEBUG' on the root logger. If the logger has
///     no handlers, call basicConfig() to add a console handler with a pre-defined
///     format.
///     """
///     if len(root.handlers) == 0:
///         basicConfig()
///     root.debug(msg, *args, **kwargs)
///
/// def log(level, msg, *args, **kwargs):
///     """
///     Log 'msg % args' with the integer severity 'level' on the root logger. If
///     the logger has no handlers, call basicConfig() to add a console handler
///     with a pre-defined format.
///     """
///     if len(root.handlers) == 0:
///         basicConfig()
///     root.log(level, msg, *args, **kwargs)
///
/// def disable(level=CRITICAL):
///     """
///     Disable all logging calls of severity 'level' and below.
///     """
///     root.manager.disable = level
///     root.manager._clear_cache()
///
/// def shutdown(handlerList=_handlerList):
///     """
///     Perform any cleanup actions in the logging system (e.g. flushing
///     buffers).
///
///     Should be called at application exit.
///     """
///     for wr in reversed(handlerList[:]):
///         #errors might occur, for example, if files are locked
///         #we just ignore them if raiseExceptions is not set
///         try:
///             h = wr()
///             if h:
///                 try:
///                     h.acquire()
///                     h.flush()
///                     h.close()
///                 except (OSError, ValueError):
///                     # Ignore errors which might be caused
///                     # because handlers have been closed but
///                     # references to them are still around at
///                     # application exit.
///                     pass
///                 finally:
///                     h.release()
///         except: # ignore everything, as we're shutting down
///             if raiseExceptions:
///                 raise
///             #else, swallow
///
/// #Let's try and shutdown automatically on application exit...
/// import atexit
/// atexit.register(shutdown)
///
/// # Null handler
///
/// class NullHandler(Handler):
///     """
///     This handler does nothing. It's intended to be used to avoid the
///     "No handlers could be found for logger XXX" one-off warning. This is
///     important for library code, which may contain code to log events. If a user
///     of the library does not configure logging, the one-off warning might be
///     produced; to avoid this, the library developer simply needs to instantiate
///     a NullHandler and add it to the top-level logger of the library module or
///     package.
///     """
///     def handle(self, record):
///         """Stub."""
///
///     def emit(self, record):
///         """Stub."""
///
///     def createLock(self):
///         self.lock = None
///
///     def _at_fork_reinit(self):
///         pass
///
/// # Warnings integration
///
/// _warnings_showwarning = None
///
/// def _showwarning(message, category, filename, lineno, file=None, line=None):
///     """
///     Implementation of showwarnings which redirects to logging, which will first
///     check to see if the file parameter is None. If a file is specified, it will
///     delegate to the original warnings implementation of showwarning. Otherwise,
///     it will call warnings.formatwarning and will log the resulting string to a
///     warnings logger named "py.warnings" with level logging.WARNING.
///     """
///     if file is not None:
///         if _warnings_showwarning is not None:
///             _warnings_showwarning(message, category, filename, lineno, file, line)
///     else:
///         s = warnings.formatwarning(message, category, filename, lineno, line)
///         logger = getLogger("py.warnings")
///         if not logger.handlers:
///             logger.addHandler(NullHandler())
///         # bpo-46557: Log str(s) as msg instead of logger.warning("%s", s)
///         # since some log aggregation tools group logs by the msg arg
///         logger.warning(str(s))
///
/// def captureWarnings(capture):
///     """
///     If capture is true, redirect all warnings to the logging package.
///     If capture is False, ensure that warnings are not redirected to logging
///     but to their original destinations.
///     """
///     global _warnings_showwarning
///     if capture:
///         if _warnings_showwarning is None:
///             _warnings_showwarning = warnings.showwarning
///             warnings.showwarning = _showwarning
///     else:
///         if _warnings_showwarning is not None:
///             warnings.showwarning = _warnings_showwarning
///             _warnings_showwarning = None
/// ```
final class logging extends PythonModule {
  logging.from(super.pythonModule) : super.from();

  static logging import() => PythonFfiDart.instance.importModule(
        "logging",
        logging.from,
      );

  /// ## addLevelName
  ///
  /// ### python docstring
  ///
  /// Associate 'levelName' with 'level'.
  ///
  /// This is used when converting levels to text during message formatting.
  ///
  /// ### python source
  /// ```py
  /// def addLevelName(level, levelName):
  ///     """
  ///     Associate 'levelName' with 'level'.
  ///
  ///     This is used when converting levels to text during message formatting.
  ///     """
  ///     _acquireLock()
  ///     try:    #unlikely to cause an exception, but you never know...
  ///         _levelToName[level] = levelName
  ///         _nameToLevel[levelName] = level
  ///     finally:
  ///         _releaseLock()
  /// ```
  Object? addLevelName({
    required Object? level,
    required Object? levelName,
  }) =>
      getFunction("addLevelName").call(
        <Object?>[
          level,
          levelName,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## basicConfig
  ///
  /// ### python docstring
  ///
  /// Do basic configuration for the logging system.
  ///
  /// This function does nothing if the root logger already has handlers
  /// configured, unless the keyword argument *force* is set to ``True``.
  /// It is a convenience method intended for use by simple scripts
  /// to do one-shot configuration of the logging package.
  ///
  /// The default behaviour is to create a StreamHandler which writes to
  /// sys.stderr, set a formatter using the BASIC_FORMAT format string, and
  /// add the handler to the root logger.
  ///
  /// A number of optional keyword arguments may be specified, which can alter
  /// the default behaviour.
  ///
  /// filename  Specifies that a FileHandler be created, using the specified
  ///           filename, rather than a StreamHandler.
  /// filemode  Specifies the mode to open the file, if filename is specified
  ///           (if filemode is unspecified, it defaults to 'a').
  /// format    Use the specified format string for the handler.
  /// datefmt   Use the specified date/time format.
  /// style     If a format string is specified, use this to specify the
  ///           type of format string (possible values '%', '{', '$', for
  ///           %-formatting, :meth:`str.format` and :class:`string.Template`
  ///           - defaults to '%').
  /// level     Set the root logger level to the specified level.
  /// stream    Use the specified stream to initialize the StreamHandler. Note
  ///           that this argument is incompatible with 'filename' - if both
  ///           are present, 'stream' is ignored.
  /// handlers  If specified, this should be an iterable of already created
  ///           handlers, which will be added to the root handler. Any handler
  ///           in the list which does not have a formatter assigned will be
  ///           assigned the formatter created in this function.
  /// force     If this keyword  is specified as true, any existing handlers
  ///           attached to the root logger are removed and closed, before
  ///           carrying out the configuration as specified by the other
  ///           arguments.
  /// encoding  If specified together with a filename, this encoding is passed to
  ///           the created FileHandler, causing it to be used when the file is
  ///           opened.
  /// errors    If specified together with a filename, this value is passed to the
  ///           created FileHandler, causing it to be used when the file is
  ///           opened in text mode. If not specified, the default value is
  ///           `backslashreplace`.
  ///
  /// Note that you could specify a stream created using open(filename, mode)
  /// rather than passing the filename and mode in. However, it should be
  /// remembered that StreamHandler does not close its stream (since it may be
  /// using sys.stdout or sys.stderr), whereas FileHandler closes its stream
  /// when the handler is closed.
  ///
  /// .. versionchanged:: 3.2
  ///    Added the ``style`` parameter.
  ///
  /// .. versionchanged:: 3.3
  ///    Added the ``handlers`` parameter. A ``ValueError`` is now thrown for
  ///    incompatible arguments (e.g. ``handlers`` specified together with
  ///    ``filename``/``filemode``, or ``filename``/``filemode`` specified
  ///    together with ``stream``, or ``handlers`` specified together with
  ///    ``stream``.
  ///
  /// .. versionchanged:: 3.8
  ///    Added the ``force`` parameter.
  ///
  /// .. versionchanged:: 3.9
  ///    Added the ``encoding`` and ``errors`` parameters.
  Object? basicConfig({
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("basicConfig").call(
        <Object?>[],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## captureWarnings
  ///
  /// ### python docstring
  ///
  /// If capture is true, redirect all warnings to the logging package.
  /// If capture is False, ensure that warnings are not redirected to logging
  /// but to their original destinations.
  ///
  /// ### python source
  /// ```py
  /// def captureWarnings(capture):
  ///     """
  ///     If capture is true, redirect all warnings to the logging package.
  ///     If capture is False, ensure that warnings are not redirected to logging
  ///     but to their original destinations.
  ///     """
  ///     global _warnings_showwarning
  ///     if capture:
  ///         if _warnings_showwarning is None:
  ///             _warnings_showwarning = warnings.showwarning
  ///             warnings.showwarning = _showwarning
  ///     else:
  ///         if _warnings_showwarning is not None:
  ///             warnings.showwarning = _warnings_showwarning
  ///             _warnings_showwarning = None
  /// ```
  Object? captureWarnings({
    required Object? capture,
  }) =>
      getFunction("captureWarnings").call(
        <Object?>[
          capture,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## critical
  ///
  /// ### python docstring
  ///
  /// Log a message with severity 'CRITICAL' on the root logger. If the logger
  /// has no handlers, call basicConfig() to add a console handler with a
  /// pre-defined format.
  ///
  /// ### python source
  /// ```py
  /// def critical(msg, *args, **kwargs):
  ///     """
  ///     Log a message with severity 'CRITICAL' on the root logger. If the logger
  ///     has no handlers, call basicConfig() to add a console handler with a
  ///     pre-defined format.
  ///     """
  ///     if len(root.handlers) == 0:
  ///         basicConfig()
  ///     root.critical(msg, *args, **kwargs)
  /// ```
  Object? critical({
    List<Object?> args = const <Object?>[],
    required Object? msg,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("critical").call(
        <Object?>[
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## currentframe
  ///
  /// ### python source
  /// ```py
  /// currentframe = lambda: sys._getframe(1)
  /// ```
  Object? currentframe() => getFunction("currentframe").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## debug
  ///
  /// ### python docstring
  ///
  /// Log a message with severity 'DEBUG' on the root logger. If the logger has
  /// no handlers, call basicConfig() to add a console handler with a pre-defined
  /// format.
  ///
  /// ### python source
  /// ```py
  /// def debug(msg, *args, **kwargs):
  ///     """
  ///     Log a message with severity 'DEBUG' on the root logger. If the logger has
  ///     no handlers, call basicConfig() to add a console handler with a pre-defined
  ///     format.
  ///     """
  ///     if len(root.handlers) == 0:
  ///         basicConfig()
  ///     root.debug(msg, *args, **kwargs)
  /// ```
  Object? debug({
    List<Object?> args = const <Object?>[],
    required Object? msg,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("debug").call(
        <Object?>[
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## disable
  ///
  /// ### python docstring
  ///
  /// Disable all logging calls of severity 'level' and below.
  ///
  /// ### python source
  /// ```py
  /// def disable(level=CRITICAL):
  ///     """
  ///     Disable all logging calls of severity 'level' and below.
  ///     """
  ///     root.manager.disable = level
  ///     root.manager._clear_cache()
  /// ```
  Object? disable({
    Object? level = 50,
  }) =>
      getFunction("disable").call(
        <Object?>[
          level,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## error
  ///
  /// ### python docstring
  ///
  /// Log a message with severity 'ERROR' on the root logger. If the logger has
  /// no handlers, call basicConfig() to add a console handler with a pre-defined
  /// format.
  ///
  /// ### python source
  /// ```py
  /// def error(msg, *args, **kwargs):
  ///     """
  ///     Log a message with severity 'ERROR' on the root logger. If the logger has
  ///     no handlers, call basicConfig() to add a console handler with a pre-defined
  ///     format.
  ///     """
  ///     if len(root.handlers) == 0:
  ///         basicConfig()
  ///     root.error(msg, *args, **kwargs)
  /// ```
  Object? error({
    List<Object?> args = const <Object?>[],
    required Object? msg,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("error").call(
        <Object?>[
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## exception
  ///
  /// ### python docstring
  ///
  /// Log a message with severity 'ERROR' on the root logger, with exception
  /// information. If the logger has no handlers, basicConfig() is called to add
  /// a console handler with a pre-defined format.
  ///
  /// ### python source
  /// ```py
  /// def exception(msg, *args, exc_info=True, **kwargs):
  ///     """
  ///     Log a message with severity 'ERROR' on the root logger, with exception
  ///     information. If the logger has no handlers, basicConfig() is called to add
  ///     a console handler with a pre-defined format.
  ///     """
  ///     error(msg, *args, exc_info=exc_info, **kwargs)
  /// ```
  Object? exception({
    List<Object?> args = const <Object?>[],
    required Object? msg,
    Object? exc_info = true,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("exception").call(
        <Object?>[
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          "exc_info": exc_info,
          ...kwargs,
        },
      );

  /// ## fatal
  ///
  /// ### python docstring
  ///
  /// Don't use this function, use critical() instead.
  ///
  /// ### python source
  /// ```py
  /// def fatal(msg, *args, **kwargs):
  ///     """
  ///     Don't use this function, use critical() instead.
  ///     """
  ///     critical(msg, *args, **kwargs)
  /// ```
  Object? fatal({
    List<Object?> args = const <Object?>[],
    required Object? msg,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("fatal").call(
        <Object?>[
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## getLevelName
  ///
  /// ### python docstring
  ///
  /// Return the textual or numeric representation of logging level 'level'.
  ///
  /// If the level is one of the predefined levels (CRITICAL, ERROR, WARNING,
  /// INFO, DEBUG) then you get the corresponding string. If you have
  /// associated levels with names using addLevelName then the name you have
  /// associated with 'level' is returned.
  ///
  /// If a numeric value corresponding to one of the defined levels is passed
  /// in, the corresponding string representation is returned.
  ///
  /// If a string representation of the level is passed in, the corresponding
  /// numeric value is returned.
  ///
  /// If no matching numeric or string value is passed in, the string
  /// 'Level %s' % level is returned.
  ///
  /// ### python source
  /// ```py
  /// def getLevelName(level):
  ///     """
  ///     Return the textual or numeric representation of logging level 'level'.
  ///
  ///     If the level is one of the predefined levels (CRITICAL, ERROR, WARNING,
  ///     INFO, DEBUG) then you get the corresponding string. If you have
  ///     associated levels with names using addLevelName then the name you have
  ///     associated with 'level' is returned.
  ///
  ///     If a numeric value corresponding to one of the defined levels is passed
  ///     in, the corresponding string representation is returned.
  ///
  ///     If a string representation of the level is passed in, the corresponding
  ///     numeric value is returned.
  ///
  ///     If no matching numeric or string value is passed in, the string
  ///     'Level %s' % level is returned.
  ///     """
  ///     # See Issues #22386, #27937 and #29220 for why it's this way
  ///     result = _levelToName.get(level)
  ///     if result is not None:
  ///         return result
  ///     result = _nameToLevel.get(level)
  ///     if result is not None:
  ///         return result
  ///     return "Level %s" % level
  /// ```
  Object? getLevelName({
    required Object? level,
  }) =>
      getFunction("getLevelName").call(
        <Object?>[
          level,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## getLevelNamesMapping
  ///
  /// ### python source
  /// ```py
  /// def getLevelNamesMapping():
  ///     return _nameToLevel.copy()
  /// ```
  Object? getLevelNamesMapping() => getFunction("getLevelNamesMapping").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## getLogRecordFactory
  ///
  /// ### python docstring
  ///
  /// Return the factory to be used when instantiating a log record.
  ///
  /// ### python source
  /// ```py
  /// def getLogRecordFactory():
  ///     """
  ///     Return the factory to be used when instantiating a log record.
  ///     """
  ///
  ///     return _logRecordFactory
  /// ```
  Object? getLogRecordFactory() => getFunction("getLogRecordFactory").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## getLogger
  ///
  /// ### python docstring
  ///
  /// Return a logger with the specified name, creating it if necessary.
  ///
  /// If no name is specified, return the root logger.
  ///
  /// ### python source
  /// ```py
  /// def getLogger(name=None):
  ///     """
  ///     Return a logger with the specified name, creating it if necessary.
  ///
  ///     If no name is specified, return the root logger.
  ///     """
  ///     if not name or isinstance(name, str) and name == root.name:
  ///         return root
  ///     return Logger.manager.getLogger(name)
  /// ```
  Object? getLogger({
    Object? name,
  }) =>
      getFunction("getLogger").call(
        <Object?>[
          name,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## getLoggerClass
  ///
  /// ### python docstring
  ///
  /// Return the class to be used when instantiating a logger.
  ///
  /// ### python source
  /// ```py
  /// def getLoggerClass():
  ///     """
  ///     Return the class to be used when instantiating a logger.
  ///     """
  ///     return _loggerClass
  /// ```
  Object? getLoggerClass() => getFunction("getLoggerClass").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## info
  ///
  /// ### python docstring
  ///
  /// Log a message with severity 'INFO' on the root logger. If the logger has
  /// no handlers, call basicConfig() to add a console handler with a pre-defined
  /// format.
  ///
  /// ### python source
  /// ```py
  /// def info(msg, *args, **kwargs):
  ///     """
  ///     Log a message with severity 'INFO' on the root logger. If the logger has
  ///     no handlers, call basicConfig() to add a console handler with a pre-defined
  ///     format.
  ///     """
  ///     if len(root.handlers) == 0:
  ///         basicConfig()
  ///     root.info(msg, *args, **kwargs)
  /// ```
  Object? info({
    List<Object?> args = const <Object?>[],
    required Object? msg,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("info").call(
        <Object?>[
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## log
  ///
  /// ### python docstring
  ///
  /// Log 'msg % args' with the integer severity 'level' on the root logger. If
  /// the logger has no handlers, call basicConfig() to add a console handler
  /// with a pre-defined format.
  ///
  /// ### python source
  /// ```py
  /// def log(level, msg, *args, **kwargs):
  ///     """
  ///     Log 'msg % args' with the integer severity 'level' on the root logger. If
  ///     the logger has no handlers, call basicConfig() to add a console handler
  ///     with a pre-defined format.
  ///     """
  ///     if len(root.handlers) == 0:
  ///         basicConfig()
  ///     root.log(level, msg, *args, **kwargs)
  /// ```
  Object? log({
    List<Object?> args = const <Object?>[],
    required Object? level,
    required Object? msg,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("log").call(
        <Object?>[
          level,
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## makeLogRecord
  ///
  /// ### python docstring
  ///
  /// Make a LogRecord whose attributes are defined by the specified dictionary,
  /// This function is useful for converting a logging event received over
  /// a socket connection (which is sent as a dictionary) into a LogRecord
  /// instance.
  ///
  /// ### python source
  /// ```py
  /// def makeLogRecord(dict):
  ///     """
  ///     Make a LogRecord whose attributes are defined by the specified dictionary,
  ///     This function is useful for converting a logging event received over
  ///     a socket connection (which is sent as a dictionary) into a LogRecord
  ///     instance.
  ///     """
  ///     rv = _logRecordFactory(None, None, "", 0, "", (), None, None)
  ///     rv.__dict__.update(dict)
  ///     return rv
  /// ```
  Object? makeLogRecord({
    required Object? dict,
  }) =>
      getFunction("makeLogRecord").call(
        <Object?>[
          dict,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## setLogRecordFactory
  ///
  /// ### python docstring
  ///
  /// Set the factory to be used when instantiating a log record.
  ///
  /// :param factory: A callable which will be called to instantiate
  /// a log record.
  ///
  /// ### python source
  /// ```py
  /// def setLogRecordFactory(factory):
  ///     """
  ///     Set the factory to be used when instantiating a log record.
  ///
  ///     :param factory: A callable which will be called to instantiate
  ///     a log record.
  ///     """
  ///     global _logRecordFactory
  ///     _logRecordFactory = factory
  /// ```
  Object? setLogRecordFactory({
    required Object? $factory,
  }) =>
      getFunction("setLogRecordFactory").call(
        <Object?>[
          $factory,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## setLoggerClass
  ///
  /// ### python docstring
  ///
  /// Set the class to be used when instantiating a logger. The class should
  /// define __init__() such that only a name argument is required, and the
  /// __init__() should call Logger.__init__()
  ///
  /// ### python source
  /// ```py
  /// def setLoggerClass(klass):
  ///     """
  ///     Set the class to be used when instantiating a logger. The class should
  ///     define __init__() such that only a name argument is required, and the
  ///     __init__() should call Logger.__init__()
  ///     """
  ///     if klass != Logger:
  ///         if not issubclass(klass, Logger):
  ///             raise TypeError("logger not derived from logging.Logger: "
  ///                             + klass.__name__)
  ///     global _loggerClass
  ///     _loggerClass = klass
  /// ```
  Object? setLoggerClass({
    required Object? klass,
  }) =>
      getFunction("setLoggerClass").call(
        <Object?>[
          klass,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## shutdown
  ///
  /// ### python docstring
  ///
  /// Perform any cleanup actions in the logging system (e.g. flushing
  /// buffers).
  ///
  /// Should be called at application exit.
  ///
  /// ### python source
  /// ```py
  /// def shutdown(handlerList=_handlerList):
  ///     """
  ///     Perform any cleanup actions in the logging system (e.g. flushing
  ///     buffers).
  ///
  ///     Should be called at application exit.
  ///     """
  ///     for wr in reversed(handlerList[:]):
  ///         #errors might occur, for example, if files are locked
  ///         #we just ignore them if raiseExceptions is not set
  ///         try:
  ///             h = wr()
  ///             if h:
  ///                 try:
  ///                     h.acquire()
  ///                     h.flush()
  ///                     h.close()
  ///                 except (OSError, ValueError):
  ///                     # Ignore errors which might be caused
  ///                     # because handlers have been closed but
  ///                     # references to them are still around at
  ///                     # application exit.
  ///                     pass
  ///                 finally:
  ///                     h.release()
  ///         except: # ignore everything, as we're shutting down
  ///             if raiseExceptions:
  ///                 raise
  ///             #else, swallow
  /// ```
  Object? shutdown({
    Object? handlerList = const [null, null],
  }) =>
      getFunction("shutdown").call(
        <Object?>[
          handlerList,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## warn
  ///
  /// ### python source
  /// ```py
  /// def warn(msg, *args, **kwargs):
  ///     warnings.warn("The 'warn' function is deprecated, "
  ///         "use 'warning' instead", DeprecationWarning, 2)
  ///     warning(msg, *args, **kwargs)
  /// ```
  Object? warn({
    List<Object?> args = const <Object?>[],
    required Object? msg,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("warn").call(
        <Object?>[
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## warning
  ///
  /// ### python docstring
  ///
  /// Log a message with severity 'WARNING' on the root logger. If the logger has
  /// no handlers, call basicConfig() to add a console handler with a pre-defined
  /// format.
  ///
  /// ### python source
  /// ```py
  /// def warning(msg, *args, **kwargs):
  ///     """
  ///     Log a message with severity 'WARNING' on the root logger. If the logger has
  ///     no handlers, call basicConfig() to add a console handler with a pre-defined
  ///     format.
  ///     """
  ///     if len(root.handlers) == 0:
  ///         basicConfig()
  ///     root.warning(msg, *args, **kwargs)
  /// ```
  Object? warning({
    List<Object?> args = const <Object?>[],
    required Object? msg,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("warning").call(
        <Object?>[
          msg,
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## lastResort (getter)
  ///
  /// ### python docstring
  ///
  /// This class is like a StreamHandler using sys.stderr, but always uses
  /// whatever sys.stderr is currently set to rather than the value of
  /// sys.stderr at handler construction time.
  Object? get lastResort => getAttribute("lastResort");

  /// ## lastResort (setter)
  ///
  /// ### python docstring
  ///
  /// This class is like a StreamHandler using sys.stderr, but always uses
  /// whatever sys.stderr is currently set to rather than the value of
  /// sys.stderr at handler construction time.
  set lastResort(Object? lastResort) => setAttribute("lastResort", lastResort);

  /// ## root (getter)
  ///
  /// ### python docstring
  ///
  /// A root logger is not that different to any other logger, except that
  /// it must have a logging level and there is only one instance of it in
  /// the hierarchy.
  Object? get root => getAttribute("root");

  /// ## root (setter)
  ///
  /// ### python docstring
  ///
  /// A root logger is not that different to any other logger, except that
  /// it must have a logging level and there is only one instance of it in
  /// the hierarchy.
  set root(Object? root) => setAttribute("root", root);

  /// ## BASIC_FORMAT (getter)
  Object? get BASIC_FORMAT => getAttribute("BASIC_FORMAT");

  /// ## BASIC_FORMAT (setter)
  set BASIC_FORMAT(Object? BASIC_FORMAT) =>
      setAttribute("BASIC_FORMAT", BASIC_FORMAT);

  /// ## CRITICAL (getter)
  Object? get CRITICAL => getAttribute("CRITICAL");

  /// ## CRITICAL (setter)
  set CRITICAL(Object? CRITICAL) => setAttribute("CRITICAL", CRITICAL);

  /// ## DEBUG (getter)
  Object? get DEBUG => getAttribute("DEBUG");

  /// ## DEBUG (setter)
  set DEBUG(Object? DEBUG) => setAttribute("DEBUG", DEBUG);

  /// ## ERROR (getter)
  Object? get ERROR => getAttribute("ERROR");

  /// ## ERROR (setter)
  set ERROR(Object? ERROR) => setAttribute("ERROR", ERROR);

  /// ## FATAL (getter)
  Object? get FATAL => getAttribute("FATAL");

  /// ## FATAL (setter)
  set FATAL(Object? FATAL) => setAttribute("FATAL", FATAL);

  /// ## INFO (getter)
  Object? get INFO => getAttribute("INFO");

  /// ## INFO (setter)
  set INFO(Object? INFO) => setAttribute("INFO", INFO);

  /// ## NOTSET (getter)
  Object? get NOTSET => getAttribute("NOTSET");

  /// ## NOTSET (setter)
  set NOTSET(Object? NOTSET) => setAttribute("NOTSET", NOTSET);

  /// ## WARN (getter)
  Object? get WARN => getAttribute("WARN");

  /// ## WARN (setter)
  set WARN(Object? WARN) => setAttribute("WARN", WARN);

  /// ## WARNING (getter)
  Object? get WARNING => getAttribute("WARNING");

  /// ## WARNING (setter)
  set WARNING(Object? WARNING) => setAttribute("WARNING", WARNING);

  /// ## logMultiprocessing (getter)
  Object? get logMultiprocessing => getAttribute("logMultiprocessing");

  /// ## logMultiprocessing (setter)
  set logMultiprocessing(Object? logMultiprocessing) =>
      setAttribute("logMultiprocessing", logMultiprocessing);

  /// ## logProcesses (getter)
  Object? get logProcesses => getAttribute("logProcesses");

  /// ## logProcesses (setter)
  set logProcesses(Object? logProcesses) =>
      setAttribute("logProcesses", logProcesses);

  /// ## logThreads (getter)
  Object? get logThreads => getAttribute("logThreads");

  /// ## logThreads (setter)
  set logThreads(Object? logThreads) => setAttribute("logThreads", logThreads);

  /// ## raiseExceptions (getter)
  Object? get raiseExceptions => getAttribute("raiseExceptions");

  /// ## raiseExceptions (setter)
  set raiseExceptions(Object? raiseExceptions) =>
      setAttribute("raiseExceptions", raiseExceptions);
}

/// ## atexit
final class atexit extends PythonModule {
  atexit.from(super.pythonModule) : super.from();

  static atexit import() => PythonFfiDart.instance.importModule(
        "atexit",
        atexit.from,
      );
}

/// ## collections
///
/// ### python docstring
///
/// This module implements specialized container datatypes providing
/// alternatives to Python's general purpose built-in containers, dict,
/// list, set, and tuple.
///
/// * namedtuple   factory function for creating tuple subclasses with named fields
/// * deque        list-like container with fast appends and pops on either end
/// * ChainMap     dict-like class for creating a single view of multiple mappings
/// * Counter      dict subclass for counting hashable objects
/// * OrderedDict  dict subclass that remembers the order entries were added
/// * defaultdict  dict subclass that calls a factory function to supply missing values
/// * UserDict     wrapper around dictionary objects for easier dict subclassing
/// * UserList     wrapper around list objects for easier list subclassing
/// * UserString   wrapper around string objects for easier string subclassing
///
/// ### python source
/// ```py
/// '''This module implements specialized container datatypes providing
/// alternatives to Python's general purpose built-in containers, dict,
/// list, set, and tuple.
///
/// * namedtuple   factory function for creating tuple subclasses with named fields
/// * deque        list-like container with fast appends and pops on either end
/// * ChainMap     dict-like class for creating a single view of multiple mappings
/// * Counter      dict subclass for counting hashable objects
/// * OrderedDict  dict subclass that remembers the order entries were added
/// * defaultdict  dict subclass that calls a factory function to supply missing values
/// * UserDict     wrapper around dictionary objects for easier dict subclassing
/// * UserList     wrapper around list objects for easier list subclassing
/// * UserString   wrapper around string objects for easier string subclassing
///
/// '''
///
/// __all__ = [
///     'ChainMap',
///     'Counter',
///     'OrderedDict',
///     'UserDict',
///     'UserList',
///     'UserString',
///     'defaultdict',
///     'deque',
///     'namedtuple',
/// ]
///
/// import _collections_abc
/// import sys as _sys
///
/// from itertools import chain as _chain
/// from itertools import repeat as _repeat
/// from itertools import starmap as _starmap
/// from keyword import iskeyword as _iskeyword
/// from operator import eq as _eq
/// from operator import itemgetter as _itemgetter
/// from reprlib import recursive_repr as _recursive_repr
/// from _weakref import proxy as _proxy
///
/// try:
///     from _collections import deque
/// except ImportError:
///     pass
/// else:
///     _collections_abc.MutableSequence.register(deque)
///
/// try:
///     from _collections import defaultdict
/// except ImportError:
///     pass
///
///
/// ################################################################################
/// ### OrderedDict
/// ################################################################################
///
/// class _OrderedDictKeysView(_collections_abc.KeysView):
///
///     def __reversed__(self):
///         yield from reversed(self._mapping)
///
/// class _OrderedDictItemsView(_collections_abc.ItemsView):
///
///     def __reversed__(self):
///         for key in reversed(self._mapping):
///             yield (key, self._mapping[key])
///
/// class _OrderedDictValuesView(_collections_abc.ValuesView):
///
///     def __reversed__(self):
///         for key in reversed(self._mapping):
///             yield self._mapping[key]
///
/// class _Link(object):
///     __slots__ = 'prev', 'next', 'key', '__weakref__'
///
/// class OrderedDict(dict):
///     'Dictionary that remembers insertion order'
///     # An inherited dict maps keys to values.
///     # The inherited dict provides __getitem__, __len__, __contains__, and get.
///     # The remaining methods are order-aware.
///     # Big-O running times for all methods are the same as regular dictionaries.
///
///     # The internal self.__map dict maps keys to links in a doubly linked list.
///     # The circular doubly linked list starts and ends with a sentinel element.
///     # The sentinel element never gets deleted (this simplifies the algorithm).
///     # The sentinel is in self.__hardroot with a weakref proxy in self.__root.
///     # The prev links are weakref proxies (to prevent circular references).
///     # Individual links are kept alive by the hard reference in self.__map.
///     # Those hard references disappear when a key is deleted from an OrderedDict.
///
///     def __init__(self, other=(), /, **kwds):
///         '''Initialize an ordered dictionary.  The signature is the same as
///         regular dictionaries.  Keyword argument order is preserved.
///         '''
///         try:
///             self.__root
///         except AttributeError:
///             self.__hardroot = _Link()
///             self.__root = root = _proxy(self.__hardroot)
///             root.prev = root.next = root
///             self.__map = {}
///         self.__update(other, **kwds)
///
///     def __setitem__(self, key, value,
///                     dict_setitem=dict.__setitem__, proxy=_proxy, Link=_Link):
///         'od.__setitem__(i, y) <==> od[i]=y'
///         # Setting a new item creates a new link at the end of the linked list,
///         # and the inherited dictionary is updated with the new key/value pair.
///         if key not in self:
///             self.__map[key] = link = Link()
///             root = self.__root
///             last = root.prev
///             link.prev, link.next, link.key = last, root, key
///             last.next = link
///             root.prev = proxy(link)
///         dict_setitem(self, key, value)
///
///     def __delitem__(self, key, dict_delitem=dict.__delitem__):
///         'od.__delitem__(y) <==> del od[y]'
///         # Deleting an existing item uses self.__map to find the link which gets
///         # removed by updating the links in the predecessor and successor nodes.
///         dict_delitem(self, key)
///         link = self.__map.pop(key)
///         link_prev = link.prev
///         link_next = link.next
///         link_prev.next = link_next
///         link_next.prev = link_prev
///         link.prev = None
///         link.next = None
///
///     def __iter__(self):
///         'od.__iter__() <==> iter(od)'
///         # Traverse the linked list in order.
///         root = self.__root
///         curr = root.next
///         while curr is not root:
///             yield curr.key
///             curr = curr.next
///
///     def __reversed__(self):
///         'od.__reversed__() <==> reversed(od)'
///         # Traverse the linked list in reverse order.
///         root = self.__root
///         curr = root.prev
///         while curr is not root:
///             yield curr.key
///             curr = curr.prev
///
///     def clear(self):
///         'od.clear() -> None.  Remove all items from od.'
///         root = self.__root
///         root.prev = root.next = root
///         self.__map.clear()
///         dict.clear(self)
///
///     def popitem(self, last=True):
///         '''Remove and return a (key, value) pair from the dictionary.
///
///         Pairs are returned in LIFO order if last is true or FIFO order if false.
///         '''
///         if not self:
///             raise KeyError('dictionary is empty')
///         root = self.__root
///         if last:
///             link = root.prev
///             link_prev = link.prev
///             link_prev.next = root
///             root.prev = link_prev
///         else:
///             link = root.next
///             link_next = link.next
///             root.next = link_next
///             link_next.prev = root
///         key = link.key
///         del self.__map[key]
///         value = dict.pop(self, key)
///         return key, value
///
///     def move_to_end(self, key, last=True):
///         '''Move an existing element to the end (or beginning if last is false).
///
///         Raise KeyError if the element does not exist.
///         '''
///         link = self.__map[key]
///         link_prev = link.prev
///         link_next = link.next
///         soft_link = link_next.prev
///         link_prev.next = link_next
///         link_next.prev = link_prev
///         root = self.__root
///         if last:
///             last = root.prev
///             link.prev = last
///             link.next = root
///             root.prev = soft_link
///             last.next = link
///         else:
///             first = root.next
///             link.prev = root
///             link.next = first
///             first.prev = soft_link
///             root.next = link
///
///     def __sizeof__(self):
///         sizeof = _sys.getsizeof
///         n = len(self) + 1                       # number of links including root
///         size = sizeof(self.__dict__)            # instance dictionary
///         size += sizeof(self.__map) * 2          # internal dict and inherited dict
///         size += sizeof(self.__hardroot) * n     # link objects
///         size += sizeof(self.__root) * n         # proxy objects
///         return size
///
///     update = __update = _collections_abc.MutableMapping.update
///
///     def keys(self):
///         "D.keys() -> a set-like object providing a view on D's keys"
///         return _OrderedDictKeysView(self)
///
///     def items(self):
///         "D.items() -> a set-like object providing a view on D's items"
///         return _OrderedDictItemsView(self)
///
///     def values(self):
///         "D.values() -> an object providing a view on D's values"
///         return _OrderedDictValuesView(self)
///
///     __ne__ = _collections_abc.MutableMapping.__ne__
///
///     __marker = object()
///
///     def pop(self, key, default=__marker):
///         '''od.pop(k[,d]) -> v, remove specified key and return the corresponding
///         value.  If key is not found, d is returned if given, otherwise KeyError
///         is raised.
///
///         '''
///         marker = self.__marker
///         result = dict.pop(self, key, marker)
///         if result is not marker:
///             # The same as in __delitem__().
///             link = self.__map.pop(key)
///             link_prev = link.prev
///             link_next = link.next
///             link_prev.next = link_next
///             link_next.prev = link_prev
///             link.prev = None
///             link.next = None
///             return result
///         if default is marker:
///             raise KeyError(key)
///         return default
///
///     def setdefault(self, key, default=None):
///         '''Insert key with a value of default if key is not in the dictionary.
///
///         Return the value for key if key is in the dictionary, else default.
///         '''
///         if key in self:
///             return self[key]
///         self[key] = default
///         return default
///
///     @_recursive_repr()
///     def __repr__(self):
///         'od.__repr__() <==> repr(od)'
///         if not self:
///             return '%s()' % (self.__class__.__name__,)
///         return '%s(%r)' % (self.__class__.__name__, list(self.items()))
///
///     def __reduce__(self):
///         'Return state information for pickling'
///         state = self.__getstate__()
///         if state:
///             if isinstance(state, tuple):
///                 state, slots = state
///             else:
///                 slots = {}
///             state = state.copy()
///             slots = slots.copy()
///             for k in vars(OrderedDict()):
///                 state.pop(k, None)
///                 slots.pop(k, None)
///             if slots:
///                 state = state, slots
///             else:
///                 state = state or None
///         return self.__class__, (), state, None, iter(self.items())
///
///     def copy(self):
///         'od.copy() -> a shallow copy of od'
///         return self.__class__(self)
///
///     @classmethod
///     def fromkeys(cls, iterable, value=None):
///         '''Create a new ordered dictionary with keys from iterable and values set to value.
///         '''
///         self = cls()
///         for key in iterable:
///             self[key] = value
///         return self
///
///     def __eq__(self, other):
///         '''od.__eq__(y) <==> od==y.  Comparison to another OD is order-sensitive
///         while comparison to a regular mapping is order-insensitive.
///
///         '''
///         if isinstance(other, OrderedDict):
///             return dict.__eq__(self, other) and all(map(_eq, self, other))
///         return dict.__eq__(self, other)
///
///     def __ior__(self, other):
///         self.update(other)
///         return self
///
///     def __or__(self, other):
///         if not isinstance(other, dict):
///             return NotImplemented
///         new = self.__class__(self)
///         new.update(other)
///         return new
///
///     def __ror__(self, other):
///         if not isinstance(other, dict):
///             return NotImplemented
///         new = self.__class__(other)
///         new.update(self)
///         return new
///
///
/// try:
///     from _collections import OrderedDict
/// except ImportError:
///     # Leave the pure Python version in place.
///     pass
///
///
/// ################################################################################
/// ### namedtuple
/// ################################################################################
///
/// try:
///     from _collections import _tuplegetter
/// except ImportError:
///     _tuplegetter = lambda index, doc: property(_itemgetter(index), doc=doc)
///
/// def namedtuple(typename, field_names, *, rename=False, defaults=None, module=None):
///     """Returns a new subclass of tuple with named fields.
///
///     >>> Point = namedtuple('Point', ['x', 'y'])
///     >>> Point.__doc__                   # docstring for the new class
///     'Point(x, y)'
///     >>> p = Point(11, y=22)             # instantiate with positional args or keywords
///     >>> p[0] + p[1]                     # indexable like a plain tuple
///     33
///     >>> x, y = p                        # unpack like a regular tuple
///     >>> x, y
///     (11, 22)
///     >>> p.x + p.y                       # fields also accessible by name
///     33
///     >>> d = p._asdict()                 # convert to a dictionary
///     >>> d['x']
///     11
///     >>> Point(**d)                      # convert from a dictionary
///     Point(x=11, y=22)
///     >>> p._replace(x=100)               # _replace() is like str.replace() but targets named fields
///     Point(x=100, y=22)
///
///     """
///
///     # Validate the field names.  At the user's option, either generate an error
///     # message or automatically replace the field name with a valid name.
///     if isinstance(field_names, str):
///         field_names = field_names.replace(',', ' ').split()
///     field_names = list(map(str, field_names))
///     typename = _sys.intern(str(typename))
///
///     if rename:
///         seen = set()
///         for index, name in enumerate(field_names):
///             if (not name.isidentifier()
///                 or _iskeyword(name)
///                 or name.startswith('_')
///                 or name in seen):
///                 field_names[index] = f'_{index}'
///             seen.add(name)
///
///     for name in [typename] + field_names:
///         if type(name) is not str:
///             raise TypeError('Type names and field names must be strings')
///         if not name.isidentifier():
///             raise ValueError('Type names and field names must be valid '
///                              f'identifiers: {name!r}')
///         if _iskeyword(name):
///             raise ValueError('Type names and field names cannot be a '
///                              f'keyword: {name!r}')
///
///     seen = set()
///     for name in field_names:
///         if name.startswith('_') and not rename:
///             raise ValueError('Field names cannot start with an underscore: '
///                              f'{name!r}')
///         if name in seen:
///             raise ValueError(f'Encountered duplicate field name: {name!r}')
///         seen.add(name)
///
///     field_defaults = {}
///     if defaults is not None:
///         defaults = tuple(defaults)
///         if len(defaults) > len(field_names):
///             raise TypeError('Got more default values than field names')
///         field_defaults = dict(reversed(list(zip(reversed(field_names),
///                                                 reversed(defaults)))))
///
///     # Variables used in the methods and docstrings
///     field_names = tuple(map(_sys.intern, field_names))
///     num_fields = len(field_names)
///     arg_list = ', '.join(field_names)
///     if num_fields == 1:
///         arg_list += ','
///     repr_fmt = '(' + ', '.join(f'{name}=%r' for name in field_names) + ')'
///     tuple_new = tuple.__new__
///     _dict, _tuple, _len, _map, _zip = dict, tuple, len, map, zip
///
///     # Create all the named tuple methods to be added to the class namespace
///
///     namespace = {
///         '_tuple_new': tuple_new,
///         '__builtins__': {},
///         '__name__': f'namedtuple_{typename}',
///     }
///     code = f'lambda _cls, {arg_list}: _tuple_new(_cls, ({arg_list}))'
///     __new__ = eval(code, namespace)
///     __new__.__name__ = '__new__'
///     __new__.__doc__ = f'Create new instance of {typename}({arg_list})'
///     if defaults is not None:
///         __new__.__defaults__ = defaults
///
///     @classmethod
///     def _make(cls, iterable):
///         result = tuple_new(cls, iterable)
///         if _len(result) != num_fields:
///             raise TypeError(f'Expected {num_fields} arguments, got {len(result)}')
///         return result
///
///     _make.__func__.__doc__ = (f'Make a new {typename} object from a sequence '
///                               'or iterable')
///
///     def _replace(self, /, **kwds):
///         result = self._make(_map(kwds.pop, field_names, self))
///         if kwds:
///             raise ValueError(f'Got unexpected field names: {list(kwds)!r}')
///         return result
///
///     _replace.__doc__ = (f'Return a new {typename} object replacing specified '
///                         'fields with new values')
///
///     def __repr__(self):
///         'Return a nicely formatted representation string'
///         return self.__class__.__name__ + repr_fmt % self
///
///     def _asdict(self):
///         'Return a new dict which maps field names to their values.'
///         return _dict(_zip(self._fields, self))
///
///     def __getnewargs__(self):
///         'Return self as a plain tuple.  Used by copy and pickle.'
///         return _tuple(self)
///
///     # Modify function metadata to help with introspection and debugging
///     for method in (
///         __new__,
///         _make.__func__,
///         _replace,
///         __repr__,
///         _asdict,
///         __getnewargs__,
///     ):
///         method.__qualname__ = f'{typename}.{method.__name__}'
///
///     # Build-up the class namespace dictionary
///     # and use type() to build the result class
///     class_namespace = {
///         '__doc__': f'{typename}({arg_list})',
///         '__slots__': (),
///         '_fields': field_names,
///         '_field_defaults': field_defaults,
///         '__new__': __new__,
///         '_make': _make,
///         '_replace': _replace,
///         '__repr__': __repr__,
///         '_asdict': _asdict,
///         '__getnewargs__': __getnewargs__,
///         '__match_args__': field_names,
///     }
///     for index, name in enumerate(field_names):
///         doc = _sys.intern(f'Alias for field number {index}')
///         class_namespace[name] = _tuplegetter(index, doc)
///
///     result = type(typename, (tuple,), class_namespace)
///
///     # For pickling to work, the __module__ variable needs to be set to the frame
///     # where the named tuple is created.  Bypass this step in environments where
///     # sys._getframe is not defined (Jython for example) or sys._getframe is not
///     # defined for arguments greater than 0 (IronPython), or where the user has
///     # specified a particular module.
///     if module is None:
///         try:
///             module = _sys._getframe(1).f_globals.get('__name__', '__main__')
///         except (AttributeError, ValueError):
///             pass
///     if module is not None:
///         result.__module__ = module
///
///     return result
///
///
/// ########################################################################
/// ###  Counter
/// ########################################################################
///
/// def _count_elements(mapping, iterable):
///     'Tally elements from the iterable.'
///     mapping_get = mapping.get
///     for elem in iterable:
///         mapping[elem] = mapping_get(elem, 0) + 1
///
/// try:                                    # Load C helper function if available
///     from _collections import _count_elements
/// except ImportError:
///     pass
///
/// class Counter(dict):
///     '''Dict subclass for counting hashable items.  Sometimes called a bag
///     or multiset.  Elements are stored as dictionary keys and their counts
///     are stored as dictionary values.
///
///     >>> c = Counter('abcdeabcdabcaba')  # count elements from a string
///
///     >>> c.most_common(3)                # three most common elements
///     [('a', 5), ('b', 4), ('c', 3)]
///     >>> sorted(c)                       # list all unique elements
///     ['a', 'b', 'c', 'd', 'e']
///     >>> ''.join(sorted(c.elements()))   # list elements with repetitions
///     'aaaaabbbbcccdde'
///     >>> sum(c.values())                 # total of all counts
///     15
///
///     >>> c['a']                          # count of letter 'a'
///     5
///     >>> for elem in 'shazam':           # update counts from an iterable
///     ...     c[elem] += 1                # by adding 1 to each element's count
///     >>> c['a']                          # now there are seven 'a'
///     7
///     >>> del c['b']                      # remove all 'b'
///     >>> c['b']                          # now there are zero 'b'
///     0
///
///     >>> d = Counter('simsalabim')       # make another counter
///     >>> c.update(d)                     # add in the second counter
///     >>> c['a']                          # now there are nine 'a'
///     9
///
///     >>> c.clear()                       # empty the counter
///     >>> c
///     Counter()
///
///     Note:  If a count is set to zero or reduced to zero, it will remain
///     in the counter until the entry is deleted or the counter is cleared:
///
///     >>> c = Counter('aaabbc')
///     >>> c['b'] -= 2                     # reduce the count of 'b' by two
///     >>> c.most_common()                 # 'b' is still in, but its count is zero
///     [('a', 3), ('c', 1), ('b', 0)]
///
///     '''
///     # References:
///     #   http://en.wikipedia.org/wiki/Multiset
///     #   http://www.gnu.org/software/smalltalk/manual-base/html_node/Bag.html
///     #   http://www.demo2s.com/Tutorial/Cpp/0380__set-multiset/Catalog0380__set-multiset.htm
///     #   http://code.activestate.com/recipes/259174/
///     #   Knuth, TAOCP Vol. II section 4.6.3
///
///     def __init__(self, iterable=None, /, **kwds):
///         '''Create a new, empty Counter object.  And if given, count elements
///         from an input iterable.  Or, initialize the count from another mapping
///         of elements to their counts.
///
///         >>> c = Counter()                           # a new, empty counter
///         >>> c = Counter('gallahad')                 # a new counter from an iterable
///         >>> c = Counter({'a': 4, 'b': 2})           # a new counter from a mapping
///         >>> c = Counter(a=4, b=2)                   # a new counter from keyword args
///
///         '''
///         super().__init__()
///         self.update(iterable, **kwds)
///
///     def __missing__(self, key):
///         'The count of elements not in the Counter is zero.'
///         # Needed so that self[missing_item] does not raise KeyError
///         return 0
///
///     def total(self):
///         'Sum of the counts'
///         return sum(self.values())
///
///     def most_common(self, n=None):
///         '''List the n most common elements and their counts from the most
///         common to the least.  If n is None, then list all element counts.
///
///         >>> Counter('abracadabra').most_common(3)
///         [('a', 5), ('b', 2), ('r', 2)]
///
///         '''
///         # Emulate Bag.sortedByCount from Smalltalk
///         if n is None:
///             return sorted(self.items(), key=_itemgetter(1), reverse=True)
///
///         # Lazy import to speedup Python startup time
///         import heapq
///         return heapq.nlargest(n, self.items(), key=_itemgetter(1))
///
///     def elements(self):
///         '''Iterator over elements repeating each as many times as its count.
///
///         >>> c = Counter('ABCABC')
///         >>> sorted(c.elements())
///         ['A', 'A', 'B', 'B', 'C', 'C']
///
///         # Knuth's example for prime factors of 1836:  2**2 * 3**3 * 17**1
///         >>> import math
///         >>> prime_factors = Counter({2: 2, 3: 3, 17: 1})
///         >>> math.prod(prime_factors.elements())
///         1836
///
///         Note, if an element's count has been set to zero or is a negative
///         number, elements() will ignore it.
///
///         '''
///         # Emulate Bag.do from Smalltalk and Multiset.begin from C++.
///         return _chain.from_iterable(_starmap(_repeat, self.items()))
///
///     # Override dict methods where necessary
///
///     @classmethod
///     def fromkeys(cls, iterable, v=None):
///         # There is no equivalent method for counters because the semantics
///         # would be ambiguous in cases such as Counter.fromkeys('aaabbc', v=2).
///         # Initializing counters to zero values isn't necessary because zero
///         # is already the default value for counter lookups.  Initializing
///         # to one is easily accomplished with Counter(set(iterable)).  For
///         # more exotic cases, create a dictionary first using a dictionary
///         # comprehension or dict.fromkeys().
///         raise NotImplementedError(
///             'Counter.fromkeys() is undefined.  Use Counter(iterable) instead.')
///
///     def update(self, iterable=None, /, **kwds):
///         '''Like dict.update() but add counts instead of replacing them.
///
///         Source can be an iterable, a dictionary, or another Counter instance.
///
///         >>> c = Counter('which')
///         >>> c.update('witch')           # add elements from another iterable
///         >>> d = Counter('watch')
///         >>> c.update(d)                 # add elements from another counter
///         >>> c['h']                      # four 'h' in which, witch, and watch
///         4
///
///         '''
///         # The regular dict.update() operation makes no sense here because the
///         # replace behavior results in the some of original untouched counts
///         # being mixed-in with all of the other counts for a mismash that
///         # doesn't have a straight-forward interpretation in most counting
///         # contexts.  Instead, we implement straight-addition.  Both the inputs
///         # and outputs are allowed to contain zero and negative counts.
///
///         if iterable is not None:
///             if isinstance(iterable, _collections_abc.Mapping):
///                 if self:
///                     self_get = self.get
///                     for elem, count in iterable.items():
///                         self[elem] = count + self_get(elem, 0)
///                 else:
///                     # fast path when counter is empty
///                     super().update(iterable)
///             else:
///                 _count_elements(self, iterable)
///         if kwds:
///             self.update(kwds)
///
///     def subtract(self, iterable=None, /, **kwds):
///         '''Like dict.update() but subtracts counts instead of replacing them.
///         Counts can be reduced below zero.  Both the inputs and outputs are
///         allowed to contain zero and negative counts.
///
///         Source can be an iterable, a dictionary, or another Counter instance.
///
///         >>> c = Counter('which')
///         >>> c.subtract('witch')             # subtract elements from another iterable
///         >>> c.subtract(Counter('watch'))    # subtract elements from another counter
///         >>> c['h']                          # 2 in which, minus 1 in witch, minus 1 in watch
///         0
///         >>> c['w']                          # 1 in which, minus 1 in witch, minus 1 in watch
///         -1
///
///         '''
///         if iterable is not None:
///             self_get = self.get
///             if isinstance(iterable, _collections_abc.Mapping):
///                 for elem, count in iterable.items():
///                     self[elem] = self_get(elem, 0) - count
///             else:
///                 for elem in iterable:
///                     self[elem] = self_get(elem, 0) - 1
///         if kwds:
///             self.subtract(kwds)
///
///     def copy(self):
///         'Return a shallow copy.'
///         return self.__class__(self)
///
///     def __reduce__(self):
///         return self.__class__, (dict(self),)
///
///     def __delitem__(self, elem):
///         'Like dict.__delitem__() but does not raise KeyError for missing values.'
///         if elem in self:
///             super().__delitem__(elem)
///
///     def __repr__(self):
///         if not self:
///             return f'{self.__class__.__name__}()'
///         try:
///             # dict() preserves the ordering returned by most_common()
///             d = dict(self.most_common())
///         except TypeError:
///             # handle case where values are not orderable
///             d = dict(self)
///         return f'{self.__class__.__name__}({d!r})'
///
///     # Multiset-style mathematical operations discussed in:
///     #       Knuth TAOCP Volume II section 4.6.3 exercise 19
///     #       and at http://en.wikipedia.org/wiki/Multiset
///     #
///     # Outputs guaranteed to only include positive counts.
///     #
///     # To strip negative and zero counts, add-in an empty counter:
///     #       c += Counter()
///     #
///     # Results are ordered according to when an element is first
///     # encountered in the left operand and then by the order
///     # encountered in the right operand.
///     #
///     # When the multiplicities are all zero or one, multiset operations
///     # are guaranteed to be equivalent to the corresponding operations
///     # for regular sets.
///     #     Given counter multisets such as:
///     #         cp = Counter(a=1, b=0, c=1)
///     #         cq = Counter(c=1, d=0, e=1)
///     #     The corresponding regular sets would be:
///     #         sp = {'a', 'c'}
///     #         sq = {'c', 'e'}
///     #     All of the following relations would hold:
///     #         set(cp + cq) == sp | sq
///     #         set(cp - cq) == sp - sq
///     #         set(cp | cq) == sp | sq
///     #         set(cp & cq) == sp & sq
///     #         (cp == cq) == (sp == sq)
///     #         (cp != cq) == (sp != sq)
///     #         (cp <= cq) == (sp <= sq)
///     #         (cp < cq) == (sp < sq)
///     #         (cp >= cq) == (sp >= sq)
///     #         (cp > cq) == (sp > sq)
///
///     def __eq__(self, other):
///         'True if all counts agree. Missing counts are treated as zero.'
///         if not isinstance(other, Counter):
///             return NotImplemented
///         return all(self[e] == other[e] for c in (self, other) for e in c)
///
///     def __ne__(self, other):
///         'True if any counts disagree. Missing counts are treated as zero.'
///         if not isinstance(other, Counter):
///             return NotImplemented
///         return not self == other
///
///     def __le__(self, other):
///         'True if all counts in self are a subset of those in other.'
///         if not isinstance(other, Counter):
///             return NotImplemented
///         return all(self[e] <= other[e] for c in (self, other) for e in c)
///
///     def __lt__(self, other):
///         'True if all counts in self are a proper subset of those in other.'
///         if not isinstance(other, Counter):
///             return NotImplemented
///         return self <= other and self != other
///
///     def __ge__(self, other):
///         'True if all counts in self are a superset of those in other.'
///         if not isinstance(other, Counter):
///             return NotImplemented
///         return all(self[e] >= other[e] for c in (self, other) for e in c)
///
///     def __gt__(self, other):
///         'True if all counts in self are a proper superset of those in other.'
///         if not isinstance(other, Counter):
///             return NotImplemented
///         return self >= other and self != other
///
///     def __add__(self, other):
///         '''Add counts from two counters.
///
///         >>> Counter('abbb') + Counter('bcc')
///         Counter({'b': 4, 'c': 2, 'a': 1})
///
///         '''
///         if not isinstance(other, Counter):
///             return NotImplemented
///         result = Counter()
///         for elem, count in self.items():
///             newcount = count + other[elem]
///             if newcount > 0:
///                 result[elem] = newcount
///         for elem, count in other.items():
///             if elem not in self and count > 0:
///                 result[elem] = count
///         return result
///
///     def __sub__(self, other):
///         ''' Subtract count, but keep only results with positive counts.
///
///         >>> Counter('abbbc') - Counter('bccd')
///         Counter({'b': 2, 'a': 1})
///
///         '''
///         if not isinstance(other, Counter):
///             return NotImplemented
///         result = Counter()
///         for elem, count in self.items():
///             newcount = count - other[elem]
///             if newcount > 0:
///                 result[elem] = newcount
///         for elem, count in other.items():
///             if elem not in self and count < 0:
///                 result[elem] = 0 - count
///         return result
///
///     def __or__(self, other):
///         '''Union is the maximum of value in either of the input counters.
///
///         >>> Counter('abbb') | Counter('bcc')
///         Counter({'b': 3, 'c': 2, 'a': 1})
///
///         '''
///         if not isinstance(other, Counter):
///             return NotImplemented
///         result = Counter()
///         for elem, count in self.items():
///             other_count = other[elem]
///             newcount = other_count if count < other_count else count
///             if newcount > 0:
///                 result[elem] = newcount
///         for elem, count in other.items():
///             if elem not in self and count > 0:
///                 result[elem] = count
///         return result
///
///     def __and__(self, other):
///         ''' Intersection is the minimum of corresponding counts.
///
///         >>> Counter('abbb') & Counter('bcc')
///         Counter({'b': 1})
///
///         '''
///         if not isinstance(other, Counter):
///             return NotImplemented
///         result = Counter()
///         for elem, count in self.items():
///             other_count = other[elem]
///             newcount = count if count < other_count else other_count
///             if newcount > 0:
///                 result[elem] = newcount
///         return result
///
///     def __pos__(self):
///         'Adds an empty counter, effectively stripping negative and zero counts'
///         result = Counter()
///         for elem, count in self.items():
///             if count > 0:
///                 result[elem] = count
///         return result
///
///     def __neg__(self):
///         '''Subtracts from an empty counter.  Strips positive and zero counts,
///         and flips the sign on negative counts.
///
///         '''
///         result = Counter()
///         for elem, count in self.items():
///             if count < 0:
///                 result[elem] = 0 - count
///         return result
///
///     def _keep_positive(self):
///         '''Internal method to strip elements with a negative or zero count'''
///         nonpositive = [elem for elem, count in self.items() if not count > 0]
///         for elem in nonpositive:
///             del self[elem]
///         return self
///
///     def __iadd__(self, other):
///         '''Inplace add from another counter, keeping only positive counts.
///
///         >>> c = Counter('abbb')
///         >>> c += Counter('bcc')
///         >>> c
///         Counter({'b': 4, 'c': 2, 'a': 1})
///
///         '''
///         for elem, count in other.items():
///             self[elem] += count
///         return self._keep_positive()
///
///     def __isub__(self, other):
///         '''Inplace subtract counter, but keep only results with positive counts.
///
///         >>> c = Counter('abbbc')
///         >>> c -= Counter('bccd')
///         >>> c
///         Counter({'b': 2, 'a': 1})
///
///         '''
///         for elem, count in other.items():
///             self[elem] -= count
///         return self._keep_positive()
///
///     def __ior__(self, other):
///         '''Inplace union is the maximum of value from either counter.
///
///         >>> c = Counter('abbb')
///         >>> c |= Counter('bcc')
///         >>> c
///         Counter({'b': 3, 'c': 2, 'a': 1})
///
///         '''
///         for elem, other_count in other.items():
///             count = self[elem]
///             if other_count > count:
///                 self[elem] = other_count
///         return self._keep_positive()
///
///     def __iand__(self, other):
///         '''Inplace intersection is the minimum of corresponding counts.
///
///         >>> c = Counter('abbb')
///         >>> c &= Counter('bcc')
///         >>> c
///         Counter({'b': 1})
///
///         '''
///         for elem, count in self.items():
///             other_count = other[elem]
///             if other_count < count:
///                 self[elem] = other_count
///         return self._keep_positive()
///
///
/// ########################################################################
/// ###  ChainMap
/// ########################################################################
///
/// class ChainMap(_collections_abc.MutableMapping):
///     ''' A ChainMap groups multiple dicts (or other mappings) together
///     to create a single, updateable view.
///
///     The underlying mappings are stored in a list.  That list is public and can
///     be accessed or updated using the *maps* attribute.  There is no other
///     state.
///
///     Lookups search the underlying mappings successively until a key is found.
///     In contrast, writes, updates, and deletions only operate on the first
///     mapping.
///
///     '''
///
///     def __init__(self, *maps):
///         '''Initialize a ChainMap by setting *maps* to the given mappings.
///         If no mappings are provided, a single empty dictionary is used.
///
///         '''
///         self.maps = list(maps) or [{}]          # always at least one map
///
///     def __missing__(self, key):
///         raise KeyError(key)
///
///     def __getitem__(self, key):
///         for mapping in self.maps:
///             try:
///                 return mapping[key]             # can't use 'key in mapping' with defaultdict
///             except KeyError:
///                 pass
///         return self.__missing__(key)            # support subclasses that define __missing__
///
///     def get(self, key, default=None):
///         return self[key] if key in self else default
///
///     def __len__(self):
///         return len(set().union(*self.maps))     # reuses stored hash values if possible
///
///     def __iter__(self):
///         d = {}
///         for mapping in reversed(self.maps):
///             d.update(dict.fromkeys(mapping))    # reuses stored hash values if possible
///         return iter(d)
///
///     def __contains__(self, key):
///         return any(key in m for m in self.maps)
///
///     def __bool__(self):
///         return any(self.maps)
///
///     @_recursive_repr()
///     def __repr__(self):
///         return f'{self.__class__.__name__}({", ".join(map(repr, self.maps))})'
///
///     @classmethod
///     def fromkeys(cls, iterable, *args):
///         'Create a ChainMap with a single dict created from the iterable.'
///         return cls(dict.fromkeys(iterable, *args))
///
///     def copy(self):
///         'New ChainMap or subclass with a new copy of maps[0] and refs to maps[1:]'
///         return self.__class__(self.maps[0].copy(), *self.maps[1:])
///
///     __copy__ = copy
///
///     def new_child(self, m=None, **kwargs):      # like Django's Context.push()
///         '''New ChainMap with a new map followed by all previous maps.
///         If no map is provided, an empty dict is used.
///         Keyword arguments update the map or new empty dict.
///         '''
///         if m is None:
///             m = kwargs
///         elif kwargs:
///             m.update(kwargs)
///         return self.__class__(m, *self.maps)
///
///     @property
///     def parents(self):                          # like Django's Context.pop()
///         'New ChainMap from maps[1:].'
///         return self.__class__(*self.maps[1:])
///
///     def __setitem__(self, key, value):
///         self.maps[0][key] = value
///
///     def __delitem__(self, key):
///         try:
///             del self.maps[0][key]
///         except KeyError:
///             raise KeyError(f'Key not found in the first mapping: {key!r}')
///
///     def popitem(self):
///         'Remove and return an item pair from maps[0]. Raise KeyError is maps[0] is empty.'
///         try:
///             return self.maps[0].popitem()
///         except KeyError:
///             raise KeyError('No keys found in the first mapping.')
///
///     def pop(self, key, *args):
///         'Remove *key* from maps[0] and return its value. Raise KeyError if *key* not in maps[0].'
///         try:
///             return self.maps[0].pop(key, *args)
///         except KeyError:
///             raise KeyError(f'Key not found in the first mapping: {key!r}')
///
///     def clear(self):
///         'Clear maps[0], leaving maps[1:] intact.'
///         self.maps[0].clear()
///
///     def __ior__(self, other):
///         self.maps[0].update(other)
///         return self
///
///     def __or__(self, other):
///         if not isinstance(other, _collections_abc.Mapping):
///             return NotImplemented
///         m = self.copy()
///         m.maps[0].update(other)
///         return m
///
///     def __ror__(self, other):
///         if not isinstance(other, _collections_abc.Mapping):
///             return NotImplemented
///         m = dict(other)
///         for child in reversed(self.maps):
///             m.update(child)
///         return self.__class__(m)
///
///
/// ################################################################################
/// ### UserDict
/// ################################################################################
///
/// class UserDict(_collections_abc.MutableMapping):
///
///     # Start by filling-out the abstract methods
///     def __init__(self, dict=None, /, **kwargs):
///         self.data = {}
///         if dict is not None:
///             self.update(dict)
///         if kwargs:
///             self.update(kwargs)
///
///     def __len__(self):
///         return len(self.data)
///
///     def __getitem__(self, key):
///         if key in self.data:
///             return self.data[key]
///         if hasattr(self.__class__, "__missing__"):
///             return self.__class__.__missing__(self, key)
///         raise KeyError(key)
///
///     def __setitem__(self, key, item):
///         self.data[key] = item
///
///     def __delitem__(self, key):
///         del self.data[key]
///
///     def __iter__(self):
///         return iter(self.data)
///
///     # Modify __contains__ to work correctly when __missing__ is present
///     def __contains__(self, key):
///         return key in self.data
///
///     # Now, add the methods in dicts but not in MutableMapping
///     def __repr__(self):
///         return repr(self.data)
///
///     def __or__(self, other):
///         if isinstance(other, UserDict):
///             return self.__class__(self.data | other.data)
///         if isinstance(other, dict):
///             return self.__class__(self.data | other)
///         return NotImplemented
///
///     def __ror__(self, other):
///         if isinstance(other, UserDict):
///             return self.__class__(other.data | self.data)
///         if isinstance(other, dict):
///             return self.__class__(other | self.data)
///         return NotImplemented
///
///     def __ior__(self, other):
///         if isinstance(other, UserDict):
///             self.data |= other.data
///         else:
///             self.data |= other
///         return self
///
///     def __copy__(self):
///         inst = self.__class__.__new__(self.__class__)
///         inst.__dict__.update(self.__dict__)
///         # Create a copy and avoid triggering descriptors
///         inst.__dict__["data"] = self.__dict__["data"].copy()
///         return inst
///
///     def copy(self):
///         if self.__class__ is UserDict:
///             return UserDict(self.data.copy())
///         import copy
///         data = self.data
///         try:
///             self.data = {}
///             c = copy.copy(self)
///         finally:
///             self.data = data
///         c.update(self)
///         return c
///
///     @classmethod
///     def fromkeys(cls, iterable, value=None):
///         d = cls()
///         for key in iterable:
///             d[key] = value
///         return d
///
///
/// ################################################################################
/// ### UserList
/// ################################################################################
///
/// class UserList(_collections_abc.MutableSequence):
///     """A more or less complete user-defined wrapper around list objects."""
///
///     def __init__(self, initlist=None):
///         self.data = []
///         if initlist is not None:
///             # XXX should this accept an arbitrary sequence?
///             if type(initlist) == type(self.data):
///                 self.data[:] = initlist
///             elif isinstance(initlist, UserList):
///                 self.data[:] = initlist.data[:]
///             else:
///                 self.data = list(initlist)
///
///     def __repr__(self):
///         return repr(self.data)
///
///     def __lt__(self, other):
///         return self.data < self.__cast(other)
///
///     def __le__(self, other):
///         return self.data <= self.__cast(other)
///
///     def __eq__(self, other):
///         return self.data == self.__cast(other)
///
///     def __gt__(self, other):
///         return self.data > self.__cast(other)
///
///     def __ge__(self, other):
///         return self.data >= self.__cast(other)
///
///     def __cast(self, other):
///         return other.data if isinstance(other, UserList) else other
///
///     def __contains__(self, item):
///         return item in self.data
///
///     def __len__(self):
///         return len(self.data)
///
///     def __getitem__(self, i):
///         if isinstance(i, slice):
///             return self.__class__(self.data[i])
///         else:
///             return self.data[i]
///
///     def __setitem__(self, i, item):
///         self.data[i] = item
///
///     def __delitem__(self, i):
///         del self.data[i]
///
///     def __add__(self, other):
///         if isinstance(other, UserList):
///             return self.__class__(self.data + other.data)
///         elif isinstance(other, type(self.data)):
///             return self.__class__(self.data + other)
///         return self.__class__(self.data + list(other))
///
///     def __radd__(self, other):
///         if isinstance(other, UserList):
///             return self.__class__(other.data + self.data)
///         elif isinstance(other, type(self.data)):
///             return self.__class__(other + self.data)
///         return self.__class__(list(other) + self.data)
///
///     def __iadd__(self, other):
///         if isinstance(other, UserList):
///             self.data += other.data
///         elif isinstance(other, type(self.data)):
///             self.data += other
///         else:
///             self.data += list(other)
///         return self
///
///     def __mul__(self, n):
///         return self.__class__(self.data * n)
///
///     __rmul__ = __mul__
///
///     def __imul__(self, n):
///         self.data *= n
///         return self
///
///     def __copy__(self):
///         inst = self.__class__.__new__(self.__class__)
///         inst.__dict__.update(self.__dict__)
///         # Create a copy and avoid triggering descriptors
///         inst.__dict__["data"] = self.__dict__["data"][:]
///         return inst
///
///     def append(self, item):
///         self.data.append(item)
///
///     def insert(self, i, item):
///         self.data.insert(i, item)
///
///     def pop(self, i=-1):
///         return self.data.pop(i)
///
///     def remove(self, item):
///         self.data.remove(item)
///
///     def clear(self):
///         self.data.clear()
///
///     def copy(self):
///         return self.__class__(self)
///
///     def count(self, item):
///         return self.data.count(item)
///
///     def index(self, item, *args):
///         return self.data.index(item, *args)
///
///     def reverse(self):
///         self.data.reverse()
///
///     def sort(self, /, *args, **kwds):
///         self.data.sort(*args, **kwds)
///
///     def extend(self, other):
///         if isinstance(other, UserList):
///             self.data.extend(other.data)
///         else:
///             self.data.extend(other)
///
///
/// ################################################################################
/// ### UserString
/// ################################################################################
///
/// class UserString(_collections_abc.Sequence):
///
///     def __init__(self, seq):
///         if isinstance(seq, str):
///             self.data = seq
///         elif isinstance(seq, UserString):
///             self.data = seq.data[:]
///         else:
///             self.data = str(seq)
///
///     def __str__(self):
///         return str(self.data)
///
///     def __repr__(self):
///         return repr(self.data)
///
///     def __int__(self):
///         return int(self.data)
///
///     def __float__(self):
///         return float(self.data)
///
///     def __complex__(self):
///         return complex(self.data)
///
///     def __hash__(self):
///         return hash(self.data)
///
///     def __getnewargs__(self):
///         return (self.data[:],)
///
///     def __eq__(self, string):
///         if isinstance(string, UserString):
///             return self.data == string.data
///         return self.data == string
///
///     def __lt__(self, string):
///         if isinstance(string, UserString):
///             return self.data < string.data
///         return self.data < string
///
///     def __le__(self, string):
///         if isinstance(string, UserString):
///             return self.data <= string.data
///         return self.data <= string
///
///     def __gt__(self, string):
///         if isinstance(string, UserString):
///             return self.data > string.data
///         return self.data > string
///
///     def __ge__(self, string):
///         if isinstance(string, UserString):
///             return self.data >= string.data
///         return self.data >= string
///
///     def __contains__(self, char):
///         if isinstance(char, UserString):
///             char = char.data
///         return char in self.data
///
///     def __len__(self):
///         return len(self.data)
///
///     def __getitem__(self, index):
///         return self.__class__(self.data[index])
///
///     def __add__(self, other):
///         if isinstance(other, UserString):
///             return self.__class__(self.data + other.data)
///         elif isinstance(other, str):
///             return self.__class__(self.data + other)
///         return self.__class__(self.data + str(other))
///
///     def __radd__(self, other):
///         if isinstance(other, str):
///             return self.__class__(other + self.data)
///         return self.__class__(str(other) + self.data)
///
///     def __mul__(self, n):
///         return self.__class__(self.data * n)
///
///     __rmul__ = __mul__
///
///     def __mod__(self, args):
///         return self.__class__(self.data % args)
///
///     def __rmod__(self, template):
///         return self.__class__(str(template) % self)
///
///     # the following methods are defined in alphabetical order:
///     def capitalize(self):
///         return self.__class__(self.data.capitalize())
///
///     def casefold(self):
///         return self.__class__(self.data.casefold())
///
///     def center(self, width, *args):
///         return self.__class__(self.data.center(width, *args))
///
///     def count(self, sub, start=0, end=_sys.maxsize):
///         if isinstance(sub, UserString):
///             sub = sub.data
///         return self.data.count(sub, start, end)
///
///     def removeprefix(self, prefix, /):
///         if isinstance(prefix, UserString):
///             prefix = prefix.data
///         return self.__class__(self.data.removeprefix(prefix))
///
///     def removesuffix(self, suffix, /):
///         if isinstance(suffix, UserString):
///             suffix = suffix.data
///         return self.__class__(self.data.removesuffix(suffix))
///
///     def encode(self, encoding='utf-8', errors='strict'):
///         encoding = 'utf-8' if encoding is None else encoding
///         errors = 'strict' if errors is None else errors
///         return self.data.encode(encoding, errors)
///
///     def endswith(self, suffix, start=0, end=_sys.maxsize):
///         return self.data.endswith(suffix, start, end)
///
///     def expandtabs(self, tabsize=8):
///         return self.__class__(self.data.expandtabs(tabsize))
///
///     def find(self, sub, start=0, end=_sys.maxsize):
///         if isinstance(sub, UserString):
///             sub = sub.data
///         return self.data.find(sub, start, end)
///
///     def format(self, /, *args, **kwds):
///         return self.data.format(*args, **kwds)
///
///     def format_map(self, mapping):
///         return self.data.format_map(mapping)
///
///     def index(self, sub, start=0, end=_sys.maxsize):
///         return self.data.index(sub, start, end)
///
///     def isalpha(self):
///         return self.data.isalpha()
///
///     def isalnum(self):
///         return self.data.isalnum()
///
///     def isascii(self):
///         return self.data.isascii()
///
///     def isdecimal(self):
///         return self.data.isdecimal()
///
///     def isdigit(self):
///         return self.data.isdigit()
///
///     def isidentifier(self):
///         return self.data.isidentifier()
///
///     def islower(self):
///         return self.data.islower()
///
///     def isnumeric(self):
///         return self.data.isnumeric()
///
///     def isprintable(self):
///         return self.data.isprintable()
///
///     def isspace(self):
///         return self.data.isspace()
///
///     def istitle(self):
///         return self.data.istitle()
///
///     def isupper(self):
///         return self.data.isupper()
///
///     def join(self, seq):
///         return self.data.join(seq)
///
///     def ljust(self, width, *args):
///         return self.__class__(self.data.ljust(width, *args))
///
///     def lower(self):
///         return self.__class__(self.data.lower())
///
///     def lstrip(self, chars=None):
///         return self.__class__(self.data.lstrip(chars))
///
///     maketrans = str.maketrans
///
///     def partition(self, sep):
///         return self.data.partition(sep)
///
///     def replace(self, old, new, maxsplit=-1):
///         if isinstance(old, UserString):
///             old = old.data
///         if isinstance(new, UserString):
///             new = new.data
///         return self.__class__(self.data.replace(old, new, maxsplit))
///
///     def rfind(self, sub, start=0, end=_sys.maxsize):
///         if isinstance(sub, UserString):
///             sub = sub.data
///         return self.data.rfind(sub, start, end)
///
///     def rindex(self, sub, start=0, end=_sys.maxsize):
///         return self.data.rindex(sub, start, end)
///
///     def rjust(self, width, *args):
///         return self.__class__(self.data.rjust(width, *args))
///
///     def rpartition(self, sep):
///         return self.data.rpartition(sep)
///
///     def rstrip(self, chars=None):
///         return self.__class__(self.data.rstrip(chars))
///
///     def split(self, sep=None, maxsplit=-1):
///         return self.data.split(sep, maxsplit)
///
///     def rsplit(self, sep=None, maxsplit=-1):
///         return self.data.rsplit(sep, maxsplit)
///
///     def splitlines(self, keepends=False):
///         return self.data.splitlines(keepends)
///
///     def startswith(self, prefix, start=0, end=_sys.maxsize):
///         return self.data.startswith(prefix, start, end)
///
///     def strip(self, chars=None):
///         return self.__class__(self.data.strip(chars))
///
///     def swapcase(self):
///         return self.__class__(self.data.swapcase())
///
///     def title(self):
///         return self.__class__(self.data.title())
///
///     def translate(self, *args):
///         return self.__class__(self.data.translate(*args))
///
///     def upper(self):
///         return self.__class__(self.data.upper())
///
///     def zfill(self, width):
///         return self.__class__(self.data.zfill(width))
/// ```
final class collections extends PythonModule {
  collections.from(super.pythonModule) : super.from();

  static collections import() => PythonFfiDart.instance.importModule(
        "collections",
        collections.from,
      );

  /// ## namedtuple
  ///
  /// ### python docstring
  ///
  /// Returns a new subclass of tuple with named fields.
  ///
  /// >>> Point = namedtuple('Point', ['x', 'y'])
  /// >>> Point.__doc__                   # docstring for the new class
  /// 'Point(x, y)'
  /// >>> p = Point(11, y=22)             # instantiate with positional args or keywords
  /// >>> p[0] + p[1]                     # indexable like a plain tuple
  /// 33
  /// >>> x, y = p                        # unpack like a regular tuple
  /// >>> x, y
  /// (11, 22)
  /// >>> p.x + p.y                       # fields also accessible by name
  /// 33
  /// >>> d = p._asdict()                 # convert to a dictionary
  /// >>> d['x']
  /// 11
  /// >>> Point(**d)                      # convert from a dictionary
  /// Point(x=11, y=22)
  /// >>> p._replace(x=100)               # _replace() is like str.replace() but targets named fields
  /// Point(x=100, y=22)
  ///
  /// ### python source
  /// ```py
  /// def namedtuple(typename, field_names, *, rename=False, defaults=None, module=None):
  ///     """Returns a new subclass of tuple with named fields.
  ///
  ///     >>> Point = namedtuple('Point', ['x', 'y'])
  ///     >>> Point.__doc__                   # docstring for the new class
  ///     'Point(x, y)'
  ///     >>> p = Point(11, y=22)             # instantiate with positional args or keywords
  ///     >>> p[0] + p[1]                     # indexable like a plain tuple
  ///     33
  ///     >>> x, y = p                        # unpack like a regular tuple
  ///     >>> x, y
  ///     (11, 22)
  ///     >>> p.x + p.y                       # fields also accessible by name
  ///     33
  ///     >>> d = p._asdict()                 # convert to a dictionary
  ///     >>> d['x']
  ///     11
  ///     >>> Point(**d)                      # convert from a dictionary
  ///     Point(x=11, y=22)
  ///     >>> p._replace(x=100)               # _replace() is like str.replace() but targets named fields
  ///     Point(x=100, y=22)
  ///
  ///     """
  ///
  ///     # Validate the field names.  At the user's option, either generate an error
  ///     # message or automatically replace the field name with a valid name.
  ///     if isinstance(field_names, str):
  ///         field_names = field_names.replace(',', ' ').split()
  ///     field_names = list(map(str, field_names))
  ///     typename = _sys.intern(str(typename))
  ///
  ///     if rename:
  ///         seen = set()
  ///         for index, name in enumerate(field_names):
  ///             if (not name.isidentifier()
  ///                 or _iskeyword(name)
  ///                 or name.startswith('_')
  ///                 or name in seen):
  ///                 field_names[index] = f'_{index}'
  ///             seen.add(name)
  ///
  ///     for name in [typename] + field_names:
  ///         if type(name) is not str:
  ///             raise TypeError('Type names and field names must be strings')
  ///         if not name.isidentifier():
  ///             raise ValueError('Type names and field names must be valid '
  ///                              f'identifiers: {name!r}')
  ///         if _iskeyword(name):
  ///             raise ValueError('Type names and field names cannot be a '
  ///                              f'keyword: {name!r}')
  ///
  ///     seen = set()
  ///     for name in field_names:
  ///         if name.startswith('_') and not rename:
  ///             raise ValueError('Field names cannot start with an underscore: '
  ///                              f'{name!r}')
  ///         if name in seen:
  ///             raise ValueError(f'Encountered duplicate field name: {name!r}')
  ///         seen.add(name)
  ///
  ///     field_defaults = {}
  ///     if defaults is not None:
  ///         defaults = tuple(defaults)
  ///         if len(defaults) > len(field_names):
  ///             raise TypeError('Got more default values than field names')
  ///         field_defaults = dict(reversed(list(zip(reversed(field_names),
  ///                                                 reversed(defaults)))))
  ///
  ///     # Variables used in the methods and docstrings
  ///     field_names = tuple(map(_sys.intern, field_names))
  ///     num_fields = len(field_names)
  ///     arg_list = ', '.join(field_names)
  ///     if num_fields == 1:
  ///         arg_list += ','
  ///     repr_fmt = '(' + ', '.join(f'{name}=%r' for name in field_names) + ')'
  ///     tuple_new = tuple.__new__
  ///     _dict, _tuple, _len, _map, _zip = dict, tuple, len, map, zip
  ///
  ///     # Create all the named tuple methods to be added to the class namespace
  ///
  ///     namespace = {
  ///         '_tuple_new': tuple_new,
  ///         '__builtins__': {},
  ///         '__name__': f'namedtuple_{typename}',
  ///     }
  ///     code = f'lambda _cls, {arg_list}: _tuple_new(_cls, ({arg_list}))'
  ///     __new__ = eval(code, namespace)
  ///     __new__.__name__ = '__new__'
  ///     __new__.__doc__ = f'Create new instance of {typename}({arg_list})'
  ///     if defaults is not None:
  ///         __new__.__defaults__ = defaults
  ///
  ///     @classmethod
  ///     def _make(cls, iterable):
  ///         result = tuple_new(cls, iterable)
  ///         if _len(result) != num_fields:
  ///             raise TypeError(f'Expected {num_fields} arguments, got {len(result)}')
  ///         return result
  ///
  ///     _make.__func__.__doc__ = (f'Make a new {typename} object from a sequence '
  ///                               'or iterable')
  ///
  ///     def _replace(self, /, **kwds):
  ///         result = self._make(_map(kwds.pop, field_names, self))
  ///         if kwds:
  ///             raise ValueError(f'Got unexpected field names: {list(kwds)!r}')
  ///         return result
  ///
  ///     _replace.__doc__ = (f'Return a new {typename} object replacing specified '
  ///                         'fields with new values')
  ///
  ///     def __repr__(self):
  ///         'Return a nicely formatted representation string'
  ///         return self.__class__.__name__ + repr_fmt % self
  ///
  ///     def _asdict(self):
  ///         'Return a new dict which maps field names to their values.'
  ///         return _dict(_zip(self._fields, self))
  ///
  ///     def __getnewargs__(self):
  ///         'Return self as a plain tuple.  Used by copy and pickle.'
  ///         return _tuple(self)
  ///
  ///     # Modify function metadata to help with introspection and debugging
  ///     for method in (
  ///         __new__,
  ///         _make.__func__,
  ///         _replace,
  ///         __repr__,
  ///         _asdict,
  ///         __getnewargs__,
  ///     ):
  ///         method.__qualname__ = f'{typename}.{method.__name__}'
  ///
  ///     # Build-up the class namespace dictionary
  ///     # and use type() to build the result class
  ///     class_namespace = {
  ///         '__doc__': f'{typename}({arg_list})',
  ///         '__slots__': (),
  ///         '_fields': field_names,
  ///         '_field_defaults': field_defaults,
  ///         '__new__': __new__,
  ///         '_make': _make,
  ///         '_replace': _replace,
  ///         '__repr__': __repr__,
  ///         '_asdict': _asdict,
  ///         '__getnewargs__': __getnewargs__,
  ///         '__match_args__': field_names,
  ///     }
  ///     for index, name in enumerate(field_names):
  ///         doc = _sys.intern(f'Alias for field number {index}')
  ///         class_namespace[name] = _tuplegetter(index, doc)
  ///
  ///     result = type(typename, (tuple,), class_namespace)
  ///
  ///     # For pickling to work, the __module__ variable needs to be set to the frame
  ///     # where the named tuple is created.  Bypass this step in environments where
  ///     # sys._getframe is not defined (Jython for example) or sys._getframe is not
  ///     # defined for arguments greater than 0 (IronPython), or where the user has
  ///     # specified a particular module.
  ///     if module is None:
  ///         try:
  ///             module = _sys._getframe(1).f_globals.get('__name__', '__main__')
  ///         except (AttributeError, ValueError):
  ///             pass
  ///     if module is not None:
  ///         result.__module__ = module
  ///
  ///     return result
  /// ```
  Object? namedtuple({
    required Object? typename,
    required Object? field_names,
    Object? rename = false,
    Object? defaults,
    Object? module,
  }) =>
      getFunction("namedtuple").call(
        <Object?>[
          typename,
          field_names,
        ],
        kwargs: <String, Object?>{
          "rename": rename,
          "defaults": defaults,
          "module": module,
        },
      );
}

/// ## threading
///
/// ### python docstring
///
/// Thread module emulating a subset of Java's threading model.
///
/// ### python source
/// ```py
/// """Thread module emulating a subset of Java's threading model."""
///
/// import os as _os
/// import sys as _sys
/// import _thread
/// import functools
///
/// from time import monotonic as _time
/// from _weakrefset import WeakSet
/// from itertools import islice as _islice, count as _count
/// try:
///     from _collections import deque as _deque
/// except ImportError:
///     from collections import deque as _deque
///
/// # Note regarding PEP 8 compliant names
/// #  This threading model was originally inspired by Java, and inherited
/// # the convention of camelCase function and method names from that
/// # language. Those original names are not in any imminent danger of
/// # being deprecated (even for Py3k),so this module provides them as an
/// # alias for the PEP 8 compliant names
/// # Note that using the new PEP 8 compliant names facilitates substitution
/// # with the multiprocessing module, which doesn't provide the old
/// # Java inspired names.
///
/// __all__ = ['get_ident', 'active_count', 'Condition', 'current_thread',
///            'enumerate', 'main_thread', 'TIMEOUT_MAX',
///            'Event', 'Lock', 'RLock', 'Semaphore', 'BoundedSemaphore', 'Thread',
///            'Barrier', 'BrokenBarrierError', 'Timer', 'ThreadError',
///            'setprofile', 'settrace', 'local', 'stack_size',
///            'excepthook', 'ExceptHookArgs', 'gettrace', 'getprofile']
///
/// # Rename some stuff so "from threading import *" is safe
/// _start_new_thread = _thread.start_new_thread
/// _allocate_lock = _thread.allocate_lock
/// _set_sentinel = _thread._set_sentinel
/// get_ident = _thread.get_ident
/// try:
///     get_native_id = _thread.get_native_id
///     _HAVE_THREAD_NATIVE_ID = True
///     __all__.append('get_native_id')
/// except AttributeError:
///     _HAVE_THREAD_NATIVE_ID = False
/// ThreadError = _thread.error
/// try:
///     _CRLock = _thread.RLock
/// except AttributeError:
///     _CRLock = None
/// TIMEOUT_MAX = _thread.TIMEOUT_MAX
/// del _thread
///
///
/// # Support for profile and trace hooks
///
/// _profile_hook = None
/// _trace_hook = None
///
/// def setprofile(func):
///     """Set a profile function for all threads started from the threading module.
///
///     The func will be passed to sys.setprofile() for each thread, before its
///     run() method is called.
///
///     """
///     global _profile_hook
///     _profile_hook = func
///
/// def getprofile():
///     """Get the profiler function as set by threading.setprofile()."""
///     return _profile_hook
///
/// def settrace(func):
///     """Set a trace function for all threads started from the threading module.
///
///     The func will be passed to sys.settrace() for each thread, before its run()
///     method is called.
///
///     """
///     global _trace_hook
///     _trace_hook = func
///
/// def gettrace():
///     """Get the trace function as set by threading.settrace()."""
///     return _trace_hook
///
/// # Synchronization classes
///
/// Lock = _allocate_lock
///
/// def RLock(*args, **kwargs):
///     """Factory function that returns a new reentrant lock.
///
///     A reentrant lock must be released by the thread that acquired it. Once a
///     thread has acquired a reentrant lock, the same thread may acquire it again
///     without blocking; the thread must release it once for each time it has
///     acquired it.
///
///     """
///     if _CRLock is None:
///         return _PyRLock(*args, **kwargs)
///     return _CRLock(*args, **kwargs)
///
/// class _RLock:
///     """This class implements reentrant lock objects.
///
///     A reentrant lock must be released by the thread that acquired it. Once a
///     thread has acquired a reentrant lock, the same thread may acquire it
///     again without blocking; the thread must release it once for each time it
///     has acquired it.
///
///     """
///
///     def __init__(self):
///         self._block = _allocate_lock()
///         self._owner = None
///         self._count = 0
///
///     def __repr__(self):
///         owner = self._owner
///         try:
///             owner = _active[owner].name
///         except KeyError:
///             pass
///         return "<%s %s.%s object owner=%r count=%d at %s>" % (
///             "locked" if self._block.locked() else "unlocked",
///             self.__class__.__module__,
///             self.__class__.__qualname__,
///             owner,
///             self._count,
///             hex(id(self))
///         )
///
///     def _at_fork_reinit(self):
///         self._block._at_fork_reinit()
///         self._owner = None
///         self._count = 0
///
///     def acquire(self, blocking=True, timeout=-1):
///         """Acquire a lock, blocking or non-blocking.
///
///         When invoked without arguments: if this thread already owns the lock,
///         increment the recursion level by one, and return immediately. Otherwise,
///         if another thread owns the lock, block until the lock is unlocked. Once
///         the lock is unlocked (not owned by any thread), then grab ownership, set
///         the recursion level to one, and return. If more than one thread is
///         blocked waiting until the lock is unlocked, only one at a time will be
///         able to grab ownership of the lock. There is no return value in this
///         case.
///
///         When invoked with the blocking argument set to true, do the same thing
///         as when called without arguments, and return true.
///
///         When invoked with the blocking argument set to false, do not block. If a
///         call without an argument would block, return false immediately;
///         otherwise, do the same thing as when called without arguments, and
///         return true.
///
///         When invoked with the floating-point timeout argument set to a positive
///         value, block for at most the number of seconds specified by timeout
///         and as long as the lock cannot be acquired.  Return true if the lock has
///         been acquired, false if the timeout has elapsed.
///
///         """
///         me = get_ident()
///         if self._owner == me:
///             self._count += 1
///             return 1
///         rc = self._block.acquire(blocking, timeout)
///         if rc:
///             self._owner = me
///             self._count = 1
///         return rc
///
///     __enter__ = acquire
///
///     def release(self):
///         """Release a lock, decrementing the recursion level.
///
///         If after the decrement it is zero, reset the lock to unlocked (not owned
///         by any thread), and if any other threads are blocked waiting for the
///         lock to become unlocked, allow exactly one of them to proceed. If after
///         the decrement the recursion level is still nonzero, the lock remains
///         locked and owned by the calling thread.
///
///         Only call this method when the calling thread owns the lock. A
///         RuntimeError is raised if this method is called when the lock is
///         unlocked.
///
///         There is no return value.
///
///         """
///         if self._owner != get_ident():
///             raise RuntimeError("cannot release un-acquired lock")
///         self._count = count = self._count - 1
///         if not count:
///             self._owner = None
///             self._block.release()
///
///     def __exit__(self, t, v, tb):
///         self.release()
///
///     # Internal methods used by condition variables
///
///     def _acquire_restore(self, state):
///         self._block.acquire()
///         self._count, self._owner = state
///
///     def _release_save(self):
///         if self._count == 0:
///             raise RuntimeError("cannot release un-acquired lock")
///         count = self._count
///         self._count = 0
///         owner = self._owner
///         self._owner = None
///         self._block.release()
///         return (count, owner)
///
///     def _is_owned(self):
///         return self._owner == get_ident()
///
/// _PyRLock = _RLock
///
///
/// class Condition:
///     """Class that implements a condition variable.
///
///     A condition variable allows one or more threads to wait until they are
///     notified by another thread.
///
///     If the lock argument is given and not None, it must be a Lock or RLock
///     object, and it is used as the underlying lock. Otherwise, a new RLock object
///     is created and used as the underlying lock.
///
///     """
///
///     def __init__(self, lock=None):
///         if lock is None:
///             lock = RLock()
///         self._lock = lock
///         # Export the lock's acquire() and release() methods
///         self.acquire = lock.acquire
///         self.release = lock.release
///         # If the lock defines _release_save() and/or _acquire_restore(),
///         # these override the default implementations (which just call
///         # release() and acquire() on the lock).  Ditto for _is_owned().
///         try:
///             self._release_save = lock._release_save
///         except AttributeError:
///             pass
///         try:
///             self._acquire_restore = lock._acquire_restore
///         except AttributeError:
///             pass
///         try:
///             self._is_owned = lock._is_owned
///         except AttributeError:
///             pass
///         self._waiters = _deque()
///
///     def _at_fork_reinit(self):
///         self._lock._at_fork_reinit()
///         self._waiters.clear()
///
///     def __enter__(self):
///         return self._lock.__enter__()
///
///     def __exit__(self, *args):
///         return self._lock.__exit__(*args)
///
///     def __repr__(self):
///         return "<Condition(%s, %d)>" % (self._lock, len(self._waiters))
///
///     def _release_save(self):
///         self._lock.release()           # No state to save
///
///     def _acquire_restore(self, x):
///         self._lock.acquire()           # Ignore saved state
///
///     def _is_owned(self):
///         # Return True if lock is owned by current_thread.
///         # This method is called only if _lock doesn't have _is_owned().
///         if self._lock.acquire(False):
///             self._lock.release()
///             return False
///         else:
///             return True
///
///     def wait(self, timeout=None):
///         """Wait until notified or until a timeout occurs.
///
///         If the calling thread has not acquired the lock when this method is
///         called, a RuntimeError is raised.
///
///         This method releases the underlying lock, and then blocks until it is
///         awakened by a notify() or notify_all() call for the same condition
///         variable in another thread, or until the optional timeout occurs. Once
///         awakened or timed out, it re-acquires the lock and returns.
///
///         When the timeout argument is present and not None, it should be a
///         floating point number specifying a timeout for the operation in seconds
///         (or fractions thereof).
///
///         When the underlying lock is an RLock, it is not released using its
///         release() method, since this may not actually unlock the lock when it
///         was acquired multiple times recursively. Instead, an internal interface
///         of the RLock class is used, which really unlocks it even when it has
///         been recursively acquired several times. Another internal interface is
///         then used to restore the recursion level when the lock is reacquired.
///
///         """
///         if not self._is_owned():
///             raise RuntimeError("cannot wait on un-acquired lock")
///         waiter = _allocate_lock()
///         waiter.acquire()
///         self._waiters.append(waiter)
///         saved_state = self._release_save()
///         gotit = False
///         try:    # restore state no matter what (e.g., KeyboardInterrupt)
///             if timeout is None:
///                 waiter.acquire()
///                 gotit = True
///             else:
///                 if timeout > 0:
///                     gotit = waiter.acquire(True, timeout)
///                 else:
///                     gotit = waiter.acquire(False)
///             return gotit
///         finally:
///             self._acquire_restore(saved_state)
///             if not gotit:
///                 try:
///                     self._waiters.remove(waiter)
///                 except ValueError:
///                     pass
///
///     def wait_for(self, predicate, timeout=None):
///         """Wait until a condition evaluates to True.
///
///         predicate should be a callable which result will be interpreted as a
///         boolean value.  A timeout may be provided giving the maximum time to
///         wait.
///
///         """
///         endtime = None
///         waittime = timeout
///         result = predicate()
///         while not result:
///             if waittime is not None:
///                 if endtime is None:
///                     endtime = _time() + waittime
///                 else:
///                     waittime = endtime - _time()
///                     if waittime <= 0:
///                         break
///             self.wait(waittime)
///             result = predicate()
///         return result
///
///     def notify(self, n=1):
///         """Wake up one or more threads waiting on this condition, if any.
///
///         If the calling thread has not acquired the lock when this method is
///         called, a RuntimeError is raised.
///
///         This method wakes up at most n of the threads waiting for the condition
///         variable; it is a no-op if no threads are waiting.
///
///         """
///         if not self._is_owned():
///             raise RuntimeError("cannot notify on un-acquired lock")
///         waiters = self._waiters
///         while waiters and n > 0:
///             waiter = waiters[0]
///             try:
///                 waiter.release()
///             except RuntimeError:
///                 # gh-92530: The previous call of notify() released the lock,
///                 # but was interrupted before removing it from the queue.
///                 # It can happen if a signal handler raises an exception,
///                 # like CTRL+C which raises KeyboardInterrupt.
///                 pass
///             else:
///                 n -= 1
///             try:
///                 waiters.remove(waiter)
///             except ValueError:
///                 pass
///
///     def notify_all(self):
///         """Wake up all threads waiting on this condition.
///
///         If the calling thread has not acquired the lock when this method
///         is called, a RuntimeError is raised.
///
///         """
///         self.notify(len(self._waiters))
///
///     def notifyAll(self):
///         """Wake up all threads waiting on this condition.
///
///         This method is deprecated, use notify_all() instead.
///
///         """
///         import warnings
///         warnings.warn('notifyAll() is deprecated, use notify_all() instead',
///                       DeprecationWarning, stacklevel=2)
///         self.notify_all()
///
///
/// class Semaphore:
///     """This class implements semaphore objects.
///
///     Semaphores manage a counter representing the number of release() calls minus
///     the number of acquire() calls, plus an initial value. The acquire() method
///     blocks if necessary until it can return without making the counter
///     negative. If not given, value defaults to 1.
///
///     """
///
///     # After Tim Peters' semaphore class, but not quite the same (no maximum)
///
///     def __init__(self, value=1):
///         if value < 0:
///             raise ValueError("semaphore initial value must be >= 0")
///         self._cond = Condition(Lock())
///         self._value = value
///
///     def __repr__(self):
///         cls = self.__class__
///         return (f"<{cls.__module__}.{cls.__qualname__} at {id(self):#x}:"
///                 f" value={self._value}>")
///
///     def acquire(self, blocking=True, timeout=None):
///         """Acquire a semaphore, decrementing the internal counter by one.
///
///         When invoked without arguments: if the internal counter is larger than
///         zero on entry, decrement it by one and return immediately. If it is zero
///         on entry, block, waiting until some other thread has called release() to
///         make it larger than zero. This is done with proper interlocking so that
///         if multiple acquire() calls are blocked, release() will wake exactly one
///         of them up. The implementation may pick one at random, so the order in
///         which blocked threads are awakened should not be relied on. There is no
///         return value in this case.
///
///         When invoked with blocking set to true, do the same thing as when called
///         without arguments, and return true.
///
///         When invoked with blocking set to false, do not block. If a call without
///         an argument would block, return false immediately; otherwise, do the
///         same thing as when called without arguments, and return true.
///
///         When invoked with a timeout other than None, it will block for at
///         most timeout seconds.  If acquire does not complete successfully in
///         that interval, return false.  Return true otherwise.
///
///         """
///         if not blocking and timeout is not None:
///             raise ValueError("can't specify timeout for non-blocking acquire")
///         rc = False
///         endtime = None
///         with self._cond:
///             while self._value == 0:
///                 if not blocking:
///                     break
///                 if timeout is not None:
///                     if endtime is None:
///                         endtime = _time() + timeout
///                     else:
///                         timeout = endtime - _time()
///                         if timeout <= 0:
///                             break
///                 self._cond.wait(timeout)
///             else:
///                 self._value -= 1
///                 rc = True
///         return rc
///
///     __enter__ = acquire
///
///     def release(self, n=1):
///         """Release a semaphore, incrementing the internal counter by one or more.
///
///         When the counter is zero on entry and another thread is waiting for it
///         to become larger than zero again, wake up that thread.
///
///         """
///         if n < 1:
///             raise ValueError('n must be one or more')
///         with self._cond:
///             self._value += n
///             for i in range(n):
///                 self._cond.notify()
///
///     def __exit__(self, t, v, tb):
///         self.release()
///
///
/// class BoundedSemaphore(Semaphore):
///     """Implements a bounded semaphore.
///
///     A bounded semaphore checks to make sure its current value doesn't exceed its
///     initial value. If it does, ValueError is raised. In most situations
///     semaphores are used to guard resources with limited capacity.
///
///     If the semaphore is released too many times it's a sign of a bug. If not
///     given, value defaults to 1.
///
///     Like regular semaphores, bounded semaphores manage a counter representing
///     the number of release() calls minus the number of acquire() calls, plus an
///     initial value. The acquire() method blocks if necessary until it can return
///     without making the counter negative. If not given, value defaults to 1.
///
///     """
///
///     def __init__(self, value=1):
///         Semaphore.__init__(self, value)
///         self._initial_value = value
///
///     def __repr__(self):
///         cls = self.__class__
///         return (f"<{cls.__module__}.{cls.__qualname__} at {id(self):#x}:"
///                 f" value={self._value}/{self._initial_value}>")
///
///     def release(self, n=1):
///         """Release a semaphore, incrementing the internal counter by one or more.
///
///         When the counter is zero on entry and another thread is waiting for it
///         to become larger than zero again, wake up that thread.
///
///         If the number of releases exceeds the number of acquires,
///         raise a ValueError.
///
///         """
///         if n < 1:
///             raise ValueError('n must be one or more')
///         with self._cond:
///             if self._value + n > self._initial_value:
///                 raise ValueError("Semaphore released too many times")
///             self._value += n
///             for i in range(n):
///                 self._cond.notify()
///
///
/// class Event:
///     """Class implementing event objects.
///
///     Events manage a flag that can be set to true with the set() method and reset
///     to false with the clear() method. The wait() method blocks until the flag is
///     true.  The flag is initially false.
///
///     """
///
///     # After Tim Peters' event class (without is_posted())
///
///     def __init__(self):
///         self._cond = Condition(Lock())
///         self._flag = False
///
///     def __repr__(self):
///         cls = self.__class__
///         status = 'set' if self._flag else 'unset'
///         return f"<{cls.__module__}.{cls.__qualname__} at {id(self):#x}: {status}>"
///
///     def _at_fork_reinit(self):
///         # Private method called by Thread._reset_internal_locks()
///         self._cond._at_fork_reinit()
///
///     def is_set(self):
///         """Return true if and only if the internal flag is true."""
///         return self._flag
///
///     def isSet(self):
///         """Return true if and only if the internal flag is true.
///
///         This method is deprecated, use is_set() instead.
///
///         """
///         import warnings
///         warnings.warn('isSet() is deprecated, use is_set() instead',
///                       DeprecationWarning, stacklevel=2)
///         return self.is_set()
///
///     def set(self):
///         """Set the internal flag to true.
///
///         All threads waiting for it to become true are awakened. Threads
///         that call wait() once the flag is true will not block at all.
///
///         """
///         with self._cond:
///             self._flag = True
///             self._cond.notify_all()
///
///     def clear(self):
///         """Reset the internal flag to false.
///
///         Subsequently, threads calling wait() will block until set() is called to
///         set the internal flag to true again.
///
///         """
///         with self._cond:
///             self._flag = False
///
///     def wait(self, timeout=None):
///         """Block until the internal flag is true.
///
///         If the internal flag is true on entry, return immediately. Otherwise,
///         block until another thread calls set() to set the flag to true, or until
///         the optional timeout occurs.
///
///         When the timeout argument is present and not None, it should be a
///         floating point number specifying a timeout for the operation in seconds
///         (or fractions thereof).
///
///         This method returns the internal flag on exit, so it will always return
///         True except if a timeout is given and the operation times out.
///
///         """
///         with self._cond:
///             signaled = self._flag
///             if not signaled:
///                 signaled = self._cond.wait(timeout)
///             return signaled
///
///
/// # A barrier class.  Inspired in part by the pthread_barrier_* api and
/// # the CyclicBarrier class from Java.  See
/// # http://sourceware.org/pthreads-win32/manual/pthread_barrier_init.html and
/// # http://java.sun.com/j2se/1.5.0/docs/api/java/util/concurrent/
/// #        CyclicBarrier.html
/// # for information.
/// # We maintain two main states, 'filling' and 'draining' enabling the barrier
/// # to be cyclic.  Threads are not allowed into it until it has fully drained
/// # since the previous cycle.  In addition, a 'resetting' state exists which is
/// # similar to 'draining' except that threads leave with a BrokenBarrierError,
/// # and a 'broken' state in which all threads get the exception.
/// class Barrier:
///     """Implements a Barrier.
///
///     Useful for synchronizing a fixed number of threads at known synchronization
///     points.  Threads block on 'wait()' and are simultaneously awoken once they
///     have all made that call.
///
///     """
///
///     def __init__(self, parties, action=None, timeout=None):
///         """Create a barrier, initialised to 'parties' threads.
///
///         'action' is a callable which, when supplied, will be called by one of
///         the threads after they have all entered the barrier and just prior to
///         releasing them all. If a 'timeout' is provided, it is used as the
///         default for all subsequent 'wait()' calls.
///
///         """
///         self._cond = Condition(Lock())
///         self._action = action
///         self._timeout = timeout
///         self._parties = parties
///         self._state = 0  # 0 filling, 1 draining, -1 resetting, -2 broken
///         self._count = 0
///
///     def __repr__(self):
///         cls = self.__class__
///         if self.broken:
///             return f"<{cls.__module__}.{cls.__qualname__} at {id(self):#x}: broken>"
///         return (f"<{cls.__module__}.{cls.__qualname__} at {id(self):#x}:"
///                 f" waiters={self.n_waiting}/{self.parties}>")
///
///     def wait(self, timeout=None):
///         """Wait for the barrier.
///
///         When the specified number of threads have started waiting, they are all
///         simultaneously awoken. If an 'action' was provided for the barrier, one
///         of the threads will have executed that callback prior to returning.
///         Returns an individual index number from 0 to 'parties-1'.
///
///         """
///         if timeout is None:
///             timeout = self._timeout
///         with self._cond:
///             self._enter() # Block while the barrier drains.
///             index = self._count
///             self._count += 1
///             try:
///                 if index + 1 == self._parties:
///                     # We release the barrier
///                     self._release()
///                 else:
///                     # We wait until someone releases us
///                     self._wait(timeout)
///                 return index
///             finally:
///                 self._count -= 1
///                 # Wake up any threads waiting for barrier to drain.
///                 self._exit()
///
///     # Block until the barrier is ready for us, or raise an exception
///     # if it is broken.
///     def _enter(self):
///         while self._state in (-1, 1):
///             # It is draining or resetting, wait until done
///             self._cond.wait()
///         #see if the barrier is in a broken state
///         if self._state < 0:
///             raise BrokenBarrierError
///         assert self._state == 0
///
///     # Optionally run the 'action' and release the threads waiting
///     # in the barrier.
///     def _release(self):
///         try:
///             if self._action:
///                 self._action()
///             # enter draining state
///             self._state = 1
///             self._cond.notify_all()
///         except:
///             #an exception during the _action handler.  Break and reraise
///             self._break()
///             raise
///
///     # Wait in the barrier until we are released.  Raise an exception
///     # if the barrier is reset or broken.
///     def _wait(self, timeout):
///         if not self._cond.wait_for(lambda : self._state != 0, timeout):
///             #timed out.  Break the barrier
///             self._break()
///             raise BrokenBarrierError
///         if self._state < 0:
///             raise BrokenBarrierError
///         assert self._state == 1
///
///     # If we are the last thread to exit the barrier, signal any threads
///     # waiting for the barrier to drain.
///     def _exit(self):
///         if self._count == 0:
///             if self._state in (-1, 1):
///                 #resetting or draining
///                 self._state = 0
///                 self._cond.notify_all()
///
///     def reset(self):
///         """Reset the barrier to the initial state.
///
///         Any threads currently waiting will get the BrokenBarrier exception
///         raised.
///
///         """
///         with self._cond:
///             if self._count > 0:
///                 if self._state == 0:
///                     #reset the barrier, waking up threads
///                     self._state = -1
///                 elif self._state == -2:
///                     #was broken, set it to reset state
///                     #which clears when the last thread exits
///                     self._state = -1
///             else:
///                 self._state = 0
///             self._cond.notify_all()
///
///     def abort(self):
///         """Place the barrier into a 'broken' state.
///
///         Useful in case of error.  Any currently waiting threads and threads
///         attempting to 'wait()' will have BrokenBarrierError raised.
///
///         """
///         with self._cond:
///             self._break()
///
///     def _break(self):
///         # An internal error was detected.  The barrier is set to
///         # a broken state all parties awakened.
///         self._state = -2
///         self._cond.notify_all()
///
///     @property
///     def parties(self):
///         """Return the number of threads required to trip the barrier."""
///         return self._parties
///
///     @property
///     def n_waiting(self):
///         """Return the number of threads currently waiting at the barrier."""
///         # We don't need synchronization here since this is an ephemeral result
///         # anyway.  It returns the correct value in the steady state.
///         if self._state == 0:
///             return self._count
///         return 0
///
///     @property
///     def broken(self):
///         """Return True if the barrier is in a broken state."""
///         return self._state == -2
///
/// # exception raised by the Barrier class
/// class BrokenBarrierError(RuntimeError):
///     pass
///
///
/// # Helper to generate new thread names
/// _counter = _count(1).__next__
/// def _newname(name_template):
///     return name_template % _counter()
///
/// # Active thread administration.
/// #
/// # bpo-44422: Use a reentrant lock to allow reentrant calls to functions like
/// # threading.enumerate().
/// _active_limbo_lock = RLock()
/// _active = {}    # maps thread id to Thread object
/// _limbo = {}
/// _dangling = WeakSet()
///
/// # Set of Thread._tstate_lock locks of non-daemon threads used by _shutdown()
/// # to wait until all Python thread states get deleted:
/// # see Thread._set_tstate_lock().
/// _shutdown_locks_lock = _allocate_lock()
/// _shutdown_locks = set()
///
/// def _maintain_shutdown_locks():
///     """
///     Drop any shutdown locks that don't correspond to running threads anymore.
///
///     Calling this from time to time avoids an ever-growing _shutdown_locks
///     set when Thread objects are not joined explicitly. See bpo-37788.
///
///     This must be called with _shutdown_locks_lock acquired.
///     """
///     # If a lock was released, the corresponding thread has exited
///     to_remove = [lock for lock in _shutdown_locks if not lock.locked()]
///     _shutdown_locks.difference_update(to_remove)
///
///
/// # Main class for threads
///
/// class Thread:
///     """A class that represents a thread of control.
///
///     This class can be safely subclassed in a limited fashion. There are two ways
///     to specify the activity: by passing a callable object to the constructor, or
///     by overriding the run() method in a subclass.
///
///     """
///
///     _initialized = False
///
///     def __init__(self, group=None, target=None, name=None,
///                  args=(), kwargs=None, *, daemon=None):
///         """This constructor should always be called with keyword arguments. Arguments are:
///
///         *group* should be None; reserved for future extension when a ThreadGroup
///         class is implemented.
///
///         *target* is the callable object to be invoked by the run()
///         method. Defaults to None, meaning nothing is called.
///
///         *name* is the thread name. By default, a unique name is constructed of
///         the form "Thread-N" where N is a small decimal number.
///
///         *args* is a list or tuple of arguments for the target invocation. Defaults to ().
///
///         *kwargs* is a dictionary of keyword arguments for the target
///         invocation. Defaults to {}.
///
///         If a subclass overrides the constructor, it must make sure to invoke
///         the base class constructor (Thread.__init__()) before doing anything
///         else to the thread.
///
///         """
///         assert group is None, "group argument must be None for now"
///         if kwargs is None:
///             kwargs = {}
///         if name:
///             name = str(name)
///         else:
///             name = _newname("Thread-%d")
///             if target is not None:
///                 try:
///                     target_name = target.__name__
///                     name += f" ({target_name})"
///                 except AttributeError:
///                     pass
///
///         self._target = target
///         self._name = name
///         self._args = args
///         self._kwargs = kwargs
///         if daemon is not None:
///             self._daemonic = daemon
///         else:
///             self._daemonic = current_thread().daemon
///         self._ident = None
///         if _HAVE_THREAD_NATIVE_ID:
///             self._native_id = None
///         self._tstate_lock = None
///         self._started = Event()
///         self._is_stopped = False
///         self._initialized = True
///         # Copy of sys.stderr used by self._invoke_excepthook()
///         self._stderr = _sys.stderr
///         self._invoke_excepthook = _make_invoke_excepthook()
///         # For debugging and _after_fork()
///         _dangling.add(self)
///
///     def _reset_internal_locks(self, is_alive):
///         # private!  Called by _after_fork() to reset our internal locks as
///         # they may be in an invalid state leading to a deadlock or crash.
///         self._started._at_fork_reinit()
///         if is_alive:
///             # bpo-42350: If the fork happens when the thread is already stopped
///             # (ex: after threading._shutdown() has been called), _tstate_lock
///             # is None. Do nothing in this case.
///             if self._tstate_lock is not None:
///                 self._tstate_lock._at_fork_reinit()
///                 self._tstate_lock.acquire()
///         else:
///             # The thread isn't alive after fork: it doesn't have a tstate
///             # anymore.
///             self._is_stopped = True
///             self._tstate_lock = None
///
///     def __repr__(self):
///         assert self._initialized, "Thread.__init__() was not called"
///         status = "initial"
///         if self._started.is_set():
///             status = "started"
///         self.is_alive() # easy way to get ._is_stopped set when appropriate
///         if self._is_stopped:
///             status = "stopped"
///         if self._daemonic:
///             status += " daemon"
///         if self._ident is not None:
///             status += " %s" % self._ident
///         return "<%s(%s, %s)>" % (self.__class__.__name__, self._name, status)
///
///     def start(self):
///         """Start the thread's activity.
///
///         It must be called at most once per thread object. It arranges for the
///         object's run() method to be invoked in a separate thread of control.
///
///         This method will raise a RuntimeError if called more than once on the
///         same thread object.
///
///         """
///         if not self._initialized:
///             raise RuntimeError("thread.__init__() not called")
///
///         if self._started.is_set():
///             raise RuntimeError("threads can only be started once")
///
///         with _active_limbo_lock:
///             _limbo[self] = self
///         try:
///             _start_new_thread(self._bootstrap, ())
///         except Exception:
///             with _active_limbo_lock:
///                 del _limbo[self]
///             raise
///         self._started.wait()
///
///     def run(self):
///         """Method representing the thread's activity.
///
///         You may override this method in a subclass. The standard run() method
///         invokes the callable object passed to the object's constructor as the
///         target argument, if any, with sequential and keyword arguments taken
///         from the args and kwargs arguments, respectively.
///
///         """
///         try:
///             if self._target is not None:
///                 self._target(*self._args, **self._kwargs)
///         finally:
///             # Avoid a refcycle if the thread is running a function with
///             # an argument that has a member that points to the thread.
///             del self._target, self._args, self._kwargs
///
///     def _bootstrap(self):
///         # Wrapper around the real bootstrap code that ignores
///         # exceptions during interpreter cleanup.  Those typically
///         # happen when a daemon thread wakes up at an unfortunate
///         # moment, finds the world around it destroyed, and raises some
///         # random exception *** while trying to report the exception in
///         # _bootstrap_inner() below ***.  Those random exceptions
///         # don't help anybody, and they confuse users, so we suppress
///         # them.  We suppress them only when it appears that the world
///         # indeed has already been destroyed, so that exceptions in
///         # _bootstrap_inner() during normal business hours are properly
///         # reported.  Also, we only suppress them for daemonic threads;
///         # if a non-daemonic encounters this, something else is wrong.
///         try:
///             self._bootstrap_inner()
///         except:
///             if self._daemonic and _sys is None:
///                 return
///             raise
///
///     def _set_ident(self):
///         self._ident = get_ident()
///
///     if _HAVE_THREAD_NATIVE_ID:
///         def _set_native_id(self):
///             self._native_id = get_native_id()
///
///     def _set_tstate_lock(self):
///         """
///         Set a lock object which will be released by the interpreter when
///         the underlying thread state (see pystate.h) gets deleted.
///         """
///         self._tstate_lock = _set_sentinel()
///         self._tstate_lock.acquire()
///
///         if not self.daemon:
///             with _shutdown_locks_lock:
///                 _maintain_shutdown_locks()
///                 _shutdown_locks.add(self._tstate_lock)
///
///     def _bootstrap_inner(self):
///         try:
///             self._set_ident()
///             self._set_tstate_lock()
///             if _HAVE_THREAD_NATIVE_ID:
///                 self._set_native_id()
///             self._started.set()
///             with _active_limbo_lock:
///                 _active[self._ident] = self
///                 del _limbo[self]
///
///             if _trace_hook:
///                 _sys.settrace(_trace_hook)
///             if _profile_hook:
///                 _sys.setprofile(_profile_hook)
///
///             try:
///                 self.run()
///             except:
///                 self._invoke_excepthook(self)
///         finally:
///             self._delete()
///
///     def _stop(self):
///         # After calling ._stop(), .is_alive() returns False and .join() returns
///         # immediately.  ._tstate_lock must be released before calling ._stop().
///         #
///         # Normal case:  C code at the end of the thread's life
///         # (release_sentinel in _threadmodule.c) releases ._tstate_lock, and
///         # that's detected by our ._wait_for_tstate_lock(), called by .join()
///         # and .is_alive().  Any number of threads _may_ call ._stop()
///         # simultaneously (for example, if multiple threads are blocked in
///         # .join() calls), and they're not serialized.  That's harmless -
///         # they'll just make redundant rebindings of ._is_stopped and
///         # ._tstate_lock.  Obscure:  we rebind ._tstate_lock last so that the
///         # "assert self._is_stopped" in ._wait_for_tstate_lock() always works
///         # (the assert is executed only if ._tstate_lock is None).
///         #
///         # Special case:  _main_thread releases ._tstate_lock via this
///         # module's _shutdown() function.
///         lock = self._tstate_lock
///         if lock is not None:
///             assert not lock.locked()
///         self._is_stopped = True
///         self._tstate_lock = None
///         if not self.daemon:
///             with _shutdown_locks_lock:
///                 # Remove our lock and other released locks from _shutdown_locks
///                 _maintain_shutdown_locks()
///
///     def _delete(self):
///         "Remove current thread from the dict of currently running threads."
///         with _active_limbo_lock:
///             del _active[get_ident()]
///             # There must not be any python code between the previous line
///             # and after the lock is released.  Otherwise a tracing function
///             # could try to acquire the lock again in the same thread, (in
///             # current_thread()), and would block.
///
///     def join(self, timeout=None):
///         """Wait until the thread terminates.
///
///         This blocks the calling thread until the thread whose join() method is
///         called terminates -- either normally or through an unhandled exception
///         or until the optional timeout occurs.
///
///         When the timeout argument is present and not None, it should be a
///         floating point number specifying a timeout for the operation in seconds
///         (or fractions thereof). As join() always returns None, you must call
///         is_alive() after join() to decide whether a timeout happened -- if the
///         thread is still alive, the join() call timed out.
///
///         When the timeout argument is not present or None, the operation will
///         block until the thread terminates.
///
///         A thread can be join()ed many times.
///
///         join() raises a RuntimeError if an attempt is made to join the current
///         thread as that would cause a deadlock. It is also an error to join() a
///         thread before it has been started and attempts to do so raises the same
///         exception.
///
///         """
///         if not self._initialized:
///             raise RuntimeError("Thread.__init__() not called")
///         if not self._started.is_set():
///             raise RuntimeError("cannot join thread before it is started")
///         if self is current_thread():
///             raise RuntimeError("cannot join current thread")
///
///         if timeout is None:
///             self._wait_for_tstate_lock()
///         else:
///             # the behavior of a negative timeout isn't documented, but
///             # historically .join(timeout=x) for x<0 has acted as if timeout=0
///             self._wait_for_tstate_lock(timeout=max(timeout, 0))
///
///     def _wait_for_tstate_lock(self, block=True, timeout=-1):
///         # Issue #18808: wait for the thread state to be gone.
///         # At the end of the thread's life, after all knowledge of the thread
///         # is removed from C data structures, C code releases our _tstate_lock.
///         # This method passes its arguments to _tstate_lock.acquire().
///         # If the lock is acquired, the C code is done, and self._stop() is
///         # called.  That sets ._is_stopped to True, and ._tstate_lock to None.
///         lock = self._tstate_lock
///         if lock is None:
///             # already determined that the C code is done
///             assert self._is_stopped
///             return
///
///         try:
///             if lock.acquire(block, timeout):
///                 lock.release()
///                 self._stop()
///         except:
///             if lock.locked():
///                 # bpo-45274: lock.acquire() acquired the lock, but the function
///                 # was interrupted with an exception before reaching the
///                 # lock.release(). It can happen if a signal handler raises an
///                 # exception, like CTRL+C which raises KeyboardInterrupt.
///                 lock.release()
///                 self._stop()
///             raise
///
///     @property
///     def name(self):
///         """A string used for identification purposes only.
///
///         It has no semantics. Multiple threads may be given the same name. The
///         initial name is set by the constructor.
///
///         """
///         assert self._initialized, "Thread.__init__() not called"
///         return self._name
///
///     @name.setter
///     def name(self, name):
///         assert self._initialized, "Thread.__init__() not called"
///         self._name = str(name)
///
///     @property
///     def ident(self):
///         """Thread identifier of this thread or None if it has not been started.
///
///         This is a nonzero integer. See the get_ident() function. Thread
///         identifiers may be recycled when a thread exits and another thread is
///         created. The identifier is available even after the thread has exited.
///
///         """
///         assert self._initialized, "Thread.__init__() not called"
///         return self._ident
///
///     if _HAVE_THREAD_NATIVE_ID:
///         @property
///         def native_id(self):
///             """Native integral thread ID of this thread, or None if it has not been started.
///
///             This is a non-negative integer. See the get_native_id() function.
///             This represents the Thread ID as reported by the kernel.
///
///             """
///             assert self._initialized, "Thread.__init__() not called"
///             return self._native_id
///
///     def is_alive(self):
///         """Return whether the thread is alive.
///
///         This method returns True just before the run() method starts until just
///         after the run() method terminates. See also the module function
///         enumerate().
///
///         """
///         assert self._initialized, "Thread.__init__() not called"
///         if self._is_stopped or not self._started.is_set():
///             return False
///         self._wait_for_tstate_lock(False)
///         return not self._is_stopped
///
///     @property
///     def daemon(self):
///         """A boolean value indicating whether this thread is a daemon thread.
///
///         This must be set before start() is called, otherwise RuntimeError is
///         raised. Its initial value is inherited from the creating thread; the
///         main thread is not a daemon thread and therefore all threads created in
///         the main thread default to daemon = False.
///
///         The entire Python program exits when only daemon threads are left.
///
///         """
///         assert self._initialized, "Thread.__init__() not called"
///         return self._daemonic
///
///     @daemon.setter
///     def daemon(self, daemonic):
///         if not self._initialized:
///             raise RuntimeError("Thread.__init__() not called")
///         if self._started.is_set():
///             raise RuntimeError("cannot set daemon status of active thread")
///         self._daemonic = daemonic
///
///     def isDaemon(self):
///         """Return whether this thread is a daemon.
///
///         This method is deprecated, use the daemon attribute instead.
///
///         """
///         import warnings
///         warnings.warn('isDaemon() is deprecated, get the daemon attribute instead',
///                       DeprecationWarning, stacklevel=2)
///         return self.daemon
///
///     def setDaemon(self, daemonic):
///         """Set whether this thread is a daemon.
///
///         This method is deprecated, use the .daemon property instead.
///
///         """
///         import warnings
///         warnings.warn('setDaemon() is deprecated, set the daemon attribute instead',
///                       DeprecationWarning, stacklevel=2)
///         self.daemon = daemonic
///
///     def getName(self):
///         """Return a string used for identification purposes only.
///
///         This method is deprecated, use the name attribute instead.
///
///         """
///         import warnings
///         warnings.warn('getName() is deprecated, get the name attribute instead',
///                       DeprecationWarning, stacklevel=2)
///         return self.name
///
///     def setName(self, name):
///         """Set the name string for this thread.
///
///         This method is deprecated, use the name attribute instead.
///
///         """
///         import warnings
///         warnings.warn('setName() is deprecated, set the name attribute instead',
///                       DeprecationWarning, stacklevel=2)
///         self.name = name
///
///
/// try:
///     from _thread import (_excepthook as excepthook,
///                          _ExceptHookArgs as ExceptHookArgs)
/// except ImportError:
///     # Simple Python implementation if _thread._excepthook() is not available
///     from traceback import print_exception as _print_exception
///     from collections import namedtuple
///
///     _ExceptHookArgs = namedtuple(
///         'ExceptHookArgs',
///         'exc_type exc_value exc_traceback thread')
///
///     def ExceptHookArgs(args):
///         return _ExceptHookArgs(*args)
///
///     def excepthook(args, /):
///         """
///         Handle uncaught Thread.run() exception.
///         """
///         if args.exc_type == SystemExit:
///             # silently ignore SystemExit
///             return
///
///         if _sys is not None and _sys.stderr is not None:
///             stderr = _sys.stderr
///         elif args.thread is not None:
///             stderr = args.thread._stderr
///             if stderr is None:
///                 # do nothing if sys.stderr is None and sys.stderr was None
///                 # when the thread was created
///                 return
///         else:
///             # do nothing if sys.stderr is None and args.thread is None
///             return
///
///         if args.thread is not None:
///             name = args.thread.name
///         else:
///             name = get_ident()
///         print(f"Exception in thread {name}:",
///               file=stderr, flush=True)
///         _print_exception(args.exc_type, args.exc_value, args.exc_traceback,
///                          file=stderr)
///         stderr.flush()
///
///
/// # Original value of threading.excepthook
/// __excepthook__ = excepthook
///
///
/// def _make_invoke_excepthook():
///     # Create a local namespace to ensure that variables remain alive
///     # when _invoke_excepthook() is called, even if it is called late during
///     # Python shutdown. It is mostly needed for daemon threads.
///
///     old_excepthook = excepthook
///     old_sys_excepthook = _sys.excepthook
///     if old_excepthook is None:
///         raise RuntimeError("threading.excepthook is None")
///     if old_sys_excepthook is None:
///         raise RuntimeError("sys.excepthook is None")
///
///     sys_exc_info = _sys.exc_info
///     local_print = print
///     local_sys = _sys
///
///     def invoke_excepthook(thread):
///         global excepthook
///         try:
///             hook = excepthook
///             if hook is None:
///                 hook = old_excepthook
///
///             args = ExceptHookArgs([*sys_exc_info(), thread])
///
///             hook(args)
///         except Exception as exc:
///             exc.__suppress_context__ = True
///             del exc
///
///             if local_sys is not None and local_sys.stderr is not None:
///                 stderr = local_sys.stderr
///             else:
///                 stderr = thread._stderr
///
///             local_print("Exception in threading.excepthook:",
///                         file=stderr, flush=True)
///
///             if local_sys is not None and local_sys.excepthook is not None:
///                 sys_excepthook = local_sys.excepthook
///             else:
///                 sys_excepthook = old_sys_excepthook
///
///             sys_excepthook(*sys_exc_info())
///         finally:
///             # Break reference cycle (exception stored in a variable)
///             args = None
///
///     return invoke_excepthook
///
///
/// # The timer class was contributed by Itamar Shtull-Trauring
///
/// class Timer(Thread):
///     """Call a function after a specified number of seconds:
///
///             t = Timer(30.0, f, args=None, kwargs=None)
///             t.start()
///             t.cancel()     # stop the timer's action if it's still waiting
///
///     """
///
///     def __init__(self, interval, function, args=None, kwargs=None):
///         Thread.__init__(self)
///         self.interval = interval
///         self.function = function
///         self.args = args if args is not None else []
///         self.kwargs = kwargs if kwargs is not None else {}
///         self.finished = Event()
///
///     def cancel(self):
///         """Stop the timer if it hasn't finished yet."""
///         self.finished.set()
///
///     def run(self):
///         self.finished.wait(self.interval)
///         if not self.finished.is_set():
///             self.function(*self.args, **self.kwargs)
///         self.finished.set()
///
///
/// # Special thread class to represent the main thread
///
/// class _MainThread(Thread):
///
///     def __init__(self):
///         Thread.__init__(self, name="MainThread", daemon=False)
///         self._set_tstate_lock()
///         self._started.set()
///         self._set_ident()
///         if _HAVE_THREAD_NATIVE_ID:
///             self._set_native_id()
///         with _active_limbo_lock:
///             _active[self._ident] = self
///
///
/// # Dummy thread class to represent threads not started here.
/// # These aren't garbage collected when they die, nor can they be waited for.
/// # If they invoke anything in threading.py that calls current_thread(), they
/// # leave an entry in the _active dict forever after.
/// # Their purpose is to return *something* from current_thread().
/// # They are marked as daemon threads so we won't wait for them
/// # when we exit (conform previous semantics).
///
/// class _DummyThread(Thread):
///
///     def __init__(self):
///         Thread.__init__(self, name=_newname("Dummy-%d"), daemon=True)
///
///         self._started.set()
///         self._set_ident()
///         if _HAVE_THREAD_NATIVE_ID:
///             self._set_native_id()
///         with _active_limbo_lock:
///             _active[self._ident] = self
///
///     def _stop(self):
///         pass
///
///     def is_alive(self):
///         assert not self._is_stopped and self._started.is_set()
///         return True
///
///     def join(self, timeout=None):
///         assert False, "cannot join a dummy thread"
///
///
/// # Global API functions
///
/// def current_thread():
///     """Return the current Thread object, corresponding to the caller's thread of control.
///
///     If the caller's thread of control was not created through the threading
///     module, a dummy thread object with limited functionality is returned.
///
///     """
///     try:
///         return _active[get_ident()]
///     except KeyError:
///         return _DummyThread()
///
/// def currentThread():
///     """Return the current Thread object, corresponding to the caller's thread of control.
///
///     This function is deprecated, use current_thread() instead.
///
///     """
///     import warnings
///     warnings.warn('currentThread() is deprecated, use current_thread() instead',
///                   DeprecationWarning, stacklevel=2)
///     return current_thread()
///
/// def active_count():
///     """Return the number of Thread objects currently alive.
///
///     The returned count is equal to the length of the list returned by
///     enumerate().
///
///     """
///     with _active_limbo_lock:
///         return len(_active) + len(_limbo)
///
/// def activeCount():
///     """Return the number of Thread objects currently alive.
///
///     This function is deprecated, use active_count() instead.
///
///     """
///     import warnings
///     warnings.warn('activeCount() is deprecated, use active_count() instead',
///                   DeprecationWarning, stacklevel=2)
///     return active_count()
///
/// def _enumerate():
///     # Same as enumerate(), but without the lock. Internal use only.
///     return list(_active.values()) + list(_limbo.values())
///
/// def enumerate():
///     """Return a list of all Thread objects currently alive.
///
///     The list includes daemonic threads, dummy thread objects created by
///     current_thread(), and the main thread. It excludes terminated threads and
///     threads that have not yet been started.
///
///     """
///     with _active_limbo_lock:
///         return list(_active.values()) + list(_limbo.values())
///
///
/// _threading_atexits = []
/// _SHUTTING_DOWN = False
///
/// def _register_atexit(func, *arg, **kwargs):
///     """CPython internal: register *func* to be called before joining threads.
///
///     The registered *func* is called with its arguments just before all
///     non-daemon threads are joined in `_shutdown()`. It provides a similar
///     purpose to `atexit.register()`, but its functions are called prior to
///     threading shutdown instead of interpreter shutdown.
///
///     For similarity to atexit, the registered functions are called in reverse.
///     """
///     if _SHUTTING_DOWN:
///         raise RuntimeError("can't register atexit after shutdown")
///
///     call = functools.partial(func, *arg, **kwargs)
///     _threading_atexits.append(call)
///
///
/// from _thread import stack_size
///
/// # Create the main thread object,
/// # and make it available for the interpreter
/// # (Py_Main) as threading._shutdown.
///
/// _main_thread = _MainThread()
///
/// def _shutdown():
///     """
///     Wait until the Python thread state of all non-daemon threads get deleted.
///     """
///     # Obscure:  other threads may be waiting to join _main_thread.  That's
///     # dubious, but some code does it.  We can't wait for C code to release
///     # the main thread's tstate_lock - that won't happen until the interpreter
///     # is nearly dead.  So we release it here.  Note that just calling _stop()
///     # isn't enough:  other threads may already be waiting on _tstate_lock.
///     if _main_thread._is_stopped:
///         # _shutdown() was already called
///         return
///
///     global _SHUTTING_DOWN
///     _SHUTTING_DOWN = True
///
///     # Call registered threading atexit functions before threads are joined.
///     # Order is reversed, similar to atexit.
///     for atexit_call in reversed(_threading_atexits):
///         atexit_call()
///
///     # Main thread
///     if _main_thread.ident == get_ident():
///         tlock = _main_thread._tstate_lock
///         # The main thread isn't finished yet, so its thread state lock can't
///         # have been released.
///         assert tlock is not None
///         assert tlock.locked()
///         tlock.release()
///         _main_thread._stop()
///     else:
///         # bpo-1596321: _shutdown() must be called in the main thread.
///         # If the threading module was not imported by the main thread,
///         # _main_thread is the thread which imported the threading module.
///         # In this case, ignore _main_thread, similar behavior than for threads
///         # spawned by C libraries or using _thread.start_new_thread().
///         pass
///
///     # Join all non-deamon threads
///     while True:
///         with _shutdown_locks_lock:
///             locks = list(_shutdown_locks)
///             _shutdown_locks.clear()
///
///         if not locks:
///             break
///
///         for lock in locks:
///             # mimic Thread.join()
///             lock.acquire()
///             lock.release()
///
///         # new threads can be spawned while we were waiting for the other
///         # threads to complete
///
///
/// def main_thread():
///     """Return the main thread object.
///
///     In normal conditions, the main thread is the thread from which the
///     Python interpreter was started.
///     """
///     return _main_thread
///
/// # get thread-local implementation, either from the thread
/// # module, or from the python fallback
///
/// try:
///     from _thread import _local as local
/// except ImportError:
///     from _threading_local import local
///
///
/// def _after_fork():
///     """
///     Cleanup threading module state that should not exist after a fork.
///     """
///     # Reset _active_limbo_lock, in case we forked while the lock was held
///     # by another (non-forked) thread.  http://bugs.python.org/issue874900
///     global _active_limbo_lock, _main_thread
///     global _shutdown_locks_lock, _shutdown_locks
///     _active_limbo_lock = RLock()
///
///     # fork() only copied the current thread; clear references to others.
///     new_active = {}
///
///     try:
///         current = _active[get_ident()]
///     except KeyError:
///         # fork() was called in a thread which was not spawned
///         # by threading.Thread. For example, a thread spawned
///         # by thread.start_new_thread().
///         current = _MainThread()
///
///     _main_thread = current
///
///     # reset _shutdown() locks: threads re-register their _tstate_lock below
///     _shutdown_locks_lock = _allocate_lock()
///     _shutdown_locks = set()
///
///     with _active_limbo_lock:
///         # Dangling thread instances must still have their locks reset,
///         # because someone may join() them.
///         threads = set(_enumerate())
///         threads.update(_dangling)
///         for thread in threads:
///             # Any lock/condition variable may be currently locked or in an
///             # invalid state, so we reinitialize them.
///             if thread is current:
///                 # There is only one active thread. We reset the ident to
///                 # its new value since it can have changed.
///                 thread._reset_internal_locks(True)
///                 ident = get_ident()
///                 thread._ident = ident
///                 new_active[ident] = thread
///             else:
///                 # All the others are already stopped.
///                 thread._reset_internal_locks(False)
///                 thread._stop()
///
///         _limbo.clear()
///         _active.clear()
///         _active.update(new_active)
///         assert len(_active) == 1
///
///
/// if hasattr(_os, "register_at_fork"):
///     _os.register_at_fork(after_in_child=_after_fork)
/// ```
final class threading extends PythonModule {
  threading.from(super.pythonModule) : super.from();

  static threading import() => PythonFfiDart.instance.importModule(
        "threading",
        threading.from,
      );

  /// ## RLock
  ///
  /// ### python docstring
  ///
  /// Factory function that returns a new reentrant lock.
  ///
  /// A reentrant lock must be released by the thread that acquired it. Once a
  /// thread has acquired a reentrant lock, the same thread may acquire it again
  /// without blocking; the thread must release it once for each time it has
  /// acquired it.
  ///
  /// ### python source
  /// ```py
  /// def RLock(*args, **kwargs):
  ///     """Factory function that returns a new reentrant lock.
  ///
  ///     A reentrant lock must be released by the thread that acquired it. Once a
  ///     thread has acquired a reentrant lock, the same thread may acquire it again
  ///     without blocking; the thread must release it once for each time it has
  ///     acquired it.
  ///
  ///     """
  ///     if _CRLock is None:
  ///         return _PyRLock(*args, **kwargs)
  ///     return _CRLock(*args, **kwargs)
  /// ```
  Object? RLock({
    List<Object?> args = const <Object?>[],
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("RLock").call(
        <Object?>[
          ...args,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## activeCount
  ///
  /// ### python docstring
  ///
  /// Return the number of Thread objects currently alive.
  ///
  /// This function is deprecated, use active_count() instead.
  ///
  /// ### python source
  /// ```py
  /// def activeCount():
  ///     """Return the number of Thread objects currently alive.
  ///
  ///     This function is deprecated, use active_count() instead.
  ///
  ///     """
  ///     import warnings
  ///     warnings.warn('activeCount() is deprecated, use active_count() instead',
  ///                   DeprecationWarning, stacklevel=2)
  ///     return active_count()
  /// ```
  Object? activeCount() => getFunction("activeCount").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## active_count
  ///
  /// ### python docstring
  ///
  /// Return the number of Thread objects currently alive.
  ///
  /// The returned count is equal to the length of the list returned by
  /// enumerate().
  ///
  /// ### python source
  /// ```py
  /// def active_count():
  ///     """Return the number of Thread objects currently alive.
  ///
  ///     The returned count is equal to the length of the list returned by
  ///     enumerate().
  ///
  ///     """
  ///     with _active_limbo_lock:
  ///         return len(_active) + len(_limbo)
  /// ```
  Object? active_count() => getFunction("active_count").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## currentThread
  ///
  /// ### python docstring
  ///
  /// Return the current Thread object, corresponding to the caller's thread of control.
  ///
  /// This function is deprecated, use current_thread() instead.
  ///
  /// ### python source
  /// ```py
  /// def currentThread():
  ///     """Return the current Thread object, corresponding to the caller's thread of control.
  ///
  ///     This function is deprecated, use current_thread() instead.
  ///
  ///     """
  ///     import warnings
  ///     warnings.warn('currentThread() is deprecated, use current_thread() instead',
  ///                   DeprecationWarning, stacklevel=2)
  ///     return current_thread()
  /// ```
  Object? currentThread() => getFunction("currentThread").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## current_thread
  ///
  /// ### python docstring
  ///
  /// Return the current Thread object, corresponding to the caller's thread of control.
  ///
  /// If the caller's thread of control was not created through the threading
  /// module, a dummy thread object with limited functionality is returned.
  ///
  /// ### python source
  /// ```py
  /// def current_thread():
  ///     """Return the current Thread object, corresponding to the caller's thread of control.
  ///
  ///     If the caller's thread of control was not created through the threading
  ///     module, a dummy thread object with limited functionality is returned.
  ///
  ///     """
  ///     try:
  ///         return _active[get_ident()]
  ///     except KeyError:
  ///         return _DummyThread()
  /// ```
  Object? current_thread() => getFunction("current_thread").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## enumerate
  ///
  /// ### python docstring
  ///
  /// Return a list of all Thread objects currently alive.
  ///
  /// The list includes daemonic threads, dummy thread objects created by
  /// current_thread(), and the main thread. It excludes terminated threads and
  /// threads that have not yet been started.
  ///
  /// ### python source
  /// ```py
  /// def enumerate():
  ///     """Return a list of all Thread objects currently alive.
  ///
  ///     The list includes daemonic threads, dummy thread objects created by
  ///     current_thread(), and the main thread. It excludes terminated threads and
  ///     threads that have not yet been started.
  ///
  ///     """
  ///     with _active_limbo_lock:
  ///         return list(_active.values()) + list(_limbo.values())
  /// ```
  Object? enumerate() => getFunction("enumerate").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## getprofile
  ///
  /// ### python docstring
  ///
  /// Get the profiler function as set by threading.setprofile().
  ///
  /// ### python source
  /// ```py
  /// def getprofile():
  ///     """Get the profiler function as set by threading.setprofile()."""
  ///     return _profile_hook
  /// ```
  Object? getprofile() => getFunction("getprofile").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## gettrace
  ///
  /// ### python docstring
  ///
  /// Get the trace function as set by threading.settrace().
  ///
  /// ### python source
  /// ```py
  /// def gettrace():
  ///     """Get the trace function as set by threading.settrace()."""
  ///     return _trace_hook
  /// ```
  Object? gettrace() => getFunction("gettrace").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## main_thread
  ///
  /// ### python docstring
  ///
  /// Return the main thread object.
  ///
  /// In normal conditions, the main thread is the thread from which the
  /// Python interpreter was started.
  ///
  /// ### python source
  /// ```py
  /// def main_thread():
  ///     """Return the main thread object.
  ///
  ///     In normal conditions, the main thread is the thread from which the
  ///     Python interpreter was started.
  ///     """
  ///     return _main_thread
  /// ```
  Object? main_thread() => getFunction("main_thread").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## setprofile
  ///
  /// ### python docstring
  ///
  /// Set a profile function for all threads started from the threading module.
  ///
  /// The func will be passed to sys.setprofile() for each thread, before its
  /// run() method is called.
  ///
  /// ### python source
  /// ```py
  /// def setprofile(func):
  ///     """Set a profile function for all threads started from the threading module.
  ///
  ///     The func will be passed to sys.setprofile() for each thread, before its
  ///     run() method is called.
  ///
  ///     """
  ///     global _profile_hook
  ///     _profile_hook = func
  /// ```
  Object? setprofile({
    required Object? func,
  }) =>
      getFunction("setprofile").call(
        <Object?>[
          func,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## settrace
  ///
  /// ### python docstring
  ///
  /// Set a trace function for all threads started from the threading module.
  ///
  /// The func will be passed to sys.settrace() for each thread, before its run()
  /// method is called.
  ///
  /// ### python source
  /// ```py
  /// def settrace(func):
  ///     """Set a trace function for all threads started from the threading module.
  ///
  ///     The func will be passed to sys.settrace() for each thread, before its run()
  ///     method is called.
  ///
  ///     """
  ///     global _trace_hook
  ///     _trace_hook = func
  /// ```
  Object? settrace({
    required Object? func,
  }) =>
      getFunction("settrace").call(
        <Object?>[
          func,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## TIMEOUT_MAX (getter)
  Object? get TIMEOUT_MAX => getAttribute("TIMEOUT_MAX");

  /// ## TIMEOUT_MAX (setter)
  set TIMEOUT_MAX(Object? TIMEOUT_MAX) =>
      setAttribute("TIMEOUT_MAX", TIMEOUT_MAX);
}

/// ## traceback
///
/// ### python docstring
///
/// Extract, format and print information about Python stack traces.
///
/// ### python source
/// ```py
/// """Extract, format and print information about Python stack traces."""
///
/// import collections.abc
/// import itertools
/// import linecache
/// import sys
/// import textwrap
/// from contextlib import suppress
///
/// __all__ = ['extract_stack', 'extract_tb', 'format_exception',
///            'format_exception_only', 'format_list', 'format_stack',
///            'format_tb', 'print_exc', 'format_exc', 'print_exception',
///            'print_last', 'print_stack', 'print_tb', 'clear_frames',
///            'FrameSummary', 'StackSummary', 'TracebackException',
///            'walk_stack', 'walk_tb']
///
/// #
/// # Formatting and printing lists of traceback lines.
/// #
///
/// def print_list(extracted_list, file=None):
///     """Print the list of tuples as returned by extract_tb() or
///     extract_stack() as a formatted stack trace to the given file."""
///     if file is None:
///         file = sys.stderr
///     for item in StackSummary.from_list(extracted_list).format():
///         print(item, file=file, end="")
///
/// def format_list(extracted_list):
///     """Format a list of tuples or FrameSummary objects for printing.
///
///     Given a list of tuples or FrameSummary objects as returned by
///     extract_tb() or extract_stack(), return a list of strings ready
///     for printing.
///
///     Each string in the resulting list corresponds to the item with the
///     same index in the argument list.  Each string ends in a newline;
///     the strings may contain internal newlines as well, for those items
///     whose source text line is not None.
///     """
///     return StackSummary.from_list(extracted_list).format()
///
/// #
/// # Printing and Extracting Tracebacks.
/// #
///
/// def print_tb(tb, limit=None, file=None):
///     """Print up to 'limit' stack trace entries from the traceback 'tb'.
///
///     If 'limit' is omitted or None, all entries are printed.  If 'file'
///     is omitted or None, the output goes to sys.stderr; otherwise
///     'file' should be an open file or file-like object with a write()
///     method.
///     """
///     print_list(extract_tb(tb, limit=limit), file=file)
///
/// def format_tb(tb, limit=None):
///     """A shorthand for 'format_list(extract_tb(tb, limit))'."""
///     return extract_tb(tb, limit=limit).format()
///
/// def extract_tb(tb, limit=None):
///     """
///     Return a StackSummary object representing a list of
///     pre-processed entries from traceback.
///
///     This is useful for alternate formatting of stack traces.  If
///     'limit' is omitted or None, all entries are extracted.  A
///     pre-processed stack trace entry is a FrameSummary object
///     containing attributes filename, lineno, name, and line
///     representing the information that is usually printed for a stack
///     trace.  The line is a string with leading and trailing
///     whitespace stripped; if the source is not available it is None.
///     """
///     return StackSummary._extract_from_extended_frame_gen(
///         _walk_tb_with_full_positions(tb), limit=limit)
///
/// #
/// # Exception formatting and output.
/// #
///
/// _cause_message = (
///     "\nThe above exception was the direct cause "
///     "of the following exception:\n\n")
///
/// _context_message = (
///     "\nDuring handling of the above exception, "
///     "another exception occurred:\n\n")
///
///
/// class _Sentinel:
///     def __repr__(self):
///         return "<implicit>"
///
/// _sentinel = _Sentinel()
///
/// def _parse_value_tb(exc, value, tb):
///     if (value is _sentinel) != (tb is _sentinel):
///         raise ValueError("Both or neither of value and tb must be given")
///     if value is tb is _sentinel:
///         if exc is not None:
///             if isinstance(exc, BaseException):
///                 return exc, exc.__traceback__
///
///             raise TypeError(f'Exception expected for value, '
///                             f'{type(exc).__name__} found')
///         else:
///             return None, None
///     return value, tb
///
///
/// def print_exception(exc, /, value=_sentinel, tb=_sentinel, limit=None, \
///                     file=None, chain=True):
///     """Print exception up to 'limit' stack trace entries from 'tb' to 'file'.
///
///     This differs from print_tb() in the following ways: (1) if
///     traceback is not None, it prints a header "Traceback (most recent
///     call last):"; (2) it prints the exception type and value after the
///     stack trace; (3) if type is SyntaxError and value has the
///     appropriate format, it prints the line where the syntax error
///     occurred with a caret on the next line indicating the approximate
///     position of the error.
///     """
///     value, tb = _parse_value_tb(exc, value, tb)
///     te = TracebackException(type(value), value, tb, limit=limit, compact=True)
///     te.print(file=file, chain=chain)
///
///
/// def format_exception(exc, /, value=_sentinel, tb=_sentinel, limit=None, \
///                      chain=True):
///     """Format a stack trace and the exception information.
///
///     The arguments have the same meaning as the corresponding arguments
///     to print_exception().  The return value is a list of strings, each
///     ending in a newline and some containing internal newlines.  When
///     these lines are concatenated and printed, exactly the same text is
///     printed as does print_exception().
///     """
///     value, tb = _parse_value_tb(exc, value, tb)
///     te = TracebackException(type(value), value, tb, limit=limit, compact=True)
///     return list(te.format(chain=chain))
///
///
/// def format_exception_only(exc, /, value=_sentinel):
///     """Format the exception part of a traceback.
///
///     The return value is a list of strings, each ending in a newline.
///
///     Normally, the list contains a single string; however, for
///     SyntaxError exceptions, it contains several lines that (when
///     printed) display detailed information about where the syntax
///     error occurred.
///
///     The message indicating which exception occurred is always the last
///     string in the list.
///
///     """
///     if value is _sentinel:
///         value = exc
///     te = TracebackException(type(value), value, None, compact=True)
///     return list(te.format_exception_only())
///
///
/// # -- not official API but folk probably use these two functions.
///
/// def _format_final_exc_line(etype, value):
///     valuestr = _safe_string(value, 'exception')
///     if value is None or not valuestr:
///         line = "%s\n" % etype
///     else:
///         line = "%s: %s\n" % (etype, valuestr)
///     return line
///
/// def _safe_string(value, what, func=str):
///     try:
///         return func(value)
///     except:
///         return f'<{what} {func.__name__}() failed>'
///
/// # --
///
/// def print_exc(limit=None, file=None, chain=True):
///     """Shorthand for 'print_exception(*sys.exc_info(), limit, file)'."""
///     print_exception(*sys.exc_info(), limit=limit, file=file, chain=chain)
///
/// def format_exc(limit=None, chain=True):
///     """Like print_exc() but return a string."""
///     return "".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))
///
/// def print_last(limit=None, file=None, chain=True):
///     """This is a shorthand for 'print_exception(sys.last_type,
///     sys.last_value, sys.last_traceback, limit, file)'."""
///     if not hasattr(sys, "last_type"):
///         raise ValueError("no last exception")
///     print_exception(sys.last_type, sys.last_value, sys.last_traceback,
///                     limit, file, chain)
///
/// #
/// # Printing and Extracting Stacks.
/// #
///
/// def print_stack(f=None, limit=None, file=None):
///     """Print a stack trace from its invocation point.
///
///     The optional 'f' argument can be used to specify an alternate
///     stack frame at which to start. The optional 'limit' and 'file'
///     arguments have the same meaning as for print_exception().
///     """
///     if f is None:
///         f = sys._getframe().f_back
///     print_list(extract_stack(f, limit=limit), file=file)
///
///
/// def format_stack(f=None, limit=None):
///     """Shorthand for 'format_list(extract_stack(f, limit))'."""
///     if f is None:
///         f = sys._getframe().f_back
///     return format_list(extract_stack(f, limit=limit))
///
///
/// def extract_stack(f=None, limit=None):
///     """Extract the raw traceback from the current stack frame.
///
///     The return value has the same format as for extract_tb().  The
///     optional 'f' and 'limit' arguments have the same meaning as for
///     print_stack().  Each item in the list is a quadruple (filename,
///     line number, function name, text), and the entries are in order
///     from oldest to newest stack frame.
///     """
///     if f is None:
///         f = sys._getframe().f_back
///     stack = StackSummary.extract(walk_stack(f), limit=limit)
///     stack.reverse()
///     return stack
///
///
/// def clear_frames(tb):
///     "Clear all references to local variables in the frames of a traceback."
///     while tb is not None:
///         try:
///             tb.tb_frame.clear()
///         except RuntimeError:
///             # Ignore the exception raised if the frame is still executing.
///             pass
///         tb = tb.tb_next
///
///
/// class FrameSummary:
///     """Information about a single frame from a traceback.
///
///     - :attr:`filename` The filename for the frame.
///     - :attr:`lineno` The line within filename for the frame that was
///       active when the frame was captured.
///     - :attr:`name` The name of the function or method that was executing
///       when the frame was captured.
///     - :attr:`line` The text from the linecache module for the
///       of code that was running when the frame was captured.
///     - :attr:`locals` Either None if locals were not supplied, or a dict
///       mapping the name to the repr() of the variable.
///     """
///
///     __slots__ = ('filename', 'lineno', 'end_lineno', 'colno', 'end_colno',
///                  'name', '_line', 'locals')
///
///     def __init__(self, filename, lineno, name, *, lookup_line=True,
///             locals=None, line=None,
///             end_lineno=None, colno=None, end_colno=None):
///         """Construct a FrameSummary.
///
///         :param lookup_line: If True, `linecache` is consulted for the source
///             code line. Otherwise, the line will be looked up when first needed.
///         :param locals: If supplied the frame locals, which will be captured as
///             object representations.
///         :param line: If provided, use this instead of looking up the line in
///             the linecache.
///         """
///         self.filename = filename
///         self.lineno = lineno
///         self.name = name
///         self._line = line
///         if lookup_line:
///             self.line
///         self.locals = {k: repr(v) for k, v in locals.items()} if locals else None
///         self.end_lineno = end_lineno
///         self.colno = colno
///         self.end_colno = end_colno
///
///     def __eq__(self, other):
///         if isinstance(other, FrameSummary):
///             return (self.filename == other.filename and
///                     self.lineno == other.lineno and
///                     self.name == other.name and
///                     self.locals == other.locals)
///         if isinstance(other, tuple):
///             return (self.filename, self.lineno, self.name, self.line) == other
///         return NotImplemented
///
///     def __getitem__(self, pos):
///         return (self.filename, self.lineno, self.name, self.line)[pos]
///
///     def __iter__(self):
///         return iter([self.filename, self.lineno, self.name, self.line])
///
///     def __repr__(self):
///         return "<FrameSummary file {filename}, line {lineno} in {name}>".format(
///             filename=self.filename, lineno=self.lineno, name=self.name)
///
///     def __len__(self):
///         return 4
///
///     @property
///     def _original_line(self):
///         # Returns the line as-is from the source, without modifying whitespace.
///         self.line
///         return self._line
///
///     @property
///     def line(self):
///         if self._line is None:
///             if self.lineno is None:
///                 return None
///             self._line = linecache.getline(self.filename, self.lineno)
///         return self._line.strip()
///
///
/// def walk_stack(f):
///     """Walk a stack yielding the frame and line number for each frame.
///
///     This will follow f.f_back from the given frame. If no frame is given, the
///     current stack is used. Usually used with StackSummary.extract.
///     """
///     if f is None:
///         f = sys._getframe().f_back.f_back.f_back.f_back
///     while f is not None:
///         yield f, f.f_lineno
///         f = f.f_back
///
///
/// def walk_tb(tb):
///     """Walk a traceback yielding the frame and line number for each frame.
///
///     This will follow tb.tb_next (and thus is in the opposite order to
///     walk_stack). Usually used with StackSummary.extract.
///     """
///     while tb is not None:
///         yield tb.tb_frame, tb.tb_lineno
///         tb = tb.tb_next
///
///
/// def _walk_tb_with_full_positions(tb):
///     # Internal version of walk_tb that yields full code positions including
///     # end line and column information.
///     while tb is not None:
///         positions = _get_code_position(tb.tb_frame.f_code, tb.tb_lasti)
///         # Yield tb_lineno when co_positions does not have a line number to
///         # maintain behavior with walk_tb.
///         if positions[0] is None:
///             yield tb.tb_frame, (tb.tb_lineno, ) + positions[1:]
///         else:
///             yield tb.tb_frame, positions
///         tb = tb.tb_next
///
///
/// def _get_code_position(code, instruction_index):
///     if instruction_index < 0:
///         return (None, None, None, None)
///     positions_gen = code.co_positions()
///     return next(itertools.islice(positions_gen, instruction_index // 2, None))
///
///
/// _RECURSIVE_CUTOFF = 3 # Also hardcoded in traceback.c.
///
/// class StackSummary(list):
///     """A list of FrameSummary objects, representing a stack of frames."""
///
///     @classmethod
///     def extract(klass, frame_gen, *, limit=None, lookup_lines=True,
///             capture_locals=False):
///         """Create a StackSummary from a traceback or stack object.
///
///         :param frame_gen: A generator that yields (frame, lineno) tuples
///             whose summaries are to be included in the stack.
///         :param limit: None to include all frames or the number of frames to
///             include.
///         :param lookup_lines: If True, lookup lines for each frame immediately,
///             otherwise lookup is deferred until the frame is rendered.
///         :param capture_locals: If True, the local variables from each frame will
///             be captured as object representations into the FrameSummary.
///         """
///         def extended_frame_gen():
///             for f, lineno in frame_gen:
///                 yield f, (lineno, None, None, None)
///
///         return klass._extract_from_extended_frame_gen(
///             extended_frame_gen(), limit=limit, lookup_lines=lookup_lines,
///             capture_locals=capture_locals)
///
///     @classmethod
///     def _extract_from_extended_frame_gen(klass, frame_gen, *, limit=None,
///             lookup_lines=True, capture_locals=False):
///         # Same as extract but operates on a frame generator that yields
///         # (frame, (lineno, end_lineno, colno, end_colno)) in the stack.
///         # Only lineno is required, the remaining fields can be None if the
///         # information is not available.
///         if limit is None:
///             limit = getattr(sys, 'tracebacklimit', None)
///             if limit is not None and limit < 0:
///                 limit = 0
///         if limit is not None:
///             if limit >= 0:
///                 frame_gen = itertools.islice(frame_gen, limit)
///             else:
///                 frame_gen = collections.deque(frame_gen, maxlen=-limit)
///
///         result = klass()
///         fnames = set()
///         for f, (lineno, end_lineno, colno, end_colno) in frame_gen:
///             co = f.f_code
///             filename = co.co_filename
///             name = co.co_name
///
///             fnames.add(filename)
///             linecache.lazycache(filename, f.f_globals)
///             # Must defer line lookups until we have called checkcache.
///             if capture_locals:
///                 f_locals = f.f_locals
///             else:
///                 f_locals = None
///             result.append(FrameSummary(
///                 filename, lineno, name, lookup_line=False, locals=f_locals,
///                 end_lineno=end_lineno, colno=colno, end_colno=end_colno))
///         for filename in fnames:
///             linecache.checkcache(filename)
///         # If immediate lookup was desired, trigger lookups now.
///         if lookup_lines:
///             for f in result:
///                 f.line
///         return result
///
///     @classmethod
///     def from_list(klass, a_list):
///         """
///         Create a StackSummary object from a supplied list of
///         FrameSummary objects or old-style list of tuples.
///         """
///         # While doing a fast-path check for isinstance(a_list, StackSummary) is
///         # appealing, idlelib.run.cleanup_traceback and other similar code may
///         # break this by making arbitrary frames plain tuples, so we need to
///         # check on a frame by frame basis.
///         result = StackSummary()
///         for frame in a_list:
///             if isinstance(frame, FrameSummary):
///                 result.append(frame)
///             else:
///                 filename, lineno, name, line = frame
///                 result.append(FrameSummary(filename, lineno, name, line=line))
///         return result
///
///     def format_frame_summary(self, frame_summary):
///         """Format the lines for a single FrameSummary.
///
///         Returns a string representing one frame involved in the stack. This
///         gets called for every frame to be printed in the stack summary.
///         """
///         row = []
///         row.append('  File "{}", line {}, in {}\n'.format(
///             frame_summary.filename, frame_summary.lineno, frame_summary.name))
///         if frame_summary.line:
///             stripped_line = frame_summary.line.strip()
///             row.append('    {}\n'.format(stripped_line))
///
///             orig_line_len = len(frame_summary._original_line)
///             frame_line_len = len(frame_summary.line.lstrip())
///             stripped_characters = orig_line_len - frame_line_len
///             if (
///                 frame_summary.colno is not None
///                 and frame_summary.end_colno is not None
///             ):
///                 start_offset = _byte_offset_to_character_offset(
///                     frame_summary._original_line, frame_summary.colno) + 1
///                 end_offset = _byte_offset_to_character_offset(
///                     frame_summary._original_line, frame_summary.end_colno) + 1
///
///                 anchors = None
///                 if frame_summary.lineno == frame_summary.end_lineno:
///                     with suppress(Exception):
///                         anchors = _extract_caret_anchors_from_line_segment(
///                             frame_summary._original_line[start_offset - 1:end_offset - 1]
///                         )
///                 else:
///                     end_offset = stripped_characters + len(stripped_line)
///
///                 # show indicators if primary char doesn't span the frame line
///                 if end_offset - start_offset < len(stripped_line) or (
///                         anchors and anchors.right_start_offset - anchors.left_end_offset > 0):
///                     row.append('    ')
///                     row.append(' ' * (start_offset - stripped_characters))
///
///                     if anchors:
///                         row.append(anchors.primary_char * (anchors.left_end_offset))
///                         row.append(anchors.secondary_char * (anchors.right_start_offset - anchors.left_end_offset))
///                         row.append(anchors.primary_char * (end_offset - start_offset - anchors.right_start_offset))
///                     else:
///                         row.append('^' * (end_offset - start_offset))
///
///                     row.append('\n')
///
///         if frame_summary.locals:
///             for name, value in sorted(frame_summary.locals.items()):
///                 row.append('    {name} = {value}\n'.format(name=name, value=value))
///
///         return ''.join(row)
///
///     def format(self):
///         """Format the stack ready for printing.
///
///         Returns a list of strings ready for printing.  Each string in the
///         resulting list corresponds to a single frame from the stack.
///         Each string ends in a newline; the strings may contain internal
///         newlines as well, for those items with source text lines.
///
///         For long sequences of the same frame and line, the first few
///         repetitions are shown, followed by a summary line stating the exact
///         number of further repetitions.
///         """
///         result = []
///         last_file = None
///         last_line = None
///         last_name = None
///         count = 0
///         for frame_summary in self:
///             formatted_frame = self.format_frame_summary(frame_summary)
///             if formatted_frame is None:
///                 continue
///             if (last_file is None or last_file != frame_summary.filename or
///                 last_line is None or last_line != frame_summary.lineno or
///                 last_name is None or last_name != frame_summary.name):
///                 if count > _RECURSIVE_CUTOFF:
///                     count -= _RECURSIVE_CUTOFF
///                     result.append(
///                         f'  [Previous line repeated {count} more '
///                         f'time{"s" if count > 1 else ""}]\n'
///                     )
///                 last_file = frame_summary.filename
///                 last_line = frame_summary.lineno
///                 last_name = frame_summary.name
///                 count = 0
///             count += 1
///             if count > _RECURSIVE_CUTOFF:
///                 continue
///             result.append(formatted_frame)
///
///         if count > _RECURSIVE_CUTOFF:
///             count -= _RECURSIVE_CUTOFF
///             result.append(
///                 f'  [Previous line repeated {count} more '
///                 f'time{"s" if count > 1 else ""}]\n'
///             )
///         return result
///
///
/// def _byte_offset_to_character_offset(str, offset):
///     as_utf8 = str.encode('utf-8')
///     return len(as_utf8[:offset].decode("utf-8", errors="replace"))
///
///
/// _Anchors = collections.namedtuple(
///     "_Anchors",
///     [
///         "left_end_offset",
///         "right_start_offset",
///         "primary_char",
///         "secondary_char",
///     ],
///     defaults=["~", "^"]
/// )
///
/// def _extract_caret_anchors_from_line_segment(segment):
///     import ast
///
///     try:
///         tree = ast.parse(segment)
///     except SyntaxError:
///         return None
///
///     if len(tree.body) != 1:
///         return None
///
///     normalize = lambda offset: _byte_offset_to_character_offset(segment, offset)
///     statement = tree.body[0]
///     match statement:
///         case ast.Expr(expr):
///             match expr:
///                 case ast.BinOp():
///                     operator_start = normalize(expr.left.end_col_offset)
///                     operator_end = normalize(expr.right.col_offset)
///                     operator_str = segment[operator_start:operator_end]
///                     operator_offset = len(operator_str) - len(operator_str.lstrip())
///
///                     left_anchor = expr.left.end_col_offset + operator_offset
///                     right_anchor = left_anchor + 1
///                     if (
///                         operator_offset + 1 < len(operator_str)
///                         and not operator_str[operator_offset + 1].isspace()
///                     ):
///                         right_anchor += 1
///                     return _Anchors(normalize(left_anchor), normalize(right_anchor))
///                 case ast.Subscript():
///                     subscript_start = normalize(expr.value.end_col_offset)
///                     subscript_end = normalize(expr.slice.end_col_offset + 1)
///                     return _Anchors(subscript_start, subscript_end)
///
///     return None
///
///
/// class _ExceptionPrintContext:
///     def __init__(self):
///         self.seen = set()
///         self.exception_group_depth = 0
///         self.need_close = False
///
///     def indent(self):
///         return ' ' * (2 * self.exception_group_depth)
///
///     def emit(self, text_gen, margin_char=None):
///         if margin_char is None:
///             margin_char = '|'
///         indent_str = self.indent()
///         if self.exception_group_depth:
///             indent_str += margin_char + ' '
///
///         if isinstance(text_gen, str):
///             yield textwrap.indent(text_gen, indent_str, lambda line: True)
///         else:
///             for text in text_gen:
///                 yield textwrap.indent(text, indent_str, lambda line: True)
///
///
/// class TracebackException:
///     """An exception ready for rendering.
///
///     The traceback module captures enough attributes from the original exception
///     to this intermediary form to ensure that no references are held, while
///     still being able to fully print or format it.
///
///     max_group_width and max_group_depth control the formatting of exception
///     groups. The depth refers to the nesting level of the group, and the width
///     refers to the size of a single exception group's exceptions array. The
///     formatted output is truncated when either limit is exceeded.
///
///     Use `from_exception` to create TracebackException instances from exception
///     objects, or the constructor to create TracebackException instances from
///     individual components.
///
///     - :attr:`__cause__` A TracebackException of the original *__cause__*.
///     - :attr:`__context__` A TracebackException of the original *__context__*.
///     - :attr:`__suppress_context__` The *__suppress_context__* value from the
///       original exception.
///     - :attr:`stack` A `StackSummary` representing the traceback.
///     - :attr:`exc_type` The class of the original traceback.
///     - :attr:`filename` For syntax errors - the filename where the error
///       occurred.
///     - :attr:`lineno` For syntax errors - the linenumber where the error
///       occurred.
///     - :attr:`end_lineno` For syntax errors - the end linenumber where the error
///       occurred. Can be `None` if not present.
///     - :attr:`text` For syntax errors - the text where the error
///       occurred.
///     - :attr:`offset` For syntax errors - the offset into the text where the
///       error occurred.
///     - :attr:`end_offset` For syntax errors - the offset into the text where the
///       error occurred. Can be `None` if not present.
///     - :attr:`msg` For syntax errors - the compiler error message.
///     """
///
///     def __init__(self, exc_type, exc_value, exc_traceback, *, limit=None,
///             lookup_lines=True, capture_locals=False, compact=False,
///             max_group_width=15, max_group_depth=10, _seen=None):
///         # NB: we need to accept exc_traceback, exc_value, exc_traceback to
///         # permit backwards compat with the existing API, otherwise we
///         # need stub thunk objects just to glue it together.
///         # Handle loops in __cause__ or __context__.
///         is_recursive_call = _seen is not None
///         if _seen is None:
///             _seen = set()
///         _seen.add(id(exc_value))
///
///         self.max_group_width = max_group_width
///         self.max_group_depth = max_group_depth
///
///         self.stack = StackSummary._extract_from_extended_frame_gen(
///             _walk_tb_with_full_positions(exc_traceback),
///             limit=limit, lookup_lines=lookup_lines,
///             capture_locals=capture_locals)
///         self.exc_type = exc_type
///         # Capture now to permit freeing resources: only complication is in the
///         # unofficial API _format_final_exc_line
///         self._str = _safe_string(exc_value, 'exception')
///         self.__notes__ = getattr(exc_value, '__notes__', None)
///
///         if exc_type and issubclass(exc_type, SyntaxError):
///             # Handle SyntaxError's specially
///             self.filename = exc_value.filename
///             lno = exc_value.lineno
///             self.lineno = str(lno) if lno is not None else None
///             end_lno = exc_value.end_lineno
///             self.end_lineno = str(end_lno) if end_lno is not None else None
///             self.text = exc_value.text
///             self.offset = exc_value.offset
///             self.end_offset = exc_value.end_offset
///             self.msg = exc_value.msg
///         if lookup_lines:
///             self._load_lines()
///         self.__suppress_context__ = \
///             exc_value.__suppress_context__ if exc_value is not None else False
///
///         # Convert __cause__ and __context__ to `TracebackExceptions`s, use a
///         # queue to avoid recursion (only the top-level call gets _seen == None)
///         if not is_recursive_call:
///             queue = [(self, exc_value)]
///             while queue:
///                 te, e = queue.pop()
///                 if (e and e.__cause__ is not None
///                     and id(e.__cause__) not in _seen):
///                     cause = TracebackException(
///                         type(e.__cause__),
///                         e.__cause__,
///                         e.__cause__.__traceback__,
///                         limit=limit,
///                         lookup_lines=lookup_lines,
///                         capture_locals=capture_locals,
///                         max_group_width=max_group_width,
///                         max_group_depth=max_group_depth,
///                         _seen=_seen)
///                 else:
///                     cause = None
///
///                 if compact:
///                     need_context = (cause is None and
///                                     e is not None and
///                                     not e.__suppress_context__)
///                 else:
///                     need_context = True
///                 if (e and e.__context__ is not None
///                     and need_context and id(e.__context__) not in _seen):
///                     context = TracebackException(
///                         type(e.__context__),
///                         e.__context__,
///                         e.__context__.__traceback__,
///                         limit=limit,
///                         lookup_lines=lookup_lines,
///                         capture_locals=capture_locals,
///                         max_group_width=max_group_width,
///                         max_group_depth=max_group_depth,
///                         _seen=_seen)
///                 else:
///                     context = None
///
///                 if e and isinstance(e, BaseExceptionGroup):
///                     exceptions = []
///                     for exc in e.exceptions:
///                         texc = TracebackException(
///                             type(exc),
///                             exc,
///                             exc.__traceback__,
///                             limit=limit,
///                             lookup_lines=lookup_lines,
///                             capture_locals=capture_locals,
///                             max_group_width=max_group_width,
///                             max_group_depth=max_group_depth,
///                             _seen=_seen)
///                         exceptions.append(texc)
///                 else:
///                     exceptions = None
///
///                 te.__cause__ = cause
///                 te.__context__ = context
///                 te.exceptions = exceptions
///                 if cause:
///                     queue.append((te.__cause__, e.__cause__))
///                 if context:
///                     queue.append((te.__context__, e.__context__))
///                 if exceptions:
///                     queue.extend(zip(te.exceptions, e.exceptions))
///
///     @classmethod
///     def from_exception(cls, exc, *args, **kwargs):
///         """Create a TracebackException from an exception."""
///         return cls(type(exc), exc, exc.__traceback__, *args, **kwargs)
///
///     def _load_lines(self):
///         """Private API. force all lines in the stack to be loaded."""
///         for frame in self.stack:
///             frame.line
///
///     def __eq__(self, other):
///         if isinstance(other, TracebackException):
///             return self.__dict__ == other.__dict__
///         return NotImplemented
///
///     def __str__(self):
///         return self._str
///
///     def format_exception_only(self):
///         """Format the exception part of the traceback.
///
///         The return value is a generator of strings, each ending in a newline.
///
///         Normally, the generator emits a single string; however, for
///         SyntaxError exceptions, it emits several lines that (when
///         printed) display detailed information about where the syntax
///         error occurred.
///
///         The message indicating which exception occurred is always the last
///         string in the output.
///         """
///         if self.exc_type is None:
///             yield _format_final_exc_line(None, self._str)
///             return
///
///         stype = self.exc_type.__qualname__
///         smod = self.exc_type.__module__
///         if smod not in ("__main__", "builtins"):
///             if not isinstance(smod, str):
///                 smod = "<unknown>"
///             stype = smod + '.' + stype
///
///         if not issubclass(self.exc_type, SyntaxError):
///             yield _format_final_exc_line(stype, self._str)
///         else:
///             yield from self._format_syntax_error(stype)
///         if isinstance(self.__notes__, collections.abc.Sequence):
///             for note in self.__notes__:
///                 note = _safe_string(note, 'note')
///                 yield from [l + '\n' for l in note.split('\n')]
///         elif self.__notes__ is not None:
///             yield _safe_string(self.__notes__, '__notes__', func=repr)
///
///     def _format_syntax_error(self, stype):
///         """Format SyntaxError exceptions (internal helper)."""
///         # Show exactly where the problem was found.
///         filename_suffix = ''
///         if self.lineno is not None:
///             yield '  File "{}", line {}\n'.format(
///                 self.filename or "<string>", self.lineno)
///         elif self.filename is not None:
///             filename_suffix = ' ({})'.format(self.filename)
///
///         text = self.text
///         if text is not None:
///             # text  = "   foo\n"
///             # rtext = "   foo"
///             # ltext =    "foo"
///             rtext = text.rstrip('\n')
///             ltext = rtext.lstrip(' \n\f')
///             spaces = len(rtext) - len(ltext)
///             yield '    {}\n'.format(ltext)
///
///             if self.offset is not None:
///                 offset = self.offset
///                 end_offset = self.end_offset if self.end_offset not in {None, 0} else offset
///                 if offset == end_offset or end_offset == -1:
///                     end_offset = offset + 1
///
///                 # Convert 1-based column offset to 0-based index into stripped text
///                 colno = offset - 1 - spaces
///                 end_colno = end_offset - 1 - spaces
///                 if colno >= 0:
///                     # non-space whitespace (likes tabs) must be kept for alignment
///                     caretspace = ((c if c.isspace() else ' ') for c in ltext[:colno])
///                     yield '    {}{}'.format("".join(caretspace), ('^' * (end_colno - colno) + "\n"))
///         msg = self.msg or "<no detail available>"
///         yield "{}: {}{}\n".format(stype, msg, filename_suffix)
///
///     def format(self, *, chain=True, _ctx=None):
///         """Format the exception.
///
///         If chain is not *True*, *__cause__* and *__context__* will not be formatted.
///
///         The return value is a generator of strings, each ending in a newline and
///         some containing internal newlines. `print_exception` is a wrapper around
///         this method which just prints the lines to a file.
///
///         The message indicating which exception occurred is always the last
///         string in the output.
///         """
///
///         if _ctx is None:
///             _ctx = _ExceptionPrintContext()
///
///         output = []
///         exc = self
///         if chain:
///             while exc:
///                 if exc.__cause__ is not None:
///                     chained_msg = _cause_message
///                     chained_exc = exc.__cause__
///                 elif (exc.__context__  is not None and
///                       not exc.__suppress_context__):
///                     chained_msg = _context_message
///                     chained_exc = exc.__context__
///                 else:
///                     chained_msg = None
///                     chained_exc = None
///
///                 output.append((chained_msg, exc))
///                 exc = chained_exc
///         else:
///             output.append((None, exc))
///
///         for msg, exc in reversed(output):
///             if msg is not None:
///                 yield from _ctx.emit(msg)
///             if exc.exceptions is None:
///                 if exc.stack:
///                     yield from _ctx.emit('Traceback (most recent call last):\n')
///                     yield from _ctx.emit(exc.stack.format())
///                 yield from _ctx.emit(exc.format_exception_only())
///             elif _ctx.exception_group_depth > self.max_group_depth:
///                 # exception group, but depth exceeds limit
///                 yield from _ctx.emit(
///                     f"... (max_group_depth is {self.max_group_depth})\n")
///             else:
///                 # format exception group
///                 is_toplevel = (_ctx.exception_group_depth == 0)
///                 if is_toplevel:
///                     _ctx.exception_group_depth += 1
///
///                 if exc.stack:
///                     yield from _ctx.emit(
///                         'Exception Group Traceback (most recent call last):\n',
///                         margin_char = '+' if is_toplevel else None)
///                     yield from _ctx.emit(exc.stack.format())
///
///                 yield from _ctx.emit(exc.format_exception_only())
///                 num_excs = len(exc.exceptions)
///                 if num_excs <= self.max_group_width:
///                     n = num_excs
///                 else:
///                     n = self.max_group_width + 1
///                 _ctx.need_close = False
///                 for i in range(n):
///                     last_exc = (i == n-1)
///                     if last_exc:
///                         # The closing frame may be added by a recursive call
///                         _ctx.need_close = True
///
///                     if self.max_group_width is not None:
///                         truncated = (i >= self.max_group_width)
///                     else:
///                         truncated = False
///                     title = f'{i+1}' if not truncated else '...'
///                     yield (_ctx.indent() +
///                            ('+-' if i==0 else '  ') +
///                            f'+---------------- {title} ----------------\n')
///                     _ctx.exception_group_depth += 1
///                     if not truncated:
///                         yield from exc.exceptions[i].format(chain=chain, _ctx=_ctx)
///                     else:
///                         remaining = num_excs - self.max_group_width
///                         plural = 's' if remaining > 1 else ''
///                         yield from _ctx.emit(
///                             f"and {remaining} more exception{plural}\n")
///
///                     if last_exc and _ctx.need_close:
///                         yield (_ctx.indent() +
///                                "+------------------------------------\n")
///                         _ctx.need_close = False
///                     _ctx.exception_group_depth -= 1
///
///                 if is_toplevel:
///                     assert _ctx.exception_group_depth == 1
///                     _ctx.exception_group_depth = 0
///
///
///     def print(self, *, file=None, chain=True):
///         """Print the result of self.format(chain=chain) to 'file'."""
///         if file is None:
///             file = sys.stderr
///         for line in self.format(chain=chain):
///             print(line, file=file, end="")
/// ```
final class traceback extends PythonModule {
  traceback.from(super.pythonModule) : super.from();

  static traceback import() => PythonFfiDart.instance.importModule(
        "traceback",
        traceback.from,
      );

  /// ## clear_frames
  ///
  /// ### python docstring
  ///
  /// Clear all references to local variables in the frames of a traceback.
  ///
  /// ### python source
  /// ```py
  /// def clear_frames(tb):
  ///     "Clear all references to local variables in the frames of a traceback."
  ///     while tb is not None:
  ///         try:
  ///             tb.tb_frame.clear()
  ///         except RuntimeError:
  ///             # Ignore the exception raised if the frame is still executing.
  ///             pass
  ///         tb = tb.tb_next
  /// ```
  Object? clear_frames({
    required Object? tb,
  }) =>
      getFunction("clear_frames").call(
        <Object?>[
          tb,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## extract_stack
  ///
  /// ### python docstring
  ///
  /// Extract the raw traceback from the current stack frame.
  ///
  /// The return value has the same format as for extract_tb().  The
  /// optional 'f' and 'limit' arguments have the same meaning as for
  /// print_stack().  Each item in the list is a quadruple (filename,
  /// line number, function name, text), and the entries are in order
  /// from oldest to newest stack frame.
  ///
  /// ### python source
  /// ```py
  /// def extract_stack(f=None, limit=None):
  ///     """Extract the raw traceback from the current stack frame.
  ///
  ///     The return value has the same format as for extract_tb().  The
  ///     optional 'f' and 'limit' arguments have the same meaning as for
  ///     print_stack().  Each item in the list is a quadruple (filename,
  ///     line number, function name, text), and the entries are in order
  ///     from oldest to newest stack frame.
  ///     """
  ///     if f is None:
  ///         f = sys._getframe().f_back
  ///     stack = StackSummary.extract(walk_stack(f), limit=limit)
  ///     stack.reverse()
  ///     return stack
  /// ```
  Object? extract_stack({
    Object? f,
    Object? limit,
  }) =>
      getFunction("extract_stack").call(
        <Object?>[
          f,
          limit,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## extract_tb
  ///
  /// ### python docstring
  ///
  /// Return a StackSummary object representing a list of
  /// pre-processed entries from traceback.
  ///
  /// This is useful for alternate formatting of stack traces.  If
  /// 'limit' is omitted or None, all entries are extracted.  A
  /// pre-processed stack trace entry is a FrameSummary object
  /// containing attributes filename, lineno, name, and line
  /// representing the information that is usually printed for a stack
  /// trace.  The line is a string with leading and trailing
  /// whitespace stripped; if the source is not available it is None.
  ///
  /// ### python source
  /// ```py
  /// def extract_tb(tb, limit=None):
  ///     """
  ///     Return a StackSummary object representing a list of
  ///     pre-processed entries from traceback.
  ///
  ///     This is useful for alternate formatting of stack traces.  If
  ///     'limit' is omitted or None, all entries are extracted.  A
  ///     pre-processed stack trace entry is a FrameSummary object
  ///     containing attributes filename, lineno, name, and line
  ///     representing the information that is usually printed for a stack
  ///     trace.  The line is a string with leading and trailing
  ///     whitespace stripped; if the source is not available it is None.
  ///     """
  ///     return StackSummary._extract_from_extended_frame_gen(
  ///         _walk_tb_with_full_positions(tb), limit=limit)
  /// ```
  Object? extract_tb({
    required Object? tb,
    Object? limit,
  }) =>
      getFunction("extract_tb").call(
        <Object?>[
          tb,
          limit,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## format_exc
  ///
  /// ### python docstring
  ///
  /// Like print_exc() but return a string.
  ///
  /// ### python source
  /// ```py
  /// def format_exc(limit=None, chain=True):
  ///     """Like print_exc() but return a string."""
  ///     return "".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))
  /// ```
  Object? format_exc({
    Object? limit,
    Object? chain = true,
  }) =>
      getFunction("format_exc").call(
        <Object?>[
          limit,
          chain,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## format_exception
  ///
  /// ### python docstring
  ///
  /// Format a stack trace and the exception information.
  ///
  /// The arguments have the same meaning as the corresponding arguments
  /// to print_exception().  The return value is a list of strings, each
  /// ending in a newline and some containing internal newlines.  When
  /// these lines are concatenated and printed, exactly the same text is
  /// printed as does print_exception().
  ///
  /// ### python source
  /// ```py
  /// def format_exception(exc, /, value=_sentinel, tb=_sentinel, limit=None, \
  ///                      chain=True):
  ///     """Format a stack trace and the exception information.
  ///
  ///     The arguments have the same meaning as the corresponding arguments
  ///     to print_exception().  The return value is a list of strings, each
  ///     ending in a newline and some containing internal newlines.  When
  ///     these lines are concatenated and printed, exactly the same text is
  ///     printed as does print_exception().
  ///     """
  ///     value, tb = _parse_value_tb(exc, value, tb)
  ///     te = TracebackException(type(value), value, tb, limit=limit, compact=True)
  ///     return list(te.format(chain=chain))
  /// ```
  Object? format_exception(
    Object? exc, {
    Object? value,
    Object? tb,
    Object? limit,
    Object? chain = true,
  }) =>
      getFunction("format_exception").call(
        <Object?>[
          exc,
          value,
          tb,
          limit,
          chain,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## format_exception_only
  ///
  /// ### python docstring
  ///
  /// Format the exception part of a traceback.
  ///
  /// The return value is a list of strings, each ending in a newline.
  ///
  /// Normally, the list contains a single string; however, for
  /// SyntaxError exceptions, it contains several lines that (when
  /// printed) display detailed information about where the syntax
  /// error occurred.
  ///
  /// The message indicating which exception occurred is always the last
  /// string in the list.
  ///
  /// ### python source
  /// ```py
  /// def format_exception_only(exc, /, value=_sentinel):
  ///     """Format the exception part of a traceback.
  ///
  ///     The return value is a list of strings, each ending in a newline.
  ///
  ///     Normally, the list contains a single string; however, for
  ///     SyntaxError exceptions, it contains several lines that (when
  ///     printed) display detailed information about where the syntax
  ///     error occurred.
  ///
  ///     The message indicating which exception occurred is always the last
  ///     string in the list.
  ///
  ///     """
  ///     if value is _sentinel:
  ///         value = exc
  ///     te = TracebackException(type(value), value, None, compact=True)
  ///     return list(te.format_exception_only())
  /// ```
  Object? format_exception_only(
    Object? exc, {
    Object? value,
  }) =>
      getFunction("format_exception_only").call(
        <Object?>[
          exc,
          value,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## format_list
  ///
  /// ### python docstring
  ///
  /// Format a list of tuples or FrameSummary objects for printing.
  ///
  /// Given a list of tuples or FrameSummary objects as returned by
  /// extract_tb() or extract_stack(), return a list of strings ready
  /// for printing.
  ///
  /// Each string in the resulting list corresponds to the item with the
  /// same index in the argument list.  Each string ends in a newline;
  /// the strings may contain internal newlines as well, for those items
  /// whose source text line is not None.
  ///
  /// ### python source
  /// ```py
  /// def format_list(extracted_list):
  ///     """Format a list of tuples or FrameSummary objects for printing.
  ///
  ///     Given a list of tuples or FrameSummary objects as returned by
  ///     extract_tb() or extract_stack(), return a list of strings ready
  ///     for printing.
  ///
  ///     Each string in the resulting list corresponds to the item with the
  ///     same index in the argument list.  Each string ends in a newline;
  ///     the strings may contain internal newlines as well, for those items
  ///     whose source text line is not None.
  ///     """
  ///     return StackSummary.from_list(extracted_list).format()
  /// ```
  Object? format_list({
    required Object? extracted_list,
  }) =>
      getFunction("format_list").call(
        <Object?>[
          extracted_list,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## format_stack
  ///
  /// ### python docstring
  ///
  /// Shorthand for 'format_list(extract_stack(f, limit))'.
  ///
  /// ### python source
  /// ```py
  /// def format_stack(f=None, limit=None):
  ///     """Shorthand for 'format_list(extract_stack(f, limit))'."""
  ///     if f is None:
  ///         f = sys._getframe().f_back
  ///     return format_list(extract_stack(f, limit=limit))
  /// ```
  Object? format_stack({
    Object? f,
    Object? limit,
  }) =>
      getFunction("format_stack").call(
        <Object?>[
          f,
          limit,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## format_tb
  ///
  /// ### python docstring
  ///
  /// A shorthand for 'format_list(extract_tb(tb, limit))'.
  ///
  /// ### python source
  /// ```py
  /// def format_tb(tb, limit=None):
  ///     """A shorthand for 'format_list(extract_tb(tb, limit))'."""
  ///     return extract_tb(tb, limit=limit).format()
  /// ```
  Object? format_tb({
    required Object? tb,
    Object? limit,
  }) =>
      getFunction("format_tb").call(
        <Object?>[
          tb,
          limit,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## print_exc
  ///
  /// ### python docstring
  ///
  /// Shorthand for 'print_exception(*sys.exc_info(), limit, file)'.
  ///
  /// ### python source
  /// ```py
  /// def print_exc(limit=None, file=None, chain=True):
  ///     """Shorthand for 'print_exception(*sys.exc_info(), limit, file)'."""
  ///     print_exception(*sys.exc_info(), limit=limit, file=file, chain=chain)
  /// ```
  Object? print_exc({
    Object? limit,
    Object? file,
    Object? chain = true,
  }) =>
      getFunction("print_exc").call(
        <Object?>[
          limit,
          file,
          chain,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## print_exception
  ///
  /// ### python docstring
  ///
  /// Print exception up to 'limit' stack trace entries from 'tb' to 'file'.
  ///
  /// This differs from print_tb() in the following ways: (1) if
  /// traceback is not None, it prints a header "Traceback (most recent
  /// call last):"; (2) it prints the exception type and value after the
  /// stack trace; (3) if type is SyntaxError and value has the
  /// appropriate format, it prints the line where the syntax error
  /// occurred with a caret on the next line indicating the approximate
  /// position of the error.
  ///
  /// ### python source
  /// ```py
  /// def print_exception(exc, /, value=_sentinel, tb=_sentinel, limit=None, \
  ///                     file=None, chain=True):
  ///     """Print exception up to 'limit' stack trace entries from 'tb' to 'file'.
  ///
  ///     This differs from print_tb() in the following ways: (1) if
  ///     traceback is not None, it prints a header "Traceback (most recent
  ///     call last):"; (2) it prints the exception type and value after the
  ///     stack trace; (3) if type is SyntaxError and value has the
  ///     appropriate format, it prints the line where the syntax error
  ///     occurred with a caret on the next line indicating the approximate
  ///     position of the error.
  ///     """
  ///     value, tb = _parse_value_tb(exc, value, tb)
  ///     te = TracebackException(type(value), value, tb, limit=limit, compact=True)
  ///     te.print(file=file, chain=chain)
  /// ```
  Object? print_exception(
    Object? exc, {
    Object? value,
    Object? tb,
    Object? limit,
    Object? file,
    Object? chain = true,
  }) =>
      getFunction("print_exception").call(
        <Object?>[
          exc,
          value,
          tb,
          limit,
          file,
          chain,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## print_last
  ///
  /// ### python docstring
  ///
  /// This is a shorthand for 'print_exception(sys.last_type,
  /// sys.last_value, sys.last_traceback, limit, file)'.
  ///
  /// ### python source
  /// ```py
  /// def print_last(limit=None, file=None, chain=True):
  ///     """This is a shorthand for 'print_exception(sys.last_type,
  ///     sys.last_value, sys.last_traceback, limit, file)'."""
  ///     if not hasattr(sys, "last_type"):
  ///         raise ValueError("no last exception")
  ///     print_exception(sys.last_type, sys.last_value, sys.last_traceback,
  ///                     limit, file, chain)
  /// ```
  Object? print_last({
    Object? limit,
    Object? file,
    Object? chain = true,
  }) =>
      getFunction("print_last").call(
        <Object?>[
          limit,
          file,
          chain,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## print_list
  ///
  /// ### python docstring
  ///
  /// Print the list of tuples as returned by extract_tb() or
  /// extract_stack() as a formatted stack trace to the given file.
  ///
  /// ### python source
  /// ```py
  /// def print_list(extracted_list, file=None):
  ///     """Print the list of tuples as returned by extract_tb() or
  ///     extract_stack() as a formatted stack trace to the given file."""
  ///     if file is None:
  ///         file = sys.stderr
  ///     for item in StackSummary.from_list(extracted_list).format():
  ///         print(item, file=file, end="")
  /// ```
  Object? print_list({
    required Object? extracted_list,
    Object? file,
  }) =>
      getFunction("print_list").call(
        <Object?>[
          extracted_list,
          file,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## print_stack
  ///
  /// ### python docstring
  ///
  /// Print a stack trace from its invocation point.
  ///
  /// The optional 'f' argument can be used to specify an alternate
  /// stack frame at which to start. The optional 'limit' and 'file'
  /// arguments have the same meaning as for print_exception().
  ///
  /// ### python source
  /// ```py
  /// def print_stack(f=None, limit=None, file=None):
  ///     """Print a stack trace from its invocation point.
  ///
  ///     The optional 'f' argument can be used to specify an alternate
  ///     stack frame at which to start. The optional 'limit' and 'file'
  ///     arguments have the same meaning as for print_exception().
  ///     """
  ///     if f is None:
  ///         f = sys._getframe().f_back
  ///     print_list(extract_stack(f, limit=limit), file=file)
  /// ```
  Object? print_stack({
    Object? f,
    Object? limit,
    Object? file,
  }) =>
      getFunction("print_stack").call(
        <Object?>[
          f,
          limit,
          file,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## print_tb
  ///
  /// ### python docstring
  ///
  /// Print up to 'limit' stack trace entries from the traceback 'tb'.
  ///
  /// If 'limit' is omitted or None, all entries are printed.  If 'file'
  /// is omitted or None, the output goes to sys.stderr; otherwise
  /// 'file' should be an open file or file-like object with a write()
  /// method.
  ///
  /// ### python source
  /// ```py
  /// def print_tb(tb, limit=None, file=None):
  ///     """Print up to 'limit' stack trace entries from the traceback 'tb'.
  ///
  ///     If 'limit' is omitted or None, all entries are printed.  If 'file'
  ///     is omitted or None, the output goes to sys.stderr; otherwise
  ///     'file' should be an open file or file-like object with a write()
  ///     method.
  ///     """
  ///     print_list(extract_tb(tb, limit=limit), file=file)
  /// ```
  Object? print_tb({
    required Object? tb,
    Object? limit,
    Object? file,
  }) =>
      getFunction("print_tb").call(
        <Object?>[
          tb,
          limit,
          file,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## walk_stack
  ///
  /// ### python docstring
  ///
  /// Walk a stack yielding the frame and line number for each frame.
  ///
  /// This will follow f.f_back from the given frame. If no frame is given, the
  /// current stack is used. Usually used with StackSummary.extract.
  ///
  /// ### python source
  /// ```py
  /// def walk_stack(f):
  ///     """Walk a stack yielding the frame and line number for each frame.
  ///
  ///     This will follow f.f_back from the given frame. If no frame is given, the
  ///     current stack is used. Usually used with StackSummary.extract.
  ///     """
  ///     if f is None:
  ///         f = sys._getframe().f_back.f_back.f_back.f_back
  ///     while f is not None:
  ///         yield f, f.f_lineno
  ///         f = f.f_back
  /// ```
  Object? walk_stack({
    required Object? f,
  }) =>
      getFunction("walk_stack").call(
        <Object?>[
          f,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## walk_tb
  ///
  /// ### python docstring
  ///
  /// Walk a traceback yielding the frame and line number for each frame.
  ///
  /// This will follow tb.tb_next (and thus is in the opposite order to
  /// walk_stack). Usually used with StackSummary.extract.
  ///
  /// ### python source
  /// ```py
  /// def walk_tb(tb):
  ///     """Walk a traceback yielding the frame and line number for each frame.
  ///
  ///     This will follow tb.tb_next (and thus is in the opposite order to
  ///     walk_stack). Usually used with StackSummary.extract.
  ///     """
  ///     while tb is not None:
  ///         yield tb.tb_frame, tb.tb_lineno
  ///         tb = tb.tb_next
  /// ```
  Object? walk_tb({
    required Object? tb,
  }) =>
      getFunction("walk_tb").call(
        <Object?>[
          tb,
        ],
        kwargs: <String, Object?>{},
      );
}

/// ## linecache
///
/// ### python docstring
///
/// Cache lines from Python source files.
///
/// This is intended to read lines from modules imported -- hence if a filename
/// is not found, it will look down the module search path for a file by
/// that name.
///
/// ### python source
/// ```py
/// """Cache lines from Python source files.
///
/// This is intended to read lines from modules imported -- hence if a filename
/// is not found, it will look down the module search path for a file by
/// that name.
/// """
///
/// import functools
/// import sys
/// import os
/// import tokenize
///
/// __all__ = ["getline", "clearcache", "checkcache", "lazycache"]
///
///
/// # The cache. Maps filenames to either a thunk which will provide source code,
/// # or a tuple (size, mtime, lines, fullname) once loaded.
/// cache = {}
///
///
/// def clearcache():
///     """Clear the cache entirely."""
///     cache.clear()
///
///
/// def getline(filename, lineno, module_globals=None):
///     """Get a line for a Python source file from the cache.
///     Update the cache if it doesn't contain an entry for this file already."""
///
///     lines = getlines(filename, module_globals)
///     if 1 <= lineno <= len(lines):
///         return lines[lineno - 1]
///     return ''
///
///
/// def getlines(filename, module_globals=None):
///     """Get the lines for a Python source file from the cache.
///     Update the cache if it doesn't contain an entry for this file already."""
///
///     if filename in cache:
///         entry = cache[filename]
///         if len(entry) != 1:
///             return cache[filename][2]
///
///     try:
///         return updatecache(filename, module_globals)
///     except MemoryError:
///         clearcache()
///         return []
///
///
/// def checkcache(filename=None):
///     """Discard cache entries that are out of date.
///     (This is not checked upon each call!)"""
///
///     if filename is None:
///         filenames = list(cache.keys())
///     elif filename in cache:
///         filenames = [filename]
///     else:
///         return
///
///     for filename in filenames:
///         entry = cache[filename]
///         if len(entry) == 1:
///             # lazy cache entry, leave it lazy.
///             continue
///         size, mtime, lines, fullname = entry
///         if mtime is None:
///             continue   # no-op for files loaded via a __loader__
///         try:
///             stat = os.stat(fullname)
///         except OSError:
///             cache.pop(filename, None)
///             continue
///         if size != stat.st_size or mtime != stat.st_mtime:
///             cache.pop(filename, None)
///
///
/// def updatecache(filename, module_globals=None):
///     """Update a cache entry and return its list of lines.
///     If something's wrong, print a message, discard the cache entry,
///     and return an empty list."""
///
///     if filename in cache:
///         if len(cache[filename]) != 1:
///             cache.pop(filename, None)
///     if not filename or (filename.startswith('<') and filename.endswith('>')):
///         return []
///
///     fullname = filename
///     try:
///         stat = os.stat(fullname)
///     except OSError:
///         basename = filename
///
///         # Realise a lazy loader based lookup if there is one
///         # otherwise try to lookup right now.
///         if lazycache(filename, module_globals):
///             try:
///                 data = cache[filename][0]()
///             except (ImportError, OSError):
///                 pass
///             else:
///                 if data is None:
///                     # No luck, the PEP302 loader cannot find the source
///                     # for this module.
///                     return []
///                 cache[filename] = (
///                     len(data),
///                     None,
///                     [line + '\n' for line in data.splitlines()],
///                     fullname
///                 )
///                 return cache[filename][2]
///
///         # Try looking through the module search path, which is only useful
///         # when handling a relative filename.
///         if os.path.isabs(filename):
///             return []
///
///         for dirname in sys.path:
///             try:
///                 fullname = os.path.join(dirname, basename)
///             except (TypeError, AttributeError):
///                 # Not sufficiently string-like to do anything useful with.
///                 continue
///             try:
///                 stat = os.stat(fullname)
///                 break
///             except OSError:
///                 pass
///         else:
///             return []
///     try:
///         with tokenize.open(fullname) as fp:
///             lines = fp.readlines()
///     except (OSError, UnicodeDecodeError, SyntaxError):
///         return []
///     if lines and not lines[-1].endswith('\n'):
///         lines[-1] += '\n'
///     size, mtime = stat.st_size, stat.st_mtime
///     cache[filename] = size, mtime, lines, fullname
///     return lines
///
///
/// def lazycache(filename, module_globals):
///     """Seed the cache for filename with module_globals.
///
///     The module loader will be asked for the source only when getlines is
///     called, not immediately.
///
///     If there is an entry in the cache already, it is not altered.
///
///     :return: True if a lazy load is registered in the cache,
///         otherwise False. To register such a load a module loader with a
///         get_source method must be found, the filename must be a cacheable
///         filename, and the filename must not be already cached.
///     """
///     if filename in cache:
///         if len(cache[filename]) == 1:
///             return True
///         else:
///             return False
///     if not filename or (filename.startswith('<') and filename.endswith('>')):
///         return False
///     # Try for a __loader__, if available
///     if module_globals and '__name__' in module_globals:
///         name = module_globals['__name__']
///         if (loader := module_globals.get('__loader__')) is None:
///             if spec := module_globals.get('__spec__'):
///                 try:
///                     loader = spec.loader
///                 except AttributeError:
///                     pass
///         get_source = getattr(loader, 'get_source', None)
///
///         if name and get_source:
///             get_lines = functools.partial(get_source, name)
///             cache[filename] = (get_lines,)
///             return True
///     return False
/// ```
final class linecache extends PythonModule {
  linecache.from(super.pythonModule) : super.from();

  static linecache import() => PythonFfiDart.instance.importModule(
        "linecache",
        linecache.from,
      );

  /// ## checkcache
  ///
  /// ### python docstring
  ///
  /// Discard cache entries that are out of date.
  /// (This is not checked upon each call!)
  ///
  /// ### python source
  /// ```py
  /// def checkcache(filename=None):
  ///     """Discard cache entries that are out of date.
  ///     (This is not checked upon each call!)"""
  ///
  ///     if filename is None:
  ///         filenames = list(cache.keys())
  ///     elif filename in cache:
  ///         filenames = [filename]
  ///     else:
  ///         return
  ///
  ///     for filename in filenames:
  ///         entry = cache[filename]
  ///         if len(entry) == 1:
  ///             # lazy cache entry, leave it lazy.
  ///             continue
  ///         size, mtime, lines, fullname = entry
  ///         if mtime is None:
  ///             continue   # no-op for files loaded via a __loader__
  ///         try:
  ///             stat = os.stat(fullname)
  ///         except OSError:
  ///             cache.pop(filename, None)
  ///             continue
  ///         if size != stat.st_size or mtime != stat.st_mtime:
  ///             cache.pop(filename, None)
  /// ```
  Object? checkcache({
    Object? filename,
  }) =>
      getFunction("checkcache").call(
        <Object?>[
          filename,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## clearcache
  ///
  /// ### python docstring
  ///
  /// Clear the cache entirely.
  ///
  /// ### python source
  /// ```py
  /// def clearcache():
  ///     """Clear the cache entirely."""
  ///     cache.clear()
  /// ```
  Object? clearcache() => getFunction("clearcache").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## getline
  ///
  /// ### python docstring
  ///
  /// Get a line for a Python source file from the cache.
  /// Update the cache if it doesn't contain an entry for this file already.
  ///
  /// ### python source
  /// ```py
  /// def getline(filename, lineno, module_globals=None):
  ///     """Get a line for a Python source file from the cache.
  ///     Update the cache if it doesn't contain an entry for this file already."""
  ///
  ///     lines = getlines(filename, module_globals)
  ///     if 1 <= lineno <= len(lines):
  ///         return lines[lineno - 1]
  ///     return ''
  /// ```
  Object? getline({
    required Object? filename,
    required Object? lineno,
    Object? module_globals,
  }) =>
      getFunction("getline").call(
        <Object?>[
          filename,
          lineno,
          module_globals,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## getlines
  ///
  /// ### python docstring
  ///
  /// Get the lines for a Python source file from the cache.
  /// Update the cache if it doesn't contain an entry for this file already.
  ///
  /// ### python source
  /// ```py
  /// def getlines(filename, module_globals=None):
  ///     """Get the lines for a Python source file from the cache.
  ///     Update the cache if it doesn't contain an entry for this file already."""
  ///
  ///     if filename in cache:
  ///         entry = cache[filename]
  ///         if len(entry) != 1:
  ///             return cache[filename][2]
  ///
  ///     try:
  ///         return updatecache(filename, module_globals)
  ///     except MemoryError:
  ///         clearcache()
  ///         return []
  /// ```
  Object? getlines({
    required Object? filename,
    Object? module_globals,
  }) =>
      getFunction("getlines").call(
        <Object?>[
          filename,
          module_globals,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## lazycache
  ///
  /// ### python docstring
  ///
  /// Seed the cache for filename with module_globals.
  ///
  /// The module loader will be asked for the source only when getlines is
  /// called, not immediately.
  ///
  /// If there is an entry in the cache already, it is not altered.
  ///
  /// :return: True if a lazy load is registered in the cache,
  ///     otherwise False. To register such a load a module loader with a
  ///     get_source method must be found, the filename must be a cacheable
  ///     filename, and the filename must not be already cached.
  ///
  /// ### python source
  /// ```py
  /// def lazycache(filename, module_globals):
  ///     """Seed the cache for filename with module_globals.
  ///
  ///     The module loader will be asked for the source only when getlines is
  ///     called, not immediately.
  ///
  ///     If there is an entry in the cache already, it is not altered.
  ///
  ///     :return: True if a lazy load is registered in the cache,
  ///         otherwise False. To register such a load a module loader with a
  ///         get_source method must be found, the filename must be a cacheable
  ///         filename, and the filename must not be already cached.
  ///     """
  ///     if filename in cache:
  ///         if len(cache[filename]) == 1:
  ///             return True
  ///         else:
  ///             return False
  ///     if not filename or (filename.startswith('<') and filename.endswith('>')):
  ///         return False
  ///     # Try for a __loader__, if available
  ///     if module_globals and '__name__' in module_globals:
  ///         name = module_globals['__name__']
  ///         if (loader := module_globals.get('__loader__')) is None:
  ///             if spec := module_globals.get('__spec__'):
  ///                 try:
  ///                     loader = spec.loader
  ///                 except AttributeError:
  ///                     pass
  ///         get_source = getattr(loader, 'get_source', None)
  ///
  ///         if name and get_source:
  ///             get_lines = functools.partial(get_source, name)
  ///             cache[filename] = (get_lines,)
  ///             return True
  ///     return False
  /// ```
  Object? lazycache({
    required Object? filename,
    required Object? module_globals,
  }) =>
      getFunction("lazycache").call(
        <Object?>[
          filename,
          module_globals,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## updatecache
  ///
  /// ### python docstring
  ///
  /// Update a cache entry and return its list of lines.
  /// If something's wrong, print a message, discard the cache entry,
  /// and return an empty list.
  ///
  /// ### python source
  /// ```py
  /// def updatecache(filename, module_globals=None):
  ///     """Update a cache entry and return its list of lines.
  ///     If something's wrong, print a message, discard the cache entry,
  ///     and return an empty list."""
  ///
  ///     if filename in cache:
  ///         if len(cache[filename]) != 1:
  ///             cache.pop(filename, None)
  ///     if not filename or (filename.startswith('<') and filename.endswith('>')):
  ///         return []
  ///
  ///     fullname = filename
  ///     try:
  ///         stat = os.stat(fullname)
  ///     except OSError:
  ///         basename = filename
  ///
  ///         # Realise a lazy loader based lookup if there is one
  ///         # otherwise try to lookup right now.
  ///         if lazycache(filename, module_globals):
  ///             try:
  ///                 data = cache[filename][0]()
  ///             except (ImportError, OSError):
  ///                 pass
  ///             else:
  ///                 if data is None:
  ///                     # No luck, the PEP302 loader cannot find the source
  ///                     # for this module.
  ///                     return []
  ///                 cache[filename] = (
  ///                     len(data),
  ///                     None,
  ///                     [line + '\n' for line in data.splitlines()],
  ///                     fullname
  ///                 )
  ///                 return cache[filename][2]
  ///
  ///         # Try looking through the module search path, which is only useful
  ///         # when handling a relative filename.
  ///         if os.path.isabs(filename):
  ///             return []
  ///
  ///         for dirname in sys.path:
  ///             try:
  ///                 fullname = os.path.join(dirname, basename)
  ///             except (TypeError, AttributeError):
  ///                 # Not sufficiently string-like to do anything useful with.
  ///                 continue
  ///             try:
  ///                 stat = os.stat(fullname)
  ///                 break
  ///             except OSError:
  ///                 pass
  ///         else:
  ///             return []
  ///     try:
  ///         with tokenize.open(fullname) as fp:
  ///             lines = fp.readlines()
  ///     except (OSError, UnicodeDecodeError, SyntaxError):
  ///         return []
  ///     if lines and not lines[-1].endswith('\n'):
  ///         lines[-1] += '\n'
  ///     size, mtime = stat.st_size, stat.st_mtime
  ///     cache[filename] = size, mtime, lines, fullname
  ///     return lines
  /// ```
  Object? updatecache({
    required Object? filename,
    Object? module_globals,
  }) =>
      getFunction("updatecache").call(
        <Object?>[
          filename,
          module_globals,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## cache (getter)
  Object? get cache => getAttribute("cache");

  /// ## cache (setter)
  set cache(Object? cache) => setAttribute("cache", cache);
}

/// ## tokenize
///
/// ### python docstring
///
/// Tokenization help for Python programs.
///
/// tokenize(readline) is a generator that breaks a stream of bytes into
/// Python tokens.  It decodes the bytes according to PEP-0263 for
/// determining source file encoding.
///
/// It accepts a readline-like method which is called repeatedly to get the
/// next line of input (or b"" for EOF).  It generates 5-tuples with these
/// members:
///
///     the token type (see token.py)
///     the token (a string)
///     the starting (row, column) indices of the token (a 2-tuple of ints)
///     the ending (row, column) indices of the token (a 2-tuple of ints)
///     the original line (string)
///
/// It is designed to match the working of the Python tokenizer exactly, except
/// that it produces COMMENT tokens for comments and gives type OP for all
/// operators.  Additionally, all token lists start with an ENCODING token
/// which tells you which encoding was used to decode the bytes stream.
///
/// ### python source
/// ```py
/// """Tokenization help for Python programs.
///
/// tokenize(readline) is a generator that breaks a stream of bytes into
/// Python tokens.  It decodes the bytes according to PEP-0263 for
/// determining source file encoding.
///
/// It accepts a readline-like method which is called repeatedly to get the
/// next line of input (or b"" for EOF).  It generates 5-tuples with these
/// members:
///
///     the token type (see token.py)
///     the token (a string)
///     the starting (row, column) indices of the token (a 2-tuple of ints)
///     the ending (row, column) indices of the token (a 2-tuple of ints)
///     the original line (string)
///
/// It is designed to match the working of the Python tokenizer exactly, except
/// that it produces COMMENT tokens for comments and gives type OP for all
/// operators.  Additionally, all token lists start with an ENCODING token
/// which tells you which encoding was used to decode the bytes stream.
/// """
///
/// __author__ = 'Ka-Ping Yee <ping@lfw.org>'
/// __credits__ = ('GvR, ESR, Tim Peters, Thomas Wouters, Fred Drake, '
///                'Skip Montanaro, Raymond Hettinger, Trent Nelson, '
///                'Michael Foord')
/// from builtins import open as _builtin_open
/// from codecs import lookup, BOM_UTF8
/// import collections
/// import functools
/// from io import TextIOWrapper
/// import itertools as _itertools
/// import re
/// import sys
/// from token import *
/// from token import EXACT_TOKEN_TYPES
///
/// cookie_re = re.compile(r'^[ \t\f]*#.*?coding[:=][ \t]*([-\w.]+)', re.ASCII)
/// blank_re = re.compile(br'^[ \t\f]*(?:[#\r\n]|$)', re.ASCII)
///
/// import token
/// __all__ = token.__all__ + ["tokenize", "generate_tokens", "detect_encoding",
///                            "untokenize", "TokenInfo"]
/// del token
///
/// class TokenInfo(collections.namedtuple('TokenInfo', 'type string start end line')):
///     def __repr__(self):
///         annotated_type = '%d (%s)' % (self.type, tok_name[self.type])
///         return ('TokenInfo(type=%s, string=%r, start=%r, end=%r, line=%r)' %
///                 self._replace(type=annotated_type))
///
///     @property
///     def exact_type(self):
///         if self.type == OP and self.string in EXACT_TOKEN_TYPES:
///             return EXACT_TOKEN_TYPES[self.string]
///         else:
///             return self.type
///
/// def group(*choices): return '(' + '|'.join(choices) + ')'
/// def any(*choices): return group(*choices) + '*'
/// def maybe(*choices): return group(*choices) + '?'
///
/// # Note: we use unicode matching for names ("\w") but ascii matching for
/// # number literals.
/// Whitespace = r'[ \f\t]*'
/// Comment = r'#[^\r\n]*'
/// Ignore = Whitespace + any(r'\\\r?\n' + Whitespace) + maybe(Comment)
/// Name = r'\w+'
///
/// Hexnumber = r'0[xX](?:_?[0-9a-fA-F])+'
/// Binnumber = r'0[bB](?:_?[01])+'
/// Octnumber = r'0[oO](?:_?[0-7])+'
/// Decnumber = r'(?:0(?:_?0)*|[1-9](?:_?[0-9])*)'
/// Intnumber = group(Hexnumber, Binnumber, Octnumber, Decnumber)
/// Exponent = r'[eE][-+]?[0-9](?:_?[0-9])*'
/// Pointfloat = group(r'[0-9](?:_?[0-9])*\.(?:[0-9](?:_?[0-9])*)?',
///                    r'\.[0-9](?:_?[0-9])*') + maybe(Exponent)
/// Expfloat = r'[0-9](?:_?[0-9])*' + Exponent
/// Floatnumber = group(Pointfloat, Expfloat)
/// Imagnumber = group(r'[0-9](?:_?[0-9])*[jJ]', Floatnumber + r'[jJ]')
/// Number = group(Imagnumber, Floatnumber, Intnumber)
///
/// # Return the empty string, plus all of the valid string prefixes.
/// def _all_string_prefixes():
///     # The valid string prefixes. Only contain the lower case versions,
///     #  and don't contain any permutations (include 'fr', but not
///     #  'rf'). The various permutations will be generated.
///     _valid_string_prefixes = ['b', 'r', 'u', 'f', 'br', 'fr']
///     # if we add binary f-strings, add: ['fb', 'fbr']
///     result = {''}
///     for prefix in _valid_string_prefixes:
///         for t in _itertools.permutations(prefix):
///             # create a list with upper and lower versions of each
///             #  character
///             for u in _itertools.product(*[(c, c.upper()) for c in t]):
///                 result.add(''.join(u))
///     return result
///
/// @functools.lru_cache
/// def _compile(expr):
///     return re.compile(expr, re.UNICODE)
///
/// # Note that since _all_string_prefixes includes the empty string,
/// #  StringPrefix can be the empty string (making it optional).
/// StringPrefix = group(*_all_string_prefixes())
///
/// # Tail end of ' string.
/// Single = r"[^'\\]*(?:\\.[^'\\]*)*'"
/// # Tail end of " string.
/// Double = r'[^"\\]*(?:\\.[^"\\]*)*"'
/// # Tail end of ''' string.
/// Single3 = r"[^'\\]*(?:(?:\\.|'(?!''))[^'\\]*)*'''"
/// # Tail end of """ string.
/// Double3 = r'[^"\\]*(?:(?:\\.|"(?!""))[^"\\]*)*"""'
/// Triple = group(StringPrefix + "'''", StringPrefix + '"""')
/// # Single-line ' or " string.
/// String = group(StringPrefix + r"'[^\n'\\]*(?:\\.[^\n'\\]*)*'",
///                StringPrefix + r'"[^\n"\\]*(?:\\.[^\n"\\]*)*"')
///
/// # Sorting in reverse order puts the long operators before their prefixes.
/// # Otherwise if = came before ==, == would get recognized as two instances
/// # of =.
/// Special = group(*map(re.escape, sorted(EXACT_TOKEN_TYPES, reverse=True)))
/// Funny = group(r'\r?\n', Special)
///
/// PlainToken = group(Number, Funny, String, Name)
/// Token = Ignore + PlainToken
///
/// # First (or only) line of ' or " string.
/// ContStr = group(StringPrefix + r"'[^\n'\\]*(?:\\.[^\n'\\]*)*" +
///                 group("'", r'\\\r?\n'),
///                 StringPrefix + r'"[^\n"\\]*(?:\\.[^\n"\\]*)*' +
///                 group('"', r'\\\r?\n'))
/// PseudoExtras = group(r'\\\r?\n|\Z', Comment, Triple)
/// PseudoToken = Whitespace + group(PseudoExtras, Number, Funny, ContStr, Name)
///
/// # For a given string prefix plus quotes, endpats maps it to a regex
/// #  to match the remainder of that string. _prefix can be empty, for
/// #  a normal single or triple quoted string (with no prefix).
/// endpats = {}
/// for _prefix in _all_string_prefixes():
///     endpats[_prefix + "'"] = Single
///     endpats[_prefix + '"'] = Double
///     endpats[_prefix + "'''"] = Single3
///     endpats[_prefix + '"""'] = Double3
/// del _prefix
///
/// # A set of all of the single and triple quoted string prefixes,
/// #  including the opening quotes.
/// single_quoted = set()
/// triple_quoted = set()
/// for t in _all_string_prefixes():
///     for u in (t + '"', t + "'"):
///         single_quoted.add(u)
///     for u in (t + '"""', t + "'''"):
///         triple_quoted.add(u)
/// del t, u
///
/// tabsize = 8
///
/// class TokenError(Exception): pass
///
/// class StopTokenizing(Exception): pass
///
///
/// class Untokenizer:
///
///     def __init__(self):
///         self.tokens = []
///         self.prev_row = 1
///         self.prev_col = 0
///         self.encoding = None
///
///     def add_whitespace(self, start):
///         row, col = start
///         if row < self.prev_row or row == self.prev_row and col < self.prev_col:
///             raise ValueError("start ({},{}) precedes previous end ({},{})"
///                              .format(row, col, self.prev_row, self.prev_col))
///         row_offset = row - self.prev_row
///         if row_offset:
///             self.tokens.append("\\\n" * row_offset)
///             self.prev_col = 0
///         col_offset = col - self.prev_col
///         if col_offset:
///             self.tokens.append(" " * col_offset)
///
///     def untokenize(self, iterable):
///         it = iter(iterable)
///         indents = []
///         startline = False
///         for t in it:
///             if len(t) == 2:
///                 self.compat(t, it)
///                 break
///             tok_type, token, start, end, line = t
///             if tok_type == ENCODING:
///                 self.encoding = token
///                 continue
///             if tok_type == ENDMARKER:
///                 break
///             if tok_type == INDENT:
///                 indents.append(token)
///                 continue
///             elif tok_type == DEDENT:
///                 indents.pop()
///                 self.prev_row, self.prev_col = end
///                 continue
///             elif tok_type in (NEWLINE, NL):
///                 startline = True
///             elif startline and indents:
///                 indent = indents[-1]
///                 if start[1] >= len(indent):
///                     self.tokens.append(indent)
///                     self.prev_col = len(indent)
///                 startline = False
///             self.add_whitespace(start)
///             self.tokens.append(token)
///             self.prev_row, self.prev_col = end
///             if tok_type in (NEWLINE, NL):
///                 self.prev_row += 1
///                 self.prev_col = 0
///         return "".join(self.tokens)
///
///     def compat(self, token, iterable):
///         indents = []
///         toks_append = self.tokens.append
///         startline = token[0] in (NEWLINE, NL)
///         prevstring = False
///
///         for tok in _itertools.chain([token], iterable):
///             toknum, tokval = tok[:2]
///             if toknum == ENCODING:
///                 self.encoding = tokval
///                 continue
///
///             if toknum in (NAME, NUMBER):
///                 tokval += ' '
///
///             # Insert a space between two consecutive strings
///             if toknum == STRING:
///                 if prevstring:
///                     tokval = ' ' + tokval
///                 prevstring = True
///             else:
///                 prevstring = False
///
///             if toknum == INDENT:
///                 indents.append(tokval)
///                 continue
///             elif toknum == DEDENT:
///                 indents.pop()
///                 continue
///             elif toknum in (NEWLINE, NL):
///                 startline = True
///             elif startline and indents:
///                 toks_append(indents[-1])
///                 startline = False
///             toks_append(tokval)
///
///
/// def untokenize(iterable):
///     """Transform tokens back into Python source code.
///     It returns a bytes object, encoded using the ENCODING
///     token, which is the first token sequence output by tokenize.
///
///     Each element returned by the iterable must be a token sequence
///     with at least two elements, a token number and token value.  If
///     only two tokens are passed, the resulting output is poor.
///
///     Round-trip invariant for full input:
///         Untokenized source will match input source exactly
///
///     Round-trip invariant for limited input:
///         # Output bytes will tokenize back to the input
///         t1 = [tok[:2] for tok in tokenize(f.readline)]
///         newcode = untokenize(t1)
///         readline = BytesIO(newcode).readline
///         t2 = [tok[:2] for tok in tokenize(readline)]
///         assert t1 == t2
///     """
///     ut = Untokenizer()
///     out = ut.untokenize(iterable)
///     if ut.encoding is not None:
///         out = out.encode(ut.encoding)
///     return out
///
///
/// def _get_normal_name(orig_enc):
///     """Imitates get_normal_name in tokenizer.c."""
///     # Only care about the first 12 characters.
///     enc = orig_enc[:12].lower().replace("_", "-")
///     if enc == "utf-8" or enc.startswith("utf-8-"):
///         return "utf-8"
///     if enc in ("latin-1", "iso-8859-1", "iso-latin-1") or \
///        enc.startswith(("latin-1-", "iso-8859-1-", "iso-latin-1-")):
///         return "iso-8859-1"
///     return orig_enc
///
/// def detect_encoding(readline):
///     """
///     The detect_encoding() function is used to detect the encoding that should
///     be used to decode a Python source file.  It requires one argument, readline,
///     in the same way as the tokenize() generator.
///
///     It will call readline a maximum of twice, and return the encoding used
///     (as a string) and a list of any lines (left as bytes) it has read in.
///
///     It detects the encoding from the presence of a utf-8 bom or an encoding
///     cookie as specified in pep-0263.  If both a bom and a cookie are present,
///     but disagree, a SyntaxError will be raised.  If the encoding cookie is an
///     invalid charset, raise a SyntaxError.  Note that if a utf-8 bom is found,
///     'utf-8-sig' is returned.
///
///     If no encoding is specified, then the default of 'utf-8' will be returned.
///     """
///     try:
///         filename = readline.__self__.name
///     except AttributeError:
///         filename = None
///     bom_found = False
///     encoding = None
///     default = 'utf-8'
///     def read_or_stop():
///         try:
///             return readline()
///         except StopIteration:
///             return b''
///
///     def find_cookie(line):
///         try:
///             # Decode as UTF-8. Either the line is an encoding declaration,
///             # in which case it should be pure ASCII, or it must be UTF-8
///             # per default encoding.
///             line_string = line.decode('utf-8')
///         except UnicodeDecodeError:
///             msg = "invalid or missing encoding declaration"
///             if filename is not None:
///                 msg = '{} for {!r}'.format(msg, filename)
///             raise SyntaxError(msg)
///
///         match = cookie_re.match(line_string)
///         if not match:
///             return None
///         encoding = _get_normal_name(match.group(1))
///         try:
///             codec = lookup(encoding)
///         except LookupError:
///             # This behaviour mimics the Python interpreter
///             if filename is None:
///                 msg = "unknown encoding: " + encoding
///             else:
///                 msg = "unknown encoding for {!r}: {}".format(filename,
///                         encoding)
///             raise SyntaxError(msg)
///
///         if bom_found:
///             if encoding != 'utf-8':
///                 # This behaviour mimics the Python interpreter
///                 if filename is None:
///                     msg = 'encoding problem: utf-8'
///                 else:
///                     msg = 'encoding problem for {!r}: utf-8'.format(filename)
///                 raise SyntaxError(msg)
///             encoding += '-sig'
///         return encoding
///
///     first = read_or_stop()
///     if first.startswith(BOM_UTF8):
///         bom_found = True
///         first = first[3:]
///         default = 'utf-8-sig'
///     if not first:
///         return default, []
///
///     encoding = find_cookie(first)
///     if encoding:
///         return encoding, [first]
///     if not blank_re.match(first):
///         return default, [first]
///
///     second = read_or_stop()
///     if not second:
///         return default, [first]
///
///     encoding = find_cookie(second)
///     if encoding:
///         return encoding, [first, second]
///
///     return default, [first, second]
///
///
/// def open(filename):
///     """Open a file in read only mode using the encoding detected by
///     detect_encoding().
///     """
///     buffer = _builtin_open(filename, 'rb')
///     try:
///         encoding, lines = detect_encoding(buffer.readline)
///         buffer.seek(0)
///         text = TextIOWrapper(buffer, encoding, line_buffering=True)
///         text.mode = 'r'
///         return text
///     except:
///         buffer.close()
///         raise
///
///
/// def tokenize(readline):
///     """
///     The tokenize() generator requires one argument, readline, which
///     must be a callable object which provides the same interface as the
///     readline() method of built-in file objects.  Each call to the function
///     should return one line of input as bytes.  Alternatively, readline
///     can be a callable function terminating with StopIteration:
///         readline = open(myfile, 'rb').__next__  # Example of alternate readline
///
///     The generator produces 5-tuples with these members: the token type; the
///     token string; a 2-tuple (srow, scol) of ints specifying the row and
///     column where the token begins in the source; a 2-tuple (erow, ecol) of
///     ints specifying the row and column where the token ends in the source;
///     and the line on which the token was found.  The line passed is the
///     physical line.
///
///     The first token sequence will always be an ENCODING token
///     which tells you which encoding was used to decode the bytes stream.
///     """
///     encoding, consumed = detect_encoding(readline)
///     empty = _itertools.repeat(b"")
///     rl_gen = _itertools.chain(consumed, iter(readline, b""), empty)
///     return _tokenize(rl_gen.__next__, encoding)
///
///
/// def _tokenize(readline, encoding):
///     lnum = parenlev = continued = 0
///     numchars = '0123456789'
///     contstr, needcont = '', 0
///     contline = None
///     indents = [0]
///
///     if encoding is not None:
///         if encoding == "utf-8-sig":
///             # BOM will already have been stripped.
///             encoding = "utf-8"
///         yield TokenInfo(ENCODING, encoding, (0, 0), (0, 0), '')
///     last_line = b''
///     line = b''
///     while True:                                # loop over lines in stream
///         try:
///             # We capture the value of the line variable here because
///             # readline uses the empty string '' to signal end of input,
///             # hence `line` itself will always be overwritten at the end
///             # of this loop.
///             last_line = line
///             line = readline()
///         except StopIteration:
///             line = b''
///
///         if encoding is not None:
///             line = line.decode(encoding)
///         lnum += 1
///         pos, max = 0, len(line)
///
///         if contstr:                            # continued string
///             if not line:
///                 raise TokenError("EOF in multi-line string", strstart)
///             endmatch = endprog.match(line)
///             if endmatch:
///                 pos = end = endmatch.end(0)
///                 yield TokenInfo(STRING, contstr + line[:end],
///                        strstart, (lnum, end), contline + line)
///                 contstr, needcont = '', 0
///                 contline = None
///             elif needcont and line[-2:] != '\\\n' and line[-3:] != '\\\r\n':
///                 yield TokenInfo(ERRORTOKEN, contstr + line,
///                            strstart, (lnum, len(line)), contline)
///                 contstr = ''
///                 contline = None
///                 continue
///             else:
///                 contstr = contstr + line
///                 contline = contline + line
///                 continue
///
///         elif parenlev == 0 and not continued:  # new statement
///             if not line: break
///             column = 0
///             while pos < max:                   # measure leading whitespace
///                 if line[pos] == ' ':
///                     column += 1
///                 elif line[pos] == '\t':
///                     column = (column//tabsize + 1)*tabsize
///                 elif line[pos] == '\f':
///                     column = 0
///                 else:
///                     break
///                 pos += 1
///             if pos == max:
///                 break
///
///             if line[pos] in '#\r\n':           # skip comments or blank lines
///                 if line[pos] == '#':
///                     comment_token = line[pos:].rstrip('\r\n')
///                     yield TokenInfo(COMMENT, comment_token,
///                            (lnum, pos), (lnum, pos + len(comment_token)), line)
///                     pos += len(comment_token)
///
///                 yield TokenInfo(NL, line[pos:],
///                            (lnum, pos), (lnum, len(line)), line)
///                 continue
///
///             if column > indents[-1]:           # count indents or dedents
///                 indents.append(column)
///                 yield TokenInfo(INDENT, line[:pos], (lnum, 0), (lnum, pos), line)
///             while column < indents[-1]:
///                 if column not in indents:
///                     raise IndentationError(
///                         "unindent does not match any outer indentation level",
///                         ("<tokenize>", lnum, pos, line))
///                 indents = indents[:-1]
///
///                 yield TokenInfo(DEDENT, '', (lnum, pos), (lnum, pos), line)
///
///         else:                                  # continued statement
///             if not line:
///                 raise TokenError("EOF in multi-line statement", (lnum, 0))
///             continued = 0
///
///         while pos < max:
///             pseudomatch = _compile(PseudoToken).match(line, pos)
///             if pseudomatch:                                # scan for tokens
///                 start, end = pseudomatch.span(1)
///                 spos, epos, pos = (lnum, start), (lnum, end), end
///                 if start == end:
///                     continue
///                 token, initial = line[start:end], line[start]
///
///                 if (initial in numchars or                 # ordinary number
///                     (initial == '.' and token != '.' and token != '...')):
///                     yield TokenInfo(NUMBER, token, spos, epos, line)
///                 elif initial in '\r\n':
///                     if parenlev > 0:
///                         yield TokenInfo(NL, token, spos, epos, line)
///                     else:
///                         yield TokenInfo(NEWLINE, token, spos, epos, line)
///
///                 elif initial == '#':
///                     assert not token.endswith("\n")
///                     yield TokenInfo(COMMENT, token, spos, epos, line)
///
///                 elif token in triple_quoted:
///                     endprog = _compile(endpats[token])
///                     endmatch = endprog.match(line, pos)
///                     if endmatch:                           # all on one line
///                         pos = endmatch.end(0)
///                         token = line[start:pos]
///                         yield TokenInfo(STRING, token, spos, (lnum, pos), line)
///                     else:
///                         strstart = (lnum, start)           # multiple lines
///                         contstr = line[start:]
///                         contline = line
///                         break
///
///                 # Check up to the first 3 chars of the token to see if
///                 #  they're in the single_quoted set. If so, they start
///                 #  a string.
///                 # We're using the first 3, because we're looking for
///                 #  "rb'" (for example) at the start of the token. If
///                 #  we switch to longer prefixes, this needs to be
///                 #  adjusted.
///                 # Note that initial == token[:1].
///                 # Also note that single quote checking must come after
///                 #  triple quote checking (above).
///                 elif (initial in single_quoted or
///                       token[:2] in single_quoted or
///                       token[:3] in single_quoted):
///                     if token[-1] == '\n':                  # continued string
///                         strstart = (lnum, start)
///                         # Again, using the first 3 chars of the
///                         #  token. This is looking for the matching end
///                         #  regex for the correct type of quote
///                         #  character. So it's really looking for
///                         #  endpats["'"] or endpats['"'], by trying to
///                         #  skip string prefix characters, if any.
///                         endprog = _compile(endpats.get(initial) or
///                                            endpats.get(token[1]) or
///                                            endpats.get(token[2]))
///                         contstr, needcont = line[start:], 1
///                         contline = line
///                         break
///                     else:                                  # ordinary string
///                         yield TokenInfo(STRING, token, spos, epos, line)
///
///                 elif initial.isidentifier():               # ordinary name
///                     yield TokenInfo(NAME, token, spos, epos, line)
///                 elif initial == '\\':                      # continued stmt
///                     continued = 1
///                 else:
///                     if initial in '([{':
///                         parenlev += 1
///                     elif initial in ')]}':
///                         parenlev -= 1
///                     yield TokenInfo(OP, token, spos, epos, line)
///             else:
///                 yield TokenInfo(ERRORTOKEN, line[pos],
///                            (lnum, pos), (lnum, pos+1), line)
///                 pos += 1
///
///     # Add an implicit NEWLINE if the input doesn't end in one
///     if last_line and last_line[-1] not in '\r\n' and not last_line.strip().startswith("#"):
///         yield TokenInfo(NEWLINE, '', (lnum - 1, len(last_line)), (lnum - 1, len(last_line) + 1), '')
///     for indent in indents[1:]:                 # pop remaining indent levels
///         yield TokenInfo(DEDENT, '', (lnum, 0), (lnum, 0), '')
///     yield TokenInfo(ENDMARKER, '', (lnum, 0), (lnum, 0), '')
///
///
/// def generate_tokens(readline):
///     """Tokenize a source reading Python code as unicode strings.
///
///     This has the same API as tokenize(), except that it expects the *readline*
///     callable to return str objects instead of bytes.
///     """
///     return _tokenize(readline, None)
///
/// def main():
///     import argparse
///
///     # Helper error handling routines
///     def perror(message):
///         sys.stderr.write(message)
///         sys.stderr.write('\n')
///
///     def error(message, filename=None, location=None):
///         if location:
///             args = (filename,) + location + (message,)
///             perror("%s:%d:%d: error: %s" % args)
///         elif filename:
///             perror("%s: error: %s" % (filename, message))
///         else:
///             perror("error: %s" % message)
///         sys.exit(1)
///
///     # Parse the arguments and options
///     parser = argparse.ArgumentParser(prog='python -m tokenize')
///     parser.add_argument(dest='filename', nargs='?',
///                         metavar='filename.py',
///                         help='the file to tokenize; defaults to stdin')
///     parser.add_argument('-e', '--exact', dest='exact', action='store_true',
///                         help='display token names using the exact type')
///     args = parser.parse_args()
///
///     try:
///         # Tokenize the input
///         if args.filename:
///             filename = args.filename
///             with _builtin_open(filename, 'rb') as f:
///                 tokens = list(tokenize(f.readline))
///         else:
///             filename = "<stdin>"
///             tokens = _tokenize(sys.stdin.readline, None)
///
///         # Output the tokenization
///         for token in tokens:
///             token_type = token.type
///             if args.exact:
///                 token_type = token.exact_type
///             token_range = "%d,%d-%d,%d:" % (token.start + token.end)
///             print("%-20s%-15s%-15r" %
///                   (token_range, tok_name[token_type], token.string))
///     except IndentationError as err:
///         line, column = err.args[1][1:3]
///         error(err.args[0], filename, (line, column))
///     except TokenError as err:
///         line, column = err.args[1]
///         error(err.args[0], filename, (line, column))
///     except SyntaxError as err:
///         error(err, filename)
///     except OSError as err:
///         error(err)
///     except KeyboardInterrupt:
///         print("interrupted\n")
///     except Exception as err:
///         perror("unexpected error: %s" % err)
///         raise
///
/// def _generate_tokens_from_c_tokenizer(source):
///     """Tokenize a source reading Python code as unicode strings using the internal C tokenizer"""
///     import _tokenize as c_tokenizer
///     for info in c_tokenizer.TokenizerIter(source):
///         tok, type, lineno, end_lineno, col_off, end_col_off, line = info
///         yield TokenInfo(type, tok, (lineno, col_off), (end_lineno, end_col_off), line)
///
///
/// if __name__ == "__main__":
///     main()
/// ```
final class tokenize extends PythonModule {
  tokenize.from(super.pythonModule) : super.from();

  static tokenize import() => PythonFfiDart.instance.importModule(
        "tokenize",
        tokenize.from,
      );

  /// ## any
  ///
  /// ### python source
  /// ```py
  /// def any(*choices): return group(*choices) + '*'
  /// ```
  Object? any({
    List<Object?> choices = const <Object?>[],
  }) =>
      getFunction("any").call(
        <Object?>[
          ...choices,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## detect_encoding
  ///
  /// ### python docstring
  ///
  /// The detect_encoding() function is used to detect the encoding that should
  /// be used to decode a Python source file.  It requires one argument, readline,
  /// in the same way as the tokenize() generator.
  ///
  /// It will call readline a maximum of twice, and return the encoding used
  /// (as a string) and a list of any lines (left as bytes) it has read in.
  ///
  /// It detects the encoding from the presence of a utf-8 bom or an encoding
  /// cookie as specified in pep-0263.  If both a bom and a cookie are present,
  /// but disagree, a SyntaxError will be raised.  If the encoding cookie is an
  /// invalid charset, raise a SyntaxError.  Note that if a utf-8 bom is found,
  /// 'utf-8-sig' is returned.
  ///
  /// If no encoding is specified, then the default of 'utf-8' will be returned.
  ///
  /// ### python source
  /// ```py
  /// def detect_encoding(readline):
  ///     """
  ///     The detect_encoding() function is used to detect the encoding that should
  ///     be used to decode a Python source file.  It requires one argument, readline,
  ///     in the same way as the tokenize() generator.
  ///
  ///     It will call readline a maximum of twice, and return the encoding used
  ///     (as a string) and a list of any lines (left as bytes) it has read in.
  ///
  ///     It detects the encoding from the presence of a utf-8 bom or an encoding
  ///     cookie as specified in pep-0263.  If both a bom and a cookie are present,
  ///     but disagree, a SyntaxError will be raised.  If the encoding cookie is an
  ///     invalid charset, raise a SyntaxError.  Note that if a utf-8 bom is found,
  ///     'utf-8-sig' is returned.
  ///
  ///     If no encoding is specified, then the default of 'utf-8' will be returned.
  ///     """
  ///     try:
  ///         filename = readline.__self__.name
  ///     except AttributeError:
  ///         filename = None
  ///     bom_found = False
  ///     encoding = None
  ///     default = 'utf-8'
  ///     def read_or_stop():
  ///         try:
  ///             return readline()
  ///         except StopIteration:
  ///             return b''
  ///
  ///     def find_cookie(line):
  ///         try:
  ///             # Decode as UTF-8. Either the line is an encoding declaration,
  ///             # in which case it should be pure ASCII, or it must be UTF-8
  ///             # per default encoding.
  ///             line_string = line.decode('utf-8')
  ///         except UnicodeDecodeError:
  ///             msg = "invalid or missing encoding declaration"
  ///             if filename is not None:
  ///                 msg = '{} for {!r}'.format(msg, filename)
  ///             raise SyntaxError(msg)
  ///
  ///         match = cookie_re.match(line_string)
  ///         if not match:
  ///             return None
  ///         encoding = _get_normal_name(match.group(1))
  ///         try:
  ///             codec = lookup(encoding)
  ///         except LookupError:
  ///             # This behaviour mimics the Python interpreter
  ///             if filename is None:
  ///                 msg = "unknown encoding: " + encoding
  ///             else:
  ///                 msg = "unknown encoding for {!r}: {}".format(filename,
  ///                         encoding)
  ///             raise SyntaxError(msg)
  ///
  ///         if bom_found:
  ///             if encoding != 'utf-8':
  ///                 # This behaviour mimics the Python interpreter
  ///                 if filename is None:
  ///                     msg = 'encoding problem: utf-8'
  ///                 else:
  ///                     msg = 'encoding problem for {!r}: utf-8'.format(filename)
  ///                 raise SyntaxError(msg)
  ///             encoding += '-sig'
  ///         return encoding
  ///
  ///     first = read_or_stop()
  ///     if first.startswith(BOM_UTF8):
  ///         bom_found = True
  ///         first = first[3:]
  ///         default = 'utf-8-sig'
  ///     if not first:
  ///         return default, []
  ///
  ///     encoding = find_cookie(first)
  ///     if encoding:
  ///         return encoding, [first]
  ///     if not blank_re.match(first):
  ///         return default, [first]
  ///
  ///     second = read_or_stop()
  ///     if not second:
  ///         return default, [first]
  ///
  ///     encoding = find_cookie(second)
  ///     if encoding:
  ///         return encoding, [first, second]
  ///
  ///     return default, [first, second]
  /// ```
  Object? detect_encoding({
    required Object? readline,
  }) =>
      getFunction("detect_encoding").call(
        <Object?>[
          readline,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## generate_tokens
  ///
  /// ### python docstring
  ///
  /// Tokenize a source reading Python code as unicode strings.
  ///
  /// This has the same API as tokenize(), except that it expects the *readline*
  /// callable to return str objects instead of bytes.
  ///
  /// ### python source
  /// ```py
  /// def generate_tokens(readline):
  ///     """Tokenize a source reading Python code as unicode strings.
  ///
  ///     This has the same API as tokenize(), except that it expects the *readline*
  ///     callable to return str objects instead of bytes.
  ///     """
  ///     return _tokenize(readline, None)
  /// ```
  Object? generate_tokens({
    required Object? readline,
  }) =>
      getFunction("generate_tokens").call(
        <Object?>[
          readline,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## group
  ///
  /// ### python source
  /// ```py
  /// def group(*choices): return '(' + '|'.join(choices) + ')'
  /// ```
  Object? group({
    List<Object?> choices = const <Object?>[],
  }) =>
      getFunction("group").call(
        <Object?>[
          ...choices,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## main
  ///
  /// ### python source
  /// ```py
  /// def main():
  ///     import argparse
  ///
  ///     # Helper error handling routines
  ///     def perror(message):
  ///         sys.stderr.write(message)
  ///         sys.stderr.write('\n')
  ///
  ///     def error(message, filename=None, location=None):
  ///         if location:
  ///             args = (filename,) + location + (message,)
  ///             perror("%s:%d:%d: error: %s" % args)
  ///         elif filename:
  ///             perror("%s: error: %s" % (filename, message))
  ///         else:
  ///             perror("error: %s" % message)
  ///         sys.exit(1)
  ///
  ///     # Parse the arguments and options
  ///     parser = argparse.ArgumentParser(prog='python -m tokenize')
  ///     parser.add_argument(dest='filename', nargs='?',
  ///                         metavar='filename.py',
  ///                         help='the file to tokenize; defaults to stdin')
  ///     parser.add_argument('-e', '--exact', dest='exact', action='store_true',
  ///                         help='display token names using the exact type')
  ///     args = parser.parse_args()
  ///
  ///     try:
  ///         # Tokenize the input
  ///         if args.filename:
  ///             filename = args.filename
  ///             with _builtin_open(filename, 'rb') as f:
  ///                 tokens = list(tokenize(f.readline))
  ///         else:
  ///             filename = "<stdin>"
  ///             tokens = _tokenize(sys.stdin.readline, None)
  ///
  ///         # Output the tokenization
  ///         for token in tokens:
  ///             token_type = token.type
  ///             if args.exact:
  ///                 token_type = token.exact_type
  ///             token_range = "%d,%d-%d,%d:" % (token.start + token.end)
  ///             print("%-20s%-15s%-15r" %
  ///                   (token_range, tok_name[token_type], token.string))
  ///     except IndentationError as err:
  ///         line, column = err.args[1][1:3]
  ///         error(err.args[0], filename, (line, column))
  ///     except TokenError as err:
  ///         line, column = err.args[1]
  ///         error(err.args[0], filename, (line, column))
  ///     except SyntaxError as err:
  ///         error(err, filename)
  ///     except OSError as err:
  ///         error(err)
  ///     except KeyboardInterrupt:
  ///         print("interrupted\n")
  ///     except Exception as err:
  ///         perror("unexpected error: %s" % err)
  ///         raise
  /// ```
  Object? main() => getFunction("main").call(
        <Object?>[],
        kwargs: <String, Object?>{},
      );

  /// ## maybe
  ///
  /// ### python source
  /// ```py
  /// def maybe(*choices): return group(*choices) + '?'
  /// ```
  Object? maybe({
    List<Object?> choices = const <Object?>[],
  }) =>
      getFunction("maybe").call(
        <Object?>[
          ...choices,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## open
  ///
  /// ### python docstring
  ///
  /// Open a file in read only mode using the encoding detected by
  /// detect_encoding().
  ///
  /// ### python source
  /// ```py
  /// def open(filename):
  ///     """Open a file in read only mode using the encoding detected by
  ///     detect_encoding().
  ///     """
  ///     buffer = _builtin_open(filename, 'rb')
  ///     try:
  ///         encoding, lines = detect_encoding(buffer.readline)
  ///         buffer.seek(0)
  ///         text = TextIOWrapper(buffer, encoding, line_buffering=True)
  ///         text.mode = 'r'
  ///         return text
  ///     except:
  ///         buffer.close()
  ///         raise
  /// ```
  Object? open({
    required Object? filename,
  }) =>
      getFunction("open").call(
        <Object?>[
          filename,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## untokenize
  ///
  /// ### python docstring
  ///
  /// Transform tokens back into Python source code.
  /// It returns a bytes object, encoded using the ENCODING
  /// token, which is the first token sequence output by tokenize.
  ///
  /// Each element returned by the iterable must be a token sequence
  /// with at least two elements, a token number and token value.  If
  /// only two tokens are passed, the resulting output is poor.
  ///
  /// Round-trip invariant for full input:
  ///     Untokenized source will match input source exactly
  ///
  /// Round-trip invariant for limited input:
  ///     # Output bytes will tokenize back to the input
  ///     t1 = [tok[:2] for tok in tokenize(f.readline)]
  ///     newcode = untokenize(t1)
  ///     readline = BytesIO(newcode).readline
  ///     t2 = [tok[:2] for tok in tokenize(readline)]
  ///     assert t1 == t2
  ///
  /// ### python source
  /// ```py
  /// def untokenize(iterable):
  ///     """Transform tokens back into Python source code.
  ///     It returns a bytes object, encoded using the ENCODING
  ///     token, which is the first token sequence output by tokenize.
  ///
  ///     Each element returned by the iterable must be a token sequence
  ///     with at least two elements, a token number and token value.  If
  ///     only two tokens are passed, the resulting output is poor.
  ///
  ///     Round-trip invariant for full input:
  ///         Untokenized source will match input source exactly
  ///
  ///     Round-trip invariant for limited input:
  ///         # Output bytes will tokenize back to the input
  ///         t1 = [tok[:2] for tok in tokenize(f.readline)]
  ///         newcode = untokenize(t1)
  ///         readline = BytesIO(newcode).readline
  ///         t2 = [tok[:2] for tok in tokenize(readline)]
  ///         assert t1 == t2
  ///     """
  ///     ut = Untokenizer()
  ///     out = ut.untokenize(iterable)
  ///     if ut.encoding is not None:
  ///         out = out.encode(ut.encoding)
  ///     return out
  /// ```
  Object? untokenize({
    required Object? iterable,
  }) =>
      getFunction("untokenize").call(
        <Object?>[
          iterable,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## AMPER (getter)
  Object? get AMPER => getAttribute("AMPER");

  /// ## AMPER (setter)
  set AMPER(Object? AMPER) => setAttribute("AMPER", AMPER);

  /// ## AMPEREQUAL (getter)
  Object? get AMPEREQUAL => getAttribute("AMPEREQUAL");

  /// ## AMPEREQUAL (setter)
  set AMPEREQUAL(Object? AMPEREQUAL) => setAttribute("AMPEREQUAL", AMPEREQUAL);

  /// ## ASYNC (getter)
  Object? get ASYNC => getAttribute("ASYNC");

  /// ## ASYNC (setter)
  set ASYNC(Object? ASYNC) => setAttribute("ASYNC", ASYNC);

  /// ## AT (getter)
  Object? get AT => getAttribute("AT");

  /// ## AT (setter)
  set AT(Object? AT) => setAttribute("AT", AT);

  /// ## ATEQUAL (getter)
  Object? get ATEQUAL => getAttribute("ATEQUAL");

  /// ## ATEQUAL (setter)
  set ATEQUAL(Object? ATEQUAL) => setAttribute("ATEQUAL", ATEQUAL);

  /// ## AWAIT (getter)
  Object? get AWAIT => getAttribute("AWAIT");

  /// ## AWAIT (setter)
  set AWAIT(Object? AWAIT) => setAttribute("AWAIT", AWAIT);

  /// ## BOM_UTF8 (getter)
  Object? get BOM_UTF8 => getAttribute("BOM_UTF8");

  /// ## BOM_UTF8 (setter)
  set BOM_UTF8(Object? BOM_UTF8) => setAttribute("BOM_UTF8", BOM_UTF8);

  /// ## Binnumber (getter)
  Object? get Binnumber => getAttribute("Binnumber");

  /// ## Binnumber (setter)
  set Binnumber(Object? Binnumber) => setAttribute("Binnumber", Binnumber);

  /// ## CIRCUMFLEX (getter)
  Object? get CIRCUMFLEX => getAttribute("CIRCUMFLEX");

  /// ## CIRCUMFLEX (setter)
  set CIRCUMFLEX(Object? CIRCUMFLEX) => setAttribute("CIRCUMFLEX", CIRCUMFLEX);

  /// ## CIRCUMFLEXEQUAL (getter)
  Object? get CIRCUMFLEXEQUAL => getAttribute("CIRCUMFLEXEQUAL");

  /// ## CIRCUMFLEXEQUAL (setter)
  set CIRCUMFLEXEQUAL(Object? CIRCUMFLEXEQUAL) =>
      setAttribute("CIRCUMFLEXEQUAL", CIRCUMFLEXEQUAL);

  /// ## COLON (getter)
  Object? get COLON => getAttribute("COLON");

  /// ## COLON (setter)
  set COLON(Object? COLON) => setAttribute("COLON", COLON);

  /// ## COLONEQUAL (getter)
  Object? get COLONEQUAL => getAttribute("COLONEQUAL");

  /// ## COLONEQUAL (setter)
  set COLONEQUAL(Object? COLONEQUAL) => setAttribute("COLONEQUAL", COLONEQUAL);

  /// ## COMMA (getter)
  Object? get COMMA => getAttribute("COMMA");

  /// ## COMMA (setter)
  set COMMA(Object? COMMA) => setAttribute("COMMA", COMMA);

  /// ## COMMENT (getter)
  Object? get COMMENT => getAttribute("COMMENT");

  /// ## COMMENT (setter)
  set COMMENT(Object? COMMENT) => setAttribute("COMMENT", COMMENT);

  /// ## Comment (getter)
  Object? get Comment => getAttribute("Comment");

  /// ## Comment (setter)
  set Comment(Object? Comment) => setAttribute("Comment", Comment);

  /// ## ContStr (getter)
  Object? get ContStr => getAttribute("ContStr");

  /// ## ContStr (setter)
  set ContStr(Object? ContStr) => setAttribute("ContStr", ContStr);

  /// ## DEDENT (getter)
  Object? get DEDENT => getAttribute("DEDENT");

  /// ## DEDENT (setter)
  set DEDENT(Object? DEDENT) => setAttribute("DEDENT", DEDENT);

  /// ## DOT (getter)
  Object? get DOT => getAttribute("DOT");

  /// ## DOT (setter)
  set DOT(Object? DOT) => setAttribute("DOT", DOT);

  /// ## DOUBLESLASH (getter)
  Object? get DOUBLESLASH => getAttribute("DOUBLESLASH");

  /// ## DOUBLESLASH (setter)
  set DOUBLESLASH(Object? DOUBLESLASH) =>
      setAttribute("DOUBLESLASH", DOUBLESLASH);

  /// ## DOUBLESLASHEQUAL (getter)
  Object? get DOUBLESLASHEQUAL => getAttribute("DOUBLESLASHEQUAL");

  /// ## DOUBLESLASHEQUAL (setter)
  set DOUBLESLASHEQUAL(Object? DOUBLESLASHEQUAL) =>
      setAttribute("DOUBLESLASHEQUAL", DOUBLESLASHEQUAL);

  /// ## DOUBLESTAR (getter)
  Object? get DOUBLESTAR => getAttribute("DOUBLESTAR");

  /// ## DOUBLESTAR (setter)
  set DOUBLESTAR(Object? DOUBLESTAR) => setAttribute("DOUBLESTAR", DOUBLESTAR);

  /// ## DOUBLESTAREQUAL (getter)
  Object? get DOUBLESTAREQUAL => getAttribute("DOUBLESTAREQUAL");

  /// ## DOUBLESTAREQUAL (setter)
  set DOUBLESTAREQUAL(Object? DOUBLESTAREQUAL) =>
      setAttribute("DOUBLESTAREQUAL", DOUBLESTAREQUAL);

  /// ## Decnumber (getter)
  Object? get Decnumber => getAttribute("Decnumber");

  /// ## Decnumber (setter)
  set Decnumber(Object? Decnumber) => setAttribute("Decnumber", Decnumber);

  /// ## Double (getter)
  Object? get Double => getAttribute("Double");

  /// ## Double (setter)
  set Double(Object? Double) => setAttribute("Double", Double);

  /// ## Double3 (getter)
  Object? get Double3 => getAttribute("Double3");

  /// ## Double3 (setter)
  set Double3(Object? Double3) => setAttribute("Double3", Double3);

  /// ## ELLIPSIS (getter)
  Object? get ELLIPSIS => getAttribute("ELLIPSIS");

  /// ## ELLIPSIS (setter)
  set ELLIPSIS(Object? ELLIPSIS) => setAttribute("ELLIPSIS", ELLIPSIS);

  /// ## ENCODING (getter)
  Object? get ENCODING => getAttribute("ENCODING");

  /// ## ENCODING (setter)
  set ENCODING(Object? ENCODING) => setAttribute("ENCODING", ENCODING);

  /// ## ENDMARKER (getter)
  Object? get ENDMARKER => getAttribute("ENDMARKER");

  /// ## ENDMARKER (setter)
  set ENDMARKER(Object? ENDMARKER) => setAttribute("ENDMARKER", ENDMARKER);

  /// ## EQEQUAL (getter)
  Object? get EQEQUAL => getAttribute("EQEQUAL");

  /// ## EQEQUAL (setter)
  set EQEQUAL(Object? EQEQUAL) => setAttribute("EQEQUAL", EQEQUAL);

  /// ## EQUAL (getter)
  Object? get EQUAL => getAttribute("EQUAL");

  /// ## EQUAL (setter)
  set EQUAL(Object? EQUAL) => setAttribute("EQUAL", EQUAL);

  /// ## ERRORTOKEN (getter)
  Object? get ERRORTOKEN => getAttribute("ERRORTOKEN");

  /// ## ERRORTOKEN (setter)
  set ERRORTOKEN(Object? ERRORTOKEN) => setAttribute("ERRORTOKEN", ERRORTOKEN);

  /// ## EXACT_TOKEN_TYPES (getter)
  Object? get EXACT_TOKEN_TYPES => getAttribute("EXACT_TOKEN_TYPES");

  /// ## EXACT_TOKEN_TYPES (setter)
  set EXACT_TOKEN_TYPES(Object? EXACT_TOKEN_TYPES) =>
      setAttribute("EXACT_TOKEN_TYPES", EXACT_TOKEN_TYPES);

  /// ## Expfloat (getter)
  Object? get Expfloat => getAttribute("Expfloat");

  /// ## Expfloat (setter)
  set Expfloat(Object? Expfloat) => setAttribute("Expfloat", Expfloat);

  /// ## Exponent (getter)
  Object? get Exponent => getAttribute("Exponent");

  /// ## Exponent (setter)
  set Exponent(Object? Exponent) => setAttribute("Exponent", Exponent);

  /// ## Floatnumber (getter)
  Object? get Floatnumber => getAttribute("Floatnumber");

  /// ## Floatnumber (setter)
  set Floatnumber(Object? Floatnumber) =>
      setAttribute("Floatnumber", Floatnumber);

  /// ## Funny (getter)
  Object? get Funny => getAttribute("Funny");

  /// ## Funny (setter)
  set Funny(Object? Funny) => setAttribute("Funny", Funny);

  /// ## GREATER (getter)
  Object? get GREATER => getAttribute("GREATER");

  /// ## GREATER (setter)
  set GREATER(Object? GREATER) => setAttribute("GREATER", GREATER);

  /// ## GREATEREQUAL (getter)
  Object? get GREATEREQUAL => getAttribute("GREATEREQUAL");

  /// ## GREATEREQUAL (setter)
  set GREATEREQUAL(Object? GREATEREQUAL) =>
      setAttribute("GREATEREQUAL", GREATEREQUAL);

  /// ## Hexnumber (getter)
  Object? get Hexnumber => getAttribute("Hexnumber");

  /// ## Hexnumber (setter)
  set Hexnumber(Object? Hexnumber) => setAttribute("Hexnumber", Hexnumber);

  /// ## INDENT (getter)
  Object? get INDENT => getAttribute("INDENT");

  /// ## INDENT (setter)
  set INDENT(Object? INDENT) => setAttribute("INDENT", INDENT);

  /// ## Ignore (getter)
  Object? get Ignore => getAttribute("Ignore");

  /// ## Ignore (setter)
  set Ignore(Object? Ignore) => setAttribute("Ignore", Ignore);

  /// ## Imagnumber (getter)
  Object? get Imagnumber => getAttribute("Imagnumber");

  /// ## Imagnumber (setter)
  set Imagnumber(Object? Imagnumber) => setAttribute("Imagnumber", Imagnumber);

  /// ## Intnumber (getter)
  Object? get Intnumber => getAttribute("Intnumber");

  /// ## Intnumber (setter)
  set Intnumber(Object? Intnumber) => setAttribute("Intnumber", Intnumber);

  /// ## LBRACE (getter)
  Object? get LBRACE => getAttribute("LBRACE");

  /// ## LBRACE (setter)
  set LBRACE(Object? LBRACE) => setAttribute("LBRACE", LBRACE);

  /// ## LEFTSHIFT (getter)
  Object? get LEFTSHIFT => getAttribute("LEFTSHIFT");

  /// ## LEFTSHIFT (setter)
  set LEFTSHIFT(Object? LEFTSHIFT) => setAttribute("LEFTSHIFT", LEFTSHIFT);

  /// ## LEFTSHIFTEQUAL (getter)
  Object? get LEFTSHIFTEQUAL => getAttribute("LEFTSHIFTEQUAL");

  /// ## LEFTSHIFTEQUAL (setter)
  set LEFTSHIFTEQUAL(Object? LEFTSHIFTEQUAL) =>
      setAttribute("LEFTSHIFTEQUAL", LEFTSHIFTEQUAL);

  /// ## LESS (getter)
  Object? get LESS => getAttribute("LESS");

  /// ## LESS (setter)
  set LESS(Object? LESS) => setAttribute("LESS", LESS);

  /// ## LESSEQUAL (getter)
  Object? get LESSEQUAL => getAttribute("LESSEQUAL");

  /// ## LESSEQUAL (setter)
  set LESSEQUAL(Object? LESSEQUAL) => setAttribute("LESSEQUAL", LESSEQUAL);

  /// ## LPAR (getter)
  Object? get LPAR => getAttribute("LPAR");

  /// ## LPAR (setter)
  set LPAR(Object? LPAR) => setAttribute("LPAR", LPAR);

  /// ## LSQB (getter)
  Object? get LSQB => getAttribute("LSQB");

  /// ## LSQB (setter)
  set LSQB(Object? LSQB) => setAttribute("LSQB", LSQB);

  /// ## MINEQUAL (getter)
  Object? get MINEQUAL => getAttribute("MINEQUAL");

  /// ## MINEQUAL (setter)
  set MINEQUAL(Object? MINEQUAL) => setAttribute("MINEQUAL", MINEQUAL);

  /// ## MINUS (getter)
  Object? get MINUS => getAttribute("MINUS");

  /// ## MINUS (setter)
  set MINUS(Object? MINUS) => setAttribute("MINUS", MINUS);

  /// ## NAME (getter)
  Object? get NAME => getAttribute("NAME");

  /// ## NAME (setter)
  set NAME(Object? NAME) => setAttribute("NAME", NAME);

  /// ## NEWLINE (getter)
  Object? get NEWLINE => getAttribute("NEWLINE");

  /// ## NEWLINE (setter)
  set NEWLINE(Object? NEWLINE) => setAttribute("NEWLINE", NEWLINE);

  /// ## NL (getter)
  Object? get NL => getAttribute("NL");

  /// ## NL (setter)
  set NL(Object? NL) => setAttribute("NL", NL);

  /// ## NOTEQUAL (getter)
  Object? get NOTEQUAL => getAttribute("NOTEQUAL");

  /// ## NOTEQUAL (setter)
  set NOTEQUAL(Object? NOTEQUAL) => setAttribute("NOTEQUAL", NOTEQUAL);

  /// ## NT_OFFSET (getter)
  Object? get NT_OFFSET => getAttribute("NT_OFFSET");

  /// ## NT_OFFSET (setter)
  set NT_OFFSET(Object? NT_OFFSET) => setAttribute("NT_OFFSET", NT_OFFSET);

  /// ## NUMBER (getter)
  Object? get NUMBER => getAttribute("NUMBER");

  /// ## NUMBER (setter)
  set NUMBER(Object? NUMBER) => setAttribute("NUMBER", NUMBER);

  /// ## N_TOKENS (getter)
  Object? get N_TOKENS => getAttribute("N_TOKENS");

  /// ## N_TOKENS (setter)
  set N_TOKENS(Object? N_TOKENS) => setAttribute("N_TOKENS", N_TOKENS);

  /// ## Name (getter)
  Object? get Name => getAttribute("Name");

  /// ## Name (setter)
  set Name(Object? Name) => setAttribute("Name", Name);

  /// ## Number (getter)
  Object? get Number => getAttribute("Number");

  /// ## Number (setter)
  set Number(Object? Number) => setAttribute("Number", Number);

  /// ## OP (getter)
  Object? get OP => getAttribute("OP");

  /// ## OP (setter)
  set OP(Object? OP) => setAttribute("OP", OP);

  /// ## Octnumber (getter)
  Object? get Octnumber => getAttribute("Octnumber");

  /// ## Octnumber (setter)
  set Octnumber(Object? Octnumber) => setAttribute("Octnumber", Octnumber);

  /// ## PERCENT (getter)
  Object? get PERCENT => getAttribute("PERCENT");

  /// ## PERCENT (setter)
  set PERCENT(Object? PERCENT) => setAttribute("PERCENT", PERCENT);

  /// ## PERCENTEQUAL (getter)
  Object? get PERCENTEQUAL => getAttribute("PERCENTEQUAL");

  /// ## PERCENTEQUAL (setter)
  set PERCENTEQUAL(Object? PERCENTEQUAL) =>
      setAttribute("PERCENTEQUAL", PERCENTEQUAL);

  /// ## PLUS (getter)
  Object? get PLUS => getAttribute("PLUS");

  /// ## PLUS (setter)
  set PLUS(Object? PLUS) => setAttribute("PLUS", PLUS);

  /// ## PLUSEQUAL (getter)
  Object? get PLUSEQUAL => getAttribute("PLUSEQUAL");

  /// ## PLUSEQUAL (setter)
  set PLUSEQUAL(Object? PLUSEQUAL) => setAttribute("PLUSEQUAL", PLUSEQUAL);

  /// ## PlainToken (getter)
  Object? get PlainToken => getAttribute("PlainToken");

  /// ## PlainToken (setter)
  set PlainToken(Object? PlainToken) => setAttribute("PlainToken", PlainToken);

  /// ## Pointfloat (getter)
  Object? get Pointfloat => getAttribute("Pointfloat");

  /// ## Pointfloat (setter)
  set Pointfloat(Object? Pointfloat) => setAttribute("Pointfloat", Pointfloat);

  /// ## PseudoExtras (getter)
  Object? get PseudoExtras => getAttribute("PseudoExtras");

  /// ## PseudoExtras (setter)
  set PseudoExtras(Object? PseudoExtras) =>
      setAttribute("PseudoExtras", PseudoExtras);

  /// ## PseudoToken (getter)
  Object? get PseudoToken => getAttribute("PseudoToken");

  /// ## PseudoToken (setter)
  set PseudoToken(Object? PseudoToken) =>
      setAttribute("PseudoToken", PseudoToken);

  /// ## RARROW (getter)
  Object? get RARROW => getAttribute("RARROW");

  /// ## RARROW (setter)
  set RARROW(Object? RARROW) => setAttribute("RARROW", RARROW);

  /// ## RBRACE (getter)
  Object? get RBRACE => getAttribute("RBRACE");

  /// ## RBRACE (setter)
  set RBRACE(Object? RBRACE) => setAttribute("RBRACE", RBRACE);

  /// ## RIGHTSHIFT (getter)
  Object? get RIGHTSHIFT => getAttribute("RIGHTSHIFT");

  /// ## RIGHTSHIFT (setter)
  set RIGHTSHIFT(Object? RIGHTSHIFT) => setAttribute("RIGHTSHIFT", RIGHTSHIFT);

  /// ## RIGHTSHIFTEQUAL (getter)
  Object? get RIGHTSHIFTEQUAL => getAttribute("RIGHTSHIFTEQUAL");

  /// ## RIGHTSHIFTEQUAL (setter)
  set RIGHTSHIFTEQUAL(Object? RIGHTSHIFTEQUAL) =>
      setAttribute("RIGHTSHIFTEQUAL", RIGHTSHIFTEQUAL);

  /// ## RPAR (getter)
  Object? get RPAR => getAttribute("RPAR");

  /// ## RPAR (setter)
  set RPAR(Object? RPAR) => setAttribute("RPAR", RPAR);

  /// ## RSQB (getter)
  Object? get RSQB => getAttribute("RSQB");

  /// ## RSQB (setter)
  set RSQB(Object? RSQB) => setAttribute("RSQB", RSQB);

  /// ## SEMI (getter)
  Object? get SEMI => getAttribute("SEMI");

  /// ## SEMI (setter)
  set SEMI(Object? SEMI) => setAttribute("SEMI", SEMI);

  /// ## SLASH (getter)
  Object? get SLASH => getAttribute("SLASH");

  /// ## SLASH (setter)
  set SLASH(Object? SLASH) => setAttribute("SLASH", SLASH);

  /// ## SLASHEQUAL (getter)
  Object? get SLASHEQUAL => getAttribute("SLASHEQUAL");

  /// ## SLASHEQUAL (setter)
  set SLASHEQUAL(Object? SLASHEQUAL) => setAttribute("SLASHEQUAL", SLASHEQUAL);

  /// ## SOFT_KEYWORD (getter)
  Object? get SOFT_KEYWORD => getAttribute("SOFT_KEYWORD");

  /// ## SOFT_KEYWORD (setter)
  set SOFT_KEYWORD(Object? SOFT_KEYWORD) =>
      setAttribute("SOFT_KEYWORD", SOFT_KEYWORD);

  /// ## STAR (getter)
  Object? get STAR => getAttribute("STAR");

  /// ## STAR (setter)
  set STAR(Object? STAR) => setAttribute("STAR", STAR);

  /// ## STAREQUAL (getter)
  Object? get STAREQUAL => getAttribute("STAREQUAL");

  /// ## STAREQUAL (setter)
  set STAREQUAL(Object? STAREQUAL) => setAttribute("STAREQUAL", STAREQUAL);

  /// ## STRING (getter)
  Object? get STRING => getAttribute("STRING");

  /// ## STRING (setter)
  set STRING(Object? STRING) => setAttribute("STRING", STRING);

  /// ## Single (getter)
  Object? get Single => getAttribute("Single");

  /// ## Single (setter)
  set Single(Object? Single) => setAttribute("Single", Single);

  /// ## Single3 (getter)
  Object? get Single3 => getAttribute("Single3");

  /// ## Single3 (setter)
  set Single3(Object? Single3) => setAttribute("Single3", Single3);

  /// ## Special (getter)
  Object? get Special => getAttribute("Special");

  /// ## Special (setter)
  set Special(Object? Special) => setAttribute("Special", Special);

  /// ## String (getter)
  Object? get $String => getAttribute("String");

  /// ## String (setter)
  set $String(Object? $String) => setAttribute("String", $String);

  /// ## StringPrefix (getter)
  Object? get StringPrefix => getAttribute("StringPrefix");

  /// ## StringPrefix (setter)
  set StringPrefix(Object? StringPrefix) =>
      setAttribute("StringPrefix", StringPrefix);

  /// ## TILDE (getter)
  Object? get TILDE => getAttribute("TILDE");

  /// ## TILDE (setter)
  set TILDE(Object? TILDE) => setAttribute("TILDE", TILDE);

  /// ## TYPE_COMMENT (getter)
  Object? get TYPE_COMMENT => getAttribute("TYPE_COMMENT");

  /// ## TYPE_COMMENT (setter)
  set TYPE_COMMENT(Object? TYPE_COMMENT) =>
      setAttribute("TYPE_COMMENT", TYPE_COMMENT);

  /// ## TYPE_IGNORE (getter)
  Object? get TYPE_IGNORE => getAttribute("TYPE_IGNORE");

  /// ## TYPE_IGNORE (setter)
  set TYPE_IGNORE(Object? TYPE_IGNORE) =>
      setAttribute("TYPE_IGNORE", TYPE_IGNORE);

  /// ## Token (getter)
  Object? get Token => getAttribute("Token");

  /// ## Token (setter)
  set Token(Object? Token) => setAttribute("Token", Token);

  /// ## Triple (getter)
  Object? get Triple => getAttribute("Triple");

  /// ## Triple (setter)
  set Triple(Object? Triple) => setAttribute("Triple", Triple);

  /// ## VBAR (getter)
  Object? get VBAR => getAttribute("VBAR");

  /// ## VBAR (setter)
  set VBAR(Object? VBAR) => setAttribute("VBAR", VBAR);

  /// ## VBAREQUAL (getter)
  Object? get VBAREQUAL => getAttribute("VBAREQUAL");

  /// ## VBAREQUAL (setter)
  set VBAREQUAL(Object? VBAREQUAL) => setAttribute("VBAREQUAL", VBAREQUAL);

  /// ## Whitespace (getter)
  Object? get Whitespace => getAttribute("Whitespace");

  /// ## Whitespace (setter)
  set Whitespace(Object? Whitespace) => setAttribute("Whitespace", Whitespace);

  /// ## endpats (getter)
  Object? get endpats => getAttribute("endpats");

  /// ## endpats (setter)
  set endpats(Object? endpats) => setAttribute("endpats", endpats);

  /// ## single_quoted (getter)
  Object? get single_quoted => getAttribute("single_quoted");

  /// ## single_quoted (setter)
  set single_quoted(Object? single_quoted) =>
      setAttribute("single_quoted", single_quoted);

  /// ## tabsize (getter)
  Object? get tabsize => getAttribute("tabsize");

  /// ## tabsize (setter)
  set tabsize(Object? tabsize) => setAttribute("tabsize", tabsize);

  /// ## tok_name (getter)
  Object? get tok_name => getAttribute("tok_name");

  /// ## tok_name (setter)
  set tok_name(Object? tok_name) => setAttribute("tok_name", tok_name);

  /// ## triple_quoted (getter)
  Object? get triple_quoted => getAttribute("triple_quoted");

  /// ## triple_quoted (setter)
  set triple_quoted(Object? triple_quoted) =>
      setAttribute("triple_quoted", triple_quoted);
}

/// ## textwrap
///
/// ### python docstring
///
/// Text wrapping and filling.
///
/// ### python source
/// ```py
/// """Text wrapping and filling.
/// """
///
/// # Copyright (C) 1999-2001 Gregory P. Ward.
/// # Copyright (C) 2002, 2003 Python Software Foundation.
/// # Written by Greg Ward <gward@python.net>
///
/// import re
///
/// __all__ = ['TextWrapper', 'wrap', 'fill', 'dedent', 'indent', 'shorten']
///
/// # Hardcode the recognized whitespace characters to the US-ASCII
/// # whitespace characters.  The main reason for doing this is that
/// # some Unicode spaces (like \u00a0) are non-breaking whitespaces.
/// _whitespace = '\t\n\x0b\x0c\r '
///
/// class TextWrapper:
///     """
///     Object for wrapping/filling text.  The public interface consists of
///     the wrap() and fill() methods; the other methods are just there for
///     subclasses to override in order to tweak the default behaviour.
///     If you want to completely replace the main wrapping algorithm,
///     you'll probably have to override _wrap_chunks().
///
///     Several instance attributes control various aspects of wrapping:
///       width (default: 70)
///         the maximum width of wrapped lines (unless break_long_words
///         is false)
///       initial_indent (default: "")
///         string that will be prepended to the first line of wrapped
///         output.  Counts towards the line's width.
///       subsequent_indent (default: "")
///         string that will be prepended to all lines save the first
///         of wrapped output; also counts towards each line's width.
///       expand_tabs (default: true)
///         Expand tabs in input text to spaces before further processing.
///         Each tab will become 0 .. 'tabsize' spaces, depending on its position
///         in its line.  If false, each tab is treated as a single character.
///       tabsize (default: 8)
///         Expand tabs in input text to 0 .. 'tabsize' spaces, unless
///         'expand_tabs' is false.
///       replace_whitespace (default: true)
///         Replace all whitespace characters in the input text by spaces
///         after tab expansion.  Note that if expand_tabs is false and
///         replace_whitespace is true, every tab will be converted to a
///         single space!
///       fix_sentence_endings (default: false)
///         Ensure that sentence-ending punctuation is always followed
///         by two spaces.  Off by default because the algorithm is
///         (unavoidably) imperfect.
///       break_long_words (default: true)
///         Break words longer than 'width'.  If false, those words will not
///         be broken, and some lines might be longer than 'width'.
///       break_on_hyphens (default: true)
///         Allow breaking hyphenated words. If true, wrapping will occur
///         preferably on whitespaces and right after hyphens part of
///         compound words.
///       drop_whitespace (default: true)
///         Drop leading and trailing whitespace from lines.
///       max_lines (default: None)
///         Truncate wrapped lines.
///       placeholder (default: ' [...]')
///         Append to the last line of truncated text.
///     """
///
///     unicode_whitespace_trans = dict.fromkeys(map(ord, _whitespace), ord(' '))
///
///     # This funky little regex is just the trick for splitting
///     # text up into word-wrappable chunks.  E.g.
///     #   "Hello there -- you goof-ball, use the -b option!"
///     # splits into
///     #   Hello/ /there/ /--/ /you/ /goof-/ball,/ /use/ /the/ /-b/ /option!
///     # (after stripping out empty strings).
///     word_punct = r'[\w!"\'&.,?]'
///     letter = r'[^\d\W]'
///     whitespace = r'[%s]' % re.escape(_whitespace)
///     nowhitespace = '[^' + whitespace[1:]
///     wordsep_re = re.compile(r'''
///         ( # any whitespace
///           %(ws)s+
///         | # em-dash between words
///           (?<=%(wp)s) -{2,} (?=\w)
///         | # word, possibly hyphenated
///           %(nws)s+? (?:
///             # hyphenated word
///               -(?: (?<=%(lt)s{2}-) | (?<=%(lt)s-%(lt)s-))
///               (?= %(lt)s -? %(lt)s)
///             | # end of word
///               (?=%(ws)s|\Z)
///             | # em-dash
///               (?<=%(wp)s) (?=-{2,}\w)
///             )
///         )''' % {'wp': word_punct, 'lt': letter,
///                 'ws': whitespace, 'nws': nowhitespace},
///         re.VERBOSE)
///     del word_punct, letter, nowhitespace
///
///     # This less funky little regex just split on recognized spaces. E.g.
///     #   "Hello there -- you goof-ball, use the -b option!"
///     # splits into
///     #   Hello/ /there/ /--/ /you/ /goof-ball,/ /use/ /the/ /-b/ /option!/
///     wordsep_simple_re = re.compile(r'(%s+)' % whitespace)
///     del whitespace
///
///     # XXX this is not locale- or charset-aware -- string.lowercase
///     # is US-ASCII only (and therefore English-only)
///     sentence_end_re = re.compile(r'[a-z]'             # lowercase letter
///                                  r'[\.\!\?]'          # sentence-ending punct.
///                                  r'[\"\']?'           # optional end-of-quote
///                                  r'\Z')               # end of chunk
///
///     def __init__(self,
///                  width=70,
///                  initial_indent="",
///                  subsequent_indent="",
///                  expand_tabs=True,
///                  replace_whitespace=True,
///                  fix_sentence_endings=False,
///                  break_long_words=True,
///                  drop_whitespace=True,
///                  break_on_hyphens=True,
///                  tabsize=8,
///                  *,
///                  max_lines=None,
///                  placeholder=' [...]'):
///         self.width = width
///         self.initial_indent = initial_indent
///         self.subsequent_indent = subsequent_indent
///         self.expand_tabs = expand_tabs
///         self.replace_whitespace = replace_whitespace
///         self.fix_sentence_endings = fix_sentence_endings
///         self.break_long_words = break_long_words
///         self.drop_whitespace = drop_whitespace
///         self.break_on_hyphens = break_on_hyphens
///         self.tabsize = tabsize
///         self.max_lines = max_lines
///         self.placeholder = placeholder
///
///
///     # -- Private methods -----------------------------------------------
///     # (possibly useful for subclasses to override)
///
///     def _munge_whitespace(self, text):
///         """_munge_whitespace(text : string) -> string
///
///         Munge whitespace in text: expand tabs and convert all other
///         whitespace characters to spaces.  Eg. " foo\\tbar\\n\\nbaz"
///         becomes " foo    bar  baz".
///         """
///         if self.expand_tabs:
///             text = text.expandtabs(self.tabsize)
///         if self.replace_whitespace:
///             text = text.translate(self.unicode_whitespace_trans)
///         return text
///
///
///     def _split(self, text):
///         """_split(text : string) -> [string]
///
///         Split the text to wrap into indivisible chunks.  Chunks are
///         not quite the same as words; see _wrap_chunks() for full
///         details.  As an example, the text
///           Look, goof-ball -- use the -b option!
///         breaks into the following chunks:
///           'Look,', ' ', 'goof-', 'ball', ' ', '--', ' ',
///           'use', ' ', 'the', ' ', '-b', ' ', 'option!'
///         if break_on_hyphens is True, or in:
///           'Look,', ' ', 'goof-ball', ' ', '--', ' ',
///           'use', ' ', 'the', ' ', '-b', ' ', option!'
///         otherwise.
///         """
///         if self.break_on_hyphens is True:
///             chunks = self.wordsep_re.split(text)
///         else:
///             chunks = self.wordsep_simple_re.split(text)
///         chunks = [c for c in chunks if c]
///         return chunks
///
///     def _fix_sentence_endings(self, chunks):
///         """_fix_sentence_endings(chunks : [string])
///
///         Correct for sentence endings buried in 'chunks'.  Eg. when the
///         original text contains "... foo.\\nBar ...", munge_whitespace()
///         and split() will convert that to [..., "foo.", " ", "Bar", ...]
///         which has one too few spaces; this method simply changes the one
///         space to two.
///         """
///         i = 0
///         patsearch = self.sentence_end_re.search
///         while i < len(chunks)-1:
///             if chunks[i+1] == " " and patsearch(chunks[i]):
///                 chunks[i+1] = "  "
///                 i += 2
///             else:
///                 i += 1
///
///     def _handle_long_word(self, reversed_chunks, cur_line, cur_len, width):
///         """_handle_long_word(chunks : [string],
///                              cur_line : [string],
///                              cur_len : int, width : int)
///
///         Handle a chunk of text (most likely a word, not whitespace) that
///         is too long to fit in any line.
///         """
///         # Figure out when indent is larger than the specified width, and make
///         # sure at least one character is stripped off on every pass
///         if width < 1:
///             space_left = 1
///         else:
///             space_left = width - cur_len
///
///         # If we're allowed to break long words, then do so: put as much
///         # of the next chunk onto the current line as will fit.
///         if self.break_long_words:
///             end = space_left
///             chunk = reversed_chunks[-1]
///             if self.break_on_hyphens and len(chunk) > space_left:
///                 # break after last hyphen, but only if there are
///                 # non-hyphens before it
///                 hyphen = chunk.rfind('-', 0, space_left)
///                 if hyphen > 0 and any(c != '-' for c in chunk[:hyphen]):
///                     end = hyphen + 1
///             cur_line.append(chunk[:end])
///             reversed_chunks[-1] = chunk[end:]
///
///         # Otherwise, we have to preserve the long word intact.  Only add
///         # it to the current line if there's nothing already there --
///         # that minimizes how much we violate the width constraint.
///         elif not cur_line:
///             cur_line.append(reversed_chunks.pop())
///
///         # If we're not allowed to break long words, and there's already
///         # text on the current line, do nothing.  Next time through the
///         # main loop of _wrap_chunks(), we'll wind up here again, but
///         # cur_len will be zero, so the next line will be entirely
///         # devoted to the long word that we can't handle right now.
///
///     def _wrap_chunks(self, chunks):
///         """_wrap_chunks(chunks : [string]) -> [string]
///
///         Wrap a sequence of text chunks and return a list of lines of
///         length 'self.width' or less.  (If 'break_long_words' is false,
///         some lines may be longer than this.)  Chunks correspond roughly
///         to words and the whitespace between them: each chunk is
///         indivisible (modulo 'break_long_words'), but a line break can
///         come between any two chunks.  Chunks should not have internal
///         whitespace; ie. a chunk is either all whitespace or a "word".
///         Whitespace chunks will be removed from the beginning and end of
///         lines, but apart from that whitespace is preserved.
///         """
///         lines = []
///         if self.width <= 0:
///             raise ValueError("invalid width %r (must be > 0)" % self.width)
///         if self.max_lines is not None:
///             if self.max_lines > 1:
///                 indent = self.subsequent_indent
///             else:
///                 indent = self.initial_indent
///             if len(indent) + len(self.placeholder.lstrip()) > self.width:
///                 raise ValueError("placeholder too large for max width")
///
///         # Arrange in reverse order so items can be efficiently popped
///         # from a stack of chucks.
///         chunks.reverse()
///
///         while chunks:
///
///             # Start the list of chunks that will make up the current line.
///             # cur_len is just the length of all the chunks in cur_line.
///             cur_line = []
///             cur_len = 0
///
///             # Figure out which static string will prefix this line.
///             if lines:
///                 indent = self.subsequent_indent
///             else:
///                 indent = self.initial_indent
///
///             # Maximum width for this line.
///             width = self.width - len(indent)
///
///             # First chunk on line is whitespace -- drop it, unless this
///             # is the very beginning of the text (ie. no lines started yet).
///             if self.drop_whitespace and chunks[-1].strip() == '' and lines:
///                 del chunks[-1]
///
///             while chunks:
///                 l = len(chunks[-1])
///
///                 # Can at least squeeze this chunk onto the current line.
///                 if cur_len + l <= width:
///                     cur_line.append(chunks.pop())
///                     cur_len += l
///
///                 # Nope, this line is full.
///                 else:
///                     break
///
///             # The current line is full, and the next chunk is too big to
///             # fit on *any* line (not just this one).
///             if chunks and len(chunks[-1]) > width:
///                 self._handle_long_word(chunks, cur_line, cur_len, width)
///                 cur_len = sum(map(len, cur_line))
///
///             # If the last chunk on this line is all whitespace, drop it.
///             if self.drop_whitespace and cur_line and cur_line[-1].strip() == '':
///                 cur_len -= len(cur_line[-1])
///                 del cur_line[-1]
///
///             if cur_line:
///                 if (self.max_lines is None or
///                     len(lines) + 1 < self.max_lines or
///                     (not chunks or
///                      self.drop_whitespace and
///                      len(chunks) == 1 and
///                      not chunks[0].strip()) and cur_len <= width):
///                     # Convert current line back to a string and store it in
///                     # list of all lines (return value).
///                     lines.append(indent + ''.join(cur_line))
///                 else:
///                     while cur_line:
///                         if (cur_line[-1].strip() and
///                             cur_len + len(self.placeholder) <= width):
///                             cur_line.append(self.placeholder)
///                             lines.append(indent + ''.join(cur_line))
///                             break
///                         cur_len -= len(cur_line[-1])
///                         del cur_line[-1]
///                     else:
///                         if lines:
///                             prev_line = lines[-1].rstrip()
///                             if (len(prev_line) + len(self.placeholder) <=
///                                     self.width):
///                                 lines[-1] = prev_line + self.placeholder
///                                 break
///                         lines.append(indent + self.placeholder.lstrip())
///                     break
///
///         return lines
///
///     def _split_chunks(self, text):
///         text = self._munge_whitespace(text)
///         return self._split(text)
///
///     # -- Public interface ----------------------------------------------
///
///     def wrap(self, text):
///         """wrap(text : string) -> [string]
///
///         Reformat the single paragraph in 'text' so it fits in lines of
///         no more than 'self.width' columns, and return a list of wrapped
///         lines.  Tabs in 'text' are expanded with string.expandtabs(),
///         and all other whitespace characters (including newline) are
///         converted to space.
///         """
///         chunks = self._split_chunks(text)
///         if self.fix_sentence_endings:
///             self._fix_sentence_endings(chunks)
///         return self._wrap_chunks(chunks)
///
///     def fill(self, text):
///         """fill(text : string) -> string
///
///         Reformat the single paragraph in 'text' to fit in lines of no
///         more than 'self.width' columns, and return a new string
///         containing the entire wrapped paragraph.
///         """
///         return "\n".join(self.wrap(text))
///
///
/// # -- Convenience interface ---------------------------------------------
///
/// def wrap(text, width=70, **kwargs):
///     """Wrap a single paragraph of text, returning a list of wrapped lines.
///
///     Reformat the single paragraph in 'text' so it fits in lines of no
///     more than 'width' columns, and return a list of wrapped lines.  By
///     default, tabs in 'text' are expanded with string.expandtabs(), and
///     all other whitespace characters (including newline) are converted to
///     space.  See TextWrapper class for available keyword args to customize
///     wrapping behaviour.
///     """
///     w = TextWrapper(width=width, **kwargs)
///     return w.wrap(text)
///
/// def fill(text, width=70, **kwargs):
///     """Fill a single paragraph of text, returning a new string.
///
///     Reformat the single paragraph in 'text' to fit in lines of no more
///     than 'width' columns, and return a new string containing the entire
///     wrapped paragraph.  As with wrap(), tabs are expanded and other
///     whitespace characters converted to space.  See TextWrapper class for
///     available keyword args to customize wrapping behaviour.
///     """
///     w = TextWrapper(width=width, **kwargs)
///     return w.fill(text)
///
/// def shorten(text, width, **kwargs):
///     """Collapse and truncate the given text to fit in the given width.
///
///     The text first has its whitespace collapsed.  If it then fits in
///     the *width*, it is returned as is.  Otherwise, as many words
///     as possible are joined and then the placeholder is appended::
///
///         >>> textwrap.shorten("Hello  world!", width=12)
///         'Hello world!'
///         >>> textwrap.shorten("Hello  world!", width=11)
///         'Hello [...]'
///     """
///     w = TextWrapper(width=width, max_lines=1, **kwargs)
///     return w.fill(' '.join(text.strip().split()))
///
///
/// # -- Loosely related functionality -------------------------------------
///
/// _whitespace_only_re = re.compile('^[ \t]+$', re.MULTILINE)
/// _leading_whitespace_re = re.compile('(^[ \t]*)(?:[^ \t\n])', re.MULTILINE)
///
/// def dedent(text):
///     """Remove any common leading whitespace from every line in `text`.
///
///     This can be used to make triple-quoted strings line up with the left
///     edge of the display, while still presenting them in the source code
///     in indented form.
///
///     Note that tabs and spaces are both treated as whitespace, but they
///     are not equal: the lines "  hello" and "\\thello" are
///     considered to have no common leading whitespace.
///
///     Entirely blank lines are normalized to a newline character.
///     """
///     # Look for the longest leading string of spaces and tabs common to
///     # all lines.
///     margin = None
///     text = _whitespace_only_re.sub('', text)
///     indents = _leading_whitespace_re.findall(text)
///     for indent in indents:
///         if margin is None:
///             margin = indent
///
///         # Current line more deeply indented than previous winner:
///         # no change (previous winner is still on top).
///         elif indent.startswith(margin):
///             pass
///
///         # Current line consistent with and no deeper than previous winner:
///         # it's the new winner.
///         elif margin.startswith(indent):
///             margin = indent
///
///         # Find the largest common whitespace between current line and previous
///         # winner.
///         else:
///             for i, (x, y) in enumerate(zip(margin, indent)):
///                 if x != y:
///                     margin = margin[:i]
///                     break
///
///     # sanity check (testing/debugging only)
///     if 0 and margin:
///         for line in text.split("\n"):
///             assert not line or line.startswith(margin), \
///                    "line = %r, margin = %r" % (line, margin)
///
///     if margin:
///         text = re.sub(r'(?m)^' + margin, '', text)
///     return text
///
///
/// def indent(text, prefix, predicate=None):
///     """Adds 'prefix' to the beginning of selected lines in 'text'.
///
///     If 'predicate' is provided, 'prefix' will only be added to the lines
///     where 'predicate(line)' is True. If 'predicate' is not provided,
///     it will default to adding 'prefix' to all non-empty lines that do not
///     consist solely of whitespace characters.
///     """
///     if predicate is None:
///         def predicate(line):
///             return line.strip()
///
///     def prefixed_lines():
///         for line in text.splitlines(True):
///             yield (prefix + line if predicate(line) else line)
///     return ''.join(prefixed_lines())
///
///
/// if __name__ == "__main__":
///     #print dedent("\tfoo\n\tbar")
///     #print dedent("  \thello there\n  \t  how are you?")
///     print(dedent("Hello there.\n  This is indented."))
/// ```
final class textwrap extends PythonModule {
  textwrap.from(super.pythonModule) : super.from();

  static textwrap import() => PythonFfiDart.instance.importModule(
        "textwrap",
        textwrap.from,
      );

  /// ## dedent
  ///
  /// ### python docstring
  ///
  /// Remove any common leading whitespace from every line in `text`.
  ///
  /// This can be used to make triple-quoted strings line up with the left
  /// edge of the display, while still presenting them in the source code
  /// in indented form.
  ///
  /// Note that tabs and spaces are both treated as whitespace, but they
  /// are not equal: the lines "  hello" and "\thello" are
  /// considered to have no common leading whitespace.
  ///
  /// Entirely blank lines are normalized to a newline character.
  ///
  /// ### python source
  /// ```py
  /// def dedent(text):
  ///     """Remove any common leading whitespace from every line in `text`.
  ///
  ///     This can be used to make triple-quoted strings line up with the left
  ///     edge of the display, while still presenting them in the source code
  ///     in indented form.
  ///
  ///     Note that tabs and spaces are both treated as whitespace, but they
  ///     are not equal: the lines "  hello" and "\\thello" are
  ///     considered to have no common leading whitespace.
  ///
  ///     Entirely blank lines are normalized to a newline character.
  ///     """
  ///     # Look for the longest leading string of spaces and tabs common to
  ///     # all lines.
  ///     margin = None
  ///     text = _whitespace_only_re.sub('', text)
  ///     indents = _leading_whitespace_re.findall(text)
  ///     for indent in indents:
  ///         if margin is None:
  ///             margin = indent
  ///
  ///         # Current line more deeply indented than previous winner:
  ///         # no change (previous winner is still on top).
  ///         elif indent.startswith(margin):
  ///             pass
  ///
  ///         # Current line consistent with and no deeper than previous winner:
  ///         # it's the new winner.
  ///         elif margin.startswith(indent):
  ///             margin = indent
  ///
  ///         # Find the largest common whitespace between current line and previous
  ///         # winner.
  ///         else:
  ///             for i, (x, y) in enumerate(zip(margin, indent)):
  ///                 if x != y:
  ///                     margin = margin[:i]
  ///                     break
  ///
  ///     # sanity check (testing/debugging only)
  ///     if 0 and margin:
  ///         for line in text.split("\n"):
  ///             assert not line or line.startswith(margin), \
  ///                    "line = %r, margin = %r" % (line, margin)
  ///
  ///     if margin:
  ///         text = re.sub(r'(?m)^' + margin, '', text)
  ///     return text
  /// ```
  Object? dedent({
    required Object? text,
  }) =>
      getFunction("dedent").call(
        <Object?>[
          text,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## fill
  ///
  /// ### python docstring
  ///
  /// Fill a single paragraph of text, returning a new string.
  ///
  /// Reformat the single paragraph in 'text' to fit in lines of no more
  /// than 'width' columns, and return a new string containing the entire
  /// wrapped paragraph.  As with wrap(), tabs are expanded and other
  /// whitespace characters converted to space.  See TextWrapper class for
  /// available keyword args to customize wrapping behaviour.
  ///
  /// ### python source
  /// ```py
  /// def fill(text, width=70, **kwargs):
  ///     """Fill a single paragraph of text, returning a new string.
  ///
  ///     Reformat the single paragraph in 'text' to fit in lines of no more
  ///     than 'width' columns, and return a new string containing the entire
  ///     wrapped paragraph.  As with wrap(), tabs are expanded and other
  ///     whitespace characters converted to space.  See TextWrapper class for
  ///     available keyword args to customize wrapping behaviour.
  ///     """
  ///     w = TextWrapper(width=width, **kwargs)
  ///     return w.fill(text)
  /// ```
  Object? fill({
    required Object? text,
    Object? width = 70,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("fill").call(
        <Object?>[
          text,
          width,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## indent
  ///
  /// ### python docstring
  ///
  /// Adds 'prefix' to the beginning of selected lines in 'text'.
  ///
  /// If 'predicate' is provided, 'prefix' will only be added to the lines
  /// where 'predicate(line)' is True. If 'predicate' is not provided,
  /// it will default to adding 'prefix' to all non-empty lines that do not
  /// consist solely of whitespace characters.
  ///
  /// ### python source
  /// ```py
  /// def indent(text, prefix, predicate=None):
  ///     """Adds 'prefix' to the beginning of selected lines in 'text'.
  ///
  ///     If 'predicate' is provided, 'prefix' will only be added to the lines
  ///     where 'predicate(line)' is True. If 'predicate' is not provided,
  ///     it will default to adding 'prefix' to all non-empty lines that do not
  ///     consist solely of whitespace characters.
  ///     """
  ///     if predicate is None:
  ///         def predicate(line):
  ///             return line.strip()
  ///
  ///     def prefixed_lines():
  ///         for line in text.splitlines(True):
  ///             yield (prefix + line if predicate(line) else line)
  ///     return ''.join(prefixed_lines())
  /// ```
  Object? indent({
    required Object? text,
    required Object? prefix,
    Object? predicate,
  }) =>
      getFunction("indent").call(
        <Object?>[
          text,
          prefix,
          predicate,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## shorten
  ///
  /// ### python docstring
  ///
  /// Collapse and truncate the given text to fit in the given width.
  ///
  /// The text first has its whitespace collapsed.  If it then fits in
  /// the *width*, it is returned as is.  Otherwise, as many words
  /// as possible are joined and then the placeholder is appended::
  ///
  ///     >>> textwrap.shorten("Hello  world!", width=12)
  ///     'Hello world!'
  ///     >>> textwrap.shorten("Hello  world!", width=11)
  ///     'Hello [...]'
  ///
  /// ### python source
  /// ```py
  /// def shorten(text, width, **kwargs):
  ///     """Collapse and truncate the given text to fit in the given width.
  ///
  ///     The text first has its whitespace collapsed.  If it then fits in
  ///     the *width*, it is returned as is.  Otherwise, as many words
  ///     as possible are joined and then the placeholder is appended::
  ///
  ///         >>> textwrap.shorten("Hello  world!", width=12)
  ///         'Hello world!'
  ///         >>> textwrap.shorten("Hello  world!", width=11)
  ///         'Hello [...]'
  ///     """
  ///     w = TextWrapper(width=width, max_lines=1, **kwargs)
  ///     return w.fill(' '.join(text.strip().split()))
  /// ```
  Object? shorten({
    required Object? text,
    required Object? width,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("shorten").call(
        <Object?>[
          text,
          width,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );

  /// ## wrap
  ///
  /// ### python docstring
  ///
  /// Wrap a single paragraph of text, returning a list of wrapped lines.
  ///
  /// Reformat the single paragraph in 'text' so it fits in lines of no
  /// more than 'width' columns, and return a list of wrapped lines.  By
  /// default, tabs in 'text' are expanded with string.expandtabs(), and
  /// all other whitespace characters (including newline) are converted to
  /// space.  See TextWrapper class for available keyword args to customize
  /// wrapping behaviour.
  ///
  /// ### python source
  /// ```py
  /// def wrap(text, width=70, **kwargs):
  ///     """Wrap a single paragraph of text, returning a list of wrapped lines.
  ///
  ///     Reformat the single paragraph in 'text' so it fits in lines of no
  ///     more than 'width' columns, and return a list of wrapped lines.  By
  ///     default, tabs in 'text' are expanded with string.expandtabs(), and
  ///     all other whitespace characters (including newline) are converted to
  ///     space.  See TextWrapper class for available keyword args to customize
  ///     wrapping behaviour.
  ///     """
  ///     w = TextWrapper(width=width, **kwargs)
  ///     return w.wrap(text)
  /// ```
  Object? wrap({
    required Object? text,
    Object? width = 70,
    Map<String, Object?> kwargs = const <String, Object?>{},
  }) =>
      getFunction("wrap").call(
        <Object?>[
          text,
          width,
        ],
        kwargs: <String, Object?>{
          ...kwargs,
        },
      );
}

/// ## weakref
///
/// ### python docstring
///
/// Weak reference support for Python.
///
/// This module is an implementation of PEP 205:
///
/// https://peps.python.org/pep-0205/
///
/// ### python source
/// ```py
/// """Weak reference support for Python.
///
/// This module is an implementation of PEP 205:
///
/// https://peps.python.org/pep-0205/
/// """
///
/// # Naming convention: Variables named "wr" are weak reference objects;
/// # they are called this instead of "ref" to avoid name collisions with
/// # the module-global ref() function imported from _weakref.
///
/// from _weakref import (
///      getweakrefcount,
///      getweakrefs,
///      ref,
///      proxy,
///      CallableProxyType,
///      ProxyType,
///      ReferenceType,
///      _remove_dead_weakref)
///
/// from _weakrefset import WeakSet, _IterationGuard
///
/// import _collections_abc  # Import after _weakref to avoid circular import.
/// import sys
/// import itertools
///
/// ProxyTypes = (ProxyType, CallableProxyType)
///
/// __all__ = ["ref", "proxy", "getweakrefcount", "getweakrefs",
///            "WeakKeyDictionary", "ReferenceType", "ProxyType",
///            "CallableProxyType", "ProxyTypes", "WeakValueDictionary",
///            "WeakSet", "WeakMethod", "finalize"]
///
///
/// _collections_abc.MutableSet.register(WeakSet)
///
/// class WeakMethod(ref):
///     """
///     A custom `weakref.ref` subclass which simulates a weak reference to
///     a bound method, working around the lifetime problem of bound methods.
///     """
///
///     __slots__ = "_func_ref", "_meth_type", "_alive", "__weakref__"
///
///     def __new__(cls, meth, callback=None):
///         try:
///             obj = meth.__self__
///             func = meth.__func__
///         except AttributeError:
///             raise TypeError("argument should be a bound method, not {}"
///                             .format(type(meth))) from None
///         def _cb(arg):
///             # The self-weakref trick is needed to avoid creating a reference
///             # cycle.
///             self = self_wr()
///             if self._alive:
///                 self._alive = False
///                 if callback is not None:
///                     callback(self)
///         self = ref.__new__(cls, obj, _cb)
///         self._func_ref = ref(func, _cb)
///         self._meth_type = type(meth)
///         self._alive = True
///         self_wr = ref(self)
///         return self
///
///     def __call__(self):
///         obj = super().__call__()
///         func = self._func_ref()
///         if obj is None or func is None:
///             return None
///         return self._meth_type(func, obj)
///
///     def __eq__(self, other):
///         if isinstance(other, WeakMethod):
///             if not self._alive or not other._alive:
///                 return self is other
///             return ref.__eq__(self, other) and self._func_ref == other._func_ref
///         return NotImplemented
///
///     def __ne__(self, other):
///         if isinstance(other, WeakMethod):
///             if not self._alive or not other._alive:
///                 return self is not other
///             return ref.__ne__(self, other) or self._func_ref != other._func_ref
///         return NotImplemented
///
///     __hash__ = ref.__hash__
///
///
/// class WeakValueDictionary(_collections_abc.MutableMapping):
///     """Mapping class that references values weakly.
///
///     Entries in the dictionary will be discarded when no strong
///     reference to the value exists anymore
///     """
///     # We inherit the constructor without worrying about the input
///     # dictionary; since it uses our .update() method, we get the right
///     # checks (if the other dictionary is a WeakValueDictionary,
///     # objects are unwrapped on the way out, and we always wrap on the
///     # way in).
///
///     def __init__(self, other=(), /, **kw):
///         def remove(wr, selfref=ref(self), _atomic_removal=_remove_dead_weakref):
///             self = selfref()
///             if self is not None:
///                 if self._iterating:
///                     self._pending_removals.append(wr.key)
///                 else:
///                     # Atomic removal is necessary since this function
///                     # can be called asynchronously by the GC
///                     _atomic_removal(self.data, wr.key)
///         self._remove = remove
///         # A list of keys to be removed
///         self._pending_removals = []
///         self._iterating = set()
///         self.data = {}
///         self.update(other, **kw)
///
///     def _commit_removals(self, _atomic_removal=_remove_dead_weakref):
///         pop = self._pending_removals.pop
///         d = self.data
///         # We shouldn't encounter any KeyError, because this method should
///         # always be called *before* mutating the dict.
///         while True:
///             try:
///                 key = pop()
///             except IndexError:
///                 return
///             _atomic_removal(d, key)
///
///     def __getitem__(self, key):
///         if self._pending_removals:
///             self._commit_removals()
///         o = self.data[key]()
///         if o is None:
///             raise KeyError(key)
///         else:
///             return o
///
///     def __delitem__(self, key):
///         if self._pending_removals:
///             self._commit_removals()
///         del self.data[key]
///
///     def __len__(self):
///         if self._pending_removals:
///             self._commit_removals()
///         return len(self.data)
///
///     def __contains__(self, key):
///         if self._pending_removals:
///             self._commit_removals()
///         try:
///             o = self.data[key]()
///         except KeyError:
///             return False
///         return o is not None
///
///     def __repr__(self):
///         return "<%s at %#x>" % (self.__class__.__name__, id(self))
///
///     def __setitem__(self, key, value):
///         if self._pending_removals:
///             self._commit_removals()
///         self.data[key] = KeyedRef(value, self._remove, key)
///
///     def copy(self):
///         if self._pending_removals:
///             self._commit_removals()
///         new = WeakValueDictionary()
///         with _IterationGuard(self):
///             for key, wr in self.data.items():
///                 o = wr()
///                 if o is not None:
///                     new[key] = o
///         return new
///
///     __copy__ = copy
///
///     def __deepcopy__(self, memo):
///         from copy import deepcopy
///         if self._pending_removals:
///             self._commit_removals()
///         new = self.__class__()
///         with _IterationGuard(self):
///             for key, wr in self.data.items():
///                 o = wr()
///                 if o is not None:
///                     new[deepcopy(key, memo)] = o
///         return new
///
///     def get(self, key, default=None):
///         if self._pending_removals:
///             self._commit_removals()
///         try:
///             wr = self.data[key]
///         except KeyError:
///             return default
///         else:
///             o = wr()
///             if o is None:
///                 # This should only happen
///                 return default
///             else:
///                 return o
///
///     def items(self):
///         if self._pending_removals:
///             self._commit_removals()
///         with _IterationGuard(self):
///             for k, wr in self.data.items():
///                 v = wr()
///                 if v is not None:
///                     yield k, v
///
///     def keys(self):
///         if self._pending_removals:
///             self._commit_removals()
///         with _IterationGuard(self):
///             for k, wr in self.data.items():
///                 if wr() is not None:
///                     yield k
///
///     __iter__ = keys
///
///     def itervaluerefs(self):
///         """Return an iterator that yields the weak references to the values.
///
///         The references are not guaranteed to be 'live' at the time
///         they are used, so the result of calling the references needs
///         to be checked before being used.  This can be used to avoid
///         creating references that will cause the garbage collector to
///         keep the values around longer than needed.
///
///         """
///         if self._pending_removals:
///             self._commit_removals()
///         with _IterationGuard(self):
///             yield from self.data.values()
///
///     def values(self):
///         if self._pending_removals:
///             self._commit_removals()
///         with _IterationGuard(self):
///             for wr in self.data.values():
///                 obj = wr()
///                 if obj is not None:
///                     yield obj
///
///     def popitem(self):
///         if self._pending_removals:
///             self._commit_removals()
///         while True:
///             key, wr = self.data.popitem()
///             o = wr()
///             if o is not None:
///                 return key, o
///
///     def pop(self, key, *args):
///         if self._pending_removals:
///             self._commit_removals()
///         try:
///             o = self.data.pop(key)()
///         except KeyError:
///             o = None
///         if o is None:
///             if args:
///                 return args[0]
///             else:
///                 raise KeyError(key)
///         else:
///             return o
///
///     def setdefault(self, key, default=None):
///         try:
///             o = self.data[key]()
///         except KeyError:
///             o = None
///         if o is None:
///             if self._pending_removals:
///                 self._commit_removals()
///             self.data[key] = KeyedRef(default, self._remove, key)
///             return default
///         else:
///             return o
///
///     def update(self, other=None, /, **kwargs):
///         if self._pending_removals:
///             self._commit_removals()
///         d = self.data
///         if other is not None:
///             if not hasattr(other, "items"):
///                 other = dict(other)
///             for key, o in other.items():
///                 d[key] = KeyedRef(o, self._remove, key)
///         for key, o in kwargs.items():
///             d[key] = KeyedRef(o, self._remove, key)
///
///     def valuerefs(self):
///         """Return a list of weak references to the values.
///
///         The references are not guaranteed to be 'live' at the time
///         they are used, so the result of calling the references needs
///         to be checked before being used.  This can be used to avoid
///         creating references that will cause the garbage collector to
///         keep the values around longer than needed.
///
///         """
///         if self._pending_removals:
///             self._commit_removals()
///         return list(self.data.values())
///
///     def __ior__(self, other):
///         self.update(other)
///         return self
///
///     def __or__(self, other):
///         if isinstance(other, _collections_abc.Mapping):
///             c = self.copy()
///             c.update(other)
///             return c
///         return NotImplemented
///
///     def __ror__(self, other):
///         if isinstance(other, _collections_abc.Mapping):
///             c = self.__class__()
///             c.update(other)
///             c.update(self)
///             return c
///         return NotImplemented
///
///
/// class KeyedRef(ref):
///     """Specialized reference that includes a key corresponding to the value.
///
///     This is used in the WeakValueDictionary to avoid having to create
///     a function object for each key stored in the mapping.  A shared
///     callback object can use the 'key' attribute of a KeyedRef instead
///     of getting a reference to the key from an enclosing scope.
///
///     """
///
///     __slots__ = "key",
///
///     def __new__(type, ob, callback, key):
///         self = ref.__new__(type, ob, callback)
///         self.key = key
///         return self
///
///     def __init__(self, ob, callback, key):
///         super().__init__(ob, callback)
///
///
/// class WeakKeyDictionary(_collections_abc.MutableMapping):
///     """ Mapping class that references keys weakly.
///
///     Entries in the dictionary will be discarded when there is no
///     longer a strong reference to the key. This can be used to
///     associate additional data with an object owned by other parts of
///     an application without adding attributes to those objects. This
///     can be especially useful with objects that override attribute
///     accesses.
///     """
///
///     def __init__(self, dict=None):
///         self.data = {}
///         def remove(k, selfref=ref(self)):
///             self = selfref()
///             if self is not None:
///                 if self._iterating:
///                     self._pending_removals.append(k)
///                 else:
///                     try:
///                         del self.data[k]
///                     except KeyError:
///                         pass
///         self._remove = remove
///         # A list of dead weakrefs (keys to be removed)
///         self._pending_removals = []
///         self._iterating = set()
///         self._dirty_len = False
///         if dict is not None:
///             self.update(dict)
///
///     def _commit_removals(self):
///         # NOTE: We don't need to call this method before mutating the dict,
///         # because a dead weakref never compares equal to a live weakref,
///         # even if they happened to refer to equal objects.
///         # However, it means keys may already have been removed.
///         pop = self._pending_removals.pop
///         d = self.data
///         while True:
///             try:
///                 key = pop()
///             except IndexError:
///                 return
///
///             try:
///                 del d[key]
///             except KeyError:
///                 pass
///
///     def _scrub_removals(self):
///         d = self.data
///         self._pending_removals = [k for k in self._pending_removals if k in d]
///         self._dirty_len = False
///
///     def __delitem__(self, key):
///         self._dirty_len = True
///         del self.data[ref(key)]
///
///     def __getitem__(self, key):
///         return self.data[ref(key)]
///
///     def __len__(self):
///         if self._dirty_len and self._pending_removals:
///             # self._pending_removals may still contain keys which were
///             # explicitly removed, we have to scrub them (see issue #21173).
///             self._scrub_removals()
///         return len(self.data) - len(self._pending_removals)
///
///     def __repr__(self):
///         return "<%s at %#x>" % (self.__class__.__name__, id(self))
///
///     def __setitem__(self, key, value):
///         self.data[ref(key, self._remove)] = value
///
///     def copy(self):
///         new = WeakKeyDictionary()
///         with _IterationGuard(self):
///             for key, value in self.data.items():
///                 o = key()
///                 if o is not None:
///                     new[o] = value
///         return new
///
///     __copy__ = copy
///
///     def __deepcopy__(self, memo):
///         from copy import deepcopy
///         new = self.__class__()
///         with _IterationGuard(self):
///             for key, value in self.data.items():
///                 o = key()
///                 if o is not None:
///                     new[o] = deepcopy(value, memo)
///         return new
///
///     def get(self, key, default=None):
///         return self.data.get(ref(key),default)
///
///     def __contains__(self, key):
///         try:
///             wr = ref(key)
///         except TypeError:
///             return False
///         return wr in self.data
///
///     def items(self):
///         with _IterationGuard(self):
///             for wr, value in self.data.items():
///                 key = wr()
///                 if key is not None:
///                     yield key, value
///
///     def keys(self):
///         with _IterationGuard(self):
///             for wr in self.data:
///                 obj = wr()
///                 if obj is not None:
///                     yield obj
///
///     __iter__ = keys
///
///     def values(self):
///         with _IterationGuard(self):
///             for wr, value in self.data.items():
///                 if wr() is not None:
///                     yield value
///
///     def keyrefs(self):
///         """Return a list of weak references to the keys.
///
///         The references are not guaranteed to be 'live' at the time
///         they are used, so the result of calling the references needs
///         to be checked before being used.  This can be used to avoid
///         creating references that will cause the garbage collector to
///         keep the keys around longer than needed.
///
///         """
///         return list(self.data)
///
///     def popitem(self):
///         self._dirty_len = True
///         while True:
///             key, value = self.data.popitem()
///             o = key()
///             if o is not None:
///                 return o, value
///
///     def pop(self, key, *args):
///         self._dirty_len = True
///         return self.data.pop(ref(key), *args)
///
///     def setdefault(self, key, default=None):
///         return self.data.setdefault(ref(key, self._remove),default)
///
///     def update(self, dict=None, /, **kwargs):
///         d = self.data
///         if dict is not None:
///             if not hasattr(dict, "items"):
///                 dict = type({})(dict)
///             for key, value in dict.items():
///                 d[ref(key, self._remove)] = value
///         if len(kwargs):
///             self.update(kwargs)
///
///     def __ior__(self, other):
///         self.update(other)
///         return self
///
///     def __or__(self, other):
///         if isinstance(other, _collections_abc.Mapping):
///             c = self.copy()
///             c.update(other)
///             return c
///         return NotImplemented
///
///     def __ror__(self, other):
///         if isinstance(other, _collections_abc.Mapping):
///             c = self.__class__()
///             c.update(other)
///             c.update(self)
///             return c
///         return NotImplemented
///
///
/// class finalize:
///     """Class for finalization of weakrefable objects
///
///     finalize(obj, func, *args, **kwargs) returns a callable finalizer
///     object which will be called when obj is garbage collected. The
///     first time the finalizer is called it evaluates func(*arg, **kwargs)
///     and returns the result. After this the finalizer is dead, and
///     calling it just returns None.
///
///     When the program exits any remaining finalizers for which the
///     atexit attribute is true will be run in reverse order of creation.
///     By default atexit is true.
///     """
///
///     # Finalizer objects don't have any state of their own.  They are
///     # just used as keys to lookup _Info objects in the registry.  This
///     # ensures that they cannot be part of a ref-cycle.
///
///     __slots__ = ()
///     _registry = {}
///     _shutdown = False
///     _index_iter = itertools.count()
///     _dirty = False
///     _registered_with_atexit = False
///
///     class _Info:
///         __slots__ = ("weakref", "func", "args", "kwargs", "atexit", "index")
///
///     def __init__(self, obj, func, /, *args, **kwargs):
///         if not self._registered_with_atexit:
///             # We may register the exit function more than once because
///             # of a thread race, but that is harmless
///             import atexit
///             atexit.register(self._exitfunc)
///             finalize._registered_with_atexit = True
///         info = self._Info()
///         info.weakref = ref(obj, self)
///         info.func = func
///         info.args = args
///         info.kwargs = kwargs or None
///         info.atexit = True
///         info.index = next(self._index_iter)
///         self._registry[self] = info
///         finalize._dirty = True
///
///     def __call__(self, _=None):
///         """If alive then mark as dead and return func(*args, **kwargs);
///         otherwise return None"""
///         info = self._registry.pop(self, None)
///         if info and not self._shutdown:
///             return info.func(*info.args, **(info.kwargs or {}))
///
///     def detach(self):
///         """If alive then mark as dead and return (obj, func, args, kwargs);
///         otherwise return None"""
///         info = self._registry.get(self)
///         obj = info and info.weakref()
///         if obj is not None and self._registry.pop(self, None):
///             return (obj, info.func, info.args, info.kwargs or {})
///
///     def peek(self):
///         """If alive then return (obj, func, args, kwargs);
///         otherwise return None"""
///         info = self._registry.get(self)
///         obj = info and info.weakref()
///         if obj is not None:
///             return (obj, info.func, info.args, info.kwargs or {})
///
///     @property
///     def alive(self):
///         """Whether finalizer is alive"""
///         return self in self._registry
///
///     @property
///     def atexit(self):
///         """Whether finalizer should be called at exit"""
///         info = self._registry.get(self)
///         return bool(info) and info.atexit
///
///     @atexit.setter
///     def atexit(self, value):
///         info = self._registry.get(self)
///         if info:
///             info.atexit = bool(value)
///
///     def __repr__(self):
///         info = self._registry.get(self)
///         obj = info and info.weakref()
///         if obj is None:
///             return '<%s object at %#x; dead>' % (type(self).__name__, id(self))
///         else:
///             return '<%s object at %#x; for %r at %#x>' % \
///                 (type(self).__name__, id(self), type(obj).__name__, id(obj))
///
///     @classmethod
///     def _select_for_exit(cls):
///         # Return live finalizers marked for exit, oldest first
///         L = [(f,i) for (f,i) in cls._registry.items() if i.atexit]
///         L.sort(key=lambda item:item[1].index)
///         return [f for (f,i) in L]
///
///     @classmethod
///     def _exitfunc(cls):
///         # At shutdown invoke finalizers for which atexit is true.
///         # This is called once all other non-daemonic threads have been
///         # joined.
///         reenable_gc = False
///         try:
///             if cls._registry:
///                 import gc
///                 if gc.isenabled():
///                     reenable_gc = True
///                     gc.disable()
///                 pending = None
///                 while True:
///                     if pending is None or finalize._dirty:
///                         pending = cls._select_for_exit()
///                         finalize._dirty = False
///                     if not pending:
///                         break
///                     f = pending.pop()
///                     try:
///                         # gc is disabled, so (assuming no daemonic
///                         # threads) the following is the only line in
///                         # this function which might trigger creation
///                         # of a new finalizer
///                         f()
///                     except Exception:
///                         sys.excepthook(*sys.exc_info())
///                     assert f not in cls._registry
///         finally:
///             # prevent any more finalizers from executing during shutdown
///             finalize._shutdown = True
///             if reenable_gc:
///                 gc.enable()
/// ```
final class weakref extends PythonModule {
  weakref.from(super.pythonModule) : super.from();

  static weakref import() => PythonFfiDart.instance.importModule(
        "weakref",
        weakref.from,
      );

  /// ## ProxyTypes (getter)
  Object? get ProxyTypes => getAttribute("ProxyTypes");

  /// ## ProxyTypes (setter)
  set ProxyTypes(Object? ProxyTypes) => setAttribute("ProxyTypes", ProxyTypes);
}

/// ## sre_constants
///
/// ### python docstring
///
/// Internal support module for sre
///
/// ### python source
/// ```py
/// #
/// # Secret Labs' Regular Expression Engine
/// #
/// # various symbols used by the regular expression engine.
/// # run this script to update the _sre include files!
/// #
/// # Copyright (c) 1998-2001 by Secret Labs AB.  All rights reserved.
/// #
/// # See the __init__.py file for information on usage and redistribution.
/// #
///
/// """Internal support module for sre"""
///
/// # update when constants are added or removed
///
/// MAGIC = 20220615
///
/// from _sre import MAXREPEAT, MAXGROUPS
///
/// # SRE standard exception (access as sre.error)
/// # should this really be here?
///
/// class error(Exception):
///     """Exception raised for invalid regular expressions.
///
///     Attributes:
///
///         msg: The unformatted error message
///         pattern: The regular expression pattern
///         pos: The index in the pattern where compilation failed (may be None)
///         lineno: The line corresponding to pos (may be None)
///         colno: The column corresponding to pos (may be None)
///     """
///
///     __module__ = 're'
///
///     def __init__(self, msg, pattern=None, pos=None):
///         self.msg = msg
///         self.pattern = pattern
///         self.pos = pos
///         if pattern is not None and pos is not None:
///             msg = '%s at position %d' % (msg, pos)
///             if isinstance(pattern, str):
///                 newline = '\n'
///             else:
///                 newline = b'\n'
///             self.lineno = pattern.count(newline, 0, pos) + 1
///             self.colno = pos - pattern.rfind(newline, 0, pos)
///             if newline in pattern:
///                 msg = '%s (line %d, column %d)' % (msg, self.lineno, self.colno)
///         else:
///             self.lineno = self.colno = None
///         super().__init__(msg)
///
///
/// class _NamedIntConstant(int):
///     def __new__(cls, value, name):
///         self = super(_NamedIntConstant, cls).__new__(cls, value)
///         self.name = name
///         return self
///
///     def __repr__(self):
///         return self.name
///
///     __reduce__ = None
///
/// MAXREPEAT = _NamedIntConstant(MAXREPEAT, 'MAXREPEAT')
///
/// def _makecodes(*names):
///     items = [_NamedIntConstant(i, name) for i, name in enumerate(names)]
///     globals().update({item.name: item for item in items})
///     return items
///
/// # operators
/// OPCODES = _makecodes(
///     # failure=0 success=1 (just because it looks better that way :-)
///     'FAILURE', 'SUCCESS',
///
///     'ANY', 'ANY_ALL',
///     'ASSERT', 'ASSERT_NOT',
///     'AT',
///     'BRANCH',
///     'CATEGORY',
///     'CHARSET', 'BIGCHARSET',
///     'GROUPREF', 'GROUPREF_EXISTS',
///     'IN',
///     'INFO',
///     'JUMP',
///     'LITERAL',
///     'MARK',
///     'MAX_UNTIL',
///     'MIN_UNTIL',
///     'NOT_LITERAL',
///     'NEGATE',
///     'RANGE',
///     'REPEAT',
///     'REPEAT_ONE',
///     'SUBPATTERN',
///     'MIN_REPEAT_ONE',
///     'ATOMIC_GROUP',
///     'POSSESSIVE_REPEAT',
///     'POSSESSIVE_REPEAT_ONE',
///
///     'GROUPREF_IGNORE',
///     'IN_IGNORE',
///     'LITERAL_IGNORE',
///     'NOT_LITERAL_IGNORE',
///
///     'GROUPREF_LOC_IGNORE',
///     'IN_LOC_IGNORE',
///     'LITERAL_LOC_IGNORE',
///     'NOT_LITERAL_LOC_IGNORE',
///
///     'GROUPREF_UNI_IGNORE',
///     'IN_UNI_IGNORE',
///     'LITERAL_UNI_IGNORE',
///     'NOT_LITERAL_UNI_IGNORE',
///     'RANGE_UNI_IGNORE',
///
///     # The following opcodes are only occurred in the parser output,
///     # but not in the compiled code.
///     'MIN_REPEAT', 'MAX_REPEAT',
/// )
/// del OPCODES[-2:] # remove MIN_REPEAT and MAX_REPEAT
///
/// # positions
/// ATCODES = _makecodes(
///     'AT_BEGINNING', 'AT_BEGINNING_LINE', 'AT_BEGINNING_STRING',
///     'AT_BOUNDARY', 'AT_NON_BOUNDARY',
///     'AT_END', 'AT_END_LINE', 'AT_END_STRING',
///
///     'AT_LOC_BOUNDARY', 'AT_LOC_NON_BOUNDARY',
///
///     'AT_UNI_BOUNDARY', 'AT_UNI_NON_BOUNDARY',
/// )
///
/// # categories
/// CHCODES = _makecodes(
///     'CATEGORY_DIGIT', 'CATEGORY_NOT_DIGIT',
///     'CATEGORY_SPACE', 'CATEGORY_NOT_SPACE',
///     'CATEGORY_WORD', 'CATEGORY_NOT_WORD',
///     'CATEGORY_LINEBREAK', 'CATEGORY_NOT_LINEBREAK',
///
///     'CATEGORY_LOC_WORD', 'CATEGORY_LOC_NOT_WORD',
///
///     'CATEGORY_UNI_DIGIT', 'CATEGORY_UNI_NOT_DIGIT',
///     'CATEGORY_UNI_SPACE', 'CATEGORY_UNI_NOT_SPACE',
///     'CATEGORY_UNI_WORD', 'CATEGORY_UNI_NOT_WORD',
///     'CATEGORY_UNI_LINEBREAK', 'CATEGORY_UNI_NOT_LINEBREAK',
/// )
///
///
/// # replacement operations for "ignore case" mode
/// OP_IGNORE = {
///     LITERAL: LITERAL_IGNORE,
///     NOT_LITERAL: NOT_LITERAL_IGNORE,
/// }
///
/// OP_LOCALE_IGNORE = {
///     LITERAL: LITERAL_LOC_IGNORE,
///     NOT_LITERAL: NOT_LITERAL_LOC_IGNORE,
/// }
///
/// OP_UNICODE_IGNORE = {
///     LITERAL: LITERAL_UNI_IGNORE,
///     NOT_LITERAL: NOT_LITERAL_UNI_IGNORE,
/// }
///
/// AT_MULTILINE = {
///     AT_BEGINNING: AT_BEGINNING_LINE,
///     AT_END: AT_END_LINE
/// }
///
/// AT_LOCALE = {
///     AT_BOUNDARY: AT_LOC_BOUNDARY,
///     AT_NON_BOUNDARY: AT_LOC_NON_BOUNDARY
/// }
///
/// AT_UNICODE = {
///     AT_BOUNDARY: AT_UNI_BOUNDARY,
///     AT_NON_BOUNDARY: AT_UNI_NON_BOUNDARY
/// }
///
/// CH_LOCALE = {
///     CATEGORY_DIGIT: CATEGORY_DIGIT,
///     CATEGORY_NOT_DIGIT: CATEGORY_NOT_DIGIT,
///     CATEGORY_SPACE: CATEGORY_SPACE,
///     CATEGORY_NOT_SPACE: CATEGORY_NOT_SPACE,
///     CATEGORY_WORD: CATEGORY_LOC_WORD,
///     CATEGORY_NOT_WORD: CATEGORY_LOC_NOT_WORD,
///     CATEGORY_LINEBREAK: CATEGORY_LINEBREAK,
///     CATEGORY_NOT_LINEBREAK: CATEGORY_NOT_LINEBREAK
/// }
///
/// CH_UNICODE = {
///     CATEGORY_DIGIT: CATEGORY_UNI_DIGIT,
///     CATEGORY_NOT_DIGIT: CATEGORY_UNI_NOT_DIGIT,
///     CATEGORY_SPACE: CATEGORY_UNI_SPACE,
///     CATEGORY_NOT_SPACE: CATEGORY_UNI_NOT_SPACE,
///     CATEGORY_WORD: CATEGORY_UNI_WORD,
///     CATEGORY_NOT_WORD: CATEGORY_UNI_NOT_WORD,
///     CATEGORY_LINEBREAK: CATEGORY_UNI_LINEBREAK,
///     CATEGORY_NOT_LINEBREAK: CATEGORY_UNI_NOT_LINEBREAK
/// }
///
/// # flags
/// SRE_FLAG_TEMPLATE = 1 # template mode (unknown purpose, deprecated)
/// SRE_FLAG_IGNORECASE = 2 # case insensitive
/// SRE_FLAG_LOCALE = 4 # honour system locale
/// SRE_FLAG_MULTILINE = 8 # treat target as multiline string
/// SRE_FLAG_DOTALL = 16 # treat target as a single string
/// SRE_FLAG_UNICODE = 32 # use unicode "locale"
/// SRE_FLAG_VERBOSE = 64 # ignore whitespace and comments
/// SRE_FLAG_DEBUG = 128 # debugging
/// SRE_FLAG_ASCII = 256 # use ascii "locale"
///
/// # flags for INFO primitive
/// SRE_INFO_PREFIX = 1 # has prefix
/// SRE_INFO_LITERAL = 2 # entire pattern is literal (given by prefix)
/// SRE_INFO_CHARSET = 4 # pattern starts with character from given set
/// ```
final class sre_constants extends PythonModule {
  sre_constants.from(super.pythonModule) : super.from();

  static sre_constants import() => PythonFfiDart.instance.importModule(
        "re._constants",
        sre_constants.from,
      );

  /// ## ANY (getter)
  Object? get ANY => getAttribute("ANY");

  /// ## ANY (setter)
  set ANY(Object? ANY) => setAttribute("ANY", ANY);

  /// ## ANY_ALL (getter)
  Object? get ANY_ALL => getAttribute("ANY_ALL");

  /// ## ANY_ALL (setter)
  set ANY_ALL(Object? ANY_ALL) => setAttribute("ANY_ALL", ANY_ALL);

  /// ## ASSERT (getter)
  Object? get ASSERT => getAttribute("ASSERT");

  /// ## ASSERT (setter)
  set ASSERT(Object? ASSERT) => setAttribute("ASSERT", ASSERT);

  /// ## ASSERT_NOT (getter)
  Object? get ASSERT_NOT => getAttribute("ASSERT_NOT");

  /// ## ASSERT_NOT (setter)
  set ASSERT_NOT(Object? ASSERT_NOT) => setAttribute("ASSERT_NOT", ASSERT_NOT);

  /// ## AT (getter)
  Object? get AT => getAttribute("AT");

  /// ## AT (setter)
  set AT(Object? AT) => setAttribute("AT", AT);

  /// ## ATCODES (getter)
  Object? get ATCODES => getAttribute("ATCODES");

  /// ## ATCODES (setter)
  set ATCODES(Object? ATCODES) => setAttribute("ATCODES", ATCODES);

  /// ## ATOMIC_GROUP (getter)
  Object? get ATOMIC_GROUP => getAttribute("ATOMIC_GROUP");

  /// ## ATOMIC_GROUP (setter)
  set ATOMIC_GROUP(Object? ATOMIC_GROUP) =>
      setAttribute("ATOMIC_GROUP", ATOMIC_GROUP);

  /// ## AT_BEGINNING (getter)
  Object? get AT_BEGINNING => getAttribute("AT_BEGINNING");

  /// ## AT_BEGINNING (setter)
  set AT_BEGINNING(Object? AT_BEGINNING) =>
      setAttribute("AT_BEGINNING", AT_BEGINNING);

  /// ## AT_BEGINNING_LINE (getter)
  Object? get AT_BEGINNING_LINE => getAttribute("AT_BEGINNING_LINE");

  /// ## AT_BEGINNING_LINE (setter)
  set AT_BEGINNING_LINE(Object? AT_BEGINNING_LINE) =>
      setAttribute("AT_BEGINNING_LINE", AT_BEGINNING_LINE);

  /// ## AT_BEGINNING_STRING (getter)
  Object? get AT_BEGINNING_STRING => getAttribute("AT_BEGINNING_STRING");

  /// ## AT_BEGINNING_STRING (setter)
  set AT_BEGINNING_STRING(Object? AT_BEGINNING_STRING) =>
      setAttribute("AT_BEGINNING_STRING", AT_BEGINNING_STRING);

  /// ## AT_BOUNDARY (getter)
  Object? get AT_BOUNDARY => getAttribute("AT_BOUNDARY");

  /// ## AT_BOUNDARY (setter)
  set AT_BOUNDARY(Object? AT_BOUNDARY) =>
      setAttribute("AT_BOUNDARY", AT_BOUNDARY);

  /// ## AT_END (getter)
  Object? get AT_END => getAttribute("AT_END");

  /// ## AT_END (setter)
  set AT_END(Object? AT_END) => setAttribute("AT_END", AT_END);

  /// ## AT_END_LINE (getter)
  Object? get AT_END_LINE => getAttribute("AT_END_LINE");

  /// ## AT_END_LINE (setter)
  set AT_END_LINE(Object? AT_END_LINE) =>
      setAttribute("AT_END_LINE", AT_END_LINE);

  /// ## AT_END_STRING (getter)
  Object? get AT_END_STRING => getAttribute("AT_END_STRING");

  /// ## AT_END_STRING (setter)
  set AT_END_STRING(Object? AT_END_STRING) =>
      setAttribute("AT_END_STRING", AT_END_STRING);

  /// ## AT_LOCALE (getter)
  Object? get AT_LOCALE => getAttribute("AT_LOCALE");

  /// ## AT_LOCALE (setter)
  set AT_LOCALE(Object? AT_LOCALE) => setAttribute("AT_LOCALE", AT_LOCALE);

  /// ## AT_LOC_BOUNDARY (getter)
  Object? get AT_LOC_BOUNDARY => getAttribute("AT_LOC_BOUNDARY");

  /// ## AT_LOC_BOUNDARY (setter)
  set AT_LOC_BOUNDARY(Object? AT_LOC_BOUNDARY) =>
      setAttribute("AT_LOC_BOUNDARY", AT_LOC_BOUNDARY);

  /// ## AT_LOC_NON_BOUNDARY (getter)
  Object? get AT_LOC_NON_BOUNDARY => getAttribute("AT_LOC_NON_BOUNDARY");

  /// ## AT_LOC_NON_BOUNDARY (setter)
  set AT_LOC_NON_BOUNDARY(Object? AT_LOC_NON_BOUNDARY) =>
      setAttribute("AT_LOC_NON_BOUNDARY", AT_LOC_NON_BOUNDARY);

  /// ## AT_MULTILINE (getter)
  Object? get AT_MULTILINE => getAttribute("AT_MULTILINE");

  /// ## AT_MULTILINE (setter)
  set AT_MULTILINE(Object? AT_MULTILINE) =>
      setAttribute("AT_MULTILINE", AT_MULTILINE);

  /// ## AT_NON_BOUNDARY (getter)
  Object? get AT_NON_BOUNDARY => getAttribute("AT_NON_BOUNDARY");

  /// ## AT_NON_BOUNDARY (setter)
  set AT_NON_BOUNDARY(Object? AT_NON_BOUNDARY) =>
      setAttribute("AT_NON_BOUNDARY", AT_NON_BOUNDARY);

  /// ## AT_UNICODE (getter)
  Object? get AT_UNICODE => getAttribute("AT_UNICODE");

  /// ## AT_UNICODE (setter)
  set AT_UNICODE(Object? AT_UNICODE) => setAttribute("AT_UNICODE", AT_UNICODE);

  /// ## AT_UNI_BOUNDARY (getter)
  Object? get AT_UNI_BOUNDARY => getAttribute("AT_UNI_BOUNDARY");

  /// ## AT_UNI_BOUNDARY (setter)
  set AT_UNI_BOUNDARY(Object? AT_UNI_BOUNDARY) =>
      setAttribute("AT_UNI_BOUNDARY", AT_UNI_BOUNDARY);

  /// ## AT_UNI_NON_BOUNDARY (getter)
  Object? get AT_UNI_NON_BOUNDARY => getAttribute("AT_UNI_NON_BOUNDARY");

  /// ## AT_UNI_NON_BOUNDARY (setter)
  set AT_UNI_NON_BOUNDARY(Object? AT_UNI_NON_BOUNDARY) =>
      setAttribute("AT_UNI_NON_BOUNDARY", AT_UNI_NON_BOUNDARY);

  /// ## BIGCHARSET (getter)
  Object? get BIGCHARSET => getAttribute("BIGCHARSET");

  /// ## BIGCHARSET (setter)
  set BIGCHARSET(Object? BIGCHARSET) => setAttribute("BIGCHARSET", BIGCHARSET);

  /// ## BRANCH (getter)
  Object? get BRANCH => getAttribute("BRANCH");

  /// ## BRANCH (setter)
  set BRANCH(Object? BRANCH) => setAttribute("BRANCH", BRANCH);

  /// ## CATEGORY (getter)
  Object? get CATEGORY => getAttribute("CATEGORY");

  /// ## CATEGORY (setter)
  set CATEGORY(Object? CATEGORY) => setAttribute("CATEGORY", CATEGORY);

  /// ## CATEGORY_DIGIT (getter)
  Object? get CATEGORY_DIGIT => getAttribute("CATEGORY_DIGIT");

  /// ## CATEGORY_DIGIT (setter)
  set CATEGORY_DIGIT(Object? CATEGORY_DIGIT) =>
      setAttribute("CATEGORY_DIGIT", CATEGORY_DIGIT);

  /// ## CATEGORY_LINEBREAK (getter)
  Object? get CATEGORY_LINEBREAK => getAttribute("CATEGORY_LINEBREAK");

  /// ## CATEGORY_LINEBREAK (setter)
  set CATEGORY_LINEBREAK(Object? CATEGORY_LINEBREAK) =>
      setAttribute("CATEGORY_LINEBREAK", CATEGORY_LINEBREAK);

  /// ## CATEGORY_LOC_NOT_WORD (getter)
  Object? get CATEGORY_LOC_NOT_WORD => getAttribute("CATEGORY_LOC_NOT_WORD");

  /// ## CATEGORY_LOC_NOT_WORD (setter)
  set CATEGORY_LOC_NOT_WORD(Object? CATEGORY_LOC_NOT_WORD) =>
      setAttribute("CATEGORY_LOC_NOT_WORD", CATEGORY_LOC_NOT_WORD);

  /// ## CATEGORY_LOC_WORD (getter)
  Object? get CATEGORY_LOC_WORD => getAttribute("CATEGORY_LOC_WORD");

  /// ## CATEGORY_LOC_WORD (setter)
  set CATEGORY_LOC_WORD(Object? CATEGORY_LOC_WORD) =>
      setAttribute("CATEGORY_LOC_WORD", CATEGORY_LOC_WORD);

  /// ## CATEGORY_NOT_DIGIT (getter)
  Object? get CATEGORY_NOT_DIGIT => getAttribute("CATEGORY_NOT_DIGIT");

  /// ## CATEGORY_NOT_DIGIT (setter)
  set CATEGORY_NOT_DIGIT(Object? CATEGORY_NOT_DIGIT) =>
      setAttribute("CATEGORY_NOT_DIGIT", CATEGORY_NOT_DIGIT);

  /// ## CATEGORY_NOT_LINEBREAK (getter)
  Object? get CATEGORY_NOT_LINEBREAK => getAttribute("CATEGORY_NOT_LINEBREAK");

  /// ## CATEGORY_NOT_LINEBREAK (setter)
  set CATEGORY_NOT_LINEBREAK(Object? CATEGORY_NOT_LINEBREAK) =>
      setAttribute("CATEGORY_NOT_LINEBREAK", CATEGORY_NOT_LINEBREAK);

  /// ## CATEGORY_NOT_SPACE (getter)
  Object? get CATEGORY_NOT_SPACE => getAttribute("CATEGORY_NOT_SPACE");

  /// ## CATEGORY_NOT_SPACE (setter)
  set CATEGORY_NOT_SPACE(Object? CATEGORY_NOT_SPACE) =>
      setAttribute("CATEGORY_NOT_SPACE", CATEGORY_NOT_SPACE);

  /// ## CATEGORY_NOT_WORD (getter)
  Object? get CATEGORY_NOT_WORD => getAttribute("CATEGORY_NOT_WORD");

  /// ## CATEGORY_NOT_WORD (setter)
  set CATEGORY_NOT_WORD(Object? CATEGORY_NOT_WORD) =>
      setAttribute("CATEGORY_NOT_WORD", CATEGORY_NOT_WORD);

  /// ## CATEGORY_SPACE (getter)
  Object? get CATEGORY_SPACE => getAttribute("CATEGORY_SPACE");

  /// ## CATEGORY_SPACE (setter)
  set CATEGORY_SPACE(Object? CATEGORY_SPACE) =>
      setAttribute("CATEGORY_SPACE", CATEGORY_SPACE);

  /// ## CATEGORY_UNI_DIGIT (getter)
  Object? get CATEGORY_UNI_DIGIT => getAttribute("CATEGORY_UNI_DIGIT");

  /// ## CATEGORY_UNI_DIGIT (setter)
  set CATEGORY_UNI_DIGIT(Object? CATEGORY_UNI_DIGIT) =>
      setAttribute("CATEGORY_UNI_DIGIT", CATEGORY_UNI_DIGIT);

  /// ## CATEGORY_UNI_LINEBREAK (getter)
  Object? get CATEGORY_UNI_LINEBREAK => getAttribute("CATEGORY_UNI_LINEBREAK");

  /// ## CATEGORY_UNI_LINEBREAK (setter)
  set CATEGORY_UNI_LINEBREAK(Object? CATEGORY_UNI_LINEBREAK) =>
      setAttribute("CATEGORY_UNI_LINEBREAK", CATEGORY_UNI_LINEBREAK);

  /// ## CATEGORY_UNI_NOT_DIGIT (getter)
  Object? get CATEGORY_UNI_NOT_DIGIT => getAttribute("CATEGORY_UNI_NOT_DIGIT");

  /// ## CATEGORY_UNI_NOT_DIGIT (setter)
  set CATEGORY_UNI_NOT_DIGIT(Object? CATEGORY_UNI_NOT_DIGIT) =>
      setAttribute("CATEGORY_UNI_NOT_DIGIT", CATEGORY_UNI_NOT_DIGIT);

  /// ## CATEGORY_UNI_NOT_LINEBREAK (getter)
  Object? get CATEGORY_UNI_NOT_LINEBREAK =>
      getAttribute("CATEGORY_UNI_NOT_LINEBREAK");

  /// ## CATEGORY_UNI_NOT_LINEBREAK (setter)
  set CATEGORY_UNI_NOT_LINEBREAK(Object? CATEGORY_UNI_NOT_LINEBREAK) =>
      setAttribute("CATEGORY_UNI_NOT_LINEBREAK", CATEGORY_UNI_NOT_LINEBREAK);

  /// ## CATEGORY_UNI_NOT_SPACE (getter)
  Object? get CATEGORY_UNI_NOT_SPACE => getAttribute("CATEGORY_UNI_NOT_SPACE");

  /// ## CATEGORY_UNI_NOT_SPACE (setter)
  set CATEGORY_UNI_NOT_SPACE(Object? CATEGORY_UNI_NOT_SPACE) =>
      setAttribute("CATEGORY_UNI_NOT_SPACE", CATEGORY_UNI_NOT_SPACE);

  /// ## CATEGORY_UNI_NOT_WORD (getter)
  Object? get CATEGORY_UNI_NOT_WORD => getAttribute("CATEGORY_UNI_NOT_WORD");

  /// ## CATEGORY_UNI_NOT_WORD (setter)
  set CATEGORY_UNI_NOT_WORD(Object? CATEGORY_UNI_NOT_WORD) =>
      setAttribute("CATEGORY_UNI_NOT_WORD", CATEGORY_UNI_NOT_WORD);

  /// ## CATEGORY_UNI_SPACE (getter)
  Object? get CATEGORY_UNI_SPACE => getAttribute("CATEGORY_UNI_SPACE");

  /// ## CATEGORY_UNI_SPACE (setter)
  set CATEGORY_UNI_SPACE(Object? CATEGORY_UNI_SPACE) =>
      setAttribute("CATEGORY_UNI_SPACE", CATEGORY_UNI_SPACE);

  /// ## CATEGORY_UNI_WORD (getter)
  Object? get CATEGORY_UNI_WORD => getAttribute("CATEGORY_UNI_WORD");

  /// ## CATEGORY_UNI_WORD (setter)
  set CATEGORY_UNI_WORD(Object? CATEGORY_UNI_WORD) =>
      setAttribute("CATEGORY_UNI_WORD", CATEGORY_UNI_WORD);

  /// ## CATEGORY_WORD (getter)
  Object? get CATEGORY_WORD => getAttribute("CATEGORY_WORD");

  /// ## CATEGORY_WORD (setter)
  set CATEGORY_WORD(Object? CATEGORY_WORD) =>
      setAttribute("CATEGORY_WORD", CATEGORY_WORD);

  /// ## CHARSET (getter)
  Object? get CHARSET => getAttribute("CHARSET");

  /// ## CHARSET (setter)
  set CHARSET(Object? CHARSET) => setAttribute("CHARSET", CHARSET);

  /// ## CHCODES (getter)
  Object? get CHCODES => getAttribute("CHCODES");

  /// ## CHCODES (setter)
  set CHCODES(Object? CHCODES) => setAttribute("CHCODES", CHCODES);

  /// ## CH_LOCALE (getter)
  Object? get CH_LOCALE => getAttribute("CH_LOCALE");

  /// ## CH_LOCALE (setter)
  set CH_LOCALE(Object? CH_LOCALE) => setAttribute("CH_LOCALE", CH_LOCALE);

  /// ## CH_UNICODE (getter)
  Object? get CH_UNICODE => getAttribute("CH_UNICODE");

  /// ## CH_UNICODE (setter)
  set CH_UNICODE(Object? CH_UNICODE) => setAttribute("CH_UNICODE", CH_UNICODE);

  /// ## FAILURE (getter)
  Object? get FAILURE => getAttribute("FAILURE");

  /// ## FAILURE (setter)
  set FAILURE(Object? FAILURE) => setAttribute("FAILURE", FAILURE);

  /// ## GROUPREF (getter)
  Object? get GROUPREF => getAttribute("GROUPREF");

  /// ## GROUPREF (setter)
  set GROUPREF(Object? GROUPREF) => setAttribute("GROUPREF", GROUPREF);

  /// ## GROUPREF_EXISTS (getter)
  Object? get GROUPREF_EXISTS => getAttribute("GROUPREF_EXISTS");

  /// ## GROUPREF_EXISTS (setter)
  set GROUPREF_EXISTS(Object? GROUPREF_EXISTS) =>
      setAttribute("GROUPREF_EXISTS", GROUPREF_EXISTS);

  /// ## GROUPREF_IGNORE (getter)
  Object? get GROUPREF_IGNORE => getAttribute("GROUPREF_IGNORE");

  /// ## GROUPREF_IGNORE (setter)
  set GROUPREF_IGNORE(Object? GROUPREF_IGNORE) =>
      setAttribute("GROUPREF_IGNORE", GROUPREF_IGNORE);

  /// ## GROUPREF_LOC_IGNORE (getter)
  Object? get GROUPREF_LOC_IGNORE => getAttribute("GROUPREF_LOC_IGNORE");

  /// ## GROUPREF_LOC_IGNORE (setter)
  set GROUPREF_LOC_IGNORE(Object? GROUPREF_LOC_IGNORE) =>
      setAttribute("GROUPREF_LOC_IGNORE", GROUPREF_LOC_IGNORE);

  /// ## GROUPREF_UNI_IGNORE (getter)
  Object? get GROUPREF_UNI_IGNORE => getAttribute("GROUPREF_UNI_IGNORE");

  /// ## GROUPREF_UNI_IGNORE (setter)
  set GROUPREF_UNI_IGNORE(Object? GROUPREF_UNI_IGNORE) =>
      setAttribute("GROUPREF_UNI_IGNORE", GROUPREF_UNI_IGNORE);

  /// ## IN (getter)
  Object? get IN => getAttribute("IN");

  /// ## IN (setter)
  set IN(Object? IN) => setAttribute("IN", IN);

  /// ## INFO (getter)
  Object? get INFO => getAttribute("INFO");

  /// ## INFO (setter)
  set INFO(Object? INFO) => setAttribute("INFO", INFO);

  /// ## IN_IGNORE (getter)
  Object? get IN_IGNORE => getAttribute("IN_IGNORE");

  /// ## IN_IGNORE (setter)
  set IN_IGNORE(Object? IN_IGNORE) => setAttribute("IN_IGNORE", IN_IGNORE);

  /// ## IN_LOC_IGNORE (getter)
  Object? get IN_LOC_IGNORE => getAttribute("IN_LOC_IGNORE");

  /// ## IN_LOC_IGNORE (setter)
  set IN_LOC_IGNORE(Object? IN_LOC_IGNORE) =>
      setAttribute("IN_LOC_IGNORE", IN_LOC_IGNORE);

  /// ## IN_UNI_IGNORE (getter)
  Object? get IN_UNI_IGNORE => getAttribute("IN_UNI_IGNORE");

  /// ## IN_UNI_IGNORE (setter)
  set IN_UNI_IGNORE(Object? IN_UNI_IGNORE) =>
      setAttribute("IN_UNI_IGNORE", IN_UNI_IGNORE);

  /// ## JUMP (getter)
  Object? get JUMP => getAttribute("JUMP");

  /// ## JUMP (setter)
  set JUMP(Object? JUMP) => setAttribute("JUMP", JUMP);

  /// ## LITERAL (getter)
  Object? get LITERAL => getAttribute("LITERAL");

  /// ## LITERAL (setter)
  set LITERAL(Object? LITERAL) => setAttribute("LITERAL", LITERAL);

  /// ## LITERAL_IGNORE (getter)
  Object? get LITERAL_IGNORE => getAttribute("LITERAL_IGNORE");

  /// ## LITERAL_IGNORE (setter)
  set LITERAL_IGNORE(Object? LITERAL_IGNORE) =>
      setAttribute("LITERAL_IGNORE", LITERAL_IGNORE);

  /// ## LITERAL_LOC_IGNORE (getter)
  Object? get LITERAL_LOC_IGNORE => getAttribute("LITERAL_LOC_IGNORE");

  /// ## LITERAL_LOC_IGNORE (setter)
  set LITERAL_LOC_IGNORE(Object? LITERAL_LOC_IGNORE) =>
      setAttribute("LITERAL_LOC_IGNORE", LITERAL_LOC_IGNORE);

  /// ## LITERAL_UNI_IGNORE (getter)
  Object? get LITERAL_UNI_IGNORE => getAttribute("LITERAL_UNI_IGNORE");

  /// ## LITERAL_UNI_IGNORE (setter)
  set LITERAL_UNI_IGNORE(Object? LITERAL_UNI_IGNORE) =>
      setAttribute("LITERAL_UNI_IGNORE", LITERAL_UNI_IGNORE);

  /// ## MAGIC (getter)
  Object? get MAGIC => getAttribute("MAGIC");

  /// ## MAGIC (setter)
  set MAGIC(Object? MAGIC) => setAttribute("MAGIC", MAGIC);

  /// ## MARK (getter)
  Object? get MARK => getAttribute("MARK");

  /// ## MARK (setter)
  set MARK(Object? MARK) => setAttribute("MARK", MARK);

  /// ## MAXGROUPS (getter)
  Object? get MAXGROUPS => getAttribute("MAXGROUPS");

  /// ## MAXGROUPS (setter)
  set MAXGROUPS(Object? MAXGROUPS) => setAttribute("MAXGROUPS", MAXGROUPS);

  /// ## MAXREPEAT (getter)
  Object? get MAXREPEAT => getAttribute("MAXREPEAT");

  /// ## MAXREPEAT (setter)
  set MAXREPEAT(Object? MAXREPEAT) => setAttribute("MAXREPEAT", MAXREPEAT);

  /// ## MAX_REPEAT (getter)
  Object? get MAX_REPEAT => getAttribute("MAX_REPEAT");

  /// ## MAX_REPEAT (setter)
  set MAX_REPEAT(Object? MAX_REPEAT) => setAttribute("MAX_REPEAT", MAX_REPEAT);

  /// ## MAX_UNTIL (getter)
  Object? get MAX_UNTIL => getAttribute("MAX_UNTIL");

  /// ## MAX_UNTIL (setter)
  set MAX_UNTIL(Object? MAX_UNTIL) => setAttribute("MAX_UNTIL", MAX_UNTIL);

  /// ## MIN_REPEAT (getter)
  Object? get MIN_REPEAT => getAttribute("MIN_REPEAT");

  /// ## MIN_REPEAT (setter)
  set MIN_REPEAT(Object? MIN_REPEAT) => setAttribute("MIN_REPEAT", MIN_REPEAT);

  /// ## MIN_REPEAT_ONE (getter)
  Object? get MIN_REPEAT_ONE => getAttribute("MIN_REPEAT_ONE");

  /// ## MIN_REPEAT_ONE (setter)
  set MIN_REPEAT_ONE(Object? MIN_REPEAT_ONE) =>
      setAttribute("MIN_REPEAT_ONE", MIN_REPEAT_ONE);

  /// ## MIN_UNTIL (getter)
  Object? get MIN_UNTIL => getAttribute("MIN_UNTIL");

  /// ## MIN_UNTIL (setter)
  set MIN_UNTIL(Object? MIN_UNTIL) => setAttribute("MIN_UNTIL", MIN_UNTIL);

  /// ## NEGATE (getter)
  Object? get NEGATE => getAttribute("NEGATE");

  /// ## NEGATE (setter)
  set NEGATE(Object? NEGATE) => setAttribute("NEGATE", NEGATE);

  /// ## NOT_LITERAL (getter)
  Object? get NOT_LITERAL => getAttribute("NOT_LITERAL");

  /// ## NOT_LITERAL (setter)
  set NOT_LITERAL(Object? NOT_LITERAL) =>
      setAttribute("NOT_LITERAL", NOT_LITERAL);

  /// ## NOT_LITERAL_IGNORE (getter)
  Object? get NOT_LITERAL_IGNORE => getAttribute("NOT_LITERAL_IGNORE");

  /// ## NOT_LITERAL_IGNORE (setter)
  set NOT_LITERAL_IGNORE(Object? NOT_LITERAL_IGNORE) =>
      setAttribute("NOT_LITERAL_IGNORE", NOT_LITERAL_IGNORE);

  /// ## NOT_LITERAL_LOC_IGNORE (getter)
  Object? get NOT_LITERAL_LOC_IGNORE => getAttribute("NOT_LITERAL_LOC_IGNORE");

  /// ## NOT_LITERAL_LOC_IGNORE (setter)
  set NOT_LITERAL_LOC_IGNORE(Object? NOT_LITERAL_LOC_IGNORE) =>
      setAttribute("NOT_LITERAL_LOC_IGNORE", NOT_LITERAL_LOC_IGNORE);

  /// ## NOT_LITERAL_UNI_IGNORE (getter)
  Object? get NOT_LITERAL_UNI_IGNORE => getAttribute("NOT_LITERAL_UNI_IGNORE");

  /// ## NOT_LITERAL_UNI_IGNORE (setter)
  set NOT_LITERAL_UNI_IGNORE(Object? NOT_LITERAL_UNI_IGNORE) =>
      setAttribute("NOT_LITERAL_UNI_IGNORE", NOT_LITERAL_UNI_IGNORE);

  /// ## OPCODES (getter)
  Object? get OPCODES => getAttribute("OPCODES");

  /// ## OPCODES (setter)
  set OPCODES(Object? OPCODES) => setAttribute("OPCODES", OPCODES);

  /// ## OP_IGNORE (getter)
  Object? get OP_IGNORE => getAttribute("OP_IGNORE");

  /// ## OP_IGNORE (setter)
  set OP_IGNORE(Object? OP_IGNORE) => setAttribute("OP_IGNORE", OP_IGNORE);

  /// ## OP_LOCALE_IGNORE (getter)
  Object? get OP_LOCALE_IGNORE => getAttribute("OP_LOCALE_IGNORE");

  /// ## OP_LOCALE_IGNORE (setter)
  set OP_LOCALE_IGNORE(Object? OP_LOCALE_IGNORE) =>
      setAttribute("OP_LOCALE_IGNORE", OP_LOCALE_IGNORE);

  /// ## OP_UNICODE_IGNORE (getter)
  Object? get OP_UNICODE_IGNORE => getAttribute("OP_UNICODE_IGNORE");

  /// ## OP_UNICODE_IGNORE (setter)
  set OP_UNICODE_IGNORE(Object? OP_UNICODE_IGNORE) =>
      setAttribute("OP_UNICODE_IGNORE", OP_UNICODE_IGNORE);

  /// ## POSSESSIVE_REPEAT (getter)
  Object? get POSSESSIVE_REPEAT => getAttribute("POSSESSIVE_REPEAT");

  /// ## POSSESSIVE_REPEAT (setter)
  set POSSESSIVE_REPEAT(Object? POSSESSIVE_REPEAT) =>
      setAttribute("POSSESSIVE_REPEAT", POSSESSIVE_REPEAT);

  /// ## POSSESSIVE_REPEAT_ONE (getter)
  Object? get POSSESSIVE_REPEAT_ONE => getAttribute("POSSESSIVE_REPEAT_ONE");

  /// ## POSSESSIVE_REPEAT_ONE (setter)
  set POSSESSIVE_REPEAT_ONE(Object? POSSESSIVE_REPEAT_ONE) =>
      setAttribute("POSSESSIVE_REPEAT_ONE", POSSESSIVE_REPEAT_ONE);

  /// ## RANGE (getter)
  Object? get RANGE => getAttribute("RANGE");

  /// ## RANGE (setter)
  set RANGE(Object? RANGE) => setAttribute("RANGE", RANGE);

  /// ## RANGE_UNI_IGNORE (getter)
  Object? get RANGE_UNI_IGNORE => getAttribute("RANGE_UNI_IGNORE");

  /// ## RANGE_UNI_IGNORE (setter)
  set RANGE_UNI_IGNORE(Object? RANGE_UNI_IGNORE) =>
      setAttribute("RANGE_UNI_IGNORE", RANGE_UNI_IGNORE);

  /// ## REPEAT (getter)
  Object? get REPEAT => getAttribute("REPEAT");

  /// ## REPEAT (setter)
  set REPEAT(Object? REPEAT) => setAttribute("REPEAT", REPEAT);

  /// ## REPEAT_ONE (getter)
  Object? get REPEAT_ONE => getAttribute("REPEAT_ONE");

  /// ## REPEAT_ONE (setter)
  set REPEAT_ONE(Object? REPEAT_ONE) => setAttribute("REPEAT_ONE", REPEAT_ONE);

  /// ## SRE_FLAG_ASCII (getter)
  Object? get SRE_FLAG_ASCII => getAttribute("SRE_FLAG_ASCII");

  /// ## SRE_FLAG_ASCII (setter)
  set SRE_FLAG_ASCII(Object? SRE_FLAG_ASCII) =>
      setAttribute("SRE_FLAG_ASCII", SRE_FLAG_ASCII);

  /// ## SRE_FLAG_DEBUG (getter)
  Object? get SRE_FLAG_DEBUG => getAttribute("SRE_FLAG_DEBUG");

  /// ## SRE_FLAG_DEBUG (setter)
  set SRE_FLAG_DEBUG(Object? SRE_FLAG_DEBUG) =>
      setAttribute("SRE_FLAG_DEBUG", SRE_FLAG_DEBUG);

  /// ## SRE_FLAG_DOTALL (getter)
  Object? get SRE_FLAG_DOTALL => getAttribute("SRE_FLAG_DOTALL");

  /// ## SRE_FLAG_DOTALL (setter)
  set SRE_FLAG_DOTALL(Object? SRE_FLAG_DOTALL) =>
      setAttribute("SRE_FLAG_DOTALL", SRE_FLAG_DOTALL);

  /// ## SRE_FLAG_IGNORECASE (getter)
  Object? get SRE_FLAG_IGNORECASE => getAttribute("SRE_FLAG_IGNORECASE");

  /// ## SRE_FLAG_IGNORECASE (setter)
  set SRE_FLAG_IGNORECASE(Object? SRE_FLAG_IGNORECASE) =>
      setAttribute("SRE_FLAG_IGNORECASE", SRE_FLAG_IGNORECASE);

  /// ## SRE_FLAG_LOCALE (getter)
  Object? get SRE_FLAG_LOCALE => getAttribute("SRE_FLAG_LOCALE");

  /// ## SRE_FLAG_LOCALE (setter)
  set SRE_FLAG_LOCALE(Object? SRE_FLAG_LOCALE) =>
      setAttribute("SRE_FLAG_LOCALE", SRE_FLAG_LOCALE);

  /// ## SRE_FLAG_MULTILINE (getter)
  Object? get SRE_FLAG_MULTILINE => getAttribute("SRE_FLAG_MULTILINE");

  /// ## SRE_FLAG_MULTILINE (setter)
  set SRE_FLAG_MULTILINE(Object? SRE_FLAG_MULTILINE) =>
      setAttribute("SRE_FLAG_MULTILINE", SRE_FLAG_MULTILINE);

  /// ## SRE_FLAG_TEMPLATE (getter)
  Object? get SRE_FLAG_TEMPLATE => getAttribute("SRE_FLAG_TEMPLATE");

  /// ## SRE_FLAG_TEMPLATE (setter)
  set SRE_FLAG_TEMPLATE(Object? SRE_FLAG_TEMPLATE) =>
      setAttribute("SRE_FLAG_TEMPLATE", SRE_FLAG_TEMPLATE);

  /// ## SRE_FLAG_UNICODE (getter)
  Object? get SRE_FLAG_UNICODE => getAttribute("SRE_FLAG_UNICODE");

  /// ## SRE_FLAG_UNICODE (setter)
  set SRE_FLAG_UNICODE(Object? SRE_FLAG_UNICODE) =>
      setAttribute("SRE_FLAG_UNICODE", SRE_FLAG_UNICODE);

  /// ## SRE_FLAG_VERBOSE (getter)
  Object? get SRE_FLAG_VERBOSE => getAttribute("SRE_FLAG_VERBOSE");

  /// ## SRE_FLAG_VERBOSE (setter)
  set SRE_FLAG_VERBOSE(Object? SRE_FLAG_VERBOSE) =>
      setAttribute("SRE_FLAG_VERBOSE", SRE_FLAG_VERBOSE);

  /// ## SRE_INFO_CHARSET (getter)
  Object? get SRE_INFO_CHARSET => getAttribute("SRE_INFO_CHARSET");

  /// ## SRE_INFO_CHARSET (setter)
  set SRE_INFO_CHARSET(Object? SRE_INFO_CHARSET) =>
      setAttribute("SRE_INFO_CHARSET", SRE_INFO_CHARSET);

  /// ## SRE_INFO_LITERAL (getter)
  Object? get SRE_INFO_LITERAL => getAttribute("SRE_INFO_LITERAL");

  /// ## SRE_INFO_LITERAL (setter)
  set SRE_INFO_LITERAL(Object? SRE_INFO_LITERAL) =>
      setAttribute("SRE_INFO_LITERAL", SRE_INFO_LITERAL);

  /// ## SRE_INFO_PREFIX (getter)
  Object? get SRE_INFO_PREFIX => getAttribute("SRE_INFO_PREFIX");

  /// ## SRE_INFO_PREFIX (setter)
  set SRE_INFO_PREFIX(Object? SRE_INFO_PREFIX) =>
      setAttribute("SRE_INFO_PREFIX", SRE_INFO_PREFIX);

  /// ## SUBPATTERN (getter)
  Object? get SUBPATTERN => getAttribute("SUBPATTERN");

  /// ## SUBPATTERN (setter)
  set SUBPATTERN(Object? SUBPATTERN) => setAttribute("SUBPATTERN", SUBPATTERN);

  /// ## SUCCESS (getter)
  Object? get SUCCESS => getAttribute("SUCCESS");

  /// ## SUCCESS (setter)
  set SUCCESS(Object? SUCCESS) => setAttribute("SUCCESS", SUCCESS);
}

/// ## sre_parse
///
/// ### python docstring
///
/// Internal support module for sre
///
/// ### python source
/// ```py
/// #
/// # Secret Labs' Regular Expression Engine
/// #
/// # convert re-style regular expression to sre pattern
/// #
/// # Copyright (c) 1998-2001 by Secret Labs AB.  All rights reserved.
/// #
/// # See the __init__.py file for information on usage and redistribution.
/// #
///
/// """Internal support module for sre"""
///
/// # XXX: show string offset and offending character for all errors
///
/// from ._constants import *
///
/// SPECIAL_CHARS = ".\\[{()*+?^$|"
/// REPEAT_CHARS = "*+?{"
///
/// DIGITS = frozenset("0123456789")
///
/// OCTDIGITS = frozenset("01234567")
/// HEXDIGITS = frozenset("0123456789abcdefABCDEF")
/// ASCIILETTERS = frozenset("abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ")
///
/// WHITESPACE = frozenset(" \t\n\r\v\f")
///
/// _REPEATCODES = frozenset({MIN_REPEAT, MAX_REPEAT, POSSESSIVE_REPEAT})
/// _UNITCODES = frozenset({ANY, RANGE, IN, LITERAL, NOT_LITERAL, CATEGORY})
///
/// ESCAPES = {
///     r"\a": (LITERAL, ord("\a")),
///     r"\b": (LITERAL, ord("\b")),
///     r"\f": (LITERAL, ord("\f")),
///     r"\n": (LITERAL, ord("\n")),
///     r"\r": (LITERAL, ord("\r")),
///     r"\t": (LITERAL, ord("\t")),
///     r"\v": (LITERAL, ord("\v")),
///     r"\\": (LITERAL, ord("\\"))
/// }
///
/// CATEGORIES = {
///     r"\A": (AT, AT_BEGINNING_STRING), # start of string
///     r"\b": (AT, AT_BOUNDARY),
///     r"\B": (AT, AT_NON_BOUNDARY),
///     r"\d": (IN, [(CATEGORY, CATEGORY_DIGIT)]),
///     r"\D": (IN, [(CATEGORY, CATEGORY_NOT_DIGIT)]),
///     r"\s": (IN, [(CATEGORY, CATEGORY_SPACE)]),
///     r"\S": (IN, [(CATEGORY, CATEGORY_NOT_SPACE)]),
///     r"\w": (IN, [(CATEGORY, CATEGORY_WORD)]),
///     r"\W": (IN, [(CATEGORY, CATEGORY_NOT_WORD)]),
///     r"\Z": (AT, AT_END_STRING), # end of string
/// }
///
/// FLAGS = {
///     # standard flags
///     "i": SRE_FLAG_IGNORECASE,
///     "L": SRE_FLAG_LOCALE,
///     "m": SRE_FLAG_MULTILINE,
///     "s": SRE_FLAG_DOTALL,
///     "x": SRE_FLAG_VERBOSE,
///     # extensions
///     "a": SRE_FLAG_ASCII,
///     "t": SRE_FLAG_TEMPLATE,
///     "u": SRE_FLAG_UNICODE,
/// }
///
/// TYPE_FLAGS = SRE_FLAG_ASCII | SRE_FLAG_LOCALE | SRE_FLAG_UNICODE
/// GLOBAL_FLAGS = SRE_FLAG_DEBUG | SRE_FLAG_TEMPLATE
///
/// class State:
///     # keeps track of state for parsing
///     def __init__(self):
///         self.flags = 0
///         self.groupdict = {}
///         self.groupwidths = [None]  # group 0
///         self.lookbehindgroups = None
///         self.grouprefpos = {}
///     @property
///     def groups(self):
///         return len(self.groupwidths)
///     def opengroup(self, name=None):
///         gid = self.groups
///         self.groupwidths.append(None)
///         if self.groups > MAXGROUPS:
///             raise error("too many groups")
///         if name is not None:
///             ogid = self.groupdict.get(name, None)
///             if ogid is not None:
///                 raise error("redefinition of group name %r as group %d; "
///                             "was group %d" % (name, gid,  ogid))
///             self.groupdict[name] = gid
///         return gid
///     def closegroup(self, gid, p):
///         self.groupwidths[gid] = p.getwidth()
///     def checkgroup(self, gid):
///         return gid < self.groups and self.groupwidths[gid] is not None
///
///     def checklookbehindgroup(self, gid, source):
///         if self.lookbehindgroups is not None:
///             if not self.checkgroup(gid):
///                 raise source.error('cannot refer to an open group')
///             if gid >= self.lookbehindgroups:
///                 raise source.error('cannot refer to group defined in the same '
///                                    'lookbehind subpattern')
///
/// class SubPattern:
///     # a subpattern, in intermediate form
///     def __init__(self, state, data=None):
///         self.state = state
///         if data is None:
///             data = []
///         self.data = data
///         self.width = None
///
///     def dump(self, level=0):
///         nl = True
///         seqtypes = (tuple, list)
///         for op, av in self.data:
///             print(level*"  " + str(op), end='')
///             if op is IN:
///                 # member sublanguage
///                 print()
///                 for op, a in av:
///                     print((level+1)*"  " + str(op), a)
///             elif op is BRANCH:
///                 print()
///                 for i, a in enumerate(av[1]):
///                     if i:
///                         print(level*"  " + "OR")
///                     a.dump(level+1)
///             elif op is GROUPREF_EXISTS:
///                 condgroup, item_yes, item_no = av
///                 print('', condgroup)
///                 item_yes.dump(level+1)
///                 if item_no:
///                     print(level*"  " + "ELSE")
///                     item_no.dump(level+1)
///             elif isinstance(av, seqtypes):
///                 nl = False
///                 for a in av:
///                     if isinstance(a, SubPattern):
///                         if not nl:
///                             print()
///                         a.dump(level+1)
///                         nl = True
///                     else:
///                         if not nl:
///                             print(' ', end='')
///                         print(a, end='')
///                         nl = False
///                 if not nl:
///                     print()
///             else:
///                 print('', av)
///     def __repr__(self):
///         return repr(self.data)
///     def __len__(self):
///         return len(self.data)
///     def __delitem__(self, index):
///         del self.data[index]
///     def __getitem__(self, index):
///         if isinstance(index, slice):
///             return SubPattern(self.state, self.data[index])
///         return self.data[index]
///     def __setitem__(self, index, code):
///         self.data[index] = code
///     def insert(self, index, code):
///         self.data.insert(index, code)
///     def append(self, code):
///         self.data.append(code)
///     def getwidth(self):
///         # determine the width (min, max) for this subpattern
///         if self.width is not None:
///             return self.width
///         lo = hi = 0
///         for op, av in self.data:
///             if op is BRANCH:
///                 i = MAXREPEAT - 1
///                 j = 0
///                 for av in av[1]:
///                     l, h = av.getwidth()
///                     i = min(i, l)
///                     j = max(j, h)
///                 lo = lo + i
///                 hi = hi + j
///             elif op is ATOMIC_GROUP:
///                 i, j = av.getwidth()
///                 lo = lo + i
///                 hi = hi + j
///             elif op is SUBPATTERN:
///                 i, j = av[-1].getwidth()
///                 lo = lo + i
///                 hi = hi + j
///             elif op in _REPEATCODES:
///                 i, j = av[2].getwidth()
///                 lo = lo + i * av[0]
///                 hi = hi + j * av[1]
///             elif op in _UNITCODES:
///                 lo = lo + 1
///                 hi = hi + 1
///             elif op is GROUPREF:
///                 i, j = self.state.groupwidths[av]
///                 lo = lo + i
///                 hi = hi + j
///             elif op is GROUPREF_EXISTS:
///                 i, j = av[1].getwidth()
///                 if av[2] is not None:
///                     l, h = av[2].getwidth()
///                     i = min(i, l)
///                     j = max(j, h)
///                 else:
///                     i = 0
///                 lo = lo + i
///                 hi = hi + j
///             elif op is SUCCESS:
///                 break
///         self.width = min(lo, MAXREPEAT - 1), min(hi, MAXREPEAT)
///         return self.width
///
/// class Tokenizer:
///     def __init__(self, string):
///         self.istext = isinstance(string, str)
///         self.string = string
///         if not self.istext:
///             string = str(string, 'latin1')
///         self.decoded_string = string
///         self.index = 0
///         self.next = None
///         self.__next()
///     def __next(self):
///         index = self.index
///         try:
///             char = self.decoded_string[index]
///         except IndexError:
///             self.next = None
///             return
///         if char == "\\":
///             index += 1
///             try:
///                 char += self.decoded_string[index]
///             except IndexError:
///                 raise error("bad escape (end of pattern)",
///                             self.string, len(self.string) - 1) from None
///         self.index = index + 1
///         self.next = char
///     def match(self, char):
///         if char == self.next:
///             self.__next()
///             return True
///         return False
///     def get(self):
///         this = self.next
///         self.__next()
///         return this
///     def getwhile(self, n, charset):
///         result = ''
///         for _ in range(n):
///             c = self.next
///             if c not in charset:
///                 break
///             result += c
///             self.__next()
///         return result
///     def getuntil(self, terminator, name):
///         result = ''
///         while True:
///             c = self.next
///             self.__next()
///             if c is None:
///                 if not result:
///                     raise self.error("missing " + name)
///                 raise self.error("missing %s, unterminated name" % terminator,
///                                  len(result))
///             if c == terminator:
///                 if not result:
///                     raise self.error("missing " + name, 1)
///                 break
///             result += c
///         return result
///     @property
///     def pos(self):
///         return self.index - len(self.next or '')
///     def tell(self):
///         return self.index - len(self.next or '')
///     def seek(self, index):
///         self.index = index
///         self.__next()
///
///     def error(self, msg, offset=0):
///         if not self.istext:
///             msg = msg.encode('ascii', 'backslashreplace').decode('ascii')
///         return error(msg, self.string, self.tell() - offset)
///
///     def checkgroupname(self, name, offset, nested):
///         if not name.isidentifier():
///             msg = "bad character in group name %r" % name
///             raise self.error(msg, len(name) + offset)
///         if not (self.istext or name.isascii()):
///             import warnings
///             warnings.warn(
///                 "bad character in group name %a at position %d" %
///                 (name, self.tell() - len(name) - offset),
///                 DeprecationWarning, stacklevel=nested + 7
///             )
///
/// def _class_escape(source, escape):
///     # handle escape code inside character class
///     code = ESCAPES.get(escape)
///     if code:
///         return code
///     code = CATEGORIES.get(escape)
///     if code and code[0] is IN:
///         return code
///     try:
///         c = escape[1:2]
///         if c == "x":
///             # hexadecimal escape (exactly two digits)
///             escape += source.getwhile(2, HEXDIGITS)
///             if len(escape) != 4:
///                 raise source.error("incomplete escape %s" % escape, len(escape))
///             return LITERAL, int(escape[2:], 16)
///         elif c == "u" and source.istext:
///             # unicode escape (exactly four digits)
///             escape += source.getwhile(4, HEXDIGITS)
///             if len(escape) != 6:
///                 raise source.error("incomplete escape %s" % escape, len(escape))
///             return LITERAL, int(escape[2:], 16)
///         elif c == "U" and source.istext:
///             # unicode escape (exactly eight digits)
///             escape += source.getwhile(8, HEXDIGITS)
///             if len(escape) != 10:
///                 raise source.error("incomplete escape %s" % escape, len(escape))
///             c = int(escape[2:], 16)
///             chr(c) # raise ValueError for invalid code
///             return LITERAL, c
///         elif c == "N" and source.istext:
///             import unicodedata
///             # named unicode escape e.g. \N{EM DASH}
///             if not source.match('{'):
///                 raise source.error("missing {")
///             charname = source.getuntil('}', 'character name')
///             try:
///                 c = ord(unicodedata.lookup(charname))
///             except (KeyError, TypeError):
///                 raise source.error("undefined character name %r" % charname,
///                                    len(charname) + len(r'\N{}')) from None
///             return LITERAL, c
///         elif c in OCTDIGITS:
///             # octal escape (up to three digits)
///             escape += source.getwhile(2, OCTDIGITS)
///             c = int(escape[1:], 8)
///             if c > 0o377:
///                 raise source.error('octal escape value %s outside of '
///                                    'range 0-0o377' % escape, len(escape))
///             return LITERAL, c
///         elif c in DIGITS:
///             raise ValueError
///         if len(escape) == 2:
///             if c in ASCIILETTERS:
///                 raise source.error('bad escape %s' % escape, len(escape))
///             return LITERAL, ord(escape[1])
///     except ValueError:
///         pass
///     raise source.error("bad escape %s" % escape, len(escape))
///
/// def _escape(source, escape, state):
///     # handle escape code in expression
///     code = CATEGORIES.get(escape)
///     if code:
///         return code
///     code = ESCAPES.get(escape)
///     if code:
///         return code
///     try:
///         c = escape[1:2]
///         if c == "x":
///             # hexadecimal escape
///             escape += source.getwhile(2, HEXDIGITS)
///             if len(escape) != 4:
///                 raise source.error("incomplete escape %s" % escape, len(escape))
///             return LITERAL, int(escape[2:], 16)
///         elif c == "u" and source.istext:
///             # unicode escape (exactly four digits)
///             escape += source.getwhile(4, HEXDIGITS)
///             if len(escape) != 6:
///                 raise source.error("incomplete escape %s" % escape, len(escape))
///             return LITERAL, int(escape[2:], 16)
///         elif c == "U" and source.istext:
///             # unicode escape (exactly eight digits)
///             escape += source.getwhile(8, HEXDIGITS)
///             if len(escape) != 10:
///                 raise source.error("incomplete escape %s" % escape, len(escape))
///             c = int(escape[2:], 16)
///             chr(c) # raise ValueError for invalid code
///             return LITERAL, c
///         elif c == "N" and source.istext:
///             import unicodedata
///             # named unicode escape e.g. \N{EM DASH}
///             if not source.match('{'):
///                 raise source.error("missing {")
///             charname = source.getuntil('}', 'character name')
///             try:
///                 c = ord(unicodedata.lookup(charname))
///             except (KeyError, TypeError):
///                 raise source.error("undefined character name %r" % charname,
///                                    len(charname) + len(r'\N{}')) from None
///             return LITERAL, c
///         elif c == "0":
///             # octal escape
///             escape += source.getwhile(2, OCTDIGITS)
///             return LITERAL, int(escape[1:], 8)
///         elif c in DIGITS:
///             # octal escape *or* decimal group reference (sigh)
///             if source.next in DIGITS:
///                 escape += source.get()
///                 if (escape[1] in OCTDIGITS and escape[2] in OCTDIGITS and
///                     source.next in OCTDIGITS):
///                     # got three octal digits; this is an octal escape
///                     escape += source.get()
///                     c = int(escape[1:], 8)
///                     if c > 0o377:
///                         raise source.error('octal escape value %s outside of '
///                                            'range 0-0o377' % escape,
///                                            len(escape))
///                     return LITERAL, c
///             # not an octal escape, so this is a group reference
///             group = int(escape[1:])
///             if group < state.groups:
///                 if not state.checkgroup(group):
///                     raise source.error("cannot refer to an open group",
///                                        len(escape))
///                 state.checklookbehindgroup(group, source)
///                 return GROUPREF, group
///             raise source.error("invalid group reference %d" % group, len(escape) - 1)
///         if len(escape) == 2:
///             if c in ASCIILETTERS:
///                 raise source.error("bad escape %s" % escape, len(escape))
///             return LITERAL, ord(escape[1])
///     except ValueError:
///         pass
///     raise source.error("bad escape %s" % escape, len(escape))
///
/// def _uniq(items):
///     return list(dict.fromkeys(items))
///
/// def _parse_sub(source, state, verbose, nested):
///     # parse an alternation: a|b|c
///
///     items = []
///     itemsappend = items.append
///     sourcematch = source.match
///     start = source.tell()
///     while True:
///         itemsappend(_parse(source, state, verbose, nested + 1,
///                            not nested and not items))
///         if not sourcematch("|"):
///             break
///         if not nested:
///             verbose = state.flags & SRE_FLAG_VERBOSE
///
///     if len(items) == 1:
///         return items[0]
///
///     subpattern = SubPattern(state)
///
///     # check if all items share a common prefix
///     while True:
///         prefix = None
///         for item in items:
///             if not item:
///                 break
///             if prefix is None:
///                 prefix = item[0]
///             elif item[0] != prefix:
///                 break
///         else:
///             # all subitems start with a common "prefix".
///             # move it out of the branch
///             for item in items:
///                 del item[0]
///             subpattern.append(prefix)
///             continue # check next one
///         break
///
///     # check if the branch can be replaced by a character set
///     set = []
///     for item in items:
///         if len(item) != 1:
///             break
///         op, av = item[0]
///         if op is LITERAL:
///             set.append((op, av))
///         elif op is IN and av[0][0] is not NEGATE:
///             set.extend(av)
///         else:
///             break
///     else:
///         # we can store this as a character set instead of a
///         # branch (the compiler may optimize this even more)
///         subpattern.append((IN, _uniq(set)))
///         return subpattern
///
///     subpattern.append((BRANCH, (None, items)))
///     return subpattern
///
/// def _parse(source, state, verbose, nested, first=False):
///     # parse a simple pattern
///     subpattern = SubPattern(state)
///
///     # precompute constants into local variables
///     subpatternappend = subpattern.append
///     sourceget = source.get
///     sourcematch = source.match
///     _len = len
///     _ord = ord
///
///     while True:
///
///         this = source.next
///         if this is None:
///             break # end of pattern
///         if this in "|)":
///             break # end of subpattern
///         sourceget()
///
///         if verbose:
///             # skip whitespace and comments
///             if this in WHITESPACE:
///                 continue
///             if this == "#":
///                 while True:
///                     this = sourceget()
///                     if this is None or this == "\n":
///                         break
///                 continue
///
///         if this[0] == "\\":
///             code = _escape(source, this, state)
///             subpatternappend(code)
///
///         elif this not in SPECIAL_CHARS:
///             subpatternappend((LITERAL, _ord(this)))
///
///         elif this == "[":
///             here = source.tell() - 1
///             # character set
///             set = []
///             setappend = set.append
/// ##          if sourcematch(":"):
/// ##              pass # handle character classes
///             if source.next == '[':
///                 import warnings
///                 warnings.warn(
///                     'Possible nested set at position %d' % source.tell(),
///                     FutureWarning, stacklevel=nested + 6
///                 )
///             negate = sourcematch("^")
///             # check remaining characters
///             while True:
///                 this = sourceget()
///                 if this is None:
///                     raise source.error("unterminated character set",
///                                        source.tell() - here)
///                 if this == "]" and set:
///                     break
///                 elif this[0] == "\\":
///                     code1 = _class_escape(source, this)
///                 else:
///                     if set and this in '-&~|' and source.next == this:
///                         import warnings
///                         warnings.warn(
///                             'Possible set %s at position %d' % (
///                                 'difference' if this == '-' else
///                                 'intersection' if this == '&' else
///                                 'symmetric difference' if this == '~' else
///                                 'union',
///                                 source.tell() - 1),
///                             FutureWarning, stacklevel=nested + 6
///                         )
///                     code1 = LITERAL, _ord(this)
///                 if sourcematch("-"):
///                     # potential range
///                     that = sourceget()
///                     if that is None:
///                         raise source.error("unterminated character set",
///                                            source.tell() - here)
///                     if that == "]":
///                         if code1[0] is IN:
///                             code1 = code1[1][0]
///                         setappend(code1)
///                         setappend((LITERAL, _ord("-")))
///                         break
///                     if that[0] == "\\":
///                         code2 = _class_escape(source, that)
///                     else:
///                         if that == '-':
///                             import warnings
///                             warnings.warn(
///                                 'Possible set difference at position %d' % (
///                                     source.tell() - 2),
///                                 FutureWarning, stacklevel=nested + 6
///                             )
///                         code2 = LITERAL, _ord(that)
///                     if code1[0] != LITERAL or code2[0] != LITERAL:
///                         msg = "bad character range %s-%s" % (this, that)
///                         raise source.error(msg, len(this) + 1 + len(that))
///                     lo = code1[1]
///                     hi = code2[1]
///                     if hi < lo:
///                         msg = "bad character range %s-%s" % (this, that)
///                         raise source.error(msg, len(this) + 1 + len(that))
///                     setappend((RANGE, (lo, hi)))
///                 else:
///                     if code1[0] is IN:
///                         code1 = code1[1][0]
///                     setappend(code1)
///
///             set = _uniq(set)
///             # XXX: <fl> should move set optimization to compiler!
///             if _len(set) == 1 and set[0][0] is LITERAL:
///                 # optimization
///                 if negate:
///                     subpatternappend((NOT_LITERAL, set[0][1]))
///                 else:
///                     subpatternappend(set[0])
///             else:
///                 if negate:
///                     set.insert(0, (NEGATE, None))
///                 # charmap optimization can't be added here because
///                 # global flags still are not known
///                 subpatternappend((IN, set))
///
///         elif this in REPEAT_CHARS:
///             # repeat previous item
///             here = source.tell()
///             if this == "?":
///                 min, max = 0, 1
///             elif this == "*":
///                 min, max = 0, MAXREPEAT
///
///             elif this == "+":
///                 min, max = 1, MAXREPEAT
///             elif this == "{":
///                 if source.next == "}":
///                     subpatternappend((LITERAL, _ord(this)))
///                     continue
///
///                 min, max = 0, MAXREPEAT
///                 lo = hi = ""
///                 while source.next in DIGITS:
///                     lo += sourceget()
///                 if sourcematch(","):
///                     while source.next in DIGITS:
///                         hi += sourceget()
///                 else:
///                     hi = lo
///                 if not sourcematch("}"):
///                     subpatternappend((LITERAL, _ord(this)))
///                     source.seek(here)
///                     continue
///
///                 if lo:
///                     min = int(lo)
///                     if min >= MAXREPEAT:
///                         raise OverflowError("the repetition number is too large")
///                 if hi:
///                     max = int(hi)
///                     if max >= MAXREPEAT:
///                         raise OverflowError("the repetition number is too large")
///                     if max < min:
///                         raise source.error("min repeat greater than max repeat",
///                                            source.tell() - here)
///             else:
///                 raise AssertionError("unsupported quantifier %r" % (char,))
///             # figure out which item to repeat
///             if subpattern:
///                 item = subpattern[-1:]
///             else:
///                 item = None
///             if not item or item[0][0] is AT:
///                 raise source.error("nothing to repeat",
///                                    source.tell() - here + len(this))
///             if item[0][0] in _REPEATCODES:
///                 raise source.error("multiple repeat",
///                                    source.tell() - here + len(this))
///             if item[0][0] is SUBPATTERN:
///                 group, add_flags, del_flags, p = item[0][1]
///                 if group is None and not add_flags and not del_flags:
///                     item = p
///             if sourcematch("?"):
///                 # Non-Greedy Match
///                 subpattern[-1] = (MIN_REPEAT, (min, max, item))
///             elif sourcematch("+"):
///                 # Possessive Match (Always Greedy)
///                 subpattern[-1] = (POSSESSIVE_REPEAT, (min, max, item))
///             else:
///                 # Greedy Match
///                 subpattern[-1] = (MAX_REPEAT, (min, max, item))
///
///         elif this == ".":
///             subpatternappend((ANY, None))
///
///         elif this == "(":
///             start = source.tell() - 1
///             capture = True
///             atomic = False
///             name = None
///             add_flags = 0
///             del_flags = 0
///             if sourcematch("?"):
///                 # options
///                 char = sourceget()
///                 if char is None:
///                     raise source.error("unexpected end of pattern")
///                 if char == "P":
///                     # python extensions
///                     if sourcematch("<"):
///                         # named group: skip forward to end of name
///                         name = source.getuntil(">", "group name")
///                         source.checkgroupname(name, 1, nested)
///                     elif sourcematch("="):
///                         # named backreference
///                         name = source.getuntil(")", "group name")
///                         source.checkgroupname(name, 1, nested)
///                         gid = state.groupdict.get(name)
///                         if gid is None:
///                             msg = "unknown group name %r" % name
///                             raise source.error(msg, len(name) + 1)
///                         if not state.checkgroup(gid):
///                             raise source.error("cannot refer to an open group",
///                                                len(name) + 1)
///                         state.checklookbehindgroup(gid, source)
///                         subpatternappend((GROUPREF, gid))
///                         continue
///
///                     else:
///                         char = sourceget()
///                         if char is None:
///                             raise source.error("unexpected end of pattern")
///                         raise source.error("unknown extension ?P" + char,
///                                            len(char) + 2)
///                 elif char == ":":
///                     # non-capturing group
///                     capture = False
///                 elif char == "#":
///                     # comment
///                     while True:
///                         if source.next is None:
///                             raise source.error("missing ), unterminated comment",
///                                                source.tell() - start)
///                         if sourceget() == ")":
///                             break
///                     continue
///
///                 elif char in "=!<":
///                     # lookahead assertions
///                     dir = 1
///                     if char == "<":
///                         char = sourceget()
///                         if char is None:
///                             raise source.error("unexpected end of pattern")
///                         if char not in "=!":
///                             raise source.error("unknown extension ?<" + char,
///                                                len(char) + 2)
///                         dir = -1 # lookbehind
///                         lookbehindgroups = state.lookbehindgroups
///                         if lookbehindgroups is None:
///                             state.lookbehindgroups = state.groups
///                     p = _parse_sub(source, state, verbose, nested + 1)
///                     if dir < 0:
///                         if lookbehindgroups is None:
///                             state.lookbehindgroups = None
///                     if not sourcematch(")"):
///                         raise source.error("missing ), unterminated subpattern",
///                                            source.tell() - start)
///                     if char == "=":
///                         subpatternappend((ASSERT, (dir, p)))
///                     else:
///                         subpatternappend((ASSERT_NOT, (dir, p)))
///                     continue
///
///                 elif char == "(":
///                     # conditional backreference group
///                     condname = source.getuntil(")", "group name")
///                     if condname.isidentifier():
///                         source.checkgroupname(condname, 1, nested)
///                         condgroup = state.groupdict.get(condname)
///                         if condgroup is None:
///                             msg = "unknown group name %r" % condname
///                             raise source.error(msg, len(condname) + 1)
///                     else:
///                         try:
///                             condgroup = int(condname)
///                             if condgroup < 0:
///                                 raise ValueError
///                         except ValueError:
///                             msg = "bad character in group name %r" % condname
///                             raise source.error(msg, len(condname) + 1) from None
///                         if not condgroup:
///                             raise source.error("bad group number",
///                                                len(condname) + 1)
///                         if condgroup >= MAXGROUPS:
///                             msg = "invalid group reference %d" % condgroup
///                             raise source.error(msg, len(condname) + 1)
///                         if condgroup not in state.grouprefpos:
///                             state.grouprefpos[condgroup] = (
///                                 source.tell() - len(condname) - 1
///                             )
///                         if not (condname.isdecimal() and condname.isascii()):
///                             import warnings
///                             warnings.warn(
///                                 "bad character in group name %s at position %d" %
///                                 (repr(condname) if source.istext else ascii(condname),
///                                  source.tell() - len(condname) - 1),
///                                 DeprecationWarning, stacklevel=nested + 6
///                             )
///                     state.checklookbehindgroup(condgroup, source)
///                     item_yes = _parse(source, state, verbose, nested + 1)
///                     if source.match("|"):
///                         item_no = _parse(source, state, verbose, nested + 1)
///                         if source.next == "|":
///                             raise source.error("conditional backref with more than two branches")
///                     else:
///                         item_no = None
///                     if not source.match(")"):
///                         raise source.error("missing ), unterminated subpattern",
///                                            source.tell() - start)
///                     subpatternappend((GROUPREF_EXISTS, (condgroup, item_yes, item_no)))
///                     continue
///
///                 elif char == ">":
///                     # non-capturing, atomic group
///                     capture = False
///                     atomic = True
///                 elif char in FLAGS or char == "-":
///                     # flags
///                     flags = _parse_flags(source, state, char)
///                     if flags is None:  # global flags
///                         if not first or subpattern:
///                             raise source.error('global flags not at the start '
///                                                'of the expression',
///                                                source.tell() - start)
///                         verbose = state.flags & SRE_FLAG_VERBOSE
///                         continue
///
///                     add_flags, del_flags = flags
///                     capture = False
///                 else:
///                     raise source.error("unknown extension ?" + char,
///                                        len(char) + 1)
///
///             # parse group contents
///             if capture:
///                 try:
///                     group = state.opengroup(name)
///                 except error as err:
///                     raise source.error(err.msg, len(name) + 1) from None
///             else:
///                 group = None
///             sub_verbose = ((verbose or (add_flags & SRE_FLAG_VERBOSE)) and
///                            not (del_flags & SRE_FLAG_VERBOSE))
///             p = _parse_sub(source, state, sub_verbose, nested + 1)
///             if not source.match(")"):
///                 raise source.error("missing ), unterminated subpattern",
///                                    source.tell() - start)
///             if group is not None:
///                 state.closegroup(group, p)
///             if atomic:
///                 assert group is None
///                 subpatternappend((ATOMIC_GROUP, p))
///             else:
///                 subpatternappend((SUBPATTERN, (group, add_flags, del_flags, p)))
///
///         elif this == "^":
///             subpatternappend((AT, AT_BEGINNING))
///
///         elif this == "$":
///             subpatternappend((AT, AT_END))
///
///         else:
///             raise AssertionError("unsupported special character %r" % (char,))
///
///     # unpack non-capturing groups
///     for i in range(len(subpattern))[::-1]:
///         op, av = subpattern[i]
///         if op is SUBPATTERN:
///             group, add_flags, del_flags, p = av
///             if group is None and not add_flags and not del_flags:
///                 subpattern[i: i+1] = p
///
///     return subpattern
///
/// def _parse_flags(source, state, char):
///     sourceget = source.get
///     add_flags = 0
///     del_flags = 0
///     if char != "-":
///         while True:
///             flag = FLAGS[char]
///             if source.istext:
///                 if char == 'L':
///                     msg = "bad inline flags: cannot use 'L' flag with a str pattern"
///                     raise source.error(msg)
///             else:
///                 if char == 'u':
///                     msg = "bad inline flags: cannot use 'u' flag with a bytes pattern"
///                     raise source.error(msg)
///             add_flags |= flag
///             if (flag & TYPE_FLAGS) and (add_flags & TYPE_FLAGS) != flag:
///                 msg = "bad inline flags: flags 'a', 'u' and 'L' are incompatible"
///                 raise source.error(msg)
///             char = sourceget()
///             if char is None:
///                 raise source.error("missing -, : or )")
///             if char in ")-:":
///                 break
///             if char not in FLAGS:
///                 msg = "unknown flag" if char.isalpha() else "missing -, : or )"
///                 raise source.error(msg, len(char))
///     if char == ")":
///         state.flags |= add_flags
///         return None
///     if add_flags & GLOBAL_FLAGS:
///         raise source.error("bad inline flags: cannot turn on global flag", 1)
///     if char == "-":
///         char = sourceget()
///         if char is None:
///             raise source.error("missing flag")
///         if char not in FLAGS:
///             msg = "unknown flag" if char.isalpha() else "missing flag"
///             raise source.error(msg, len(char))
///         while True:
///             flag = FLAGS[char]
///             if flag & TYPE_FLAGS:
///                 msg = "bad inline flags: cannot turn off flags 'a', 'u' and 'L'"
///                 raise source.error(msg)
///             del_flags |= flag
///             char = sourceget()
///             if char is None:
///                 raise source.error("missing :")
///             if char == ":":
///                 break
///             if char not in FLAGS:
///                 msg = "unknown flag" if char.isalpha() else "missing :"
///                 raise source.error(msg, len(char))
///     assert char == ":"
///     if del_flags & GLOBAL_FLAGS:
///         raise source.error("bad inline flags: cannot turn off global flag", 1)
///     if add_flags & del_flags:
///         raise source.error("bad inline flags: flag turned on and off", 1)
///     return add_flags, del_flags
///
/// def fix_flags(src, flags):
///     # Check and fix flags according to the type of pattern (str or bytes)
///     if isinstance(src, str):
///         if flags & SRE_FLAG_LOCALE:
///             raise ValueError("cannot use LOCALE flag with a str pattern")
///         if not flags & SRE_FLAG_ASCII:
///             flags |= SRE_FLAG_UNICODE
///         elif flags & SRE_FLAG_UNICODE:
///             raise ValueError("ASCII and UNICODE flags are incompatible")
///     else:
///         if flags & SRE_FLAG_UNICODE:
///             raise ValueError("cannot use UNICODE flag with a bytes pattern")
///         if flags & SRE_FLAG_LOCALE and flags & SRE_FLAG_ASCII:
///             raise ValueError("ASCII and LOCALE flags are incompatible")
///     return flags
///
/// def parse(str, flags=0, state=None):
///     # parse 're' pattern into list of (opcode, argument) tuples
///
///     source = Tokenizer(str)
///
///     if state is None:
///         state = State()
///     state.flags = flags
///     state.str = str
///
///     p = _parse_sub(source, state, flags & SRE_FLAG_VERBOSE, 0)
///     p.state.flags = fix_flags(str, p.state.flags)
///
///     if source.next is not None:
///         assert source.next == ")"
///         raise source.error("unbalanced parenthesis")
///
///     for g in p.state.grouprefpos:
///         if g >= p.state.groups:
///             msg = "invalid group reference %d" % g
///             raise error(msg, str, p.state.grouprefpos[g])
///
///     if flags & SRE_FLAG_DEBUG:
///         p.dump()
///
///     return p
///
/// def parse_template(source, state):
///     # parse 're' replacement string into list of literals and
///     # group references
///     s = Tokenizer(source)
///     sget = s.get
///     groups = []
///     literals = []
///     literal = []
///     lappend = literal.append
///     def addgroup(index, pos):
///         if index > state.groups:
///             raise s.error("invalid group reference %d" % index, pos)
///         if literal:
///             literals.append(''.join(literal))
///             del literal[:]
///         groups.append((len(literals), index))
///         literals.append(None)
///     groupindex = state.groupindex
///     while True:
///         this = sget()
///         if this is None:
///             break # end of replacement string
///         if this[0] == "\\":
///             # group
///             c = this[1]
///             if c == "g":
///                 if not s.match("<"):
///                     raise s.error("missing <")
///                 name = s.getuntil(">", "group name")
///                 if name.isidentifier():
///                     s.checkgroupname(name, 1, -1)
///                     try:
///                         index = groupindex[name]
///                     except KeyError:
///                         raise IndexError("unknown group name %r" % name) from None
///                 else:
///                     try:
///                         index = int(name)
///                         if index < 0:
///                             raise ValueError
///                     except ValueError:
///                         raise s.error("bad character in group name %r" % name,
///                                       len(name) + 1) from None
///                     if index >= MAXGROUPS:
///                         raise s.error("invalid group reference %d" % index,
///                                       len(name) + 1)
///                     if not (name.isdecimal() and name.isascii()):
///                         import warnings
///                         warnings.warn(
///                             "bad character in group name %s at position %d" %
///                             (repr(name) if s.istext else ascii(name),
///                              s.tell() - len(name) - 1),
///                             DeprecationWarning, stacklevel=5
///                         )
///                 addgroup(index, len(name) + 1)
///             elif c == "0":
///                 if s.next in OCTDIGITS:
///                     this += sget()
///                     if s.next in OCTDIGITS:
///                         this += sget()
///                 lappend(chr(int(this[1:], 8) & 0xff))
///             elif c in DIGITS:
///                 isoctal = False
///                 if s.next in DIGITS:
///                     this += sget()
///                     if (c in OCTDIGITS and this[2] in OCTDIGITS and
///                         s.next in OCTDIGITS):
///                         this += sget()
///                         isoctal = True
///                         c = int(this[1:], 8)
///                         if c > 0o377:
///                             raise s.error('octal escape value %s outside of '
///                                           'range 0-0o377' % this, len(this))
///                         lappend(chr(c))
///                 if not isoctal:
///                     addgroup(int(this[1:]), len(this) - 1)
///             else:
///                 try:
///                     this = chr(ESCAPES[this][1])
///                 except KeyError:
///                     if c in ASCIILETTERS:
///                         raise s.error('bad escape %s' % this, len(this)) from None
///                 lappend(this)
///         else:
///             lappend(this)
///     if literal:
///         literals.append(''.join(literal))
///     if not isinstance(source, str):
///         # The tokenizer implicitly decodes bytes objects as latin-1, we must
///         # therefore re-encode the final representation.
///         literals = [None if s is None else s.encode('latin-1') for s in literals]
///     return groups, literals
///
/// def expand_template(template, match):
///     g = match.group
///     empty = match.string[:0]
///     groups, literals = template
///     literals = literals[:]
///     try:
///         for index, group in groups:
///             literals[index] = g(group) or empty
///     except IndexError:
///         raise error("invalid group reference %d" % index) from None
///     return empty.join(literals)
/// ```
final class sre_parse extends PythonModule {
  sre_parse.from(super.pythonModule) : super.from();

  static sre_parse import() => PythonFfiDart.instance.importModule(
        "re._parser",
        sre_parse.from,
      );

  /// ## expand_template
  ///
  /// ### python source
  /// ```py
  /// def expand_template(template, match):
  ///     g = match.group
  ///     empty = match.string[:0]
  ///     groups, literals = template
  ///     literals = literals[:]
  ///     try:
  ///         for index, group in groups:
  ///             literals[index] = g(group) or empty
  ///     except IndexError:
  ///         raise error("invalid group reference %d" % index) from None
  ///     return empty.join(literals)
  /// ```
  Object? expand_template({
    required Object? template,
    required Object? match,
  }) =>
      getFunction("expand_template").call(
        <Object?>[
          template,
          match,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## fix_flags
  ///
  /// ### python source
  /// ```py
  /// def fix_flags(src, flags):
  ///     # Check and fix flags according to the type of pattern (str or bytes)
  ///     if isinstance(src, str):
  ///         if flags & SRE_FLAG_LOCALE:
  ///             raise ValueError("cannot use LOCALE flag with a str pattern")
  ///         if not flags & SRE_FLAG_ASCII:
  ///             flags |= SRE_FLAG_UNICODE
  ///         elif flags & SRE_FLAG_UNICODE:
  ///             raise ValueError("ASCII and UNICODE flags are incompatible")
  ///     else:
  ///         if flags & SRE_FLAG_UNICODE:
  ///             raise ValueError("cannot use UNICODE flag with a bytes pattern")
  ///         if flags & SRE_FLAG_LOCALE and flags & SRE_FLAG_ASCII:
  ///             raise ValueError("ASCII and LOCALE flags are incompatible")
  ///     return flags
  /// ```
  Object? fix_flags({
    required Object? src,
    required Object? flags,
  }) =>
      getFunction("fix_flags").call(
        <Object?>[
          src,
          flags,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## parse
  ///
  /// ### python source
  /// ```py
  /// def parse(str, flags=0, state=None):
  ///     # parse 're' pattern into list of (opcode, argument) tuples
  ///
  ///     source = Tokenizer(str)
  ///
  ///     if state is None:
  ///         state = State()
  ///     state.flags = flags
  ///     state.str = str
  ///
  ///     p = _parse_sub(source, state, flags & SRE_FLAG_VERBOSE, 0)
  ///     p.state.flags = fix_flags(str, p.state.flags)
  ///
  ///     if source.next is not None:
  ///         assert source.next == ")"
  ///         raise source.error("unbalanced parenthesis")
  ///
  ///     for g in p.state.grouprefpos:
  ///         if g >= p.state.groups:
  ///             msg = "invalid group reference %d" % g
  ///             raise error(msg, str, p.state.grouprefpos[g])
  ///
  ///     if flags & SRE_FLAG_DEBUG:
  ///         p.dump()
  ///
  ///     return p
  /// ```
  Object? parse({
    required Object? str,
    Object? flags = 0,
    Object? state,
  }) =>
      getFunction("parse").call(
        <Object?>[
          str,
          flags,
          state,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## parse_template
  ///
  /// ### python source
  /// ```py
  /// def parse_template(source, state):
  ///     # parse 're' replacement string into list of literals and
  ///     # group references
  ///     s = Tokenizer(source)
  ///     sget = s.get
  ///     groups = []
  ///     literals = []
  ///     literal = []
  ///     lappend = literal.append
  ///     def addgroup(index, pos):
  ///         if index > state.groups:
  ///             raise s.error("invalid group reference %d" % index, pos)
  ///         if literal:
  ///             literals.append(''.join(literal))
  ///             del literal[:]
  ///         groups.append((len(literals), index))
  ///         literals.append(None)
  ///     groupindex = state.groupindex
  ///     while True:
  ///         this = sget()
  ///         if this is None:
  ///             break # end of replacement string
  ///         if this[0] == "\\":
  ///             # group
  ///             c = this[1]
  ///             if c == "g":
  ///                 if not s.match("<"):
  ///                     raise s.error("missing <")
  ///                 name = s.getuntil(">", "group name")
  ///                 if name.isidentifier():
  ///                     s.checkgroupname(name, 1, -1)
  ///                     try:
  ///                         index = groupindex[name]
  ///                     except KeyError:
  ///                         raise IndexError("unknown group name %r" % name) from None
  ///                 else:
  ///                     try:
  ///                         index = int(name)
  ///                         if index < 0:
  ///                             raise ValueError
  ///                     except ValueError:
  ///                         raise s.error("bad character in group name %r" % name,
  ///                                       len(name) + 1) from None
  ///                     if index >= MAXGROUPS:
  ///                         raise s.error("invalid group reference %d" % index,
  ///                                       len(name) + 1)
  ///                     if not (name.isdecimal() and name.isascii()):
  ///                         import warnings
  ///                         warnings.warn(
  ///                             "bad character in group name %s at position %d" %
  ///                             (repr(name) if s.istext else ascii(name),
  ///                              s.tell() - len(name) - 1),
  ///                             DeprecationWarning, stacklevel=5
  ///                         )
  ///                 addgroup(index, len(name) + 1)
  ///             elif c == "0":
  ///                 if s.next in OCTDIGITS:
  ///                     this += sget()
  ///                     if s.next in OCTDIGITS:
  ///                         this += sget()
  ///                 lappend(chr(int(this[1:], 8) & 0xff))
  ///             elif c in DIGITS:
  ///                 isoctal = False
  ///                 if s.next in DIGITS:
  ///                     this += sget()
  ///                     if (c in OCTDIGITS and this[2] in OCTDIGITS and
  ///                         s.next in OCTDIGITS):
  ///                         this += sget()
  ///                         isoctal = True
  ///                         c = int(this[1:], 8)
  ///                         if c > 0o377:
  ///                             raise s.error('octal escape value %s outside of '
  ///                                           'range 0-0o377' % this, len(this))
  ///                         lappend(chr(c))
  ///                 if not isoctal:
  ///                     addgroup(int(this[1:]), len(this) - 1)
  ///             else:
  ///                 try:
  ///                     this = chr(ESCAPES[this][1])
  ///                 except KeyError:
  ///                     if c in ASCIILETTERS:
  ///                         raise s.error('bad escape %s' % this, len(this)) from None
  ///                 lappend(this)
  ///         else:
  ///             lappend(this)
  ///     if literal:
  ///         literals.append(''.join(literal))
  ///     if not isinstance(source, str):
  ///         # The tokenizer implicitly decodes bytes objects as latin-1, we must
  ///         # therefore re-encode the final representation.
  ///         literals = [None if s is None else s.encode('latin-1') for s in literals]
  ///     return groups, literals
  /// ```
  Object? parse_template({
    required Object? source,
    required Object? state,
  }) =>
      getFunction("parse_template").call(
        <Object?>[
          source,
          state,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## ANY (getter)
  Object? get ANY => getAttribute("ANY");

  /// ## ANY (setter)
  set ANY(Object? ANY) => setAttribute("ANY", ANY);

  /// ## ANY_ALL (getter)
  Object? get ANY_ALL => getAttribute("ANY_ALL");

  /// ## ANY_ALL (setter)
  set ANY_ALL(Object? ANY_ALL) => setAttribute("ANY_ALL", ANY_ALL);

  /// ## ASSERT (getter)
  Object? get ASSERT => getAttribute("ASSERT");

  /// ## ASSERT (setter)
  set ASSERT(Object? ASSERT) => setAttribute("ASSERT", ASSERT);

  /// ## ASSERT_NOT (getter)
  Object? get ASSERT_NOT => getAttribute("ASSERT_NOT");

  /// ## ASSERT_NOT (setter)
  set ASSERT_NOT(Object? ASSERT_NOT) => setAttribute("ASSERT_NOT", ASSERT_NOT);

  /// ## AT (getter)
  Object? get AT => getAttribute("AT");

  /// ## AT (setter)
  set AT(Object? AT) => setAttribute("AT", AT);

  /// ## ATCODES (getter)
  Object? get ATCODES => getAttribute("ATCODES");

  /// ## ATCODES (setter)
  set ATCODES(Object? ATCODES) => setAttribute("ATCODES", ATCODES);

  /// ## ATOMIC_GROUP (getter)
  Object? get ATOMIC_GROUP => getAttribute("ATOMIC_GROUP");

  /// ## ATOMIC_GROUP (setter)
  set ATOMIC_GROUP(Object? ATOMIC_GROUP) =>
      setAttribute("ATOMIC_GROUP", ATOMIC_GROUP);

  /// ## AT_BEGINNING (getter)
  Object? get AT_BEGINNING => getAttribute("AT_BEGINNING");

  /// ## AT_BEGINNING (setter)
  set AT_BEGINNING(Object? AT_BEGINNING) =>
      setAttribute("AT_BEGINNING", AT_BEGINNING);

  /// ## AT_BEGINNING_LINE (getter)
  Object? get AT_BEGINNING_LINE => getAttribute("AT_BEGINNING_LINE");

  /// ## AT_BEGINNING_LINE (setter)
  set AT_BEGINNING_LINE(Object? AT_BEGINNING_LINE) =>
      setAttribute("AT_BEGINNING_LINE", AT_BEGINNING_LINE);

  /// ## AT_BEGINNING_STRING (getter)
  Object? get AT_BEGINNING_STRING => getAttribute("AT_BEGINNING_STRING");

  /// ## AT_BEGINNING_STRING (setter)
  set AT_BEGINNING_STRING(Object? AT_BEGINNING_STRING) =>
      setAttribute("AT_BEGINNING_STRING", AT_BEGINNING_STRING);

  /// ## AT_BOUNDARY (getter)
  Object? get AT_BOUNDARY => getAttribute("AT_BOUNDARY");

  /// ## AT_BOUNDARY (setter)
  set AT_BOUNDARY(Object? AT_BOUNDARY) =>
      setAttribute("AT_BOUNDARY", AT_BOUNDARY);

  /// ## AT_END (getter)
  Object? get AT_END => getAttribute("AT_END");

  /// ## AT_END (setter)
  set AT_END(Object? AT_END) => setAttribute("AT_END", AT_END);

  /// ## AT_END_LINE (getter)
  Object? get AT_END_LINE => getAttribute("AT_END_LINE");

  /// ## AT_END_LINE (setter)
  set AT_END_LINE(Object? AT_END_LINE) =>
      setAttribute("AT_END_LINE", AT_END_LINE);

  /// ## AT_END_STRING (getter)
  Object? get AT_END_STRING => getAttribute("AT_END_STRING");

  /// ## AT_END_STRING (setter)
  set AT_END_STRING(Object? AT_END_STRING) =>
      setAttribute("AT_END_STRING", AT_END_STRING);

  /// ## AT_LOCALE (getter)
  Object? get AT_LOCALE => getAttribute("AT_LOCALE");

  /// ## AT_LOCALE (setter)
  set AT_LOCALE(Object? AT_LOCALE) => setAttribute("AT_LOCALE", AT_LOCALE);

  /// ## AT_LOC_BOUNDARY (getter)
  Object? get AT_LOC_BOUNDARY => getAttribute("AT_LOC_BOUNDARY");

  /// ## AT_LOC_BOUNDARY (setter)
  set AT_LOC_BOUNDARY(Object? AT_LOC_BOUNDARY) =>
      setAttribute("AT_LOC_BOUNDARY", AT_LOC_BOUNDARY);

  /// ## AT_LOC_NON_BOUNDARY (getter)
  Object? get AT_LOC_NON_BOUNDARY => getAttribute("AT_LOC_NON_BOUNDARY");

  /// ## AT_LOC_NON_BOUNDARY (setter)
  set AT_LOC_NON_BOUNDARY(Object? AT_LOC_NON_BOUNDARY) =>
      setAttribute("AT_LOC_NON_BOUNDARY", AT_LOC_NON_BOUNDARY);

  /// ## AT_MULTILINE (getter)
  Object? get AT_MULTILINE => getAttribute("AT_MULTILINE");

  /// ## AT_MULTILINE (setter)
  set AT_MULTILINE(Object? AT_MULTILINE) =>
      setAttribute("AT_MULTILINE", AT_MULTILINE);

  /// ## AT_NON_BOUNDARY (getter)
  Object? get AT_NON_BOUNDARY => getAttribute("AT_NON_BOUNDARY");

  /// ## AT_NON_BOUNDARY (setter)
  set AT_NON_BOUNDARY(Object? AT_NON_BOUNDARY) =>
      setAttribute("AT_NON_BOUNDARY", AT_NON_BOUNDARY);

  /// ## AT_UNICODE (getter)
  Object? get AT_UNICODE => getAttribute("AT_UNICODE");

  /// ## AT_UNICODE (setter)
  set AT_UNICODE(Object? AT_UNICODE) => setAttribute("AT_UNICODE", AT_UNICODE);

  /// ## AT_UNI_BOUNDARY (getter)
  Object? get AT_UNI_BOUNDARY => getAttribute("AT_UNI_BOUNDARY");

  /// ## AT_UNI_BOUNDARY (setter)
  set AT_UNI_BOUNDARY(Object? AT_UNI_BOUNDARY) =>
      setAttribute("AT_UNI_BOUNDARY", AT_UNI_BOUNDARY);

  /// ## AT_UNI_NON_BOUNDARY (getter)
  Object? get AT_UNI_NON_BOUNDARY => getAttribute("AT_UNI_NON_BOUNDARY");

  /// ## AT_UNI_NON_BOUNDARY (setter)
  set AT_UNI_NON_BOUNDARY(Object? AT_UNI_NON_BOUNDARY) =>
      setAttribute("AT_UNI_NON_BOUNDARY", AT_UNI_NON_BOUNDARY);

  /// ## BIGCHARSET (getter)
  Object? get BIGCHARSET => getAttribute("BIGCHARSET");

  /// ## BIGCHARSET (setter)
  set BIGCHARSET(Object? BIGCHARSET) => setAttribute("BIGCHARSET", BIGCHARSET);

  /// ## BRANCH (getter)
  Object? get BRANCH => getAttribute("BRANCH");

  /// ## BRANCH (setter)
  set BRANCH(Object? BRANCH) => setAttribute("BRANCH", BRANCH);

  /// ## CATEGORIES (getter)
  Object? get CATEGORIES => getAttribute("CATEGORIES");

  /// ## CATEGORIES (setter)
  set CATEGORIES(Object? CATEGORIES) => setAttribute("CATEGORIES", CATEGORIES);

  /// ## CATEGORY (getter)
  Object? get CATEGORY => getAttribute("CATEGORY");

  /// ## CATEGORY (setter)
  set CATEGORY(Object? CATEGORY) => setAttribute("CATEGORY", CATEGORY);

  /// ## CATEGORY_DIGIT (getter)
  Object? get CATEGORY_DIGIT => getAttribute("CATEGORY_DIGIT");

  /// ## CATEGORY_DIGIT (setter)
  set CATEGORY_DIGIT(Object? CATEGORY_DIGIT) =>
      setAttribute("CATEGORY_DIGIT", CATEGORY_DIGIT);

  /// ## CATEGORY_LINEBREAK (getter)
  Object? get CATEGORY_LINEBREAK => getAttribute("CATEGORY_LINEBREAK");

  /// ## CATEGORY_LINEBREAK (setter)
  set CATEGORY_LINEBREAK(Object? CATEGORY_LINEBREAK) =>
      setAttribute("CATEGORY_LINEBREAK", CATEGORY_LINEBREAK);

  /// ## CATEGORY_LOC_NOT_WORD (getter)
  Object? get CATEGORY_LOC_NOT_WORD => getAttribute("CATEGORY_LOC_NOT_WORD");

  /// ## CATEGORY_LOC_NOT_WORD (setter)
  set CATEGORY_LOC_NOT_WORD(Object? CATEGORY_LOC_NOT_WORD) =>
      setAttribute("CATEGORY_LOC_NOT_WORD", CATEGORY_LOC_NOT_WORD);

  /// ## CATEGORY_LOC_WORD (getter)
  Object? get CATEGORY_LOC_WORD => getAttribute("CATEGORY_LOC_WORD");

  /// ## CATEGORY_LOC_WORD (setter)
  set CATEGORY_LOC_WORD(Object? CATEGORY_LOC_WORD) =>
      setAttribute("CATEGORY_LOC_WORD", CATEGORY_LOC_WORD);

  /// ## CATEGORY_NOT_DIGIT (getter)
  Object? get CATEGORY_NOT_DIGIT => getAttribute("CATEGORY_NOT_DIGIT");

  /// ## CATEGORY_NOT_DIGIT (setter)
  set CATEGORY_NOT_DIGIT(Object? CATEGORY_NOT_DIGIT) =>
      setAttribute("CATEGORY_NOT_DIGIT", CATEGORY_NOT_DIGIT);

  /// ## CATEGORY_NOT_LINEBREAK (getter)
  Object? get CATEGORY_NOT_LINEBREAK => getAttribute("CATEGORY_NOT_LINEBREAK");

  /// ## CATEGORY_NOT_LINEBREAK (setter)
  set CATEGORY_NOT_LINEBREAK(Object? CATEGORY_NOT_LINEBREAK) =>
      setAttribute("CATEGORY_NOT_LINEBREAK", CATEGORY_NOT_LINEBREAK);

  /// ## CATEGORY_NOT_SPACE (getter)
  Object? get CATEGORY_NOT_SPACE => getAttribute("CATEGORY_NOT_SPACE");

  /// ## CATEGORY_NOT_SPACE (setter)
  set CATEGORY_NOT_SPACE(Object? CATEGORY_NOT_SPACE) =>
      setAttribute("CATEGORY_NOT_SPACE", CATEGORY_NOT_SPACE);

  /// ## CATEGORY_NOT_WORD (getter)
  Object? get CATEGORY_NOT_WORD => getAttribute("CATEGORY_NOT_WORD");

  /// ## CATEGORY_NOT_WORD (setter)
  set CATEGORY_NOT_WORD(Object? CATEGORY_NOT_WORD) =>
      setAttribute("CATEGORY_NOT_WORD", CATEGORY_NOT_WORD);

  /// ## CATEGORY_SPACE (getter)
  Object? get CATEGORY_SPACE => getAttribute("CATEGORY_SPACE");

  /// ## CATEGORY_SPACE (setter)
  set CATEGORY_SPACE(Object? CATEGORY_SPACE) =>
      setAttribute("CATEGORY_SPACE", CATEGORY_SPACE);

  /// ## CATEGORY_UNI_DIGIT (getter)
  Object? get CATEGORY_UNI_DIGIT => getAttribute("CATEGORY_UNI_DIGIT");

  /// ## CATEGORY_UNI_DIGIT (setter)
  set CATEGORY_UNI_DIGIT(Object? CATEGORY_UNI_DIGIT) =>
      setAttribute("CATEGORY_UNI_DIGIT", CATEGORY_UNI_DIGIT);

  /// ## CATEGORY_UNI_LINEBREAK (getter)
  Object? get CATEGORY_UNI_LINEBREAK => getAttribute("CATEGORY_UNI_LINEBREAK");

  /// ## CATEGORY_UNI_LINEBREAK (setter)
  set CATEGORY_UNI_LINEBREAK(Object? CATEGORY_UNI_LINEBREAK) =>
      setAttribute("CATEGORY_UNI_LINEBREAK", CATEGORY_UNI_LINEBREAK);

  /// ## CATEGORY_UNI_NOT_DIGIT (getter)
  Object? get CATEGORY_UNI_NOT_DIGIT => getAttribute("CATEGORY_UNI_NOT_DIGIT");

  /// ## CATEGORY_UNI_NOT_DIGIT (setter)
  set CATEGORY_UNI_NOT_DIGIT(Object? CATEGORY_UNI_NOT_DIGIT) =>
      setAttribute("CATEGORY_UNI_NOT_DIGIT", CATEGORY_UNI_NOT_DIGIT);

  /// ## CATEGORY_UNI_NOT_LINEBREAK (getter)
  Object? get CATEGORY_UNI_NOT_LINEBREAK =>
      getAttribute("CATEGORY_UNI_NOT_LINEBREAK");

  /// ## CATEGORY_UNI_NOT_LINEBREAK (setter)
  set CATEGORY_UNI_NOT_LINEBREAK(Object? CATEGORY_UNI_NOT_LINEBREAK) =>
      setAttribute("CATEGORY_UNI_NOT_LINEBREAK", CATEGORY_UNI_NOT_LINEBREAK);

  /// ## CATEGORY_UNI_NOT_SPACE (getter)
  Object? get CATEGORY_UNI_NOT_SPACE => getAttribute("CATEGORY_UNI_NOT_SPACE");

  /// ## CATEGORY_UNI_NOT_SPACE (setter)
  set CATEGORY_UNI_NOT_SPACE(Object? CATEGORY_UNI_NOT_SPACE) =>
      setAttribute("CATEGORY_UNI_NOT_SPACE", CATEGORY_UNI_NOT_SPACE);

  /// ## CATEGORY_UNI_NOT_WORD (getter)
  Object? get CATEGORY_UNI_NOT_WORD => getAttribute("CATEGORY_UNI_NOT_WORD");

  /// ## CATEGORY_UNI_NOT_WORD (setter)
  set CATEGORY_UNI_NOT_WORD(Object? CATEGORY_UNI_NOT_WORD) =>
      setAttribute("CATEGORY_UNI_NOT_WORD", CATEGORY_UNI_NOT_WORD);

  /// ## CATEGORY_UNI_SPACE (getter)
  Object? get CATEGORY_UNI_SPACE => getAttribute("CATEGORY_UNI_SPACE");

  /// ## CATEGORY_UNI_SPACE (setter)
  set CATEGORY_UNI_SPACE(Object? CATEGORY_UNI_SPACE) =>
      setAttribute("CATEGORY_UNI_SPACE", CATEGORY_UNI_SPACE);

  /// ## CATEGORY_UNI_WORD (getter)
  Object? get CATEGORY_UNI_WORD => getAttribute("CATEGORY_UNI_WORD");

  /// ## CATEGORY_UNI_WORD (setter)
  set CATEGORY_UNI_WORD(Object? CATEGORY_UNI_WORD) =>
      setAttribute("CATEGORY_UNI_WORD", CATEGORY_UNI_WORD);

  /// ## CATEGORY_WORD (getter)
  Object? get CATEGORY_WORD => getAttribute("CATEGORY_WORD");

  /// ## CATEGORY_WORD (setter)
  set CATEGORY_WORD(Object? CATEGORY_WORD) =>
      setAttribute("CATEGORY_WORD", CATEGORY_WORD);

  /// ## CHARSET (getter)
  Object? get CHARSET => getAttribute("CHARSET");

  /// ## CHARSET (setter)
  set CHARSET(Object? CHARSET) => setAttribute("CHARSET", CHARSET);

  /// ## CHCODES (getter)
  Object? get CHCODES => getAttribute("CHCODES");

  /// ## CHCODES (setter)
  set CHCODES(Object? CHCODES) => setAttribute("CHCODES", CHCODES);

  /// ## CH_LOCALE (getter)
  Object? get CH_LOCALE => getAttribute("CH_LOCALE");

  /// ## CH_LOCALE (setter)
  set CH_LOCALE(Object? CH_LOCALE) => setAttribute("CH_LOCALE", CH_LOCALE);

  /// ## CH_UNICODE (getter)
  Object? get CH_UNICODE => getAttribute("CH_UNICODE");

  /// ## CH_UNICODE (setter)
  set CH_UNICODE(Object? CH_UNICODE) => setAttribute("CH_UNICODE", CH_UNICODE);

  /// ## ESCAPES (getter)
  Object? get ESCAPES => getAttribute("ESCAPES");

  /// ## ESCAPES (setter)
  set ESCAPES(Object? ESCAPES) => setAttribute("ESCAPES", ESCAPES);

  /// ## FAILURE (getter)
  Object? get FAILURE => getAttribute("FAILURE");

  /// ## FAILURE (setter)
  set FAILURE(Object? FAILURE) => setAttribute("FAILURE", FAILURE);

  /// ## FLAGS (getter)
  Object? get FLAGS => getAttribute("FLAGS");

  /// ## FLAGS (setter)
  set FLAGS(Object? FLAGS) => setAttribute("FLAGS", FLAGS);

  /// ## GLOBAL_FLAGS (getter)
  Object? get GLOBAL_FLAGS => getAttribute("GLOBAL_FLAGS");

  /// ## GLOBAL_FLAGS (setter)
  set GLOBAL_FLAGS(Object? GLOBAL_FLAGS) =>
      setAttribute("GLOBAL_FLAGS", GLOBAL_FLAGS);

  /// ## GROUPREF (getter)
  Object? get GROUPREF => getAttribute("GROUPREF");

  /// ## GROUPREF (setter)
  set GROUPREF(Object? GROUPREF) => setAttribute("GROUPREF", GROUPREF);

  /// ## GROUPREF_EXISTS (getter)
  Object? get GROUPREF_EXISTS => getAttribute("GROUPREF_EXISTS");

  /// ## GROUPREF_EXISTS (setter)
  set GROUPREF_EXISTS(Object? GROUPREF_EXISTS) =>
      setAttribute("GROUPREF_EXISTS", GROUPREF_EXISTS);

  /// ## GROUPREF_IGNORE (getter)
  Object? get GROUPREF_IGNORE => getAttribute("GROUPREF_IGNORE");

  /// ## GROUPREF_IGNORE (setter)
  set GROUPREF_IGNORE(Object? GROUPREF_IGNORE) =>
      setAttribute("GROUPREF_IGNORE", GROUPREF_IGNORE);

  /// ## GROUPREF_LOC_IGNORE (getter)
  Object? get GROUPREF_LOC_IGNORE => getAttribute("GROUPREF_LOC_IGNORE");

  /// ## GROUPREF_LOC_IGNORE (setter)
  set GROUPREF_LOC_IGNORE(Object? GROUPREF_LOC_IGNORE) =>
      setAttribute("GROUPREF_LOC_IGNORE", GROUPREF_LOC_IGNORE);

  /// ## GROUPREF_UNI_IGNORE (getter)
  Object? get GROUPREF_UNI_IGNORE => getAttribute("GROUPREF_UNI_IGNORE");

  /// ## GROUPREF_UNI_IGNORE (setter)
  set GROUPREF_UNI_IGNORE(Object? GROUPREF_UNI_IGNORE) =>
      setAttribute("GROUPREF_UNI_IGNORE", GROUPREF_UNI_IGNORE);

  /// ## IN (getter)
  Object? get IN => getAttribute("IN");

  /// ## IN (setter)
  set IN(Object? IN) => setAttribute("IN", IN);

  /// ## INFO (getter)
  Object? get INFO => getAttribute("INFO");

  /// ## INFO (setter)
  set INFO(Object? INFO) => setAttribute("INFO", INFO);

  /// ## IN_IGNORE (getter)
  Object? get IN_IGNORE => getAttribute("IN_IGNORE");

  /// ## IN_IGNORE (setter)
  set IN_IGNORE(Object? IN_IGNORE) => setAttribute("IN_IGNORE", IN_IGNORE);

  /// ## IN_LOC_IGNORE (getter)
  Object? get IN_LOC_IGNORE => getAttribute("IN_LOC_IGNORE");

  /// ## IN_LOC_IGNORE (setter)
  set IN_LOC_IGNORE(Object? IN_LOC_IGNORE) =>
      setAttribute("IN_LOC_IGNORE", IN_LOC_IGNORE);

  /// ## IN_UNI_IGNORE (getter)
  Object? get IN_UNI_IGNORE => getAttribute("IN_UNI_IGNORE");

  /// ## IN_UNI_IGNORE (setter)
  set IN_UNI_IGNORE(Object? IN_UNI_IGNORE) =>
      setAttribute("IN_UNI_IGNORE", IN_UNI_IGNORE);

  /// ## JUMP (getter)
  Object? get JUMP => getAttribute("JUMP");

  /// ## JUMP (setter)
  set JUMP(Object? JUMP) => setAttribute("JUMP", JUMP);

  /// ## LITERAL (getter)
  Object? get LITERAL => getAttribute("LITERAL");

  /// ## LITERAL (setter)
  set LITERAL(Object? LITERAL) => setAttribute("LITERAL", LITERAL);

  /// ## LITERAL_IGNORE (getter)
  Object? get LITERAL_IGNORE => getAttribute("LITERAL_IGNORE");

  /// ## LITERAL_IGNORE (setter)
  set LITERAL_IGNORE(Object? LITERAL_IGNORE) =>
      setAttribute("LITERAL_IGNORE", LITERAL_IGNORE);

  /// ## LITERAL_LOC_IGNORE (getter)
  Object? get LITERAL_LOC_IGNORE => getAttribute("LITERAL_LOC_IGNORE");

  /// ## LITERAL_LOC_IGNORE (setter)
  set LITERAL_LOC_IGNORE(Object? LITERAL_LOC_IGNORE) =>
      setAttribute("LITERAL_LOC_IGNORE", LITERAL_LOC_IGNORE);

  /// ## LITERAL_UNI_IGNORE (getter)
  Object? get LITERAL_UNI_IGNORE => getAttribute("LITERAL_UNI_IGNORE");

  /// ## LITERAL_UNI_IGNORE (setter)
  set LITERAL_UNI_IGNORE(Object? LITERAL_UNI_IGNORE) =>
      setAttribute("LITERAL_UNI_IGNORE", LITERAL_UNI_IGNORE);

  /// ## MAGIC (getter)
  Object? get MAGIC => getAttribute("MAGIC");

  /// ## MAGIC (setter)
  set MAGIC(Object? MAGIC) => setAttribute("MAGIC", MAGIC);

  /// ## MARK (getter)
  Object? get MARK => getAttribute("MARK");

  /// ## MARK (setter)
  set MARK(Object? MARK) => setAttribute("MARK", MARK);

  /// ## MAXGROUPS (getter)
  Object? get MAXGROUPS => getAttribute("MAXGROUPS");

  /// ## MAXGROUPS (setter)
  set MAXGROUPS(Object? MAXGROUPS) => setAttribute("MAXGROUPS", MAXGROUPS);

  /// ## MAXREPEAT (getter)
  Object? get MAXREPEAT => getAttribute("MAXREPEAT");

  /// ## MAXREPEAT (setter)
  set MAXREPEAT(Object? MAXREPEAT) => setAttribute("MAXREPEAT", MAXREPEAT);

  /// ## MAX_REPEAT (getter)
  Object? get MAX_REPEAT => getAttribute("MAX_REPEAT");

  /// ## MAX_REPEAT (setter)
  set MAX_REPEAT(Object? MAX_REPEAT) => setAttribute("MAX_REPEAT", MAX_REPEAT);

  /// ## MAX_UNTIL (getter)
  Object? get MAX_UNTIL => getAttribute("MAX_UNTIL");

  /// ## MAX_UNTIL (setter)
  set MAX_UNTIL(Object? MAX_UNTIL) => setAttribute("MAX_UNTIL", MAX_UNTIL);

  /// ## MIN_REPEAT (getter)
  Object? get MIN_REPEAT => getAttribute("MIN_REPEAT");

  /// ## MIN_REPEAT (setter)
  set MIN_REPEAT(Object? MIN_REPEAT) => setAttribute("MIN_REPEAT", MIN_REPEAT);

  /// ## MIN_REPEAT_ONE (getter)
  Object? get MIN_REPEAT_ONE => getAttribute("MIN_REPEAT_ONE");

  /// ## MIN_REPEAT_ONE (setter)
  set MIN_REPEAT_ONE(Object? MIN_REPEAT_ONE) =>
      setAttribute("MIN_REPEAT_ONE", MIN_REPEAT_ONE);

  /// ## MIN_UNTIL (getter)
  Object? get MIN_UNTIL => getAttribute("MIN_UNTIL");

  /// ## MIN_UNTIL (setter)
  set MIN_UNTIL(Object? MIN_UNTIL) => setAttribute("MIN_UNTIL", MIN_UNTIL);

  /// ## NEGATE (getter)
  Object? get NEGATE => getAttribute("NEGATE");

  /// ## NEGATE (setter)
  set NEGATE(Object? NEGATE) => setAttribute("NEGATE", NEGATE);

  /// ## NOT_LITERAL (getter)
  Object? get NOT_LITERAL => getAttribute("NOT_LITERAL");

  /// ## NOT_LITERAL (setter)
  set NOT_LITERAL(Object? NOT_LITERAL) =>
      setAttribute("NOT_LITERAL", NOT_LITERAL);

  /// ## NOT_LITERAL_IGNORE (getter)
  Object? get NOT_LITERAL_IGNORE => getAttribute("NOT_LITERAL_IGNORE");

  /// ## NOT_LITERAL_IGNORE (setter)
  set NOT_LITERAL_IGNORE(Object? NOT_LITERAL_IGNORE) =>
      setAttribute("NOT_LITERAL_IGNORE", NOT_LITERAL_IGNORE);

  /// ## NOT_LITERAL_LOC_IGNORE (getter)
  Object? get NOT_LITERAL_LOC_IGNORE => getAttribute("NOT_LITERAL_LOC_IGNORE");

  /// ## NOT_LITERAL_LOC_IGNORE (setter)
  set NOT_LITERAL_LOC_IGNORE(Object? NOT_LITERAL_LOC_IGNORE) =>
      setAttribute("NOT_LITERAL_LOC_IGNORE", NOT_LITERAL_LOC_IGNORE);

  /// ## NOT_LITERAL_UNI_IGNORE (getter)
  Object? get NOT_LITERAL_UNI_IGNORE => getAttribute("NOT_LITERAL_UNI_IGNORE");

  /// ## NOT_LITERAL_UNI_IGNORE (setter)
  set NOT_LITERAL_UNI_IGNORE(Object? NOT_LITERAL_UNI_IGNORE) =>
      setAttribute("NOT_LITERAL_UNI_IGNORE", NOT_LITERAL_UNI_IGNORE);

  /// ## OPCODES (getter)
  Object? get OPCODES => getAttribute("OPCODES");

  /// ## OPCODES (setter)
  set OPCODES(Object? OPCODES) => setAttribute("OPCODES", OPCODES);

  /// ## OP_IGNORE (getter)
  Object? get OP_IGNORE => getAttribute("OP_IGNORE");

  /// ## OP_IGNORE (setter)
  set OP_IGNORE(Object? OP_IGNORE) => setAttribute("OP_IGNORE", OP_IGNORE);

  /// ## OP_LOCALE_IGNORE (getter)
  Object? get OP_LOCALE_IGNORE => getAttribute("OP_LOCALE_IGNORE");

  /// ## OP_LOCALE_IGNORE (setter)
  set OP_LOCALE_IGNORE(Object? OP_LOCALE_IGNORE) =>
      setAttribute("OP_LOCALE_IGNORE", OP_LOCALE_IGNORE);

  /// ## OP_UNICODE_IGNORE (getter)
  Object? get OP_UNICODE_IGNORE => getAttribute("OP_UNICODE_IGNORE");

  /// ## OP_UNICODE_IGNORE (setter)
  set OP_UNICODE_IGNORE(Object? OP_UNICODE_IGNORE) =>
      setAttribute("OP_UNICODE_IGNORE", OP_UNICODE_IGNORE);

  /// ## POSSESSIVE_REPEAT (getter)
  Object? get POSSESSIVE_REPEAT => getAttribute("POSSESSIVE_REPEAT");

  /// ## POSSESSIVE_REPEAT (setter)
  set POSSESSIVE_REPEAT(Object? POSSESSIVE_REPEAT) =>
      setAttribute("POSSESSIVE_REPEAT", POSSESSIVE_REPEAT);

  /// ## POSSESSIVE_REPEAT_ONE (getter)
  Object? get POSSESSIVE_REPEAT_ONE => getAttribute("POSSESSIVE_REPEAT_ONE");

  /// ## POSSESSIVE_REPEAT_ONE (setter)
  set POSSESSIVE_REPEAT_ONE(Object? POSSESSIVE_REPEAT_ONE) =>
      setAttribute("POSSESSIVE_REPEAT_ONE", POSSESSIVE_REPEAT_ONE);

  /// ## RANGE (getter)
  Object? get RANGE => getAttribute("RANGE");

  /// ## RANGE (setter)
  set RANGE(Object? RANGE) => setAttribute("RANGE", RANGE);

  /// ## RANGE_UNI_IGNORE (getter)
  Object? get RANGE_UNI_IGNORE => getAttribute("RANGE_UNI_IGNORE");

  /// ## RANGE_UNI_IGNORE (setter)
  set RANGE_UNI_IGNORE(Object? RANGE_UNI_IGNORE) =>
      setAttribute("RANGE_UNI_IGNORE", RANGE_UNI_IGNORE);

  /// ## REPEAT (getter)
  Object? get REPEAT => getAttribute("REPEAT");

  /// ## REPEAT (setter)
  set REPEAT(Object? REPEAT) => setAttribute("REPEAT", REPEAT);

  /// ## REPEAT_CHARS (getter)
  Object? get REPEAT_CHARS => getAttribute("REPEAT_CHARS");

  /// ## REPEAT_CHARS (setter)
  set REPEAT_CHARS(Object? REPEAT_CHARS) =>
      setAttribute("REPEAT_CHARS", REPEAT_CHARS);

  /// ## REPEAT_ONE (getter)
  Object? get REPEAT_ONE => getAttribute("REPEAT_ONE");

  /// ## REPEAT_ONE (setter)
  set REPEAT_ONE(Object? REPEAT_ONE) => setAttribute("REPEAT_ONE", REPEAT_ONE);

  /// ## SPECIAL_CHARS (getter)
  Object? get SPECIAL_CHARS => getAttribute("SPECIAL_CHARS");

  /// ## SPECIAL_CHARS (setter)
  set SPECIAL_CHARS(Object? SPECIAL_CHARS) =>
      setAttribute("SPECIAL_CHARS", SPECIAL_CHARS);

  /// ## SRE_FLAG_ASCII (getter)
  Object? get SRE_FLAG_ASCII => getAttribute("SRE_FLAG_ASCII");

  /// ## SRE_FLAG_ASCII (setter)
  set SRE_FLAG_ASCII(Object? SRE_FLAG_ASCII) =>
      setAttribute("SRE_FLAG_ASCII", SRE_FLAG_ASCII);

  /// ## SRE_FLAG_DEBUG (getter)
  Object? get SRE_FLAG_DEBUG => getAttribute("SRE_FLAG_DEBUG");

  /// ## SRE_FLAG_DEBUG (setter)
  set SRE_FLAG_DEBUG(Object? SRE_FLAG_DEBUG) =>
      setAttribute("SRE_FLAG_DEBUG", SRE_FLAG_DEBUG);

  /// ## SRE_FLAG_DOTALL (getter)
  Object? get SRE_FLAG_DOTALL => getAttribute("SRE_FLAG_DOTALL");

  /// ## SRE_FLAG_DOTALL (setter)
  set SRE_FLAG_DOTALL(Object? SRE_FLAG_DOTALL) =>
      setAttribute("SRE_FLAG_DOTALL", SRE_FLAG_DOTALL);

  /// ## SRE_FLAG_IGNORECASE (getter)
  Object? get SRE_FLAG_IGNORECASE => getAttribute("SRE_FLAG_IGNORECASE");

  /// ## SRE_FLAG_IGNORECASE (setter)
  set SRE_FLAG_IGNORECASE(Object? SRE_FLAG_IGNORECASE) =>
      setAttribute("SRE_FLAG_IGNORECASE", SRE_FLAG_IGNORECASE);

  /// ## SRE_FLAG_LOCALE (getter)
  Object? get SRE_FLAG_LOCALE => getAttribute("SRE_FLAG_LOCALE");

  /// ## SRE_FLAG_LOCALE (setter)
  set SRE_FLAG_LOCALE(Object? SRE_FLAG_LOCALE) =>
      setAttribute("SRE_FLAG_LOCALE", SRE_FLAG_LOCALE);

  /// ## SRE_FLAG_MULTILINE (getter)
  Object? get SRE_FLAG_MULTILINE => getAttribute("SRE_FLAG_MULTILINE");

  /// ## SRE_FLAG_MULTILINE (setter)
  set SRE_FLAG_MULTILINE(Object? SRE_FLAG_MULTILINE) =>
      setAttribute("SRE_FLAG_MULTILINE", SRE_FLAG_MULTILINE);

  /// ## SRE_FLAG_TEMPLATE (getter)
  Object? get SRE_FLAG_TEMPLATE => getAttribute("SRE_FLAG_TEMPLATE");

  /// ## SRE_FLAG_TEMPLATE (setter)
  set SRE_FLAG_TEMPLATE(Object? SRE_FLAG_TEMPLATE) =>
      setAttribute("SRE_FLAG_TEMPLATE", SRE_FLAG_TEMPLATE);

  /// ## SRE_FLAG_UNICODE (getter)
  Object? get SRE_FLAG_UNICODE => getAttribute("SRE_FLAG_UNICODE");

  /// ## SRE_FLAG_UNICODE (setter)
  set SRE_FLAG_UNICODE(Object? SRE_FLAG_UNICODE) =>
      setAttribute("SRE_FLAG_UNICODE", SRE_FLAG_UNICODE);

  /// ## SRE_FLAG_VERBOSE (getter)
  Object? get SRE_FLAG_VERBOSE => getAttribute("SRE_FLAG_VERBOSE");

  /// ## SRE_FLAG_VERBOSE (setter)
  set SRE_FLAG_VERBOSE(Object? SRE_FLAG_VERBOSE) =>
      setAttribute("SRE_FLAG_VERBOSE", SRE_FLAG_VERBOSE);

  /// ## SRE_INFO_CHARSET (getter)
  Object? get SRE_INFO_CHARSET => getAttribute("SRE_INFO_CHARSET");

  /// ## SRE_INFO_CHARSET (setter)
  set SRE_INFO_CHARSET(Object? SRE_INFO_CHARSET) =>
      setAttribute("SRE_INFO_CHARSET", SRE_INFO_CHARSET);

  /// ## SRE_INFO_LITERAL (getter)
  Object? get SRE_INFO_LITERAL => getAttribute("SRE_INFO_LITERAL");

  /// ## SRE_INFO_LITERAL (setter)
  set SRE_INFO_LITERAL(Object? SRE_INFO_LITERAL) =>
      setAttribute("SRE_INFO_LITERAL", SRE_INFO_LITERAL);

  /// ## SRE_INFO_PREFIX (getter)
  Object? get SRE_INFO_PREFIX => getAttribute("SRE_INFO_PREFIX");

  /// ## SRE_INFO_PREFIX (setter)
  set SRE_INFO_PREFIX(Object? SRE_INFO_PREFIX) =>
      setAttribute("SRE_INFO_PREFIX", SRE_INFO_PREFIX);

  /// ## SUBPATTERN (getter)
  Object? get SUBPATTERN => getAttribute("SUBPATTERN");

  /// ## SUBPATTERN (setter)
  set SUBPATTERN(Object? SUBPATTERN) => setAttribute("SUBPATTERN", SUBPATTERN);

  /// ## SUCCESS (getter)
  Object? get SUCCESS => getAttribute("SUCCESS");

  /// ## SUCCESS (setter)
  set SUCCESS(Object? SUCCESS) => setAttribute("SUCCESS", SUCCESS);

  /// ## TYPE_FLAGS (getter)
  Object? get TYPE_FLAGS => getAttribute("TYPE_FLAGS");

  /// ## TYPE_FLAGS (setter)
  set TYPE_FLAGS(Object? TYPE_FLAGS) => setAttribute("TYPE_FLAGS", TYPE_FLAGS);
}

/// ## unicodedata
final class unicodedata extends PythonModule {
  unicodedata.from(super.pythonModule) : super.from();

  static unicodedata import() => PythonFfiDart.instance.importModule(
        "unicodedata",
        unicodedata.from,
      );

  /// ## ucd_3_2_0 (getter)
  Object? get ucd_3_2_0 => getAttribute("ucd_3_2_0");

  /// ## ucd_3_2_0 (setter)
  set ucd_3_2_0(Object? ucd_3_2_0) => setAttribute("ucd_3_2_0", ucd_3_2_0);

  /// ## unidata_version (getter)
  Object? get unidata_version => getAttribute("unidata_version");

  /// ## unidata_version (setter)
  set unidata_version(Object? unidata_version) =>
      setAttribute("unidata_version", unidata_version);
}

/// ## visitors
///
/// ### python source
/// ```py
/// from typing import TypeVar, Tuple, List, Callable, Generic, Type, Union, Optional, Any, cast
/// from abc import ABC
///
/// from .utils import combine_alternatives
/// from .tree import Tree, Branch
/// from .exceptions import VisitError, GrammarError
/// from .lexer import Token
///
/// ###{standalone
/// from functools import wraps, update_wrapper
/// from inspect import getmembers, getmro
///
/// _Return_T = TypeVar('_Return_T')
/// _Return_V = TypeVar('_Return_V')
/// _Leaf_T = TypeVar('_Leaf_T')
/// _Leaf_U = TypeVar('_Leaf_U')
/// _R = TypeVar('_R')
/// _FUNC = Callable[..., _Return_T]
/// _DECORATED = Union[_FUNC, type]
///
/// class _DiscardType:
///     """When the Discard value is returned from a transformer callback,
///     that node is discarded and won't appear in the parent.
///
///     Note:
///         This feature is disabled when the transformer is provided to Lark
///         using the ``transformer`` keyword (aka Tree-less LALR mode).
///
///     Example:
///         ::
///
///             class T(Transformer):
///                 def ignore_tree(self, children):
///                     return Discard
///
///                 def IGNORE_TOKEN(self, token):
///                     return Discard
///     """
///
///     def __repr__(self):
///         return "lark.visitors.Discard"
///
/// Discard = _DiscardType()
///
/// # Transformers
///
/// class _Decoratable:
///     "Provides support for decorating methods with @v_args"
///
///     @classmethod
///     def _apply_v_args(cls, visit_wrapper):
///         mro = getmro(cls)
///         assert mro[0] is cls
///         libmembers = {name for _cls in mro[1:] for name, _ in getmembers(_cls)}
///         for name, value in getmembers(cls):
///
///             # Make sure the function isn't inherited (unless it's overwritten)
///             if name.startswith('_') or (name in libmembers and name not in cls.__dict__):
///                 continue
///             if not callable(value):
///                 continue
///
///             # Skip if v_args already applied (at the function level)
///             if isinstance(cls.__dict__[name], _VArgsWrapper):
///                 continue
///
///             setattr(cls, name, _VArgsWrapper(cls.__dict__[name], visit_wrapper))
///         return cls
///
///     def __class_getitem__(cls, _):
///         return cls
///
///
/// class Transformer(_Decoratable, ABC, Generic[_Leaf_T, _Return_T]):
///     """Transformers work bottom-up (or depth-first), starting with visiting the leaves and working
///     their way up until ending at the root of the tree.
///
///     For each node visited, the transformer will call the appropriate method (callbacks), according to the
///     node's ``data``, and use the returned value to replace the node, thereby creating a new tree structure.
///
///     Transformers can be used to implement map & reduce patterns. Because nodes are reduced from leaf to root,
///     at any point the callbacks may assume the children have already been transformed (if applicable).
///
///     If the transformer cannot find a method with the right name, it will instead call ``__default__``, which by
///     default creates a copy of the node.
///
///     To discard a node, return Discard (``lark.visitors.Discard``).
///
///     ``Transformer`` can do anything ``Visitor`` can do, but because it reconstructs the tree,
///     it is slightly less efficient.
///
///     A transformer without methods essentially performs a non-memoized partial deepcopy.
///
///     All these classes implement the transformer interface:
///
///     - ``Transformer`` - Recursively transforms the tree. This is the one you probably want.
///     - ``Transformer_InPlace`` - Non-recursive. Changes the tree in-place instead of returning new instances
///     - ``Transformer_InPlaceRecursive`` - Recursive. Changes the tree in-place instead of returning new instances
///
///     Parameters:
///         visit_tokens (bool, optional): Should the transformer visit tokens in addition to rules.
///                                        Setting this to ``False`` is slightly faster. Defaults to ``True``.
///                                        (For processing ignored tokens, use the ``lexer_callbacks`` options)
///
///     """
///     __visit_tokens__ = True   # For backwards compatibility
///
///     def __init__(self,  visit_tokens: bool=True) -> None:
///         self.__visit_tokens__ = visit_tokens
///
///     def _call_userfunc(self, tree, new_children=None):
///         # Assumes tree is already transformed
///         children = new_children if new_children is not None else tree.children
///         try:
///             f = getattr(self, tree.data)
///         except AttributeError:
///             return self.__default__(tree.data, children, tree.meta)
///         else:
///             try:
///                 wrapper = getattr(f, 'visit_wrapper', None)
///                 if wrapper is not None:
///                     return f.visit_wrapper(f, tree.data, children, tree.meta)
///                 else:
///                     return f(children)
///             except GrammarError:
///                 raise
///             except Exception as e:
///                 raise VisitError(tree.data, tree, e)
///
///     def _call_userfunc_token(self, token):
///         try:
///             f = getattr(self, token.type)
///         except AttributeError:
///             return self.__default_token__(token)
///         else:
///             try:
///                 return f(token)
///             except GrammarError:
///                 raise
///             except Exception as e:
///                 raise VisitError(token.type, token, e)
///
///     def _transform_children(self, children):
///         for c in children:
///             if isinstance(c, Tree):
///                 res = self._transform_tree(c)
///             elif self.__visit_tokens__ and isinstance(c, Token):
///                 res = self._call_userfunc_token(c)
///             else:
///                 res = c
///
///             if res is not Discard:
///                 yield res
///
///     def _transform_tree(self, tree):
///         children = list(self._transform_children(tree.children))
///         return self._call_userfunc(tree, children)
///
///     def transform(self, tree: Tree[_Leaf_T]) -> _Return_T:
///         "Transform the given tree, and return the final result"
///         return self._transform_tree(tree)
///
///     def __mul__(
///             self: 'Transformer[_Leaf_T, Tree[_Leaf_U]]',
///             other: 'Union[Transformer[_Leaf_U, _Return_V], TransformerChain[_Leaf_U, _Return_V,]]'
///     ) -> 'TransformerChain[_Leaf_T, _Return_V]':
///         """Chain two transformers together, returning a new transformer.
///         """
///         return TransformerChain(self, other)
///
///     def __default__(self, data, children, meta):
///         """Default function that is called if there is no attribute matching ``data``
///
///         Can be overridden. Defaults to creating a new copy of the tree node (i.e. ``return Tree(data, children, meta)``)
///         """
///         return Tree(data, children, meta)
///
///     def __default_token__(self, token):
///         """Default function that is called if there is no attribute matching ``token.type``
///
///         Can be overridden. Defaults to returning the token as-is.
///         """
///         return token
///
///
/// def merge_transformers(base_transformer=None, **transformers_to_merge):
///     """Merge a collection of transformers into the base_transformer, each into its own 'namespace'.
///
///     When called, it will collect the methods from each transformer, and assign them to base_transformer,
///     with their name prefixed with the given keyword, as ``prefix__methodname``.
///
///     This function is especially useful for processing grammars that import other grammars,
///     thereby creating some of their rules in a 'namespace'. (i.e with a consistent name prefix).
///     In this case, the key for the transformer should match the name of the imported grammar.
///
///     Parameters:
///         base_transformer (Transformer, optional): The transformer that all other transformers will be added to.
///         **transformers_to_merge: Keyword arguments, in the form of ``name_prefix = transformer``.
///
///     Raises:
///         AttributeError: In case of a name collision in the merged methods
///
///     Example:
///         ::
///
///             class TBase(Transformer):
///                 def start(self, children):
///                     return children[0] + 'bar'
///
///             class TImportedGrammar(Transformer):
///                 def foo(self, children):
///                     return "foo"
///
///             composed_transformer = merge_transformers(TBase(), imported=TImportedGrammar())
///
///             t = Tree('start', [ Tree('imported__foo', []) ])
///
///             assert composed_transformer.transform(t) == 'foobar'
///
///     """
///     if base_transformer is None:
///         base_transformer = Transformer()
///     for prefix, transformer in transformers_to_merge.items():
///         for method_name in dir(transformer):
///             method = getattr(transformer, method_name)
///             if not callable(method):
///                 continue
///             if method_name.startswith("_") or method_name == "transform":
///                 continue
///             prefixed_method = prefix + "__" + method_name
///             if hasattr(base_transformer, prefixed_method):
///                 raise AttributeError("Cannot merge: method '%s' appears more than once" % prefixed_method)
///
///             setattr(base_transformer, prefixed_method, method)
///
///     return base_transformer
///
///
/// class InlineTransformer(Transformer):   # XXX Deprecated
///     def _call_userfunc(self, tree, new_children=None):
///         # Assumes tree is already transformed
///         children = new_children if new_children is not None else tree.children
///         try:
///             f = getattr(self, tree.data)
///         except AttributeError:
///             return self.__default__(tree.data, children, tree.meta)
///         else:
///             return f(*children)
///
///
/// class TransformerChain(Generic[_Leaf_T, _Return_T]):
///
///     transformers: 'Tuple[Union[Transformer, TransformerChain], ...]'
///
///     def __init__(self, *transformers: 'Union[Transformer, TransformerChain]') -> None:
///         self.transformers = transformers
///
///     def transform(self, tree: Tree[_Leaf_T]) -> _Return_T:
///         for t in self.transformers:
///             tree = t.transform(tree)
///         return cast(_Return_T, tree)
///
///     def __mul__(
///             self: 'TransformerChain[_Leaf_T, Tree[_Leaf_U]]',
///             other: 'Union[Transformer[_Leaf_U, _Return_V], TransformerChain[_Leaf_U, _Return_V]]'
///     ) -> 'TransformerChain[_Leaf_T, _Return_V]':
///         return TransformerChain(*self.transformers + (other,))
///
///
/// class Transformer_InPlace(Transformer):
///     """Same as Transformer, but non-recursive, and changes the tree in-place instead of returning new instances
///
///     Useful for huge trees. Conservative in memory.
///     """
///     def _transform_tree(self, tree):           # Cancel recursion
///         return self._call_userfunc(tree)
///
///     def transform(self, tree: Tree[_Leaf_T]) -> _Return_T:
///         for subtree in tree.iter_subtrees():
///             subtree.children = list(self._transform_children(subtree.children))
///
///         return self._transform_tree(tree)
///
///
/// class Transformer_NonRecursive(Transformer):
///     """Same as Transformer but non-recursive.
///
///     Like Transformer, it doesn't change the original tree.
///
///     Useful for huge trees.
///     """
///
///     def transform(self, tree: Tree[_Leaf_T]) -> _Return_T:
///         # Tree to postfix
///         rev_postfix = []
///         q: List[Branch[_Leaf_T]] = [tree]
///         while q:
///             t = q.pop()
///             rev_postfix.append(t)
///             if isinstance(t, Tree):
///                 q += t.children
///
///         # Postfix to tree
///         stack: List = []
///         for x in reversed(rev_postfix):
///             if isinstance(x, Tree):
///                 size = len(x.children)
///                 if size:
///                     args = stack[-size:]
///                     del stack[-size:]
///                 else:
///                     args = []
///
///                 res = self._call_userfunc(x, args)
///                 if res is not Discard:
///                     stack.append(res)
///
///             elif self.__visit_tokens__ and isinstance(x, Token):
///                 res = self._call_userfunc_token(x)
///                 if res is not Discard:
///                     stack.append(res)
///             else:
///                 stack.append(x)
///
///         result, = stack  # We should have only one tree remaining
///         # There are no guarantees on the type of the value produced by calling a user func for a
///         # child will produce. This means type system can't statically know that the final result is
///         # _Return_T. As a result a cast is required.
///         return cast(_Return_T, result)
///
///
/// class Transformer_InPlaceRecursive(Transformer):
///     "Same as Transformer, recursive, but changes the tree in-place instead of returning new instances"
///     def _transform_tree(self, tree):
///         tree.children = list(self._transform_children(tree.children))
///         return self._call_userfunc(tree)
///
///
/// # Visitors
///
/// class VisitorBase:
///     def _call_userfunc(self, tree):
///         return getattr(self, tree.data, self.__default__)(tree)
///
///     def __default__(self, tree):
///         """Default function that is called if there is no attribute matching ``tree.data``
///
///         Can be overridden. Defaults to doing nothing.
///         """
///         return tree
///
///     def __class_getitem__(cls, _):
///         return cls
///
///
/// class Visitor(VisitorBase, ABC, Generic[_Leaf_T]):
///     """Tree visitor, non-recursive (can handle huge trees).
///
///     Visiting a node calls its methods (provided by the user via inheritance) according to ``tree.data``
///     """
///
///     def visit(self, tree: Tree[_Leaf_T]) -> Tree[_Leaf_T]:
///         "Visits the tree, starting with the leaves and finally the root (bottom-up)"
///         for subtree in tree.iter_subtrees():
///             self._call_userfunc(subtree)
///         return tree
///
///     def visit_topdown(self, tree: Tree[_Leaf_T]) -> Tree[_Leaf_T]:
///         "Visit the tree, starting at the root, and ending at the leaves (top-down)"
///         for subtree in tree.iter_subtrees_topdown():
///             self._call_userfunc(subtree)
///         return tree
///
///
/// class Visitor_Recursive(VisitorBase, Generic[_Leaf_T]):
///     """Bottom-up visitor, recursive.
///
///     Visiting a node calls its methods (provided by the user via inheritance) according to ``tree.data``
///
///     Slightly faster than the non-recursive version.
///     """
///
///     def visit(self, tree: Tree[_Leaf_T]) -> Tree[_Leaf_T]:
///         "Visits the tree, starting with the leaves and finally the root (bottom-up)"
///         for child in tree.children:
///             if isinstance(child, Tree):
///                 self.visit(child)
///
///         self._call_userfunc(tree)
///         return tree
///
///     def visit_topdown(self,tree: Tree[_Leaf_T]) -> Tree[_Leaf_T]:
///         "Visit the tree, starting at the root, and ending at the leaves (top-down)"
///         self._call_userfunc(tree)
///
///         for child in tree.children:
///             if isinstance(child, Tree):
///                 self.visit_topdown(child)
///
///         return tree
///
///
/// class Interpreter(_Decoratable, ABC, Generic[_Leaf_T, _Return_T]):
///     """Interpreter walks the tree starting at the root.
///
///     Visits the tree, starting with the root and finally the leaves (top-down)
///
///     For each tree node, it calls its methods (provided by user via inheritance) according to ``tree.data``.
///
///     Unlike ``Transformer`` and ``Visitor``, the Interpreter doesn't automatically visit its sub-branches.
///     The user has to explicitly call ``visit``, ``visit_children``, or use the ``@visit_children_decor``.
///     This allows the user to implement branching and loops.
///     """
///
///     def visit(self, tree: Tree[_Leaf_T]) -> _Return_T:
///         # There are no guarantees on the type of the value produced by calling a user func for a
///         # child will produce. So only annotate the public method and use an internal method when
///         # visiting child trees.
///         return self._visit_tree(tree)
///
///     def _visit_tree(self, tree: Tree[_Leaf_T]):
///         f = getattr(self, tree.data)
///         wrapper = getattr(f, 'visit_wrapper', None)
///         if wrapper is not None:
///             return f.visit_wrapper(f, tree.data, tree.children, tree.meta)
///         else:
///             return f(tree)
///
///     def visit_children(self, tree: Tree[_Leaf_T]) -> List:
///         return [self._visit_tree(child) if isinstance(child, Tree) else child
///                 for child in tree.children]
///
///     def __getattr__(self, name):
///         return self.__default__
///
///     def __default__(self, tree):
///         return self.visit_children(tree)
///
///
/// _InterMethod = Callable[[Type[Interpreter], _Return_T], _R]
///
/// def visit_children_decor(func: _InterMethod) -> _InterMethod:
///     "See Interpreter"
///     @wraps(func)
///     def inner(cls, tree):
///         values = cls.visit_children(tree)
///         return func(cls, values)
///     return inner
///
/// # Decorators
///
/// def _apply_v_args(obj, visit_wrapper):
///     try:
///         _apply = obj._apply_v_args
///     except AttributeError:
///         return _VArgsWrapper(obj, visit_wrapper)
///     else:
///         return _apply(visit_wrapper)
///
///
/// class _VArgsWrapper:
///     """
///     A wrapper around a Callable. It delegates `__call__` to the Callable.
///     If the Callable has a `__get__`, that is also delegate and the resulting function is wrapped.
///     Otherwise, we use the original function mirroring the behaviour without a __get__.
///     We also have the visit_wrapper attribute to be used by Transformers.
///     """
///     base_func: Callable
///
///     def __init__(self, func: Callable, visit_wrapper: Callable[[Callable, str, list, Any], Any]):
///         if isinstance(func, _VArgsWrapper):
///             func = func.base_func
///         # https://github.com/python/mypy/issues/708
///         self.base_func = func  # type: ignore[assignment]
///         self.visit_wrapper = visit_wrapper
///         update_wrapper(self, func)
///
///     def __call__(self, *args, **kwargs):
///         return self.base_func(*args, **kwargs)
///
///     def __get__(self, instance, owner=None):
///         try:
///             # Use the __get__ attribute of the type instead of the instance
///             # to fully mirror the behavior of getattr
///             g = type(self.base_func).__get__
///         except AttributeError:
///             return self
///         else:
///             return _VArgsWrapper(g(self.base_func, instance, owner), self.visit_wrapper)
///
///     def __set_name__(self, owner, name):
///         try:
///             f = type(self.base_func).__set_name__
///         except AttributeError:
///             return
///         else:
///             f(self.base_func, owner, name)
///
///
/// def _vargs_inline(f, _data, children, _meta):
///     return f(*children)
/// def _vargs_meta_inline(f, _data, children, meta):
///     return f(meta, *children)
/// def _vargs_meta(f, _data, children, meta):
///     return f(meta, children)
/// def _vargs_tree(f, data, children, meta):
///     return f(Tree(data, children, meta))
///
///
/// def v_args(inline: bool = False, meta: bool = False, tree: bool = False, wrapper: Optional[Callable] = None) -> Callable[[_DECORATED], _DECORATED]:
///     """A convenience decorator factory for modifying the behavior of user-supplied visitor methods.
///
///     By default, callback methods of transformers/visitors accept one argument - a list of the node's children.
///
///     ``v_args`` can modify this behavior. When used on a transformer/visitor class definition,
///     it applies to all the callback methods inside it.
///
///     ``v_args`` can be applied to a single method, or to an entire class. When applied to both,
///     the options given to the method take precedence.
///
///     Parameters:
///         inline (bool, optional): Children are provided as ``*args`` instead of a list argument (not recommended for very long lists).
///         meta (bool, optional): Provides two arguments: ``children`` and ``meta`` (instead of just the first)
///         tree (bool, optional): Provides the entire tree as the argument, instead of the children.
///         wrapper (function, optional): Provide a function to decorate all methods.
///
///     Example:
///         ::
///
///             @v_args(inline=True)
///             class SolveArith(Transformer):
///                 def add(self, left, right):
///                     return left + right
///
///
///             class ReverseNotation(Transformer_InPlace):
///                 @v_args(tree=True)
///                 def tree_node(self, tree):
///                     tree.children = tree.children[::-1]
///     """
///     if tree and (meta or inline):
///         raise ValueError("Visitor functions cannot combine 'tree' with 'meta' or 'inline'.")
///
///     func = None
///     if meta:
///         if inline:
///             func = _vargs_meta_inline
///         else:
///             func = _vargs_meta
///     elif inline:
///         func = _vargs_inline
///     elif tree:
///         func = _vargs_tree
///
///     if wrapper is not None:
///         if func is not None:
///             raise ValueError("Cannot use 'wrapper' along with 'tree', 'meta' or 'inline'.")
///         func = wrapper
///
///     def _visitor_args_dec(obj):
///         return _apply_v_args(obj, func)
///     return _visitor_args_dec
///
///
/// ###}
///
///
/// # --- Visitor Utilities ---
///
/// class CollapseAmbiguities(Transformer):
///     """
///     Transforms a tree that contains any number of _ambig nodes into a list of trees,
///     each one containing an unambiguous tree.
///
///     The length of the resulting list is the product of the length of all _ambig nodes.
///
///     Warning: This may quickly explode for highly ambiguous trees.
///
///     """
///     def _ambig(self, options):
///         return sum(options, [])
///
///     def __default__(self, data, children_lists, meta):
///         return [Tree(data, children, meta) for children in combine_alternatives(children_lists)]
///
///     def __default_token__(self, t):
///         return [t]
/// ```
final class visitors extends PythonModule {
  visitors.from(super.pythonModule) : super.from();

  static visitors import() => PythonFfiDart.instance.importModule(
        "lark.visitors",
        visitors.from,
      );

  /// ## merge_transformers
  ///
  /// ### python docstring
  ///
  /// Merge a collection of transformers into the base_transformer, each into its own 'namespace'.
  ///
  /// When called, it will collect the methods from each transformer, and assign them to base_transformer,
  /// with their name prefixed with the given keyword, as ``prefix__methodname``.
  ///
  /// This function is especially useful for processing grammars that import other grammars,
  /// thereby creating some of their rules in a 'namespace'. (i.e with a consistent name prefix).
  /// In this case, the key for the transformer should match the name of the imported grammar.
  ///
  /// Parameters:
  ///     base_transformer (Transformer, optional): The transformer that all other transformers will be added to.
  ///     **transformers_to_merge: Keyword arguments, in the form of ``name_prefix = transformer``.
  ///
  /// Raises:
  ///     AttributeError: In case of a name collision in the merged methods
  ///
  /// Example:
  ///     ::
  ///
  ///         class TBase(Transformer):
  ///             def start(self, children):
  ///                 return children[0] + 'bar'
  ///
  ///         class TImportedGrammar(Transformer):
  ///             def foo(self, children):
  ///                 return "foo"
  ///
  ///         composed_transformer = merge_transformers(TBase(), imported=TImportedGrammar())
  ///
  ///         t = Tree('start', [ Tree('imported__foo', []) ])
  ///
  ///         assert composed_transformer.transform(t) == 'foobar'
  ///
  /// ### python source
  /// ```py
  /// def merge_transformers(base_transformer=None, **transformers_to_merge):
  ///     """Merge a collection of transformers into the base_transformer, each into its own 'namespace'.
  ///
  ///     When called, it will collect the methods from each transformer, and assign them to base_transformer,
  ///     with their name prefixed with the given keyword, as ``prefix__methodname``.
  ///
  ///     This function is especially useful for processing grammars that import other grammars,
  ///     thereby creating some of their rules in a 'namespace'. (i.e with a consistent name prefix).
  ///     In this case, the key for the transformer should match the name of the imported grammar.
  ///
  ///     Parameters:
  ///         base_transformer (Transformer, optional): The transformer that all other transformers will be added to.
  ///         **transformers_to_merge: Keyword arguments, in the form of ``name_prefix = transformer``.
  ///
  ///     Raises:
  ///         AttributeError: In case of a name collision in the merged methods
  ///
  ///     Example:
  ///         ::
  ///
  ///             class TBase(Transformer):
  ///                 def start(self, children):
  ///                     return children[0] + 'bar'
  ///
  ///             class TImportedGrammar(Transformer):
  ///                 def foo(self, children):
  ///                     return "foo"
  ///
  ///             composed_transformer = merge_transformers(TBase(), imported=TImportedGrammar())
  ///
  ///             t = Tree('start', [ Tree('imported__foo', []) ])
  ///
  ///             assert composed_transformer.transform(t) == 'foobar'
  ///
  ///     """
  ///     if base_transformer is None:
  ///         base_transformer = Transformer()
  ///     for prefix, transformer in transformers_to_merge.items():
  ///         for method_name in dir(transformer):
  ///             method = getattr(transformer, method_name)
  ///             if not callable(method):
  ///                 continue
  ///             if method_name.startswith("_") or method_name == "transform":
  ///                 continue
  ///             prefixed_method = prefix + "__" + method_name
  ///             if hasattr(base_transformer, prefixed_method):
  ///                 raise AttributeError("Cannot merge: method '%s' appears more than once" % prefixed_method)
  ///
  ///             setattr(base_transformer, prefixed_method, method)
  ///
  ///     return base_transformer
  /// ```
  Object? merge_transformers({
    Object? base_transformer,
    Map<String, Object?> transformers_to_merge = const <String, Object?>{},
  }) =>
      getFunction("merge_transformers").call(
        <Object?>[
          base_transformer,
        ],
        kwargs: <String, Object?>{
          ...transformers_to_merge,
        },
      );

  /// ## v_args
  ///
  /// ### python docstring
  ///
  /// A convenience decorator factory for modifying the behavior of user-supplied visitor methods.
  ///
  /// By default, callback methods of transformers/visitors accept one argument - a list of the node's children.
  ///
  /// ``v_args`` can modify this behavior. When used on a transformer/visitor class definition,
  /// it applies to all the callback methods inside it.
  ///
  /// ``v_args`` can be applied to a single method, or to an entire class. When applied to both,
  /// the options given to the method take precedence.
  ///
  /// Parameters:
  ///     inline (bool, optional): Children are provided as ``*args`` instead of a list argument (not recommended for very long lists).
  ///     meta (bool, optional): Provides two arguments: ``children`` and ``meta`` (instead of just the first)
  ///     tree (bool, optional): Provides the entire tree as the argument, instead of the children.
  ///     wrapper (function, optional): Provide a function to decorate all methods.
  ///
  /// Example:
  ///     ::
  ///
  ///         @v_args(inline=True)
  ///         class SolveArith(Transformer):
  ///             def add(self, left, right):
  ///                 return left + right
  ///
  ///
  ///         class ReverseNotation(Transformer_InPlace):
  ///             @v_args(tree=True)
  ///             def tree_node(self, tree):
  ///                 tree.children = tree.children[::-1]
  ///
  /// ### python source
  /// ```py
  /// def v_args(inline: bool = False, meta: bool = False, tree: bool = False, wrapper: Optional[Callable] = None) -> Callable[[_DECORATED], _DECORATED]:
  ///     """A convenience decorator factory for modifying the behavior of user-supplied visitor methods.
  ///
  ///     By default, callback methods of transformers/visitors accept one argument - a list of the node's children.
  ///
  ///     ``v_args`` can modify this behavior. When used on a transformer/visitor class definition,
  ///     it applies to all the callback methods inside it.
  ///
  ///     ``v_args`` can be applied to a single method, or to an entire class. When applied to both,
  ///     the options given to the method take precedence.
  ///
  ///     Parameters:
  ///         inline (bool, optional): Children are provided as ``*args`` instead of a list argument (not recommended for very long lists).
  ///         meta (bool, optional): Provides two arguments: ``children`` and ``meta`` (instead of just the first)
  ///         tree (bool, optional): Provides the entire tree as the argument, instead of the children.
  ///         wrapper (function, optional): Provide a function to decorate all methods.
  ///
  ///     Example:
  ///         ::
  ///
  ///             @v_args(inline=True)
  ///             class SolveArith(Transformer):
  ///                 def add(self, left, right):
  ///                     return left + right
  ///
  ///
  ///             class ReverseNotation(Transformer_InPlace):
  ///                 @v_args(tree=True)
  ///                 def tree_node(self, tree):
  ///                     tree.children = tree.children[::-1]
  ///     """
  ///     if tree and (meta or inline):
  ///         raise ValueError("Visitor functions cannot combine 'tree' with 'meta' or 'inline'.")
  ///
  ///     func = None
  ///     if meta:
  ///         if inline:
  ///             func = _vargs_meta_inline
  ///         else:
  ///             func = _vargs_meta
  ///     elif inline:
  ///         func = _vargs_inline
  ///     elif tree:
  ///         func = _vargs_tree
  ///
  ///     if wrapper is not None:
  ///         if func is not None:
  ///             raise ValueError("Cannot use 'wrapper' along with 'tree', 'meta' or 'inline'.")
  ///         func = wrapper
  ///
  ///     def _visitor_args_dec(obj):
  ///         return _apply_v_args(obj, func)
  ///     return _visitor_args_dec
  /// ```
  Object? v_args({
    Object? inline = false,
    Object? meta = false,
    Object? tree = false,
    Object? wrapper,
  }) =>
      getFunction("v_args").call(
        <Object?>[
          inline,
          meta,
          tree,
          wrapper,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## visit_children_decor
  ///
  /// ### python docstring
  ///
  /// See Interpreter
  ///
  /// ### python source
  /// ```py
  /// def visit_children_decor(func: _InterMethod) -> _InterMethod:
  ///     "See Interpreter"
  ///     @wraps(func)
  ///     def inner(cls, tree):
  ///         values = cls.visit_children(tree)
  ///         return func(cls, values)
  ///     return inner
  /// ```
  Object? visit_children_decor({
    required Object? func,
  }) =>
      getFunction("visit_children_decor").call(
        <Object?>[
          func,
        ],
        kwargs: <String, Object?>{},
      );

  /// ## Discard (getter)
  ///
  /// ### python docstring
  ///
  /// When the Discard value is returned from a transformer callback,
  /// that node is discarded and won't appear in the parent.
  ///
  /// Note:
  ///     This feature is disabled when the transformer is provided to Lark
  ///     using the ``transformer`` keyword (aka Tree-less LALR mode).
  ///
  /// Example:
  ///     ::
  ///
  ///         class T(Transformer):
  ///             def ignore_tree(self, children):
  ///                 return Discard
  ///
  ///             def IGNORE_TOKEN(self, token):
  ///                 return Discard
  Object? get Discard => getAttribute("Discard");

  /// ## Discard (setter)
  ///
  /// ### python docstring
  ///
  /// When the Discard value is returned from a transformer callback,
  /// that node is discarded and won't appear in the parent.
  ///
  /// Note:
  ///     This feature is disabled when the transformer is provided to Lark
  ///     using the ``transformer`` keyword (aka Tree-less LALR mode).
  ///
  /// Example:
  ///     ::
  ///
  ///         class T(Transformer):
  ///             def ignore_tree(self, children):
  ///                 return Discard
  ///
  ///             def IGNORE_TOKEN(self, token):
  ///                 return Discard
  set Discard(Object? Discard) => setAttribute("Discard", Discard);
}
